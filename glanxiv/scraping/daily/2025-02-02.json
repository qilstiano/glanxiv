[
  {
    "id": "http://arxiv.org/abs/2502.00960v1",
    "title": "SAM-guided Pseudo Label Enhancement for Multi-modal 3D Semantic Segmentation",
    "authors": [
      "Mingyu Yang",
      "Jitong Lu",
      "Hun-Seok Kim"
    ],
    "abstract": "Multi-modal 3D semantic segmentation is vital for applications such as\nautonomous driving and virtual reality (VR). To effectively deploy these models\nin real-world scenarios, it is essential to employ cross-domain adaptation\ntechniques that bridge the gap between training data and real-world data.\nRecently, self-training with pseudo-labels has emerged as a predominant method\nfor cross-domain adaptation in multi-modal 3D semantic segmentation. However,\ngenerating reliable pseudo-labels necessitates stringent constraints, which\noften result in sparse pseudo-labels after pruning. This sparsity can\npotentially hinder performance improvement during the adaptation process. We\npropose an image-guided pseudo-label enhancement approach that leverages the\ncomplementary 2D prior knowledge from the Segment Anything Model (SAM) to\nintroduce more reliable pseudo-labels, thereby boosting domain adaptation\nperformance. Specifically, given a 3D point cloud and the SAM masks from its\npaired image data, we collect all 3D points covered by each SAM mask that\npotentially belong to the same object. Then our method refines the\npseudo-labels within each SAM mask in two steps. First, we determine the class\nlabel for each mask using majority voting and employ various constraints to\nfilter out unreliable mask labels. Next, we introduce Geometry-Aware\nProgressive Propagation (GAPP) which propagates the mask label to all 3D points\nwithin the SAM mask while avoiding outliers caused by 2D-3D misalignment.\nExperiments conducted across multiple datasets and domain adaptation scenarios\ndemonstrate that our proposed method significantly increases the quantity of\nhigh-quality pseudo-labels and enhances the adaptation performance over\nbaseline methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.00960v1",
    "published": "2025-02-02T23:52:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00959v1",
    "title": "An algebraic model for rational U(2)-spectra",
    "authors": [
      "J. P. C. Greenlees"
    ],
    "abstract": "We construct an explicit and calculable models for rational U(2)-spectra.\nThis is obtained by assembling seven blocks obtained in previous work: the\ntoral part and earlier work on small toral groups. The assembly process\nrequires detailed input on fusion and Weyl groups.",
    "pdf_url": "http://arxiv.org/pdf/2502.00959v1",
    "published": "2025-02-02T23:39:47+00:00",
    "categories": [
      "math.AT",
      "55P42, 55P91"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00958v1",
    "title": "Inertial Updating with General Information",
    "authors": [
      "Adam Dominiak",
      "Matthew Kovach",
      "Gerelt Tserenjigmid"
    ],
    "abstract": "We study belief revision when information is represented by a set of\nprobability distributions, or general information. General information extends\nthe standard event notion while including qualitative information (A is more\nlikely than B), interval information (A has a ten-to-twenty percent chance),\nand more. We behaviorally characterize Inertial Updating: the decision maker's\nposterior is of minimal subjective distance from her prior, given the\ninformation constraint. Further, we introduce and characterize a notion of\nBayesian updating for general information and show that Bayesian agents may\ndisagree. We also behaviorally characterize f-divergences, the class of\ndistances consistent with Bayesian updating.",
    "pdf_url": "http://arxiv.org/pdf/2502.00958v1",
    "published": "2025-02-02T23:36:52+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2502.00957v1",
    "title": "Pauli webs spun by transversal $|Y\\rangle$ state initialisation",
    "authors": [
      "Kwok Ho Wan",
      "Zhenghao Zhong"
    ],
    "abstract": "Originally motivated by the (fold-)transversal related initialisation of\nlogical surface code $|Y\\rangle$ states from [arXiv:1603.02286,\narXiv:2302.07395, arXiv:2302.12292], which was then explicitly extended to the\nfold-transversal $S$ gate implementation in [arXiv:2412.01391] for the rotated\nsurface code, we employ ZX-calculus and Pauli web to understand the\n$|Y\\rangle=S|+\\rangle$ state transversal initialisation scheme.",
    "pdf_url": "http://arxiv.org/pdf/2502.00957v1",
    "published": "2025-02-02T23:29:32+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00956v1",
    "title": "$RO(C_2\\times C_2)$-graded cohomology ring of a point and applications",
    "authors": [
      "Bill Deng",
      "Mircea Voineagu"
    ],
    "abstract": "We describe the main properties of the $RO(C_2\\times \\Sigma_2)$-graded\ncohomology ring of a point and apply the results to compute the subring of\nmotivic classes given by the Bredon motivic cohomology of real numbers and to\ncompute $RO(C_2\\times \\Sigma_2)$-graded cohomology ring of $E_{\\Sigma_2}C_2$.\n  This generalizes Voevodsky's identification of motivic cohomology of real\nnumbers with the positive cone of $RO(C_2)$ graded cohomology of a point.",
    "pdf_url": "http://arxiv.org/pdf/2502.00956v1",
    "published": "2025-02-02T23:20:56+00:00",
    "categories": [
      "math.AT",
      "math.AG",
      "math.KT"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00955v1",
    "title": "Efficient Multi-Agent System Training with Data Influence-Oriented Tree Search",
    "authors": [
      "Wentao Shi",
      "Zichun Yu",
      "Fuli Feng",
      "Xiangnan He",
      "Chenyan Xiong"
    ],
    "abstract": "Monte Carlo Tree Search (MCTS) based methods provide promising approaches for\ngenerating synthetic data to enhance the self-training of Large Language Model\n(LLM) based multi-agent systems (MAS). These methods leverage Q-values to\nestimate individual agent contributions. However, relying solely on Q-values to\nidentify informative data may misalign with the data synthesis objective, as\nthe focus should be on selecting data that best enhances model training. To\naddress this discrepancy, we propose Data Influence-oriented Tree Search\n(DITS), a novel framework that incorporates influence scores to guide both tree\nsearch and data selection. By leveraging influence scores, we effectively\nidentify the most impactful data for system improvement, thereby enhancing\nmodel performance. Furthermore, we derive influence score estimation methods\ntailored for non-differentiable metrics, significantly reducing computational\noverhead by utilizing inference computations. Extensive experiments on eight\nmulti-agent datasets demonstrate the robustness and effectiveness of the\nproposed methods. Notably, our findings reveal that allocating more inference\nresources to estimate influence scores, rather than Q-values, during data\nsynthesis can more effectively and efficiently enhance model training.",
    "pdf_url": "http://arxiv.org/pdf/2502.00955v1",
    "published": "2025-02-02T23:20:16+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00954v3",
    "title": "Hypo3D: Exploring Hypothetical Reasoning in 3D",
    "authors": [
      "Ye Mao",
      "Weixun Luo",
      "Junpeng Jing",
      "Anlan Qiu",
      "Krystian Mikolajczyk"
    ],
    "abstract": "The rise of vision-language foundation models marks an advancement in\nbridging the gap between human and machine capabilities in 3D scene reasoning.\nExisting 3D reasoning benchmarks assume real-time scene accessibility, which is\nimpractical due to the high cost of frequent scene updates. To this end, we\nintroduce Hypothetical 3D Reasoning, namely Hypo3D, a benchmark designed to\nevaluate models' ability to reason without access to real-time scene data.\nModels need to imagine the scene state based on a provided change description\nbefore reasoning. Hypo3D is formulated as a 3D Visual Question Answering (VQA)\nbenchmark, comprising 7,727 context changes across 700 indoor scenes, resulting\nin 14,885 question-answer pairs. An anchor-based world frame is established for\nall scenes, ensuring consistent reference to a global frame for directional\nterms in context changes and QAs. Extensive experiments show that\nstate-of-the-art foundation models struggle to reason in hypothetically changed\nscenes. This reveals a substantial performance gap compared to humans,\nparticularly in scenarios involving movement changes and directional reasoning.\nEven when the context change is irrelevant to the question, models often\nincorrectly adjust their answers. Project website:\nhttps://matchlab-imperial.github.io/Hypo3D/",
    "pdf_url": "http://arxiv.org/pdf/2502.00954v3",
    "published": "2025-02-02T23:11:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.01696v1",
    "title": "Local Quantum Mechanical Prediction of the Singlet State",
    "authors": [
      "Carl F. Diether III"
    ],
    "abstract": "We deduce the quantum mechanical prediction of $-{\\bf a}\\cdot{\\bf b}$ for the\nsinglet spin state employing local measurement functions following Bell's\napproach. Our derivation is corroborated through a computational simulation\nconducted via the Mathematica programming environment.",
    "pdf_url": "http://arxiv.org/pdf/2502.01696v1",
    "published": "2025-02-02T23:11:16+00:00",
    "categories": [
      "physics.gen-ph"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00953v1",
    "title": "Partitioned solution strategies for coupled BEM-FEM acoustic fluid-structure interaction problems",
    "authors": [
      "Luis Rodríguez-Tembleque",
      "José A. González",
      "Antonio Cerrato"
    ],
    "abstract": "This paper investigates two FEM-BEM coupling formulations for acoustic\nfluid-structure interaction (FSI) problems, using the Finite Element Method\n(FEM) to model the structure and the Boundary Element Method (BEM) to represent\na linear acoustic fluid. The coupling methods described interconnect fluid and\nstructure using classical or localized Lagrange multipliers, allowing the\nconnection of non-matching interfaces. First coupling technique is the well\nknown mortar method, that uses classical multipliers and is compared with a new\nformulation of the method of localized Lagrange multipliers (LLM) for FSI\napplications with non-matching interfaces. The proposed non-overlapping domain\ndecomposition technique uses a classical non-symmetrical acoustic BEM\nformulation for the fluid, although a symmetric Galerkin BEM formulation could\nbe used as well. A comparison between the localized methodology and the mortar\nmethod in highly non conforming interface meshes is presented. Furthermore, the\nmethodology proposes an iterative preconditioned and projected bi-conjugate\ngradient solver which presents very good scalability properties in the solution\nof this kind of problems.",
    "pdf_url": "http://arxiv.org/pdf/2502.00953v1",
    "published": "2025-02-02T23:10:53+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00952v1",
    "title": "Mapping the Spiral of Silence: Surveying Unspoken Opinions in Online Communities",
    "authors": [
      "Dora Zhao",
      "Diyi Yang",
      "Michael S. Bernstein"
    ],
    "abstract": "We often treat social media as a lens onto society. How might that lens be\ndistorting the actual popularity of political and social viewpoints? In this\npaper, we examine the difference between the viewpoints publicly posted in a\ncommunity and the privately surveyed viewpoints of community members,\ncontributing a measurement of a theory called the \"spiral of silence.\" This\ntheory observes that people are less likely to voice their opinion when they\nbelieve they are in the minority--leading to a spiral where minority opinions\nare less likely to be shared, so they appear even further in the minority, and\nbecome even less likely to be shared. We surveyed active members of politically\noriented Reddit communities to gauge their willingness to post on contentious\ntopics, yielding 627 responses from 108 participants about 11 topics and 33\nsubreddits. We find that 72.6% of participants who perceive themselves in the\nminority remain silent, and are only half as likely to post their viewpoint\ncompared to those who believe their opinion is in the majority. Communities\nperceived as being more inclusive reduce the magnitude of this effect. These\nresults emphasize how far out of step the opinions we see online may be with\nthe population they purport to represent.",
    "pdf_url": "http://arxiv.org/pdf/2502.00952v1",
    "published": "2025-02-02T23:06:05+00:00",
    "categories": [
      "cs.SI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00951v1",
    "title": "Graph parameters that are coarsely equivalent to tree-length",
    "authors": [
      "Feodor F. Dragan"
    ],
    "abstract": "Two graph parameters are said to be coarsely equivalent if they are within\nconstant factors from each other for every graph $G$. Recently, several graph\nparameters were shown to be coarsely equivalent to tree-length. Recall that the\nlength of a tree-decomposition ${\\cal T}(G)$ of a graph $G$ is the largest\ndiameter of a bag in ${\\cal T}(G)$, and the tree-length of $G$ is the minimum\nof the length, over all tree-decompositions of $G$. We present simpler and\nsometimes with better bounds proofs for those known in literature results and\nfurther extend this list of graph parameters coarsely equivalent to\ntree-length. Among other new results, we show that the tree-length of a graph\n$G$ is small if and only if for every bramble ${\\cal F}$ (or every Helly family\nof connected subgraphs ${\\cal F}$, or every Helly family of paths ${\\cal F}$)\nof $G$, there is a disk in $G$ with small radius that intercepts all members of\n${\\cal F}$. Furthermore, the tree-length of a graph $G$ is small if and only if\n$G$ can be embedded with a small additive distortion to an unweighted tree with\nthe same vertex set as in $G$ (not involving any Steiner points). Additionally,\nwe introduce a new natural \"bridging`` property for cycles, which generalizes a\nknown property of cycles in chordal graphs, and show that it also coarsely\ndefines the tree-length.",
    "pdf_url": "http://arxiv.org/pdf/2502.00951v1",
    "published": "2025-02-02T23:05:26+00:00",
    "categories": [
      "math.CO",
      "cs.DS"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00950v3",
    "title": "Fast Audio Codec Identification Using Overlapping LCS",
    "authors": [
      "Farzane Jafari"
    ],
    "abstract": "Audio data are widely exchanged over telecommunications networks. Due to the\nlimitations of network resources, these data are typically compressed before\ntransmission. Various methods are available for compressing audio data. To\naccess such audio information, it is first necessary to identify the codec used\nfor compression. One of the most effective approaches for audio codec\nidentification involves analyzing the content of received packets. In these\nmethods, statistical features extracted from the packets are utilized to\ndetermine the codec employed. This paper proposes a novel method for audio\ncodec classification based on features derived from the overlapped longest\ncommon sub-string and sub-sequence (LCS). The simulation results, which\nachieved an accuracy of 97% for 8 KB packets, demonstrate the superiority of\nthe proposed method over conventional approaches. This method divides each 8 KB\npacket into fifteen 1 KB packets with a 50% overlap. The results indicate that\nthis division has no significant impact on the simulation outcomes, while\nsignificantly speeding up the feature extraction, being eight times faster than\nthe traditional method for extracting LCS features.",
    "pdf_url": "http://arxiv.org/pdf/2502.00950v3",
    "published": "2025-02-02T23:04:55+00:00",
    "categories": [
      "cs.MM",
      "cs.CR"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2502.00949v1",
    "title": "A domain-theoretic framework for conditional probability and Bayesian updating in programming",
    "authors": [
      "Pietro Di Gianantonio",
      "Abbas Edalat"
    ],
    "abstract": "We present a domain-theoretic framework for probabilistic programming that\nprovides a constructive definition of conditional probability and addresses\ncomputability challenges previously identified in the literature. We introduce\na novel approach based on an observable notion of events that enables\ncomputability. We examine two methods for computing conditional probabilities\n-- one using conditional density functions and another using trace sampling\nwith rejection -- and prove they yield consistent results within our framework.\nWe implement these ideas in a simple probabilistic functional language with\nprimitives for sampling and evaluation, providing both operational and\ndenotational semantics and proving their consistency. Our work provides a\nrigorous foundation for implementing conditional probability in probabilistic\nprogramming languages.",
    "pdf_url": "http://arxiv.org/pdf/2502.00949v1",
    "published": "2025-02-02T22:46:26+00:00",
    "categories": [
      "cs.LO",
      "cs.PL",
      "03B70",
      "F.3.2"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00948v3",
    "title": "Paradoxical behavior in Collatz sequences",
    "authors": [
      "Olivier Rozier",
      "Claude Terracol"
    ],
    "abstract": "On the set of positive integers, we consider an iterated process that sends\n$n$ to $\\frac{3n+1}{2}$ or to $\\frac{n}{2}$ depending on the parity of $n$.\nAccording to a conjecture due to Collatz, all such sequences end up in the\ncycle $(1,2)$. In a seminal paper, Terras further conjectured that the\nproportion of odd terms encountered when starting from $n\\geq2$ is sufficient\nto determine its stopping time, namely, the number of iterations needed to\ndescend below $n$. However, when iterating beyond the stopping time, there\nexist \"paradoxical\" sequences for which the first term is unexpectedly\nexceeded. In the present study, we show that this topic is strongly linked to\nthe Collatz conjecture. Moreover, this non-typical behavior seems to occur\nfinitely many times apart from the trivial cycle, thus lending support to\nTerras' conjecture.",
    "pdf_url": "http://arxiv.org/pdf/2502.00948v3",
    "published": "2025-02-02T22:41:21+00:00",
    "categories": [
      "math.GM",
      "11B83 (Primary) 06A07, 11A55, 11J86 (Secondary)"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2502.00947v1",
    "title": "Minimax Optimality of Classical Scaling Under General Noise Conditions",
    "authors": [
      "Siddharth Vishwanath",
      "Ery Arias-Castro"
    ],
    "abstract": "We establish the consistency of classical scaling under a broad class of\nnoise models, encompassing many commonly studied cases in literature. Our\napproach requires only finite fourth moments of the noise, significantly\nweakening standard assumptions. We derive convergence rates for classical\nscaling and establish matching minimax lower bounds, demonstrating that\nclassical scaling achieves minimax optimality in recovering the true\nconfiguration even when the input dissimilarities are corrupted by noise.",
    "pdf_url": "http://arxiv.org/pdf/2502.00947v1",
    "published": "2025-02-02T22:35:52+00:00",
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.ML",
      "stat.TH",
      "62R07, 94A16, 62G05, 62C20"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2502.00946v2",
    "title": "The Simons Observatory: Validation of reconstructed power spectra from simulated filtered maps for the Small Aperture Telescope survey",
    "authors": [
      "Carlos Hervías-Caimapo",
      "Kevin Wolz",
      "Adrien La Posta",
      "Susanna Azzoni",
      "David Alonso",
      "Kam Arnold",
      "Carlo Baccigalupi",
      "Simon Biquard",
      "Michael L. Brown",
      "Erminia Calabrese",
      "Yuji Chinone",
      "Samuel Day-Weiss",
      "Jo Dunkley",
      "Rolando Dünner",
      "Josquin Errard",
      "Giulio Fabbian",
      "Ken Ganga",
      "Serena Giardiello",
      "Emilie Hertig",
      "Kevin M. Huffenberger",
      "Bradley R. Johnson",
      "Baptiste Jost",
      "Reijo Keskitalo",
      "Theodore S. Kisner",
      "Thibaut Louis",
      "Magdy Morshed",
      "Lyman A. Page",
      "Christian L. Reichardt",
      "Erik Rosenberg",
      "Max Silva-Feaver",
      "Wuhyun Sohn",
      "Yoshinori Sueno",
      "Dan B. Thomas",
      "Ema Tsang King Sang",
      "Amalia Villarrubia-Aguilar",
      "Kyohei Yamada"
    ],
    "abstract": "We present a transfer function-based method to estimate angular power spectra\nfrom filtered maps for cosmic microwave background (CMB) surveys. This is\nespecially relevant for experiments targeting the faint primordial\ngravitational wave signatures in CMB polarisation at large scales, such as the\nSimons Observatory (SO) small aperture telescopes. While timestreams can be\nfiltered to mitigate the contamination from low-frequency noise, usual methods\nthat calculate the mode coupling at individual multipoles can be challenging\nfor experiments covering large sky areas or reaching few-arcminute resolution.\nThe method we present here, although approximate, is more practical and faster\nfor larger data volumes. We validate it through the use of simulated\nobservations approximating the first year of SO data, going from half-wave\nplate-modulated timestreams to maps, and using simulations to estimate the\nmixing of polarisation modes induced by an example of time-domain filtering. We\nshow its performance through an example null test and with an end-to-end\npipeline that performs inference on cosmological parameters, including the\ntensor-to-scalar ratio $r$. The performance demonstration uses simulated\nobservations at multiple frequency bands. We find that the method can recover\nunbiased parameters for our simulated noise levels.",
    "pdf_url": "http://arxiv.org/pdf/2502.00946v2",
    "published": "2025-02-02T22:35:30+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00944v2",
    "title": "Analysis of static and dynamic batching algorithms for graph neural networks",
    "authors": [
      "Daniel T. Speckhard",
      "Tim Bechtel",
      "Sebastian Kehl",
      "Jonathan Godwin",
      "Claudia Draxl"
    ],
    "abstract": "Graph neural networks (GNN) have shown promising results for several domains\nsuch as materials science, chemistry, and the social sciences. GNN models often\ncontain millions of parameters, and like other neural network (NN) models, are\noften fed only a fraction of the graphs that make up the training dataset in\nbatches to update model parameters. The effect of batching algorithms on\ntraining time and model performance has been thoroughly explored for NNs but\nnot yet for GNNs. We analyze two different batching algorithms for graph based\nmodels, namely static and dynamic batching for two datasets, the QM9 dataset of\nsmall molecules and the AFLOW materials database. Our experiments show that\nchanging the batching algorithm can provide up to a 2.7x speedup, but the\nfastest algorithm depends on the data, model, batch size, hardware, and number\nof training steps run. Experiments show that for a select number of\ncombinations of batch size, dataset, and model, significant differences in\nmodel learning metrics are observed between static and dynamic batching\nalgorithms.",
    "pdf_url": "http://arxiv.org/pdf/2502.00944v2",
    "published": "2025-02-02T22:34:17+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00945v1",
    "title": "Predictive Information Decomposition as a Tool to Quantify Emergent Dynamical Behaviors In Physiological Networks",
    "authors": [
      "Luca Faes",
      "Gorana Mijatovic",
      "Laura Sparacino",
      "Alberto Porta"
    ],
    "abstract": "Objective: This work introduces a framework for multivariate time series\nanalysis aimed at detecting and quantifying collective emerging behaviors in\nthe dynamics of physiological networks. Methods: Given a network system mapped\nby a vector random process, we compute the predictive information (PI) between\nthe present and past network states and dissect it into amounts quantifying the\nunique, redundant and synergistic information shared by the present of the\nnetwork and the past of each unit. Emergence is then quantified as the\nprevalence of the synergistic over the redundant contribution. The framework is\nimplemented in practice using vector autoregressive (VAR) models. Results:\nValidation in simulated VAR processes documents that emerging behaviors arise\nin networks where multiple causal interactions coexist with internal dynamics.\nThe application to cardiovascular and respiratory networks mapping the\nbeat-to-beat variability of heart rate, arterial pressure and respiration\nmeasured at rest and during postural stress reveals the presence of\nstatistically significant net synergy, as well as its modulation with\nsympathetic nervous system activation. Conclusion: Causal emergence can be\nefficiently assessed decomposing the PI of network systems via VAR models\napplied to multivariate time series. This approach evidences the\nsynergy/redundancy balance as a hallmark of integrated short-term autonomic\ncontrol in cardiovascular and respiratory networks. Significance: Measures of\ncausal emergence provide a practical tool to quantify the mechanisms of causal\ninfluence that determine the dynamic state of cardiovascular and neural network\nsystems across distinct physiopathological conditions.",
    "pdf_url": "http://arxiv.org/pdf/2502.00945v1",
    "published": "2025-02-02T22:34:17+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.00943v2",
    "title": "Universal Abstraction: Harnessing Frontier Models to Structure Real-World Data at Scale",
    "authors": [
      "Cliff Wong",
      "Sam Preston",
      "Qianchu Liu",
      "Zelalem Gero",
      "Jaspreet Bagga",
      "Sheng Zhang",
      "Shrey Jain",
      "Theodore Zhao",
      "Yu Gu",
      "Yanbo Xu",
      "Sid Kiblawi",
      "Srinivasan Yegnasubramanian",
      "Taxiarchis Botsis",
      "Marvin Borja",
      "Luis M. Ahumada",
      "Joseph C. Murray",
      "Guo Hui Gan",
      "Roshanthi Weerasinghe",
      "Kristina Young",
      "Rom Leidner",
      "Brian Piening",
      "Carlo Bifulco",
      "Tristan Naumann",
      "Mu Wei",
      "Hoifung Poon"
    ],
    "abstract": "A significant fraction of real-world patient information resides in\nunstructured clinical text. Medical abstraction extracts and normalizes key\nstructured attributes from free-text clinical notes, which is the prerequisite\nfor a variety of important downstream applications, including registry\ncuration, clinical trial operations, and real-world evidence generation. Prior\nmedical abstraction methods typically resort to building attribute-specific\nmodels, each of which requires extensive manual effort such as rule creation or\nsupervised label annotation for the individual attribute, thus limiting\nscalability. In this paper, we show that existing frontier models already\npossess the universal abstraction capability for scaling medical abstraction to\na wide range of clinical attributes. We present UniMedAbstractor (UMA), a\nunifying framework for zero-shot medical abstraction with a modular,\ncustomizable prompt template and the selection of any frontier large language\nmodels. Given a new attribute for abstraction, users only need to conduct\nlightweight prompt adaptation in UMA to adjust the specification in natural\nlanguages. Compared to traditional methods, UMA eliminates the need for\nattribute-specific training labels or handcrafted rules, thus substantially\nreducing the development time and cost. We conducted a comprehensive evaluation\nof UMA in oncology using a wide range of marquee attributes representing the\ncancer patient journey. These include relatively simple attributes typically\nspecified within a single clinical note (e.g. performance status), as well as\ncomplex attributes requiring sophisticated reasoning across multiple notes at\nvarious time points (e.g. tumor staging). Based on a single frontier model such\nas GPT-4o, UMA matched or even exceeded the performance of state-of-the-art\nattribute-specific methods, each of which was tailored to the individual\nattribute.",
    "pdf_url": "http://arxiv.org/pdf/2502.00943v2",
    "published": "2025-02-02T22:31:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00942v1",
    "title": "Large deviations of geodesic midpoint fluctuations in last-passage percolation with general i.i.d. weights",
    "authors": [
      "Tom Alberts",
      "Riddhipratim Basu",
      "Sean Groathouse",
      "Xiao Shen"
    ],
    "abstract": "The study of transversal fluctuations of the optimal path is a crucial aspect\nof the Kardar-Parisi-Zhang (KPZ) universality class. In this work, we establish\nthe large deviation limit for the midpoint transversal fluctuations in a\ngeneral last-passage percolation (LPP) model with mild assumption on the i.i.d.\nweights. The rate function is expressed in terms of the right tail large\ndeviation rate function of the last-passage value and the shape function. When\nthe weights are chosen to be i.i.d. exponential random variables, our result\nverifies a conjecture communicated to us by Liu [Liu'22], showing the\nasymptotic probability of the geodesic from $(0,0)$ to $(n,n)$ following the\ncorner path $(0,0) \\to (n,0) \\to (n,n)$ is $({4}/{e^2})^{n+o(n)}$.",
    "pdf_url": "http://arxiv.org/pdf/2502.00942v1",
    "published": "2025-02-02T22:26:41+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP",
      "60K35, 60K37"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00941v1",
    "title": "Exploring Multiscale Navigation of Homogeneous and Dense Objects with Progressive Refinement in Virtual Reality",
    "authors": [
      "Leonardo Pavanatto",
      "Alexander Giovannelli",
      "Brian Giera",
      "Peer-Timo Bremer",
      "Haichao Miao",
      "Doug Bowman"
    ],
    "abstract": "Locating small features in a large, dense object in virtual reality (VR)\nposes a significant interaction challenge. While existing multiscale techniques\nsupport transitions between various levels of scale, they are not focused on\nhandling dense, homogeneous objects with hidden features. We propose a novel\napproach that applies the concept of progressive refinement to VR navigation,\nenabling focused inspections. We conducted a user study where we varied two\nindependent variables in our design, navigation style (STRUCTURED vs.\nUNSTRUCTURED) and display mode (SELECTION vs. EVERYTHING), to better understand\ntheir effects on efficiency and awareness during multiscale navigation. Our\nresults showed that unstructured navigation can be faster than structured and\nthat displaying only the selection can be faster than displaying the entire\nobject. However, using an everything display mode can support better location\nawareness and object understanding.",
    "pdf_url": "http://arxiv.org/pdf/2502.00941v1",
    "published": "2025-02-02T22:25:42+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00940v1",
    "title": "An MDP Model for Censoring in Harvesting Sensors: Optimal and Approximated Solutions",
    "authors": [
      "Jesus Fernandez-Bes",
      "Jesus Cid-Sueiro",
      "Antonio G. Marques"
    ],
    "abstract": "In this paper, we propose a novel censoring policy for energy-efficient\ntransmissions in energy-harvesting sensors. The problem is formulated as an\ninfinite-horizon Markov Decision Process (MDP). The objective to be optimized\nis the expected sum of the importance (utility) of all transmitted messages.\nAssuming that such importance can be evaluated at the transmitting node, we\nshow that, under certain conditions on the battery model, the optimal censoring\npolicy is a threshold function on the importance value. Specifically, messages\nare transmitted only if their importance is above a threshold whose value\ndepends on the battery level. Exploiting this property, we propose a\nmodel-based stochastic scheme that approximates the optimal solution, with less\ncomputational complexity and faster convergence speed than a conventional\nQ-learning algorithm. Numerical experiments in single-hop and multi-hop\nnetworks confirm the analytical advantages of the proposed scheme.",
    "pdf_url": "http://arxiv.org/pdf/2502.00940v1",
    "published": "2025-02-02T22:22:21+00:00",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.00939v1",
    "title": "Fruit Fly Classification (Diptera: Tephritidae) in Images, Applying Transfer Learning",
    "authors": [
      "Erick Andrew Bustamante Flores",
      "Harley Vera Olivera",
      "Ivan Cesar Medrano Valencia",
      "Carlos Fernando Montoya Cubas"
    ],
    "abstract": "This study develops a transfer learning model for the automated\nclassification of two species of fruit flies, Anastrepha fraterculus and\nCeratitis capitata, in a controlled laboratory environment. The research\naddresses the need to optimize identification and classification, which are\ncurrently performed manually by experts, being affected by human factors and\nfacing time challenges. The methodological process of this study includes the\ncapture of high-quality images using a mobile phone camera and a stereo\nmicroscope, followed by segmentation to reduce size and focus on relevant\nmorphological areas. The images were carefully labeled and preprocessed to\nensure the quality and consistency of the dataset used to train the pre-trained\nconvolutional neural network models VGG16, VGG19, and Inception-v3. The results\nwere evaluated using the F1-score, achieving 82% for VGG16 and VGG19, while\nInception-v3 reached an F1-score of 93%. Inception-v3's reliability was\nverified through model testing in uncontrolled environments, with positive\nresults, complemented by the Grad-CAM technique, demonstrating its ability to\ncapture essential morphological features. These findings indicate that\nInception-v3 is an effective and replicable approach for classifying Anastrepha\nfraterculus and Ceratitis capitata, with potential for implementation in\nautomated monitoring systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.00939v1",
    "published": "2025-02-02T22:16:04+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T10",
      "I.2.10"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00938v1",
    "title": "On Noncommutative Quantum Mechanics and the Black-Scholes Model",
    "authors": [
      "Abraham Espinoza-García",
      "Pablo Vega-Lara",
      "Luis Rey Díaz-Barrón",
      "F. Teodoro Hernández Grovas"
    ],
    "abstract": "Two novel and direct quantum mechanical representations of the Black-Scholes\nmodel are constructed based on the (Wick-rotated) quantization of two specific\nmechanical systems. The quantum setup is achieved by means of the associated\nLaplace-Beltrami operator (one for each model), and not by merely applying the\nusual naive rule. Additionally, the clear identification of the geometric\ncontent of the underlying classical framework is exploited in order to arrive\nat a noncommutative quantum mechanics generalization of the Black-Scholes\nmodel. We also consider a system consisting of two degrees of freedom whose\n(Wick-rotated) quantization leads to a model which can be seen as related to\nthe Merton-Garman family. This model is also generalized via noncommutative\nquantum mechanics.",
    "pdf_url": "http://arxiv.org/pdf/2502.00938v1",
    "published": "2025-02-02T22:10:45+00:00",
    "categories": [
      "q-fin.MF",
      "quant-ph"
    ],
    "primary_category": "q-fin.MF"
  },
  {
    "id": "http://arxiv.org/abs/2502.00937v2",
    "title": "ModServe: Scalable and Resource-Efficient Large Multimodal Model Serving",
    "authors": [
      "Haoran Qiu",
      "Anish Biswas",
      "Zihan Zhao",
      "Jayashree Mohan",
      "Alind Khare",
      "Esha Choukse",
      "Íñigo Goiri",
      "Zeyu Zhang",
      "Haiying Shen",
      "Chetan Bansal",
      "Ramachandran Ramjee",
      "Rodrigo Fonseca"
    ],
    "abstract": "Large multimodal models (LMMs) demonstrate impressive capabilities in\nunderstanding images, videos, and audio beyond text. However, efficiently\nserving LMMs in production environments poses significant challenges due to\ntheir complex architectures and heterogeneous characteristics across their\nmulti-stage inference pipelines. We present the first comprehensive systems\nanalysis of two prominent LMM architectures, decoder-only and cross-attention,\nacross six representative open-source models, revealing key systems design\nimplications. We also present an in-depth analysis of production LMM inference\ntraces, uncovering unique workload characteristics, including variable,\nheavy-tailed request distributions and bursty traffic patterns. Based on these\ninsights, we propose ModServe, a modular LMM serving system that decouples\nstages for independent optimization and adaptive scaling. ModServe dynamically\nreconfigures stages and handles bursty traffic with modality-aware scheduling\nand autoscaling to meet tail latency SLOs while minimizing costs. ModServe\nachieves 3.3-5.5x higher throughput (leading to 25-41.3% cost saving) while\nmeeting SLOs on a 128-GPU cluster with production traces.",
    "pdf_url": "http://arxiv.org/pdf/2502.00937v2",
    "published": "2025-02-02T22:10:40+00:00",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00936v1",
    "title": "Fabrication and characterization of shape- and topology-optimized optical cavities with deep sub-wavelength confinement for interfacing with colloidal quantum dots",
    "authors": [
      "Mohammad Abutoama",
      "Rasmus Ellebæk Christiansen",
      "Adrian Holm Dubré",
      "Meng Xiong",
      "Jesper Mørk",
      "Philip Trøst Kristensen"
    ],
    "abstract": "We employ a combined shape- and topology-optimization strategy to design\nmanufacturable two-dimensional photonic crystal-based optical nanocavities that\nconfine light to length scales well below the resonance wavelength. We present\ndetails of the design strategy as well as scanning electron micrographs of the\nfabricated indium phosphide cavities with a compact footprint of\n~\"4.5{\\lambda}*4.5{\\lambda}\" , which feature gaps on the order of 10 nm and\ntheoretical mode volumes in the gap center below (0.1 ({\\lambda}/2n_air))^3.\nSubsequent optical characterization of the far-field emission as well as\nPurcell-enhanced photoluminescence from the cavities with and without\nspin-coated colloidal quantum dots are compared to numerical simulations. The\nresults corroborate the potential of the design strategy and fabrication\nprocess for ensuring high yield and reliable performance as well as the\nviability of the material platform for exploring light-matter interaction with\ncolloidal QDs.",
    "pdf_url": "http://arxiv.org/pdf/2502.00936v1",
    "published": "2025-02-02T22:10:34+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.00935v3",
    "title": "Generalizing Safety Beyond Collision-Avoidance via Latent-Space Reachability Analysis",
    "authors": [
      "Kensuke Nakamura",
      "Lasse Peters",
      "Andrea Bajcsy"
    ],
    "abstract": "Hamilton-Jacobi (HJ) reachability is a rigorous mathematical framework that\nenables robots to simultaneously detect unsafe states and generate actions that\nprevent future failures. While in theory, HJ reachability can synthesize safe\ncontrollers for nonlinear systems and nonconvex constraints, in practice, it\nhas been limited to hand-engineered collision-avoidance constraints modeled via\nlow-dimensional state-space representations and first-principles dynamics. In\nthis work, our goal is to generalize safe robot controllers to prevent failures\nthat are hard--if not impossible--to write down by hand, but can be intuitively\nidentified from high-dimensional observations: for example, spilling the\ncontents of a bag. We propose Latent Safety Filters, a latent-space\ngeneralization of HJ reachability that tractably operates directly on raw\nobservation data (e.g., RGB images) to automatically compute safety-preserving\nactions without explicit recovery demonstrations by performing safety analysis\nin the latent embedding space of a generative world model. Our method leverages\ndiverse robot observation-action data of varying quality (including successes,\nrandom exploration, and unsafe demonstrations) to learn a world model.\nConstraint specification is then transformed into a classification problem in\nthe latent space of the learned world model. In simulation and hardware\nexperiments, we compute an approximation of Latent Safety Filters to safeguard\narbitrary policies (from imitation- learned policies to direct teleoperation)\nfrom complex safety hazards, like preventing a Franka Research 3 manipulator\nfrom spilling the contents of a bag or toppling cluttered objects.",
    "pdf_url": "http://arxiv.org/pdf/2502.00935v3",
    "published": "2025-02-02T22:00:20+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00934v2",
    "title": "Optimizing Global Genomic Surveillance for Early Detection of Emerging SARS-CoV-2 Variants",
    "authors": [
      "Haogao Gu",
      "Jifan Li",
      "Wanying Sun",
      "Mengting Li",
      "Kathy Leung",
      "Joseph T. Wu",
      "Hsiang-Yu Yuan",
      "Maggie H. Wang",
      "Bingyi Yang",
      "Matthew R. McKay",
      "Ning Ning",
      "Leo L. M. Poon"
    ],
    "abstract": "Background: Global viral threats underscore the need for effective genomic\nsurveillance, but high costs and uneven resource distribution hamper its\nimplementation. Targeting surveillance to international travelers in major\ntravel hubs may offer a more efficient strategy for the early detection of\nSARS-CoV-2 variants.\n  Methods: We developed and calibrated a multiple-strain metapopulation model\nof global SARS-CoV-2 transmission using extensive epidemiological,\nphylogenetic, and high-resolution air travel data. We then compared baseline\nsurveillance with various resource-allocation approaches that prioritize\ntravelers, focusing on Omicron BA.1/BA.2 retrospectively and on hypothetical\nfuture variants under different emergence, transmission and vaccine\neffectiveness scenarios.\n  Findings: Focusing existing surveillance resources on travelers at key global\nhubs significantly shortened detection delays without increasing total\nsurveillance efforts. In retrospective analyses of Omicron BA.1/BA.2,\ntraveler-targeted approaches consistently outperformed baseline strategies,\neven when overall resources were reduced. Simulations indicate that focusing\nsurveillance on key travel hubs outperform baseline practices in detecting\nfuture variants, across different possible origins, even with reduced\nresources. This approach also remains effective in future pandemic scenarios\nwith varying reproductive numbers and vaccine effectiveness.\n  Interpretation: These findings provide a quantitative, cost-effective\nframework for strengthening global genomic surveillance. By reallocating\nresources toward international travelers in select travel hubs, early detection\nof emerging variants can be enhanced, informing rapid public health\ninterventions and bolstering preparedness for future pandemics.",
    "pdf_url": "http://arxiv.org/pdf/2502.00934v2",
    "published": "2025-02-02T21:55:05+00:00",
    "categories": [
      "q-bio.PE",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2502.00933v2",
    "title": "L{é}vy-noise-induced wavefront propagation for bistable systems",
    "authors": [
      "Vladimir V. Semenov"
    ],
    "abstract": "The influence of the L{\\'e}vy noise's properties on wavefront propagation is\nanalyzed on examples of ensembles of locally coupled bistable oscillators and a\nsingle bistable delayed-feedback oscillator considered as a spatially-extended\nsystem evolving in quasi-space. It is shown that additive L{\\'e}vy noise allows\nto induce wavefront propagation in ensembles of symmetric bistable oscillators.\nIn such a case, the direction and velocity of the noise-sustained propagation\nis determined both by the noise's skewness parameter and by the coupling\ntopology (bidirectional and unidirectional coupling schemes are distinguished).\nIn addition, additive L{\\'e}vy noise induces wavefront propagation in a\nbistable delayed-feedback oscillator assumed to be symmetric such that its\ndynamics replicates the collective behaviour in the ensemble with\nunidirectional coupling. The wavefront propagation velocity used in this\nanalysis is shown to be varied when adjusting the noise parameters. The\nrevealed effects are demonstrated in the ensembles by using numerical\nsimulation, whereas the numerical exploration of the delayed-feedback\noscillator is complemented by physical experiments, showing a good\ncorrespondence and disclosing thereby the robustness of the observed phenomena.",
    "pdf_url": "http://arxiv.org/pdf/2502.00933v2",
    "published": "2025-02-02T21:54:20+00:00",
    "categories": [
      "nlin.AO"
    ],
    "primary_category": "nlin.AO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00932v1",
    "title": "Nodal lines in a honeycomb plasmonic crystal with synthetic spin",
    "authors": [
      "Sang Hyun Park",
      "E. J. Mele",
      "Tony Low"
    ],
    "abstract": "We analyze a plasmonic model on a honeycomb lattice of metallic nanodisks\nthat hosts nodal lines protected by local symmetries. Using both continuum and\ntight-binding models, we show that a combination of a synthetic time-reversal\nsymmetry, inversion symmetry, and particle-hole symmetry enforce the existence\nof nodal lines enclosing the $\\mathrm{K}$ and $\\mathrm{K}'$ points. The nodal\nlines are not directly gapped even when these symmetries are weakly broken. The\nexistence of the nodal lines is verified using full-wave electromagnetic\nsimulations. We also show that the degeneracies at nodal lines can be relieved\nby introducing a Kekul\\'e distortion that acts to mix the nodal lines near the\n$\\mathrm{K},\\mathrm{K}'$ points. Our findings open pathways for designing novel\nplasmonic and photonic devices without reliance on complex symmetry\nengineering, presenting a convenient platform for studying nodal structures in\ntwo-dimensional systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.00932v1",
    "published": "2025-02-02T21:52:04+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.00931v3",
    "title": "VL-Nav: Real-time Vision-Language Navigation with Spatial Reasoning",
    "authors": [
      "Yi Du",
      "Taimeng Fu",
      "Zhuoqun Chen",
      "Bowen Li",
      "Shaoshu Su",
      "Zhipeng Zhao",
      "Chen Wang"
    ],
    "abstract": "Vision-language navigation in unknown environments is crucial for mobile\nrobots. In scenarios such as household assistance and rescue, mobile robots\nneed to understand a human command, such as \"find a person wearing black\". We\npresent a novel vision-language navigation (VL-Nav) system that integrates\nefficient spatial reasoning on low-power robots. Unlike prior methods that rely\non a single image-level feature similarity to guide a robot, our method\nintegrates pixel-wise vision-language features with curiosity-driven\nexploration. This approach enables robust navigation to human-instructed\ninstances across diverse environments. We deploy VL-Nav on a four-wheel mobile\nrobot and evaluate its performance through comprehensive navigation tasks in\nboth indoor and outdoor environments, spanning different scales and semantic\ncomplexities. Remarkably, VL-Nav operates at a real-time frequency of 30 Hz\nwith a Jetson Orin NX, highlighting its ability to conduct efficient\nvision-language navigation. Results show that VL-Nav achieves an overall\nsuccess rate of 86.3%, outperforming previous methods by 44.15%.",
    "pdf_url": "http://arxiv.org/pdf/2502.00931v3",
    "published": "2025-02-02T21:44:15+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00930v1",
    "title": "Event-Triggered Newton-Based Extremum Seeking Control",
    "authors": [
      "Victor Hugo Pereira Rodrigues",
      "Tiago Roux Oliveira",
      "Miroslav Krstic",
      "Paulo Tabuada"
    ],
    "abstract": "This paper proposes the incorporation of static event-triggered control in\nthe actuation path of Newton-based extremum seeking and its comparison with the\nearlier gradient version. As in the continuous methods, the convergence rate of\nthe gradient approach depends on the unknown Hessian of the nonlinear map to be\noptimized, whereas the proposed event-triggered Newton-based extremum seeking\neliminates this dependence, becoming user-assignable. This is achieved by means\nof a dynamic estimator for the Hessian's inverse, implemented as a Riccati\nequation filter. Lyapunov stability and averaging theory for discontinuous\nsystems are applied to analyze the closed-loop system. Local exponential\npractical stability is guaranteed to a small neighborhood of the extremum point\nof scalar and static maps. Numerical simulations illustrate the advantages of\nthe proposed approach over the previous gradient method, including improved\nconvergence speed, followed by a reduction in the amplitude and updating\nfrequency of the control signals.",
    "pdf_url": "http://arxiv.org/pdf/2502.00930v1",
    "published": "2025-02-02T21:42:26+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.01695v1",
    "title": "A Novel Real-Time Full-Color 3D Holographic (Diffractive) Video Capture, Processing, and Transmission Pipeline Using Off-The-Shelf Hardware",
    "authors": [
      "Ankur Samanta",
      "Gregor Mackenzie",
      "Tyler Rathkamp",
      "Adrian Cable",
      "Darran Milne",
      "Andrzej Kaczorowski",
      "Ronjon Nag"
    ],
    "abstract": "This paper details the world's first live 3D holographic (diffractive) video\ncall using off-the-shelf hardware. We introduce a novel pipeline that\nfacilitates the capture, processing, and transmission of RGBZ data, using an\niPhone for image and depth capture with VividQ's SDK for hologram generation\nand hardware for display.",
    "pdf_url": "http://arxiv.org/pdf/2502.01695v1",
    "published": "2025-02-02T21:42:00+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "H.5.1; H.5.2"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00929v1",
    "title": "QUOKKA-based understanding of outflows (QED) -- III. Outflow loading and phase structure as a function of galactic environment",
    "authors": [
      "Aditi Vijayan",
      "Mark R. Krumholz",
      "Benjamin D. Wibking"
    ],
    "abstract": "We present results from a suite of 3D high-resolution hydrodynamic\nsimulations of supernova-driven outflows from galactic disc regions with a\nrange of gas surface density, metallicity, and supernova scale height. We use\nthis suite to quantify how outflow properties -- particularly the loading\nfactors for mass, metallicity, and energy -- vary with these parameters. We\nfind that the winds fall into three broad categories: steady and hot,\nmultiphase and moderately bursty, and cool and highly bursty. The first of\nthese is characterised by efficient metal and energy loading but weak mass\nloading, the second by moderate loading of mass, metals, and energy, and the\nthird by negligible metal and energy loading but substantial mass loading. The\nmost important factor in determining the kind of wind a galaxy will produce is\nthe ratio of supernova to gas gas scale heights, with the latter set by a\ncombination of supernova rate, metallicity-dependent cooling rate, and the\ngravitational potential. These often combine in counterintuitive ways -- for\nexample increased cooling causes cold clouds to sink into the galactic midplane\nmore rapidly, lowering the volume-filling factor of dense gas and making the\nenvironment more favourable for strong winds. Our findings suggest that the\nnature of galactic winds is likely highly sensitive to phenomena such as\nrunaway stars occuring at a large height and dense gas and are poorly captured\nin most simulations, and that metal loading factors for type Ia supernovae may\nbe substantially larger than those for type II, with important implications for\ngalactic chemical evolution.",
    "pdf_url": "http://arxiv.org/pdf/2502.00929v1",
    "published": "2025-02-02T21:39:50+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00928v1",
    "title": "Mathematical Cell Deployment Optimization for Capacity and Coverage of Ground and UAV Users",
    "authors": [
      "Saeed Karimi-Bidhendi",
      "Giovanni Geraci",
      "Hamid Jafarkhani"
    ],
    "abstract": "We present a general mathematical framework for optimizing cell deployment\nand antenna configuration in wireless networks, inspired by quantization\ntheory. Unlike traditional methods, our framework supports networks with\ndeterministically located nodes, enabling modeling and optimization under\ncontrolled deployment scenarios. We demonstrate our framework through two\napplications: joint fine-tuning of antenna parameters across base stations\n(BSs) to optimize network coverage, capacity, and load balancing, and the\nstrategic deployment of new BSs, including the optimization of their locations\nand antenna settings. These optimizations are conducted for a heterogeneous 3D\nuser population, comprising ground users (GUEs) and uncrewed aerial vehicles\n(UAVs) along aerial corridors. Our case studies highlight the framework's\nversatility in optimizing performance metrics such as the coverage-capacity\ntrade-off and capacity per region. Our results confirm that optimizing the\nplacement and orientation of additional BSs consistently outperforms approaches\nfocused solely on antenna adjustments, regardless of GUE distribution.\nFurthermore, joint optimization for both GUEs and UAVs significantly enhances\nUAV service without severely affecting GUE performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.00928v1",
    "published": "2025-02-02T21:39:08+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00927v1",
    "title": "Modeling Cosmic Rays at AGN Jet-Driven Shock Fronts",
    "authors": [
      "Kung-Yi Su",
      "Greg L. Bryan",
      "Philip F. Hopkins",
      "Priyamvada Natarajan",
      "Sam B. Ponnada",
      "Razieh Emami",
      "Yue Samuel Lu"
    ],
    "abstract": "Active Galactic Nuclei (AGN) feedback is a key physical mechanism proposed to\nregulate star formation, primarily in massive galaxies. In particular, cosmic\nrays associated with AGN jets have the potential to efficiently suppress\ncooling flows and quench star formation. The locus of cosmic ray production and\ntheir coupling to gas play a crucial role in the overall self-regulation\nprocess. To investigate this in detail, we conduct high-resolution,\nnon-cosmological MHD simulations of a massive $10^{14} {\\rm M_\\odot}$ halo\nusing the FIRE-2 (Feedback In Realistic Environments) stellar feedback model.\nWe explore a variety of AGN jet feedback scenarios with cosmic rays, examining\ndifferent values for the cosmic ray energy fraction in jets, cosmic ray\ncoupling sites (in the black hole vicinity versus at the large-scale jet-driven\nshock front), and jet precession parameters. Our findings indicate that when\ncosmic rays are injected near the black hole, they efficiently inhibit black\nhole accretion by suppressing the density before the jet propagates out to\nlarge radii. As a result, this leads to episodic black hole accretion, with the\njet not having sufficient energy flux to reach large radii and impact cooling\nflows. Conversely, if the cosmic rays are injected at the jet-driven shock\nfront, not only does the jet sustain a higher overall energy flux for an\nextended period, but it also disperses cosmic rays out to larger radii, more\neffectively suppressing the cooling flow. Furthermore, the period and angle of\njet precession can influence the position of shock fronts. We identify an\noptimal range of jet precession periods ($\\sim$ tens of Myr) that generates\nshocks at the inner circumgalactic medium, where cooling flows are most severe.\nWe report that this specific configuration offers the most effective scenario\nfor cosmic rays at the shock front to suppress the cooling flow and star\nformation.",
    "pdf_url": "http://arxiv.org/pdf/2502.00927v1",
    "published": "2025-02-02T21:30:34+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00926v2",
    "title": "Structured Pneumatic Fingerpads for Actively Tunable Grip Friction",
    "authors": [
      "Katherine Allison",
      "Jonathan Kelly",
      "Benjamin Hatton"
    ],
    "abstract": "Grip surfaces with tunable friction can actively modify contact conditions,\nenabling transitions between higher- and lower-friction states for grasp\nadjustment. Friction can be increased to grip securely and then decreased to\ngently release (e.g., for handovers) or manipulate in-hand. Recent\nfriction-tuning surface designs using soft pneumatic chambers show good control\nover grip friction; however, most require complex fabrication processes and/or\ncustom gripper hardware. We present a practical structured fingerpad design for\nfriction tuning that uses less than $1 USD of materials, takes only seconds to\nrepair, and is easily adapted to existing grippers. Our design uses surface\nmorphology changes to tune friction. The fingerpad is actuated by pressurizing\nits internal chambers, thereby deflecting its flexible grip surface out from or\ninto these chambers. We characterize the friction-tuning capabilities of our\ndesign by measuring the shear force required to pull an object from a gripper\nequipped with two independently actuated fingerpads. Our results show that\nvarying actuation pressure and timing changes the magnitude of friction forces\non a gripped object by up to a factor of 2.8. We demonstrate additional\nfeatures including macro-scale interlocking behaviour and pressure-based object\ndetection.",
    "pdf_url": "http://arxiv.org/pdf/2502.00926v2",
    "published": "2025-02-02T21:29:23+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00925v1",
    "title": "On $\\overline\\partial$ homotopy formulae for product domains: Nijenhuis-Woolf's formulae and optimal Sobolev estimates",
    "authors": [
      "Liding Yao",
      "Yuan Zhang"
    ],
    "abstract": "We construct homotopy formulae $f=\\overline\\partial\\mathcal H_qf+\\mathcal\nH_{q+1}\\overline\\partial f$ for $(0,q)$ forms on the product domain\n$\\Omega_1\\times\\dots\\times\\Omega_m$, where each $\\Omega_j$ is either a bounded\nLipschitz domain in $\\mathbb C^1$, a bounded strongly pseudoconvex domain with\n$C^2$ boundary, or a smooth convex domain of finite type. Such homotopy\noperators $\\mathcal H_q$ yield solutions to the $\\overline\\partial$ equation\nwith optimal Sobolev regularity $W^{k,p}\\to W^{k,p}$ simultaneously for all\n$k\\in\\mathbb Z$ and $1<p<\\infty$.",
    "pdf_url": "http://arxiv.org/pdf/2502.00925v1",
    "published": "2025-02-02T21:27:28+00:00",
    "categories": [
      "math.CV",
      "32A26 (primary) 32W05 and 46E35 (secondary)"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00924v3",
    "title": "Generalized Simple Graphical Rules for Assessing Selection Bias",
    "authors": [
      "Yichi Zhang",
      "Haidong Lu"
    ],
    "abstract": "Selection bias is a major obstacle toward valid causal inference in\nepidemiology. Over the past decade, several simple graphical rules based on\ncausal diagrams have been proposed as the sufficient identification conditions\nfor addressing selection bias and recovering causal effects. However, these\nsimple graphical rules are usually coupled with specific identification\nstrategies and estimators. In this article, we show two important cases of\nselection bias that cannot be addressed by these simple rules and their\nestimators: one case where selection is a descendant of a collider of the\ntreatment and the outcome, and the other case where selection is affected by\nthe mediator. To address selection bias in these two cases, we construct\nidentification formulas by the g-computation and the inverse probability\nweighting (IPW) methods based on single-world intervention graphs (SWIGs). They\nare generalized to recover the average treatment effect by adjusting for\npost-treatment upstream causes of selection. We propose two IPW estimators and\ntheir variance estimators to recover the average treatment effect in the\npresence of selection bias in these two cases. We conduct simulation studies to\nverify the performance of the estimators when the traditional crude\nselected-sample analysis returns erroneous contradictory conclusions to the\ntruth.",
    "pdf_url": "http://arxiv.org/pdf/2502.00924v3",
    "published": "2025-02-02T21:27:20+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.00923v1",
    "title": "Dark energy and cosmic acceleration",
    "authors": [
      "Rodrigo von Marttens",
      "Jailson Alcaniz"
    ],
    "abstract": "The discovery that we live in an accelerating universe changed drastically\nthe paradigm of physics and introduced the concept of \\textit{dark energy}. In\nthis work, we present a brief historical description of the main events related\nto the discovery of cosmic acceleration and the basic elements of theoretical\nand observational aspects of dark energy. Regarding the historical perspective,\nwe outline some of the key milestones for tracing the journey from Einstein's\nproposal of the cosmological constant to the type Ia supernovae results.\nConversely, on the theoretical/observational side, we begin by analyzing cosmic\nacceleration within the context of the standard cosmological model, i.e., in\nterms of the cosmological constant. In this case, we show how a positive\ncosmological constant drives accelerated expansion and discuss the main\nobservational aspects, such as updated results and current cosmological\ntensions. We also explore alternative descriptions of dark energy, encompassing\ndynamic and interacting dark energy models.",
    "pdf_url": "http://arxiv.org/pdf/2502.00923v1",
    "published": "2025-02-02T21:27:16+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00922v1",
    "title": "Huff-LLM: End-to-End Lossless Compression for Efficient LLM Inference",
    "authors": [
      "Patrick Yubeaton",
      "Tareq Mahmoud",
      "Shehab Naga",
      "Pooria Taheri",
      "Tianhua Xia",
      "Arun George",
      "Yasmein Khalil",
      "Sai Qian Zhang",
      "Siddharth Joshi",
      "Chinmay Hegde",
      "Siddharth Garg"
    ],
    "abstract": "As they become more capable, large language models (LLMs) have continued to\nrapidly increase in size. This has exacerbated the difficulty in running state\nof the art LLMs on small, edge devices. Standard techniques advocate solving\nthis problem through lossy compression techniques such as quantization or\npruning. However, such compression techniques are lossy, and have been shown to\nchange model behavior in unpredictable manners. We propose Huff-LLM, an\n\\emph{end-to-end, lossless} model compression method that lets users store LLM\nweights in compressed format \\emph{everywhere} -- cloud, disk, main memory, and\neven in on-chip memory/buffers. This allows us to not only load larger models\nin main memory, but also reduces bandwidth required to load weights on chip,\nand makes more efficient use of on-chip weight buffers. In addition to the\nmemory savings achieved via compression, we also show latency and energy\nefficiency improvements when performing inference with the compressed model.",
    "pdf_url": "http://arxiv.org/pdf/2502.00922v1",
    "published": "2025-02-02T21:23:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00921v2",
    "title": "Blink of an eye: a simple theory for feature localization in generative models",
    "authors": [
      "Marvin Li",
      "Aayush Karan",
      "Sitan Chen"
    ],
    "abstract": "Large language models can exhibit unexpected behavior in the blink of an eye.\nIn a recent computer use demo, a language model switched from coding to\nGoogling pictures of Yellowstone, and these sudden shifts in behavior have also\nbeen observed in reasoning patterns and jailbreaks. This phenomenon is not\nunique to autoregressive models: in diffusion models, key features of the final\noutput are decided in narrow ``critical windows'' of the generation process. In\nthis work we develop a simple, unifying theory to explain this phenomenon using\nthe formalism of stochastic localization samplers. We show that it emerges\ngenerically as the generation process localizes to a sub-population of the\ndistribution it models.\n  While critical windows have been studied at length in diffusion models,\nexisting theory heavily relies on strong distributional assumptions and the\nparticulars of Gaussian diffusion. In contrast to existing work our theory (1)\napplies to autoregressive and diffusion models; (2) makes no distributional\nassumptions; (3) quantitatively improves previous bounds even when specialized\nto diffusions; and (4) requires basic tools and no stochastic calculus or\nstatistical-physics-based machinery. We also identify an intriguing connection\nto the all-or-nothing phenomenon from statistical inference. Finally, we\nvalidate our predictions empirically for LLMs and find that critical windows\noften coincide with failures in problem solving for various math and reasoning\nbenchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2502.00921v2",
    "published": "2025-02-02T21:19:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00920v2",
    "title": "Extending the Lattice Boltzmann Method to Non-linear Solid Mechanics",
    "authors": [
      "Henning Müller",
      "Erik Faust",
      "Alexander Schlüter",
      "Ralf Müller"
    ],
    "abstract": "This work outlines a Lattice Boltzmann Method (LBM) for geometrically and\nconstitutively nonlinear solid mechanics to simulate large deformations under\ndynamic loading conditions. The method utilizes the moment chain approach,\nwhere the non-linear constitutive law is incorporated via a forcing term.\nStress and deformation measures are expressed in the reference configuration.\nFinite difference schemes are employed for gradient and divergence\ncomputations, and Neumann- and Dirichlet-type boundary conditions are\nintroduced.\n  Numerical studies are performed to assess the proposed method and illustrate\nits capabilities. Benchmark tests for weakly dynamic uniaxial tension and\nsimple shear across a range of Poisson's ratios demonstrate the feasibility of\nthe scheme and serve as validation of the implementation. Furthermore, a\ndynamic test case involving the propagation of bending waves in a cantilever\nbeam highlights the potential of the method to model complex dynamic phenomena.",
    "pdf_url": "http://arxiv.org/pdf/2502.00920v2",
    "published": "2025-02-02T21:18:32+00:00",
    "categories": [
      "cs.CE",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2502.00919v1",
    "title": "Attention Sinks and Outlier Features: A 'Catch, Tag, and Release' Mechanism for Embeddings",
    "authors": [
      "Stephen Zhang",
      "Mustafa Khan",
      "Vardan Papyan"
    ],
    "abstract": "Two prominent features of large language models (LLMs) is the presence of\nlarge-norm (outlier) features and the tendency for tokens to attend very\nstrongly to a select few tokens. Despite often having no semantic relevance,\nthese select tokens, called attention sinks, along with the large outlier\nfeatures, have proven important for model performance, compression, and\nstreaming. Consequently, investigating the roles of these phenomena within\nmodels and exploring how they might manifest in the model parameters has become\nan area of active interest. Through an empirical investigation, we demonstrate\nthat attention sinks utilize outlier features to: catch a sequence of tokens,\ntag the captured tokens by applying a common perturbation, and then release the\ntokens back into the residual stream, where the tagged tokens are eventually\nretrieved. We prove that simple tasks, like averaging, necessitate the 'catch,\ntag, release' mechanism hence explaining why it would arise organically in\nmodern LLMs. Our experiments also show that the creation of attention sinks can\nbe completely captured in the model parameters using low-rank matrices, which\nhas important implications for model compression and substantiates the success\nof recent approaches that incorporate a low-rank term to offset performance\ndegradation.",
    "pdf_url": "http://arxiv.org/pdf/2502.00919v1",
    "published": "2025-02-02T21:15:07+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00918v1",
    "title": "Equilibrium Moment Analysis of Itô SDEs",
    "authors": [
      "David Sabin-Miller",
      "Daniel M. Abrams"
    ],
    "abstract": "Stochastic differential equations have proved to be a valuable governing\nframework for many real-world systems which exhibit ``noise'' or randomness in\ntheir evolution. One quality of interest in such systems is the shape of their\nequilibrium probability distribution, if such a thing exists. In some cases a\nstraightforward integral equation may yield this steady-state distribution, but\nin other cases the equilibrium distribution exists and yet that integral\nequation diverges. Here we establish a new equilibrium-analysis technique based\non the logic of finite-timestep simulation which allows us to glean information\nabout the equilibrium regardless -- in particular, a relationship between the\nraw moments of the equilibrium distribution. We utilize this technique to\nextract information about one such equilibrium resistant to direct definition.",
    "pdf_url": "http://arxiv.org/pdf/2502.00918v1",
    "published": "2025-02-02T21:14:27+00:00",
    "categories": [
      "math.DS",
      "cs.NA",
      "math-ph",
      "math.MP",
      "math.NA"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.00917v1",
    "title": "Rigidity and Toeplitz systems",
    "authors": [
      "Henk Bruin",
      "Olena Karpel",
      "Piotr Oprocha",
      "Silvia Radinger"
    ],
    "abstract": "The aim of this paper is to study measure-theoretical rigidity and partial\nrigidity for classes of Cantor dynamical systems including Toeplitz systems and\nenumeration systems. We use Bratteli diagrams to control invariant measures\nthat are produced in our constructions. This leads to systems with desired\nproperties. Among other things, we show that there exist Toeplitz systems with\nzero entropy which are not partially measure-theoretically rigid with respect\nto any of its invariant measures. We investigate enumeration systems defined by\na linear recursion, prove that all such systems are partially rigid and present\nan example of an enumeration system which is not measure-theoretically rigid.\nWe construct a minimal $\\mathcal{S}$-adic Toeplitz subshift which has countably\ninfinitely many ergodic invariant probability measures which are rigid for the\nsame rigidity sequence.",
    "pdf_url": "http://arxiv.org/pdf/2502.00917v1",
    "published": "2025-02-02T21:13:42+00:00",
    "categories": [
      "math.DS",
      "37B20 (Primary) 37B10, 37A05 (Secondary)"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.00916v1",
    "title": "The Accuracy, Robustness, and Readability of LLM-Generated Sustainability-Related Word Definitions",
    "authors": [
      "Alice Heiman"
    ],
    "abstract": "A common language with standardized definitions is crucial for effective\nclimate discussions. However, concerns exist about LLMs misrepresenting climate\nterms. We compared 300 official IPCC glossary definitions with those generated\nby GPT-4o-mini, Llama3.1 8B, and Mistral 7B, analyzing adherence, robustness,\nand readability using SBERT sentence embeddings. The LLMs scored an average\nadherence of $0.57-0.59 \\pm 0.15$, and their definitions proved harder to read\nthan the originals. Model-generated definitions vary mainly among words with\nmultiple or ambiguous definitions, showing the potential to highlight terms\nthat need standardization. The results show how LLMs could support\nenvironmental discourse while emphasizing the need to align model outputs with\nestablished terminology for clarity and consistency.",
    "pdf_url": "http://arxiv.org/pdf/2502.00916v1",
    "published": "2025-02-02T21:05:21+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00915v1",
    "title": "A Variational Inequality Approach to Independent Learning in Static Mean-Field Games",
    "authors": [
      "Batuhan Yardim",
      "Semih Cayci",
      "Niao He"
    ],
    "abstract": "Competitive games involving thousands or even millions of players are\nprevalent in real-world contexts, such as transportation, communications, and\ncomputer networks. However, learning in these large-scale multi-agent\nenvironments presents a grand challenge, often referred to as the \"curse of\nmany agents\". In this paper, we formalize and analyze the Static Mean-Field\nGame (SMFG) under both full and bandit feedback, offering a generic framework\nfor modeling large population interactions while enabling independent learning.\n  We first establish close connections between SMFG and variational inequality\n(VI), showing that SMFG can be framed as a VI problem in the infinite agent\nlimit. Building on the VI perspective, we propose independent learning and\nexploration algorithms that efficiently converge to approximate Nash\nequilibria, when dealing with a finite number of agents. Theoretically, we\nprovide explicit finite sample complexity guarantees for independent learning\nacross various feedback models in repeated play scenarios, assuming\n(strongly-)monotone payoffs. Numerically, we validate our results through both\nsimulations and real-world applications in city traffic and network access\nmanagement.",
    "pdf_url": "http://arxiv.org/pdf/2502.00915v1",
    "published": "2025-02-02T21:05:12+00:00",
    "categories": [
      "math.OC",
      "cs.GT"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.06804v1",
    "title": "Gauss Circle Primes",
    "authors": [
      "Thomas Ehrenborg"
    ],
    "abstract": "Given a circle of radius $r$ centered at the origin, the Gauss Circle Problem\nconcerns counting the number of lattice points $C(r)$ within this circle. It is\nknown that as $r$ grows large, the number of lattice points approaches $\\pi\nr^2$, that is, the area of the circle. The present research is to study how\noften $C(r)$ will return a prime number of lattice points for $r \\leq n$. The\nPrime Number Theorem predicts that the number of primes less than or equal to\n$n$ is asymptotic to $\\frac{n}{\\log n}$. We find that the number of Gauss\nCircle Primes for $r \\leq n$ is also of order $\\frac{n}{\\log n}$ for $n \\leq 2\n\\times 10^6$. We include a heuristic argument that the Gauss Circle Primes can\nbe approximated by $\\frac{n}{\\log n}$.",
    "pdf_url": "http://arxiv.org/pdf/2502.06804v1",
    "published": "2025-02-02T21:03:23+00:00",
    "categories": [
      "math.GM"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2502.00914v2",
    "title": "Ultradense Dark Matter Halos with Poisson Noise from Stellar-Mass Primordial Black Holes",
    "authors": [
      "Saeed Fakhry",
      "Javad T. Firouzjaee"
    ],
    "abstract": "In this work, we investigate the impact of Poisson noise from stellar-mass\nprimordial black holes (PBHs) on the formation of ultradense dark matter halos\n(UDMHs). Our findings reveal that the discrete spatial distribution of PBHs\nsignificantly enhances small-scale density fluctuations, particularly for\nmassive stellar-mass PBHs. Our results indicate that the modified power\nspectrum, incorporating both adiabatic and isocurvature contributions from\nPBH-induced Poisson noise, strongly depends on PBH mass and fraction.\nSpecifically, increasing PBH mass shifts the differential mass function of\nUDMHs toward higher masses, while variations in the suppression parameter $n$\nmodulate the efficiency of UDMH formation at small scales. For lower values of\n$n$, our findings show a significant boost in UDMH abundance, favoring\nmulti-component dark matter scenarios. Conversely, at higher values of $n$, the\npredicted UDMH distributions align more closely with single-component models\ndominated by stellar-mass PBHs. Furthermore, our analysis demonstrates that\nmore realistic halo mass functions, which account for angular momentum and\ndynamical friction, consistently predict higher UDMH abundances compared to\ntraditional Press-Schechter formalism.",
    "pdf_url": "http://arxiv.org/pdf/2502.00914v2",
    "published": "2025-02-02T20:53:02+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00913v1",
    "title": "Influence of pressure on properties of multi-gap type-I superconductor BeAu",
    "authors": [
      "Rustem Khasanov",
      "Riccardo Vocaturo",
      "Oleg Janson",
      "Andreas Koitzsch",
      "Ritu Gupta",
      "Debarchan Das",
      "Nicola P. M. Casati",
      "Maia G. Vergniory",
      "Jeroen van den Brink",
      "Eteri Svanidze"
    ],
    "abstract": "We report on studies of the superconducting and normal state properties of\nthe noncentrosymmetric superconductor BeAu under hydrostatic pressure\nconditions. The room-temperature equation of state (EOS) reveals the values of\nthe bulk modulus ($B_0$) and its first derivative ($B^\\prime_0$) at ambient\npressure to be $B_0 \\simeq 132$~GPa and $B^\\prime_0 \\simeq 30$, respectively.\nUp to the highest pressures studied ($p \\simeq 2.2$~GPa), BeAu remains a\nmulti-gap type-I superconductor. The analysis of $B_{\\rm c}(T, p)$ data within\nthe self-consistent two-gap approach suggests the presence of two\nsuperconducting energy gaps, with the gap-to-$T_{\\rm c}$ ratios\n$\\Delta_1/k_{\\rm B}T_{\\rm c} \\sim 2.3$ and $\\Delta_2/k_{\\rm B}T_{\\rm c} \\sim\n1.1$ for the larger and smaller gaps, respectively [$\\Delta = \\Delta(0)$ is the\nzero-temperature value of the gap and $k_{\\rm B}$ is the Boltzmann constant].\nWith increasing pressure, $\\Delta_1/k_{\\rm B}T_{\\rm c}$ increases while\n$\\Delta_2/k_{\\rm B}T_{\\rm c}$ decreases, suggesting that pressure enhances\n(weakens) the coupling strength between the superconducting carriers within the\nbands where the larger (smaller) superconducting energy gap has opened. The\nsuperconducting transition temperature $T_{\\rm c}$, \\textcolor{black}{the\nzero-temperature values of the superconducting gaps $\\Delta_1$ and $\\Delta_2$}\nand the zero-temperature value of the thermodynamic critical field $B_{\\rm\nc}(0)$ decrease with increasing pressure, with the rates of ${\\rm d}T_{\\rm\nc}/{\\rm d}p \\simeq -0.195$~K/GPa, \\textcolor{black}{${\\rm d}\\Delta_1/{\\rm d}p\n\\simeq -0.034$~meV/GPa, ${\\rm d}\\Delta_2/{\\rm d}p \\simeq -0.029$~meV/GPa,} and\n${\\rm d}B_{\\rm c}(0)/{\\rm d}p = -2.65(1)$~mT/GPa, respectively. The measured\n$B_{\\rm c}(0)$ values plotted as a function of $T_{\\rm c}$ follow an empirical\nscaling relation established for conventional type-I superconductors.",
    "pdf_url": "http://arxiv.org/pdf/2502.00913v1",
    "published": "2025-02-02T20:51:32+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2502.00912v1",
    "title": "Basis for KBSM of fibered torus with multiplicity two exceptional fiber",
    "authors": [
      "Mieczyslaw K. Dabkowski",
      "Cheyu Wu"
    ],
    "abstract": "We construct a family of bases for the Kauffman bracket skein module (KBSM)\nof the product of an annulus and a circle. Using these bases, we find a new\nbasis for the KBSM of $(\\beta,2)$-fibered torus as a first step toward\ndeveloping techniques for computing KBSM of a family of small Seifert fibered\n$3$-manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2502.00912v1",
    "published": "2025-02-02T20:47:37+00:00",
    "categories": [
      "math.GT",
      "57K31, 57K10"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00911v1",
    "title": "Developing Compelling Safety Cases",
    "authors": [
      "Richard Hawkins"
    ],
    "abstract": "This paper describes a method for creating compelling safety cases. The\nmethod seeks to help improve safety case practice in order to address the\nweaknesses identified in current practice, in particular confirmation bias,\nafter-the-fact assurance and safety cases as a paperwork exercise. Rather than\ncreating new notations and tools to address these issues, we contend that it is\nimprovements in the safety case process that will make the most significant\nimprovement to safety case practice. Our method builds upon established\napproaches and best practice to create an approach that will ensure safety\ncases are risk-focused, seek to identify ways in which the system may not be\nsafe (rather than just assuming it is), drive safe design and operation of the\nsystem (influencing the system itself rather than just documenting what's\nthere), are used to support decisions made throughout the life of the system,\nincluding system operation and change, and encourage developers and operators\nto think about and understand why their system is safe (and when it isn't). A\nsimple example of an infusion pump system is used to illustrate how the new\nmethod is applied in practice.",
    "pdf_url": "http://arxiv.org/pdf/2502.00911v1",
    "published": "2025-02-02T20:47:30+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.00910v1",
    "title": "Attention-Based Functional-Group Coarse-Graining: A Deep Learning Framework for Molecular Prediction and Design",
    "authors": [
      "Ming Han",
      "Ge Sun",
      "Juan J. de Pablo"
    ],
    "abstract": "Machine learning (ML) offers considerable promise for the design of new\nmolecules and materials. In real-world applications, the design problem is\noften domain-specific, and suffers from insufficient data, particularly labeled\ndata, for ML training. In this study, we report a data-efficient, deep-learning\nframework for molecular discovery that integrates a coarse-grained\nfunctional-group representation with a self-attention mechanism to capture\nintricate chemical interactions. Our approach exploits group-contribution\ntheory to create a graph-based intermediate representation of molecules,\nserving as a low-dimensional embedding that substantially reduces the data\ndemands typically required for training. By leveraging the self-attention\nmechanism to learn subtle chemical context, our method consistently outperforms\nconventional methods in predicting multiple thermophysical properties. In a\ncase study focused on adhesive polymer monomers, we train on a limited dataset\ncomprising just 6,000 unlabeled and 600 labeled monomers. The resulting\nchemistry prediction model achieves over 92% accuracy in forecasting properties\ndirectly from SMILES strings, exceeding the performance of current\nstate-of-the-art techniques. Furthermore, the latent molecular embedding is\ninvertible, allowing the design pipeline to incorporate a decoder that can\nautomatically generate new monomers from the learned chemical subspace. We\nillustrate this functionality by targeting high and low glass transition\ntemperatures ($T_g$), successfully identifying novel candidates whose $T_g$\nextends beyond the range observed in the training data. The ease with which our\ncoarse-grained, attention-based framework navigates both chemical diversity and\ndata scarcity offers a compelling route to accelerate and broaden the search\nfor functional materials.",
    "pdf_url": "http://arxiv.org/pdf/2502.00910v1",
    "published": "2025-02-02T20:47:24+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00909v1",
    "title": "Can the Nexus of Scaling Laws Coupled with Constant or Variable Elasticity of Substitution Predict AI and Other Technology Adoption?",
    "authors": [
      "Rajesh P. Narayanan",
      "R. Kelley Pace"
    ],
    "abstract": "Emergent technologies such as solar power, electric vehicles, and artificial\nintelligence (AI) often exhibit exponential or power function price declines\nand various ``S-curves'' of adoption. We show that under CES and VES utility,\nsuch price and adoption curves are functionally linked. When price declines\nfollow Moore's, Wright's and AI scaling \"Laws,'' the S-curve of adoption is\nLogistic or Log-Logistic whose slope depends on the interaction between an\nexperience parameter and the elasticity of substitution between the incumbent\nand emergent good. These functional relations can serve as a building block for\nmore complex models and guide empirical specifications of technology adoption.",
    "pdf_url": "http://arxiv.org/pdf/2502.00909v1",
    "published": "2025-02-02T20:47:01+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2502.00908v1",
    "title": "Exploring the Effects of Level of Control in the Initialization of Shared Whiteboarding Sessions in Collaborative Augmented Reality",
    "authors": [
      "Logan Lane",
      "Jerald Thomas",
      "Alexander Giovannelli",
      "Ibrahim Tahmid",
      "Doug Bowman"
    ],
    "abstract": "Augmented Reality (AR) collaboration can benefit from a shared 2D surface,\nsuch as a whiteboard. However, many features of each collaborators physical\nenvironment must be considered in order to determine the best placement and\nshape of the shared surface. We explored the effects of three methods for\nbeginning a collaborative whiteboarding session with varying levels of user\ncontrol: MANUAL, DISCRETE CHOICE, and AUTOMATIC by conducting a simulated AR\nstudy within Virtual Reality (VR). In the MANUAL method, users draw their own\nsurfaces directly in the environment until they agree on the placement; in the\nDISCRETE CHOICE method, the system provides three options for whiteboard size\nand location; and in the AUTOMATIC method, the system automatically creates a\nwhiteboard that fits within each collaborators environment. We evaluate these\nthree conditions in a study in which two collaborators used each method to\nbegin collaboration sessions. After establishing a session, the users worked\ntogether to complete an affinity diagramming task using the shared whiteboard.\nWe found that the majority of participants preferred to have direct control\nduring the initialization of a new collaboration session, despite the\nadditional workload induced by the Manual method.",
    "pdf_url": "http://arxiv.org/pdf/2502.00908v1",
    "published": "2025-02-02T20:46:29+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00907v1",
    "title": "Identifying the Unique Geochemical Fingerprints of Omo Group Beds around Lake Turkana, Kenya by Modified Gaussian Discrimination Analysis",
    "authors": [
      "Gerard T. Schuster",
      "Shihang Feng"
    ],
    "abstract": "A modified Gaussian Discriminant Analysis (GDA) is used with an optimal\nsearch strategy to identify the unique geochemical fingerprints of six\ndifferent geological beds in the Lake Turkana area. Three-hundred samples were\ncollected from six different beds in the Omo Group of Lake Turkana, where each\nsample consisted of the PPMs of 11 different chemical compound. The GDA\nanalysis discovered a unique combination of three tuff compounds that can\nuniquely identify one of the five beds, where a 6th bed is excluded because\nonly 7 samples were collected from it. These geochemical fingerprints are\nimportant because any Turkana hominin fossil in the Omo Group can now be\nefficiently identified by matching the geochemical fingerprint of a fossil's\nhost rock to the fingerprint of the bed in which it is found. In general, the\nGDA search strategy can be a powerful tool for efficiently identifying unique\nclass fingerprints of high-dimensional data.",
    "pdf_url": "http://arxiv.org/pdf/2502.00907v1",
    "published": "2025-02-02T20:44:15+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00906v2",
    "title": "Multi-Velocity Sharp-Interface Continuum Thermodynamics of Fluid Systems with Adsorption",
    "authors": [
      "Dieter Bothe"
    ],
    "abstract": "We revisit the sharp-interface continuum thermodynamics of two-phase\nmulticomponent fluid systems, accounting for partial mass and partial momentum\nbalances both in the bulk phases and on the interface. This allows to describe\nthe transfer of species between the individual bulk phases and the interface,\ni.e. ad- and desorption processes. In fact, the transfer of any constituent\nbetween the two bulk-phases is considered as a series of ad- and desorption\nprocesses. In this framework, all species transfer processes are coupled via\nthe interfacial thermodynamics. As a consequence, the influence of surface\nactive species on the transfer of other constituents can be captured in detail.\nThe derivation of this model class relies on an axiomatic form of the entropy\nprinciple which, at the same time, allows for an efficient closure process.\nThis form of the entropy principle has been introduced for one-phase fluid\nsystems in (Bothe, Dreyer, Acta Mechanica 226, 2015) as the result of intense\njoint work of the late Wolfgang Dreyer and the present author.",
    "pdf_url": "http://arxiv.org/pdf/2502.00906v2",
    "published": "2025-02-02T20:44:13+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.00905v1",
    "title": "Generalized Eddington--Finkelstein Coordinates and Exact Vaidya-Type Solutions in Weyl Conformal Gravity",
    "authors": [
      "Petr Jizba",
      "Tereza Lehečková"
    ],
    "abstract": "We study Vaidya-type solutions in Weyl conformal gravity (WCG) using\nEddington--Finkelstein-like coordinates. Our considerations focus on spherical\nas well as hyperbolic and planar symmetries. In particular, we find all vacuum\ndynamical solutions for the aforementioned symmetries. These are, in contrast\nto general relativity, structurally quite non-trivial. We provide a thorough\nanalysis of their basic properties, such as, relation to other known WCG\nsolutions, algebraic types, singularities, horizons, and symmetries. In the\nsame vein, we also derive, classify, and discuss non-vacuum solutions with the\nCoulombic electric field and null dust. Other salient issues, such as the gauge\nequivalence of WCG solutions to Einstein spaces and the role of the\nBirkhoff--Riegert theorem, are also addressed.",
    "pdf_url": "http://arxiv.org/pdf/2502.00905v1",
    "published": "2025-02-02T20:38:45+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.00904v1",
    "title": "Parameter Estimation of State Space Models Using Particle Importance Sampling",
    "authors": [
      "Yuxiong Gao",
      "Wentao Li",
      "Rong Chen"
    ],
    "abstract": "State-space models have been used in many applications, including\neconometrics, engineering, medical research, etc. The maximum likelihood\nestimation (MLE) of the static parameter of general state-space models is not\nstraightforward because the likelihood function is intractable. It is popular\nto use the sequential Monte Carlo(SMC) method to perform gradient ascent\noptimisation in either offline or online fashion. One problem with existing\nonline SMC methods for MLE is that the score estimators are inconsistent, i.e.\nthe bias does not vanish with increasing particle size. In this paper, two SMC\nalgorithms are proposed based on an importance sampling weight function to use\neach set of generated particles more efficiently. The first one is an offline\nalgorithm that locally approximates the likelihood function using importance\nsampling, where the locality is adapted by the effective sample size (ESS). The\nsecond one is a semi-online algorithm that has a computational cost linear in\nthe particle size and uses score estimators that are consistent. We study its\nconsistency and asymptotic normality. Their computational superiority is\nillustrated in numerical studies for long time series.",
    "pdf_url": "http://arxiv.org/pdf/2502.00904v1",
    "published": "2025-02-02T20:29:40+00:00",
    "categories": [
      "stat.ME",
      "stat.CO"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.00903v2",
    "title": "Embracing Dialectic Intersubjectivity: Coordination of Different Perspectives in Content Analysis with LLM Persona Simulation",
    "authors": [
      "Taewoo Kang",
      "Kjerstin Thorson",
      "Tai-Quan Peng",
      "Dan Hiaeshutter-Rice",
      "Sanguk Lee",
      "Stuart Soroka"
    ],
    "abstract": "This study attempts to advancing content analysis methodology from\nconsensus-oriented to coordination-oriented practices, thereby embracing\ndiverse coding outputs and exploring the dynamics among differential\nperspectives. As an exploratory investigation of this approach, we evaluate six\nGPT-4o configurations to analyze sentiment in Fox News and MSNBC transcripts on\nBiden and Trump during the 2020 U.S. presidential campaign, examining patterns\nacross these models. By assessing each model's alignment with ideological\nperspectives, we explore how partisan selective processing could be identified\nin LLM-Assisted Content Analysis (LACA). Findings reveal that partisan persona\nLLMs exhibit stronger ideological biases when processing politically congruent\ncontent. Additionally, intercoder reliability is higher among same-partisan\npersonas compared to cross-partisan pairs. This approach enhances the nuanced\nunderstanding of LLM outputs and advances the integrity of AI-driven social\nscience research, enabling simulations of real-world implications.",
    "pdf_url": "http://arxiv.org/pdf/2502.00903v2",
    "published": "2025-02-02T20:29:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00902v2",
    "title": "More Rigorous Software Engineering Would Improve Reproducibility in Machine Learning Research",
    "authors": [
      "Moritz Wolter",
      "Lokesh Veeramacheneni",
      "Charles Tapley Hoyt"
    ],
    "abstract": "While experimental reproduction remains a pillar of the scientific method, we\nobserve that the software best practices supporting the reproduction of machine\nlearning ( ML ) research are often undervalued or overlooked, leading both to\npoor reproducibility and damage to trust in the ML community. We quantify these\nconcerns by surveying the usage of software best practices in software\nrepositories associated with publications at major ML conferences and journals\nsuch as NeurIPS, ICML, ICLR, TMLR, and MLOSS within the last decade. We report\nthe results of this survey that identify areas where software best practices\nare lacking and areas with potential for growth in the ML community. Finally,\nwe discuss the implications and present concrete recommendations on how we, as\na community, can improve reproducibility in ML research.",
    "pdf_url": "http://arxiv.org/pdf/2502.00902v2",
    "published": "2025-02-02T20:29:09+00:00",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.00901v1",
    "title": "Fundamental limits of learning in sequence multi-index models and deep attention networks: High-dimensional asymptotics and sharp thresholds",
    "authors": [
      "Emanuele Troiani",
      "Hugo Cui",
      "Yatin Dandi",
      "Florent Krzakala",
      "Lenka Zdeborová"
    ],
    "abstract": "In this manuscript, we study the learning of deep attention neural networks,\ndefined as the composition of multiple self-attention layers, with tied and\nlow-rank weights. We first establish a mapping of such models to sequence\nmulti-index models, a generalization of the widely studied multi-index model to\nsequential covariates, for which we establish a number of general results. In\nthe context of Bayesian-optimal learning, in the limit of large dimension $D$\nand commensurably large number of samples $N$, we derive a sharp asymptotic\ncharacterization of the optimal performance as well as the performance of the\nbest-known polynomial-time algorithm for this setting --namely approximate\nmessage-passing--, and characterize sharp thresholds on the minimal sample\ncomplexity required for better-than-random prediction performance. Our analysis\nuncovers, in particular, how the different layers are learned sequentially.\nFinally, we discuss how this sequential learning can also be observed in a\nrealistic setup.",
    "pdf_url": "http://arxiv.org/pdf/2502.00901v1",
    "published": "2025-02-02T20:27:11+00:00",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00900v1",
    "title": "Dynamical equivalence between resonant translocation of a polymer chain and diversity-induced resonance",
    "authors": [
      "Marco Patriarca",
      "Stefano Scialla",
      "Els Heinsalu",
      "Marius E. Yamakou",
      "Julyan H. E. Cartwright"
    ],
    "abstract": "Networks of heterogeneous oscillators are often seen to display collective\nsynchronized oscillations, even when single elements of the network do not\noscillate in isolation. It has been found that it is the diversity of the\nindividual elements that drives the phenomenon, possibly leading to the\nappearance of a resonance in the response. Here we study the way in which\nheterogeneity acts in producing an oscillatory regime in a network and show\nthat the resonance response is based on the same physics underlying the\nresonant translocation regime observed in models of polymer diffusion on a\nsubstrate potential. Such a mechanical analog provides an alternative viewpoint\nthat is useful to interpret and understand the nature of collective\noscillations in heterogeneous networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.00900v1",
    "published": "2025-02-02T20:26:17+00:00",
    "categories": [
      "physics.bio-ph"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00899v1",
    "title": "HASSLE-free: A unified Framework for Sparse plus Low-Rank Matrix Decomposition for LLMs",
    "authors": [
      "Mehdi Makni",
      "Kayhan Behdin",
      "Zheng Xu",
      "Natalia Ponomareva",
      "Rahul Mazumder"
    ],
    "abstract": "The impressive capabilities of large foundation models come at a cost of\nsubstantial computing resources to serve them. Compressing these pre-trained\nmodels is of practical interest as it can democratize deploying them to the\nmachine learning community at large by lowering the costs associated with\ninference. A promising compression scheme is to decompose foundation models'\ndense weights into a sum of sparse plus low-rank matrices. In this paper, we\ndesign a unified framework coined HASSLE-free for (semi-structured) sparse plus\nlow-rank matrix decomposition of foundation models. Our framework introduces\nthe local layer-wise reconstruction error objective for this decomposition, we\ndemonstrate that prior work solves a relaxation of this optimization problem;\nand we provide efficient and scalable methods to minimize the exact introduced\noptimization problem. HASSLE-free substantially outperforms state-of-the-art\nmethods in terms of the introduced objective and a wide range of LLM evaluation\nbenchmarks. For the Llama3-8B model with a 2:4 sparsity component plus a\n64-rank component decomposition, a compression scheme for which recent work\nshows important inference acceleration on GPUs, HASSLE-free reduces the test\nperplexity by 12% for the WikiText-2 dataset and reduces the gap (compared to\nthe dense model) of the average of eight popular zero-shot tasks by 15%\ncompared to existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.00899v1",
    "published": "2025-02-02T20:23:32+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.00898v2",
    "title": "Finite codimension stability of invariant surfaces",
    "authors": [
      "Giovanni Forni"
    ],
    "abstract": "Following recent work of T. Alazard and C. Shao on applications of\npara-differential calculus to smooth conjugacy and stability problems for\nHamiltonian systems, we prove finite codimension stability of invariant\nsurfaces (in finite differentiability classes) of flat geodesic flows on\ntranslation surfaces. The result is also based on work of the author on the\ncohomological equation for translation flows.",
    "pdf_url": "http://arxiv.org/pdf/2502.00898v2",
    "published": "2025-02-02T20:16:50+00:00",
    "categories": [
      "math.DS",
      "37C75, 37C83, 35S50"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.00897v1",
    "title": "Multi-frequency wavefield solutions for variable velocity models using meta-learning enhanced low-rank physics-informed neural network",
    "authors": [
      "Shijun Cheng",
      "Tariq Alkhalifah"
    ],
    "abstract": "Physics-informed neural networks (PINNs) face significant challenges in\nmodeling multi-frequency wavefields in complex velocity models due to their\nslow convergence, difficulty in representing high-frequency details, and lack\nof generalization to varying frequencies and velocity scenarios. To address\nthese issues, we propose Meta-LRPINN, a novel framework that combines low-rank\nparameterization using singular value decomposition (SVD) with meta-learning\nand frequency embedding. Specifically, we decompose the weights of PINN's\nhidden layers using SVD and introduce an innovative frequency embedding\nhypernetwork (FEH) that links input frequencies with the singular values,\nenabling efficient and frequency-adaptive wavefield representation.\nMeta-learning is employed to provide robust initialization, improving\noptimization stability and reducing training time. Additionally, we implement\nadaptive rank reduction and FEH pruning during the meta-testing phase to\nfurther enhance efficiency. Numerical experiments, which are presented on\nmulti-frequency scattered wavefields for different velocity models, demonstrate\nthat Meta-LRPINN achieves much fast convergence speed and much high accuracy\ncompared to baseline methods such as Meta-PINN and vanilla PINN. Also, the\nproposed framework shows strong generalization to out-of-distribution\nfrequencies while maintaining computational efficiency. These results highlight\nthe potential of our Meta-LRPINN for scalable and adaptable seismic wavefield\nmodeling.",
    "pdf_url": "http://arxiv.org/pdf/2502.00897v1",
    "published": "2025-02-02T20:12:39+00:00",
    "categories": [
      "cs.LG",
      "physics.geo-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00896v3",
    "title": "LoR-VP: Low-Rank Visual Prompting for Efficient Vision Model Adaptation",
    "authors": [
      "Can Jin",
      "Ying Li",
      "Mingyu Zhao",
      "Shiyu Zhao",
      "Zhenting Wang",
      "Xiaoxiao He",
      "Ligong Han",
      "Tong Che",
      "Dimitris N. Metaxas"
    ],
    "abstract": "Visual prompting has gained popularity as a method for adapting pre-trained\nmodels to specific tasks, particularly in the realm of parameter-efficient\ntuning. However, existing visual prompting techniques often pad the prompt\nparameters around the image, limiting the interaction between the visual\nprompts and the original image to a small set of patches while neglecting the\ninductive bias present in shared information across different patches. In this\nstudy, we conduct a thorough preliminary investigation to identify and address\nthese limitations. We propose a novel visual prompt design, introducing\nLow-Rank matrix multiplication for Visual Prompting (LoR-VP), which enables\nshared and patch-specific information across rows and columns of image pixels.\nExtensive experiments across seven network architectures and four datasets\ndemonstrate significant improvements in both performance and efficiency\ncompared to state-of-the-art visual prompting methods, achieving up to 6 times\nfaster training times, utilizing 18 times fewer visual prompt parameters, and\ndelivering a 3.1% improvement in performance. The code is available as\nhttps://github.com/jincan333/LoR-VP.",
    "pdf_url": "http://arxiv.org/pdf/2502.00896v3",
    "published": "2025-02-02T20:10:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00895v1",
    "title": "Mechanism of tulip flame formation in highly reactive and low reactive gas mixtures",
    "authors": [
      "Chengeng Qian",
      "Mikhail Liberman"
    ],
    "abstract": "The early stages of flame dynamics and the development and evolution of tulip\nflames in closed tubes of various aspect ratios and in a semi-open tube are\nstudied by solving the fully compressible reactive Navier-Stokes equations\nusing a high-order numerical method coupled to detailed chemical models in a\nstoichiometric hydrogen/air and methane/air mixtures. The use of adaptive mesh\nrefinement provides adequate resolution of the flame reaction zone, pressure\nwaves, and flame-pressure wave interactions. The purpose of this study is to\ngain a deeper insight into the influence of chemical kinetics on the combustion\nregimes leading to the formation of a tulip flame and its subsequent evolution.\nThe simulations highlight the effect of flame thickness, flame velocity, and\nreaction order on the intensity of the rarefaction wave generated by the flame\nduring the deceleration phase, which is the principal physical mechanism of\ntulip flame formation. The obtained results explain most of the experimentally\nobserved features of tulip flame formation, e.g. faster tulip flame formation\nwith deeper tulip shape for faster flames compared to slower flames.",
    "pdf_url": "http://arxiv.org/pdf/2502.00895v1",
    "published": "2025-02-02T20:06:43+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.00894v1",
    "title": "MorphBPE: A Morpho-Aware Tokenizer Bridging Linguistic Complexity for Efficient LLM Training Across Morphologies",
    "authors": [
      "Ehsaneddin Asgari",
      "Yassine El Kheir",
      "Mohammad Ali Sadraei Javaheri"
    ],
    "abstract": "Tokenization is fundamental to Natural Language Processing (NLP), directly\nimpacting model efficiency and linguistic fidelity. While Byte Pair Encoding\n(BPE) is widely used in Large Language Models (LLMs), it often disregards\nmorpheme boundaries, leading to suboptimal segmentation, particularly in\nmorphologically rich languages. We introduce MorphBPE, a morphology-aware\nextension of BPE that integrates linguistic structure into subword tokenization\nwhile preserving statistical efficiency. Additionally, we propose two\nmorphology-based evaluation metrics: (i) Morphological Consistency F1-Score,\nwhich quantifies the consistency between morpheme sharing and token sharing,\ncontributing to LLM training convergence, and (ii) Morphological Edit Distance,\nwhich measures alignment between morphemes and tokens concerning\ninterpretability. Experiments on English, Russian, Hungarian, and Arabic across\n300M and 1B parameter LLMs demonstrate that MorphBPE consistently reduces\ncross-entropy loss, accelerates convergence, and improves morphological\nalignment scores. Fully compatible with existing LLM pipelines, MorphBPE\nrequires minimal modifications for integration. The MorphBPE codebase and\ntokenizer playground will be available at:\nhttps://github.com/llm-lab-org/MorphBPE and https://tokenizer.llm-lab.org",
    "pdf_url": "http://arxiv.org/pdf/2502.00894v1",
    "published": "2025-02-02T20:06:39+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00893v3",
    "title": "ToddlerBot: Open-Source ML-Compatible Humanoid Platform for Loco-Manipulation",
    "authors": [
      "Haochen Shi",
      "Weizhuo Wang",
      "Shuran Song",
      "C. Karen Liu"
    ],
    "abstract": "Learning-based robotics research driven by data demands a new approach to\nrobot hardware design-one that serves as both a platform for policy execution\nand a tool for embodied data collection to train policies. We introduce\nToddlerBot, a low-cost, open-source humanoid robot platform designed for\nscalable policy learning and research in robotics and AI. ToddlerBot enables\nseamless acquisition of high-quality simulation and real-world data. The\nplug-and-play zero-point calibration and transferable motor system\nidentification ensure a high-fidelity digital twin, enabling zero-shot policy\ntransfer from simulation to the real world. A user-friendly teleoperation\ninterface facilitates streamlined real-world data collection for learning motor\nskills from human demonstrations. Utilizing its data collection ability and\nanthropomorphic design, ToddlerBot is an ideal platform to perform whole-body\nloco-manipulation. Additionally, ToddlerBot's compact size (0.56m, 3.4kg)\nensures safe operation in real-world environments. Reproducibility is achieved\nwith an entirely 3D-printed, open-source design and commercially available\ncomponents, keeping the total cost under 6,000 USD. Comprehensive documentation\nallows assembly and maintenance with basic technical expertise, as validated by\na successful independent replication of the system. We demonstrate ToddlerBot's\ncapabilities through arm span, payload, endurance tests, loco-manipulation\ntasks, and a collaborative long-horizon scenario where two robots tidy a toy\nsession together. By advancing ML-compatibility, capability, and\nreproducibility, ToddlerBot provides a robust platform for scalable learning\nand dynamic policy execution in robotics research.",
    "pdf_url": "http://arxiv.org/pdf/2502.00893v3",
    "published": "2025-02-02T20:05:32+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00892v1",
    "title": "A declarative approach to specifying distributed algorithms using three-valued modal logic",
    "authors": [
      "Murdoch J. Gabbay",
      "Luca Zanolini"
    ],
    "abstract": "We present Coalition Logic, a three-valued modal fixed-point logic designed\nfor declaratively specifying and reasoning about distributed algorithms, such\nas the Paxos consensus algorithm.\n  Our methodology represents a distributed algorithm as a logical theory,\nenabling correctness properties to be derived directly within the framework --\nor revealing logical errors in the algorithm's design when they exist.\n  Coalition Logic adopts a declarative approach, specifying the overall logic\nof computation without prescribing control flow. Notably, message-passing is\nnot explicitly modeled, distinguishing our framework from approaches like TLA+.\nThis abstraction emphasises the logical essence of distributed algorithms,\noffering a novel perspective on their specification and reasoning.\n  We define the syntax and semantics of Coalition Logic, explore its\ntheoretical properties, and demonstrate its applicability through a detailed\ntreatment of the Paxos consensus algorithm. By presenting Paxos as a logical\ntheory and deriving its standard correctness properties, we showcase the\nframework's capacity to handle non-trivial distributed systems.\n  We envision Coalition Logic as a versatile tool for specifying and reasoning\nabout distributed algorithms. The Paxos example highlights the framework's\nability to capture intricate details, offering a new lens through which\ndistributed algorithms can be specified, studied, and checked.",
    "pdf_url": "http://arxiv.org/pdf/2502.00892v1",
    "published": "2025-02-02T20:03:21+00:00",
    "categories": [
      "cs.LO",
      "math.LO",
      "03B45, 03B50, 68Q60",
      "F.4.1; F.3.1"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00891v1",
    "title": "Isoperimetric inequality for nearly spherical domains in the Bergman ball in $\\mathbb{C}^n$",
    "authors": [
      "David Kalaj"
    ],
    "abstract": "We prove a quantitative isoperimetric inequality for the nearly spherical\nsubset of the Bergman ball in $\\mathbb{C}^n$. We prove the Fuglede theorem for\nsuch sets. This result is a counterpart of a similar result obtained for the\nhyperbolic unit ball and it makes the first result on the isoperimetric\nphenomenon in the Bergman ball.",
    "pdf_url": "http://arxiv.org/pdf/2502.00891v1",
    "published": "2025-02-02T19:57:50+00:00",
    "categories": [
      "math.CV",
      "math.DG"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00890v1",
    "title": "Lorentz-violating pseudovectors in effective field theories for quantum gravity",
    "authors": [
      "Hollis Williams"
    ],
    "abstract": "Effective field theories which describe the coupling between gravity and\nmatter fields have recently been extended to include terms with operators of\nnon-minimal mass dimension. These terms preserve the usual gauge symmetries but\nmay violate local Lorentz and diffeomorphism invariance. The number of possible\nterms in the field theory explodes once one allows for non-minimal operators,\nwith no criterion to choose between them. We suggest as such a criterion to\nfocus on terms which violate Lorentz invariance via a (pseudo)vector background\nfield, leaving a number of possible terms in the Higgs, gauge and gravitational\nsectors. Further study of these terms is motivated by the proposed\ncorrespondence between the general effective theory for Lorentz violation and\nemergent Lorentz symmetry in condensed-matter systems, which is mostly\nunexplored for higher mass dimension operators and couplings to gauge fields\nand gravity. We suggest bounds in the Higgs sector and we show that some of the\ncoefficients in the gauge sector vanish at one loop, whereas others have bounds\nwhich are comparable with those suggested by Kosteleck\\'y and Li for\ncoefficients in Lorentz-violating QCD and QED coupled to quarks. We also find\nnew bounds in the gravitational sector by considering Robertson-Walker\ncosmology. Finally, we discuss the special case where only diffeomorphism\ninvariance is spontaneously broken and explain why it does not allow for\nnon-trivial Nambu-Goldstone modes.",
    "pdf_url": "http://arxiv.org/pdf/2502.00890v1",
    "published": "2025-02-02T19:55:54+00:00",
    "categories": [
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00889v1",
    "title": "Interplay of correlations and Majorana mode from local solution perspective",
    "authors": [
      "Jan Barański",
      "Magdalena Barańska",
      "Tomasz Zienkiewicz",
      "Tadeusz Domański"
    ],
    "abstract": "We study the quasiparticle spectrum of a hybrid system, comprising a\ncorrelated (Anderson-type) quantum dot coupled to a topological superconducting\nnanowire hosting the Majorana boundarymodes. From the exact solution of the\nlow-energy effective Hamiltonian, we uncover a subtle interplay between Coulomb\nrepulsion and the Majorana mode. Our analytical expressions show that the\nspectral weight of the leaking Majorana mode is sensitive to both the quantum\ndot energy level and the repulsive potential. We compare our results with\nestimations by L.S. Ricco et al. Phys. Rev. B 99, 155159 (2019) obtained for\nthe same hybrid structure using the Hubbard-type decoupling scheme, and\nanalytically quantify the spectral weight of the zero-energy (topological) mode\ncoexisting with the finite-energy (trivial) states of the quantum dot. We also\nshow that empirical verification of these spectral weights could be feasible\nthrough spin-polarized Andreev spectroscopy.",
    "pdf_url": "http://arxiv.org/pdf/2502.00889v1",
    "published": "2025-02-02T19:53:02+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.00888v1",
    "title": "Planet Purifiers: A Collaborative Immersive Experience Proposing New Modifications to HOMER and Fishing Reel Interaction Techniques",
    "authors": [
      "Alexander Giovannelli",
      "Fionn Murphy",
      "Trey Davis",
      "Chaerin Lee",
      "Rehema Abulikemu",
      "Matthew Gallagher",
      "Sahil Sharma",
      "Lee Lisle",
      "Doug Bowman"
    ],
    "abstract": "This paper presents our solution to the 2025 3DUI Contest challenge. We aimed\nto develop a collaborative, immersive experience that raises awareness about\ntrash pollution in natural landscapes while enhancing traditional interaction\ntechniques in virtual environments. To achieve these objectives, we created an\nengaging multiplayer game where one user collects harmful pollutants while the\nother user provides medication to impacted wildlife using enhancements to\ntraditional interaction techniques: HOMER and Fishing Reel. We enhanced HOMER\nto use a cone volume to reduce the precise aiming required by a selection\nraycast to provide a more efficient means to collect pollutants at large\ndistances, coined as FLOW-MATCH. To improve the animal feed distribution to\nwildlife far away from the user with Fishing Reel, we created RAWR-XD, an\nasymmetric bi-manual technique to more conveniently adjust the reeling speed\nusing the non-selecting wrist rotation of the user.",
    "pdf_url": "http://arxiv.org/pdf/2502.00888v1",
    "published": "2025-02-02T19:52:24+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00887v1",
    "title": "Poststack Seismic Data Preconditioning via Dynamic Guided Learning",
    "authors": [
      "Javier Torres-Quintero",
      "Paul Goyes-Peñafiel",
      "Ana Mantilla-Dulcey",
      "Luis Rodríguez-López",
      "José Sanabria-Gómez",
      "Henry Arguello"
    ],
    "abstract": "Seismic data preconditioning is essential for subsurface interpretation. It\nenhances signal quality while attenuating noise, improving the accuracy of\ngeophysical tasks that would otherwise be biased by noise. Although classical\npoststack seismic data enhancement methods can effectively reduce noise, they\nrely on predefined statistical distributions, which often fail to capture the\ncomplexity of seismic noise. On the other hand, deep learning methods offer an\nalternative but require large and diverse data sets. Typically, static\ndatabases are used for training, introducing domain bias, and limiting\nadaptability to new noise poststack patterns. This work proposes a novel\ntwo-process dynamic training method to overcome these limitations. Our method\nuses a dynamic database that continuously generates clean and noisy patches\nduring training to guide the learning of a supervised enhancement network. This\ndynamic-guided learning workflow significantly improves generalization by\nintroducing variability into the training data. In addition, we employ a domain\nadaptation via a neural style transfer strategy to address the potential\nchallenge of encountering unknown noise domains caused by specific geological\nconfigurations. Experimental results demonstrate that our method outperforms\nstate-of-the-art solutions on both synthetic and field data, within and outside\nthe training domain, eliminating reliance on known statistical distributions\nand enhancing adaptability across diverse data sets of poststack data.",
    "pdf_url": "http://arxiv.org/pdf/2502.00887v1",
    "published": "2025-02-02T19:48:52+00:00",
    "categories": [
      "physics.geo-ph",
      "J.2"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00886v2",
    "title": "The survey of planetary nebulae in Andromeda (M31) VII. Predictions of a major merger simulation model compared with chemodynamical data of the disc and inner halo substructures",
    "authors": [
      "C. Tsakonas",
      "M. Arnaboldi",
      "S. Bhattacharya",
      "F. Hammer",
      "Y. Yang",
      "O. Gerhard",
      "R. F. G. Wyse",
      "D. Hatzidimitriou"
    ],
    "abstract": "The nearest giant spiral, M31, exhibits a kinematically hot stellar disc, a\nglobal star formation episode ~2-4 Gyr ago, and conspicuous substructures in\nits stellar halo that are suggestive of a recent accretion event. Recent\nchemodynamical measurements in the M31 disc and inner halo can be used as\nadditional constraints for N-body hydrodynamical simulations that successfully\nreproduce the disc age-velocity dispersion relation and star formation history\nas well as the morphology of the inner halo substructures. We combined a\nsimulation of a major merger (mass ratio 1:4) with a well-motivated chemical\nmodel to predict abundance distributions and gradients in the merger remnant at\nz=0. We computed the projected phase space and the [M/H] distributions for the\nsubstructures in the M31 inner halo, namely, the Giant Stellar Stream (GSS) and\nthe North-East (NE) and Western (W) shelves, and compared them with recent\nmeasurements for the M31 stars in the inner halo. This major merger model\npredicts (i) multiple distinct components within each of the substructures;\n(ii) a high mean metallicity and large spread in the GSS and NE and W Shelves\nwhich explain various photometric and spectroscopic metallicity measurements;\n(iii) simulated phase space diagrams that qualitatively reproduce various\nfeatures identified in the projected phase space of the substructures in\npublished data from the DESI; (iv) a large distance spread in the GSS, as\nsuggested by previous tip of the RGB measurements; and (v) phase space ridges\ncaused by several wraps of the secondary as well as up-scattered main M31 disc\nstars that also have plausible counterparts in the observed phase spaces. These\nresults provide further strong and independent arguments for a major satellite\nmerger in M31 ~3 Gyr ago and a coherent explanation for many of the\nobservational results that make M31 appear so different from the Milky Way.",
    "pdf_url": "http://arxiv.org/pdf/2502.00886v2",
    "published": "2025-02-02T19:33:43+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00885v1",
    "title": "Algorithmic Stability of Stochastic Gradient Descent with Momentum under Heavy-Tailed Noise",
    "authors": [
      "Thanh Dang",
      "Melih Barsbey",
      "A K M Rokonuzzaman Sonet",
      "Mert Gurbuzbalaban",
      "Umut Simsekli",
      "Lingjiong Zhu"
    ],
    "abstract": "Understanding the generalization properties of optimization algorithms under\nheavy-tailed noise has gained growing attention. However, the existing\ntheoretical results mainly focus on stochastic gradient descent (SGD) and the\nanalysis of heavy-tailed optimizers beyond SGD is still missing. In this work,\nwe establish generalization bounds for SGD with momentum (SGDm) under\nheavy-tailed gradient noise. We first consider the continuous-time limit of\nSGDm, i.e., a Levy-driven stochastic differential equation (SDE), and establish\nquantitative Wasserstein algorithmic stability bounds for a class of\npotentially non-convex loss functions. Our bounds reveal a remarkable\nobservation: For quadratic loss functions, we show that SGDm admits a worse\ngeneralization bound in the presence of heavy-tailed noise, indicating that the\ninteraction of momentum and heavy tails can be harmful for generalization. We\nthen extend our analysis to discrete-time and develop a uniform-in-time\ndiscretization error bound, which, to our knowledge, is the first result of its\nkind for SDEs with degenerate noise. This result shows that, with appropriately\nchosen step-sizes, the discrete dynamics retain the generalization properties\nof the limiting SDE. We illustrate our theory on both synthetic quadratic\nproblems and neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.00885v1",
    "published": "2025-02-02T19:25:48+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC",
      "math.PR"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.00884v1",
    "title": "Synchronization of the time-delayed Kuramoto model in a regular network",
    "authors": [
      "Sara Ameli",
      "Esmaeil Mahdavi",
      "Mina Zarei",
      "Farhad Shahbazi"
    ],
    "abstract": "This study investigates the impact of delayed coupling on the global and\nlocal synchronization of identical coupled oscillators residing in a ring.\nUtilizing the Kuramoto model, we examine the effects of delayed coupling on\ncollective dynamics. Our analytical and numerical results reveal distinct\nsynchronization behaviors across various time delay regimes, including fully\nsynchronized states, helical patterns, dynamically incoherent states, and\nrandom phase-locked states. We identify the regime in which time delay inhibits\nsynchrony, which aligns with theoretical predictions derived from stability\nanalysis. In the region between the synchrony-possible and synchrony-forbidden\nzones, a coexistence of synchronized and unsynchronized dynamics is observed,\nreferred to as Chimera states. We ascertain that the type of Chimera states\npresent is moving-turbulent.",
    "pdf_url": "http://arxiv.org/pdf/2502.00884v1",
    "published": "2025-02-02T19:25:46+00:00",
    "categories": [
      "nlin.AO"
    ],
    "primary_category": "nlin.AO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00883v4",
    "title": "SimPER: A Minimalist Approach to Preference Alignment without Hyperparameters",
    "authors": [
      "Teng Xiao",
      "Yige Yuan",
      "Zhengyu Chen",
      "Mingxiao Li",
      "Shangsong Liang",
      "Zhaochun Ren",
      "Vasant G Honavar"
    ],
    "abstract": "Existing preference optimization objectives for language model alignment\nrequire additional hyperparameters that must be extensively tuned to achieve\noptimal performance, increasing both the complexity and time required for\nfine-tuning large language models. In this paper, we propose a simple yet\neffective hyperparameter-free preference optimization algorithm for alignment.\nWe observe that promising performance can be achieved simply by optimizing\ninverse perplexity, which is calculated as the inverse of the exponentiated\naverage log-likelihood of the chosen and rejected responses in the preference\ndataset. The resulting simple learning objective, SimPER, is easy to implement\nand eliminates the need for expensive hyperparameter tuning and a reference\nmodel, making it both computationally and memory efficient. Extensive\nexperiments on widely used real-world benchmarks, including MT-Bench,\nAlpacaEval 2, and 10 key benchmarks of the Open LLM Leaderboard with 5 base\nmodels, demonstrate that SimPER consistently and significantly outperforms\nexisting approaches-even without any hyperparameters or a reference model . For\nexample, despite its simplicity, SimPER outperforms state-of-the-art methods by\nup to 5.7 points on AlpacaEval 2 and achieves the highest average ranking\nacross 10 benchmarks on the Open LLM Leaderboard. The source code for SimPER is\npublicly available at: https://github.com/tengxiao1/SimPER.",
    "pdf_url": "http://arxiv.org/pdf/2502.00883v4",
    "published": "2025-02-02T19:25:41+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00882v2",
    "title": "Worth Their Weight: Randomized and Regularized Block Kaczmarz Algorithms without Preprocessing",
    "authors": [
      "Gil Goldshlager",
      "Jiang Hu",
      "Lin Lin"
    ],
    "abstract": "Due to the ever growing amounts of data leveraged for machine learning and\nscientific computing, it is increasingly important to develop algorithms that\nsample only a small portion of the data at a time. In the case of linear\nleast-squares, the randomized block Kaczmarz method (RBK) is an appealing\nexample of such an algorithm, but its convergence is only understood under\nsampling distributions that require potentially prohibitively expensive\npreprocessing steps. To address this limitation, we analyze RBK when the data\nis sampled uniformly, showing that its iterates converge in a Monte Carlo sense\nto a $\\textit{weighted}$ least-squares solution. Unfortunately, for general\nproblems the condition number of the weight matrix and the variance of the\niterates can become arbitrarily large. We control these issues by incorporating\nregularization into the RBK iterations, yielding the regularized algorithm\nReBlocK. Numerical experiments including examples arising from natural gradient\noptimization demonstrate that ReBlocK can outperform both RBK and minibatch\nstochastic gradient descent for inconsistent problems with rapidly decaying\nsingular values.",
    "pdf_url": "http://arxiv.org/pdf/2502.00882v2",
    "published": "2025-02-02T19:23:46+00:00",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00881v1",
    "title": "Toward Living Narrative Reviews: An Empirical Study of the Processes and Challenges in Updating Survey Articles in Computing Research",
    "authors": [
      "Raymond Fok",
      "Alexa Siu",
      "Daniel S. Weld"
    ],
    "abstract": "Surveying prior literature to establish a foundation for new knowledge is\nessential for scholarly progress. However, survey articles are\nresource-intensive and challenging to create, and can quickly become outdated\nas new research is published, risking information staleness and inaccuracy.\nKeeping survey articles current with the latest evidence is therefore\ndesirable, though there is a limited understanding of why, when, and how these\nsurveys should be updated. Toward this end, through a series of in-depth\nretrospective interviews with 11 researchers, we present an empirical\nexamination of the work practices in authoring and updating survey articles in\ncomputing research. We find that while computing researchers acknowledge the\nvalue in maintaining an updated survey, continuous updating remains\nunmanageable and misaligned with academic incentives. Our findings suggest key\nleverage points within current workflows that present opportunities for\nenabling technologies to facilitate more efficient and effective updates.",
    "pdf_url": "http://arxiv.org/pdf/2502.00881v1",
    "published": "2025-02-02T19:16:19+00:00",
    "categories": [
      "cs.HC",
      "cs.DL"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00880v1",
    "title": "Investigating the Influence of Playback Interactivity during Guided Tours for Asynchronous Collaboration in Virtual Reality",
    "authors": [
      "Alexander Giovannelli",
      "Leonardo Pavanatto",
      "Shakiba Davari",
      "Haichao Miao",
      "Vuthea Chheang",
      "Brian Giera",
      "Peer-Timo Bremer",
      "Doug Bowman"
    ],
    "abstract": "Collaborative virtual environments allow workers to contribute to team\nprojects across space and time. While much research has closely examined the\nproblem of working in different spaces at the same time, few have investigated\nthe best practices for collaborating in those spaces at different times aside\nfrom textual and auditory annotations. We designed a system that allows experts\nto record a tour inside a virtual inspection space, preserving knowledge and\nproviding later observers with insights through a 3D playback of the expert's\ninspection. We also created several interactions to ensure that observers are\ntracking the tour and remaining engaged. We conducted a user study to evaluate\nthe influence of these interactions on an observing user's information recall\nand user experience. Findings indicate that independent viewpoint control\nduring a tour enhances the user experience compared to fully passive playback\nand that additional interactivity can improve auditory and spatial recall of\nkey information conveyed during the tour.",
    "pdf_url": "http://arxiv.org/pdf/2502.00880v1",
    "published": "2025-02-02T19:12:10+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00879v2",
    "title": "Generating Computational Cognitive Models using Large Language Models",
    "authors": [
      "Milena Rmus",
      "Akshay K. Jagadish",
      "Marvin Mathony",
      "Tobias Ludwig",
      "Eric Schulz"
    ],
    "abstract": "Computational cognitive models, which formalize theories of cognition, enable\nresearchers to quantify cognitive processes and arbitrate between competing\ntheories by fitting models to behavioral data. Traditionally, these models are\nhandcrafted, which requires significant domain knowledge, coding expertise, and\ntime investment. However, recent advances in machine learning offer solutions\nto these challenges. In particular, Large Language Models (LLMs) have\ndemonstrated remarkable capabilities for in-context pattern recognition,\nleveraging knowledge from diverse domains to solve complex problems, and\ngenerating executable code that can be used to facilitate the generation of\ncognitive models. Building on this potential, we introduce a pipeline for\nGuided generation of Computational Cognitive Models (GeCCo). Given task\ninstructions, participant data, and a template function, GeCCo prompts an LLM\nto propose candidate models, fits proposals to held-out data, and iteratively\nrefines them based on feedback constructed from their predictive performance.\nWe benchmark this approach across four different cognitive domains -- decision\nmaking, learning, planning, and memory -- using three open-source LLMs,\nspanning different model sizes, capacities, and families. On four human\nbehavioral data sets, the LLM generated models that consistently matched or\noutperformed the best domain-specific models from the cognitive science\nliterature. Taken together, our results suggest that LLMs can generate\ncognitive models with conceptually plausible theories that rival -- or even\nsurpass -- the best models from the literature across diverse task domains.",
    "pdf_url": "http://arxiv.org/pdf/2502.00879v2",
    "published": "2025-02-02T19:07:13+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00878v2",
    "title": "Ultrafast electrical control of dipolariton-based optical circuits with a few femto-joul per bit power consumption",
    "authors": [
      "Dror Liran",
      "Ronen Rapaport",
      "Kirk Baldwin",
      "Loren Pfeiffer",
      "Hui Deng"
    ],
    "abstract": "The next generation of photonic circuits will require programmable,\nultrafast, and energy-efficient components on a scalable platform for quantum\nand neuromorphic computing. Here, we present ultrafast electrical control of\nhighly nonlinear light-matter hybrid quasi-particles, called waveguide\nexciton-dipolaritons, with extremely low power consumption. Our device performs\nas an optical transistor with a GHz-rate electrical modulation at a record-low\ntotal energy consumption $\\sim$3 fJ/bit and a compact active area of down to 25\n$\\mu$m$^2$. This work establishes waveguide-dipolariton platforms for scalable,\nelectrically reconfigurable, ultra-low power photonic circuits for both\nclassical and quantum computing and communication.",
    "pdf_url": "http://arxiv.org/pdf/2502.00878v2",
    "published": "2025-02-02T19:03:37+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.00877v1",
    "title": "Trade Dynamics of the Global Dry Bulk Shipping Network",
    "authors": [
      "Yan Li",
      "Carol Alexander",
      "Michael Coulon",
      "Istvan Kiss"
    ],
    "abstract": "This study investigates the inherently random structures of dry bulk shipping\nnetworks, often likened to a taxi service, and identifies the underlying trade\ndynamics that contribute to this randomness within individual cargo\nsub-networks. By analysing micro-level trade flow data from 2015 to 2023, we\nexplore the evolution of dry commodity networks, including grain, coal, and\niron ore, and suggest that the Giant Strongly Connected Components exhibit\nsmall-world phenomena, indicative of efficient bilateral trade. The significant\nheterogeneity of in-degree and out-degree within these sub-networks, primarily\ndriven by importing ports, underscores the complexity of their dynamics. Our\ntemporal analysis shows that while the Covid-19 pandemic profoundly impacted\nthe coal network, the Ukraine conflict significantly altered the grain network,\nresulting in changes in community structures. Notably, grain sub-networks\ndisplay periodic changes, suggesting distinct life cycles absent in coal and\niron ore networks. These findings illustrate that the randomness in dry bulk\nshipping networks is a reflection of real-world trade dynamics, providing\nvaluable insights for stakeholders in navigating and predicting network\nbehaviours.",
    "pdf_url": "http://arxiv.org/pdf/2502.00877v1",
    "published": "2025-02-02T19:01:22+00:00",
    "categories": [
      "q-fin.MF",
      "physics.soc-ph"
    ],
    "primary_category": "q-fin.MF"
  },
  {
    "id": "http://arxiv.org/abs/2502.00876v1",
    "title": "The eigencurve at crystalline points with scalar Frobenius and Gross-Stark regulators",
    "authors": [
      "Adel Betina",
      "Alexandre Maksoud",
      "Alice Pozzi"
    ],
    "abstract": "A complete description of the local geometry of the $p$-adic eigencurve at\n$p$-irregular classical weight one cusp forms is given in the cases where the\nusual $R=T$ methods fall short. As an application, we show that the ordinary\n$p$-adic \\'etale cohomology group attached to the tower of elliptic modular\ncurves $X_1(Np^r)$ is not free over the Hecke algebra, when localized at a\n$p$-irregular weight one point.",
    "pdf_url": "http://arxiv.org/pdf/2502.00876v1",
    "published": "2025-02-02T19:00:56+00:00",
    "categories": [
      "math.NT",
      "11F33, 11G18 (Primary) 11F80, 11R23 (Secondary)"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00875v1",
    "title": "Characteristics of Femtosecond Laser Induced Filament and Energy Coupling by Nanosecond Laser Pulse in Air",
    "authors": [
      "Sagar Pokharel",
      "Albina Tropina"
    ],
    "abstract": "This study presents a detailed plasma kinetics model for laser-induced\nnon-equilibrium plasmas in atmospheric pressure air, incorporating a\nself-consistent energy balance and refined rate expressions within a\nthree-temperature framework. The model is validated against experimental data\nof femtosecond-laser-induced filaments, showing good agreement in electron\ndynamics and gas temperature. The analysis focuses on femtosecond filament\ndecay kinetics and characteristic properties across varying initial electron\ndensities and electron temperatures, including cases with oxygen addition and\nits influence on decay behavior. The study further examines energy coupling\nbetween the femtosecond filament and nanosecond laser pulse, identifying\ndominant kinetic pathways and optimal time delays through a comparative\nanalysis of single-pulse and dual-pulse plasmas. Additionally, results indicate\nthat temporal shaping of the nanosecond laser pulse intensity enhances\ndual-pulse performance relative to Gaussian pulses.",
    "pdf_url": "http://arxiv.org/pdf/2502.00875v1",
    "published": "2025-02-02T19:00:44+00:00",
    "categories": [
      "physics.plasm-ph",
      "physics.app-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00874v2",
    "title": "Paper Copilot Position: The Artificial Intelligence and Machine Learning Community Should Adopt a More Transparent and Regulated Peer Review Process",
    "authors": [
      "Jing Yang"
    ],
    "abstract": "The rapid growth of submissions to top-tier Artificial Intelligence (AI) and\nMachine Learning (ML) conferences has prompted many venues to transition from\nclosed to open review platforms. Some have fully embraced open peer reviews,\nallowing public visibility throughout the process, while others adopt hybrid\napproaches, such as releasing reviews only after final decisions or keeping\nreviews private despite using open peer review systems. In this work, we\nanalyze the strengths and limitations of these models, highlighting the growing\ncommunity interest in transparent peer review. To support this discussion, we\nexamine insights from Paper Copilot, a website launched two years ago to\naggregate and analyze AI / ML conference data while engaging a global audience.\nThe site has attracted over 200,000 early-career researchers, particularly\nthose aged 18-34 from 177 countries, many of whom are actively engaged in the\npeer review process. Drawing on our findings, this position paper advocates for\na more transparent, open, and well-regulated peer review aiming to foster\ngreater community involvement and propel advancements in the field.",
    "pdf_url": "http://arxiv.org/pdf/2502.00874v2",
    "published": "2025-02-02T18:58:08+00:00",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00873v1",
    "title": "Language Models Use Trigonometry to Do Addition",
    "authors": [
      "Subhash Kantamneni",
      "Max Tegmark"
    ],
    "abstract": "Mathematical reasoning is an increasingly important indicator of large\nlanguage model (LLM) capabilities, yet we lack understanding of how LLMs\nprocess even simple mathematical tasks. To address this, we reverse engineer\nhow three mid-sized LLMs compute addition. We first discover that numbers are\nrepresented in these LLMs as a generalized helix, which is strongly causally\nimplicated for the tasks of addition and subtraction, and is also causally\nrelevant for integer division, multiplication, and modular arithmetic. We then\npropose that LLMs compute addition by manipulating this generalized helix using\nthe \"Clock\" algorithm: to solve $a+b$, the helices for $a$ and $b$ are\nmanipulated to produce the $a+b$ answer helix which is then read out to model\nlogits. We model influential MLP outputs, attention head outputs, and even\nindividual neuron preactivations with these helices and verify our\nunderstanding with causal interventions. By demonstrating that LLMs represent\nnumbers on a helix and manipulate this helix to perform addition, we present\nthe first representation-level explanation of an LLM's mathematical capability.",
    "pdf_url": "http://arxiv.org/pdf/2502.00873v1",
    "published": "2025-02-02T18:55:26+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00872v2",
    "title": "Representation Number of Word-Representable Split Graphs",
    "authors": [
      "Tithi Dwary",
      "Khyodeno Mozhui",
      "K. V. Krishna"
    ],
    "abstract": "A split graph is a graph whose vertex set can be partitioned into a clique\nand an independent set. The word-representability of split graphs was studied\nin a series of papers in the literature, and the class of word-representable\nsplit graphs was characterized through semi-transitive orientation.\nNonetheless, the representation number of this class of graphs is still not\nknown. In general, determining the representation number of a\nword-representable graph is an NP-complete problem. In this work, through an\nalgorithmic procedure, we show that the representation number of the class of\nword-representable split graphs is at most three. Further, we characterize the\nclass of word-representable split graphs as well as the class of split\ncomparability graphs which have representation number exactly three.",
    "pdf_url": "http://arxiv.org/pdf/2502.00872v2",
    "published": "2025-02-02T18:54:52+00:00",
    "categories": [
      "math.CO",
      "cs.DM"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00871v1",
    "title": "Modified Adaptive Tree-Structured Parzen Estimator for Hyperparameter Optimization",
    "authors": [
      "Szymon Sieradzki",
      "Jacek Mańdziuk"
    ],
    "abstract": "In this paper, we review hyperparameter optimization methods for machine\nlearning models, with a particular focus on the Adaptive Tree-Structured Parzen\nEstimator (ATPE) algorithm. We propose several modifications to ATPE and assess\ntheir efficacy on a diverse set of standard benchmark functions. Experimental\nresults demonstrate that the proposed modifications significantly improve the\neffectiveness of ATPE hyperparameter optimization on selected benchmarks, a\nfinding that holds practical relevance for their application in real-world\nmachine learning / optimization tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.00871v1",
    "published": "2025-02-02T18:45:28+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00870v1",
    "title": "FedHPD: Heterogeneous Federated Reinforcement Learning via Policy Distillation",
    "authors": [
      "Wenzheng Jiang",
      "Ji Wang",
      "Xiongtao Zhang",
      "Weidong Bao",
      "Cheston Tan",
      "Flint Xiaofeng Fan"
    ],
    "abstract": "Federated Reinforcement Learning (FedRL) improves sample efficiency while\npreserving privacy; however, most existing studies assume homogeneous agents,\nlimiting its applicability in real-world scenarios. This paper investigates\nFedRL in black-box settings with heterogeneous agents, where each agent employs\ndistinct policy networks and training configurations without disclosing their\ninternal details. Knowledge Distillation (KD) is a promising method for\nfacilitating knowledge sharing among heterogeneous models, but it faces\nchallenges related to the scarcity of public datasets and limitations in\nknowledge representation when applied to FedRL. To address these challenges, we\npropose Federated Heterogeneous Policy Distillation (FedHPD), which solves the\nproblem of heterogeneous FedRL by utilizing action probability distributions as\na medium for knowledge sharing. We provide a theoretical analysis of FedHPD's\nconvergence under standard assumptions. Extensive experiments corroborate that\nFedHPD shows significant improvements across various reinforcement learning\nbenchmark tasks, further validating our theoretical findings. Moreover,\nadditional experiments demonstrate that FedHPD operates effectively without the\nneed for an elaborate selection of public datasets.",
    "pdf_url": "http://arxiv.org/pdf/2502.00870v1",
    "published": "2025-02-02T18:44:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "I.2.11"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00869v2",
    "title": "STAF: Sinusoidal Trainable Activation Functions for Implicit Neural Representation",
    "authors": [
      "Alireza Morsali",
      "MohammadJavad Vaez",
      "Mohammadhossein Soltani",
      "Amirhossein Kazerouni",
      "Babak Taati",
      "Morteza Mohammad-Noori"
    ],
    "abstract": "Implicit Neural Representations (INRs) have emerged as a powerful framework\nfor modeling continuous signals. The spectral bias of ReLU-based networks is a\nwell-established limitation, restricting their ability to capture fine-grained\ndetails in target signals. While previous works have attempted to mitigate this\nissue through frequency-based encodings or architectural modifications, these\napproaches often introduce additional complexity and do not fully address the\nunderlying challenge of learning high-frequency components efficiently. We\nintroduce Sinusoidal Trainable Activation Functions (STAF), designed to\ndirectly tackle this limitation by enabling networks to adaptively learn and\nrepresent complex signals with higher precision and efficiency. STAF inherently\nmodulates its frequency components, allowing for self-adaptive spectral\nlearning. This capability significantly improves convergence speed and\nexpressivity, making STAF highly effective for both signal representations and\ninverse problems. Through extensive evaluations across a range of tasks,\nincluding signal representation (shape, image, audio) and inverse problems\n(super-resolution, denoising), as well as neural radiance fields (NeRF), we\ndemonstrate that STAF consistently outperforms state-of-the-art methods in\naccuracy and reconstruction fidelity. These results establish STAF as a robust\nsolution to spectral bias and the capacity--convergence tradeoff, with broad\napplicability in computer vision and graphics. Our codebase is publicly\naccessible at https://github.com/AlirezaMorsali/STAF.",
    "pdf_url": "http://arxiv.org/pdf/2502.00869v2",
    "published": "2025-02-02T18:29:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00868v1",
    "title": "Gorenstein analogues of a projectivity criterion over group algebras",
    "authors": [
      "Rudradip Biswas",
      "Dimitra-Dionysia Stergiopoulou"
    ],
    "abstract": "We formulate and answer Gorenstein projective, flat, and injective analogues\nof a classical projectivity question for group rings under some mild additional\nassumptions. Although the original question, that was proposed by Jang-Hyun Jo\nin 2007, was for integral group rings, in this article, we deal with more\ngeneral commutative base rings. We make use of the vast developments that have\nhappened in the field of Gorenstein homological algebra over group rings in\nrecent years, and we also improve and generalize several existing results from\nthis area along the way.",
    "pdf_url": "http://arxiv.org/pdf/2502.00868v1",
    "published": "2025-02-02T18:28:21+00:00",
    "categories": [
      "math.RA",
      "Primary: 20C07, Secondary: 18G05, 20K40"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00867v2",
    "title": "Partitions of an Eulerian Digraph into Circuits",
    "authors": [
      "Joshua Cooper",
      "Utku Okur"
    ],
    "abstract": "We investigate a cancellation property satisfied by a connected Eulerian\ndigraph $D$. Namely, unless $D$ is a single directed cycle, we have\n$\\sum_{k\\geq 1} (-1)^{k} f_k(D)=0$, where $f_k(D)$ is the number of partitions\nof Eulerian circuits of $D$ into $k$ circuits. This property is a consequence\nof the fact that the Martin polynomial of a digraph has no constant term. We\nprovide an alternative proof by employing Viennot's theory of Heaps of Pieces,\nand in particular, a bijection between closed trails of a digraph and heaps\nwith a unique maximal piece, which are also in bijection with unique sink\norientations of the intersection graphs $G_a$ of partitions $a$ of $E(D)$ into\ncycles. The argument considers the partition lattice of the edge set of a\ndigraph $D$, restricted to the join-semilattice $T(D)$ induced by elements\nwhose blocks are connected and Eulerian. The minimal elements of $T(D)$ are\nexactly the partitions of $D$ into cycles, and the up-set of a minimal element\n$a\\in T(D)$ is shown to be isomorphic to the bond lattice $L(G_a)$. Using tools\ndeveloped by Whitney and Rota, we perform M\\\"{o}bius inversion on $T(D)$ and\nobtain the claimed cancellation.\n  As a consequence of this alternative proof, we relate the Martin polynomial\nof a digraph directly to the chromatic polynomials of the intersection graphs\nof partitions of $D$ into cycles. Finally, we apply the cancellation property\nin order to deduce the classical Harary-Sachs Theorem for graphs of rank $2$\nfrom a hypergraph generalization thereof, remedying a gap in a previous proof\nof this.",
    "pdf_url": "http://arxiv.org/pdf/2502.00867v2",
    "published": "2025-02-02T18:27:46+00:00",
    "categories": [
      "math.CO",
      "05C45 (Primary) 05C20, 06A07, 05C65 (Secondary)"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00866v1",
    "title": "Modeling Filamentary Conduction in Reset Phase Change Memory Devices",
    "authors": [
      "Md Samzid Bin Hafiz",
      "Helena Silva",
      "Ali Gokirmak"
    ],
    "abstract": "We performed a computational analysis on percolation transport and filament\nformation in amorphous $Ge_2Sb_2Te_5$ (a-GST) using 2D finite-element\nmulti-physics simulations with 2 nm out-of-plane depth using an electric-field\nand temperature dependent electronic transport model with carrier activation\nenergies that vary locally around 0.3 eV and as a function of temperature. We\nobserve the snapback (threshold switching) behavior in the current-voltage\n(I-V) characteristics at ~50 MV/m electric field with 0.63 $\\mu$A current for\n300 K ambient temperature, where current collapses onto a single molten\nfilament with ~ 2 nm diameter, aligned with the electric field, and the device\nswitches from a high resistance state (108 $\\Omega$) to a low resistance state\n(103 $\\Omega$). Further increase in voltage across the device leads to widening\nof the molten filament. Snap-back current and electric field are strong\nfunctions of ambient temperature, ranging from ~ 0.53 $\\mu$A at 200 K to ~\n16.93 $\\mu$A at 800 K and ~ 85 MV/m at 150 K to 45 MV/m at 350 K, respectively.\nSnap-back electric-field decreases exponentially with increasing device length,\nconverging to ~ 38 MV/m for devices longer than 200 nm.",
    "pdf_url": "http://arxiv.org/pdf/2502.00866v1",
    "published": "2025-02-02T18:20:02+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.01694v2",
    "title": "Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of Search, RL and Distillation",
    "authors": [
      "Juno Kim",
      "Denny Wu",
      "Jason Lee",
      "Taiji Suzuki"
    ],
    "abstract": "A key paradigm to improve the reasoning capabilities of large language models\n(LLMs) is to allocate more inference-time compute to search against a verifier\nor reward model. This process can then be utilized to refine the pretrained\nmodel or distill its reasoning patterns into more efficient models. In this\npaper, we study inference-time compute by viewing chain-of-thought (CoT)\ngeneration as a metastable Markov process: easy reasoning steps (e.g.,\nalgebraic manipulations) form densely connected clusters, while hard reasoning\nsteps (e.g., applying a relevant theorem) create sparse, low-probability edges\nbetween clusters, leading to phase transitions at longer timescales. Under this\nframework, we prove that implementing a search protocol that rewards sparse\nedges improves CoT by decreasing the expected number of steps to reach\ndifferent clusters. In contrast, we establish a limit on reasoning capability\nwhen the model is restricted to local information of the pretrained graph. We\nalso show that the information gained by search can be utilized to obtain a\nbetter reasoning model: (1) the pretrained model can be directly finetuned to\nfavor sparse edges via policy gradient methods, and moreover (2) a compressed\nmetastable representation of the reasoning dynamics can be distilled into a\nsmaller, more efficient model.",
    "pdf_url": "http://arxiv.org/pdf/2502.01694v2",
    "published": "2025-02-02T18:19:14+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2503.04734v2",
    "title": "What can large language models do for sustainable food?",
    "authors": [
      "Anna T. Thomas",
      "Adam Yee",
      "Andrew Mayne",
      "Maya B. Mathur",
      "Dan Jurafsky",
      "Kristina Gligorić"
    ],
    "abstract": "Food systems are responsible for a third of human-caused greenhouse gas\nemissions. We investigate what Large Language Models (LLMs) can contribute to\nreducing the environmental impacts of food production. We define a typology of\ndesign and prediction tasks based on the sustainable food literature and\ncollaboration with domain experts, and evaluate six LLMs on four tasks in our\ntypology. For example, for a sustainable protein design task, food science\nexperts estimated that collaboration with an LLM can reduce time spent by 45%\non average, compared to 22% for collaboration with another expert human food\nscientist. However, for a sustainable menu design task, LLMs produce suboptimal\nsolutions when instructed to consider both human satisfaction and climate\nimpacts. We propose a general framework for integrating LLMs with combinatorial\noptimization to improve reasoning capabilities. Our approach decreases\nemissions of food choices by 79% in a hypothetical restaurant while maintaining\nparticipants' satisfaction with their set of choices. Our results demonstrate\nLLMs' potential, supported by optimization techniques, to accelerate\nsustainable food development and adoption.",
    "pdf_url": "http://arxiv.org/pdf/2503.04734v2",
    "published": "2025-02-02T18:12:16+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.00865v2",
    "title": "Predicting potentially abusive clauses in Chilean terms of services with natural language processing",
    "authors": [
      "Christoffer Loeffler",
      "Andrea Martínez Freile",
      "Tomás Rey Pizarro"
    ],
    "abstract": "This study addresses the growing concern of information asymmetry in consumer\ncontracts, exacerbated by the proliferation of online services with complex\nTerms of Service that are rarely even read. Even though research on automatic\nanalysis methods is conducted, the problem is aggravated by the general focus\non English-language Machine Learning approaches and on major jurisdictions,\nsuch as the European Union. We introduce a new methodology and a substantial\ndataset addressing this gap. We propose a novel annotation scheme with four\ncategories and a total of 20 classes, and apply it on 50 online Terms of\nService used in Chile. Our evaluation of transformer-based models highlights\nhow factors like language- and/or domain-specific pre-training, few-shot sample\nsize, and model architecture affect the detection and classification of\npotentially abusive clauses. Results show a large variability in performance\nfor the different tasks and models, with the highest macro-F1 scores for the\ndetection task ranging from 79% to 89% and micro-F1 scores up to 96%, while\nmacro-F1 scores for the classification task range from 60% to 70% and micro-F1\nscores from 64% to 80%. Notably, this is the first Spanish-language multi-label\nclassification dataset for legal clauses, applying Chilean law and offering a\ncomprehensive evaluation of Spanish-language models in the legal domain. Our\nwork lays the ground for future research in method development for rarely\nconsidered legal analysis and potentially leads to practical applications to\nsupport consumers in Chile and Latin America as a whole.",
    "pdf_url": "http://arxiv.org/pdf/2502.00865v2",
    "published": "2025-02-02T18:01:39+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00864v2",
    "title": "Prior selection for the precision parameter of Dirichlet Process Mixtures",
    "authors": [
      "Carlo Vicentini",
      "Ian Hyla Jermyn"
    ],
    "abstract": "Consider a Dirichlet process mixture model (DPM) with random precision\nparameter $\\alpha$, inducing $K_n$ clusters over $n$ observations through its\nlatent random partition. Our goal is to specify the prior distribution\n$p\\left(\\alpha\\mid\\boldsymbol{\\eta}\\right)$, including its fixed parameter\nvector $\\boldsymbol{\\eta}$, in a way that is meaningful.\n  Existing approaches can be broadly categorised into three groups. Those in\nthe first group depend on the sample size $n$, and often rely on the linkage\nbetween $p\\left(\\alpha\\mid\\boldsymbol{\\eta}\\right)$ and $p\\left(K_n\\right)$ to\ndraw conclusions on how to best choose $\\boldsymbol{\\eta}$ to reflect one's\nprior knowledge of $K_{n}$; we call them sample-size-dependent. Those in the\nsecond and third group consist instead of using quasi-degenerate or improper\npriors, respectively.\n  In this article, we show how all three methods have limitations, especially\nfor large $n$. Then we propose an alternative methodology which does not depend\non $K_n$ or on the size of the available sample, but rather on the relationship\nbetween the largest stick lengths in the stick-breaking construction of the\nDPM; and which reflects those prior beliefs in\n$p\\left(\\alpha\\mid\\boldsymbol{\\eta}\\right)$. We conclude with an example where\nexisting sample-size-dependent approaches fail, while our\nsample-size-independent approach continues to be feasible.",
    "pdf_url": "http://arxiv.org/pdf/2502.00864v2",
    "published": "2025-02-02T17:54:20+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.00863v1",
    "title": "Nonspherical oscillations of an encapsulated magnetic microbubble",
    "authors": [
      "Arun Krishna B. J.",
      "Ganesh Tamadapu"
    ],
    "abstract": "This paper presents a model for nonspherical oscillations of encapsulated\nbubbles coated with a polymer infused with magnetic particles, developed using\nmembrane theory for thin weakly magnetic membranes. According to this theory,\nonly the applied magnetic field significantly contributes to the Maxwell stress\nand membrane is under generalized plane stress. The study focuses on\naxisymmetric deformations of bubbles under symmetrically arranged magnetic\ncoils. Non-spherical oscillations of the bubble are restricted to the linear\nregime, with the second mode dominating within the pressure range of the\nstability region. The pressure-frequency stability region is computationally\ndetermined, and its variation with different material properties and applied\nmagnetic field is analyzed. The natural frequency of each mode is estimated\nusing boundary layer approximation. Time-series analysis of the second mode\namplitude reveals a significant oscillation amplitude relative to the bubble\nradius. Estimation using the model indicates that the interface magnetic\nsusceptibility and initial bubble radius enhance the amplitude of second-mode\noscillations. Computational findings suggest that the applied magnetic field\ndoes not influence the stability region for exponential stability.",
    "pdf_url": "http://arxiv.org/pdf/2502.00863v1",
    "published": "2025-02-02T17:51:58+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.00862v2",
    "title": "Antipodal self-duality of square fishnet graphs",
    "authors": [
      "Lance J. Dixon",
      "Claude Duhr"
    ],
    "abstract": "In strongly-deformed planar ${\\cal N}=4$ super-Yang-Mills theory, or fishnet\ntheory, a point-split single-trace correlation function of four dimension-$m$\nscalar operators is given by a single Feynman integral, which involves\nintegrating over locations of a $m\\times m$ grid of points. We show that for\nany integer $m$ this square fishnet graph is invariant under the combined\naction of a kinematic map and the antipode map of the Hopf algebra on multiple\npolylogarithms, i.e. it possesses an antipodal self-duality.",
    "pdf_url": "http://arxiv.org/pdf/2502.00862v2",
    "published": "2025-02-02T17:50:53+00:00",
    "categories": [
      "hep-th",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.00861v1",
    "title": "Multivariable Stochastic Newton-Based Extremum Seeking with Delays",
    "authors": [
      "Paulo Cesar Souza Silva",
      "Paulo Cesar Pellanda",
      "Tiago Roux Oliveira"
    ],
    "abstract": "This paper presents a Newton-based stochastic extremum-seeking control method\nfor real-time optimization in multi-input systems with distinct input delays.\nIt combines predictor-based feedback and Hessian inverse estimation via\nstochastic perturbations to enable delay compensation with user-defined\nconvergence rates. The method ensures exponential stability and convergence\nnear the unknown extremum, even under long delays. It extends to multi-input,\nsingle-output systems with cross-coupled channels. Stability is analyzed using\nbackstepping and infinite-dimensional averaging. Numerical simulations\ndemonstrate its effectiveness in handling time-delayed channels, showcasing\nboth the challenges and benefits of real-time optimization in distributed\nparameter settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.00861v1",
    "published": "2025-02-02T17:40:05+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00860v1",
    "title": "Completed Cycles Leaky Hurwitz Numbers",
    "authors": [
      "Davide Accadia",
      "Maksim Karev",
      "Danilo Lewański"
    ],
    "abstract": "We introduce $(r+1)$-completed cycles $k$-leaky Hurwitz numbers and prove\npiecewise polynomiality as well as establishing their chamber polynomiality\nstructure and their wall crossing formulae. For $k=0$ the results recover\nprevious results of Shadrin-Spitz-Zvonkine. The specialization for $r=1$\nrecovers Hurwitz numbers that are close to the ones studied by\nCavalieri-Markwig-Ranganathan and Cavalieri-Markwig-Schmitt. The ramifications\ndiffer by a lower order torus correction, natural from the Fock space\nperspective, not affecting the genus zero enumeration, nor the enumeration for\nleaky parameter values $k = \\pm 1$ in all genera.",
    "pdf_url": "http://arxiv.org/pdf/2502.00860v1",
    "published": "2025-02-02T17:29:51+00:00",
    "categories": [
      "math.CO",
      "math.AG",
      "14N35 (Primary) 14T99 (Secondary)"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.01693v3",
    "title": "Predicting Steady-State Behavior in Complex Networks with Graph Neural Networks",
    "authors": [
      "Priodyuti Pradhan",
      "Amit Reza"
    ],
    "abstract": "In complex systems, information propagation can be defined as diffused or\ndelocalized, weakly localized, and strongly localized. This study investigates\nthe application of graph neural network models to learn the behavior of a\nlinear dynamical system on networks. A graph convolution and attention-based\nneural network framework has been developed to identify the steady-state\nbehavior of the linear dynamical system. We reveal that our trained model\ndistinguishes the different states with high accuracy. Furthermore, we have\nevaluated model performance with real-world data. In addition, to understand\nthe explainability of our model, we provide an analytical derivation for the\nforward and backward propagation of our framework.",
    "pdf_url": "http://arxiv.org/pdf/2502.01693v3",
    "published": "2025-02-02T17:29:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "nlin.AO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.01692v5",
    "title": "Fast Direct: Query-Efficient Online Black-box Guidance for Diffusion-model Target Generation",
    "authors": [
      "Kim Yong Tan",
      "Yueming Lyu",
      "Ivor Tsang",
      "Yew-Soon Ong"
    ],
    "abstract": "Guided diffusion-model generation is a promising direction for customizing\nthe generation process of a pre-trained diffusion model to address specific\ndownstream tasks. Existing guided diffusion models either rely on training the\nguidance model with pre-collected datasets or require the objective functions\nto be differentiable. However, for most real-world tasks, offline datasets are\noften unavailable, and their objective functions are often not differentiable,\nsuch as image generation with human preferences, molecular generation for drug\ndiscovery, and material design. Thus, we need an $\\textbf{online}$ algorithm\ncapable of collecting data during runtime and supporting a $\\textbf{black-box}$\nobjective function. Moreover, the $\\textbf{query efficiency}$ of the algorithm\nis also critical because the objective evaluation of the query is often\nexpensive in real-world scenarios. In this work, we propose a novel and simple\nalgorithm, $\\textbf{Fast Direct}$, for query-efficient online black-box target\ngeneration. Our Fast Direct builds a pseudo-target on the data manifold to\nupdate the noise sequence of the diffusion model with a universal direction,\nwhich is promising to perform query-efficient guided generation. Extensive\nexperiments on twelve high-resolution ($\\small {1024 \\times 1024}$) image\ntarget generation tasks and six 3D-molecule target generation tasks show\n$\\textbf{6}\\times$ up to $\\textbf{10}\\times$ query efficiency improvement and\n$\\textbf{11}\\times$ up to $\\textbf{44}\\times$ query efficiency improvement,\nrespectively. Our implementation is publicly available at:\nhttps://github.com/kimyong95/guide-stable-diffusion/tree/fast-direct",
    "pdf_url": "http://arxiv.org/pdf/2502.01692v5",
    "published": "2025-02-02T17:21:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00859v2",
    "title": "FedRIR: Rethinking Information Representation in Federated Learning",
    "authors": [
      "Yongqiang Huang",
      "Zerui Shao",
      "Ziyuan Yang",
      "Zexin Lu",
      "Yi Zhang"
    ],
    "abstract": "Mobile and Web-of-Things (WoT) devices at the network edge generate vast\namounts of data for machine learning applications, yet privacy concerns hinder\ncentralized model training. Federated Learning (FL) allows clients (devices) to\ncollaboratively train a shared model coordinated by a central server without\ntransfer private data, but inherent statistical heterogeneity among clients\npresents challenges, often leading to a dilemma between clients' needs for\npersonalized local models and the server's goal of building a generalized\nglobal model. Existing FL methods typically prioritize either global\ngeneralization or local personalization, resulting in a trade-off between these\ntwo objectives and limiting the full potential of diverse client data. To\naddress this challenge, we propose a novel framework that simultaneously\nenhances global generalization and local personalization by Rethinking\nInformation Representation in the Federated learning process (FedRIR).\nSpecifically, we introduce Masked Client-Specific Learning (MCSL), which\nisolates and extracts fine-grained client-specific features tailored to each\nclient's unique data characteristics, thereby enhancing personalization.\nConcurrently, the Information Distillation Module (IDM) refines the global\nshared features by filtering out redundant client-specific information,\nresulting in a purer and more robust global representation that enhances\ngeneralization. By integrating the refined global features with the isolated\nclient-specific features, we construct enriched representations that\neffectively capture both global patterns and local nuances, thereby improving\nthe performance of downstream tasks on the client. The code is available at\nhttps://github.com/Deep-Imaging-Group/FedRIR.",
    "pdf_url": "http://arxiv.org/pdf/2502.00859v2",
    "published": "2025-02-02T17:17:29+00:00",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00858v3",
    "title": "Learning to Plan with Personalized Preferences",
    "authors": [
      "Manjie Xu",
      "Xinyi Yang",
      "Wei Liang",
      "Chi Zhang",
      "Yixin Zhu"
    ],
    "abstract": "Effective integration of AI agents into daily life requires them to\nunderstand and adapt to individual human preferences, particularly in\ncollaborative roles. Although recent studies on embodied intelligence have\nadvanced significantly, they typically adopt generalized approaches that\noverlook personal preferences in planning. We address this limitation by\ndeveloping agents that not only learn preferences from few demonstrations but\nalso learn to adapt their planning strategies based on these preferences. Our\nresearch leverages the observation that preferences, though implicitly\nexpressed through minimal demonstrations, can generalize across diverse\nplanning scenarios. To systematically evaluate this hypothesis, we introduce\nPreference-based Planning (PbP) benchmark, an embodied benchmark featuring\nhundreds of diverse preferences spanning from atomic actions to complex\nsequences. Our evaluation of SOTA methods reveals that while symbol-based\napproaches show promise in scalability, significant challenges remain in\nlearning to generate and execute plans that satisfy personalized preferences.\nWe further demonstrate that incorporating learned preferences as intermediate\nrepresentations in planning significantly improves the agent's ability to\nconstruct personalized plans. These findings establish preferences as a\nvaluable abstraction layer for adaptive planning, opening new directions for\nresearch in preference-guided plan generation and execution.",
    "pdf_url": "http://arxiv.org/pdf/2502.00858v3",
    "published": "2025-02-02T17:16:25+00:00",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00857v1",
    "title": "HintEval: A Comprehensive Framework for Hint Generation and Evaluation for Questions",
    "authors": [
      "Jamshid Mozafari",
      "Bhawna Piryani",
      "Abdelrahman Abdallah",
      "Adam Jatowt"
    ],
    "abstract": "Large Language Models (LLMs) are transforming how people find information,\nand many users turn nowadays to chatbots to obtain answers to their questions.\nDespite the instant access to abundant information that LLMs offer, it is still\nimportant to promote critical thinking and problem-solving skills. Automatic\nhint generation is a new task that aims to support humans in answering\nquestions by themselves by creating hints that guide users toward answers\nwithout directly revealing them. In this context, hint evaluation focuses on\nmeasuring the quality of hints, helping to improve the hint generation\napproaches. However, resources for hint research are currently spanning\ndifferent formats and datasets, while the evaluation tools are missing or\nincompatible, making it hard for researchers to compare and test their models.\nTo overcome these challenges, we introduce HintEval, a Python library that\nmakes it easy to access diverse datasets and provides multiple approaches to\ngenerate and evaluate hints. HintEval aggregates the scattered resources into a\nsingle toolkit that supports a range of research goals and enables a clear,\nmulti-faceted, and reliable evaluation. The proposed library also includes\ndetailed online documentation, helping users quickly explore its features and\nget started. By reducing barriers to entry and encouraging consistent\nevaluation practices, HintEval offers a major step forward for facilitating\nhint generation and analysis research within the NLP/IR community.",
    "pdf_url": "http://arxiv.org/pdf/2502.00857v1",
    "published": "2025-02-02T17:07:18+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00856v4",
    "title": "Secondary spins of extreme mass ratio inspirals: A probe to the formation channels",
    "authors": [
      "Qiuxin Cui",
      "Wen-Biao Han",
      "Zhen Pan"
    ],
    "abstract": "Extreme mass-ratio inspirals (EMRIs), consisting of a secondary (stellar\nmass) black hole (BH) orbiting around a supermassive BH, are one of the primary\ntargets for future spaceborne gravitational wave (GW) detectors. The spin of\nthe secondary BH encodes the formation history of the stellar mass BH and the\nformation process of the EMRI. In this work, we construct a kludge EMRI\nwaveform model taking the secondary spin into account and preliminarily\nforecast the measurement precision of the secondary spin by future spaceborne\nGW detectors with the Fisher information matrix. We find the secondary spin\nmight be measured with reasonably good precision for generic eccentric and\ninclined EMRIs, with the caveat that the predictive precision may be\nconstrained by the model's inherent simplifications. As an example of its\nastrophysical applications, we propose that the secondary spin can be used for\ndistinguishing dry (loss cone) EMRIs (where the secondary BHs were born in the\ncollapse of individual massive stars and are of low spin) and Hills EMRIs\n(where the secondary BHs are remnants of massive star binaries and the\nsecondary spins follow a bimodal distribution).",
    "pdf_url": "http://arxiv.org/pdf/2502.00856v4",
    "published": "2025-02-02T17:05:50+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.00855v1",
    "title": "Psychometric-Based Evaluation for Theorem Proving with Large Language Models",
    "authors": [
      "Jianyu Zhang",
      "Yongwang Zhao",
      "Long Zhang",
      "Jilin Hu",
      "Xiaokun Luan",
      "Zhiwei Xu",
      "Feng Yang"
    ],
    "abstract": "Large language models (LLMs) for formal theorem proving have become a\nprominent research focus. At present, the proving ability of these LLMs is\nmainly evaluated through proof pass rates on datasets such as miniF2F. However,\nthis evaluation method overlooks the varying importance of theorems. As a\nresult, it fails to highlight the real performance disparities between LLMs and\nleads to high evaluation costs. This study proposes a psychometric-based\nevaluation method for theorem proving with LLMs, comprising two main\ncomponents: Dataset Annotation and Adaptive Evaluation. First, we propose a\nmetric calculation method to annotate the dataset with difficulty and\ndiscrimination metrics. Specifically, we annotate each theorem in the miniF2F\ndataset and grade them into varying difficulty levels according to the\nperformance of LLMs, resulting in an enhanced dataset: miniF2F-Graded.\nExperimental results show that the difficulty grading in miniF2F-Graded better\nreflects the theorem difficulty perceived by LLMs. Secondly, we design an\nadaptive evaluation method to dynamically select the most suitable theorems for\ntesting based on the annotated metrics and the real-time performance of LLMs.\nWe apply this method to evaluate 10 LLMs. The results show that our method\nfinely highlights the performance disparities between LLMs. It also reduces\nevaluation costs by using only 23% of the theorems in the dataset.",
    "pdf_url": "http://arxiv.org/pdf/2502.00855v1",
    "published": "2025-02-02T17:00:22+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00854v1",
    "title": "High-Dimensional Bayesian Optimization Using Both Random and Supervised Embeddings",
    "authors": [
      "Rémy Priem",
      "Youssef Diouane",
      "Nathalie Bartoli",
      "Sylvain Dubreuil",
      "Paul Saves"
    ],
    "abstract": "Bayesian optimization (BO) is one of the most powerful strategies to solve\ncomputationally expensive-to-evaluate blackbox optimization problems. However,\nBO methods are conventionally used for optimization problems of small dimension\nbecause of the curse of dimensionality. In this paper, a high-dimensionnal\noptimization method incorporating linear embedding subspaces of small dimension\nis proposed to efficiently perform the optimization. An adaptive learning\nstrategy for these linear embeddings is carried out in conjunction with the\noptimization. The resulting BO method, named efficient global optimization\ncoupled with random and supervised embedding (EGORSE), combines in an adaptive\nway both random and supervised linear embeddings. EGORSE has been compared to\nstate-of-the-art algorithms and tested on academic examples with a number of\ndesign variables ranging from 10 to 600. The obtained results show the high\npotential of EGORSE to solve high-dimensional blackbox optimization problems,\nin terms of both CPU time and the limited number of calls to the expensive\nblackbox simulation.",
    "pdf_url": "http://arxiv.org/pdf/2502.00854v1",
    "published": "2025-02-02T16:57:05+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.01691v1",
    "title": "Agent-Based Uncertainty Awareness Improves Automated Radiology Report Labeling with an Open-Source Large Language Model",
    "authors": [
      "Hadas Ben-Atya",
      "Naama Gavrielov",
      "Zvi Badash",
      "Gili Focht",
      "Ruth Cytter-Kuint",
      "Talar Hagopian",
      "Dan Turner",
      "Moti Freiman"
    ],
    "abstract": "Reliable extraction of structured data from radiology reports using Large\nLanguage Models (LLMs) remains challenging, especially for complex, non-English\ntexts like Hebrew. This study introduces an agent-based uncertainty-aware\napproach to improve the trustworthiness of LLM predictions in medical\napplications. We analyzed 9,683 Hebrew radiology reports from Crohn's disease\npatients (from 2010 to 2023) across three medical centers. A subset of 512\nreports was manually annotated for six gastrointestinal organs and 15\npathological findings, while the remaining reports were automatically annotated\nusing HSMP-BERT. Structured data extraction was performed using Llama 3.1\n(Llama 3-8b-instruct) with Bayesian Prompt Ensembles (BayesPE), which employed\nsix semantically equivalent prompts to estimate uncertainty. An Agent-Based\nDecision Model integrated multiple prompt outputs into five confidence levels\nfor calibrated uncertainty and was compared against three entropy-based models.\nPerformance was evaluated using accuracy, F1 score, precision, recall, and\nCohen's Kappa before and after filtering high-uncertainty cases. The\nagent-based model outperformed the baseline across all metrics, achieving an F1\nscore of 0.3967, recall of 0.6437, and Cohen's Kappa of 0.3006. After filtering\nhigh-uncertainty cases (greater than or equal to 0.5), the F1 score improved to\n0.4787, and Kappa increased to 0.4258. Uncertainty histograms demonstrated\nclear separation between correct and incorrect predictions, with the\nagent-based model providing the most well-calibrated uncertainty estimates. By\nincorporating uncertainty-aware prompt ensembles and an agent-based decision\nmodel, this approach enhances the performance and reliability of LLMs in\nstructured data extraction from radiology reports, offering a more\ninterpretable and trustworthy solution for high-stakes medical applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.01691v1",
    "published": "2025-02-02T16:57:03+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00853v1",
    "title": "Exploring Spatial Hybrid User Interface for Visual Sensemaking",
    "authors": [
      "Wai Tong",
      "Haobo Li",
      "Meng Xia",
      "Wong Kam-Kwai",
      "Ting-Chuen Pong",
      "Huamin Qu",
      "Yalong Yang"
    ],
    "abstract": "We built a spatial hybrid system that combines a personal computer (PC) and\nvirtual reality (VR) for visual sensemaking, addressing limitations in both\nenvironments. Although VR offers immense potential for interactive data\nvisualization (e.g., large display space and spatial navigation), it can also\npresent challenges such as imprecise interactions and user fatigue. At the same\ntime, a PC offers precise and familiar interactions but has limited display\nspace and interaction modality. Therefore, we iteratively designed a spatial\nhybrid system (PC+VR) to complement these two environments by enabling seamless\nswitching between PC and VR environments. To evaluate the system's\neffectiveness and user experience, we compared it to using a single computing\nenvironment (i.e., PC-only and VR-only). Our study results (N=18) showed that\nspatial PC+VR could combine the benefits of both devices to outperform user\npreference for VR-only without a negative impact on performance from device\nswitching overhead. Finally, we discussed future design implications.",
    "pdf_url": "http://arxiv.org/pdf/2502.00853v1",
    "published": "2025-02-02T16:55:57+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.01690v1",
    "title": "HuViDPO:Enhancing Video Generation through Direct Preference Optimization for Human-Centric Alignment",
    "authors": [
      "Lifan Jiang",
      "Boxi Wu",
      "Jiahui Zhang",
      "Xiaotong Guan",
      "Shuang Chen"
    ],
    "abstract": "With the rapid development of AIGC technology, significant progress has been\nmade in diffusion model-based technologies for text-to-image (T2I) and\ntext-to-video (T2V). In recent years, a few studies have introduced the\nstrategy of Direct Preference Optimization (DPO) into T2I tasks, significantly\nenhancing human preferences in generated images. However, existing T2V\ngeneration methods lack a well-formed pipeline with exact loss function to\nguide the alignment of generated videos with human preferences using DPO\nstrategies. Additionally, challenges such as the scarcity of paired video\npreference data hinder effective model training. At the same time, the lack of\ntraining datasets poses a risk of insufficient flexibility and poor video\ngeneration quality in the generated videos. Based on those problems, our work\nproposes three targeted solutions in sequence. 1) Our work is the first to\nintroduce the DPO strategy into the T2V tasks. By deriving a carefully\nstructured loss function, we utilize human feedback to align video generation\nwith human preferences. We refer to this new method as HuViDPO. 2) Our work\nconstructs small-scale human preference datasets for each action category and\nfine-tune this model, improving the aesthetic quality of the generated videos\nwhile reducing training costs. 3) We adopt a First-Frame-Conditioned strategy,\nleveraging the rich in formation from the first frame to guide the generation\nof subsequent frames, enhancing flexibility in video generation. At the same\ntime, we employ a SparseCausal Attention mechanism to enhance the quality of\nthe generated videos.More details and examples can be accessed on our website:\nhttps://tankowa.github.io/HuViDPO. github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2502.01690v1",
    "published": "2025-02-02T16:55:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00852v1",
    "title": "Cosmological super-resolution of the 21-cm signal",
    "authors": [
      "Simon Pochinda",
      "Jiten Dhandha",
      "Anastasia Fialkov",
      "Eloy de Lera Acedo"
    ],
    "abstract": "In this study, we train score-based diffusion models to super-resolve\ngigaparsec-scale cosmological simulations of the 21-cm signal. We examine the\nimpact of network and training dataset size on model performance, demonstrating\nthat a single simulation is sufficient for a model to learn the\nsuper-resolution task regardless of the initial conditions. Our best-performing\nmodel achieves pixelwise $\\mathrm{RMSE}\\sim0.57\\ \\mathrm{mK}$ and dimensionless\npower spectrum residuals ranging from $10^{-2}-10^{-1}\\ \\mathrm{mK^2}$ for\n$128^3$, $256^3$ and $512^3$ voxel simulation volumes at redshift $10$. The\nsuper-resolution network ultimately allows us to utilize all spatial scales\ncovered by the SKA1-Low instrument, and could in future be employed to help\nconstrain the astrophysics of the early Universe.",
    "pdf_url": "http://arxiv.org/pdf/2502.00852v1",
    "published": "2025-02-02T16:52:29+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00851v2",
    "title": "A More Precise Elbow Method for Optimum K-means Clustering",
    "authors": [
      "Indra Herdiana",
      "M Alfin Kamal",
      "Triyani",
      "Mutia Nur Estri",
      "Renny"
    ],
    "abstract": "K-means clustering is an unsupervised clustering method that requires an\ninitial decision of number of clusters. One method to determine the number of\nclusters is the elbow method, a heuristic method that relies on visual\nrepresentation. The method uses the number based on the elbow point, the point\nclosest to 90 degrees that indicates the most optimum number of clusters. This\nresearch improves the elbow method such that it becomes an objective method. We\nuse the analytical geometric formula to calculate an angle between lines and\nreal analysis principle of derivative to simplify the elbow point\ndetermination. We also consider every possibility of the elbow method graph\nbehaviour such that the algorithm is universally applicable. The result is that\nthe elbow point can be measured precisely with a simple algorithm that does not\ninvolve complex functions or calculations. This improved method gives an\nalternative of more reliable cluster determination method that contributes to\nmore optimum k-means clustering.",
    "pdf_url": "http://arxiv.org/pdf/2502.00851v2",
    "published": "2025-02-02T16:50:56+00:00",
    "categories": [
      "stat.ME",
      "91C20, 62-08, 62A09"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2503.02885v2",
    "title": "\"Would You Want an AI Tutor?\" Understanding Stakeholder Perceptions of LLM-based Systems in the Classroom",
    "authors": [
      "Caterina Fuligni",
      "Daniel Dominguez Figaredo",
      "Julia Stoyanovich"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) rapidly gained popularity\nacross all parts of society, including education. After initial skepticism and\nbans, many schools have chosen to embrace this new technology by integrating it\ninto their curricula in the form of virtual tutors and teaching assistants.\nHowever, neither the companies developing this technology nor the public\ninstitutions involved in its implementation have set up a formal system to\ncollect feedback from the stakeholders impacted by them. In this paper, we\nargue that understanding the perceptions of those directly or indirectly\nimpacted by LLMs in the classroom, including parents and school staff, is\nessential for ensuring responsible use of AI in this critical domain.\n  Our contributions are two-fold. First, we propose the Contextualized\nPerceptions for the Adoption of LLMs in Education (Co-PALE) framework, which\ncan be used to systematically elicit perceptions and inform whether and how\nLLM-based tools should be designed, developed, and deployed in the classroom.\nSecond, we explain how our framework can be used to ground specific rubrics for\neliciting perceptions of the relevant stakeholders in view of specific goals\nand context of implementation. Overall, Co-PALE is a practical step toward\nhelping educational agents, policymakers, researchers, and technologists ensure\nthe responsible and effective deployment of LLM-based systems across diverse\nlearning contexts.",
    "pdf_url": "http://arxiv.org/pdf/2503.02885v2",
    "published": "2025-02-02T16:50:08+00:00",
    "categories": [
      "cs.CY",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.00850v2",
    "title": "Dual Alignment Maximin Optimization for Offline Model-based RL",
    "authors": [
      "Chi Zhou",
      "Wang Luo",
      "Haoran Li",
      "Congying Han",
      "Tiande Guo",
      "Zicheng Zhang"
    ],
    "abstract": "Offline reinforcement learning agents face significant deployment challenges\ndue to the synthetic-to-real distribution mismatch. While most prior research\nhas focused on improving the fidelity of synthetic sampling and incorporating\noff-policy mechanisms, the directly integrated paradigm often fails to ensure\nconsistent policy behavior in biased models and underlying environmental\ndynamics, which inherently arise from discrepancies between behavior and\nlearning policies. In this paper, we first shift the focus from model\nreliability to policy discrepancies while optimizing for expected returns, and\nthen self-consistently incorporate synthetic data, deriving a novel\nactor-critic paradigm, Dual Alignment Maximin Optimization (DAMO). It is a\nunified framework to ensure both model-environment policy consistency and\nsynthetic and offline data compatibility. The inner minimization performs dual\nconservative value estimation, aligning policies and trajectories to avoid\nout-of-distribution states and actions, while the outer maximization ensures\nthat policy improvements remain consistent with inner value estimates.\nEmpirical evaluations demonstrate that DAMO effectively ensures model and\npolicy alignments, achieving competitive performance across diverse benchmark\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.00850v2",
    "published": "2025-02-02T16:47:35+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00849v4",
    "title": "Nonclassical dynamics of Néel vector and magnetization accompanied by THz and high-harmonic radiation from ultrafast-light-driven NiO antiferromagnet insulator",
    "authors": [
      "Federico Garcia-Gaitan",
      "Adrian E. Feiguin",
      "Branislav K. Nikolic"
    ],
    "abstract": "Ultrafast-light-driven strongly correlated antiferromagnetic insulators, such\nas prototypical NiO with large energy gap 4 eV, have recently attracted\nexperimental attention using either above-gap [K. Gillmeister et al., Nat.\nCommun. 11, 4095 (2020)] or subgap [H. Qiu et al., Nat. Phys. 17, 388 (2021)]\nenergy photons that are of fundamental interest in far-from-equilibrium quantum\nmatter or spintronic applications, respectively. In the latter context,\nemission of THz radiation is also observed from NiO/Pt bilayers, where heavy\nmetal (HM) Pt introduces strong spin-orbit coupling (SOC). However, microscopic\nmechanisms of such emission remain obscure because spintronic THz emitters have\nbeen amply studied using FM/HM (FM-ferromagnetic metal of conventional type)\nbilayers, where ultrafast demagnetization takes place and is directly related\nto THz emission. Conversely, in NiO total magnetization is zero prior to the fs\nlaser pulse (fsLP) application. Here we employ the two-orbital\nHubbard-Hund-Heisenberg model and study, via numerically exact nonequilibrium\nquantum many-body methods, the dynamics of its Neel vector and nonequilibrium\nmagnetization. Additionally, we compute electromagnetic radiation by both\ntime-dependent magnetization and local charge currents arising in either plain\nNiO or NiO with proximity SOC introduced by HM layer. Our analysis reveals\nnonclassical dynamics of Neel vector and nonequilibrium magnetization, changing\nonly in length while not rotating, where the former is substantially reduced\nonly in the case above-gap fsLP. In the plain NiO case, THz radiation of\ninterest to applications is insignificant, but adding SOC enhances both current\nand magnetic dipole contributions to it. Above THz range, we find integer\nhigh-harmonic generation, as well as unusual noninteger harmonics for above-gap\nfsLP pump.",
    "pdf_url": "http://arxiv.org/pdf/2502.00849v4",
    "published": "2025-02-02T16:44:50+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.00848v2",
    "title": "RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning",
    "authors": [
      "Yuanhuiyi Lyu",
      "Xu Zheng",
      "Lutao Jiang",
      "Yibo Yan",
      "Xin Zou",
      "Huiyu Zhou",
      "Linfeng Zhang",
      "Xuming Hu"
    ],
    "abstract": "Recent text-to-image generative models, e.g., Stable Diffusion V3 and Flux,\nhave achieved notable progress. However, these models are strongly restricted\nto their limited knowledge, a.k.a., their own fixed parameters, that are\ntrained with closed datasets. This leads to significant hallucinations or\ndistortions when facing fine-grained and unseen novel real-world objects, e.g.,\nthe appearance of the Tesla Cybertruck. To this end, we present the first\nreal-object-based retrieval-augmented generation framework (RealRAG), which\naugments fine-grained and unseen novel object generation by learning and\nretrieving real-world images to overcome the knowledge gaps of generative\nmodels. Specifically, to integrate missing memory for unseen novel object\ngeneration, we train a reflective retriever by self-reflective contrastive\nlearning, which injects the generator's knowledge into the sef-reflective\nnegatives, ensuring that the retrieved augmented images compensate for the\nmodel's missing knowledge. Furthermore, the real-object-based framework\nintegrates fine-grained visual knowledge for the generative models, tackling\nthe distortion problem and improving the realism for fine-grained object\ngeneration. Our Real-RAG is superior in its modular application to all types of\nstate-of-the-art text-to-image generative models and also delivers remarkable\nperformance boosts with all of them, such as a gain of 16.18% FID score with\nthe auto-regressive model on the Stanford Car benchmark.",
    "pdf_url": "http://arxiv.org/pdf/2502.00848v2",
    "published": "2025-02-02T16:41:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00847v1",
    "title": "SecPE: Secure Prompt Ensembling for Private and Robust Large Language Models",
    "authors": [
      "Jiawen Zhang",
      "Kejia Chen",
      "Zunlei Feng",
      "Jian Lou",
      "Mingli Song",
      "Jian Liu",
      "Xiaohu Yang"
    ],
    "abstract": "With the growing popularity of LLMs among the general public users,\nprivacy-preserving and adversarial robustness have become two pressing demands\nfor LLM-based services, which have largely been pursued separately but rarely\njointly. In this paper, to the best of our knowledge, we are among the first\nattempts towards robust and private LLM inference by tightly integrating two\ndisconnected fields: private inference and prompt ensembling. The former\nprotects users' privacy by encrypting inference data transmitted and processed\nby LLMs, while the latter enhances adversarial robustness by yielding an\naggregated output from multiple prompted LLM responses. Although widely\nrecognized as effective individually, private inference for prompt ensembling\ntogether entails new challenges that render the naive combination of existing\ntechniques inefficient. To overcome the hurdles, we propose SecPE, which\ndesigns efficient fully homomorphic encryption (FHE) counterparts for the core\nalgorithmic building blocks of prompt ensembling. We conduct extensive\nexperiments on 8 tasks to evaluate the accuracy, robustness, and efficiency of\nSecPE. The results show that SecPE maintains high clean accuracy and offers\nbetter robustness at the expense of merely $2.5\\%$ efficiency overhead compared\nto baseline private inference methods, indicating a satisfactory\n``accuracy-robustness-efficiency'' tradeoff. For the efficiency of the\nencrypted Argmax operation that incurs major slowdown for prompt ensembling,\nSecPE is 35.4x faster than the state-of-the-art peers, which can be of\nindependent interest beyond this work.",
    "pdf_url": "http://arxiv.org/pdf/2502.00847v1",
    "published": "2025-02-02T16:40:21+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00846v3",
    "title": "Federated Generalised Variational Inference: A Robust Probabilistic Federated Learning Framework",
    "authors": [
      "Terje Mildner",
      "Oliver Hamelijnck",
      "Paris Giampouras",
      "Theodoros Damoulas"
    ],
    "abstract": "We introduce FedGVI, a probabilistic Federated Learning (FL) framework that\nis robust to both prior and likelihood misspecification. FedGVI addresses\nlimitations in both frequentist and Bayesian FL by providing unbiased\npredictions under model misspecification, with calibrated uncertainty\nquantification. Our approach generalises previous FL approaches, specifically\nPartitioned Variational Inference (Ashman et al., 2022), by allowing robust and\nconjugate updates, decreasing computational complexity at the clients. We offer\ntheoretical analysis in terms of fixed-point convergence, optimality of the\ncavity distribution, and provable robustness to likelihood misspecification.\nFurther, we empirically demonstrate the effectiveness of FedGVI in terms of\nimproved robustness and predictive performance on multiple synthetic and real\nworld classification data sets.",
    "pdf_url": "http://arxiv.org/pdf/2502.00846v3",
    "published": "2025-02-02T16:39:37+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00845v1",
    "title": "Counting Imaginary Quadratic Fields with an Ideal Class Group of 5-rank at least 2",
    "authors": [
      "Kollin Bartz",
      "Aaron Levin",
      "Aman Dhruva Thamminana"
    ],
    "abstract": "We prove that there are $\\gg\\frac{X^{\\frac{1}{3}}}{(\\log X)^2}$ imaginary\nquadratic fields $k$ with discriminant $|d_k|\\leq X$ and an ideal class group\nof $5$-rank at least $2$. This improves a result of Byeon, who proved the lower\nbound $\\gg X^{\\frac{1}{4}}$ in the same setting. We use a method of Howe,\nLepr\\'{e}vost, and Poonen to construct a genus $2$ curve $C$ over $\\mathbb{Q}$\nsuch that $C$ has a rational Weierstrass point and the Jacobian of $C$ has a\nrational torsion subgroup of $5$-rank $2$. We deduce the main result from the\nexistence of the curve $C$ and a quantitative result of Kulkarni and the second\nauthor.",
    "pdf_url": "http://arxiv.org/pdf/2502.00845v1",
    "published": "2025-02-02T16:34:19+00:00",
    "categories": [
      "math.NT",
      "11R29, 11R11"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00844v1",
    "title": "A $χ^2$ statistic for the identification of strongly lensed gravitational waves from compact binary coalescences",
    "authors": [
      "Sudhir Gholap",
      "Kanchan Soni",
      "Shasvath J. Kapadia",
      "Sanjeev Dhurandhar"
    ],
    "abstract": "Gravitational waves (GWs) emanated by stellar mass compact binary\ncoalescences (CBCs), and lensed by galaxy- or cluster-scale lenses, will\nproduce two or more copies of the GW signal. These will have identical phase\nevolution but differing amplitudes. Such lensing signatures are expected to be\ndetected by the end of the LIGO-Virgo-Kagra's (LVK's) fifth observing run (O5).\nIn this work, we propose a novel $\\chi_{\\mathrm{lens}}^2$ statistic to\nsegregate pairs of detected GW events as either lensed or unlensed, using\ntemplates typically used in GW searches. The statistic is an application of the\ngeneralized $\\chi^2$ discriminator described in \\citet{dhurandhar2017},\ntailored to probe the similarity (or lack thereof) between the phase evolutions\nof two CBC signals. We assess the performance of $\\chi_{\\mathrm{lens}}^2$ on a\nrealistic astrophysical dataset of lensed and unlensed CBCs detectable in O4,\nassuming a single LIGO-like detector at design sensitivity. We find that we can\ncorrectly identify lensed events with efficiencies comparable to existing\nBayesian and machine learning methods. Evaluating $\\chi_{\\mathrm{lens}}^2$ is\norders of magnitude faster than Bayesian methods. Moreover, the statistics of\n$\\chi_{\\mathrm{lens}}^2$, in stationary Gaussian noise, are fully understood,\nin contrast to machine learning methods. $\\chi_{\\mathrm{lens}}^2$ can,\ntherefore, be used to rapidly and accurately weed out the vast majority of\nunlensed candidate pairs and identify lensed pairs.",
    "pdf_url": "http://arxiv.org/pdf/2502.00844v1",
    "published": "2025-02-02T16:32:58+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.HE",
      "astro-ph.IM"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.00843v1",
    "title": "VLM-Assisted Continual learning for Visual Question Answering in Self-Driving",
    "authors": [
      "Yuxin Lin",
      "Mengshi Qi",
      "Liang Liu",
      "Huadong Ma"
    ],
    "abstract": "In this paper, we propose a novel approach for solving the Visual Question\nAnswering (VQA) task in autonomous driving by integrating Vision-Language\nModels (VLMs) with continual learning. In autonomous driving, VQA plays a vital\nrole in enabling the system to understand and reason about its surroundings.\nHowever, traditional models often struggle with catastrophic forgetting when\nsequentially exposed to new driving tasks, such as perception, prediction, and\nplanning, each requiring different forms of knowledge. To address this\nchallenge, we present a novel continual learning framework that combines VLMs\nwith selective memory replay and knowledge distillation, reinforced by\ntask-specific projection layer regularization. The knowledge distillation\nallows a previously trained model to act as a \"teacher\" to guide the model\nthrough subsequent tasks, minimizing forgetting. Meanwhile, task-specific\nprojection layers calculate the loss based on the divergence of feature\nrepresentations, ensuring continuity in learning and reducing the shift between\ntasks. Evaluated on the DriveLM dataset, our framework shows substantial\nperformance improvements, with gains ranging from 21.40% to 32.28% across\nvarious metrics. These results highlight the effectiveness of combining\ncontinual learning with VLMs in enhancing the resilience and reliability of VQA\nsystems in autonomous driving. We will release our source code.",
    "pdf_url": "http://arxiv.org/pdf/2502.00843v1",
    "published": "2025-02-02T16:27:44+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00842v1",
    "title": "Adiabatic Index in Fluid Models of Collisionless Black Hole Accretion",
    "authors": [
      "Charles F. Gammie"
    ],
    "abstract": "Models of highly sub-Eddington accretion onto black holes commonly use a\nsingle fluid model for the collisionless, near-horizon plasma. These models\nmust specify an equation of state. It is common to use an ideal gas with $p =\n(\\gamma - 1) u$ and $\\gamma = 4/3, 13/9,$ or $5/3$, but these produce\nsignificantly different outcomes. We discuss the origins of this discrepancy\nand the assumptions underlying the single fluid model. The main result of this\ninvestigation is that under conditions relevant to low luminosity black hole\naccretion the best choice of single fluid adiabatic index is close to but\nslightly less than $5/3$. Along the way we provide a simple equilibrium model\nfor the relation between the ion-to-electron dissipation ratio and the ion to\nelectron temperature ratio and explore the implications for electron\ntemperature fluctuations in Event Horizon Telescope sources.",
    "pdf_url": "http://arxiv.org/pdf/2502.00842v1",
    "published": "2025-02-02T16:26:47+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.00841v1",
    "title": "Polynomial Time Learning-Augmented Algorithms for NP-hard Permutation Problems",
    "authors": [
      "Evripidis Bampis",
      "Bruno Escoffier",
      "Dimitris Fotakis",
      "Panagiotis Patsilinakos",
      "Michalis Xefteris"
    ],
    "abstract": "We consider a learning-augmented framework for NP-hard permutation problems.\nThe algorithm has access to predictions telling, given a pair $u,v$ of\nelements, whether $u$ is before $v$ or not in an optimal solution. Building on\nthe work of Braverman and Mossel (SODA 2008), we show that for a class of\noptimization problems including scheduling, network design and other graph\npermutation problems, these predictions allow to solve them in polynomial time\nwith high probability, provided that predictions are true with probability at\nleast $1/2+\\epsilon$. Moreover, this can be achieved with a parsimonious access\nto the predictions.",
    "pdf_url": "http://arxiv.org/pdf/2502.00841v1",
    "published": "2025-02-02T16:26:23+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.00840v2",
    "title": "Activation Approximations Can Incur Safety Vulnerabilities Even in Aligned LLMs: Comprehensive Analysis and Defense",
    "authors": [
      "Jiawen Zhang",
      "Kejia Chen",
      "Lipeng He",
      "Jian Lou",
      "Dan Li",
      "Zunlei Feng",
      "Mingli Song",
      "Jian Liu",
      "Kui Ren",
      "Xiaohu Yang"
    ],
    "abstract": "Large Language Models (LLMs) have showcased remarkable capabilities across\nvarious domains. Accompanying the evolving capabilities and expanding\ndeployment scenarios of LLMs, their deployment challenges escalate due to their\nsheer scale and the advanced yet complex activation designs prevalent in\nnotable model series, such as Llama, Gemma, Mistral. These challenges have\nbecome particularly pronounced in resource-constrained deployment scenarios,\nwhere mitigating inference bottlenecks is imperative. Among various recent\nefforts, activation approximation has emerged as a promising avenue for\npursuing inference efficiency, sometimes considered indispensable in\napplications such as private inference. Despite achieving substantial speedups\nwith minimal impact on utility, even appearing sound and practical for\nreal-world deployment, the safety implications of activation approximations\nremain unclear. In this work, we fill this critical gap in LLM safety by\nconducting the first systematic safety evaluation of activation approximations.\nOur safety vetting spans seven state-of-the-art techniques across three popular\ncategories (activation polynomialization, activation sparsification, and\nactivation quantization), revealing consistent safety degradation across ten\nsafety-aligned LLMs. To overcome the hurdle of devising a unified defense\naccounting for diverse activation approximation methods, we perform an in-depth\nanalysis of their shared error patterns and uncover three key findings. We\npropose QuadA, a novel safety enhancement method tailored to mitigate the\nsafety compromises introduced by activation approximations. Extensive\nexperiments and ablation studies corroborate QuadA's effectiveness in enhancing\nthe safety capabilities of LLMs after activation approximations.",
    "pdf_url": "http://arxiv.org/pdf/2502.00840v2",
    "published": "2025-02-02T16:25:48+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00839v1",
    "title": "Integrated plasmo-photonic sensor with voltage controled detection",
    "authors": [
      "Jacek Gosciniak",
      "Ryszard Piramidowicz"
    ],
    "abstract": "In this paper, we propose and analyze a waveguide-integrated interferometric\nsensor in which interference occurs between two plasmonic modes propagating in\na single plasmonic waveguide. For the purpose of sensing, the vertical\nplasmonic slot waveguide was rearranged by increasing the distance between the\nmetal electrodes. Consequently, the plasmonic modes associated with each metal\nelectrode have been separated, enabling them to propagate independently on\nopposing edges of metal electrodes what allows for the implementation of a\nMach-Zehnder interferometer. The metal electrodes that support the plasmonic\nmodes can also function as electrical contacts. By applying a DC voltage\nbetween them, it is possible to efficiently separate ions that drift to one of\nthe metal electrodes. Consequently, any change in a transmission from the\ninterferometer refers only to the amount of ions in a liquid as the output\nsignal from the interferometer is normalized to a liquid by the reference arm\nwhich is in direct contact with the examined liquid solution. The total amount\nof ions in the examined liquid remains constant, however, what changes is their\ndistribution in the gap as the ions drift toward one of the metal electrodes\nwhen a voltage is applied. The proposed configuration is highly sensitive to\nvariations in transmission between the two arms of the interferometer, enabling\na record sensitivity of over 12460 nm/RIU, even at the telecom wavelength of\n1550 nm. A further enhancement in sensitivity is expected in the mid-infrared\nwavelengths, which correspond to the maximum absorption peaks of most chemical\nand biological compounds.",
    "pdf_url": "http://arxiv.org/pdf/2502.00839v1",
    "published": "2025-02-02T16:22:27+00:00",
    "categories": [
      "physics.optics",
      "physics.chem-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.00838v1",
    "title": "System Architecture Optimization Strategies: Dealing with Expensive Hierarchical Problems",
    "authors": [
      "Jasper H. Bussemaker",
      "Paul Saves",
      "Nathalie Bartoli",
      "Thierry Lefebvre",
      "Rémi Lafage"
    ],
    "abstract": "Choosing the right system architecture for the problem at hand is challenging\ndue to the large design space and high uncertainty in the early stage of the\ndesign process. Formulating the architecting process as an optimization problem\nmay mitigate some of these challenges. This work investigates strategies for\nsolving System Architecture Optimization (SAO) problems: expensive, black-box,\nhierarchical, mixed-discrete, constrained, multi-objective problems that may be\nsubject to hidden constraints. Imputation ratio, correction ratio, correction\nfraction, and max rate diversity metrics are defined for characterizing hierar\nchical design spaces. This work considers two classes of optimization\nalgorithms for SAO: Multi-Objective Evolutionary Algorithms (MOEA) such as\nNSGA-II, and Bayesian Optimization (BO) algorithms. A new Gaussian process\nkernel is presented that enables modeling hierarchical categorical variables,\nextending previous work on modeling continuous and integer hierarchical\nvariables. Next, a hierarchical sampling algorithm that uses design space\nhierarchy to group design vectors by active design variables is developed.\nThen, it is demonstrated that integrating more hierarchy information in the\noptimization algorithms yields better optimization results for BO algorithms.\nSeveral realistic single-objective and multi-objective test problems are used\nfor investigations. Finally, the BO algorithm is applied to a jet engine\narchitecture optimization problem. This work shows that the developed BO\nalgorithm can effectively solve the problem with one order of magnitude less\nfunction evaluations than NSGA-II. The algorithms and problems used in this\nwork are implemented in the open-source Python library SBArchOpt.",
    "pdf_url": "http://arxiv.org/pdf/2502.00838v1",
    "published": "2025-02-02T16:19:20+00:00",
    "categories": [
      "math.OC",
      "cs.DM",
      "stat.AP"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00837v2",
    "title": "Explainability in Practice: A Survey of Explainable NLP Across Various Domains",
    "authors": [
      "Hadi Mohammadi",
      "Ayoub Bagheri",
      "Anastasia Giachanou",
      "Daniel L. Oberski"
    ],
    "abstract": "Natural Language Processing (NLP) has become a cornerstone in many critical\nsectors, including healthcare, finance, and customer relationship management.\nThis is especially true with the development and use of advanced models such as\nGPT-based architectures and BERT, which are widely used in decision-making\nprocesses. However, the black-box nature of these advanced NLP models has\ncreated an urgent need for transparency and explainability. This review\nexplores explainable NLP (XNLP) with a focus on its practical deployment and\nreal-world applications, examining its implementation and the challenges faced\nin domain-specific contexts. The paper underscores the importance of\nexplainability in NLP and provides a comprehensive perspective on how XNLP can\nbe designed to meet the unique demands of various sectors, from healthcare's\nneed for clear insights to finance's emphasis on fraud detection and risk\nassessment. Additionally, this review aims to bridge the knowledge gap in XNLP\nliterature by offering a domain-specific exploration and discussing\nunderrepresented areas such as real-world applicability, metric evaluation, and\nthe role of human interaction in model assessment. The paper concludes by\nsuggesting future research directions that could enhance the understanding and\nbroader application of XNLP.",
    "pdf_url": "http://arxiv.org/pdf/2502.00837v2",
    "published": "2025-02-02T16:18:44+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00836v1",
    "title": "Doped resonating valence bond states: How robust are the spin ice phases in 3D Rydberg arrays",
    "authors": [
      "Jingya Wang",
      "Changle Liu",
      "Yan-Cheng Wang",
      "Zheng Yan"
    ],
    "abstract": "Rydberg blockade effect provides a convenient platform for simulating locally\nconstrained many-body systems, such as quantum dimer models and quantum loop\nmodels, especially their novel phases like topological orders and gapless\nquantum spin ice (QSI) phases. To discuss the possible phase diagram containing\ndifferent QSIs in 3D Rydberg arrays, here, we have constructed an extended\nRokhsar-Kivelson (RK) Hamiltonian with equal-weight-superposition ground state\nin different fillings at the RK point. Therefore, both the perfect QSIs with\nfixed local dimer filling and their monomer-doped states can be simulated\ndirectly by Monte Carlo sampling. Using single mode approximation, the\nexcitations of dimers and monomers have also been explored in different\nfillings. We find that, in the thermodynamical limit, even doping a small\namount of monomers can disrupt the topological structure and lead to the\nexistence of off-diagonal long-range order. However, in a finite size (as in\ncold-atom experiment), the property of QSI will be kept in a certain region\nlike a crossover after doping. The phase diagram containing different QSIs and\noff-diagonal order phases is proposed.",
    "pdf_url": "http://arxiv.org/pdf/2502.00836v1",
    "published": "2025-02-02T16:18:35+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "cond-mat.stat-mech",
      "cond-mat.str-el",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2502.00835v2",
    "title": "CAIMAN: Causal Action Influence Detection for Sample-efficient Loco-manipulation",
    "authors": [
      "Yuanchen Yuan",
      "Jin Cheng",
      "Núria Armengol Urpí",
      "Stelian Coros"
    ],
    "abstract": "Enabling legged robots to perform non-prehensile loco-manipulation is crucial\nfor enhancing their versatility. Learning behaviors such as whole-body object\npushing often requires sophisticated planning strategies or extensive\ntask-specific reward shaping, especially in unstructured environments. In this\nwork, we present CAIMAN, a practical reinforcement learning framework that\nencourages the agent to gain control over other entities in the environment.\nCAIMAN leverages causal action influence as an intrinsic motivation objective,\nallowing legged robots to efficiently acquire object pushing skills even under\nsparse task rewards. We employ a hierarchical control strategy, combining a\nlow-level locomotion module with a high-level policy that generates\ntask-relevant velocity commands and is trained to maximize the intrinsic\nreward. To estimate causal action influence, we learn the dynamics of the\nenvironment by integrating a kinematic prior with data collected during\ntraining.We empirically demonstrate CAIMAN's superior sample efficiency and\nadaptability to diverse scenarios in simulation, as well as its successful\ntransfer to real-world systems without further fine-tuning.",
    "pdf_url": "http://arxiv.org/pdf/2502.00835v2",
    "published": "2025-02-02T16:16:53+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00834v1",
    "title": "Boosting Adversarial Robustness and Generalization with Structural Prior",
    "authors": [
      "Zhichao Hou",
      "Weizhi Gao",
      "Hamid Krim",
      "Xiaorui Liu"
    ],
    "abstract": "This work investigates a novel approach to boost adversarial robustness and\ngeneralization by incorporating structural prior into the design of deep\nlearning models. Specifically, our study surprisingly reveals that existing\ndictionary learning-inspired convolutional neural networks (CNNs) provide a\nfalse sense of security against adversarial attacks. To address this, we\npropose Elastic Dictionary Learning Networks (EDLNets), a novel ResNet\narchitecture that significantly enhances adversarial robustness and\ngeneralization. This novel and effective approach is supported by a theoretical\nrobustness analysis using influence functions. Moreover, extensive and reliable\nexperiments demonstrate consistent and significant performance improvement on\nopen robustness leaderboards such as RobustBench, surpassing state-of-the-art\nbaselines. To the best of our knowledge, this is the first work to discover and\nvalidate that structural prior can reliably enhance deep learning robustness\nunder strong adaptive attacks, unveiling a promising direction for future\nresearch.",
    "pdf_url": "http://arxiv.org/pdf/2502.00834v1",
    "published": "2025-02-02T16:15:10+00:00",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00833v2",
    "title": "Cross multiscale vision transformer for deep fake detection",
    "authors": [
      "Akhshan P",
      "Taneti Sanjay",
      "Chandrakala S"
    ],
    "abstract": "The proliferation of deep fake technology poses significant challenges to\ndigital media authenticity, necessitating robust detection mechanisms. This\nproject evaluates deep fake detection using the SP Cup's 2025 deep fake\ndetection challenge dataset. We focused on exploring various deep learning\nmodels for detecting deep fake content, utilizing traditional deep learning\ntechniques alongside newer architectures. Our approach involved training a\nseries of models and rigorously assessing their performance using metrics such\nas accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2502.00833v2",
    "published": "2025-02-02T16:09:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00832v1",
    "title": "Generalization of Medical Large Language Models through Cross-Domain Weak Supervision",
    "authors": [
      "Robert Long",
      "Eric Gonzalez",
      "Harrison Fuller"
    ],
    "abstract": "The advancement of large language models (LLMs) has opened new frontiers in\nnatural language processing, particularly in specialized domains like\nhealthcare. In this paper, we propose the Incremental Curriculum-Based\nFine-Tuning (ICFT) framework to enhance the generative capabilities of medical\nlarge language models (MLLMs). ICFT combines curriculum-based learning,\ndual-stage memory coordination, and parameter-efficient fine-tuning to enable a\nprogressive transition from general linguistic knowledge to strong\ndomain-specific expertise. Experimental results across diverse medical NLP\ntasks, including question answering, preference classification, and response\ngeneration, demonstrate that ICFT consistently outperforms state-of-the-art\nbaselines, achieving improvements in both accuracy and efficiency. Further\nanalysis reveals the framework's ability to generalize to unseen data, reduce\nerrors, and deliver diverse, contextually relevant medical responses. These\nfindings establish ICFT as a robust and scalable solution for adapting LLMs to\nthe medical domain, offering practical benefits for real-world healthcare\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2502.00832v1",
    "published": "2025-02-02T16:05:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00831v1",
    "title": "Closed-Loop Long-Term Experimental Molecular Communication System",
    "authors": [
      "Maike Scherer",
      "Lukas Brand",
      "Louis Wolf",
      "Teena tom Dieck",
      "Maximilian Schäfer",
      "Sebastian Lotter",
      "Andreas Burkovski",
      "Heinrich Sticht",
      "Robert Schober",
      "Kathrin Castiglione"
    ],
    "abstract": "We present a fluid-based experimental molecular communication (MC) testbed\nwhich uses media modulation. Motivated by the natural human cardiovascular\nsystem, the testbed operates in a closed-loop tube system. The proposed system\nis designed to be biocompatible, resource-efficient, and controllable from\noutside the tube. As signaling molecule, the testbed employs the green\nfluorescent protein variant \"Dreiklang\" (GFPD). GFPDs can be reversibly\nswitched via light of different wavelengths between a bright fluorescent state\nand a less fluorescent state. GFPDs in solution are filled into the testbed\nprior to the start of information transmission and remain there for an entire\nexperiment. For information transmission, an optical transmitter (TX) and an\noptical eraser (EX), which are located outside the tube, are used to write and\nerase the information encoded in the state of the GFPDs, respectively. At the\nreceiver (RX), the state of the GFPDs is read out by fluorescence detection. In\nour testbed, due to the closed-loop setup, we observe new forms of inter-symbol\ninterferences (ISI), which do not occur in short experiments and open-loop\nsystems. For the testbed, we developed a communication scheme, which includes\nblind transmission start detection, symbol-by-symbol synchronization, and\nadaptive threshold detection. We comprehensively analyze our MC experiments\nusing different performance metrics. Moreover, we experimentally demonstrate\nthe error-free transmission of 5370 bit at a data rate of 36 $\\textrm{bit}\\,\n\\textrm{min}^{\\boldsymbol{-1}}$ using 8-ary modulation and the error-free\nbinary transmission of around 90000 bit at a data rate of 12 $\\textrm{bit}\\,\n\\textrm{min}^{\\boldsymbol{-1}}$. For the latter experiment, data was\ntransmitted for a period of 125 hours. All signals recorded and parts of the\nevaluation code are publicly available on Zenodo and Github, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.00831v1",
    "published": "2025-02-02T16:01:55+00:00",
    "categories": [
      "cs.ET"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2502.00830v1",
    "title": "Magnetic-Field Dependence of Paramagnetic Properties Investigated by 63/65Cu-NMR on the Yb Zigzag-Chain Semiconductor YbCuS2",
    "authors": [
      "Fumiya Hori",
      "Shunsaku Kitagawa",
      "Kenji Ishida",
      "Yudai Ohmagari",
      "Takahiro Onimaru"
    ],
    "abstract": "To investigate the paramagnetic properties of YbCuS2 under magnetic fields,\nwe have performed the 63/65Cu-nuclear magnetic resonance (NMR) measurements.\nThe NMR spectra can be reproduced by the simulations of the three-dimensional\npowder pattern and the additional two-dimensional powder pattern, indicating\nthe partial sample orientation due to the anisotropy of the magnetic\nproperties. These simulations suggest that the ac plane is the easy plane in\nYbCuS2. The Knight shift K is proportional to the bulk magnetic susceptibility\nand field-independent. The broad maximum of the nuclear spin-lattice relaxation\nrate 1/T1 at Tmax ~ 50 K (50 K anomaly) observed at zero magnetic field is\nquickly suppressed by the magnetic fields. This indicates that the 50 K anomaly\nis field-dependent. Furthermore, an anomalous enhancement of 1/T1 at low\ntemperatures was observed above 3 T. This field seemingly corresponds to the\nmagnetic field at which a field-induced phase transition occurs below the\nantiferromagnetic transition temperature TN ~ 1 K. The changes in 1/T1 observed\nin the paramagnetic state suggest the presence of the complex quantum phenomena\nunder magnetic fields in YbCuS2.",
    "pdf_url": "http://arxiv.org/pdf/2502.00830v1",
    "published": "2025-02-02T16:01:46+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.00829v2",
    "title": "When Do LLMs Help With Node Classification? A Comprehensive Analysis",
    "authors": [
      "Xixi Wu",
      "Yifei Shen",
      "Fangzhou Ge",
      "Caihua Shan",
      "Yizhu Jiao",
      "Xiangguo Sun",
      "Hong Cheng"
    ],
    "abstract": "Node classification is a fundamental task in graph analysis, with broad\napplications across various fields. Recent breakthroughs in Large Language\nModels (LLMs) have enabled LLM-based approaches for this task. Although many\nstudies demonstrate the impressive performance of LLM-based methods, the lack\nof clear design guidelines may hinder their practical application. In this\nwork, we aim to establish such guidelines through a fair and systematic\ncomparison of these algorithms. As a first step, we developed LLMNodeBed, a\ncomprehensive codebase and testbed for node classification using LLMs. It\nincludes 10 homophilic datasets, 4 heterophilic datasets, 8 LLM-based\nalgorithms, 8 classic baselines, and 3 learning paradigms. Subsequently, we\nconducted extensive experiments, training and evaluating over 2,700 models, to\ndetermine the key settings (e.g., learning paradigms and homophily) and\ncomponents (e.g., model size and prompt) that affect performance. Our findings\nuncover 8 insights, e.g., (1) LLM-based methods can significantly outperform\ntraditional methods in a semi-supervised setting, while the advantage is\nmarginal in a supervised setting; (2) Graph Foundation Models can beat\nopen-source LLMs but still fall short of strong LLMs like GPT-4o in a zero-shot\nsetting. We hope that the release of LLMNodeBed, along with our insights, will\nfacilitate reproducible research and inspire future studies in this field.\nCodes and datasets are released at\n\\href{https://llmnodebed.github.io/}{\\texttt{https://llmnodebed.github.io/}}.",
    "pdf_url": "http://arxiv.org/pdf/2502.00829v2",
    "published": "2025-02-02T15:56:05+00:00",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00828v1",
    "title": "Decision-informed Neural Networks with Large Language Model Integration for Portfolio Optimization",
    "authors": [
      "Yoontae Hwang",
      "Yaxuan Kong",
      "Stefan Zohren",
      "Yongjae Lee"
    ],
    "abstract": "This paper addresses the critical disconnect between prediction and decision\nquality in portfolio optimization by integrating Large Language Models (LLMs)\nwith decision-focused learning. We demonstrate both theoretically and\nempirically that minimizing the prediction error alone leads to suboptimal\nportfolio decisions. We aim to exploit the representational power of LLMs for\ninvestment decisions. An attention mechanism processes asset relationships,\ntemporal dependencies, and macro variables, which are then directly integrated\ninto a portfolio optimization layer. This enables the model to capture complex\nmarket dynamics and align predictions with the decision objectives. Extensive\nexperiments on S\\&P100 and DOW30 datasets show that our model consistently\noutperforms state-of-the-art deep learning models. In addition, gradient-based\nanalyses show that our model prioritizes the assets most crucial to decision\nmaking, thus mitigating the effects of prediction errors on portfolio\nperformance. These findings underscore the value of integrating decision\nobjectives into predictions for more robust and context-aware portfolio\nmanagement.",
    "pdf_url": "http://arxiv.org/pdf/2502.00828v1",
    "published": "2025-02-02T15:45:21+00:00",
    "categories": [
      "q-fin.PM",
      "cs.AI",
      "q-fin.CP"
    ],
    "primary_category": "q-fin.PM"
  },
  {
    "id": "http://arxiv.org/abs/2502.00827v1",
    "title": "A new categorial equivalence for Stone Algebras",
    "authors": [
      "Ismael Calomino",
      "Gustavo Pelaitay"
    ],
    "abstract": "The aim of this paper is to give a categorical equivalence for Stone\nalgebras. We introduce the variety of Stone-Kleene algebras with intuitionistic\nnegation, or Stone KAN-algebras for short, and explore Kalman's construction\nfor Stone algebras. We examine the centered algebras within this new variety\nand prove that the category of Stone algebras is equivalent to the category of\ncentered Stone KAN-algebras. Moreover, inspired by Monteiro's construction for\nNelson algebras, we propose a method to construct a centered Stone KAN-algebra\nfrom a given Stone KAN-algebra and show the connection between Kalman's\nconstruction and Monteiro's construction.",
    "pdf_url": "http://arxiv.org/pdf/2502.00827v1",
    "published": "2025-02-02T15:44:27+00:00",
    "categories": [
      "math.LO"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2502.01689v1",
    "title": "scGSDR: Harnessing Gene Semantics for Single-Cell Pharmacological Profiling",
    "authors": [
      "Yu-An Huang",
      "Xiyue Cao",
      "Zhu-Hong You",
      "Yue-Chao Li",
      "Xuequn Shang",
      "Zhi-An Huang"
    ],
    "abstract": "The rise of single-cell sequencing technologies has revolutionized the\nexploration of drug resistance, revealing the crucial role of cellular\nheterogeneity in advancing precision medicine. By building computational models\nfrom existing single-cell drug response data, we can rapidly annotate cellular\nresponses to drugs in subsequent trials. To this end, we developed scGSDR, a\nmodel that integrates two computational pipelines grounded in the knowledge of\ncellular states and gene signaling pathways, both essential for understanding\nbiological gene semantics. scGSDR enhances predictive performance by\nincorporating gene semantics and employs an interpretability module to identify\nkey pathways contributing to drug resistance phenotypes. Our extensive\nvalidation, which included 16 experiments covering 11 drugs, demonstrates\nscGSDR's superior predictive accuracy, when trained with either bulk-seq or\nscRNA-seq data, achieving high AUROC, AUPR, and F1 Scores. The model's\napplication has extended from single-drug predictions to scenarios involving\ndrug combinations. Leveraging pathways of known drug target genes, we found\nthat scGSDR's cell-pathway attention scores are biologically interpretable,\nwhich helped us identify other potential drug-related genes. Literature review\nof top-ranking genes in our predictions such as BCL2, CCND1, the AKT family,\nand PIK3CA for PLX4720; and ICAM1, VCAM1, NFKB1, NFKBIA, and RAC1 for\nPaclitaxel confirmed their relevance. In conclusion, scGSDR, by incorporating\ngene semantics, enhances predictive modeling of cellular responses to diverse\ndrugs, proving invaluable for scenarios involving both single drug and\ncombination therapies and effectively identifying key resistance-related\npathways, thus advancing precision medicine and targeted therapy development.",
    "pdf_url": "http://arxiv.org/pdf/2502.01689v1",
    "published": "2025-02-02T15:43:20+00:00",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2502.00826v1",
    "title": "Weak Supervision Dynamic KL-Weighted Diffusion Models Guided by Large Language Models",
    "authors": [
      "Julian Perry",
      "Frank Sanders",
      "Carter Scott"
    ],
    "abstract": "In this paper, we presents a novel method for improving text-to-image\ngeneration by combining Large Language Models (LLMs) with diffusion models, a\nhybrid approach aimed at achieving both higher quality and efficiency in image\nsynthesis from text descriptions. Our approach introduces a new dynamic\nKL-weighting strategy to optimize the diffusion process, along with\nincorporating semantic understanding from pre-trained LLMs to guide the\ngeneration process. The proposed method significantly improves both the visual\nquality and alignment of generated images with text descriptions, addressing\nchallenges such as computational inefficiency, instability in training, and\nrobustness to textual variability. We evaluate our method on the COCO dataset\nand demonstrate its superior performance over traditional GAN-based models,\nboth quantitatively and qualitatively. Extensive experiments, including\nablation studies and human evaluations, confirm that our method outperforms\nexisting approaches in terms of image realism, relevance to the input text, and\noverall aesthetic quality. Our approach also shows promise in scalability to\nother multimodal tasks, making it a versatile solution for a wide range of\ngenerative applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.00826v1",
    "published": "2025-02-02T15:43:13+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00825v1",
    "title": "An overview of regularity results for the Laplacian and $p$-Laplacian in metric spaces",
    "authors": [
      "Ivan Yuri Violo"
    ],
    "abstract": "We review some regularity results for the Laplacian and $p$-Laplacian in\nmetric measure spaces. The focus is mainly on interior H\\\"older, Lipschitz and\nsecond-regularity estimates and on spaces supporting a Poincar\\'e inequality or\nhaving Ricci curvature bounded below.",
    "pdf_url": "http://arxiv.org/pdf/2502.00825v1",
    "published": "2025-02-02T15:43:10+00:00",
    "categories": [
      "math.AP",
      "math.MG",
      "35B65, 35J92, 46E36, 58J05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.00824v1",
    "title": "Direct Uplink Connectivity in Space MIMO Systems with THz and FSO Inter-Satellite Links",
    "authors": [
      "Zohre Mashayekh Bakhsh",
      "Yasaman Omid",
      "Gaojie Chen",
      "Farbod Kayhan",
      "Yi Ma",
      "Rahim Tafazolli"
    ],
    "abstract": "This paper investigates uplink transmission from a single-antenna mobile\nphone to a cluster of satellites, emphasizing the role of inter-satellite links\n(ISLs) in facilitating cooperative signal detection. The study focuses on\nnon-ideal ISLs, examining both terahertz (THz) and free-space optical (FSO)\nISLs concerning their ergodic capacity. We present a practical scenario derived\nfrom the recent 3GPP standard, specifying the frequency band, bandwidth, user\nand satellite antenna gains, power levels, and channel characteristics in\nalignment with the latest 3GPP for non-terrestrial networks (NTN).\nAdditionally, we propose a satellite selection method to identify the optimal\nsatellite as the master node (MN), responsible for signal processing. This\nmethod takes into account both the user-satellite link and ISL channels. For\nthe THz ISL analysis, we derive a closed-form approximation for ergodic\ncapacity under two scenarios: one with instantaneous channel state information\n(CSI) and another with only statistical CSI shared between satellites. For the\nFSO ISL analysis, we present a closed-form approximate upper bound for ergodic\ncapacity, accounting for the impact of pointing error loss. Furthermore, we\nevaluate the effects of different ISL frequencies and pointing errors on\nspectral efficiency. Simulation results demonstrate that multi-satellite\nmultiple-input multiple-output (MIMO) satellite communication (SatCom)\nsignificantly outperforms single-satellite SatCom in terms of spectral\nefficiency. Additionally, our approximated upper bound for ergodic capacity\nclosely aligns with results obtained from Monte Carlo simulations.",
    "pdf_url": "http://arxiv.org/pdf/2502.00824v1",
    "published": "2025-02-02T15:42:46+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.02609v1",
    "title": "On the Convergence of Strong Cylindrical and Spherical Shock Waves in Solid Materials",
    "authors": [
      "R. K. Anand"
    ],
    "abstract": "In this article, we present a description of the behaviour of\nshock-compressed solid materials following the Geometrical Shock Dynamics (GSD)\ntheory. GSD has been successfully applied to various gas dynamics problems, and\nhere we have employed it to investigate the propagation of cylindrically and\nspherically symmetric converging shock waves in solid materials. The analytical\nsolution of shock dynamics equations has been obtained in strong-shock limit,\nassuming the solid material to be homogeneous and isotropic and obeying the\nMie-Gruneisen equation of state. The non-dimensional expressions are obtained\nfor the velocity of shock, the pressure, the mass density, the particle\nvelocity, the temperature, the speed of sound, the adiabatic bulk modulus, and\nthe change-in-entropy behind the strong converging shock front. The influences\nas a result of changes in (i) the propagation distance r from the axis or\ncentre (r=0) of convergence, (ii) the Gruneisen parameter, and (iii) the\nmaterial parameter are explored on the shock velocity and the domain behind the\nconverging shock front. The results show that as the shock focuses at the axis\nor origin, the shock velocity, the pressure, the temperature, and the\nchange-in-entropy increase in the shock-compressed titanium Ti6Al4V, stainless\nsteel 304, aluminum 6061-T6, etc.",
    "pdf_url": "http://arxiv.org/pdf/2502.02609v1",
    "published": "2025-02-02T15:35:36+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "astro-ph.HE",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.00823v2",
    "title": "Online Learning of Pure States is as Hard as Mixed States",
    "authors": [
      "Maxime Meyer",
      "Soumik Adhikary",
      "Naixu Guo",
      "Patrick Rebentrost"
    ],
    "abstract": "Quantum state tomography, the task of learning an unknown quantum state, is a\nfundamental problem in quantum information. In standard settings, the\ncomplexity of this problem depends significantly on the type of quantum state\nthat one is trying to learn, with pure states being substantially easier to\nlearn than general mixed states. A natural question is whether this separation\nholds for any quantum state learning setting. In this work, we consider the\nonline learning framework and prove the surprising result that learning pure\nstates in this setting is as hard as learning mixed states. More specifically,\nwe show that both classes share almost the same sequential fat-shattering\ndimension, leading to identical regret scaling. We also generalize previous\nresults on full quantum state tomography in the online setting to (i) the\n$\\epsilon$-realizable setting and (ii) learning the density matrix only\npartially, using smoothed analysis.",
    "pdf_url": "http://arxiv.org/pdf/2502.00823v2",
    "published": "2025-02-02T15:27:14+00:00",
    "categories": [
      "quant-ph",
      "cs.LG",
      "81P18 (Primary) 68T05, 62L10 (Secondary)",
      "I.2.6"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00822v1",
    "title": "Detection of Ubiquitous Circumbinary Matter in Hot Subdwarfs Formed from Common-Envelope Ejections",
    "authors": [
      "Jiangdan Li",
      "Christian Wolf",
      "Jiao Li",
      "Yangping Luo",
      "Jingkun Zhao",
      "Bingqiu Chen",
      "Lin Zhang",
      "Shi Jia",
      "Xuefei Chen",
      "Zhanwen Han"
    ],
    "abstract": "The formation of compact binary systems is largely driven by their evolution\nthrough a common envelope (CE) phase, crucial for understanding phenomena such\nas type Ia supernovae and black hole mergers. Despite their importance, direct\nobservational evidence for CE material has been elusive due to the transient\nnature of these envelopes. Numerical simulations suggest that some envelope\nmaterial may persist post-ejection. In this study, we investigate circumstellar\nmaterial (CSM) surrounding hot subdwarf (sdB) stars, focusing on material\nejected during the CE phase of binary evolution. We analyze Ca II K absorption\nlines in 727 sdB candidates from the LAMOST-LRS survey, selecting 145 stars\nwith strong absorption features, indicating the presence of CSM. We compare the\nvelocities of the Ca II K lines with the systemic velocities of sdB binaries,\nconfirming that the material originates from ejected common-envelope material.\nThe results show that the CSM persists long after the CE event, suggesting the\nformation of a stable, long-lived circumstellar environment around sdB stars.\nThis study enhances our understanding of the role of CSM in post-CE evolution\nand provides new insights into the physical processes shaping the evolution of\nsdB binaries.",
    "pdf_url": "http://arxiv.org/pdf/2502.00822v1",
    "published": "2025-02-02T15:25:48+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00821v1",
    "title": "Can Q-balls describe cosmological and galactic dark matter?",
    "authors": [
      "Susobhan Mandal",
      "S. Shankaranarayanan"
    ],
    "abstract": "The Cold Dark Matter (CDM) hypothesis accurately predicts large-scale\nstructure formation and fits the Cosmic Microwave Background temperature\nfluctuations (CMB). However, observations of the inner regions of dark matter\nhalos and dwarf galaxy satellites have consistently posed challenges to CDM. On\nthe other hand, the Modified Newtonian Dynamics (MOND) hypothesis can explain\ngalactic phenomena but fails to account for the complex shape of the CMB and\nmatter power spectra. CDM and MOND are effective in nearly mutually exclusive\nregimes, prompting the question: Is there a physical mechanism where CDM and\nMOND share a common origin? Q-balls, which are localized, non-topological\nsolitons, can be a bridge between the two hypotheses. Q-balls formed in the\nearly Universe can mimic CDM at cosmological scales. Interestingly, Q-balls can\nexhibit MOND-like behavior in the late Universe at galactic scales, providing a\nunified framework. Specifically, we demonstrate that millicharged composite\nQ-balls formed from complex scalar fields, decoupled from the background\nradiation, can naturally arise during the radiation-dominated epoch. From the\nmatter-radiation equality, we also obtain the mass of Q-balls to be $1~{eV}$,\nwhich are much smaller than the electron mass. Using the constraints from the\ninvisible decay mode of ortho-positronium, we obtain $Q < 3.4 \\times 10^{-5}$.\nWe also establish an upper bound on the number density of Q-balls, which\ndepends on the charge of the Q-ball and the small initial charge asymmetry.\nFurthermore, we demonstrate that the MOND naturally emerges at the galactic\nscale within the framework of our Q-ball model.",
    "pdf_url": "http://arxiv.org/pdf/2502.00821v1",
    "published": "2025-02-02T15:25:33+00:00",
    "categories": [
      "hep-th",
      "astro-ph.CO",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.00820v1",
    "title": "OOD Detection with immature Models",
    "authors": [
      "Behrooz Montazeran",
      "Ullrich Köthe"
    ],
    "abstract": "Likelihood-based deep generative models (DGMs) have gained significant\nattention for their ability to approximate the distributions of\nhigh-dimensional data. However, these models lack a performance guarantee in\nassigning higher likelihood values to in-distribution (ID) inputs, data the\nmodels are trained on, compared to out-of-distribution (OOD) inputs. This\ncounter-intuitive behaviour is particularly pronounced when ID inputs are more\ncomplex than OOD data points. One potential approach to address this challenge\ninvolves leveraging the gradient of a data point with respect to the parameters\nof the DGMs. A recent OOD detection framework proposed estimating the joint\ndensity of layer-wise gradient norms for a given data point as a model-agnostic\nmethod, demonstrating superior performance compared to the Typicality Test\nacross likelihood-based DGMs and image dataset pairs. In particular, most\nexisting methods presuppose access to fully converged models, the training of\nwhich is both time-intensive and computationally demanding. In this work, we\ndemonstrate that using immature models,stopped at early stages of training, can\nmostly achieve equivalent or even superior results on this downstream task\ncompared to mature models capable of generating high-quality samples that\nclosely resemble ID data. This novel finding enhances our understanding of how\nDGMs learn the distribution of ID data and highlights the potential of\nleveraging partially trained models for downstream tasks. Furthermore, we offer\na possible explanation for this unexpected behaviour through the concept of\nsupport overlap.",
    "pdf_url": "http://arxiv.org/pdf/2502.00820v1",
    "published": "2025-02-02T15:14:17+00:00",
    "categories": [
      "cs.LG",
      "cs.CV",
      "53A45",
      "I.4.7; I.4.9"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00819v2",
    "title": "Kaon Modification in Pion Medium",
    "authors": [
      "Yu. B. Ivanov"
    ],
    "abstract": "Kaon properties in thermal pion-nucleon medium are studied. The dense\npion-nucleon medium is produced in high-energy heavy-ion collisions. The\nconsideration is based on the chiral nucleon-kaon-pion Lagrangian. It is found\nthat the pion medium does not produce a substantive contribution but enhances\nthe effect of the baryon matter. Numerical estimate shows that this enhancement\nfactor induced by the pion medium does not exceed 5% at the freeze-out stage of\nheavy-ion collisions, i.e. it is small. However, the impact of this enhancement\ncan be higher in actual nuclear collisions because the effect of the in-medium\n(anti)kaon modification is accumulated during the (anti)kaon evolution before\nthe freeze-out when the pion density is higher.",
    "pdf_url": "http://arxiv.org/pdf/2502.00819v2",
    "published": "2025-02-02T15:08:09+00:00",
    "categories": [
      "nucl-th",
      "hep-ph"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.00818v2",
    "title": "Error-quantified Conformal Inference for Time Series",
    "authors": [
      "Junxi Wu",
      "Dongjian Hu",
      "Yajie Bao",
      "Shu-Tao Xia",
      "Changliang Zou"
    ],
    "abstract": "Uncertainty quantification in time series prediction is challenging due to\nthe temporal dependence and distribution shift on sequential data. Conformal\ninference provides a pivotal and flexible instrument for assessing the\nuncertainty of machine learning models through prediction sets. Recently, a\nseries of online conformal inference methods updated thresholds of prediction\nsets by performing online gradient descent on a sequence of quantile loss\nfunctions. A drawback of such methods is that they only use the information of\nrevealed non-conformity scores via miscoverage indicators but ignore error\nquantification, namely the distance between the non-conformity score and the\ncurrent threshold. To accurately leverage the dynamic of miscoverage error, we\npropose \\textit{Error-quantified Conformal Inference} (ECI) by smoothing the\nquantile loss function. ECI introduces a continuous and adaptive feedback scale\nwith the miscoverage error, rather than simple binary feedback in existing\nmethods. We establish a long-term coverage guarantee for ECI under arbitrary\ndependence and distribution shift. The extensive experimental results show that\nECI can achieve valid miscoverage control and output tighter prediction sets\nthan other baselines.",
    "pdf_url": "http://arxiv.org/pdf/2502.00818v2",
    "published": "2025-02-02T15:02:36+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.00817v1",
    "title": "Probing Large Language Models in Reasoning and Translating Complex Linguistic Puzzles",
    "authors": [
      "Zheng-Lin Lin",
      "Yu-Fei Shih",
      "Shu-Kai Hsieh"
    ],
    "abstract": "This paper investigates the utilization of Large Language Models (LLMs) for\nsolving complex linguistic puzzles, a domain requiring advanced reasoning and\nadept translation capabilities akin to human cognitive processes. We explore\nspecific prompting techniques designed to enhance ability of LLMs to reason and\nelucidate their decision-making pathways, with a focus on Input-Output\nPrompting (IO), Chain-of-Thought Prompting (CoT), and Solo Performance\nPrompting (SPP). Utilizing datasets from the Puzzling Machine Competition and\nvarious Linguistics Olympiads, we employ a comprehensive set of metrics to\nassess the performance of GPT-4 0603, a prominent LLM, across these prompting\nmethods. Our findings illuminate the potential of LLMs in linguistic reasoning\nand complex translation tasks, highlighting their capabilities and identifying\nlimitations in the context of linguistic puzzles. This research contributes\nsignificantly to the broader field of Natural Language Processing (NLP) by\nproviding insights into the optimization of LLM applications for improved\nreasoning and translation accuracy, thereby enriching the ongoing dialogue in\nNLP advancements.",
    "pdf_url": "http://arxiv.org/pdf/2502.00817v1",
    "published": "2025-02-02T14:53:14+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00816v2",
    "title": "Sundial: A Family of Highly Capable Time Series Foundation Models",
    "authors": [
      "Yong Liu",
      "Guo Qin",
      "Zhiyuan Shi",
      "Zhi Chen",
      "Caiyin Yang",
      "Xiangdong Huang",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "abstract": "We introduce Sundial, a family of native, flexible, and scalable time series\nfoundation models. To predict the next-patch's distribution, we propose a\nTimeFlow Loss based on flow-matching, which facilitates native pre-training of\nTransformers on continuous-valued time series without discrete tokenization.\nConditioned on arbitrary-length time series, our models are pre-trained without\nspecifying any prior distribution and can generate multiple probable\npredictions, achieving more flexibility in representation learning than using\nparametric densities. Towards time series foundation models, we leverage\nminimal but crucial adaptations of Transformers and curate TimeBench with one\ntrillion time points, comprising mostly real-world datasets and synthetic data.\nBy mitigating mode collapse via TimeFlow Loss, we pre-train a family of Sundial\nmodels on TimeBench, which achieve unprecedented model capacity and\ngeneralization performance. In addition to excellent scalability, Sundial\nachieves state-of-the-art results on both point and probabilistic forecasting\nbenchmarks with a just-in-time inference speed, i.e., making zero-shot\npredictions within a few milliseconds. We believe that Sundial's pioneering\ngenerative forecasting capability can improve model reliability in real-world\ndecision-making. Code is available at: https://github.com/thuml/Sundial.",
    "pdf_url": "http://arxiv.org/pdf/2502.00816v2",
    "published": "2025-02-02T14:52:50+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00815v1",
    "title": "A gasket construction of the Koch snowflake and variations",
    "authors": [
      "Robert C. Sargent"
    ],
    "abstract": "We introduce a construction of the Koch snowflake that is not inherently\nsix-way symmetrical, based on iteratively placing similar rhombi. This\nconstruction naturally splits the snowflake into four identical self-similar\ncurves, in contrast to the typical decomposition into three Koch curves.\nVarying the shape of the rhombi creates a continuous family of new fractal\ncurves with rectangular symmetry. We compute the Hausdorff dimension of the\ngeneralized curve and show that it attains a maximum at the original Koch\nsnowflake.",
    "pdf_url": "http://arxiv.org/pdf/2502.00815v1",
    "published": "2025-02-02T14:50:48+00:00",
    "categories": [
      "math.MG",
      "math.FA",
      "28A80, 28A78"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00814v2",
    "title": "Disentangling Length Bias In Preference Learning Via Response-Conditioned Modeling",
    "authors": [
      "Jianfeng Cai",
      "Jinhua Zhu",
      "Ruopei Sun",
      "Yue Wang",
      "Li Li",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has achieved considerable\nsuccess in aligning large language models (LLMs) by modeling human preferences\nwith a learnable reward model and employing a reinforcement learning algorithm\nto maximize the reward model's scores. However, these reward models are\nsusceptible to exploitation through various superficial confounding factors,\nwith length bias emerging as a particularly significant concern. Moreover,\nwhile the pronounced impact of length bias on preference modeling suggests that\nLLMs possess an inherent sensitivity to length perception, our preliminary\ninvestigations reveal that fine-tuned LLMs consistently struggle to adhere to\nexplicit length instructions. To address these two limitations, we propose a\nnovel framework wherein the reward model explicitly differentiates between\nhuman semantic preferences and response length requirements. Specifically, we\nintroduce a $\\textbf{R}$esponse-$\\textbf{c}$onditioned\n$\\textbf{B}$radley-$\\textbf{T}$erry (Rc-BT) model that enhances the model's\ncapability in length bias mitigating and length instruction following, through\ntraining on our augmented dataset. Furthermore, we propose the Rc-RM and Rc-DPO\nalgorithm to leverage the Rc-BT model for reward modeling and direct policy\noptimization (DPO) of LLMs, simultaneously mitigating length bias and promoting\nadherence to length instructions. Extensive experiments across various\nfoundational models and datasets demonstrate the effectiveness and\ngeneralizability of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2502.00814v2",
    "published": "2025-02-02T14:50:25+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00813v1",
    "title": "Emamectin benzoate sensing using vivianenes (2D vivianites)",
    "authors": [
      "Surbhi Slathia",
      "Bruno Ipaves",
      "Raphael Benjamim de Oliveira",
      "Guilherme da Silva Lopes Fabris",
      "Marcelo Lopes Pereira Júnior",
      "Raphael Matozo Tromer",
      "Gelu Costin",
      "Suman Sarkar",
      "Douglas Soares Galvao",
      "Chandra Sekhar Tiwary"
    ],
    "abstract": "The excessive application of pesticides, particularly the overreliance on\ninsecticides for the protection of desirable crops from pests, has posed a\nsignificant threat to both ecological systems and human health due to\nenvironmental pollution. This research outlines a comprehensive approach to\nrecognizing and quantifying the presence of insecticides through the\napplication of spectroscopic and electrochemical sensing methods. The detection\nof Emamectin benzoate (EB), a commonly used insecticide, was performed\nutilizing vivianenes, a 2D phosphate that has been mechanically exfoliated from\nthe naturally occurring vivianite minerals. This investigation examined the\nstructural and compositional characteristics of vivianenes, utilizing a range\nof characterization methods. The spectroscopic analyses reveal the molecular\ninteractions and structural modifications that take place during the\ninteraction of EB with the 2D template. Electrochemical investigations\nemploying cyclic voltammetry were performed for different concentrations of EB\nto enable real-time monitoring of the pesticide. The modified sensing electrode\nusing vivianene demonstrated a linear range of from 50 mg/L to 10 micro g/L,\neffectively detecting EB molecules at levels significantly below the hazardous\nthreshold. Fully atomistic molecular dynamics simulations were also carried out\nto obtain further insights into the interaction mechanisms of the EB with the\nvivianites, and the results corroborate the adsorption mechanism. Our results\nhighlight the potential application of 2D phosphate minerals as advanced\nsensors to enhance agricultural monitoring and promote sustainable development.",
    "pdf_url": "http://arxiv.org/pdf/2502.00813v1",
    "published": "2025-02-02T14:40:06+00:00",
    "categories": [
      "physics.chem-ph",
      "physics.bio-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00812v2",
    "title": "Direct sampling from conditional distributions by sequential maximum likelihood estimations",
    "authors": [
      "Shuhei Mano"
    ],
    "abstract": "We can directly sample from the conditional distribution of any log-affine\nmodel. The algorithm is a Markov chain on a bounded integer lattice, and its\ntransition probability is the ratio of the UMVUE (uniformly minimum variance\nunbiased estimator) of the expected counts to the total number of counts. The\ncomputation of the UMVUE accounts for most of the computational cost, which\nmakes the implementation challenging. Here, we investigated an approximate\nalgorithm that replaces the UMVUE with the MLE (maximum likelihood estimator).\nAlthough it is generally not exact, it is efficient and easy to implement; no\nprior study is required, such as about the connection matrices of the holonomic\nideal in the original algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2502.00812v2",
    "published": "2025-02-02T14:33:24+00:00",
    "categories": [
      "math.ST",
      "stat.TH",
      "33C90, 33F99, 62H17, 62R01, 65C05"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2502.00811v2",
    "title": "Bilinear Subspace Variational Bayesian Inference for Joint Scattering Environment Sensing and Data Recovery in ISAC Systems",
    "authors": [
      "An Liu",
      "Wenkang Xu",
      "Wei Xu",
      "Giuseppe Caire"
    ],
    "abstract": "This paper considers a joint scattering environment sensing and data recovery\nproblem in an uplink integrated sensing and communication (ISAC) system. To\nfacilitate joint scatterers localization and multi-user (MU) channel\nestimation, we introduce a three-dimensional (3D) location-domain sparse\nchannel model to capture the joint sparsity of the MU channel (i.e., different\nuser channels share partially overlapped scatterers). Then the joint problem is\nformulated as a bilinear structured sparse recovery problem with a dynamic\nposition grid and imperfect parameters (such as time offset and user position\nerrors). We propose an expectation maximization based turbo bilinear subspace\nvariational Bayesian inference (EM-Turbo-BiSVBI) algorithm to solve the problem\neffectively, where the E-step performs Bayesian estimation of the the\nlocation-domain sparse MU channel by exploiting the joint sparsity, and the\nM-step refines the dynamic position grid and learns the imperfect factors via\ngradient update. Two methods are introduced to greatly reduce the complexity\nwith almost no sacrifice on the performance and convergence speed: 1) a\nsubspace constrained bilinear variational Bayesian inference (VBI) method is\nproposed to avoid any high-dimensional matrix inverse; 2) the multiple signal\nclassification (MUSIC) and subspace constrained VBI methods are combined to\nobtain a coarse estimation result to reduce the search range. Simulations\nverify the advantages of the proposed scheme over baseline schemes.",
    "pdf_url": "http://arxiv.org/pdf/2502.00811v2",
    "published": "2025-02-02T14:31:27+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.00810v2",
    "title": "The Subalgebras of the Real Forms of \\(\\mathfrak{sl}_3(\\mathbb{C})\\)",
    "authors": [
      "Andrew Douglas",
      "Willem A. de Graaf"
    ],
    "abstract": "We classify the subalgebras of the real forms the complex linear algebra\n$\\mathfrak{sl}_3(\\mathbb{C})$, namely the real special linear algebra\n$\\mathfrak{sl}_3(\\mathbb{R})$, the special unitary algebra $\\mathfrak{su}(3)$,\nand the generalized special unitary algebra $\\mathfrak{su}(2,1)$. Our approach\napplies Galois cohomology to the known classification of complex subalgebras of\n$\\mathfrak{sl}_3(\\mathbb{C})$. The subalgebras of $\\mathfrak{sl}_3(\\mathbb{R})$\nwere previously classified by Winternitz using different techniques. We recover\nthis classification using our cohomological approach and amend minor\ninaccuracies. Our work, however, constitutes the first complete classifications\nof the subalgebras of $\\mathfrak{su}(3)$ and $\\mathfrak{su}(2,1)$. In addition\nto illuminating the internal structure of the real forms of\n$\\mathfrak{sl}_3(\\mathbb{C})$, our methodology provides a pathway for future\ninvestigations into the subalgebra structure of higher-dimensional cases. In\naddition, the present work and its extensions offer potential applications in\nrepresentation theory, applied mathematics, and physics.",
    "pdf_url": "http://arxiv.org/pdf/2502.00810v2",
    "published": "2025-02-02T14:30:15+00:00",
    "categories": [
      "math.GR",
      "17B05, 17B20, 17B30, 20G10, 20G20"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2502.01688v1",
    "title": "BrainOOD: Out-of-distribution Generalizable Brain Network Analysis",
    "authors": [
      "Jiaxing Xu",
      "Yongqiang Chen",
      "Xia Dong",
      "Mengcheng Lan",
      "Tiancheng Huang",
      "Qingtian Bian",
      "James Cheng",
      "Yiping Ke"
    ],
    "abstract": "In neuroscience, identifying distinct patterns linked to neurological\ndisorders, such as Alzheimer's and Autism, is critical for early diagnosis and\neffective intervention. Graph Neural Networks (GNNs) have shown promising in\nanalyzing brain networks, but there are two major challenges in using GNNs: (1)\ndistribution shifts in multi-site brain network data, leading to poor\nOut-of-Distribution (OOD) generalization, and (2) limited interpretability in\nidentifying key brain regions critical to neurological disorders. Existing\ngraph OOD methods, while effective in other domains, struggle with the unique\ncharacteristics of brain networks. To bridge these gaps, we introduce BrainOOD,\na novel framework tailored for brain networks that enhances GNNs' OOD\ngeneralization and interpretability. BrainOOD framework consists of a feature\nselector and a structure extractor, which incorporates various auxiliary losses\nincluding an improved Graph Information Bottleneck (GIB) objective to recover\ncausal subgraphs. By aligning structure selection across brain networks and\nfiltering noisy features, BrainOOD offers reliable interpretations of critical\nbrain regions. Our approach outperforms 16 existing methods and improves\ngeneralization to OOD subjects by up to 8.5%. Case studies highlight the\nscientific validity of the patterns extracted, which aligns with the findings\nin known neuroscience literature. We also propose the first OOD brain network\nbenchmark, which provides a foundation for future research in this field. Our\ncode is available at https://github.com/AngusMonroe/BrainOOD.",
    "pdf_url": "http://arxiv.org/pdf/2502.01688v1",
    "published": "2025-02-02T14:26:09+00:00",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00809v2",
    "title": "Anomalous Hall effect in highly c-plane oriented Mn$_{3}$Ge/Si(100) thin films grown by pulsed laser deposition",
    "authors": [
      "Indraneel Sinha",
      "Purba Dutta",
      "Nazma Firdosh",
      "Shreyashi Sinha",
      "Nirmal Ganguli",
      "Sujit Manna"
    ],
    "abstract": "Antiferromagnetic Mn$_{3}$Ge with a non-collinear Kagome structures present\nexciting prospects for exploring Berry curvature driven anomalous Hall effects\n(AHE). Despite substantial progress in bulk systems, the synthesis of\ncrystalline thin films directly on silicon with a hexagonal phase presents a\nparticular challenge unless a buffer layer is employed. In this study, we\nreport the synthesis of single phase c-plane oriented hexagonal\nMn$_{3}$Ge(0001) films on Si(100) using pulsed laser deposition. Under suitable\ngrowth conditions, we obtain layer-by-layer films with atomically flat surfaces\nand interfaces. High-resolution scanning tunneling microscopy study reveals the\ndetail surface atomic structures, where the surface Mn atoms spontaneously\narrange into a Kagome lattice. Tunneling spectroscopy (dI/dV) measurement on\nthe atomically resolved Kagome surface show a minima in local density of states\nnear the Fermi level, likely originated from the Weyl crossings near K points.\nDespite the nearly vanishing magnetization, magnetotransport measurements in 30\nnm $Mn_{3}$Ge(0001) films show anomalous Hall resistivity up to 0.41\n($\\mu\\Omega\\cdot\\text{cm}$) at 2 K. Our \\textit{ab initio} calculations shed\nfurther light on the existence of topological features and the band structures\nin Mn$_{3+x}$Ge$_{1-x}$ with increasing Mn concentration $x$. The anomalous\nHall response at room temperature in crystalline Mn$_{3}$Ge films on Si(100)\noffer promising potential for the development of antiferromagnetic spintronics.",
    "pdf_url": "http://arxiv.org/pdf/2502.00809v2",
    "published": "2025-02-02T14:20:50+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.00808v1",
    "title": "Synthetic Artifact Auditing: Tracing LLM-Generated Synthetic Data Usage in Downstream Applications",
    "authors": [
      "Yixin Wu",
      "Ziqing Yang",
      "Yun Shen",
      "Michael Backes",
      "Yang Zhang"
    ],
    "abstract": "Large language models (LLMs) have facilitated the generation of high-quality,\ncost-effective synthetic data for developing downstream models and conducting\nstatistical analyses in various domains. However, the increased reliance on\nsynthetic data may pose potential negative impacts. Numerous studies have\ndemonstrated that LLM-generated synthetic data can perpetuate and even amplify\nsocietal biases and stereotypes, and produce erroneous outputs known as\n``hallucinations'' that deviate from factual knowledge. In this paper, we aim\nto audit artifacts, such as classifiers, generators, or statistical plots, to\nidentify those trained on or derived from synthetic data and raise user\nawareness, thereby reducing unexpected consequences and risks in downstream\napplications. To this end, we take the first step to introduce synthetic\nartifact auditing to assess whether a given artifact is derived from\nLLM-generated synthetic data. We then propose an auditing framework with three\nmethods including metric-based auditing, tuning-based auditing, and\nclassification-based auditing. These methods operate without requiring the\nartifact owner to disclose proprietary training details. We evaluate our\nauditing framework on three text classification tasks, two text summarization\ntasks, and two data visualization tasks across three training scenarios. Our\nevaluation demonstrates the effectiveness of all proposed auditing methods\nacross all these tasks. For instance, black-box metric-based auditing can\nachieve an average accuracy of $0.868 \\pm 0.071$ for auditing classifiers and\n$0.880 \\pm 0.052$ for auditing generators using only 200 random queries across\nthree scenarios. We hope our research will enhance model transparency and\nregulatory compliance, ensuring the ethical and responsible use of synthetic\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2502.00808v1",
    "published": "2025-02-02T14:18:28+00:00",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00807v2",
    "title": "Mixed-Integer Optimization for Loopless Flux Distributions in Metabolic Networks",
    "authors": [
      "Hannah Troppens",
      "Mathieu Besançon",
      "St. Elmo Wilken",
      "Sebastian Pokutta"
    ],
    "abstract": "Constraint-based metabolic models can be used to investigate the\nintracellular physiology of microorganisms. These models couple genes to\nreactions, and typically seek to predict metabolite fluxes that optimize some\nbiologically important metric. Classical techniques, like Flux Balance Analysis\n(FBA), formulate the metabolism of a microbe as an optimization problem where\ngrowth rate is maximized. While FBA has found widespread use, it often leads to\nthermodynamically infeasible solutions that contain internal cycles (loops). To\naddress this shortcoming, Loopless-Flux Balance Analysis (ll-FBA) seeks to\npredict flux distributions that do not contain these loops. ll-FBA is a\ndisjunctive program, usually reformulated as a mixed-integer program, and is\nchallenging to solve for biological models that often contain thousands of\nreactions and metabolites. In this paper, we compare various reformulations of\nll-FBA and different solution approaches. Overall, the combinatorial Benders'\ndecomposition is the most promising of the tested approaches with which we\ncould solve most instances. However, the model size and numerical instability\npose a challenge to the combinatorial Benders' method.",
    "pdf_url": "http://arxiv.org/pdf/2502.00807v2",
    "published": "2025-02-02T14:07:10+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00806v2",
    "title": "UniGraph2: Learning a Unified Embedding Space to Bind Multimodal Graphs",
    "authors": [
      "Yufei He",
      "Yuan Sui",
      "Xiaoxin He",
      "Yue Liu",
      "Yifei Sun",
      "Bryan Hooi"
    ],
    "abstract": "Existing foundation models, such as CLIP, aim to learn a unified embedding\nspace for multimodal data, enabling a wide range of downstream web-based\napplications like search, recommendation, and content classification. However,\nthese models often overlook the inherent graph structures in multimodal\ndatasets, where entities and their relationships are crucial. Multimodal graphs\n(MMGs) represent such graphs where each node is associated with features from\ndifferent modalities, while the edges capture the relationships between these\nentities. On the other hand, existing graph foundation models primarily focus\non text-attributed graphs (TAGs) and are not designed to handle the\ncomplexities of MMGs. To address these limitations, we propose UniGraph2, a\nnovel cross-domain graph foundation model that enables general representation\nlearning on MMGs, providing a unified embedding space. UniGraph2 employs\nmodality-specific encoders alongside a graph neural network (GNN) to learn a\nunified low-dimensional embedding space that captures both the multimodal\ninformation and the underlying graph structure. We propose a new cross-domain\nmulti-graph pre-training algorithm at scale to ensure effective transfer\nlearning across diverse graph domains and modalities. Additionally, we adopt a\nMixture of Experts (MoE) component to align features from different domains and\nmodalities, ensuring coherent and robust embeddings that unify the information\nacross modalities. Extensive experiments on a variety of multimodal graph tasks\ndemonstrate that UniGraph2 significantly outperforms state-of-the-art models in\ntasks such as representation learning, transfer learning, and multimodal\ngenerative tasks, offering a scalable and flexible solution for learning on\nMMGs.",
    "pdf_url": "http://arxiv.org/pdf/2502.00806v2",
    "published": "2025-02-02T14:04:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00805v2",
    "title": "Constraints on Lorentz Invariance Violation from Gamma-ray Burst rest-frame spectral lags using Profile Likelihood",
    "authors": [
      "Vyaas Ramakrishnan",
      "Shantanu Desai"
    ],
    "abstract": "We reanalyze the spectral lag data for 56 Gamma-Ray Bursts (GRBs) in the\ncosmological rest frame to search for Lorentz Invariance Violation (LIV) using\nfrequentist inference. For this purpose, we use the technique of profile\nlikelihood to deal with the nuisance parameters, corresponding to a constant\ntime lag in the GRB rest frame and an unknown intrinsic scatter, while the\nparameter of interest is the energy scale for LIV ($E_{QG}$). With this method,\nwe do not obtain a global minimum for $\\chi^2$ as a function of $E_{QG}$ up to\nthe Planck scale. Thus, we can obtain one-sided lower limits on $E_{QG}$ in a\nseamless manner. Therefore, the 95\\% c.l. lower limits which we thus obtain on\n$E_{QG}$ are then given by: $E_{QG}\\geq 2.07 \\times 10^{14}$ GeV and\n$E_{QG}\\geq 3.71\\times 10^{5}$ GeV, for linear and quadratic LIV, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.00805v2",
    "published": "2025-02-02T13:59:07+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.00804v2",
    "title": "Effect of 2$^\\text{nd}$ harmonic current--phase relation on a behavior of a Josephson Traveling Wave Parametric Amplifier",
    "authors": [
      "Claudio Guarcello",
      "Carlo Barone",
      "Giovanni Carapella",
      "Giovanni Filatrella",
      "Andrea Giachero",
      "Sergio Pagano"
    ],
    "abstract": "We numerically investigate the behavior of a Josephson traveling wave\nparametric amplifier assuming a current-phase relation with a second--harmonic\ncontribution. We find that varying the weight of harmonic terms in the\nJosephson current affects the gain profile. The analysis of gain\ncharacteristics, phase-space portraits, Poincar\\'e sections, and Fourier\nspectra demonstrates that the nonsinusoidal contribution influences the\noperating mode and stability of the device. In particular, we identify the\noptimal weighting of harmonic contributions that maximizes amplification,\nachieving gains up to $\\sim 13\\;\\text{dB}$ in a device without dispersion\nengineering.",
    "pdf_url": "http://arxiv.org/pdf/2502.00804v2",
    "published": "2025-02-02T13:57:14+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "cond-mat.other"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2502.00803v2",
    "title": "ProPINN: Demystifying Propagation Failures in Physics-Informed Neural Networks",
    "authors": [
      "Haixu Wu",
      "Yuezhou Ma",
      "Hang Zhou",
      "Huikun Weng",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "abstract": "Physics-informed neural networks (PINNs) have earned high expectations in\nsolving partial differential equations (PDEs), but their optimization usually\nfaces thorny challenges due to the unique derivative-dependent loss function.\nBy analyzing the loss distribution, previous research observed the propagation\nfailure phenomenon of PINNs, intuitively described as the correct supervision\nfor model outputs cannot ''propagate'' from initial states or boundaries to the\ninterior domain. Going beyond intuitive understanding, this paper provides a\nformal and in-depth study of propagation failure and its root cause. Based on a\ndetailed comparison with classical finite element methods, we ascribe the\nfailure to the conventional single-point-processing architecture of PINNs and\nfurther prove that propagation failure is essentially caused by the lower\ngradient correlation of PINN models on nearby collocation points. Compared to\nsuperficial loss maps, this new perspective provides a more precise\nquantitative criterion to identify where and why PINN fails. The theoretical\nfinding also inspires us to present a new PINN architecture, named ProPINN,\nwhich can effectively unite the gradients of region points for better\npropagation. ProPINN can reliably resolve PINN failure modes and significantly\nsurpass advanced Transformer-based models with 46% relative promotion.",
    "pdf_url": "http://arxiv.org/pdf/2502.00803v2",
    "published": "2025-02-02T13:56:38+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00802v1",
    "title": "Fisher-Guided Selective Forgetting: Mitigating The Primacy Bias in Deep Reinforcement Learning",
    "authors": [
      "Massimiliano Falzari",
      "Matthia Sabatelli"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) systems often tend to overfit to early\nexperiences, a phenomenon known as the primacy bias (PB). This bias can\nseverely hinder learning efficiency and final performance, particularly in\ncomplex environments. This paper presents a comprehensive investigation of PB\nthrough the lens of the Fisher Information Matrix (FIM). We develop a framework\ncharacterizing PB through distinct patterns in the FIM trace, identifying\ncritical memorization and reorganization phases during learning. Building on\nthis understanding, we propose Fisher-Guided Selective Forgetting (FGSF), a\nnovel method that leverages the geometric structure of the parameter space to\nselectively modify network weights, preventing early experiences from\ndominating the learning process. Empirical results across DeepMind Control\nSuite (DMC) environments show that FGSF consistently outperforms baselines,\nparticularly in complex tasks. We analyze the different impacts of PB on actor\nand critic networks, the role of replay ratios in exacerbating the effect, and\nthe effectiveness of even simple noise injection methods. Our findings provide\na deeper understanding of PB and practical mitigation strategies, offering a\nFIM-based geometric perspective for advancing DRL.",
    "pdf_url": "http://arxiv.org/pdf/2502.00802v1",
    "published": "2025-02-02T13:54:47+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00801v2",
    "title": "Environment-Driven Online LiDAR-Camera Extrinsic Calibration",
    "authors": [
      "Zhiwei Huang",
      "Jiaqi Li",
      "Ping Zhong",
      "Rui Fan"
    ],
    "abstract": "LiDAR-camera extrinsic calibration (LCEC) is crucial for multi-modal data\nfusion in mechatronics. Existing methods, whether target-based or target-free,\ntypically rely on customized calibration targets or fixed scene types, limiting\ntheir practicality in real-world applications. To address these challenges, we\nintroduce EdO-LCEC, the first environment-driven online calibration approach.\nUnlike traditional target-free methods, EdO-LCEC observes the feature density\nof the application environment through a generalizable scene discriminator.\nBased on this feature density, EdO-LCEC extracts LiDAR intensity and depth\nfeatures from varying perspectives to achieve higher calibration accuracy. To\novercome the challenges of cross-modal feature matching between LiDAR and\ncamera, we propose dual-path correspondence matching (DPCM), which leverages\nboth structural and textural consistency for reliable 3D-2D correspondences.\nAdditionally, our approach models the calibration process as a joint\noptimization problem utilizing global constraints from multiple views and\nscenes to enhance accuracy. Extensive experiments on real-world datasets\ndemonstrate that EdO-LCEC outperforms state-of-the-art methods, particularly in\nsparse or partially overlapping sensor views.",
    "pdf_url": "http://arxiv.org/pdf/2502.00801v2",
    "published": "2025-02-02T13:52:35+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00800v1",
    "title": "Adversarial Semantic Augmentation for Training Generative Adversarial Networks under Limited Data",
    "authors": [
      "Mengping Yang",
      "Zhe Wang",
      "Ziqiu Chi",
      "Dongdong Li",
      "Wenli Du"
    ],
    "abstract": "Generative adversarial networks (GANs) have made remarkable achievements in\nsynthesizing images in recent years. Typically, training GANs requires massive\ndata, and the performance of GANs deteriorates significantly when training data\nis limited. To improve the synthesis performance of GANs in low-data regimes,\nexisting approaches use various data augmentation techniques to enlarge the\ntraining sets. However, it is identified that these augmentation techniques may\nleak or even alter the data distribution. To remedy this, we propose an\nadversarial semantic augmentation (ASA) technique to enlarge the training data\nat the semantic level instead of the image level. Concretely, considering\nsemantic features usually encode informative information of images, we estimate\nthe covariance matrices of semantic features for both real and generated images\nto find meaningful transformation directions. Such directions translate\noriginal features to another semantic representation, e.g., changing the\nbackgrounds or expressions of the human face dataset. Moreover, we derive an\nupper bound of the expected adversarial loss. By optimizing the upper bound,\nour semantic augmentation is implicitly achieved. Such design avoids redundant\nsampling of the augmented features and introduces negligible computation\noverhead, making our approach computation efficient. Extensive experiments on\nboth few-shot and large-scale datasets demonstrate that our method consistently\nimprove the synthesis quality under various data regimes, and further\nvisualized and analytic results suggesting satisfactory versatility of our\nproposed method.",
    "pdf_url": "http://arxiv.org/pdf/2502.00800v1",
    "published": "2025-02-02T13:50:38+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2503.05875v1",
    "title": "Detecting Destabilizing Nonlinearities in Absolute Stability Analysis of Discrete-Time Feedback Systems",
    "authors": [
      "Hibiki Gyotoku",
      "Tsuyoshi Yuno",
      "Yoshio Ebihara",
      "Dimitri Peaucelle",
      "Sophie Tarbouriech",
      "Victor Magron"
    ],
    "abstract": "This paper is concerned with the absolute stability analysis of discrete-time\nfeedback systems with slope-restricted nonlinearities. By employing static\nO'Shea-Zames-Falb multipliers in the framework of integral quadratic\nconstraints, we can obtain a certificate for the absolute stability in the form\nof a linear matrix inequality (LMI). However, since this LMI certificate is\nonly a sufficient condition, we cannot draw any definite conclusion if the LMI\nturns out to be infeasible. To address this issue, we focus on the dual LMI\nthat is feasible if and only if the original (primal) LMI is infeasible. As the\nmain result, if the dual solution satisfies a certain rank condition, we prove\nthat we can detect a destabilizing nonlinearity within the assumed class of\nslope-restricted nonlinearities as well as a non-zero equilibrium point of the\nresulting feedback system, thereby we can conclude that the system of interest\nis never absolutely stable. The effectiveness of the technical results is\ndemonstrated through numerical examples.",
    "pdf_url": "http://arxiv.org/pdf/2503.05875v1",
    "published": "2025-02-02T13:47:39+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00799v1",
    "title": "Minimal matroids in dependency posets: algorithms and applications to computing irreducible decompositions of circuit varieties",
    "authors": [
      "Emiliano Liwski",
      "Fatemeh Mohammadi"
    ],
    "abstract": "We study point-line configurations, their minimal matroids, and their\nassociated circuit varieties. We present an algorithm for identifying the\nminimal matroids of these configurations with respect to dependency order, or\nequivalently, the maximal matroids with respect to weak order, and use it to\ndetermine the irreducible decomposition of their corresponding circuit\nvarieties. Our algorithm is applied to several classical configurations,\nincluding the Fano matroid, affine plane of order three, MacLane, and Pappus\nconfigurations. Additionally, we explore the connection to a conjecture by\nJackson and Tanigawa, which provides a criterion for the uniqueness of the\nminimal matroids.",
    "pdf_url": "http://arxiv.org/pdf/2502.00799v1",
    "published": "2025-02-02T13:39:45+00:00",
    "categories": [
      "math.CO",
      "math.AC",
      "math.AG"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00798v2",
    "title": "Deep Neural Network for Phonon-Assisted Optical Spectra in Semiconductors",
    "authors": [
      "Qiangqiang Gu",
      "Shishir Kumar Pandey",
      "Zhanghao Zhouyin"
    ],
    "abstract": "Ab initio based accurate simulation of phonon-assisted optical spectra of\nsemiconductors at finite temperatures remains a formidable challenge, as it\nrequires large supercells for phonon sampling and computationally expensive\nhigh-accuracy exchange-correlation (XC) functionals. In this work, we present\nan efficient approach that combines deep learning tight-binding and potential\nmodels to address this challenge with ab initio fidelity. By leveraging\nmolecular dynamics for atomic configuration sampling and deep learning-enabled\nrapid Hamiltonian evaluation, our approach enables large-scale simulations of\ntemperature-dependent optical properties using advanced XC functionals (HSE,\nSCAN). Demonstrated on silicon and gallium arsenide across temperature 100-400\nK, the method accurately captures phonon-induced bandgap renormalization and\nindirect/direct absorption processes which are in excellent agreement with\nexperimental findings over five orders of magnitude. This work establishes a\npathway for high-throughput investigation of electron-phonon coupled phenomena\nin complex materials, overcoming traditional computational limitations arising\nfrom large supercell used with computationally expensive XC-functionals.",
    "pdf_url": "http://arxiv.org/pdf/2502.00798v2",
    "published": "2025-02-02T13:37:56+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.00797v1",
    "title": "Dynamic Structures of Knowledge Production: Citation Rates in Hydrogen Technologies",
    "authors": [
      "David Dekker",
      "Dimitirs Christopoulos",
      "Heather McGregor"
    ],
    "abstract": "We explore a dynamic patent citation network model to explain the established\nlink between network structure and technological improvement rate. This model,\na type of survival model, posits that the *dynamic* network structure\ndetermines the *constant* improvement rate, requiring consistent structural\nreproduction over time. The model's hazard rate, the probability of a patent\nbeing cited, represents \"knowledge production,\" reflecting the output of new\npatents given existing ones. Analyzing hydrogen technology patents, we find\ndistinct subdomain knowledge production rates, but consistent development\nacross subdomains. \"Distribution\" patents show the lowest production rate,\nsuggesting dominant \"distribution\" costs in $H_2$ pricing. Further modeling\nshows Katz-centrality predicts knowledge production, outperforming subdomain\nclassification. Lower Katz centrality in \"distribution\" suggests inherent\norganizational differences in invention. Exploitative learning\n(within-subdomain citations) correlates with higher patenting opportunity\ncosts, potentially explaining slower \"distribution\" development, as high\ninvestment needs may incentivize monopolization over knowledge sharing.",
    "pdf_url": "http://arxiv.org/pdf/2502.00797v1",
    "published": "2025-02-02T13:36:25+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2502.00796v1",
    "title": "Task-Specific Adaptation with Restricted Model Access",
    "authors": [
      "Matan Levy",
      "Rami Ben-Ari",
      "Dvir Samuel",
      "Nir Darshan",
      "Dani Lischinski"
    ],
    "abstract": "The emergence of foundational models has greatly improved performance across\nvarious downstream tasks, with fine-tuning often yielding even better results.\nHowever, existing fine-tuning approaches typically require access to model\nweights and layers, leading to challenges such as managing multiple model\ncopies or inference pipelines, inefficiencies in edge device optimization, and\nconcerns over proprietary rights, privacy, and exposure to unsafe model\nvariants. In this paper, we address these challenges by exploring \"Gray-box\"\nfine-tuning approaches, where the model's architecture and weights remain\nhidden, allowing only gradient propagation. We introduce a novel yet simple and\neffective framework that adapts to new tasks using two lightweight learnable\nmodules at the model's input and output. Additionally, we present a less\nrestrictive variant that offers more entry points into the model, balancing\nperformance with model exposure. We evaluate our approaches across several\nbackbones on benchmarks such as text-image alignment, text-video alignment, and\nsketch-image alignment. Results show that our Gray-box approaches are\ncompetitive with full-access fine-tuning methods, despite having limited access\nto the model.",
    "pdf_url": "http://arxiv.org/pdf/2502.00796v1",
    "published": "2025-02-02T13:29:44+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00795v1",
    "title": "Data Fusion for Full-Range Response Reconstruction via Diffusion Models",
    "authors": [
      "Wingho Feng",
      "Quanwang Li",
      "Chen Wang",
      "Jian-sheng Fan"
    ],
    "abstract": "Accurately capturing the full-range response of structures is crucial in\nstructural health monitoring (SHM) for ensuring safety and operational\nintegrity. However, limited sensor deployment due to cost, accessibility, or\nscale often hinders comprehensive monitoring. This paper presents a novel data\nfusion framework utilizing diffusion models to reconstruct the full-range\nstructural response from sparse and heterogeneous sensor measurements. We\nincorporate Diffusion Posterior Sampling (DPS) into the reconstruction\nframework, using sensor measurements as probabilistic constraints to guide the\nsampling process. A lightweight neural network serves as the surrogate forward\nmodel within the DPS algorithm, which maps full-range structural responses to\nlocal sensor data. This approach enables flexibility in sensor configurations\nwhile reducing computational costs. The proposed framework is validated on a\nsteel plate shear wall exhibiting nonlinear responses. Comparative experiments\nare conducted with three forward models. Among these, the neural network\nsurrogate model achieves a desirable reconstruction accuracy, with a weighted\nmean absolute percentage error (WMAPE) as low as 1.57%, while also\ndemonstrating superior adaptability and computational efficiency. Additional\nexperiments explore the impact of sensor placement strategies and noise levels.\nResults show that even under sparse measurements or high noise conditions, the\nWMAPE remains capped at 15%, demonstrating the robustness in challenging\nscenarios. The proposed framework shows new possibilities for probabilistic\nmodeling and decision-making in SHM, offering a novel data fusion approach for\nfull-range monitoring of structures.",
    "pdf_url": "http://arxiv.org/pdf/2502.00795v1",
    "published": "2025-02-02T13:27:59+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2502.00794v2",
    "title": "Some Properties of The Finitely Additive Vector Integral",
    "authors": [
      "Gianluca Cassese"
    ],
    "abstract": "We prove some results concerning the finitely additive, vector integral of\nBochner and Pettis and their representation over a countably additive\nprobability space. Applications to convergence of vector valued martingales and\nto the non compact Choquet theorem are provided.",
    "pdf_url": "http://arxiv.org/pdf/2502.00794v2",
    "published": "2025-02-02T13:17:25+00:00",
    "categories": [
      "math.FA",
      "math.PR",
      "28B05, 28C05, 28C15, 46A55"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00793v1",
    "title": "Sensitivity Analysis for Mean-Field SDEs With Jump By Malliavin Calculus: Chaos Expansion Approach",
    "authors": [
      "Samaneh Sojudi",
      "Mahdieh Tahmasebi"
    ],
    "abstract": "In this paper, we describe an explicit extension formula in sensitivity\nanalysis regarding the Malliavin weight for jump-diffusion mean-field\nstochastic differential equations whose local Lipschitz drift coefficients are\ninfluenced by the product of the solution and its law. We state that these\nextended equations have unique Malliavin differentiable solutions in\nWiener-Poisson space and establish the sensitivity analysis of path-dependent\ndiscontinuous payoff functions. It will be realized after finding a relation\nbetween the stochastic flow of the solutions and their derivatives. The\nMalliavin derivatives are defined in a chaos approach in which the chain rule\nis not held. The convergence of the Euler method to approximate Delta Greek is\nproved. The simulation experiment illustrates our results to compute the Delta,\nin the context of financial mathematics, and demonstrates that the Malliavin\nMonte-Carlo computations applied in our formula are more efficient than using\nthe finite difference method directly.",
    "pdf_url": "http://arxiv.org/pdf/2502.00793v1",
    "published": "2025-02-02T13:16:36+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00792v1",
    "title": "RTBAgent: A LLM-based Agent System for Real-Time Bidding",
    "authors": [
      "Leng Cai",
      "Junxuan He",
      "Yikai Li",
      "Junjie Liang",
      "Yuanping Lin",
      "Ziming Quan",
      "Yawen Zeng",
      "Jin Xu"
    ],
    "abstract": "Real-Time Bidding (RTB) enables advertisers to place competitive bids on\nimpression opportunities instantaneously, striving for cost-effectiveness in a\nhighly competitive landscape. Although RTB has widely benefited from the\nutilization of technologies such as deep learning and reinforcement learning,\nthe reliability of related methods often encounters challenges due to the\ndiscrepancies between online and offline environments and the rapid\nfluctuations of online bidding. To handle these challenges, RTBAgent is\nproposed as the first RTB agent system based on large language models (LLMs),\nwhich synchronizes real competitive advertising bidding environments and\nobtains bidding prices through an integrated decision-making process.\nSpecifically, obtaining reasoning ability through LLMs, RTBAgent is further\ntailored to be more professional for RTB via involved auxiliary modules, i.e.,\nclick-through rate estimation model, expert strategy knowledge, and daily\nreflection. In addition, we propose a two-step decision-making process and\nmulti-memory retrieval mechanism, which enables RTBAgent to review historical\ndecisions and transaction records and subsequently make decisions more adaptive\nto market changes in real-time bidding. Empirical testing with real advertising\ndatasets demonstrates that RTBAgent significantly enhances profitability. The\nRTBAgent code will be publicly accessible at:\nhttps://github.com/CaiLeng/RTBAgent.",
    "pdf_url": "http://arxiv.org/pdf/2502.00792v1",
    "published": "2025-02-02T13:10:15+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00791v3",
    "title": "Vision-centric Token Compression in Large Language Model",
    "authors": [
      "Ling Xing",
      "Alex Jinpeng Wang",
      "Rui Yan",
      "Xiangbo Shu",
      "Jinhui Tang"
    ],
    "abstract": "Real-world applications are stretching context windows to hundreds of\nthousand of tokens while Large Language Models (LLMs) swell from billions to\ntrillions of parameters. This dual expansion send compute and memory costs\nskyrocketing, making token compression indispensable. We introduce Vision\nCentric Token Compression (Vist), a slow-fast compression framework that\nmirrors human reading: the fast path renders distant tokens into images,\nletting a frozen, lightweight vision encoder skim the low-salience context; the\nslow path feeds the proximal window into the LLM for fine-grained reasoning. A\nProbability-Informed Visual Enhancement (PVE) objective masks high-frequency\ntokens during training, steering the Resampler to concentrate on semantically\nrich regions-just as skilled reader gloss over function words. On eleven\nin-context learning benchmarks, Vist achieves the same accuracy with 2.3 times\nfewer tokens, cutting FLOPs by 16% and memory by 50%. This method delivers\nremarkable results, outperforming the strongest text encoder-based compression\nmethod CEPE by 7.6% on average over benchmarks like TriviaQA, NQ, PopQA, NLUI,\nand CLIN, setting a new standard for token efficiency in LLMs. The source code\nwill be released.",
    "pdf_url": "http://arxiv.org/pdf/2502.00791v3",
    "published": "2025-02-02T13:10:06+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00790v1",
    "title": "On minimal model program and Zariski decomposition of potential triples",
    "authors": [
      "Sung Rak Choi",
      "Sungwook Jang",
      "Dae-Won Lee"
    ],
    "abstract": "In this paper, we investigate properties of potential triples $(X,\\Delta,D)$\nwhich consists of a pair $(X,\\Delta)$ and a pseudoeffective\n$\\mathbb{R}$-Cartier divisor $D$. In particular, we show that if $D$ admits a\nbirational Zariski decomposition, then one can associate a generalized pair\nstructure to the potential triple $(X,\\Delta,D)$. Moreover, we can run the\ngeneralized MMP on $(K_X+\\Delta+D)$ as special cases. As an application, we\nalso show that for a pklt pair $(X,\\Delta)$, if $-(K_X+\\Delta)$ admits a\nbirational Zariski decomposition with $\\mathrm{NQC}$ positive part, then there\nexists a $-(K_X+\\Delta)$-minimal model.",
    "pdf_url": "http://arxiv.org/pdf/2502.00790v1",
    "published": "2025-02-02T13:09:25+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00789v1",
    "title": "Improving SDN Performance Using Network Coding: A Quantitative Analysis",
    "authors": [
      "Amer T. Ali",
      "Qutaiba I. Ali"
    ],
    "abstract": "Software Defined Networking or SDN is an architectural approach to managing\nthe network where the control and forwarding are different planes that are\ncontrolled through an application interface.",
    "pdf_url": "http://arxiv.org/pdf/2502.00789v1",
    "published": "2025-02-02T13:09:05+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00788v1",
    "title": "Explicit positivity preserving numerical method for linear stochastic volatility models driven by $α$-stable process",
    "authors": [
      "Xiaotong Li",
      "Wei Liu",
      "Xuerong Mao",
      "Hongjiong Tian",
      "Yue Wu"
    ],
    "abstract": "In this paper, we introduce a linear stochastic volatility model driven by\n$\\alpha$-stable processes, which admits a unique positive solution. To preserve\npositivity, we modify the classical forward Euler-Maruyama scheme and analyze\nits numerical properties. The scheme achieves a strong convergence order of\n$1/\\alpha$. Numerical simulations are presented at the end to verify\ntheoretical results.",
    "pdf_url": "http://arxiv.org/pdf/2502.00788v1",
    "published": "2025-02-02T13:07:08+00:00",
    "categories": [
      "math.PR",
      "60H35, 65C30, 60J76"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00787v1",
    "title": "Mathematical Modeling for Network Upgrades in Internet Service Provider Infrastructure",
    "authors": [
      "Omar M Malallah",
      "Qutaiba I. Ali"
    ],
    "abstract": "The ongoing growth of the need for superior Internet services creates great\npressure on the ISPs as to the accurate estimation of network upgrade need.",
    "pdf_url": "http://arxiv.org/pdf/2502.00787v1",
    "published": "2025-02-02T13:02:34+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00786v1",
    "title": "Periodic FPU system: Continuum limit to KdV via regularization and Fourier analysis",
    "authors": [
      "Chulkwang Kwak",
      "Changhun Yang"
    ],
    "abstract": "The Fermi-Pasta-Ulam (FPU) system, initially introduced by Fermi for\nnumerical simulations, models vibrating chains with fixed endpoints, where\nparticles interact weakly, nonlinearly with their nearest neighbors. Contrary\nto the anticipated ergodic behavior, the simulation revealed nearly periodic\n(quasi-periodic) motion of the solutions, a phenomenon later referred to as the\nFPU paradox. A partial but remarkable explanation was provided by Zabusky and\nKruskal [36], who formally derived the continuum limit of the FPU system,\nconnecting it to the Korteweg-de Vries (KdV) equation. This formal derivation\nwas later rigorously justified by Bambusi and Ponno [4].\n  In this paper, we revisit the problem studied in [4], specifically focusing\non the continuum limit of the periodic FPU system for a broader class of\ninitial data, as the number of particles N tends to infinity within a fixed\ndomain. Unlike the non-periodic case discussed in [15], periodic FPU solutions\nlack a (local) smoothing effect, posing a significant challenge in controlling\none derivative in the nonlinearity. This control is crucial not only for\nproving the (uniform in N) well-posedness for rough data but also for deriving\nthe continuum limit. The main strategies to resolve this issue involve deriving\nL4-Strichartz estimates for FPU solutions, analogous to those previously\nderived for KdV solutions in [7], and regularizing the system via the normal\nform method introduced in [1].",
    "pdf_url": "http://arxiv.org/pdf/2502.00786v1",
    "published": "2025-02-02T13:01:38+00:00",
    "categories": [
      "math.AP",
      "37K60, 35Q53, 70K45"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.00785v1",
    "title": "Forecasting Global Network Traffic Trends: The Role of Virtual Reality",
    "authors": [
      "Raghad H. AlShekh",
      "Qutaiba I. Ali"
    ],
    "abstract": "Virtual Reality (VR) technology demands real-time data transmission to\ndeliver an immersive and interactive user experience. This study investigates\nthe implementation of UDP Ethernet communication in VR systems, focusing on its\nimpact on network performance. Experiments were conducted to analyze how\nfactors such as cable length, data rate, and packet processing rate (PPR)\ninfluence system performance. A series of tests were performed, and the results\nwere visualized through detailed graphs. The findings reveal how variations in\nthese parameters affect communication speed and stability, providing insights\nfor optimizing VR system design. By leveraging the high-speed, low-overhead\nadvantages of UDP Ethernet, this study may contribute understanding of network\nperformance in VR applications, offering practical guidance for developers and\nengineers in creating responsive and efficient VR environments.",
    "pdf_url": "http://arxiv.org/pdf/2502.00785v1",
    "published": "2025-02-02T12:57:22+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.01687v2",
    "title": "Gravitational Waves beyond the Linear Approximation and Gravitational Wave Reflection",
    "authors": [
      "Victor Atanasov",
      "Avadh Saxena"
    ],
    "abstract": "We derive a relativistic field equation for the trace of the metric\nperturbation beyond the weak field approximation to the Einstein field\nequations. The dynamics is governed by a massive Klein-Gordon equation on\ncurved space-time, where the effective mass of the field is associated with the\nmaterial and the dark energy content via the cosmological term. We solve the\nequation in the case of a Schwarzschild black hole and show that it can be cast\ninto an effective Schr\\\"odinger form with an effective geometric potential\nwhich binds the zero angular momentum states. The non-zero angular momentum\nstates experience a positive potential peak before the event horizon pointing\nto gravitational waves scattering. Black holes scatter gravitational waves and\nthus we provide an unambiguous testable prediction of black hole existence. The\nNewtonian limit for this equation points to the possibility of reflecting\ngravitational waves at interfaces with sharp density boundary, thus opening up\ngravitational wave propulsion physics. We discuss this type of propulsion in\nthe light of Newton's third law of Mechanics. Compelling questions such as the\nexistence of quanta of this field which may account for the dark matter content\nare also addressed.",
    "pdf_url": "http://arxiv.org/pdf/2502.01687v2",
    "published": "2025-02-02T12:56:36+00:00",
    "categories": [
      "physics.gen-ph"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00784v1",
    "title": "Estimating forest carbon stocks from high-resolution remote sensing imagery by reducing domain shift with style transfer",
    "authors": [
      "Zhenyu Yu",
      "Jinnian Wang"
    ],
    "abstract": "Forests function as crucial carbon reservoirs on land, and their carbon sinks\ncan efficiently reduce atmospheric CO2 concentrations and mitigate climate\nchange. Currently, the overall trend for monitoring and assessing forest carbon\nstocks is to integrate ground monitoring sample data with satellite remote\nsensing imagery. This style of analysis facilitates large-scale observation.\nHowever, these techniques require improvement in accuracy. We used GF-1 WFV and\nLandsat TM images to analyze Huize County, Qujing City, Yunnan Province in\nChina. Using the style transfer method, we introduced Swin Transformer to\nextract global features through attention mechanisms, converting the carbon\nstock estimation into an image translation.",
    "pdf_url": "http://arxiv.org/pdf/2502.00784v1",
    "published": "2025-02-02T12:45:46+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00783v1",
    "title": "A method for estimating forest carbon storage distribution density via artificial intelligence generated content model",
    "authors": [
      "Zhenyu Yu",
      "Jinnian Wang"
    ],
    "abstract": "Forest is the most significant land-based carbon storage mechanism. The\nforest carbon sink can effectively decrease the atmospheric CO2 concentration\nand mitigate climate change. Remote sensing estimation not only ensures high\naccuracy of data, but also enables large-scale area observation. Optical images\nprovide the possibility for long-term monitoring, which is a potential issue in\nthe future carbon storage estimation research. We chose Huize County, Qujing\nCity, Yunnan Province, China as the study area, took GF-1 WFV satellite image\nas the data, introduced the KD-VGG module to extract the initial features, and\nproposed the improved implicit diffusion model (IIDM). The results showed that:\n(1) The VGG-19 module after knowledge distillation can realize the initial\nfeature extraction, reduce the inference time and improve the accuracy in the\ncase of reducing the number of model parameters. (2) The Attention + MLP module\nwas added for feature fusion to obtain the relationship between global and\nlocal features and realized the restoration of high-fidelity images in the\ncontinuous scale range. (3) The IIDM model proposed in this paper had the\nhighest estimation accuracy, with RMSE of 28.68, which was 13.16 higher than\nthat of the regression model, about 31.45%. In the estimation of carbon\nstorage, the generative model can extract deeper features, and its performance\nwas significantly better than other models. It demonstrated the feasibility of\nartificial intelligence-generated content (AIGC) in the field of quantitative\nremote sensing and provided valuable insights for the study of carbon\nneutralization effect. By combining the actual characteristics of the forest,\nthe regional carbon storage estimation with a resolution of 16-meter was\nutilized to provide a significant theoretical basis for the formulation of\nforest carbon sink regulation.",
    "pdf_url": "http://arxiv.org/pdf/2502.00783v1",
    "published": "2025-02-02T12:41:47+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00782v1",
    "title": "Transfer Learning in Physics-Informed Neural Networks: Full Fine-Tuning, Lightweight Fine-Tuning, and Low-Rank Adaptation",
    "authors": [
      "Yizheng Wang",
      "Jinshuai Bai",
      "Mohammad Sadegh Eshaghi",
      "Cosmin Anitescu",
      "Xiaoying Zhuang",
      "Timon Rabczuk",
      "Yinghua Liu"
    ],
    "abstract": "AI for PDEs has garnered significant attention, particularly Physics-Informed\nNeural Networks (PINNs). However, PINNs are typically limited to solving\nspecific problems, and any changes in problem conditions necessitate\nretraining. Therefore, we explore the generalization capability of transfer\nlearning in the strong and energy form of PINNs across different boundary\nconditions, materials, and geometries. The transfer learning methods we employ\ninclude full finetuning, lightweight finetuning, and Low-Rank Adaptation\n(LoRA). The results demonstrate that full finetuning and LoRA can significantly\nimprove convergence speed while providing a slight enhancement in accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2502.00782v1",
    "published": "2025-02-02T12:40:22+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00780v1",
    "title": "Constructing Fundamentals for the Theory of Proportions and Symbolic Allusions Applied Interdisciplinarily",
    "authors": [
      "Diogen Babuc"
    ],
    "abstract": "The Theory of Proportions and Symbolic Allusions applied Interdisciplinary\n(TPASAI) is a framework that integrates mathematics, linguistics, psychology,\nand game theory to uncover hidden patterns and proportions in reality. Its\ncentral idea is that numerical encoding of symbols, dates, and language can\nreveal recurring structures and connections that reflect universal principles.\nBy applying fractal analysis, the theory identifies patterns across different\nscales, offering a unifying perspective on the structure of the world. One key\naspect of TPASAI is symbolic analysis, which allows for the reinterpretation of\ntraumatic experiences in psychotherapy. For example, assigning numerical values\nto elements like fingers, dates, or words can help individuals uncover\nmeaningful associations between personal experiences and collective symbols.\nThis approach encourages cognitive flexibility and provides a therapeutic\navenue for recontextualizing emotions. The theory also incorporates principles\nof game theory, which frame reality as a system of symbolic \"codes\" governed by\nrules that can be understood and strategically used. This perspective is\nespecially useful for psychological conditions like obsessive-compulsive\ndisorder (OCD), enabling patients to approach their obsessions as decipherable\npatterns rather than rigid constraints. TPASAI has practical applications in\npsychology, education, and technology. In education, it aids in teaching\nmathematical and linguistic concepts by exploring connections between symbolic\nrepresentations and real-world events. In technology, the methodology can be\nemployed in ciphering and natural language processing. The innovation of TPASAI\nlies in its ability to merge the structured rigor of mathematics with the\ninterpretative flexibility of symbolic analysis, offering a deeper\nunderstanding of events and relationships.",
    "pdf_url": "http://arxiv.org/pdf/2502.00780v1",
    "published": "2025-02-02T12:34:01+00:00",
    "categories": [
      "cs.IT",
      "math.IT",
      "q-bio.NC"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00781v2",
    "title": "Spectral transfer for metaplectic groups. II. Hecke algebra correspondences",
    "authors": [
      "Fei Chen",
      "Wen-Wei Li"
    ],
    "abstract": "Let $\\mathrm{Mp}(2n)$ be the metaplectic group over a local field $F \\supset\n\\mathbb{Q}_p$ defined by an additive character of $F$ of conductor\n$4\\mathfrak{o}_F$. Gan-Savin ($p \\neq 2$) and Takeda-Wood ($p=2$) obtained an\nequivalence between the Bernstein block of $\\mathrm{Mp}(2n)$ containing the\neven (resp. odd) Weil representation and the Iwahori-spherical block of the\nsplit $\\mathrm{SO}(2n+1)$ (resp. its non-split inner form), by giving an\nisomorphism between Hecke algebras. We revisit this equivalence from an\nendoscopic perspective. It turns out that the L-parameters of irreducible\nrepresentations are preserved, whilst the difference between characters of\ncomponent groups is governed by symplectic local root numbers.",
    "pdf_url": "http://arxiv.org/pdf/2502.00781v2",
    "published": "2025-02-02T12:34:01+00:00",
    "categories": [
      "math.RT",
      "22E50 (Primary) 11F70, 20C08 (Secondary)"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00779v1",
    "title": "Role of Mixup in Topological Persistence Based Knowledge Distillation for Wearable Sensor Data",
    "authors": [
      "Eun Som Jeon",
      "Hongjun Choi",
      "Matthew P. Buman",
      "Pavan Turaga"
    ],
    "abstract": "The analysis of wearable sensor data has enabled many successes in several\napplications. To represent the high-sampling rate time-series with sufficient\ndetail, the use of topological data analysis (TDA) has been considered, and it\nis found that TDA can complement other time-series features. Nonetheless, due\nto the large time consumption and high computational resource requirements of\nextracting topological features through TDA, it is difficult to deploy\ntopological knowledge in various applications. To tackle this problem,\nknowledge distillation (KD) can be adopted, which is a technique facilitating\nmodel compression and transfer learning to generate a smaller model by\ntransferring knowledge from a larger network. By leveraging multiple teachers\nin KD, both time-series and topological features can be transferred, and\nfinally, a superior student using only time-series data is distilled. On the\nother hand, mixup has been popularly used as a robust data augmentation\ntechnique to enhance model performance during training. Mixup and KD employ\nsimilar learning strategies. In KD, the student model learns from the smoothed\ndistribution generated by the teacher model, while mixup creates smoothed\nlabels by blending two labels. Hence, this common smoothness serves as the\nconnecting link that establishes a connection between these two methods. In\nthis paper, we analyze the role of mixup in KD with time-series as well as\ntopological persistence, employing multiple teachers. We present a\ncomprehensive analysis of various methods in KD and mixup on wearable sensor\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2502.00779v1",
    "published": "2025-02-02T12:33:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00778v1",
    "title": "An Efficient Implementation of Edge-Based Discretization without Forming Dual Control Volumes",
    "authors": [
      "Hiroaki Nishikawa"
    ],
    "abstract": "This paper shows that lumped directed-area vectors at edges and dual control\nvolumes required to implement the edge-based discretization can be computed\nwithout explicitly defining the dual control volume around each node for\ntriangular and tetrahedral grids. It is a simpler implementation because there\nis no need to form a dual control volume by connecting edge-midpoints, face\ncentroids, and element centroids, and also reduces the time for computing\nlumped directed-area vectors for a given grid, especially for tetrahedral\ngrids. The speed-up achieved by the proposed algorithm may not be large enough\nto greatly impact the overall simulation time, but the proposed algorithm is\nexpected to serve as a major stepping stone towards extending the edge-based\ndiscretization to four dimensions and beyond (e.g., space-time simulations).\nEfficient algorithms for computing lumped directed-area vectors and dual\nvolumes without forming dual volumes are presented, and their implementations\nare described and compared with traditional algorithms in terms of complexity\nas well as actual computing time for a given grid.",
    "pdf_url": "http://arxiv.org/pdf/2502.00778v1",
    "published": "2025-02-02T12:32:48+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.DG",
      "physics.comp-ph"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00777v1",
    "title": "A note on involution prefixes in Coxeter groups",
    "authors": [
      "Sarah B. Hart",
      "Peter J. Rowley"
    ],
    "abstract": "Let $(W, R)$ be a Coxeter system and let $w \\in W$. We say that $u$ is a\nprefix of $w$ if there is a reduced expression for $u$ that can be extended to\none for $w$. That is, $w = uv$ for some $v$ in $W$ such that $\\ell(w) = \\ell(u)\n+ \\ell(v)$. We say that $w$ has the ancestor property if the set of prefixes of\n$w$ contains a unique involution of maximal length. In this paper we show that\nall Coxeter elements of finitely generated Coxeter groups have the ancestor\nproperty, and hence a canonical expression as a product of involutions. We\nconjecture that the property in fact holds for all non-identity elements of\nfinite Coxeter groups.",
    "pdf_url": "http://arxiv.org/pdf/2502.00777v1",
    "published": "2025-02-02T12:32:07+00:00",
    "categories": [
      "math.GR",
      "20F55"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00776v2",
    "title": "Coulomb correlated multi-particle polarons",
    "authors": [
      "Petr Klenovsky"
    ],
    "abstract": "The electronic and emission properties of correlated multi-particle states\nare studied theoretically using ${\\bf k}\\cdot{\\bf p}$ and the configuration\ninteraction methods on a well-known and measured GaAs/AlGaAs quantum dots as a\ntest system. The convergence of the calculated energies and radiative lifetimes\nof Coulomb correlated exciton, biexciton, positive and negative trions to\nexperimentally observed values is reached when the electron-electron and\nhole-hole exchange interactions are neglected. That unexpected and striking\nresult uncovers a rich structure of multi-particle states in the studied\nsystem, which is further quantitatively compared to published measurements in\nthe literature, obtaining astonishingly good agreement. It is proposed that in\nreal experiments the neglected electron-electron and hole-hole exchange\ninteractions are emitted as acoustic phonons during the radiative recombination\nof the ground state of complexes, leading to the observation of polaronic\nmulti-particle states. Analysis of their energy spectra provides a direct and\nmeasurable insight into the Coulomb correlation, being interesting both on the\nfundamental level and as possible experimentally tunable property in a wide\nvariety of solid-state systems, in particular associated with quantum\ncomputing.",
    "pdf_url": "http://arxiv.org/pdf/2502.00776v2",
    "published": "2025-02-02T12:22:49+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "math-ph",
      "math.MP",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.00775v2",
    "title": "ATA: Adaptive Task Allocation for Efficient Resource Management in Distributed Machine Learning",
    "authors": [
      "Artavazd Maranjyan",
      "El Mehdi Saad",
      "Peter Richtárik",
      "Francesco Orabona"
    ],
    "abstract": "Asynchronous methods are fundamental for parallelizing computations in\ndistributed machine learning. They aim to accelerate training by fully\nutilizing all available resources. However, their greedy approach can lead to\ninefficiencies using more computation than required, especially when\ncomputation times vary across devices. If the computation times were known in\nadvance, training could be fast and resource-efficient by assigning more tasks\nto faster workers. The challenge lies in achieving this optimal allocation\nwithout prior knowledge of the computation time distributions. In this paper,\nwe propose ATA (Adaptive Task Allocation), a method that adapts to\nheterogeneous and random distributions of worker computation times. Through\nrigorous theoretical analysis, we show that ATA identifies the optimal task\nallocation and performs comparably to methods with prior knowledge of\ncomputation times. Experimental results further demonstrate that ATA is\nresource-efficient, significantly reducing costs compared to the greedy\napproach, which can be arbitrarily expensive depending on the number of\nworkers.",
    "pdf_url": "http://arxiv.org/pdf/2502.00775v2",
    "published": "2025-02-02T12:22:26+00:00",
    "categories": [
      "cs.LG",
      "cs.DC",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00774v1",
    "title": "Character triples and weights",
    "authors": [
      "Zhicheng Feng"
    ],
    "abstract": "We define a new relation between character triples and prove some Clifford\ntheory properties for weights in terms of character triples.",
    "pdf_url": "http://arxiv.org/pdf/2502.00774v1",
    "published": "2025-02-02T12:21:15+00:00",
    "categories": [
      "math.RT",
      "math.GR"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00773v2",
    "title": "Instabilities in visco-thermodiffusive swirling flows",
    "authors": [
      "Oleg N. Kirillov",
      "Innocent Mutabazi"
    ],
    "abstract": "An analytical theory is presented for linear, local, short-wavelength\ninstabilities in swirling flows, in which axial shear, differential rotation,\nradial thermal stratification, viscosity, and thermal diffusivity are all taken\ninto account. A geometrical optics approach is applied to the Navier-Stokes\nequations, coupled with the energy equation, leading to a set of amplitude\ntransport equations. From these, a dispersion relation is derived, capturing\ntwo distinct types of instability: a stationary centrifugal instability and an\noscillatory, visco-diffusive McIntyre instability. Instability regions\ncorresponding to different axial or azimuthal wavenumbers are found to possess\nenvelopes in the plane of physical parameters, which are explicitly determined\nusing the discriminants of polynomials. As these envelopes are shown to bound\nthe union of instability regions associated with particular wavenumbers, it is\nconcluded that the envelopes correspond to curves of critical values of\nphysical parameters, thereby providing compact, closed-form criteria for the\nonset of instability. The derived analytical criteria are validated for\nswirling flows modelled by a cylindrical, differentially rotating annulus with\naxial flow induced by either a sliding inner cylinder, an axial pressure\ngradient, or a radial temperature gradient combined with vertical gravity.\nThese criteria unify and extend, to viscous and thermodiffusive differentially\nheated swirling flows, the Rayleigh criterion for centrifugally driven\ninstabilities, the Ludwieg-Eckhoff-Leibovich-Stewartson criterion for\nisothermal swirling flows, and the Goldreich-Schubert-Fricke criterion for\nnon-isothermal azimuthal flows. Additionally, they predict oscillatory modes in\nswirling, differentially heated, visco-diffusive flows, thereby generalising\nthe McIntyre instability criterion to these systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.00773v2",
    "published": "2025-02-02T12:20:29+00:00",
    "categories": [
      "physics.flu-dyn",
      "math-ph",
      "math.DS",
      "math.MP",
      "physics.ao-ph",
      "physics.geo-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.00772v1",
    "title": "Intermediate dimensions of measures: Interpolating between Hausdorff and Minkowski dimensions",
    "authors": [
      "Nicolas E. Angelini",
      "Ursula M. Molter",
      "Jose M. Tejada"
    ],
    "abstract": "In this paper, we define a family of dimensions for Borel measures that lie\nbetween the Hausdorff and Minkowski dimensions for measures, analogous to the\nintermediate dimensions of sets. Previously, Hare et. al. in [10] defined\nintermediate dimensions that interpolate between the Minkowski and Assouad\ndimensions for measures. Additionally, Fraser, in [7] introduced intermediate\ndimensions that interpolate between the Fourier and Hausdorff dimensions of\nmeasures. Our results address a \"gap\" in the study of dimension interpolation\nfor measures, almost completing the spectrum of intermediate dimensions for\nmeasures: from Fourier to Assouad dimensions.\n  Furthermore, Theorem 3.11 can be interpreted as a \"reverse Frostman\" lemma\nfor intermediate dimensions. We also obtain a capacity-theoretic definition\nthat enables us to estimate the intermediate dimensions of pushforward measures\nby projections.",
    "pdf_url": "http://arxiv.org/pdf/2502.00772v1",
    "published": "2025-02-02T12:18:39+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00771v1",
    "title": "The nucleon structure from an AdS/QCD model in the Veneziano limit",
    "authors": [
      "Jiali Deng",
      "Defu Hou"
    ],
    "abstract": "We employ the VQCD model, a holographic approach that dynamically simulates\nessential QCD characteristics, including linear mass spectra, confinement,\nasymptotic freedom, and magnetic charge screening, while incorporating quark\nflavor effects. Using this model, we first calculate the proton mass spectrum\nand the wave function, incorporating anomalous dimensions to refine our\nresults. Next, we compute the proton structure functions across a range of\nBjorken $x$ values using consistent parameters. Furthermore, we derive the\nproton electromagnetic form factor by solving the electromagnetic field's\nmotion equation, accounting for background effects, and demonstrate qualitative\nconsistency with results from free electromagnetic fields coupled to fermions.\nFinally, we calculate the gravitational form factors by introducing an\neffective graviton mass $m$ arising from chiral symmetry breaking and the\nproton energy-momentum tensor. Our calculations yield results that are in\nexcellent agreement with experimental data and lattice QCD computations,\nvalidating the VQCD model as a robust tool for studying proton properties.",
    "pdf_url": "http://arxiv.org/pdf/2502.00771v1",
    "published": "2025-02-02T12:16:09+00:00",
    "categories": [
      "nucl-th",
      "hep-ph"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.00770v2",
    "title": "A closer look at some cyclic semifields",
    "authors": [
      "Susanne Pumpluen"
    ],
    "abstract": "We show that different choices of generators $\\sigma$ of the Galois group of\n$\\mathbb{F}_{q^n}/\\mathbb{F}_{q}$ produce non-isomorphic cyclic semifields\n$\\mathbb{F}_{q^n}[t;\\sigma]/\\mathbb{F}_{q^n}[t;\\sigma](t^m-a)$ when $n\\geq\nm-1$: there are thus $\\varphi(n)$ non-isomorphic classes of Sandler semifields\n$\\mathbb{F}_{q^n}[t;\\sigma]/\\mathbb{F}_{q^n}[t;\\sigma](t^m-a)$, one class for\neach generator $\\sigma$ involved in their construction, where $\\varphi$ is the\nEuler function. We prove that when $n=m$, two Sandler semifields constructed\nfrom different generators $\\sigma_1$ and $\\sigma_2$ of ${\\rm\nGal}(\\mathbb{F}_{q^n}/\\mathbb{F}_{q})$ are not isotopic. Hence when $n=m$ there\nare $\\varphi(m)$ non-isotopic classes of these semifields, each class belonging\nto one choice of generator. We then present a full parametrization of the\nnon-isomorphic Sandler semifields\n$\\mathbb{F}_{q^m}[t;\\sigma]/\\mathbb{F}_{q^m}[t;\\sigma](t^m-a)$ , when $m$ is\nprime and $\\mathbb{F}_{q}$ contains a primitive $m$th root of unity. Since for\n$m=n$, two Sandler semifields constructed from the same generator are isotopic\nif and only if they are isomorphic, this parametrizes these Sandler semifields\nup to isotopy, and thus parametrizes both the corresponding non-Desarguesian\nprojective planes, and maximum rank distance codes. Most of our results are\nproved in all generality for any cyclic Galois field extension.",
    "pdf_url": "http://arxiv.org/pdf/2502.00770v2",
    "published": "2025-02-02T12:09:24+00:00",
    "categories": [
      "math.RA",
      "math.NT"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00769v2",
    "title": "A Note on Black Hole Entropy and Wormhole Instabilities",
    "authors": [
      "J. L. F. Barbon",
      "E. Velasco-Aja"
    ],
    "abstract": "We discuss recent approaches to the computation of black hole entropies\nthrough semiclassical estimates of appropriate state overlaps, saturated by\nEuclidean wormhole configurations. We notice that the relevant saddle-point\nmanifolds may exhibit instabilities, thereby compromising the interpretation of\nthe Euclidean path integral as a tool for computing positive-definite inner\nproducts. We show that a proper treatment using a microcanonical formulation\neffectively addresses the puzzles posed by these instabilities.",
    "pdf_url": "http://arxiv.org/pdf/2502.00769v2",
    "published": "2025-02-02T12:08:03+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.00768v2",
    "title": "On the Algebraic Independence of $E$- and $G$-Functions, I: A $p$-adic Criterion",
    "authors": [
      "Daniel Vargas-Montoya"
    ],
    "abstract": "Let $K$ be a finite extension of $\\mathbb{Q}_p$, and let $f_1(z),\\ldots,\nf_m(z) \\in K[[z]]$ such that, for every $1 \\leq i \\leq m$, $f_i(z)$ is a\nsolution of a differential operator $\\mathcal{L}_i \\in E_p[d/dz]$, where $E_p$\nis the field of analytic elements. Suppose that $K$ is totally ramified over\n$\\mathbb{Q}_p$, and that for every $1 \\leq i \\leq m$, the operator\n$\\mathcal{L}_i$ has a strong Frobenius structure and satisfies the maximal\norder multiplicity (MOM) condition at zero. Then, we show that $f_1(z),\\ldots,\nf_m(z)$ are algebraically dependent over $E_p$ if and only if there exist\nintegers $a_1,\\ldots, a_m$, not all zero, such that $f_1(z)^{a_1} \\cdots\nf_m(z)^{a_m}\\in E_p$. The main consequence of this result is that it provides a\ntool to study the algebraic independence of a broad class of $G$-functions and\ncertain $E$-functions over the field of analytic elements.",
    "pdf_url": "http://arxiv.org/pdf/2502.00768v2",
    "published": "2025-02-02T12:07:28+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00767v1",
    "title": "Learning-Based TSP-Solvers Tend to Be Overly Greedy",
    "authors": [
      "Xiayang Li",
      "Shihua Zhang"
    ],
    "abstract": "Deep learning has shown significant potential in solving combinatorial\noptimization problems such as the Euclidean traveling salesman problem (TSP).\nHowever, most training and test instances for existing TSP algorithms are\ngenerated randomly from specific distributions like uniform distribution. This\nhas led to a lack of analysis and understanding of the performance of deep\nlearning algorithms in out-of-distribution (OOD) generalization scenarios,\nwhich has a close relationship with the worst-case performance in the\ncombinatorial optimization field. For data-driven algorithms, the statistical\nproperties of randomly generated datasets are critical. This study constructs a\nstatistical measure called nearest-neighbor density to verify the asymptotic\nproperties of randomly generated datasets and reveal the greedy behavior of\nlearning-based solvers, i.e., always choosing the nearest neighbor nodes to\nconstruct the solution path. Based on this statistical measure, we develop\ninterpretable data augmentation methods that rely on distribution shifts or\ninstance perturbations and validate that the performance of the learning-based\nsolvers degenerates much on such augmented data. Moreover, fine-tuning\nlearning-based solvers with augmented data further enhances their\ngeneralization abilities. In short, we decipher the limitations of\nlearning-based TSP solvers tending to be overly greedy, which may have profound\nimplications for AI-empowered combinatorial optimization solvers.",
    "pdf_url": "http://arxiv.org/pdf/2502.00767v1",
    "published": "2025-02-02T12:06:13+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "90C27",
      "I.2.0; I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00766v2",
    "title": "Packaged Quantum States in Field Theory: No Partial Factorization, Multi-Particle Packaging, and Hybrid Gauge-Invariant Entanglement",
    "authors": [
      "Rongchao Ma"
    ],
    "abstract": "We demonstrate that quantum field excitations can generate packaged entangled\nstates, in which all internal quantum numbers (IQNs) (e.g., electric charge,\nflavor, and color) are inseparably entangled and constrained to irreducible\nrepresentation (irrep) blocks. This is a consequence of local gauge invariance\nand superselection rules. The confinement restricts the net gauge charge to a\nsingle superselection sector, thereby excluding cross-sector superpositions but\nallowing entanglement within one sector. We establish theorems that:\n\\textbf{(1)} Explain how these packaged entangled states naturally arise from\nquantum field excitations, \\textbf{(2)} Show how they remain gauge invariant or\ntransform covariantly within a fixed net-charge sector, and \\textbf{(3)}\nIllustrate how external degrees of freedom (DOFs) (e.g., spin or momentum) can\ncombine with packaged internal charges to yield gauge-invariant entanglement.\nFinally, we show that spin or momentum measurements on these hybrid states\ninduce a collapse of the internal entanglement.",
    "pdf_url": "http://arxiv.org/pdf/2502.00766v2",
    "published": "2025-02-02T12:05:27+00:00",
    "categories": [
      "quant-ph",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00765v1",
    "title": "AGNNCert: Defending Graph Neural Networks against Arbitrary Perturbations with Deterministic Certification",
    "authors": [
      "Jiate Li",
      "Binghui Wang"
    ],
    "abstract": "Graph neural networks (GNNs) achieve the state-of-the-art on graph-relevant\ntasks such as node and graph classification. However, recent works show GNNs\nare vulnerable to adversarial perturbations include the perturbation on edges,\nnodes, and node features, the three components forming a graph. Empirical\ndefenses against such attacks are soon broken by adaptive ones. While certified\ndefenses offer robustness guarantees, they face several limitations: 1) almost\nall restrict the adversary's capability to only one type of perturbation, which\nis impractical; 2) all are designed for a particular GNN task, which limits\ntheir applicability; and 3) the robustness guarantees of all methods except one\nare not 100% accurate.\n  We address all these limitations by developing AGNNCert, the first certified\ndefense for GNNs against arbitrary (edge, node, and node feature) perturbations\nwith deterministic robustness guarantees, and applicable to the two most common\nnode and graph classification tasks. AGNNCert also encompass existing certified\ndefenses as special cases. Extensive evaluations on multiple benchmark\nnode/graph classification datasets and two real-world graph datasets, and\nmultiple GNNs validate the effectiveness of AGNNCert to provably defend against\narbitrary perturbations. AGNNCert also shows its superiority over the\nstate-of-the-art certified defenses against the individual edge perturbation\nand node perturbation.",
    "pdf_url": "http://arxiv.org/pdf/2502.00765v1",
    "published": "2025-02-02T11:56:42+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00764v1",
    "title": "Non-Markovian Quantum Jump Method for Driven-Dissipative Two-Level Systems",
    "authors": [
      "Huanyuan Zhang",
      "Jiasen Jin"
    ],
    "abstract": "We propose a modified non-Markovian quantum jump method to overcome the\nobstacle of exponentially increased trajectory number in conventional quantum\ntrajectory simulations. In our method the trajectories are classified into the\ntrajectory classes characterized by the number of quantum jumps. We derive the\nexpression of the existence probability of each trajectory (class) which is\nessential to construct the density matrix of the open quantum system. This\nmodified method costs less computational resource and is more efficient than\nthe conventional quantum trajectory approach. As applications we investigate\nthe dynamics of spin-1/2 systems subject to Lorentzian reservoirs with\nconsidering only the no-jump and one-jump trajectories. The revival of\ncoherence and entanglement induced by the memory effect is observed.",
    "pdf_url": "http://arxiv.org/pdf/2502.00764v1",
    "published": "2025-02-02T11:56:03+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00763v1",
    "title": "Generative AI for Analyzing Participatory Rural Appraisal Data: An Exploratory Case Study in Gender Research",
    "authors": [
      "Srividya Sheshadri",
      "Unnikrishnan Radhakrishnan",
      "Aswathi Padmavilochanan",
      "Christopher Coley",
      "Rao R. Bhavani"
    ],
    "abstract": "This study explores the novel application of Generative Artificial\nIntelligence (GenAI) in analyzing unstructured visual data generated through\nParticipatory Rural Appraisal (PRA), specifically focusing on women's\nempowerment research in rural communities. Using the \"Ideal Village\" PRA\nactivity as a case study, we evaluate three state-of-the-art Large Language\nModels (LLMs) - GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro - in their\nability to interpret hand-drawn artifacts containing multilingual content from\nvarious Indian states. Through comparative analysis, we assess the models'\nperformance across critical dimensions including visual interpretation,\nlanguage translation, and data classification. Our findings reveal significant\nchallenges in AI's current capabilities to process such unstructured data,\nparticularly in handling multilingual content, maintaining contextual accuracy,\nand avoiding hallucinations. While the models showed promise in basic visual\ninterpretation, they struggled with nuanced cultural contexts and consistent\nclassification of empowerment-related elements. This study contributes to both\nAI and gender research by highlighting the potential and limitations of AI in\nanalyzing participatory research data, while emphasizing the need for human\noversight and improved contextual understanding. Our findings suggest future\ndirections for developing more inclusive AI models that can better serve\ncommunity-based participatory research, particularly in gender studies and\nrural development contexts.",
    "pdf_url": "http://arxiv.org/pdf/2502.00763v1",
    "published": "2025-02-02T11:55:52+00:00",
    "categories": [
      "cs.CY",
      "J.4; K.4; I.4"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.00762v2",
    "title": "On Overlap Ratio in Defocused Electron Ptychography",
    "authors": [
      "Amirafshar Moshtaghpour",
      "Angus I. Kirkland"
    ],
    "abstract": "Four-dimensional Scanning Transmission Electron Microscopy (4D STEM) with\ndata acquired using a defocused electron probe is a promising tool for\ncharacterising complex biological specimens and materials through a phase\nretrieval process known as Electron Ptychography (EP). The efficacy of 4D STEM\nacquisition and the resulting quality of EP reconstruction depends on the\noverlap ratio of adjacent illuminated areas. This paper demonstrates how the\noverlap ratio impacts the data redundancy and the quality of the EP\nreconstruction. We define two quantities as a function of the overlap ratio\nthat are independent of both the object and the EP algorithm. Subsequently, we\nevaluate an EP algorithm for varying overlap ratios using simulated 4D STEM\ndatasets. Notably, a 40% or greater overlap ratio yields stable, high-quality\nreconstructions.",
    "pdf_url": "http://arxiv.org/pdf/2502.00762v2",
    "published": "2025-02-02T11:53:55+00:00",
    "categories": [
      "eess.SP",
      "cs.IR",
      "physics.app-ph",
      "physics.med-ph"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.00761v3",
    "title": "FIRE: Flexible Integration of Data Quality Ratings for Effective Pre-Training",
    "authors": [
      "Liangyu Xu",
      "Xuemiao Zhang",
      "Feiyu Duan",
      "Sirui Wang",
      "Rongxiang Weng",
      "Jingang Wang",
      "Xunliang Cai"
    ],
    "abstract": "Selecting high-quality data can improve the pretraining efficiency of large\nlanguage models (LLMs). Existing methods generally rely on heuristic techniques\nor single quality signals, limiting their ability to evaluate data quality\ncomprehensively. In this work, we propose FIRE, a flexible and scalable\nframework for integrating multiple data quality raters, which allows for a\ncomprehensive assessment of data quality across various dimensions. FIRE aligns\nmultiple quality signals into a unified space, and integrates diverse data\nquality raters to provide a comprehensive quality signal for each data point.\nFurther, we introduce a progressive data selection scheme based on FIRE that\niteratively refines the selection of high-quality data points. Extensive\nexperiments show that FIRE outperforms other data selection methods and\nsignificantly boosts pretrained model performance across a wide range of\ndownstream tasks, while requiring less than 37.5\\% of the training data needed\nby the Random baseline to reach the target performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.00761v3",
    "published": "2025-02-02T11:52:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00760v1",
    "title": "Privacy Preserving Properties of Vision Classifiers",
    "authors": [
      "Pirzada Suhail",
      "Amit Sethi"
    ],
    "abstract": "Vision classifiers are often trained on proprietary datasets containing\nsensitive information, yet the models themselves are frequently shared openly\nunder the privacy-preserving assumption. Although these models are assumed to\nprotect sensitive information in their training data, the extent to which this\nassumption holds for different architectures remains unexplored. This\nassumption is challenged by inversion attacks which attempt to reconstruct\ntraining data from model weights, exposing significant privacy vulnerabilities.\nIn this study, we systematically evaluate the privacy-preserving properties of\nvision classifiers across diverse architectures, including Multi-Layer\nPerceptrons (MLPs), Convolutional Neural Networks (CNNs), and Vision\nTransformers (ViTs). Using network inversion-based reconstruction techniques,\nwe assess the extent to which these architectures memorize and reveal training\ndata, quantifying the relative ease of reconstruction across models. Our\nanalysis highlights how architectural differences, such as input\nrepresentation, feature extraction mechanisms, and weight structures, influence\nprivacy risks. By comparing these architectures, we identify which are more\nresilient to inversion attacks and examine the trade-offs between model\nperformance and privacy preservation, contributing to the development of secure\nand privacy-respecting machine learning models for sensitive applications. Our\nfindings provide actionable insights into the design of secure and\nprivacy-aware machine learning systems, emphasizing the importance of\nevaluating architectural decisions in sensitive applications involving\nproprietary or personal data.",
    "pdf_url": "http://arxiv.org/pdf/2502.00760v1",
    "published": "2025-02-02T11:50:00+00:00",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00759v2",
    "title": "Almost sure central limit theorems via chaos expansions and related results",
    "authors": [
      "Leonardo Maini",
      "Maurizia Rossi",
      "Guangqu Zheng"
    ],
    "abstract": "In this work, we investigate the asymptotic behavior of integral functionals\nof stationary Gaussian random fields as the integration domain tends to be the\nwhole space. More precisely, using the Wiener chaos expansion and\nMalliavin-Stein method, we establish an almost sure central limit theorem\n(ASCLT) only under mild conditions on the covariance function of the underlying\nstationary Gaussian field. In this setting, we additionally derive a\nquantitative central limit theorem with rate of convergence in Wasserstein\ndistance, and show certain regularity property for the said integral\nfunctionals (the latter under weaker conditions). In particular, we solved an\nopen question on the Malliavin differentiability of the excursion volume of\nBerry's random wave model. As a key consequence of our analysis, we obtain the\nexact asymptotic rate (as a function of the exponent) for moments of Bessel\nfunctions, thus confirming a conjecture based on existing numerical\nsimulations. In the end, we provide two applications of our result: (i) ASCLT\nin the context of Breuer-Major central limit theorems, (ii) ASCLT for Berry's\nrandom wave model. It is worth stressing that our approach does not require any\nknowledge on the regularity properties of random variables (e.g., Malliavin\ndifferentiability) and hence not only complements the existing literature, but\nalso leads to novel results that are of independent interest.",
    "pdf_url": "http://arxiv.org/pdf/2502.00759v2",
    "published": "2025-02-02T11:46:39+00:00",
    "categories": [
      "math.PR",
      "60F05, 60F15, 60H30"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00758v2",
    "title": "Structural Latency Perturbation in Large Language Models Through Recursive State Induction",
    "authors": [
      "Michael Mangrum",
      "Jonathan Pemberton",
      "Benedict Wetherby",
      "Philip Montague"
    ],
    "abstract": "Computational efficiency has remained a critical consideration in scaling\nhigh-capacity language models, with inference latency and resource consumption\npresenting significant constraints on real-time applications. The study has\nintroduced a structured latency perturbation mechanism that modifies\ncomputational pathways through recursive state induction, enabling dynamic\nsuppression of redundant activations while preserving generative fidelity. A\nformal mathematical framework has been established to describe recursive\nperturbations, ensuring that modifications remain adaptive rather than\nstatically imposed. Experiments have demonstrated that applying recursive state\nadjustments reduces inference latency across varying sequence lengths, with\nlonger text generations benefiting from cumulative efficiency improvements.\nComparative evaluations against structured pruning and quantization have\nindicated that latency gains can be achieved without compromising token\nretention or memory utilization. The analysis of computational overhead has\nsuggested that selectively suppressing redundant activations contributes to\nimproved power efficiency, particularly in scenarios requiring extended text\ngeneration. An assessment of linguistic stability has shown that token-level\nconsistency remains largely intact under controlled perturbation thresholds,\nreinforcing the viability of structural latency modifications as an alternative\nto weight-centric optimization techniques. The results have supported the\nhypothesis that recursive state induction offers an effective method for\nreducing computational complexity without requiring architectural modifications\nor external augmentation.",
    "pdf_url": "http://arxiv.org/pdf/2502.00758v2",
    "published": "2025-02-02T11:45:35+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00757v3",
    "title": "AgentBreeder: Mitigating the AI Safety Impact of Multi-Agent Scaffolds via Self-Improvement",
    "authors": [
      "J Rosser",
      "Jakob Nicolaus Foerster"
    ],
    "abstract": "Scaffolding Large Language Models (LLMs) into multi-agent systems often\nimproves performance on complex tasks, but the safety impact of such scaffolds\nhas not been thoroughly explored. We introduce AgentBreeder, a framework for\nmulti-objective self-improving evolutionary search over scaffolds. We evaluate\ndiscovered scaffolds on widely recognized reasoning, mathematics, and safety\nbenchmarks and compare them with popular baselines. In 'blue' mode, we see a\n79.4% average uplift in safety benchmark performance while maintaining or\nimproving capability scores. In 'red' mode, we find adversarially weak\nscaffolds emerging concurrently with capability optimization. Our work\ndemonstrates the risks of multi-agent scaffolding and provides a framework for\nmitigating them. Code is available at\nhttps://github.com/J-Rosser-UK/AgentBreeder.",
    "pdf_url": "http://arxiv.org/pdf/2502.00757v3",
    "published": "2025-02-02T11:40:07+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NE",
      "68T42, 68T50",
      "I.2.11"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00756v1",
    "title": "Hamiltonian dynamics and geometry on the two-plectic six-sphere",
    "authors": [
      "Maxime Wagner",
      "Tilmann Wurzbacher"
    ],
    "abstract": "We study the two-plectic geometry of the six-sphere induced by pulling back a\ncanonical $G_2$-invariant three-form from $\\mathbb{R}^7$ . Notably we\nexplicitly prove non-flatness of this structure and show that its infinitesimal\nautomorphisms are given by the exceptional Lie algebra $\\mathfrak{g}_2$.\nSeveral interesting classes of solutions of the dynamical Hamilton-de\nDonder-Weyl equations with one- and two-dimensional sources are exhibited.",
    "pdf_url": "http://arxiv.org/pdf/2502.00756v1",
    "published": "2025-02-02T11:39:58+00:00",
    "categories": [
      "math.DG",
      "math-ph",
      "math.MP",
      "math.SG",
      "53C15, 53D05, 70G45, 70H05"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00755v1",
    "title": "Optimal domain of Volterra operators in Korenblum spaces",
    "authors": [
      "Angela A. Albanese",
      "José Bonet",
      "Werner J. Ricker"
    ],
    "abstract": "The aim of this article is to study the largest domain space $[T,X]$,\nwhenever it exists, of a given continuous linear operator $T\\colon X\\to X$,\nwhere $X\\subseteq H(\\mathbb{D})$ is a Banach space of analytic functions on the\nopen unit disc $\\mathbb{D}\\subseteq \\mathbb{C}$. That is, $[T,X]\\subseteq\nH(\\mathbb{D})$ is the \\textit{largest} Banach space of analytic functions\ncontaining $X$ to which $T$ has a continuous, linear, $X$-valued extension\n$T\\colon [T,X]\\to X$. The class of operators considered consists of generalized\nVolterra operators $T$ acting in the Korenblum growth Banach spaces\n$X:=A^{-\\gamma}$, for $\\gamma>0$. Previous studies dealt with the classical\nCes\\`aro operator $T:=C$ acting in the Hardy spaces $H^p$, $1\\leq p<\\infty$,\n\\cite{CR}, \\cite{CR1}, in $A^{-\\gamma}$, \\cite{ABR-R}, and more recently,\ngeneralized Volterra operators $T$ acting in $X:=H^p$, \\cite{BDNS}.",
    "pdf_url": "http://arxiv.org/pdf/2502.00755v1",
    "published": "2025-02-02T11:33:35+00:00",
    "categories": [
      "math.FA",
      "Primary 46E15, 47B38, Secondary 46E10, 47A10, 47A16, 47A35 47A16,\n  47A35"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00754v1",
    "title": "Continuity-Preserving Convolutional Autoencoders for Learning Continuous Latent Dynamical Models from Images",
    "authors": [
      "Aiqing Zhu",
      "Yuting Pan",
      "Qianxiao Li"
    ],
    "abstract": "Continuous dynamical systems are cornerstones of many scientific and\nengineering disciplines. While machine learning offers powerful tools to model\nthese systems from trajectory data, challenges arise when these trajectories\nare captured as images, resulting in pixel-level observations that are discrete\nin nature. Consequently, a naive application of a convolutional autoencoder can\nresult in latent coordinates that are discontinuous in time. To resolve this,\nwe propose continuity-preserving convolutional autoencoders (CpAEs) to learn\ncontinuous latent states and their corresponding continuous latent dynamical\nmodels from discrete image frames. We present a mathematical formulation for\nlearning dynamics from image frames, which illustrates issues with previous\napproaches and motivates our methodology based on promoting the continuity of\nconvolution filters, thereby preserving the continuity of the latent states.\nThis approach enables CpAEs to produce latent states that evolve continuously\nwith the underlying dynamics, leading to more accurate latent dynamical models.\nExtensive experiments across various scenarios demonstrate the effectiveness of\nCpAEs.",
    "pdf_url": "http://arxiv.org/pdf/2502.00754v1",
    "published": "2025-02-02T11:31:58+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00753v2",
    "title": "Mirror Descent Under Generalized Smoothness",
    "authors": [
      "Dingzhi Yu",
      "Wei Jiang",
      "Yuanyu Wan",
      "Lijun Zhang"
    ],
    "abstract": "Smoothness is crucial for attaining fast rates in first-order optimization.\nHowever, many optimization problems in modern machine learning involve\nnon-smooth objectives. Recent studies relax the smoothness assumption by\nallowing the Lipschitz constant of the gradient to grow with respect to the\ngradient norm, which accommodates a broad range of objectives in practice.\nDespite this progress, existing generalizations of smoothness are restricted to\nEuclidean geometry with $\\ell_2$-norm and only have theoretical guarantees for\noptimization in the Euclidean space. In this paper, we address this limitation\nby introducing a new $\\ell*$-smoothness concept that measures the norm of\nHessians in terms of a general norm and its dual, and establish convergence for\nmirror-descent-type algorithms, matching the rates under the classic\nsmoothness. Notably, we propose a generalized self-bounding property that\nfacilitates bounding the gradients via controlling suboptimality gaps, serving\nas a principal component for convergence analysis. Beyond deterministic\noptimization, we establish an anytime convergence for stochastic mirror descent\nbased on a new bounded noise condition that encompasses the widely adopted\nbounded or affine noise assumptions.",
    "pdf_url": "http://arxiv.org/pdf/2502.00753v2",
    "published": "2025-02-02T11:23:10+00:00",
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00752v1",
    "title": "Zero-Shot Warning Generation for Misinformative Multimodal Content",
    "authors": [
      "Giovanni Pio Delvecchio",
      "Huy Hong Nguyen",
      "Isao Echizen"
    ],
    "abstract": "The widespread prevalence of misinformation poses significant societal\nconcerns. Out-of-context misinformation, where authentic images are paired with\nfalse text, is particularly deceptive and easily misleads audiences. Most\nexisting detection methods primarily evaluate image-text consistency but often\nlack sufficient explanations, which are essential for effectively debunking\nmisinformation. We present a model that detects multimodal misinformation\nthrough cross-modality consistency checks, requiring minimal training time.\nAdditionally, we propose a lightweight model that achieves competitive\nperformance using only one-third of the parameters. We also introduce a\ndual-purpose zero-shot learning task for generating contextualized warnings,\nenabling automated debunking and enhancing user comprehension. Qualitative and\nhuman evaluations of the generated warnings highlight both the potential and\nlimitations of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2502.00752v1",
    "published": "2025-02-02T11:18:05+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00751v1",
    "title": "Online Generalized Method of Moments for Time Series",
    "authors": [
      "Man Fung Leung",
      "Kin Wai Chan",
      "Xiaofeng Shao"
    ],
    "abstract": "Online learning has gained popularity in recent years due to the urgent need\nto analyse large-scale streaming data, which can be collected in perpetuity and\nserially dependent. This motivates us to develop the online generalized method\nof moments (OGMM), an explicitly updated estimation and inference framework in\nthe time series setting. The OGMM inherits many properties of offline GMM, such\nas its broad applicability to many problems in econometrics and statistics,\nnatural accommodation for over-identification, and achievement of\nsemiparametric efficiency under temporal dependence. As an online method, the\nkey gain relative to offline GMM is the vast improvement in time complexity and\nmemory requirement.\n  Building on the OGMM framework, we propose improved versions of online\nSargan--Hansen and structural stability tests following recent work in\neconometrics and statistics. Through Monte Carlo simulations, we observe\nencouraging finite-sample performance in online instrumental variables\nregression, online over-identifying restrictions test, online quantile\nregression, and online anomaly detection. Interesting applications of OGMM to\nstochastic volatility modelling and inertial sensor calibration are presented\nto demonstrate the effectiveness of OGMM.",
    "pdf_url": "http://arxiv.org/pdf/2502.00751v1",
    "published": "2025-02-02T11:16:20+00:00",
    "categories": [
      "stat.ME",
      "econ.EM",
      "62L12, 62M15 (Primary) 62J20 (Secondary)"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.07800v1",
    "title": "neuro2voc: Decoding Vocalizations from Neural Activity",
    "authors": [
      "Fei Gao"
    ],
    "abstract": "Accurate decoding of neural spike trains and relating them to motor output is\na challenging task due to the inherent sparsity and length in neural spikes and\nthe complexity of brain circuits. This master project investigates experimental\nmethods for decoding zebra finch motor outputs (in both discrete syllables and\ncontinuous spectrograms), from invasive neural recordings obtained from\nNeuropixels.\n  There are three major achievements: (1) XGBoost with SHAP analysis trained on\nspike rates revealed neuronal interaction patterns crucial for syllable\nclassification. (2) Novel method (tokenizing neural data with GPT2) and\narchitecture (Mamba2) demonstrated potential for decoding of syllables using\nspikes. (3) A combined contrastive learning-VAE framework successfully\ngenerated spectrograms from binned neural data.\n  This work establishes a promising foundation for neural decoding of complex\nmotor outputs and offers several novel methodological approaches for processing\nsparse neural data.",
    "pdf_url": "http://arxiv.org/pdf/2502.07800v1",
    "published": "2025-02-02T11:09:31+00:00",
    "categories": [
      "q-bio.NC",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00750v1",
    "title": "Guiding, not Driving: Design and Evaluation of a Command-Based User Interface for Teleoperation of Autonomous Vehicles",
    "authors": [
      "Felix Tener",
      "Joel Lanir"
    ],
    "abstract": "Autonomous vehicles (AVs) are rapidly evolving as an innovative mode of\ntransportation. However, the consensus in both industry and academia is that\nAVs cannot independently resolve all traffic scenarios. Consequently, the need\nfor remote human assistance becomes clear. To enable the widespread integration\nof AVs on public roadways, it is imperative to develop novel models for remote\noperation. One such model is tele-assistance, which promotes delegating\nlow-level maneuvers to automation through high-level directives. Our study\ninvestigates the design and evaluation of a new command-based tele-assistance\nuser interface for the teleoperation of AVs. First, by integrating various\ncontrol paradigms and interaction concepts, we created a simulation-based,\nhigh-fidelity interactive prototype consisting of 175 screens. Next, we\nconducted a comprehensive usability study with 14 expert teleoperators to\nassess the acceptance and usability of the system. Finally, we formulated\nhigh-level insights and guidelines for designing command-based user interfaces\nfor the remote operation of AVs.",
    "pdf_url": "http://arxiv.org/pdf/2502.00750v1",
    "published": "2025-02-02T10:57:51+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00749v1",
    "title": "An Event-Based Perception Pipeline for a Table Tennis Robot",
    "authors": [
      "Andreas Ziegler",
      "Thomas Gossard",
      "Arren Glover",
      "Andreas Zell"
    ],
    "abstract": "Table tennis robots gained traction over the last years and have become a\npopular research challenge for control and perception algorithms. Fast and\naccurate ball detection is crucial for enabling a robotic arm to rally the ball\nback successfully. So far, most table tennis robots use conventional,\nframe-based cameras for the perception pipeline. However, frame-based cameras\nsuffer from motion blur if the frame rate is not high enough for fast-moving\nobjects. Event-based cameras, on the other hand, do not have this drawback\nsince pixels report changes in intensity asynchronously and independently,\nleading to an event stream with a temporal resolution on the order of us. To\nthe best of our knowledge, we present the first real-time perception pipeline\nfor a table tennis robot that uses only event-based cameras. We show that\ncompared to a frame-based pipeline, event-based perception pipelines have an\nupdate rate which is an order of magnitude higher. This is beneficial for the\nestimation and prediction of the ball's position, velocity, and spin, resulting\nin lower mean errors and uncertainties. These improvements are an advantage for\nthe robot control, which has to be fast, given the short time a table tennis\nball is flying until the robot has to hit back.",
    "pdf_url": "http://arxiv.org/pdf/2502.00749v1",
    "published": "2025-02-02T10:56:37+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00748v1",
    "title": "Double-beta decay of $^{150}$Nd to excited levels of $^{150}$Sm",
    "authors": [
      "A. S. Barabash",
      "P. Belli",
      "R. Bernabei",
      "R. S. Boiko",
      "F. Cappella",
      "V. Caracciolo",
      "R. Cerulli",
      "F. A. Danevich",
      "D. L. Fang",
      "F. Ferella",
      "A. Incicchitti",
      "V. V. Kobychev",
      "S. I. Konovalov",
      "M. Laubenstein",
      "A. Leoncini",
      "V. Merlo",
      "S. Nisi",
      "O. Nitescu",
      "D. V. Poda",
      "O. G. Polischuk",
      "I. B. -K. Shcherbakov",
      "F. Simkovic",
      "A. Timonina",
      "V. S. Tinkova",
      "V. I. Tretyak",
      "V. I. Umatov"
    ],
    "abstract": "The $2\\nu2\\beta$ decay of $^{150}$Nd to the first excited 740.5 keV\n$0^{+}_{1}$ level of $^{150}$Sm was measured over 5.845 yr with the help of a\nfour-crystal low-background HPGe $\\gamma$ spectrometry system in the\nunderground low-background laboratory STELLA of LNGS-INFN. A 2.381 kg highly\npurified Nd-containing sample was employed as the decay source. The expected\nde-excitation gamma-quanta of the $0^{+}_{1}$ level with energies 334.0 keV and\n406.5 keV were observed both in one-dimensional spectrum and in coincidence\ndata resulting in the half-life\n$T_{1/2}=[0.83^{+0.18}_{-0.13}\\mathrm{(stat)}^{+0.16}_{-0.19}\\mathrm{(syst)}]\\times\n10^{20}$ yr. Interpreting an excess of the 334.0-keV peak area as an indication\nof the $2\\beta$ decay of $^{150}$Nd to the 334.0 keV $2^+_1$ excited level of\n$^{150}$Sm with a half-life of $T_{1/2}=[1.5^{+2.3}_{-0.6}\\mathrm{(stat)}\\pm\n0.4\\mathrm{(syst)}]\\times10^{20}$ yr, the $2\\nu2\\beta$ half-life of $^{150}$Nd\nfor the transition to the 0$^{+}_{1}$ level is\n$T_{1/2}=[1.03^{+0.35}_{-0.22}\\mathrm{(stat)}^{+0.16}_{-0.19}\\mathrm{(syst)}]\\times\n10^{20}$ yr, in agreement with the previous experiments. Both half-life values\nreasonably agree with the theoretical calculations in the framework of\nproton-neutron QRPA with isospin restoration combined with like nucleon QRPA\nfor description of excited states in the final nuclei. For $2\\nu2\\beta$ and\n$0\\nu2\\beta$ transitions of $^{150}$Nd and $^{148}$Nd to several excited levels\nof $^{150}$Sm and $^{148}$Sm, limits were set at level of\n$T_{1/2}>10^{20}-10^{21}$ yr.",
    "pdf_url": "http://arxiv.org/pdf/2502.00748v1",
    "published": "2025-02-02T10:54:43+00:00",
    "categories": [
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2502.00747v1",
    "title": "Universal Post-Processing Networks for Joint Optimization of Modules in Task-Oriented Dialogue Systems",
    "authors": [
      "Atsumoto Ohashi",
      "Ryuichiro Higashinaka"
    ],
    "abstract": "Post-processing networks (PPNs) are components that modify the outputs of\narbitrary modules in task-oriented dialogue systems and are optimized using\nreinforcement learning (RL) to improve the overall task completion capability\nof the system. However, previous PPN-based approaches have been limited to\nhandling only a subset of modules within a system, which poses a significant\nlimitation in improving the system performance. In this study, we propose a\njoint optimization method for post-processing the outputs of all modules using\nuniversal post-processing networks (UniPPNs), which are language-model-based\nnetworks that can modify the outputs of arbitrary modules in a system as a\nsequence-transformation task. Moreover, our RL algorithm, which employs a\nmodule-level Markov decision process, enables fine-grained value and advantage\nestimation for each module, thereby stabilizing joint learning for\npost-processing the outputs of all modules. Through both simulation-based and\nhuman evaluation experiments using the MultiWOZ dataset, we demonstrated that\nUniPPN outperforms conventional PPNs in the task completion capability of\ntask-oriented dialogue systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.00747v1",
    "published": "2025-02-02T10:46:37+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00746v1",
    "title": "The Hartman-Stampacchia Theorem and the Maximum Displacements of Nonvanishing Continuous Vector-Valued Functions",
    "authors": [
      "Nguyen Nang Thieu",
      "Nguyen Dong Yen"
    ],
    "abstract": "This paper aims at giving solutions to six interesting interconnected open\nquestions suggested by Professor Biagio Ricceri. The questions focus on the\nbehavior of nonvanishing continuous vector-valued functions in\nfinite-dimensional normed spaces as well as in infinite-dimensional normed\nspaces. Using the celebrated Hartman-Stampacchia Theorem (1966) on the solution\nexistence of variational inequalities, we establish sharp lower estimates for\nthe maximum displacements of nonvanishing continuous vector-valued functions.\nThen, combining the obtained results with suitable tools from functional\nanalysis and several novel geometrical constructions, we get the\nabove-mentioned solutions.",
    "pdf_url": "http://arxiv.org/pdf/2502.00746v1",
    "published": "2025-02-02T10:43:31+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2502.01686v2",
    "title": "Energetically consistent localised APE budgets for local and regional studies of stratified flow energetics",
    "authors": [
      "Remi Tailleux",
      "Guillaume Roullet"
    ],
    "abstract": "Because it allows a rigorous separation between reversible and irreversible\nprocesses, the concept of available potential energy (APE) has become central\nto the study of turbulent stratified fluids. In ocean modelling, it is\nfundamental to the parameterisation of meso-scale ocean eddies and of the\nturbulent mixing of heat and salt. However, how to apply APE theory\nconsistently to local or regional subdomains has been a longstanding source of\nconfusion due to the globally defined Lorenz reference state entering the\ndefinition of APE and of buoyancy forces being generally thought to be\nmeaningless in those cases. In practice, this is often remedied by introducing\nheuristic `localised' forms of APE density depending uniquely on\nregion-specific reference states, possibly diverging significantly from the\nglobal Lorenz reference state. In this paper, we argue that across-scale energy\ntransfers can only be consistently described if localised forms of APE density\nare defined as the eddy APE component of an exact mean/eddy decomposition of\nthe APE density, for which a new physically more intuitive and mathematically\nsimpler framework is proposed. The eddy APE density thus defined exhibits a\nmuch weaker dependency on the global Lorenz reference state than the mean APE,\nin agreement with physical intuition, but with a different structure than that\nof existing heuristic localised APE forms. Our framework establishes a rigorous\nphysical basis for linking parameterised energy transfers to molecular viscous\nand diffusive dissipation rates. We illustrate its potential usefulness by\ndiscussing the energetics implications of standard advective and diffusive\nparameterisations of the turbulent density flux, which reveals potential new\nsources of numerical instability in ocean models.",
    "pdf_url": "http://arxiv.org/pdf/2502.01686v2",
    "published": "2025-02-02T10:42:36+00:00",
    "categories": [
      "physics.ao-ph",
      "physics.flu-dyn"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00745v1",
    "title": "BEEM: Boosting Performance of Early Exit DNNs using Multi-Exit Classifiers as Experts",
    "authors": [
      "Divya Jyoti Bajpai",
      "Manjesh Kumar Hanawal"
    ],
    "abstract": "Early Exit (EE) techniques have emerged as a means to reduce inference\nlatency in Deep Neural Networks (DNNs). The latency improvement and accuracy in\nthese techniques crucially depend on the criteria used to make exit decisions.\nWe propose a new decision criterion where exit classifiers are treated as\nexperts BEEM and aggregate their confidence scores. The confidence scores are\naggregated only if neighbouring experts are consistent in prediction as the\nsamples pass through them, thus capturing their ensemble effect. A sample exits\nwhen the aggregated confidence value exceeds a threshold. The threshold is set\nusing the error rates of the intermediate exits aiming to surpass the\nperformance of conventional DNN inference. Experimental results on the COCO\ndataset for Image captioning and GLUE datasets for various language tasks\ndemonstrate that our method enhances the performance of state-of-the-art EE\nmethods, achieving improvements in speed-up by a factor 1.5x to 2.1x. When\ncompared to the final layer, its accuracy is comparable in harder Image\nCaptioning and improves in the easier language tasks. The source code for this\nwork is publicly available at https://github.com/Div290/BEEM1/tree/main",
    "pdf_url": "http://arxiv.org/pdf/2502.00745v1",
    "published": "2025-02-02T10:35:19+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00744v2",
    "title": "CoNNect: Connectivity-Based Regularization for Structural Pruning",
    "authors": [
      "Christian Franssen",
      "Jinyang Jiang",
      "Yijie Peng",
      "Bernd Heidergott"
    ],
    "abstract": "Pruning encompasses a range of techniques aimed at increasing the sparsity of\nneural networks (NNs). These techniques can generally be framed as minimizing a\nloss function subject to an $L_0$ norm constraint. This paper introduces\nCoNNect, a novel differentiable regularizer for sparse NN training that ensures\nconnectivity between input and output layers. We prove that CoNNect\napproximates $L_0$ regularization, guaranteeing maximally connected network\nstructures while avoiding issues like layer collapse. Moreover, CoNNect is\neasily integrated with established structural pruning strategies. Numerical\nexperiments demonstrate that CoNNect can improve classical pruning strategies\nand enhance state-of-the-art one-shot pruners, such as DepGraph and LLM-pruner.",
    "pdf_url": "http://arxiv.org/pdf/2502.00744v2",
    "published": "2025-02-02T10:32:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00743v1",
    "title": "Green peas in the southern sky: Broad-band color selection and spectroscopic follow up",
    "authors": [
      "Yejin Jeong",
      "Hyunjin Shim",
      "Eunchong Kim",
      "Jeong Hwan Lee"
    ],
    "abstract": "We present a systematic search for 1696 Green Pea (GP) galaxy candidates in\nthe southern hemisphere selected from the Dark Energy Survey Data Release 2\n(DES DR2) and provide preliminary results from spectroscopic follow-up\nobservations of 26 targets chosen among them. Our selection criteria include\nthe colors in $gri$-bands and compact morphology in the color composite images.\nThe multi-wavelength spectral energy distribution fitting shows that the\nselected GP candidates exhibit star formation rates up to several tens\n$\\mathrm{M}_\\odot\\,\\mathrm{yr}^{-1}$. With the mean stellar mass of\n$\\mathrm{log}\\,M_*/\\mathrm{M}_\\odot=8.6$, GP candidates are located at roughly\n1 dex above the main sequence of star-forming galaxies at $z\\sim0.3$.\nSpectroscopic follow-up observations of the GP candidates with Gemini/GMOS are\nunderway. All 26 targets are spectroscopically confirmed to be at $z=0.3-0.41$\nand have [OIII] equivalent width larger than 85$\\r{A}$, classified to be\nstarbursts with low to moderate dust attenuation. These confirmed GPs show a\nlower metallicity offset from the mass-metallicity relation of local\nstar-forming galaxies, indicating that GPs are less chemically evolved systems\nat their early stage of evolution.",
    "pdf_url": "http://arxiv.org/pdf/2502.00743v1",
    "published": "2025-02-02T10:30:24+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00742v1",
    "title": "An alternative $\\mathbb{Q}$-form of the cyclotomic double shuffle Lie algebra",
    "authors": [
      "Hidekazu Furusho",
      "Khalef Yaddaden"
    ],
    "abstract": "We present an alternative $\\mathbb{Q}$-form for Racinet's cyclotomic double\nshuffle Lie algebra, inspired by the double shuffle relations among congruent\nmultiple zeta values studied by Yuan and Zhao. Our main result establishes an\ninvariance characterization theorem, demonstrating how these two\n$\\mathbb{Q}$-forms can be reconstructed from each other under Galois action.",
    "pdf_url": "http://arxiv.org/pdf/2502.00742v1",
    "published": "2025-02-02T10:28:40+00:00",
    "categories": [
      "math.NT",
      "math.QA",
      "Primary 11M32, 16T05. Secondary 11F32"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00741v1",
    "title": "Fabrication of Fibers with Complex Features Using Thermal Drawing of 3D-Printed Preforms",
    "authors": [
      "Ali Anil Demircali",
      "Jinshi Zhao",
      "Ayhan Aktas",
      "Mohamed EMK Abdelaziz",
      "Burak Temelkuran"
    ],
    "abstract": "High-aspect-ratio polymer materials are widely utilized in applications\nranging from everyday materials such as clothing to specialized equipment in\nindustrial and medical fields. Traditional fabrication methods, such as\nextrusion and molding, face challenges in integrating diverse materials and\nachieving complex geometries. Additionally, these methods are limited in their\nability to provide low-cost and rapid prototyping, which are critical for\nresearch and development processes. In this work, we investigated the use of\ncommercially available 3D printers to fabricate fiber preforms, which were\nsubsequently thermally drawn into fibers. By optimizing 3D printing parameters,\nwe achieved the fabrication of fibers with diameters as small as 200 um having\ncomplex shapes, with features down to a few microns. We demonstrated the\nversatility of this method by fabricating fibers from diverse set of materials,\nsuch as fibers with different stiffnesses and fibers with magnetic\ncharacteristics, which are beneficial for developing tendon-driven and\nmagnetically actuated robotic fibers. In addition, by designing novel preform\ngeometries, we produced tapered fibers and fibers with interlocking mechanisms,\nalso tailored for use in medical steerable catheter applications. These\nadvancements highlight the scalability and versatility of this approach,\noffering a robust platform for producing high-precision polymer fibers for\ndiverse applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.00741v1",
    "published": "2025-02-02T10:28:27+00:00",
    "categories": [
      "physics.med-ph"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.01685v1",
    "title": "Automated Extraction of Spatio-Semantic Graphs for Identifying Cognitive Impairment",
    "authors": [
      "Si-Ioi Ng",
      "Pranav S. Ambadi",
      "Kimberly D. Mueller",
      "Julie Liss",
      "Visar Berisha"
    ],
    "abstract": "Existing methods for analyzing linguistic content from picture descriptions\nfor assessment of cognitive-linguistic impairment often overlook the\nparticipant's visual narrative path, which typically requires eye tracking to\nassess. Spatio-semantic graphs are a useful tool for analyzing this narrative\npath from transcripts alone, however they are limited by the need for manual\ntagging of content information units (CIUs). In this paper, we propose an\nautomated approach for estimation of spatio-semantic graphs (via automated\nextraction of CIUs) from the Cookie Theft picture commonly used in\ncognitive-linguistic analyses. The method enables the automatic\ncharacterization of the visual semantic path during picture description.\nExperiments demonstrate that the automatic spatio-semantic graphs effectively\ndifferentiate between cognitively impaired and unimpaired speakers. Statistical\nanalyses reveal that the features derived by the automated method produce\ncomparable results to the manual method, with even greater group differences\nbetween clinical groups of interest. These results highlight the potential of\nthe automated approach for extracting spatio-semantic features in developing\nclinical speech models for cognitive impairment assessment.",
    "pdf_url": "http://arxiv.org/pdf/2502.01685v1",
    "published": "2025-02-02T10:25:19+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00740v3",
    "title": "Floating exercise boundaries for American options in time-inhomogeneous models",
    "authors": [
      "Andrey Itkin",
      "Yerkin Kitapbayev"
    ],
    "abstract": "This paper examines a semi-analytical approach for pricing American options\nin time-inhomogeneous models characterized by negative interest rates (for\nequity/FX) or negative convenience yields (for commodities/cryptocurrencies).\nUnder such conditions, exercise boundaries may exhibit a \"floating\" structure -\ndynamically appearing and disappearing. For example, a second exercise boundary\ncould emerge within the computational domain and subsequently both could\ncollapse, demanding specialized pricing methodologies.",
    "pdf_url": "http://arxiv.org/pdf/2502.00740v3",
    "published": "2025-02-02T10:21:22+00:00",
    "categories": [
      "q-fin.PR",
      "q-fin.CP",
      "q-fin.MF"
    ],
    "primary_category": "q-fin.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00739v1",
    "title": "Orlicz-Sobolev Transport for Unbalanced Measures on a Graph",
    "authors": [
      "Tam Le",
      "Truyen Nguyen",
      "Hideitsu Hino",
      "Kenji Fukumizu"
    ],
    "abstract": "Moving beyond $L^p$ geometric structure, Orlicz-Wasserstein (OW) leverages a\nspecific class of convex functions for Orlicz geometric structure. While OW\nremarkably helps to advance certain machine learning approaches, it has a high\ncomputational complexity due to its two-level optimization formula. Recently,\nLe et al. (2024) exploits graph structure to propose generalized Sobolev\ntransport (GST), i.e., a scalable variant for OW. However, GST assumes that\ninput measures have the same mass. Unlike optimal transport (OT), it is\nnontrivial to incorporate a mass constraint to extend GST for measures on a\ngraph, possibly having different total mass. In this work, we propose to take a\nstep back by considering the entropy partial transport (EPT) for nonnegative\nmeasures on a graph. By leveraging Caffarelli & McCann (2010)'s observations,\nEPT can be reformulated as a standard complete OT between two corresponding\nbalanced measures. Consequently, we develop a novel EPT with Orlicz geometric\nstructure, namely Orlicz-EPT, for unbalanced measures on a graph. Especially,\nby exploiting the dual EPT formulation and geometric structures of the\ngraph-based Orlicz-Sobolev space, we derive a novel regularization to propose\nOrlicz-Sobolev transport (OST). The resulting distance can be efficiently\ncomputed by simply solving a univariate optimization problem, unlike the\nhigh-computational two-level optimization problem for Orlicz-EPT. Additionally,\nwe derive geometric structures for the OST and draw its relations to other\ntransport distances. We empirically show that OST is several-order faster than\nOrlicz-EPT. We further illustrate preliminary evidences on the advantages of\nOST for document classification, and several tasks in topological data\nanalysis.",
    "pdf_url": "http://arxiv.org/pdf/2502.00739v1",
    "published": "2025-02-02T10:16:09+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.00738v1",
    "title": "Coupling hydrodynamics of several Facilitated Exclusion Processes with closed boundaries",
    "authors": [
      "Hugo Da Cunha",
      "Lu Xu"
    ],
    "abstract": "In this paper, we prove the hydrodynamic limit for the ergodic dynamics of\nthe Facilitated Exclusion Process with closed boundaries in the symmetric,\nasymmetric and weakly asymmetric regimes. For this, we couple it with a Simple\nExclusion Process by constructing a mapping that transforms the facilitated\ndynamics into the simple one. As the hydrodynamic behaviour of the simple\nexclusion process with closed boundaries has been extensively studied, we can\ndeduce the corresponding hydrodynamics for the facilitated exclusion process.",
    "pdf_url": "http://arxiv.org/pdf/2502.00738v1",
    "published": "2025-02-02T10:15:34+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00737v2",
    "title": "Scalable Sobolev IPM for Probability Measures on a Graph",
    "authors": [
      "Tam Le",
      "Truyen Nguyen",
      "Hideitsu Hino",
      "Kenji Fukumizu"
    ],
    "abstract": "We investigate the Sobolev IPM problem for probability measures supported on\na graph metric space. Sobolev IPM is an important instance of integral\nprobability metrics (IPM), and is obtained by constraining a critic function\nwithin a unit ball defined by the Sobolev norm. In particular, it has been used\nto compare probability measures and is crucial for several theoretical works in\nmachine learning. However, to our knowledge, there are no efficient algorithmic\napproaches to compute Sobolev IPM effectively, which hinders its practical\napplications. In this work, we establish a relation between Sobolev norm and\nweighted $L^p$-norm, and leverage it to propose a \\emph{novel regularization}\nfor Sobolev IPM. By exploiting the graph structure, we demonstrate that the\nregularized Sobolev IPM provides a \\emph{closed-form} expression for fast\ncomputation. This advancement addresses long-standing computational challenges,\nand paves the way to apply Sobolev IPM for practical applications, even in\nlarge-scale settings. Additionally, the regularized Sobolev IPM is negative\ndefinite. Utilizing this property, we design positive-definite kernels upon the\nregularized Sobolev IPM, and provide preliminary evidences of their advantages\nfor comparing probability measures on a given graph for document classification\nand topological data analysis.",
    "pdf_url": "http://arxiv.org/pdf/2502.00737v2",
    "published": "2025-02-02T10:14:53+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.00736v1",
    "title": "ZTF J172132.75+445851.0: A Possible New Cataclysmic Variable of the VY Sculptoris Type",
    "authors": [
      "Klaus Bernhard",
      "Christopher Lloyd",
      "Peter Frank",
      "Wolfgang Moschner"
    ],
    "abstract": "We report the discovery of ZTF J172132.75+445851.0 as a new possible VY\nSculptoris variable, with an orbital period of 0.109765426(44) days. Survey\nobservations from 2005 to the present reveal significant activity in the\nsystem, with brightness variations ranging between 18.1 and 21.3 (zr)\nmagnitudes, including deep fades exceeding an amplitude of 3 magnitudes.",
    "pdf_url": "http://arxiv.org/pdf/2502.00736v1",
    "published": "2025-02-02T10:13:12+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00735v3",
    "title": "`Do as I say not as I do': A Semi-Automated Approach for Jailbreak Prompt Attack against Multimodal LLMs",
    "authors": [
      "Chun Wai Chiu",
      "Linghan Huang",
      "Bo Li",
      "Huaming Chen",
      "Kim-Kwang Raymond Choo"
    ],
    "abstract": "Large Language Models (LLMs) have seen widespread applications across various\ndomains due to their growing ability to process diverse types of input data,\nincluding text, audio, image and video. While LLMs have demonstrated\noutstanding performance in understanding and generating contexts for different\nscenarios, they are vulnerable to prompt-based attacks, which are mostly via\ntext input. In this paper, we introduce the first voice-based jailbreak attack\nagainst multimodal LLMs, termed as Flanking Attack, which can process different\ntypes of input simultaneously towards the multimodal LLMs. Our work is\nmotivated by recent advancements in monolingual voice-driven large language\nmodels, which have introduced new attack surfaces beyond traditional text-based\nvulnerabilities for LLMs. To investigate these risks, we examine the\nstate-of-the-art multimodal LLMs, which can be accessed via different types of\ninputs such as audio input, focusing on how adversarial prompts can bypass its\ndefense mechanisms. We propose a novel strategy, in which the disallowed prompt\nis flanked by benign, narrative-driven prompts. It is integrated in the\nFlanking Attack which attempts to humanizes the interaction context and execute\nthe attack through a fictional setting. Further, to better evaluate the attack\nperformance, we present a semi-automated self-assessment framework for policy\nviolation detection. We demonstrate that Flanking Attack is capable of\nmanipulating state-of-the-art LLMs into generating misaligned and forbidden\noutputs, which achieves an average attack success rate ranging from 0.67 to\n0.93 across seven forbidden scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.00735v3",
    "published": "2025-02-02T10:05:08+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00734v1",
    "title": "CycleGuardian: A Framework for Automatic RespiratorySound classification Based on Improved Deep clustering and Contrastive Learning",
    "authors": [
      "Yun Chu",
      "Qiuhao Wang",
      "Enze Zhou",
      "Ling Fu",
      "Qian Liu",
      "Gang Zheng"
    ],
    "abstract": "Auscultation plays a pivotal role in early respiratory and pulmonary disease\ndiagnosis. Despite the emergence of deep learning-based methods for automatic\nrespiratory sound classification post-Covid-19, limited datasets impede\nperformance enhancement. Distinguishing between normal and abnormal respiratory\nsounds poses challenges due to the coexistence of normal respiratory components\nand noise components in both types. Moreover, different abnormal respiratory\nsounds exhibit similar anomalous features, hindering their differentiation.\nBesides, existing state-of-the-art models suffer from excessive parameter size,\nimpeding deployment on resource-constrained mobile platforms. To address these\nissues, we design a lightweight network CycleGuardian and propose a framework\nbased on an improved deep clustering and contrastive learning. We first\ngenerate a hybrid spectrogram for feature diversity and grouping spectrograms\nto facilitating intermittent abnormal sound capture.Then, CycleGuardian\nintegrates a deep clustering module with a similarity-constrained clustering\ncomponent to improve the ability to capture abnormal features and a contrastive\nlearning module with group mixing for enhanced abnormal feature discernment.\nMulti-objective optimization enhances overall performance during training. In\nexperiments we use the ICBHI2017 dataset, following the official split method\nand without any pre-trained weights, our method achieves Sp: 82.06 $\\%$, Se:\n44.47$\\%$, and Score: 63.26$\\%$ with a network model size of 38M, comparing to\nthe current model, our method leads by nearly 7$\\%$, achieving the current best\nperformances. Additionally, we deploy the network on Android devices,\nshowcasing a comprehensive intelligent respiratory sound auscultation system.",
    "pdf_url": "http://arxiv.org/pdf/2502.00734v1",
    "published": "2025-02-02T09:56:47+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2502.00733v1",
    "title": "Charge sum rules for quark fragmentation functions",
    "authors": [
      "D. Kotlorz",
      "O. V. Teryaev"
    ],
    "abstract": "Charge sum rules for quark fragmentation functions are studied. The\nsimultaneous implementation of the conservation of electric and baryon charges,\nstrangeness and isospin symmetry is achieved when the fragmentation to both\nmesons and baryons is considered. The results are compatible to\nGell-Mann--Nishijima formulas and may be the new manifestation of\nsuperconformal symmetry between mesons and baryons. The numerical estimates are\nperformed and compared with phenomenological models. The recently suggested\nviolations of sum rules due to Wilson lines contributions are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2502.00733v1",
    "published": "2025-02-02T09:44:05+00:00",
    "categories": [
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00732v1",
    "title": "On cyclic groups covers of the projective line",
    "authors": [
      "George Katsimprakis",
      "Aristides Kontogeorgis"
    ],
    "abstract": "We use tools of combinatorial group theory in order to compute the\nfundamental group of ramified covers of the projective line with the most\ngeneral ramification type.",
    "pdf_url": "http://arxiv.org/pdf/2502.00732v1",
    "published": "2025-02-02T09:38:47+00:00",
    "categories": [
      "math.AG",
      "11G30, 14H37, 20F36"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12024v2",
    "title": "Computing and Learning Stationary Mean Field Equilibria with Scalar Interactions: Algorithms and Applications",
    "authors": [
      "Bar Light"
    ],
    "abstract": "Mean field equilibrium (MFE) has emerged as a computationally tractable\nsolution concept for large dynamic games. However, computing MFE remains\nchallenging due to nonlinearities and the absence of contraction properties,\nlimiting its reliability for counterfactual analysis and comparative statics.\nThis paper focuses on MFE in dynamic models where agents interact through a\nscalar function of the population distribution, referred to as the scalar\ninteraction function. Such models naturally arise in a wide range of\napplications involving market dynamics and strategic competition. The main\ncontribution of this paper is to introduce iterative algorithms that leverage\nthe scalar interaction structure and are guaranteed to converge to the MFE\nunder mild assumptions. Leveraging this structure, we also establish an MFE\nexistence result for non-compact state spaces and analytical comparative\nstatics. To the best of our knowledge, these are the first algorithms with\nglobal convergence guarantees in such settings. Unlike existing approaches, our\nalgorithms do not rely on monotonicity or contraction properties, significantly\nbroadening their applicability. Furthermore, we provide a model-free algorithm\nthat learns the MFE via simulation and reinforcement learning techniques such\nas Q-learning and policy gradient methods without requiring prior knowledge of\npayoff or transition functions. We apply our algorithms to classic models of\ndynamic competition, such as capacity competition, and to competitive models\nmotivated by online marketplaces, including ridesharing and inventory\ncompetition, as well as to social learning models. We show how key market\nparameters influence equilibrium outcomes through reliable comparative statics\nin these representative models, providing insights into the design of\ncompetitive systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.12024v2",
    "published": "2025-02-02T09:38:40+00:00",
    "categories": [
      "econ.TH",
      "cs.GT",
      "math.OC"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2502.00731v1",
    "title": "Diophantine approximation and the subspace theorem",
    "authors": [
      "Shivani Goel",
      "Rashi Lunia",
      "Anwesh Ray"
    ],
    "abstract": "Diophantine approximation explores how well irrational numbers can be\napproximated by rationals, with foundational results by Dirichlet, Hurwitz, and\nLiouville culminating in Roth's theorem. Schmidt's subspace theorem extends\nRoth's results to higher dimensions, with profound implications to Diophantine\nequations and transcendence theory. This article provides a self-contained and\naccessible exposition of Roth's theorem and Schlickewei's refinement of the\nsubspace theorem, with an emphasis on proofs. The arguments presented are\nclassical and approachable for readers with a background in algebraic number\ntheory, serving as a streamlined, yet condensed reference for these fundamental\nresults.",
    "pdf_url": "http://arxiv.org/pdf/2502.00731v1",
    "published": "2025-02-02T09:32:21+00:00",
    "categories": [
      "math.NT",
      "11J87"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00730v1",
    "title": "Spatio-Temporal Progressive Attention Model for EEG Classification in Rapid Serial Visual Presentation Task",
    "authors": [
      "Yang Li",
      "Wei Liu",
      "Tianzhi Feng",
      "Fu Li",
      "Chennan Wu",
      "Boxun Fu",
      "Zhifu Zhao",
      "Xiaotian Wang",
      "Guangming Shi"
    ],
    "abstract": "As a type of multi-dimensional sequential data, the spatial and temporal\ndependencies of electroencephalogram (EEG) signals should be further\ninvestigated. Thus, in this paper, we propose a novel spatial-temporal\nprogressive attention model (STPAM) to improve EEG classification in rapid\nserial visual presentation (RSVP) tasks. STPAM first adopts three distinct\nspatial experts to learn the spatial topological information of brain regions\nprogressively, which is used to minimize the interference of irrelevant brain\nregions. Concretely, the former expert filters out EEG electrodes in the\nrelative brain regions to be used as prior knowledge for the next expert,\nensuring that the subsequent experts gradually focus their attention on\ninformation from significant EEG electrodes. This process strengthens the\neffect of the important brain regions. Then, based on the above-obtained\nfeature sequence with spatial information, three temporal experts are adopted\nto capture the temporal dependence by progressively assigning attention to the\ncrucial EEG slices. Except for the above EEG classification method, in this\npaper, we build a novel Infrared RSVP EEG Dataset (IRED) which is based on dim\ninfrared images with small targets for the first time, and conduct extensive\nexperiments on it. The results show that our STPAM can achieve better\nperformance than all the compared methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.00730v1",
    "published": "2025-02-02T09:28:38+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00729v2",
    "title": "Selective Response Strategies for GenAI",
    "authors": [
      "Boaz Taitler",
      "Omer Ben-Porat"
    ],
    "abstract": "The rise of Generative AI (GenAI) has significantly impacted human-based\nforums like Stack Overflow, which are essential for generating high-quality\ndata. This creates a negative feedback loop, hindering the development of GenAI\nsystems, which rely on such data to provide accurate responses. In this paper,\nwe provide a possible remedy: A novel strategy we call selective response.\nSelective response implies that GenAI could strategically provide inaccurate\n(or conservative) responses to queries involving emerging topics and novel\ntechnologies, thereby driving users to use human-based forums like Stack\nOverflow. We show that selective response can potentially have a compounding\neffect on the data generation process, increasing both GenAI's revenue and user\nwelfare in the long term. From an algorithmic perspective, we propose an\napproximately optimal approach to maximize GenAI's revenue under social welfare\nconstraints. From a regulatory perspective, we derive sufficient and necessary\nconditions for selective response to improve welfare improvements.",
    "pdf_url": "http://arxiv.org/pdf/2502.00729v2",
    "published": "2025-02-02T09:27:02+00:00",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.SI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00728v1",
    "title": "Meta-Prompt Optimization for LLM-Based Sequential Decision Making",
    "authors": [
      "Mingze Kong",
      "Zhiyong Wang",
      "Yao Shu",
      "Zhongxiang Dai"
    ],
    "abstract": "Large language models (LLMs) have recently been employed as agents to solve\nsequential decision-making tasks such as Bayesian optimization and multi-armed\nbandits (MAB). These works usually adopt an LLM for sequential action selection\nby providing it with a fixed, manually designed meta-prompt. However, numerous\nprevious works have found that the prompt has a significant impact on the\nperformance of the LLM, which calls for a method to automatically optimize the\nmeta-prompt for LLM-based agents. Unfortunately, the non-stationarity in the\nreward observations during LLM-based sequential decision-making makes\nmeta-prompt optimization highly challenging. To address this challenge, we draw\ninspirations from adversarial bandit algorithms, which are inherently capable\nof handling non-stationary reward observations. Building on this foundation, we\npropose our EXPonential-weight algorithm for prompt Optimization} (EXPO) to\nautomatically optimize the task description and meta-instruction in the\nmeta-prompt for LLM-based agents. We also extend EXPO to additionally optimize\nthe exemplars (i.e., history of interactions) in the meta-prompt to further\nenhance the performance, hence introducing our EXPO-ES algorithm. We use\nextensive experiments to show that our algorithms significantly improve the\nperformance of LLM-based sequential decision-making.",
    "pdf_url": "http://arxiv.org/pdf/2502.00728v1",
    "published": "2025-02-02T09:22:39+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00727v1",
    "title": "Inner and characteristic functions in polydiscs",
    "authors": [
      "Ramlal Debnath",
      "Deepak K. Pradhan",
      "Jaydeb Sarkar"
    ],
    "abstract": "Characteristic functions of linear operators are analytic functions that\nserve as complete unitary invariants. Such functions, as long as they are built\nin a natural and canonical manner, provide representations of inner functions\non a suitable domain and make significant contributions to the development of\nvarious theories in Hilbert function spaces. In this paper, we solve this\nproblem in polydiscs. In particular, we present a concrete description of the\ncharacteristic functions of tuples of commuting pure contractions and,\nconsequently, provide a description of inner functions on polydiscs.",
    "pdf_url": "http://arxiv.org/pdf/2502.00727v1",
    "published": "2025-02-02T09:17:30+00:00",
    "categories": [
      "math.FA",
      "math.CV",
      "math.OA",
      "46J15, 47A15, 30H05, 47A56, 32A35, 30J05"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00726v1",
    "title": "Perspectives for Direct Interpretability in Multi-Agent Deep Reinforcement Learning",
    "authors": [
      "Yoann Poupart",
      "Aurélie Beynier",
      "Nicolas Maudet"
    ],
    "abstract": "Multi-Agent Deep Reinforcement Learning (MADRL) was proven efficient in\nsolving complex problems in robotics or games, yet most of the trained models\nare hard to interpret. While learning intrinsically interpretable models\nremains a prominent approach, its scalability and flexibility are limited in\nhandling complex tasks or multi-agent dynamics. This paper advocates for direct\ninterpretability, generating post hoc explanations directly from trained\nmodels, as a versatile and scalable alternative, offering insights into agents'\nbehaviour, emergent phenomena, and biases without altering models'\narchitectures. We explore modern methods, including relevance backpropagation,\nknowledge edition, model steering, activation patching, sparse autoencoders and\ncircuit discovery, to highlight their applicability to single-agent,\nmulti-agent, and training process challenges. By addressing MADRL\ninterpretability, we propose directions aiming to advance active topics such as\nteam identification, swarm coordination and sample efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2502.00726v1",
    "published": "2025-02-02T09:15:27+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00725v1",
    "title": "Understanding and Mitigating the High Computational Cost in Path Data Diffusion",
    "authors": [
      "Dingyuan Shi",
      "Lulu Zhang",
      "Yongxin Tong",
      "Ke Xu"
    ],
    "abstract": "Advancements in mobility services, navigation systems, and smart\ntransportation technologies have made it possible to collect large amounts of\npath data. Modeling the distribution of this path data, known as the Path\nGeneration (PG) problem, is crucial for understanding urban mobility patterns\nand developing intelligent transportation systems. Recent studies have explored\nusing diffusion models to address the PG problem due to their ability to\ncapture multimodal distributions and support conditional generation. A recent\nwork devises a diffusion process explicitly in graph space and achieves\nstate-of-the-art performance. However, this method suffers a high computation\ncost in terms of both time and memory, which prohibits its application. In this\npaper, we analyze this method both theoretically and experimentally and find\nthat the main culprit of its high computation cost is its explicit design of\nthe diffusion process in graph space. To improve efficiency, we devise a\nLatent-space Path Diffusion (LPD) model, which operates in latent space instead\nof graph space. Our LPD significantly reduces both time and memory costs by up\nto 82.8% and 83.1%, respectively. Despite these reductions, our approach does\nnot suffer from performance degradation. It outperforms the state-of-the-art\nmethod in most scenarios by 24.5%~34.0%.",
    "pdf_url": "http://arxiv.org/pdf/2502.00725v1",
    "published": "2025-02-02T09:02:36+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00724v2",
    "title": "Learned Bayesian Cramér-Rao Bound for Unknown Measurement Models Using Score Neural Networks",
    "authors": [
      "Hai Victor Habi",
      "Hagit Messer",
      "Yoram Bresler"
    ],
    "abstract": "The Bayesian Cram\\'er-Rao bound (BCRB) is a crucial tool in signal processing\nfor assessing the fundamental limitations of any estimation problem as well as\nbenchmarking within a Bayesian frameworks. However, the BCRB cannot be computed\nwithout full knowledge of the prior and the measurement distributions. In this\nwork, we propose a fully learned Bayesian Cram\\'er-Rao bound (LBCRB) that\nlearns both the prior and the measurement distributions. Specifically, we\nsuggest two approaches to obtain the LBCRB: the Posterior Approach and the\nMeasurement-Prior Approach. The Posterior Approach provides a simple method to\nobtain the LBCRB, whereas the Measurement-Prior Approach enables us to\nincorporate domain knowledge to improve the sample complexity and\n{interpretability}. To achieve this, we introduce a Physics-encoded score\nneural network which enables us to easily incorporate such domain knowledge\ninto a neural network. We {study the learning} errors of the two suggested\napproaches theoretically, and validate them numerically. We demonstrate the two\napproaches on several signal processing examples, including a linear\nmeasurement problem with unknown mixing and Gaussian noise covariance matrices,\nfrequency estimation, and quantized measurement. In addition, we test our\napproach on a nonlinear signal processing problem of frequency estimation with\nreal-world underwater ambient noise.",
    "pdf_url": "http://arxiv.org/pdf/2502.00724v2",
    "published": "2025-02-02T09:00:40+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.00723v1",
    "title": "Effect of Non-Extensive Parameter on Page Curve",
    "authors": [
      "Ankit Anand",
      "Dinesh Kumar",
      "Aditya Singh"
    ],
    "abstract": "This work employs the quantum extremal surface framework to compute the Page\ncurve for black holes corrected by non-extensive entropy. The entropy of\nHawking radiation increases linearly with time, leading to the persistence of\nthe information paradox for non-extensive entropy-corrected black holes. At\nlate time, we extremize the generalized entropy functional; incorporating\ncontributions from both matter and the quantum extremal island, we establish\nthat the entanglement entropy of Hawking radiation saturates to the\nnon-extensive extension of the Bekenstein-Hawking entropy. Finally, we study\nthe dependence of non-extensive parameters on the Page time.",
    "pdf_url": "http://arxiv.org/pdf/2502.00723v1",
    "published": "2025-02-02T08:59:46+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.00722v2",
    "title": "Demystifying Cost-Efficiency in LLM Serving over Heterogeneous GPUs",
    "authors": [
      "Youhe Jiang",
      "Fangcheng Fu",
      "Xiaozhe Yao",
      "Guoliang He",
      "Xupeng Miao",
      "Ana Klimovic",
      "Bin Cui",
      "Binhang Yuan",
      "Eiko Yoneki"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have led to increasingly\ndiverse requests, accompanied with varying resource (compute and memory)\ndemands to serve them. However, this in turn degrades the cost-efficiency of\nLLM serving as common practices primarily rely on homogeneous GPU resources. In\nresponse to this problem, this work conducts a thorough study about serving\nLLMs over heterogeneous GPU resources on cloud platforms. The rationale is that\ndifferent GPU types exhibit distinct compute and memory characteristics,\naligning well with the divergent resource demands of diverse requests.\nParticularly, through comprehensive benchmarking, we discover that the\ncost-efficiency of LLM serving can be substantially optimized by meticulously\ndetermining GPU composition, deployment configurations, and workload\nassignments. Subsequently, we design a scheduling algorithm via mixed-integer\nlinear programming, aiming at deducing the most cost-efficient serving plan\nunder the constraints of price budget and real-time GPU availability.\nRemarkably, our approach effectively outperforms homogeneous and heterogeneous\nbaselines under a wide array of scenarios, covering diverse workload traces,\nvarying GPU availablilities, and multi-model serving. This casts new light on\nmore accessible and efficient LLM serving over heterogeneous cloud resources.",
    "pdf_url": "http://arxiv.org/pdf/2502.00722v2",
    "published": "2025-02-02T08:44:43+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00721v3",
    "title": "A Turing Test for Artificial Nets devoted to model Human Vision",
    "authors": [
      "Jorge Vila-Tomás",
      "Pablo Hernández-Cámara",
      "Qiang Li",
      "Valero Laparra",
      "Jesús Malo"
    ],
    "abstract": "In our invited talk at the AI Evaluation Workshop of the University of\nBristol back in June 2022 we argued that, despite claims about successful\nmodeling of the visual brain using ANNs, the problem is far from being solved\n(even for low-level vision). Open issues include: where should we read from\nANNs to reproduce human behavior?, this ad-hoc read-out is part of the brain\nmodel or not?, should we use artificial psychophysics or artificial\nphysiology?, artificial experiments should literally match the experiments in\nhumans?. There is a clear need of rigorous procedures for experimental tests\nfor ANNs models of the visual brain, and more generally, to understand ANNs\ndevoted to generic vision tasks. Following our experience in using low-level\nfacts from Visual Neuroscience in Image Processing, we presented the idea of\ndeveloping a low-level dataset compiling the basic spatio-temporal and\nchromatic facts that are known to happen in the retina-V1 pathway, and they are\nnot currently available in existing databases such as BrainScore. In our\nresults we checked the behavior of three recently proposed models with similar\narchitecture: (1) A parametric model tuned via Maximum Differentiation [Malo &\nSimoncelli SPIE 15, Martinez et al. PLOS 18, Martinez et al. Front. Neurosci.\n19], (2) A non-parametric model, the PerceptNet, tuned to maximize the\ncorrelation with human opinion on subjective distortions [Hepburn et al. IEEE\nICIP 20], and (3) A model with the same encoder as PerceptNet, but tuned for\nsegmentation (published later as Hernandez-Camara et al. Patt.Recogn.Lett. 23,\nHernandez-Camara et al. Neurocomp. 25). Results on 10 compelling psycho/physio\nvisual facts show that the first model is the one with closer behavior to the\nhumans in terms of receptive fields, but more interestingly, on the nonlinear\nbehavior for spatio-chromatic patterns of a range of luminances and contrasts.",
    "pdf_url": "http://arxiv.org/pdf/2502.00721v3",
    "published": "2025-02-02T08:43:47+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00720v1",
    "title": "Singular and regular analysis for the free boundaries of two-phase inviscid fluids in gravity field",
    "authors": [
      "Lili Du",
      "Feng Ji"
    ],
    "abstract": "In this paper, we consider a free boundary problem of two-phase inviscid\nincompressible fluid in gravity field. The presence of the gravity field\ninduces novel phenomena that there might be some stagnation points on free\nsurface of the two-phase flow, where the velocity field of the fluid vanishes.\nFrom the mathematical point of view, the gradient of the stream function\ndegenerates near the stagnation point, leading to singular behaviors on the\nfree surface. The primary objective of this study is to investigate the\nsingularity and regularity of the two-phase free surface, considering their\nmutual interaction between the two incompressible fluids in two dimensions.\nMore precisely, if the two fluids meet locally at a single point, referred to\nas the possible two-phase stagnation point, we demonstrate that the singular\nside of the two-phase free surface exhibits a symmetric Stokes singular\nprofile, while the regular side near this point maintains the $C^{1,\\alpha}$\nregularity. On the other hand, if the free surfaces of the two fluids stick\ntogether and have non-trivial overlapping common boundary at the stagnation\npoint, then the interaction between the two fluids will break the symmetry of\nthe Stokes corner profile, which is attached to the $C^{1,\\alpha}$ regular free\nsurface on the other side. As a byproduct of our analysis, it's shown that the\nvelocity field for the two fluids cannot vanish simultaneously on the two-phase\nfree boundary.\n  Our results generalize the significant works on the Stokes conjecture in\n[V$\\check{a}$rv$\\check{a}$ruc$\\check{a}$-Weiss, Acta Math., 206, (2011)] for\none-phase gravity water wave, and on regular results on the free boundaries in\n[De Philippis-Spolaor-Velichkov, Invent. Math., 225, (2021)] for two-phase\nfluids without gravity.",
    "pdf_url": "http://arxiv.org/pdf/2502.00720v1",
    "published": "2025-02-02T08:43:04+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.00719v1",
    "title": "Vision and Language Reference Prompt into SAM for Few-shot Segmentation",
    "authors": [
      "Kosuke Sakurai",
      "Ryotaro Shimizu",
      "Masayuki Goto"
    ],
    "abstract": "Segment Anything Model (SAM) represents a large-scale segmentation model that\nenables powerful zero-shot capabilities with flexible prompts. While SAM can\nsegment any object in zero-shot, it requires user-provided prompts for each\ntarget image and does not attach any label information to masks. Few-shot\nsegmentation models addressed these issues by inputting annotated reference\nimages as prompts to SAM and can segment specific objects in target images\nwithout user-provided prompts. Previous SAM-based few-shot segmentation models\nonly use annotated reference images as prompts, resulting in limited accuracy\ndue to a lack of reference information. In this paper, we propose a novel\nfew-shot segmentation model, Vision and Language reference Prompt into SAM\n(VLP-SAM), that utilizes the visual information of the reference images and the\nsemantic information of the text labels by inputting not only images but also\nlanguage as reference information. In particular, VLP-SAM is a simple and\nscalable structure with minimal learnable parameters, which inputs prompt\nembeddings with vision-language information into SAM using a multimodal\nvision-language model. To demonstrate the effectiveness of VLP-SAM, we\nconducted experiments on the PASCAL-5i and COCO-20i datasets, and achieved high\nperformance in the few-shot segmentation task, outperforming the previous\nstate-of-the-art model by a large margin (6.3% and 9.5% in mIoU, respectively).\nFurthermore, VLP-SAM demonstrates its generality in unseen objects that are not\nincluded in the training data. Our code is available at\nhttps://github.com/kosukesakurai1/VLP-SAM.",
    "pdf_url": "http://arxiv.org/pdf/2502.00719v1",
    "published": "2025-02-02T08:40:14+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00718v2",
    "title": "\"I am bad\": Interpreting Stealthy, Universal and Robust Audio Jailbreaks in Audio-Language Models",
    "authors": [
      "Isha Gupta",
      "David Khachaturov",
      "Robert Mullins"
    ],
    "abstract": "The rise of multimodal large language models has introduced innovative\nhuman-machine interaction paradigms but also significant challenges in machine\nlearning safety. Audio-Language Models (ALMs) are especially relevant due to\nthe intuitive nature of spoken communication, yet little is known about their\nfailure modes. This paper explores audio jailbreaks targeting ALMs, focusing on\ntheir ability to bypass alignment mechanisms. We construct adversarial\nperturbations that generalize across prompts, tasks, and even base audio\nsamples, demonstrating the first universal jailbreaks in the audio modality,\nand show that these remain effective in simulated real-world conditions. Beyond\ndemonstrating attack feasibility, we analyze how ALMs interpret these audio\nadversarial examples and reveal them to encode imperceptible first-person toxic\nspeech - suggesting that the most effective perturbations for eliciting toxic\noutputs specifically embed linguistic features within the audio signal. These\nresults have important implications for understanding the interactions between\ndifferent modalities in multimodal models, and offer actionable insights for\nenhancing defenses against adversarial audio attacks.",
    "pdf_url": "http://arxiv.org/pdf/2502.00718v2",
    "published": "2025-02-02T08:36:23+00:00",
    "categories": [
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00717v1",
    "title": "MINT: Mitigating Hallucinations in Large Vision-Language Models via Token Reduction",
    "authors": [
      "Chao Wang",
      "Jianming Yang",
      "Yang Zhou"
    ],
    "abstract": "Hallucination has been a long-standing and inevitable problem that hinders\nthe application of Large Vision-Language Models (LVLMs) in domains that require\nhigh reliability. Various methods focus on improvement depending on data\nannotations or training strategies, yet place less emphasis on LLM's inherent\nproblems. To fill this gap, we delve into the attention mechanism of the\ndecoding process in the LVLM. Intriguingly, our investigation uncovers the\nprevalent attention redundancy within the hierarchical architecture of the\nLVLM, manifesting as overextended image processing in deep layers and an\noverabundance of non-essential image tokens. Stemming from the observation, we\nthus propose MINT, a novel training-free decoding strategy, MItigating\nhallucinations via tokeN reducTion. Specifically, we dynamically intensify the\nLVLM's local perception capability by masking its attention to irrelevant image\ntokens. In addition, we use contrastive decoding that pushes the model to focus\nmore on those key image regions. Our full method aims to guide the model in\nconcentrating more on key visual elements during generation. Extensive\nexperimental results on several popular public benchmarks show that our\napproach achieves a 4% improvement in mitigating hallucinations caused by\ndistracted perception compared to original models. Meanwhile, our approach is\ndemonstrated to make the model perceive 5% more visual points even though we\nreduce a suite of image tokens.",
    "pdf_url": "http://arxiv.org/pdf/2502.00717v1",
    "published": "2025-02-02T08:34:57+00:00",
    "categories": [
      "cs.CV",
      "I.2.10"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.02608v1",
    "title": "On the behavior of a distributed network of capacitive constant phase elements",
    "authors": [
      "Anis Allagui",
      "Ahmed S. Elwakil"
    ],
    "abstract": "As a generalization of integer-order calculus, fractional calculus has seen\ntremendous applications in the past few years especially in the description of\nanomalous viscoelastic properties, transport processes in complex media as well\nas in dielectric and impedance spectroscopy of materials and\nelectrode/electrolyte interfaces. The fractional-order capacitor or constant\nphase element (CPE) is a fractional-order model with impedance $z_c(s) =\n1/(C_{\\alpha} s^{\\alpha})$ ($s=j \\omega$, $C_{\\alpha}>0$, $0<\\alpha<1$) and is\nwidely used in modeling impedance spectroscopy data in dispersive materials. In\nthis study, we investigate the behavior of a network of distributed-order CPEs,\neach of which described by a Caputo-type time fractional differential equation\nrelating the current on the CPE to its voltage, but with a non-negative,\ntime-invariant weight function $\\phi(\\alpha)$. The behavior of the\ndistributed-order network in terms of impedance and time-domain response to a\nconstant current excitation is derived for two simple cases of $\\phi(\\alpha)$:\n(i) $\\phi(\\alpha)=1$ for $0 < \\alpha < 1$ and zero otherwise, and $(ii)$\n$\\phi(\\alpha) = \\sum_i C_{\\alpha_i}\\, \\delta(\\alpha-\\alpha_i)$ corresponding to\nthe general case of parallel-connected elemental CPEs of different orders\n$\\alpha$, and pseudocapacitances $C_{\\alpha}$. Our results show that the\noverall network is not equivalent to a single CPE, contrary to what would of\nbeen expected with ideal capacitors.",
    "pdf_url": "http://arxiv.org/pdf/2502.02608v1",
    "published": "2025-02-02T08:31:37+00:00",
    "categories": [
      "physics.app-ph",
      "cond-mat.dis-nn"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00716v1",
    "title": "UPL: Uncertainty-aware Pseudo-labeling for Imbalance Transductive Node Classification",
    "authors": [
      "Mohammad T. Teimuri",
      "Zahra Dehghanian",
      "Gholamali Aminian",
      "Hamid R. Rabiee"
    ],
    "abstract": "Graph-structured datasets often suffer from class imbalance, which\ncomplicates node classification tasks. In this work, we address this issue by\nfirst providing an upper bound on population risk for imbalanced transductive\nnode classification. We then propose a simple and novel algorithm,\nUncertainty-aware Pseudo-labeling (UPL). Our approach leverages pseudo-labels\nassigned to unlabeled nodes to mitigate the adverse effects of imbalance on\nclassification accuracy. Furthermore, the UPL algorithm enhances the accuracy\nof pseudo-labeling by reducing training noise of pseudo-labels through a novel\nuncertainty-aware approach. We comprehensively evaluate the UPL algorithm\nacross various benchmark datasets, demonstrating its superior performance\ncompared to existing state-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.00716v1",
    "published": "2025-02-02T08:19:42+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00715v1",
    "title": "REAL: Reinforcement Learning-Enabled xApps for Experimental Closed-Loop Optimization in O-RAN with OSC RIC and srsRAN",
    "authors": [
      "Ryan Barker",
      "Alireza Ebrahimi Dorcheh",
      "Tolunay Seyfi",
      "Fatemeh Afghah"
    ],
    "abstract": "Open Radio Access Network (O-RAN) offers an open, programmable architecture\nfor next-generation wireless networks, enabling advanced control through\nAI-based applications on the near-Real-Time RAN Intelligent Controller (near-RT\nRIC). However, fully integrated, real-time demonstrations of closed-loop\noptimization in O-RAN remain scarce. In this paper, we present a complete\nframework that combines the O-RAN Software Community RIC (OSC RIC) with srsRAN\nfor near-real-time network slicing using Reinforcement Learning (RL). Our\nsystem orchestrates resources across diverse slice types (eMBB, URLLC, mMTC)\nfor up to 12 UEs. We incorporate GNU Radio blocks for channel modeling,\nincluding Free-Space Path Loss (FSPL), single-tap multipath, AWGN, and Doppler\neffects, to emulate an urban mobility scenario. Experimental results show that\nour RL-based xApps dynamically adapt resource allocation and maintain QoS under\nvarying traffic demands, highlighting both the feasibility and challenges of\nend-to-end AI-driven optimization in a lightweight O-RAN testbed. Our findings\nestablish a baseline for real-time RL-based slicing in a disaggregated 5G\nframework and underscore the need for further enhancements to support fully\nsimulated PHY digital twins without reliance on commercial software.",
    "pdf_url": "http://arxiv.org/pdf/2502.00715v1",
    "published": "2025-02-02T08:11:59+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00714v1",
    "title": "Harnessing Discrete Differential Geometry: A Virtual Playground for the Bilayer Soft Robotics",
    "authors": [
      "Jiahao Li",
      "Dezhong Tong",
      "Zhuonan Hao",
      "Yinbo Zhu",
      "Hengan Wu",
      "Mingchao Liu",
      "Weicheng Huang"
    ],
    "abstract": "Soft robots have garnered significant attention due to their promising\napplications across various domains. A hallmark of these systems is their\nbilayer structure, where strain mismatch caused by differential expansion\nbetween layers induces complex deformations. Despite progress in theoretical\nmodeling and numerical simulation, accurately capturing their dynamic behavior,\nespecially during environmental interactions, remains challenging. This study\npresents a novel simulation environment based on the Discrete Elastic Rod (DER)\nmodel to address the challenge. By leveraging discrete differential geometry\n(DDG), the DER approach offers superior convergence compared to conventional\nmethods like Finite Element Method (FEM), particularly in handling contact\ninteractions -- an essential aspect of soft robot dynamics in real-world\nscenarios. Our simulation framework incorporates key features of bilayer\nstructures, including stretching, bending, twisting, and inter-layer coupling.\nThis enables the exploration of a wide range of dynamic behaviors for bilayer\nsoft robots, such as gripping, crawling, jumping, and swimming. The insights\ngained from this work provide a robust foundation for the design and control of\nadvanced bilayer soft robotic systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.00714v1",
    "published": "2025-02-02T08:07:36+00:00",
    "categories": [
      "cs.RO",
      "cond-mat.soft"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00713v1",
    "title": "Using Individualized Treatment Effects to Assess Treatment Effect Heterogeneity",
    "authors": [
      "Konstantinos Sechidis",
      "Cong Zhang",
      "Sophie Sun",
      "Yao Chen",
      "Asher Spector",
      "Björn Bornkamp"
    ],
    "abstract": "Assessing treatment effect heterogeneity (TEH) in clinical trials is crucial,\nas it provides insights into the variability of treatment responses among\npatients, influencing important decisions related to drug development.\nFurthermore, it can lead to personalized medicine by tailoring treatments to\nindividual patient characteristics. This paper introduces novel methodologies\nfor assessing treatment effects using the individual treatment effect as a\nbasis. To estimate this effect, we use a Double Robust (DR) learner to infer a\npseudo-outcome that reflects the causal contrast. This pseudo-outcome is then\nused to perform three objectives: (1) a global test for heterogeneity, (2)\nranking covariates based on their influence on effect modification, and (3)\nproviding estimates of the individualized treatment effect. We compare our\nDR-learner with various alternatives and competing methods in a simulation\nstudy, and also use it to assess heterogeneity in a pooled analysis of five\nPhase III trials in psoriatic arthritis. By integrating these methods with the\nrecently proposed WATCH workflow (Workflow to Assess Treatment Effect\nHeterogeneity in Drug Development for Clinical Trial Sponsors), we provide a\nrobust framework for analyzing TEH, offering insights that enable more informed\ndecision-making in this challenging area.",
    "pdf_url": "http://arxiv.org/pdf/2502.00713v1",
    "published": "2025-02-02T08:03:23+00:00",
    "categories": [
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.07799v2",
    "title": "Simultaneous spatial-parametric collocation approximation for parametric PDEs with log-normal random inputs",
    "authors": [
      "Dinh Dũng"
    ],
    "abstract": "We proved convergence rates of fully discrete multi-level simultaneous linear\ncollocation approximation of solutions to parametric elliptic PDEs on bounded\npolygonal domain with log-normal random inputs based on a finite number of\ntheir values at points in the spatial-parametric domain. These convergence\nrates significantly improve the best-known convergence rates of fully discrete\ncollocation approximation and with some logarithm factors coincide with the\nconvergence rates of best $n$-term approximation. These results are obtained as\nconsequences of general results on multi-level linear sampling recovery by\nextended least squares algorithms in abstract Bochner spaces.",
    "pdf_url": "http://arxiv.org/pdf/2502.07799v2",
    "published": "2025-02-02T08:00:15+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65C30, 65N15, 65N35, 41A25, 41A65"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00712v1",
    "title": "Registration-Enhanced Segmentation Method for Prostate Cancer in Ultrasound Images",
    "authors": [
      "Shengtian Sang",
      "Hassan Jahanandish",
      "Cynthia Xinran Li",
      "Indrani Bhattachary",
      "Jeong Hoon Lee",
      "Lichun Zhang",
      "Sulaiman Vesal",
      "Pejman Ghanouni",
      "Richard Fan",
      "Geoffrey A. Sonn",
      "Mirabela Rusu"
    ],
    "abstract": "Prostate cancer is a major cause of cancer-related deaths in men, where early\ndetection greatly improves survival rates. Although MRI-TRUS fusion biopsy\noffers superior accuracy by combining MRI's detailed visualization with TRUS's\nreal-time guidance, it is a complex and time-intensive procedure that relies\nheavily on manual annotations, leading to potential errors. To address these\nchallenges, we propose a fully automatic MRI-TRUS fusion-based segmentation\nmethod that identifies prostate tumors directly in TRUS images without\nrequiring manual annotations. Unlike traditional multimodal fusion approaches\nthat rely on naive data concatenation, our method integrates a\nregistration-segmentation framework to align and leverage spatial information\nbetween MRI and TRUS modalities. This alignment enhances segmentation accuracy\nand reduces reliance on manual effort. Our approach was validated on a dataset\nof 1,747 patients from Stanford Hospital, achieving an average Dice coefficient\nof 0.212, outperforming TRUS-only (0.117) and naive MRI-TRUS fusion (0.132)\nmethods, with significant improvements (p $<$ 0.01). This framework\ndemonstrates the potential for reducing the complexity of prostate cancer\ndiagnosis and provides a flexible architecture applicable to other multimodal\nmedical imaging tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.00712v1",
    "published": "2025-02-02T07:58:40+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00711v2",
    "title": "VIKSER: Visual Knowledge-Driven Self-Reinforcing Reasoning Framework",
    "authors": [
      "Chao Wang",
      "Chunbai Zhang",
      "Yongxiao Tian",
      "Yang Zhou",
      "Yan Peng"
    ],
    "abstract": "Visual reasoning refers to the task of solving questions about visual\ninformation. Current visual reasoning methods typically employ pre-trained\nvision-language model (VLM) strategies or deep neural network approaches.\nHowever, existing efforts are constrained by limited reasoning\ninterpretability, while hindering by the phenomenon of underspecification in\nthe question text. Additionally, the absence of fine-grained visual knowledge\nlimits the precise understanding of subject behavior in visual reasoning tasks.\nTo address these issues, we propose VIKSER (Visual Knowledge-Driven\nSelf-Reinforcing Reasoning Framework). Specifically, VIKSER, trained using\nknowledge distilled from large language models, extracts fine-grained visual\nknowledge with the assistance of visual relationship detection techniques.\nSubsequently, VIKSER utilizes fine-grained visual knowledge to paraphrase the\nquestion with underspecification. Additionally, we design a novel prompting\nmethod called Chain-of-Evidence (CoE), which leverages the power of \"evidence\nfor reasoning\" to endow VIKSER with interpretable reasoning capabilities.\nMeanwhile, the integration of self-reflection technology empowers VIKSER with\nthe ability to learn and improve from its mistakes. Experiments conducted on\nwidely used datasets demonstrate that VIKSER achieves new state-of-the-art\n(SOTA) results in relevant tasks. Moreover, VIKSER achieves performance on par\nwith leading proprietary models, such as the latest ChatGPT-5.",
    "pdf_url": "http://arxiv.org/pdf/2502.00711v2",
    "published": "2025-02-02T07:54:55+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00710v1",
    "title": "Fractional anisotropic Calderón problem with external data",
    "authors": [
      "Ali Feizmohammadi",
      "Tuhin Ghosh",
      "Katya Krupchyk",
      "Angkana Rüland",
      "Johannes Sjöstrand",
      "Gunther Uhlmann"
    ],
    "abstract": "In this paper, we solve the fractional anisotropic Calder\\'on problem with\nexternal data in the Euclidean space, in dimensions two and higher, for smooth\nRiemannian metrics that agree with the Euclidean metric outside a compact set.\nSpecifically, we prove that the knowledge of the partial exterior\nDirichlet--to--Neumann map for the fractional Laplace-Beltrami operator, given\non arbitrary open nonempty sets in the exterior of the domain in the Euclidean\nspace, determines the Riemannian metric up to diffeomorphism, fixing the\nexterior. We provide two proofs of this result: one relies on the heat\nsemigroup representation of the fractional Laplacian and a pseudodifferential\napproach, while the other is based on a variable-coefficient elliptic extension\ninterpretation of the fractional Laplacian.",
    "pdf_url": "http://arxiv.org/pdf/2502.00710v1",
    "published": "2025-02-02T07:50:01+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.00709v4",
    "title": "RankFlow: A Multi-Role Collaborative Reranking Workflow Utilizing Large Language Models",
    "authors": [
      "Can Jin",
      "Hongwu Peng",
      "Anxiang Zhang",
      "Nuo Chen",
      "Jiahui Zhao",
      "Xi Xie",
      "Kuangzheng Li",
      "Shuya Feng",
      "Kai Zhong",
      "Caiwen Ding",
      "Dimitris N. Metaxas"
    ],
    "abstract": "In an Information Retrieval (IR) system, reranking plays a critical role by\nsorting candidate passages according to their relevance to a specific query.\nThis process demands a nuanced understanding of the variations among passages\nlinked to the query. In this work, we introduce RankFlow, a multi-role\nreranking workflow that leverages the capabilities of Large Language Models\n(LLMs) and role specializations to improve reranking performance. RankFlow\nenlists LLMs to fulfill four distinct roles: the query Rewriter, the pseudo\nAnswerer, the passage Summarizer, and the Reranker. This orchestrated approach\nenables RankFlow to: (1) accurately interpret queries, (2) draw upon LLMs'\nextensive pre-existing knowledge, (3) distill passages into concise versions,\nand (4) assess passages in a comprehensive manner, resulting in notably better\nreranking results. Our experimental results reveal that RankFlow outperforms\nexisting leading approaches on widely recognized IR benchmarks, such as\nTREC-DL, BEIR, and NovelEval. Additionally, we investigate the individual\ncontributions of each role in RankFlow.",
    "pdf_url": "http://arxiv.org/pdf/2502.00709v4",
    "published": "2025-02-02T07:49:56+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00708v1",
    "title": "PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation",
    "authors": [
      "Qixuan Li",
      "Chao Wang",
      "Zongjin He",
      "Yan Peng"
    ],
    "abstract": "Text-to-3D asset generation has achieved significant optimization under the\nsupervision of 2D diffusion priors. However, when dealing with compositional\nscenes, existing methods encounter several challenges: 1). failure to ensure\nthat composite scene layouts comply with physical laws; 2). difficulty in\naccurately capturing the assets and relationships described in complex scene\ndescriptions; 3). limited autonomous asset generation capabilities among layout\napproaches leveraging large language models (LLMs). To avoid these compromises,\nwe propose a novel framework for compositional scene generation, PhiP-G, which\nseamlessly integrates generation techniques with layout guidance based on a\nworld model. Leveraging LLM-based agents, PhiP-G analyzes the complex scene\ndescription to generate a scene graph, and integrating a multimodal 2D\ngeneration agent and a 3D Gaussian generation method for targeted assets\ncreation. For the stage of layout, PhiP-G employs a physical pool with adhesion\ncapabilities and a visual supervision agent, forming a world model for layout\nprediction and planning. Extensive experiments demonstrate that PhiP-G\nsignificantly enhances the generation quality and physical rationality of the\ncompositional scenes. Notably, PhiP-G attains state-of-the-art (SOTA)\nperformance in CLIP scores, achieves parity with the leading methods in\ngeneration quality as measured by the T$^3$Bench, and improves efficiency by\n24x.",
    "pdf_url": "http://arxiv.org/pdf/2502.00708v1",
    "published": "2025-02-02T07:47:03+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00707v2",
    "title": "Sharing quantum nonlocality and teleportation over long distance using optical hybrid states",
    "authors": [
      "Subhankar Bera",
      "Soumyakanti Bose",
      "Hyunseok Jeong",
      "Archan S Majumdar"
    ],
    "abstract": "We analyze sharing Bell-type nonlocal correlation between two distant parties\nwith optical hybrid states comprising a single photon polarization state and a\nmultiphoton coherent state. By deploying entanglement swapping over the\ncoherent state parts at the middle station, we show that the optical hybrid\nstates can efficiently generate a polarization-entangled state that violates\nClauser-Horne-Shimony-Holt (CHSH) Bell-inequality well over a metropolitan\ndistance. We further assess the quality of the shared entangled state in the\ninformation processing task of quantum teleportation of an unknown polarization\nqubit. Our results with realistic devices, embedding detection inefficiency and\ntransmission losses, indicate the viability of faithful quantum teleportation\nover large distances, consistent with the quality of the shared correlation.",
    "pdf_url": "http://arxiv.org/pdf/2502.00707v2",
    "published": "2025-02-02T07:46:02+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.01684v4",
    "title": "Predict, Cluster, Refine: A Joint Embedding Predictive Self-Supervised Framework for Graph Representation Learning",
    "authors": [
      "Srinitish Srinivasan",
      "Omkumar CU"
    ],
    "abstract": "Graph representation learning has emerged as a cornerstone for tasks like\nnode classification and link prediction, yet prevailing self-supervised\nlearning (SSL) methods face challenges such as computational inefficiency,\nreliance on contrastive objectives, and representation collapse. Existing\napproaches often depend on feature reconstruction, negative sampling, or\ncomplex decoders, which introduce training overhead and hinder generalization.\nFurther, current techniques which address such limitations fail to account for\nthe contribution of node embeddings to a certain prediction in the absence of\nlabeled nodes. To address these limitations, we propose a novel joint embedding\npredictive framework for graph SSL that eliminates contrastive objectives and\nnegative sampling while preserving semantic and structural information.\nAdditionally, we introduce a semantic-aware objective term that incorporates\npseudo-labels derived from Gaussian Mixture Models (GMMs), enhancing node\ndiscriminability by evaluating latent feature contributions. Extensive\nexperiments demonstrate that our framework outperforms state-of-the-art graph\nSSL methods across benchmarks, achieving superior performance without\ncontrastive loss or complex decoders. Key innovations include (1) a\nnon-contrastive, view-invariant joint embedding predictive architecture, (2)\nLeveraging single context and multiple targets relationship between subgraphs,\nand (3) GMM-based pseudo-label scoring to capture semantic contributions. This\nwork advances graph SSL by offering a computationally efficient,\ncollapse-resistant paradigm that bridges spatial and semantic graph features\nfor downstream tasks. The code for our paper can be found at\nhttps://github.com/Deceptrax123/JPEB-GSSL",
    "pdf_url": "http://arxiv.org/pdf/2502.01684v4",
    "published": "2025-02-02T07:42:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00706v1",
    "title": "Model Provenance Testing for Large Language Models",
    "authors": [
      "Ivica Nikolic",
      "Teodora Baluta",
      "Prateek Saxena"
    ],
    "abstract": "Large language models are increasingly customized through fine-tuning and\nother adaptations, creating challenges in enforcing licensing terms and\nmanaging downstream impacts. Tracking model origins is crucial both for\nprotecting intellectual property and for identifying derived models when biases\nor vulnerabilities are discovered in foundation models. We address this\nchallenge by developing a framework for testing model provenance: Whether one\nmodel is derived from another. Our approach is based on the key observation\nthat real-world model derivations preserve significant similarities in model\noutputs that can be detected through statistical analysis. Using only black-box\naccess to models, we employ multiple hypothesis testing to compare model\nsimilarities against a baseline established by unrelated models. On two\ncomprehensive real-world benchmarks spanning models from 30M to 4B parameters\nand comprising over 600 models, our tester achieves 90-95% precision and 80-90%\nrecall in identifying derived models. These results demonstrate the viability\nof systematic provenance verification in production environments even when only\nAPI access is available.",
    "pdf_url": "http://arxiv.org/pdf/2502.00706v1",
    "published": "2025-02-02T07:39:37+00:00",
    "categories": [
      "cs.CR",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00705v1",
    "title": "Optimization for Neural Operators can Benefit from Width",
    "authors": [
      "Pedro Cisneros-Velarde",
      "Bhavesh Shrimali",
      "Arindam Banerjee"
    ],
    "abstract": "Neural Operators that directly learn mappings between function spaces, such\nas Deep Operator Networks (DONs) and Fourier Neural Operators (FNOs), have\nreceived considerable attention. Despite the universal approximation guarantees\nfor DONs and FNOs, there is currently no optimization convergence guarantee for\nlearning such networks using gradient descent (GD). In this paper, we address\nthis open problem by presenting a unified framework for optimization based on\nGD and applying it to establish convergence guarantees for both DONs and FNOs.\nIn particular, we show that the losses associated with both of these neural\noperators satisfy two conditions -- restricted strong convexity (RSC) and\nsmoothness -- that guarantee a decrease on their loss values due to GD.\nRemarkably, these two conditions are satisfied for each neural operator due to\ndifferent reasons associated with the architectural differences of the\nrespective models. One takeaway that emerges from the theory is that wider\nnetworks should lead to better optimization convergence for both DONs and FNOs.\nWe present empirical results on canonical operator learning problems to support\nour theoretical results.",
    "pdf_url": "http://arxiv.org/pdf/2502.00705v1",
    "published": "2025-02-02T07:33:00+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00704v1",
    "title": "What is the maximal connected partial symmetry index of a connected graph of a given size?",
    "authors": [
      "Z. Janelidze",
      "F. van Niekerk",
      "J. Viljoen"
    ],
    "abstract": "For a given graph, by its \\emph{connected partial symmetry index} we mean the\nnumber of all isomorphisms between connected induced subgraphs of the graph. In\nthis brief note we answer the question in the title.",
    "pdf_url": "http://arxiv.org/pdf/2502.00704v1",
    "published": "2025-02-02T07:27:57+00:00",
    "categories": [
      "math.CO",
      "05C30, 05A05, 05D99"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00703v1",
    "title": "DeLIAP e DeLIAJ: Interfaces de biblioteca de Dependabilidade para Python e Julia",
    "authors": [
      "Marcos Irigoyen",
      "Carla Santana",
      "Ramon C. F Araújo",
      "Samuel Xavier-de-Souza"
    ],
    "abstract": "The evergrowing computational complexity of High Performance Computing\napplications is often met with an horizontal scalling of computing systems.\nColaterally, each added node risks being a single point of failure to parallel\nprograms, increasing the demand for fault tolerant techniques to be applied,\nspecially at software level. Under such conditions, the fault tolerance library\nDeLIA was developed in C/C++ with error detection and recovery features. We\npropose, then, to extend the library's capabilities to Python and Julia through\nthe wrappers DeLIAP and DeLIAJ in order to lower the barrier to entry for\nimplementing fault-tolerant solutions in these languages, which both lack\nalternatives to the library. To validate the efficiency of the wrappers, an\napplication of the Julia wrapper in the 4D Full waveform inversion method was\nanalyzed, quantitatively assessing the introduced overhead through runtime\ncomparisons, while an implementation report is provided to address\napplicability. The added computational cost reflected on a median overhead of\n1.4%, while limitations in the original parallel computing module used in the\napplication rendered local-scope data checkpointing unfeasible.",
    "pdf_url": "http://arxiv.org/pdf/2502.00703v1",
    "published": "2025-02-02T07:27:34+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00702v1",
    "title": "CardioLive: Empowering Video Streaming with Online Cardiac Monitoring",
    "authors": [
      "Sheng Lyu",
      "Ruiming Huang",
      "Sijie Ji",
      "Yasar Abbas Ur Rehman",
      "Lan Ma",
      "Chenshu Wu"
    ],
    "abstract": "Online Cardiac Monitoring (OCM) emerges as a compelling enhancement for the\nnext-generation video streaming platforms. It enables various applications\nincluding remote health, online affective computing, and deepfake detection.\nYet the physiological information encapsulated in the video streams has been\nlong neglected. In this paper, we present the design and implementation of\nCardioLive, the first online cardiac monitoring system in video streaming\nplatforms. We leverage the naturally co-existed video and audio streams and\ndevise CardioNet, the first audio-visual network to learn the cardiac series.\nIt incorporates multiple unique designs to extract temporal and spectral\nfeatures, ensuring robust performance under realistic video streaming\nconditions. To enable the Service-On-Demand online cardiac monitoring, we\nimplement CardioLive as a plug-and-play middleware service and develop\nsystematic solutions to practical issues including changing FPS and\nunsynchronized streams. Extensive experiments have been done to demonstrate the\neffectiveness of our system. We achieve a Mean Square Error (MAE) of 1.79 BPM\nerror, outperforming the video-only and audio-only solutions by 69.2% and\n81.2%, respectively. Our CardioLive service achieves average throughputs of\n115.97 and 98.16 FPS when implemented in Zoom and YouTube. We believe our work\nopens up new applications for video stream systems. We will release the code\nsoon.",
    "pdf_url": "http://arxiv.org/pdf/2502.00702v1",
    "published": "2025-02-02T07:26:05+00:00",
    "categories": [
      "cs.HC",
      "cs.NI",
      "cs.SD",
      "eess.AS",
      "eess.IV"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00701v2",
    "title": "Orbital correlations in bilayer nickelates: roles of doping and interlayer coupling",
    "authors": [
      "Garima Goyal",
      "Aastha Jain",
      "Dheeraj Kumar Singh"
    ],
    "abstract": "We study the nature of orbital correlations present in the bilayer nickelate\nwithin a minimal two-orbital tight-binding model to gain insights into their\npossible role in stabilizing the less-known weakly-insulating state. The latter\nhas been observed experimentally at ambient pressure. In order to achieve this\nobjective, we examine the static orbital susceptibilities within the\nrandom-phase approximation. Our study highlights the sensitivity of orbital\ncorrelations to various factors including the interlayer coupling, carrier\nconcentration, band-structure details such as the orbital contents, the number\nof bands contributing at the Fermi level etc. We relate this sensitiveness to\nthe modification of the Fermi surfaces as well as their orbital contents\ndependent on aforementioned factors.",
    "pdf_url": "http://arxiv.org/pdf/2502.00701v2",
    "published": "2025-02-02T07:21:21+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.00700v3",
    "title": "S2CFormer: Revisiting the RD-Latency Trade-off in Transformer-based Learned Image Compression",
    "authors": [
      "Yunuo Chen",
      "Qian Li",
      "Bing He",
      "Donghui Feng",
      "Ronghua Wu",
      "Qi Wang",
      "Li Song",
      "Guo Lu",
      "Wenjun Zhang"
    ],
    "abstract": "Transformer-based Learned Image Compression (LIC) suffers from a suboptimal\ntrade-off between decoding latency and rate-distortion (R-D) performance.\nMoreover, the critical role of the FeedForward Network (FFN)-based channel\naggregation module has been largely overlooked. Our research reveals that\nefficient channel aggregation-rather than complex and time-consuming spatial\noperations-is the key to achieving competitive LIC models. Based on this\ninsight, we initiate the ``S2CFormer'' paradigm, a general architecture that\nsimplifies spatial operations and enhances channel operations to overcome the\nprevious trade-off. We present two instances of the S2CFormer: S2C-Conv, and\nS2C-Attention. Both models demonstrate state-of-the-art (SOTA) R-D performance\nand significantly faster decoding speed. Furthermore, we introduce S2C-Hybrid,\nan enhanced variant that maximizes the strengths of different S2CFormer\ninstances to achieve a better performance-latency trade-off. This model\noutperforms all the existing methods on the Kodak, Tecnick, and CLIC\nProfessional Validation datasets, setting a new benchmark for efficient and\nhigh-performance LIC. The code is at\n\\href{https://github.com/YunuoChen/S2CFormer}{https://github.com/YunuoChen/S2CFormer}.",
    "pdf_url": "http://arxiv.org/pdf/2502.00700v3",
    "published": "2025-02-02T07:15:51+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00699v1",
    "title": "Measurement and Analysis of Scattering From Building Surfaces at Millimeter-Wave Frequency",
    "authors": [
      "Yulu Guo",
      "Tongjia Zhang",
      "Shu Sun",
      "Meixia Tao",
      "Ruifeng Gao"
    ],
    "abstract": "In future air-to-ground integrated networks, the scattering effects from\nground-based scatterers, such as buildings, cannot be neglected in\nmillimeter-wave and higher frequency bands, and have a significant impact on\nchannel characteristics. However, current scattering measurement studies\nprimarily focus on single incident angles within the incident plane, leading to\ninsufficient characterization of scattering properties. In this paper, we\npresent scattering measurements conducted at 28 GHz on various real-world\nbuilding surfaces with multiple incident angles and three-dimensional (3D)\nreceiving angles. The measured data are analyzed in conjunction with\nparameterized scattering models in ray tracing and numerical simulations.\nResults indicate that for millimeter-wave channel modeling near building\nsurfaces, it is crucial to account not only for surface materials but also for\nthe scattering properties of the building surfaces with respect to the incident\nangle and receiving positions in 3D space.",
    "pdf_url": "http://arxiv.org/pdf/2502.00699v1",
    "published": "2025-02-02T07:13:40+00:00",
    "categories": [
      "eess.SP",
      "cs.ET"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.00698v2",
    "title": "MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models",
    "authors": [
      "Huanqia Cai",
      "Yijun Yang",
      "Winston Hu"
    ],
    "abstract": "IQ testing has served as a foundational methodology for evaluating human\ncognitive capabilities, deliberately decoupling assessment from linguistic\nbackground, language proficiency, or domain-specific knowledge to isolate core\ncompetencies in abstraction and reasoning. Yet, artificial intelligence\nresearch currently lacks systematic benchmarks to quantify these critical\ncognitive capabilities in multimodal systems. To address this crucial gap, we\npropose MM-IQ, a comprehensive evaluation framework, which comprises a\nlarge-scale training set with 4,776 visual reasoning problems and 2,710\nmeticulously curated test items spanning 8 distinct reasoning paradigms.\nThrough systematic evaluation of existing open-source and proprietary\nmultimodal models, our benchmark reveals striking limitations: even\nstate-of-the-art architectures achieve only marginally superior performance to\nrandom chance (33.17% vs. 25% baseline accuracy). This substantial performance\nchasm highlights the inadequacy of current multimodal models in approximating\nfundamental human reasoning capacities, underscoring the need for\nparadigm-shifting advancements to bridge this cognitive divide. Moreover,\ninspired by the recent surge of large reasoning models, we also release a\nmultimodal reasoning model as the baseline that is trained via reinforcement\nlearning with verifiable reward functions, reaching competitive performance to\nthe state-of-the-art with a notably smaller model size.",
    "pdf_url": "http://arxiv.org/pdf/2502.00698v2",
    "published": "2025-02-02T07:12:03+00:00",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00697v1",
    "title": "Role of Dirac cones in the anisotropic properties associated with the spin-density wave state of iron pnictides",
    "authors": [
      "Garima Goyal",
      "Dheeraj Kumar Singh"
    ],
    "abstract": "The origin of unusual anisotropic electronic properties in the spin-density\nwave state of iron pnictides has conventionally been attributed to the breaking\nof four-fold rotational symmetry associated with the collinear magnetic order.\nBy using a minimal two-orbital model, we show that a significant portion of the\ncontribution to the anisotropy may come from the Dirac cones, which are not far\naway from the Fermi level. We demonstrate this phenomenon by examining optical\nconductivity and quasiparticle interference in the Dirac-semimetallic state\nwith spin-density wave order, and the latter can be obtained by choosing\nappropriate interaction parameters and orbital splitting between the $d_{xz}$\nand $d_{yz}$ orbitals. We further extend this study to investigate the\nlow-energy spin-wave excitations in the Dirac-semimetallic state with\nspin-density wave order.",
    "pdf_url": "http://arxiv.org/pdf/2502.00697v1",
    "published": "2025-02-02T07:11:04+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.00696v1",
    "title": "Comprehensive Analysis of Bioactive Peptides from Cuminum cyminum L. Seeds: Sequence Identification and Pharmacological Evaluation",
    "authors": [
      "Ermatov Ismoil",
      "Sumairemu subuer",
      "Rena awuti",
      "Haili qian Taurtaihon",
      "Ahmidin wali",
      "Yasen Mijiti"
    ],
    "abstract": "Cuminum cyminum L. (cumin) is a medicinal and edible plant widely used in\ntraditional Chinese medicine (TCM) for treating various ailments, including\ndiarrhea, abdominal pain, inflammation, asthma, and diabetes. While previous\nresearch has primarily focused on its essential oils, studies on its\nprotein-derived bioactive peptides remain limited. In this study, we employed\nan innovative extraction method to isolate peptides from cumin seeds for the\nfirst time and screened their biological activities, revealing significant\nantimicrobial, antioxidant, and hypoglycemic properties. Guided by bioactivity,\nwe utilized advanced separation and structural identification techniques,\nincluding Matrix-Assisted Laser Desorption/Ionization Time-of-Flight Mass\nSpectrometry (MALDI-TOF/TOF MS/MS), to systematically purify and characterize\ncumin-derived peptides. A total of 479 unique peptide sequences were identified\nusing Mascot software and the SwissProt/UniProt_Bos databases. Among these, 15\nhighly bioactive peptides were selected for further analysis based on\nbioactivity and toxicity predictions using PeptideRanker and ToxinPred.\nStructural characterization revealed key features, such as {\\alpha}-helices and\n\\b{eta}-sheets, associated with their multifunctional activities. This study\nprovides the first comprehensive analysis of bioactive peptides from Cuminum\ncyminum L. seeds, elucidating their potential as antimicrobial, antioxidant,\nand hypoglycemic agents. These findings not only clarify the pharmacological\nbasis of cumin's traditional uses but also lay a theoretical foundation for the\ndevelopment of novel therapeutic agents from this medicinal plant.",
    "pdf_url": "http://arxiv.org/pdf/2502.00696v1",
    "published": "2025-02-02T07:09:07+00:00",
    "categories": [
      "q-bio.OT"
    ],
    "primary_category": "q-bio.OT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00695v1",
    "title": "TMI-CLNet: Triple-Modal Interaction Network for Chronic Liver Disease Prognosis From Imaging, Clinical, and Radiomic Data Fusion",
    "authors": [
      "Linglong Wu",
      "Xuhao Shan",
      "Ruiquan Ge",
      "Ruoyu Liang",
      "Chi Zhang",
      "Yonghong Li",
      "Ahmed Elazab",
      "Huoling Luo",
      "Yunbi Liu",
      "Changmiao Wang"
    ],
    "abstract": "Chronic liver disease represents a significant health challenge worldwide and\naccurate prognostic evaluations are essential for personalized treatment plans.\nRecent evidence suggests that integrating multimodal data, such as computed\ntomography imaging, radiomic features, and clinical information, can provide\nmore comprehensive prognostic information. However, modalities have an inherent\nheterogeneity, and incorporating additional modalities may exacerbate the\nchallenges of heterogeneous data fusion. Moreover, existing multimodal fusion\nmethods often struggle to adapt to richer medical modalities, making it\ndifficult to capture inter-modal relationships. To overcome these limitations,\nWe present the Triple-Modal Interaction Chronic Liver Network (TMI-CLNet).\nSpecifically, we develop an Intra-Modality Aggregation module and a\nTriple-Modal Cross-Attention Fusion module, which are designed to eliminate\nintra-modality redundancy and extract cross-modal information, respectively.\nFurthermore, we design a Triple-Modal Feature Fusion loss function to align\nfeature representations across modalities. Extensive experiments on the liver\nprognosis dataset demonstrate that our approach significantly outperforms\nexisting state-of-the-art unimodal models and other multi-modal techniques. Our\ncode is available at https://github.com/Mysterwll/liver.git.",
    "pdf_url": "http://arxiv.org/pdf/2502.00695v1",
    "published": "2025-02-02T07:05:28+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00694v1",
    "title": "Leveraging Large Language Models to Predict Antibody Biological Activity Against Influenza A Hemagglutinin",
    "authors": [
      "Ella Barkan",
      "Ibrahim Siddiqui",
      "Kevin J. Cheng",
      "Alex Golts",
      "Yoel Shoshan",
      "Jeffrey K. Weber",
      "Yailin Campos Mota",
      "Michal Ozery-Flato",
      "Giuseppe A. Sautto"
    ],
    "abstract": "Monoclonal antibodies (mAbs) represent one of the most prevalent FDA-approved\nmodalities for treating autoimmune diseases, infectious diseases, and cancers.\nHowever, discovery and development of therapeutic antibodies remains a\ntime-consuming and expensive process. Recent advancements in machine learning\n(ML) and artificial intelligence (AI) have shown significant promise in\nrevolutionizing antibody discovery and optimization. In particular, models that\npredict antibody biological activity enable in-silico evaluation of binding and\nfunctional properties; such models can prioritize antibodies with the highest\nlikelihoods of success in costly and time-intensive laboratory testing\nprocedures. We here explore an AI model for predicting the binding and receptor\nblocking activity of antibodies against influenza A hemagglutinin (HA)\nantigens. Our present model is developed with the MAMMAL framework for\nbiologics discovery to predict antibody-antigen interactions using only\nsequence information. To evaluate the model's performance, we tested it under\nvarious data split conditions to mimic real-world scenarios.\n  Our models achieved an AUROC $\\geq$ 0.91 for predicting the activity of\nexisting antibodies against seen HAs and an AUROC of 0.9 for unseen HAs. For\nnovel antibody activity prediction, the AUROC was 0.73, which further declined\nto 0.63-0.66 under stringent constraints on similarity to existing antibodies.\nThese results demonstrate the potential of AI foundation models to transform\nantibody design by reducing dependence on extensive laboratory testing and\nenabling more efficient prioritization of antibody candidates. Moreover, our\nfindings emphasize the critical importance of diverse and comprehensive\nantibody datasets to improve the generalization of prediction models,\nparticularly for novel antibody development.",
    "pdf_url": "http://arxiv.org/pdf/2502.00694v1",
    "published": "2025-02-02T06:48:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00693v1",
    "title": "DPBloomfilter: Securing Bloom Filters with Differential Privacy",
    "authors": [
      "Yekun Ke",
      "Yingyu Liang",
      "Zhizhou Sha",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "The Bloom filter is a simple yet space-efficient probabilistic data structure\nthat supports membership queries for dramatically large datasets. It is widely\nutilized and implemented across various industrial scenarios, often handling\nmassive datasets that include sensitive user information necessitating privacy\npreservation. To address the challenge of maintaining privacy within the Bloom\nfilter, we have developed the DPBloomfilter. This innovation integrates the\nclassical differential privacy mechanism, specifically the Random Response\ntechnique, into the Bloom filter, offering robust privacy guarantees under the\nsame running complexity as the standard Bloom filter. Through rigorous\nsimulation experiments, we have demonstrated that our DPBloomfilter algorithm\nmaintains high utility while ensuring privacy protections. To the best of our\nknowledge, this is the first work to provide differential privacy guarantees\nfor the Bloom filter for membership query problems.",
    "pdf_url": "http://arxiv.org/pdf/2502.00693v1",
    "published": "2025-02-02T06:47:50+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00692v1",
    "title": "Machine learning based Photometric Redshifts for Galaxies in the North Ecliptic Pole Wide field: catalogs of spectroscopic and photometric redshifts",
    "authors": [
      "Taewan Kim",
      "Jubee Sohn",
      "Ho Seong Hwang",
      "Simon C. -C. Ho",
      "Denis Burgarella",
      "Tomotsugu Goto",
      "Tetsuya Hashimoto",
      "Woong-Seob Jeong",
      "Seong Jin Kim",
      "Matthew A. Malkan",
      "Takamitsu Miyaji",
      "Nagisa Oi",
      "Hyunjin Shim",
      "Hyunmi Song",
      "Narae Hwang",
      "Byeong-Gon Park"
    ],
    "abstract": "We perform an MMT/Hectospec redshift survey of the North Ecliptic Pole Wide\n(NEPW) field covering 5.4 square degrees, and use it to estimate the\nphotometric redshifts for the sources without spectroscopic redshifts. By\ncombining 2572 newly measured redshifts from our survey with existing data from\nthe literature, we create a large sample of 4421 galaxies with spectroscopic\nredshifts in the NEPW field. Using this sample, we estimate photometric\nredshifts of 77755 sources in the band-merged catalog of the NEPW field with a\nrandom forest model. The estimated photometric redshifts are generally\nconsistent with the spectroscopic redshifts, with a dispersion of 0.028, an\noutlier fraction of 7.3%, and a bias of -0.01. We find that the standard\ndeviation of the prediction from each decision tree in the random forest model\ncan be used to infer the fraction of catastrophic outliers and the measurement\nuncertainties. We test various combinations of input observables, including\ncolors and magnitude uncertainties, and find that the details of these various\ncombinations do not change the prediction accuracy much. As a result, we\nprovide a catalog of 77755 sources in the NEPW field, which includes both\nspectroscopic and photometric redshifts up to z~2. This dataset has significant\nlegacy value for studies in the NEPW region, especially with upcoming space\nmissions such as JWST, Euclid, and SPHEREx.",
    "pdf_url": "http://arxiv.org/pdf/2502.00692v1",
    "published": "2025-02-02T06:43:44+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.01683v1",
    "title": "LLM-Powered Benchmark Factory: Reliable, Generic, and Efficient",
    "authors": [
      "Peiwen Yuan",
      "Shaoxiong Feng",
      "Yiwei Li",
      "Xinglin Wang",
      "Yueqi Zhang",
      "Jiayi Shi",
      "Chuyi Tan",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has led to a surge in\nboth model supply and application demands. To facilitate effective matching\nbetween them, reliable, generic and efficient benchmark generators are widely\nneeded. However, human annotators are constrained by inefficiency, and current\nLLM benchmark generators not only lack generalizability but also struggle with\nlimited reliability, as they lack a comprehensive evaluation framework for\nvalidation and optimization. To fill this gap, we first propose an automated\nand unbiased evaluation framework, structured around four dimensions and ten\ncriteria. Under this framework, we carefully analyze the advantages and\nweaknesses of directly prompting LLMs as generic benchmark generators. To\nenhance the reliability, we introduce a series of methods to address the\nidentified weaknesses and integrate them as BenchMaker. Experiments across\nmultiple LLMs and tasks confirm that BenchMaker achieves superior or comparable\nperformance to human-annotated benchmarks on all metrics, highlighting its\ngeneralizability and reliability. More importantly, it delivers highly\nconsistent evaluation results across 12 LLMs (0.967 Pearson correlation against\nMMLU-Pro), while taking only $0.005 and 0.38 minutes per sample.",
    "pdf_url": "http://arxiv.org/pdf/2502.01683v1",
    "published": "2025-02-02T06:36:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00691v4",
    "title": "To Code or not to Code? Adaptive Tool Integration for Math Language Models via Expectation-Maximization",
    "authors": [
      "Haozhe Wang",
      "Long Li",
      "Chao Qu",
      "Fengming Zhu",
      "Weidi Xu",
      "Wei Chu",
      "Fangzhen Lin"
    ],
    "abstract": "Recent advances in mathematical problem-solving with language models (LMs)\nintegrate chain-of-thought (CoT) reasoning and code execution to harness their\ncomplementary strengths. However, existing hybrid frameworks exhibit a critical\nlimitation: they depend on externally dictated instructions or rigid\ncode-integration templates, lacking metacognitive awareness -- the capacity to\ndynamically evaluate intrinsic capabilities and autonomously determine when and\nhow to integrate tools. This rigidity motivates our study of autonomous code\nintegration, enabling models to adapt tool-usage strategies as their reasoning\nabilities evolve during training.\n  While reinforcement learning (RL) shows promise for boosting LLM reasoning at\nscale (e.g., DeepSeek-R1), we demonstrate its inefficiency in learning\nautonomous code integration due to inadequate exploration of the vast\ncombinatorial space of CoT-code interleaving patterns. To address this\nchallenge, we propose a novel Expectation-Maximization (EM) framework that\nsynergizes structured exploration (E-step) with off-policy RL optimization\n(M-step), creating a self-reinforcing cycle between metacognitive tool-use\ndecisions and evolving capabilities. Experiments reveal our method achieves\nsuperior results through improved exploration. Notably, our 7B model improves\nover 11% on MATH500 and 9.4% on AIME without o1-like CoT.",
    "pdf_url": "http://arxiv.org/pdf/2502.00691v4",
    "published": "2025-02-02T06:32:23+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00690v1",
    "title": "Dissecting Submission Limit in Desk-Rejections: A Mathematical Analysis of Fairness in AI Conference Policies",
    "authors": [
      "Yuefan Cao",
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhizhou Sha",
      "Zhenmei Shi",
      "Zhao Song",
      "Jiahao Zhang"
    ],
    "abstract": "As AI research surges in both impact and volume, conferences have imposed\nsubmission limits to maintain paper quality and alleviate organizational\npressure. In this work, we examine the fairness of desk-rejection systems under\nsubmission limits and reveal that existing practices can result in substantial\ninequities. Specifically, we formally define the paper submission limit problem\nand identify a critical dilemma: when the number of authors exceeds three, it\nbecomes impossible to reject papers solely based on excessive submissions\nwithout negatively impacting innocent authors. Thus, this issue may unfairly\naffect early-career researchers, as their submissions may be penalized due to\nco-authors with significantly higher submission counts, while senior\nresearchers with numerous papers face minimal consequences. To address this, we\npropose an optimization-based fairness-aware desk-rejection mechanism and\nformally define two fairness metrics: individual fairness and group fairness.\nWe prove that optimizing individual fairness is NP-hard, whereas group fairness\ncan be efficiently optimized via linear programming. Through case studies, we\ndemonstrate that our proposed system ensures greater equity than existing\nmethods, including those used in CVPR 2025, offering a more socially just\napproach to managing excessive submissions in AI conferences.",
    "pdf_url": "http://arxiv.org/pdf/2502.00690v1",
    "published": "2025-02-02T06:29:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.DL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00689v1",
    "title": "Leveraging LLMs for Dynamic IoT Systems Generation through Mixed-Initiative Interaction",
    "authors": [
      "Bassam Adnan",
      "Sathvika Miryala",
      "Aneesh Sambu",
      "Karthik Vaidhyanathan",
      "Martina De Sanctis",
      "Romina Spalazzese"
    ],
    "abstract": "IoT systems face significant challenges in adapting to user needs, which are\noften under-specified and evolve with changing environmental contexts. To\naddress these complexities, users should be able to explore possibilities,\nwhile IoT systems must learn and support users in the process of providing\nproper services, e.g., to serve novel experiences. The IoT-Together paradigm\naims to meet this demand through the Mixed-Initiative Interaction (MII)\nparadigm that facilitates a collaborative synergy between users and IoT\nsystems, enabling the co-creation of intelligent and adaptive solutions that\nare precisely aligned with user-defined goals. This work advances IoT-Together\nby integrating Large Language Models (LLMs) into its architecture. Our approach\nenables intelligent goal interpretation through a multi-pass dialogue framework\nand dynamic service generation at runtime according to user needs. To\ndemonstrate the efficacy of our methodology, we design and implement the system\nin the context of a smart city tourism case study. We evaluate the system's\nperformance using agent-based simulation and user studies. Results indicate\nefficient and accurate service identification and high adaptation quality. The\nempirical evidence indicates that the integration of Large Language Models\n(LLMs) into IoT architectures can significantly enhance the architectural\nadaptability of the system while ensuring real-world usability.",
    "pdf_url": "http://arxiv.org/pdf/2502.00689v1",
    "published": "2025-02-02T06:21:49+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.00688v1",
    "title": "High-Order Matching for One-Step Shortcut Diffusion Models",
    "authors": [
      "Bo Chen",
      "Chengyue Gong",
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhizhou Sha",
      "Zhenmei Shi",
      "Zhao Song",
      "Mingda Wan"
    ],
    "abstract": "One-step shortcut diffusion models [Frans, Hafner, Levine and Abbeel, ICLR\n2025] have shown potential in vision generation, but their reliance on\nfirst-order trajectory supervision is fundamentally limited. The Shortcut\nmodel's simplistic velocity-only approach fails to capture intrinsic manifold\ngeometry, leading to erratic trajectories, poor geometric alignment, and\ninstability-especially in high-curvature regions. These shortcomings stem from\nits inability to model mid-horizon dependencies or complex distributional\nfeatures, leaving it ill-equipped for robust generative modeling. In this work,\nwe introduce HOMO (High-Order Matching for One-Step Shortcut Diffusion), a\ngame-changing framework that leverages high-order supervision to revolutionize\ndistribution transportation. By incorporating acceleration, jerk, and beyond,\nHOMO not only fixes the flaws of the Shortcut model but also achieves\nunprecedented smoothness, stability, and geometric precision. Theoretically, we\nprove that HOMO's high-order supervision ensures superior approximation\naccuracy, outperforming first-order methods. Empirically, HOMO dominates in\ncomplex settings, particularly in high-curvature regions where the Shortcut\nmodel struggles. Our experiments show that HOMO delivers smoother trajectories\nand better distributional alignment, setting a new standard for one-step\ngenerative models.",
    "pdf_url": "http://arxiv.org/pdf/2502.00688v1",
    "published": "2025-02-02T06:19:59+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00687v1",
    "title": "A Flexible Precision Scaling Deep Neural Network Accelerator with Efficient Weight Combination",
    "authors": [
      "Liang Zhao",
      "Kunming Shao",
      "Fengshi Tian",
      "Tim Kwang-Ting Cheng",
      "Chi-Ying Tsui",
      "Yi Zou"
    ],
    "abstract": "Deploying mixed-precision neural networks on edge devices is friendly to\nhardware resources and power consumption. To support fully mixed-precision\nneural network inference, it is necessary to design flexible hardware\naccelerators for continuous varying precision operations. However, the previous\nworks have issues on hardware utilization and overhead of reconfigurable logic.\nIn this paper, we propose an efficient accelerator for 2~8-bit precision\nscaling with serial activation input and parallel weight preloaded. First, we\nset two loading modes for the weight operands and decompose the weight into the\ncorresponding bitwidths, which extends the weight precision support\nefficiently. Then, to improve hardware utilization of low-precision operations,\nwe design the architecture that performs bit-serial MAC operation with systolic\ndataflow, and the partial sums are combined spatially. Furthermore, we designed\nan efficient carry save adder tree supporting both signed and unsigned number\nsummation across rows. The experiment result shows that the proposed\naccelerator, synthesized with TSMC 28nm CMOS technology, achieves peak\nthroughput of 4.09TOPS and peak energy efficiency of 68.94TOPS/W at 2/2-bit\noperations.",
    "pdf_url": "http://arxiv.org/pdf/2502.00687v1",
    "published": "2025-02-02T06:15:55+00:00",
    "categories": [
      "cs.AR",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00686v3",
    "title": "Improved Community Detection using Stochastic Block Models",
    "authors": [
      "Minhyuk Park",
      "Daniel Wang Feng",
      "Siya Digra",
      "The-Anh Vu-Le",
      "Lahari Anne",
      "George Chacko",
      "Tandy Warnow"
    ],
    "abstract": "Identifying edge-dense communities that are also well-connected is an\nimportant aspect of understanding community structure. Prior work has shown\nthat community detection methods can produce poorly connected communities, and\nsome can even produce internally disconnected communities. In this study we\nevaluate the connectivity of communities obtained using Stochastic Block\nModels. We find that SBMs produce internally disconnected communities from\nreal-world networks. We present a simple technique, Well-Connected Clusters\n(WCC), which repeatedly removes small edge cuts until the communities meet a\nuser-specified threshold for well-connectivity. Our study using a large\ncollection of synthetic networks based on clustered real-world networks shows\nthat using WCC as a post-processing tool with SBM community detection typically\nimproves clustering accuracy. WCC is fast enough to use on networks with\nmillions of nodes and is freely available in open source form.",
    "pdf_url": "http://arxiv.org/pdf/2502.00686v3",
    "published": "2025-02-02T06:09:29+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00685v1",
    "title": "IEEEICM25: \"A High-Performance Disturbance Observer\"",
    "authors": [
      "Emre Sariyildiz"
    ],
    "abstract": "This paper proposes a novel Disturbance Observer, termed the High-Performance\nDisturbance Observer, which achieves more accurate disturbance estimation\ncompared to the conventional disturbance observer, thereby delivering\nsignificant improvements in robustness and performance for motion control\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2502.00685v1",
    "published": "2025-02-02T06:08:51+00:00",
    "categories": [
      "eess.SY",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.00684v1",
    "title": "Compositional Concept-Based Neuron-Level Interpretability for Deep Reinforcement Learning",
    "authors": [
      "Zeyu Jiang",
      "Hai Huang",
      "Xingquan Zuo"
    ],
    "abstract": "Deep reinforcement learning (DRL), through learning policies or values\nrepresented by neural networks, has successfully addressed many complex control\nproblems. However, the neural networks introduced by DRL lack interpretability\nand transparency. Current DRL interpretability methods largely treat neural\nnetworks as black boxes, with few approaches delving into the internal\nmechanisms of policy/value networks. This limitation undermines trust in both\nthe neural network models that represent policies and the explanations derived\nfrom them. In this work, we propose a novel concept-based interpretability\nmethod that provides fine-grained explanations of DRL models at the neuron\nlevel. Our method formalizes atomic concepts as binary functions over the state\nspace and constructs complex concepts through logical operations. By analyzing\nthe correspondence between neuron activations and concept functions, we\nestablish interpretable explanations for individual neurons in policy/value\nnetworks. Experimental results on both continuous control tasks and discrete\ndecision-making environments demonstrate that our method can effectively\nidentify meaningful concepts that align with human understanding while\nfaithfully reflecting the network's decision-making logic.",
    "pdf_url": "http://arxiv.org/pdf/2502.00684v1",
    "published": "2025-02-02T06:05:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.2.1; I.2.4"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00683v1",
    "title": "IEEEICM25: \"Stability of Digital Robust Motion Control Systems with Disturbance Observer\"",
    "authors": [
      "Emre Sariyildiz"
    ],
    "abstract": "In this paper, new stability analysis methods are proposed for digital robust\nmotion control systems implemented using a disturbance observer.",
    "pdf_url": "http://arxiv.org/pdf/2502.00683v1",
    "published": "2025-02-02T06:05:31+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.00682v1",
    "title": "Guidance Source Matters: How Guidance from AI, Expert, or a Group of Analysts Impacts Visual Data Preparation and Analysis",
    "authors": [
      "Arpit Narechania",
      "Alex Endert",
      "Atanu R Sinha"
    ],
    "abstract": "The progress in generative AI has fueled AI-powered tools like co-pilots and\nassistants to provision better guidance, particularly during data analysis.\nHowever, research on guidance has not yet examined the perceived efficacy of\nthe source from which guidance is offered and the impact of this source on the\nuser's perception and usage of guidance. We ask whether users perceive all\nguidance sources as equal, with particular interest in three sources: (i) AI,\n(ii) human expert, and (iii) a group of human analysts. As a benchmark, we\nconsider a fourth source, (iv) unattributed guidance, where guidance is\nprovided without attribution to any source, enabling isolation of and\ncomparison with the effects of source-specific guidance. We design a\nfive-condition between-subjects study, with one condition for each of the four\nguidance sources and an additional (v) no-guidance condition, which serves as a\nbaseline to evaluate the influence of any kind of guidance. We situate our\nstudy in a custom data preparation and analysis tool wherein we task users to\nselect relevant attributes from an unfamiliar dataset to inform a business\nreport. Depending on the assigned condition, users can request guidance, which\nthe system then provides in the form of attribute suggestions. To ensure\ninternal validity, we control for the quality of guidance across\nsource-conditions. Through several metrics of usage and perception, we\nstatistically test five preregistered hypotheses and report on additional\nanalysis. We find that the source of guidance matters to users, but not in a\nmanner that matches received wisdom. For instance, users utilize guidance\ndifferently at various stages of analysis, including expressing varying levels\nof regret, despite receiving guidance of similar quality. Notably, users in the\nAI condition reported both higher post-task benefit and regret.",
    "pdf_url": "http://arxiv.org/pdf/2502.00682v1",
    "published": "2025-02-02T05:59:02+00:00",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00681v1",
    "title": "A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models",
    "authors": [
      "Qika Lin",
      "Zhen Peng",
      "Kaize Shi",
      "Kai He",
      "Yiming Xu",
      "Erik Cambria",
      "Mengling Feng"
    ],
    "abstract": "Recent years have witnessed rapid advances in graph representation learning,\nwith the continuous embedding approach emerging as the dominant paradigm.\nHowever, such methods encounter issues regarding parameter efficiency,\ninterpretability, and robustness. Thus, Quantized Graph Representation (QGR)\nlearning has recently gained increasing interest, which represents the graph\nstructure with discrete codes instead of conventional continuous embeddings.\nGiven its analogous representation form to natural language, QGR also possesses\nthe capability to seamlessly integrate graph structures with large language\nmodels (LLMs). As this emerging paradigm is still in its infancy yet holds\nsignificant promise, we undertake this thorough survey to promote its rapid\nfuture prosperity. We first present the background of the general quantization\nmethods and their merits. Moreover, we provide an in-depth demonstration of\ncurrent QGR studies from the perspectives of quantized strategies, training\nobjectives, distinctive designs, knowledge graph quantization, and\napplications. We further explore the strategies for code dependence learning\nand integration with LLMs. At last, we give discussions and conclude future\ndirections, aiming to provide a comprehensive picture of QGR and inspire future\nresearch.",
    "pdf_url": "http://arxiv.org/pdf/2502.00681v1",
    "published": "2025-02-02T05:57:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00680v1",
    "title": "Some structural complexity results for $\\exists\\mathbb R$",
    "authors": [
      "Klaus Meer",
      "Adrian Wurm"
    ],
    "abstract": "The complexity class $\\exists\\mathbb R$, standing for the complexity of\ndeciding the existential first order theory of the reals as real closed field\nin the Turing model, has raised considerable interest in recent years. It is\nwell known that NP $ \\subseteq \\exists\\mathbb R\\subseteq$ PSPACE. In their\ncompendium, Schaefer, Cardinal, and Miltzow give a comprehensive presentation\nof results together with a rich collection of open problems. Here, we answer\nsome of them dealing with structural issues of $\\exists\\mathbb R$ as a\ncomplexity class. We show analogues of the classical results of Baker, Gill,\nand Solovay finding oracles which do and do not separate NP form\n$\\exists\\mathbb R$, of Ladner's theorem showing the existence of problems in\n$\\exists\\mathbb R \\setminus$ NP not being complete for $\\exists\\mathbb R$ (in\ncase the two classes are different), as well as a characterization of\n$\\exists\\mathbb R$ by means of descriptive complexity.",
    "pdf_url": "http://arxiv.org/pdf/2502.00680v1",
    "published": "2025-02-02T05:54:54+00:00",
    "categories": [
      "cs.CC"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2503.15518v2",
    "title": "Robot Character Generation and Adaptive Human-Robot Interaction with Personality Shaping",
    "authors": [
      "Cheng Tang",
      "Chao Tang",
      "Steven Gong",
      "Thomas M. Kwok",
      "Yue Hu"
    ],
    "abstract": "We present a novel framework for designing emotionally agile robots with\ndynamic personalities and memory-based learning, with the aim of performing\nadaptive and non-deterministic interactions with humans while conforming to\nshared social understanding. While existing work has largely focused on emotion\nrecognition and static response systems, many approaches rely on sentiment\nanalysis and action mapping frameworks that are pre-defined with limited\ndimensionality and fixed configurations, lacking the flexibility of dynamic\npersonality traits and memory-enabled adaptation. Other systems are often\nrestricted to limited modes of expression and fail to develop a causal\nrelationship between human behavior and the robot's proactive physical actions,\nresulting in constrained adaptability and reduced responsiveness in complex,\ndynamic interactions. Our methodology integrates the Big Five Personality\nTraits, Appraisal Theory, and abstracted memory layers through Large Language\nModels (LLMs). The LLM generates a parameterized robot personality based on the\nBig Five, processes human language and sentiments, evaluates human behavior\nusing Appraisal Theory, and generates emotions and selects appropriate actions\nadapted by historical context over time. We validated the framework by testing\nthree robots with distinct personalities in identical background contexts and\nfound that personality, appraisal, and memory influence the adaptability of\nhuman-robot interactions. The impact of the individual components was further\nvalidated through ablation tests. We conclude that this system enables robots\nto engage in meaningful and personalized interactions with users, and holds\nsignificant potential for applications in domains such as pet robots, assistive\nrobots, educational robots, and collaborative functional robots, where\ncultivating tailored relationships and enriching user experiences are\nessential.",
    "pdf_url": "http://arxiv.org/pdf/2503.15518v2",
    "published": "2025-02-02T05:53:13+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00679v2",
    "title": "Expedited Noise Spectroscopy of Transmon Qubits",
    "authors": [
      "Bhavesh Gupta",
      "Vismay Joshi",
      "Udit Kandpal",
      "Prabha Mandayam",
      "Nicolas Gheeraert",
      "Siddharth Dhomkar"
    ],
    "abstract": "There has been tremendous progress in the physical realization of quantum\ncomputing hardware in recent times, bringing us closer than ever before to\nrealizing the promise of quantum computing. However, noise continues to pose a\ncrucial challenge when it comes to scaling up present day quantum processors.\nWhile decoherence limits the qubits ability to store information for long\nperiods in the presence of uncontrollable noise sources, the erroneous\nimplementation of control methods for state preparation and measurements leads\nto faulty implementations of quantum circuits. Conventional noise spectroscopy\nprotocols can characterize and model environmental noise but are usually\nresource intensive and lengthy. Moreover, the underlying noise can vary in\nnature over time, making noise profile extraction futile as this new\ninformation cannot be harnessed to improve quantum error correction or\ndynamical decoupling protocols. In this work, we address this challenge using a\nmachine learning-based methodology to quickly extract noise spectra of multiple\nqubits and demonstrate a possible noise mitigation strategy. The procedure\ninvolves implementing undemanding dynamical decoupling sequences to record\ncoherence decays of the investigated qubits and then predict the underlying\nnoise spectra with the help of a convolution neural network pre-trained on a\nsynthetic dataset. While our protocol is virtually hardware-agnostic, we\nvalidate its effectiveness using superconducting qubits available on the IBM\nQuantum platform. We further use these rapidly obtained, yet accurate, noise\nspectra to design bespoke dynamic decoupling sequences and perform\ntime-dependent noise spectroscopy.",
    "pdf_url": "http://arxiv.org/pdf/2502.00679v2",
    "published": "2025-02-02T05:52:45+00:00",
    "categories": [
      "quant-ph",
      "physics.app-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00678v2",
    "title": "How Contaminated Is Your Benchmark? Quantifying Dataset Leakage in Large Language Models with Kernel Divergence",
    "authors": [
      "Hyeong Kyu Choi",
      "Maxim Khanov",
      "Hongxin Wei",
      "Yixuan Li"
    ],
    "abstract": "Dataset contamination, where evaluation datasets overlap with pre-training\ncorpora, inflates performance metrics and undermines the reliability of model\nevaluations. Measuring dataset contamination thus becomes essential to ensure\nthat performance evaluations genuinely reflect a model's ability to generalize\nto unseen data, rather than relying on memorized examples. To address this\nproblem, we propose Kernel Divergence Score (KDS), a novel method that\nevaluates dataset contamination by computing the divergence between the kernel\nsimilarity matrix of sample embeddings, before and after fine-tuning on the\nbenchmark dataset. Leveraging the insight that fine-tuning affects unseen\nsamples more significantly than seen ones, KDS provides a reliable measure of\ncontamination. Through extensive experiments on controlled contamination\nscenarios, KDS demonstrates a near-perfect correlation with contamination\nlevels and outperforms existing baselines. Additionally, we perform\ncomprehensive ablation studies to analyze the impact of key design choices,\nproviding deeper insights into the components and effectiveness of KDS. These\nablations highlight the importance of leveraging fine-grained kernel-based\ninformation and confirm the reliability of the proposed framework across\ndiverse datasets and settings. Code is released in\nhttps://github.com/deeplearning-wisc/kernel-divergence-score.",
    "pdf_url": "http://arxiv.org/pdf/2502.00678v2",
    "published": "2025-02-02T05:50:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.13969v1",
    "title": "Bridging Simulation and Reality: A 3D Clustering-Based Deep Learning Model for UAV-Based RF Source Localization",
    "authors": [
      "Saad Masrur",
      "Ismail Guvenc"
    ],
    "abstract": "Localization of radio frequency (RF) sources has critical applications,\nincluding search and rescue, jammer detection, and monitoring of hostile\nactivities. Unmanned aerial vehicles (UAVs) offer significant advantages for RF\nsource localization (RFSL) over terrestrial methods, leveraging autonomous 3D\nnavigation and improved signal capture at higher altitudes. Recent advancements\nin deep learning (DL) have further enhanced localization accuracy, particularly\nfor outdoor scenarios. DL models often face challenges in real-world\nperformance, as they are typically trained on simulated datasets that fail to\nreplicate real-world conditions fully. To address this, we first propose the\nEnhanced Two-Ray propagation model, reducing the simulation-to-reality gap by\nimproving the accuracy of propagation environment modeling. For RFSL, we\npropose the 3D Cluster-Based RealAdaptRNet, a DL-based method leveraging 3D\nclustering-based feature extraction for robust localization. Experimental\nresults demonstrate that the proposed Enhanced Two-Ray model provides superior\naccuracy in simulating real-world propagation scenarios compared to\nconventional free-space and two-ray models. Notably, the 3D Cluster-Based\nRealAdaptRNet, trained entirely on simulated datasets, achieves exceptional\nperformance when validated in real-world environments using the AERPAW physical\ntestbed, with an average localization error of 18.2 m. The proposed approach is\ncomputationally efficient, utilizing 33.5 times fewer parameters, and\ndemonstrates strong generalization capabilities across diverse trajectories,\nmaking it highly suitable for real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.13969v1",
    "published": "2025-02-02T05:48:44+00:00",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.01682v1",
    "title": "The exception of humour: Iconicity, Phonemic Surprisal, Memory Recall, and Emotional Associations",
    "authors": [
      "Alexander Kilpatrick",
      "Maria Flaksman"
    ],
    "abstract": "This meta-study explores the relationships between humor, phonemic bigram\nsurprisal, emotional valence, and memory recall. Prior research indicates that\nwords with higher phonemic surprisal are more readily remembered, suggesting\nthat unpredictable phoneme sequences promote long-term memory recall. Emotional\nvalence is another well-documented factor influencing memory, with negative\nexperiences and stimuli typically being remembered more easily than positive\nones. Building on existing findings, this study highlights that words with\nnegative associations often exhibit greater surprisal and are easier to recall.\nHumor, however, presents an exception: while associated with positive emotions,\nhumorous words also display heightened surprisal and enhanced memorability.",
    "pdf_url": "http://arxiv.org/pdf/2502.01682v1",
    "published": "2025-02-02T05:31:46+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00677v1",
    "title": "LLM-based event log analysis techniques: A survey",
    "authors": [
      "Siraaj Akhtar",
      "Saad Khan",
      "Simon Parkinson"
    ],
    "abstract": "Event log analysis is an important task that security professionals\nundertake. Event logs record key information on activities that occur on\ncomputing devices, and due to the substantial number of events generated, they\nconsume a large amount of time and resources to analyse. This demanding and\nrepetitive task is also prone to errors. To address these concerns, researchers\nhave developed automated techniques to improve the event log analysis process.\nLarge Language Models (LLMs) have recently demonstrated the ability to\nsuccessfully perform a wide range of tasks that individuals would usually\npartake in, to high standards, and at a pace and degree of complexity that\noutperform humans. Due to this, researchers are rapidly investigating the use\nof LLMs for event log analysis. This includes fine-tuning, Retrieval-Augmented\nGeneration (RAG) and in-context learning, which affect performance. These works\ndemonstrate good progress, yet there is a need to understand the developing\nbody of knowledge, identify commonalities between works, and identify key\nchallenges and potential solutions to further developments in this domain. This\npaper aims to survey LLM-based event log analysis techniques, providing readers\nwith an in-depth overview of the domain, gaps identified in previous research,\nand concluding with potential avenues to explore in future.",
    "pdf_url": "http://arxiv.org/pdf/2502.00677v1",
    "published": "2025-02-02T05:28:17+00:00",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00676v1",
    "title": "Optimal local certification on graphs of bounded pathwidth",
    "authors": [
      "Dan Alden Baterisna",
      "Yi-Jun Chang"
    ],
    "abstract": "We present proof labeling schemes for graphs with bounded pathwidth that can\ndecide any graph property expressible in monadic second-order (MSO) logic using\n$O(\\log n)$-bit vertex labels. Examples of such properties include planarity,\nHamiltonicity, $k$-colorability, $H$-minor-freeness, admitting a perfect\nmatching, and having a vertex cover of a given size.\n  Our proof labeling schemes improve upon a recent result by Fraigniaud,\nMontealegre, Rapaport, and Todinca (Algorithmica 2024), which achieved the same\nresult for graphs of bounded treewidth but required $O(\\log^2 n)$-bit labels.\nOur improved label size $O(\\log n)$ is optimal, as it is well-known that any\nproof labeling scheme that accepts paths and rejects cycles requires labels of\nsize $\\Omega(\\log n)$.\n  Our result implies that graphs with pathwidth at most $k$ can be certified\nusing $O(\\log n)$-bit labels for any fixed constant $k$. Applying the Excluding\nForest Theorem of Robertson and Seymour, we deduce that the class of\n$F$-minor-free graphs can be certified with $O(\\log n)$-bit labels for any\nfixed forest $F$, thereby providing an affirmative answer to an open question\nposed by Bousquet, Feuilloley, and Pierron (Journal of Parallel and Distributed\nComputing 2024).",
    "pdf_url": "http://arxiv.org/pdf/2502.00676v1",
    "published": "2025-02-02T05:28:08+00:00",
    "categories": [
      "cs.DC",
      "cs.DS"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.01681v3",
    "title": "DeepGate4: Efficient and Effective Representation Learning for Circuit Design at Scale",
    "authors": [
      "Ziyang Zheng",
      "Shan Huang",
      "Jianyuan Zhong",
      "Zhengyuan Shi",
      "Guohao Dai",
      "Ningyi Xu",
      "Qiang Xu"
    ],
    "abstract": "Circuit representation learning has become pivotal in electronic design\nautomation, enabling critical tasks such as testability analysis, logic\nreasoning, power estimation, and SAT solving. However, existing models face\nsignificant challenges in scaling to large circuits due to limitations like\nover-squashing in graph neural networks and the quadratic complexity of\ntransformer-based models. To address these issues, we introduce DeepGate4, a\nscalable and efficient graph transformer specifically designed for large-scale\ncircuits. DeepGate4 incorporates several key innovations: (1) an update\nstrategy tailored for circuit graphs, which reduce memory complexity to\nsub-linear and is adaptable to any graph transformer; (2) a GAT-based sparse\ntransformer with global and local structural encodings for AIGs; and (3) an\ninference acceleration CUDA kernel that fully exploit the unique sparsity\npatterns of AIGs. Our extensive experiments on the ITC99 and EPFL benchmarks\nshow that DeepGate4 significantly surpasses state-of-the-art methods, achieving\n15.5% and 31.1% performance improvements over the next-best models.\nFurthermore, the Fused-DeepGate4 variant reduces runtime by 35.1% and memory\nusage by 46.8%, making it highly efficient for large-scale circuit analysis.\nThese results demonstrate the potential of DeepGate4 to handle complex EDA\ntasks while offering superior scalability and efficiency. Code is available at\nhttps://github.com/zyzheng17/DeepGate4-ICLR-25.",
    "pdf_url": "http://arxiv.org/pdf/2502.01681v3",
    "published": "2025-02-02T05:25:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00675v5",
    "title": "ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Consensus Enforcement, and Column Exploration",
    "authors": [
      "Minghang Deng",
      "Ashwin Ramachandran",
      "Canwen Xu",
      "Lanxiang Hu",
      "Zhewei Yao",
      "Anupam Datta",
      "Hao Zhang"
    ],
    "abstract": "We present ReFoRCE, a Text-to-SQL agent that tops the Spider 2.0\nleaderboard--a challenging benchmark reflecting complex, real-world Text-to-SQL\nscenarios. While Text-to-SQL systems enable natural language queries over\nstructured databases, deploying them in enterprise environments remains\ndifficult due to large, complex schemas (with over 1,000 columns), diverse SQL\ndialects (e.g., BigQuery, Snowflake), and sophisticated query requirements\n(e.g., transformations and analytics). ReFoRCE addresses these challenges\nthrough: (a) database information compression via pattern-based table grouping\nand LLM-guided schema linking to alleviate long-context issues; (b)\nself-refinement to iteratively correct syntax and semantic errors across\ndialects; (c) majority-vote consensus to select high-confidence candidates\nwhile deferring ambiguous cases arising from sophisticated queries; and (d)\niterative column exploration guided by execution feedback to resolve those\ndeferred cases. ReFoRCE achieves new state-of-the-art results, with scores of\n35.83 on Spider 2.0-Snow and 36.56 on Spider 2.0-Lite.",
    "pdf_url": "http://arxiv.org/pdf/2502.00675v5",
    "published": "2025-02-02T05:25:03+00:00",
    "categories": [
      "cs.CL",
      "I.2.7; I.2.0; H.2.0"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00674v1",
    "title": "Rethinking Mixture-of-Agents: Is Mixing Different Large Language Models Beneficial?",
    "authors": [
      "Wenzhe Li",
      "Yong Lin",
      "Mengzhou Xia",
      "Chi Jin"
    ],
    "abstract": "Ensembling outputs from diverse sources is a straightforward yet effective\napproach to boost performance. Mixture-of-Agents (MoA) is one such popular\nensemble method that aggregates outputs from multiple different Large Language\nModels (LLMs). This paper raises the question in the context of language\nmodels: is mixing different LLMs truly beneficial? We propose Self-MoA -- an\nensemble method that aggregates outputs from only the single top-performing\nLLM. Our extensive experiments reveal that, surprisingly, Self-MoA outperforms\nstandard MoA that mixes different LLMs in a large number of scenarios: Self-MoA\nachieves $6.6\\%$ improvement over MoA on the AlpacaEval 2.0 benchmark, and an\naverage of $3.8\\%$ improvement across various benchmarks, including MMLU, CRUX,\nand MATH. Applying Self-MoA to one of the top-ranking models in AlpacaEval 2.0\ndirectly achieves the new state-of-the-art performance on the leaderboard. To\nunderstand the effectiveness of Self-MoA, we systematically investigate the\ntrade-off between diversity and quality of outputs under various MoA settings.\nWe confirm that the MoA performance is rather sensitive to the quality, and\nmixing different LLMs often lowers the average quality of the models. To\ncomplement the study, we identify the scenarios where mixing different LLMs\ncould be helpful. This paper further introduces a sequential version of\nSelf-MoA, that is capable of aggregating a large number of LLM outputs\non-the-fly over multiple rounds, and is as effective as aggregating all outputs\nat once.",
    "pdf_url": "http://arxiv.org/pdf/2502.00674v1",
    "published": "2025-02-02T05:23:29+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.05206v5",
    "title": "Safety at Scale: A Comprehensive Survey of Large Model and Agent Safety",
    "authors": [
      "Xingjun Ma",
      "Yifeng Gao",
      "Yixu Wang",
      "Ruofan Wang",
      "Xin Wang",
      "Ye Sun",
      "Yifan Ding",
      "Hengyuan Xu",
      "Yunhao Chen",
      "Yunhan Zhao",
      "Hanxun Huang",
      "Yige Li",
      "Yutao Wu",
      "Jiaming Zhang",
      "Xiang Zheng",
      "Yang Bai",
      "Zuxuan Wu",
      "Xipeng Qiu",
      "Jingfeng Zhang",
      "Yiming Li",
      "Xudong Han",
      "Haonan Li",
      "Jun Sun",
      "Cong Wang",
      "Jindong Gu",
      "Baoyuan Wu",
      "Siheng Chen",
      "Tianwei Zhang",
      "Yang Liu",
      "Mingming Gong",
      "Tongliang Liu",
      "Shirui Pan",
      "Cihang Xie",
      "Tianyu Pang",
      "Yinpeng Dong",
      "Ruoxi Jia",
      "Yang Zhang",
      "Shiqing Ma",
      "Xiangyu Zhang",
      "Neil Gong",
      "Chaowei Xiao",
      "Sarah Erfani",
      "Tim Baldwin",
      "Bo Li",
      "Masashi Sugiyama",
      "Dacheng Tao",
      "James Bailey",
      "Yu-Gang Jiang"
    ],
    "abstract": "The rapid advancement of large models, driven by their exceptional abilities\nin learning and generalization through large-scale pre-training, has reshaped\nthe landscape of Artificial Intelligence (AI). These models are now\nfoundational to a wide range of applications, including conversational AI,\nrecommendation systems, autonomous driving, content generation, medical\ndiagnostics, and scientific discovery. However, their widespread deployment\nalso exposes them to significant safety risks, raising concerns about\nrobustness, reliability, and ethical implications. This survey provides a\nsystematic review of current safety research on large models, covering Vision\nFoundation Models (VFMs), Large Language Models (LLMs), Vision-Language\nPre-training (VLP) models, Vision-Language Models (VLMs), Diffusion Models\n(DMs), and large-model-powered Agents. Our contributions are summarized as\nfollows: (1) We present a comprehensive taxonomy of safety threats to these\nmodels, including adversarial attacks, data poisoning, backdoor attacks,\njailbreak and prompt injection attacks, energy-latency attacks, data and model\nextraction attacks, and emerging agent-specific threats. (2) We review defense\nstrategies proposed for each type of attacks if available and summarize the\ncommonly used datasets and benchmarks for safety research. (3) Building on\nthis, we identify and discuss the open challenges in large model safety,\nemphasizing the need for comprehensive safety evaluations, scalable and\neffective defense mechanisms, and sustainable data practices. More importantly,\nwe highlight the necessity of collective efforts from the research community\nand international collaboration. Our work can serve as a useful reference for\nresearchers and practitioners, fostering the ongoing development of\ncomprehensive defense systems and platforms to safeguard AI models.",
    "pdf_url": "http://arxiv.org/pdf/2502.05206v5",
    "published": "2025-02-02T05:14:22+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.01680v1",
    "title": "Neurosymbolic AI for Travel Demand Prediction: Integrating Decision Tree Rules into Neural Networks",
    "authors": [
      "Kamal Acharya",
      "Mehul Lad",
      "Liang Sun",
      "Houbing Song"
    ],
    "abstract": "Travel demand prediction is crucial for optimizing transportation planning,\nresource allocation, and infrastructure development, ensuring efficient\nmobility and economic sustainability. This study introduces a Neurosymbolic\nArtificial Intelligence (Neurosymbolic AI) framework that integrates decision\ntree (DT)-based symbolic rules with neural networks (NNs) to predict travel\ndemand, leveraging the interpretability of symbolic reasoning and the\npredictive power of neural learning. The framework utilizes data from diverse\nsources, including geospatial, economic, and mobility datasets, to build a\ncomprehensive feature set. DTs are employed to extract interpretable if-then\nrules that capture key patterns, which are then incorporated as additional\nfeatures into a NN to enhance its predictive capabilities. Experimental results\nshow that the combined dataset, enriched with symbolic rules, consistently\noutperforms standalone datasets across multiple evaluation metrics, including\nMean Absolute Error (MAE), \\(R^2\\), and Common Part of Commuters (CPC). Rules\nselected at finer variance thresholds (e.g., 0.0001) demonstrate superior\neffectiveness in capturing nuanced relationships, reducing prediction errors,\nand aligning with observed commuter patterns. By merging symbolic and neural\nlearning paradigms, this Neurosymbolic approach achieves both interpretability\nand accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2502.01680v1",
    "published": "2025-02-02T05:10:31+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00673v1",
    "title": "Retracted Citations and Self-citations in Retracted Publications: A Comparative Study of Plagiarism and Fake Peer Review",
    "authors": [
      "Kiran Sharmaa",
      "Parul Khurana"
    ],
    "abstract": "Retracted citations remain a significant concern in academia as they\nperpetuate misinformation and compromise the integrity of scientific literature\ndespite their invalidation. To analyze the impact of retracted citations, we\nfocused on two retraction categories: plagiarism and fake peer review. The data\nset was sourced from Scopus and the reasons for the retraction were mapped\nusing the Retraction Watch database. The retraction trend shows a steady\naverage growth in plagiarism cases of 1.2 times, while the fake peer review\nexhibits a fluctuating pattern with an average growth of 5.5 times. Although\nfewer papers are retracted in the plagiarism category compared to fake peer\nreviews, plagiarism-related papers receive 2.5 times more citations.\nFurthermore, the total number of retracted citations for plagiarized papers is\n1.8 times higher than that for fake peer review papers. Within the plagiarism\ncategory, 46% of the retracted citations are due to plagiarism, while 53.6% of\nthe retracted citations in the fake peer review category are attributed to the\nfake peer review. The results also suggest that fake peer review cases are\nidentified and retracted more rapidly than plagiarism cases. Finally,\nself-citations constitute a small percentage of citations to retracted papers\nbut are notably higher among citations that are later retracted in both the\ncategories.",
    "pdf_url": "http://arxiv.org/pdf/2502.00673v1",
    "published": "2025-02-02T05:05:09+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00672v2",
    "title": "Biogeochemistry-Informed Neural Network (BINN) for Improving Accuracy of Model Prediction and Scientific Understanding of Soil Organic Carbon",
    "authors": [
      "Haodi Xu",
      "Joshua Fan",
      "Feng Tao",
      "Lifen Jiang",
      "Fengqi You",
      "Benjamin Z. Houlton",
      "Ying Sun",
      "Carla P. Gomes",
      "Yiqi Luo"
    ],
    "abstract": "Big data and the rapid development of artificial intelligence (AI) provide\nunprecedented opportunities to enhance our understanding of the global carbon\ncycle and other biogeochemical processes. However, retrieving mechanistic\nknowledge from big data remains a challenge. Here, we develop a\nBiogeochemistry-Informed Neural Network (BINN) that seamlessly integrates a\nvectorized process-based soil carbon cycle model (i.e., Community Land Model\nversion 5, CLM5) into a neural network (NN) structure to examine mechanisms\ngoverning soil organic carbon (SOC) storage from big data. BINN demonstrates\nhigh accuracy in retrieving biogeochemical parameter values from synthetic data\nin a parameter recovery experiment. We use BINN to predict six major processes\nregulating the soil carbon cycle (or components in process-based models) from\n25,925 observed SOC profiles across the conterminous US and compared them with\nthe same processes previously retrieved by a Bayesian inference-based\nPROcess-guided deep learning and DAta-driven modeling (PRODA) approach (Tao et\nal. 2020; 2023). The high agreement between the spatial patterns of the\nretrieved processes using the two approaches with an average correlation\ncoefficient of 0.81 confirms BINN's ability in retrieving mechanistic knowledge\nfrom big data. Additionally, the integration of neural networks and\nprocess-based models in BINN improves computational efficiency by more than 50\ntimes over PRODA. We conclude that BINN is a transformative tool that harnesses\nthe power of both AI and process-based modeling, facilitating new scientific\ndiscoveries while improving interpretability and accuracy of Earth system\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2502.00672v2",
    "published": "2025-02-02T05:02:42+00:00",
    "categories": [
      "physics.geo-ph",
      "cs.AI"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00671v1",
    "title": "POSMAC: Powering Up In-Network AR/CG Traffic Classification with Online Learning",
    "authors": [
      "Alireza Shirmarz",
      "Fabio Luciano Verdi",
      "Suneet Kumar Singh",
      "Christian Esteve Rothenberg"
    ],
    "abstract": "In this demonstration, we showcase POSMAC1, a platform designed to deploy\nDecision Tree (DT) and Random Forest (RF) models on the NVIDIA DOCA DPU,\nequipped with an ARM processor, for real-time network traffic classification.\nDeveloped specifically for Augmented Reality (AR) and Cloud Gaming (CG) traffic\nclassification, POSMAC streamlines model evaluation, and generalization while\noptimizing throughput to closely match line rates.",
    "pdf_url": "http://arxiv.org/pdf/2502.00671v1",
    "published": "2025-02-02T04:49:18+00:00",
    "categories": [
      "cs.NI",
      "cs.DC"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00670v1",
    "title": "Gaussian quantum data hiding",
    "authors": [
      "Yunkai Wang",
      "Graeme Smith"
    ],
    "abstract": "Quantum data hiding encodes a hidden classical bit to a pair of quantum\nstates that is difficult to distinguish using a particular set of measurement,\ndenoted as $M$. In this work, we explore quantum data hiding in two contexts\ninvolving Gaussian operations or states. First, we consider the set of\nmeasurement $M$ as Gaussian local quantum operations and classical\ncommunication, a new set of operations not previously discussed in the\nliterature for data hiding. We hide one classical bit in the two different\nmixture of displaced two-mode squeezed states. Second, we consider the set of\nmeasurement $M$ as general Gaussian measurement and construct the data hiding\nstates using two-mode thermal states. This data hiding scheme is effective in\nthe weak strength limit, providing a new example compared to existing\ndiscussions for the set of general Gaussian measurement.",
    "pdf_url": "http://arxiv.org/pdf/2502.00670v1",
    "published": "2025-02-02T04:46:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00669v1",
    "title": "Safety Alignment Depth in Large Language Models: A Markov Chain Perspective",
    "authors": [
      "Ching-Chia Kao",
      "Chia-Mu Yu",
      "Chun-Shien Lu",
      "Chu-Song Chen"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly adopted in high-stakes\nscenarios, yet their safety mechanisms often remain fragile. Simple jailbreak\nprompts or even benign fine-tuning can bypass these protocols, underscoring the\nneed to understand where and how they fail. Recent findings suggest that\nvulnerabilities emerge when alignment is confined to only the initial output\ntokens. Unfortunately, even with the introduction of deep safety alignment,\ndetermining the optimal safety depth remains an unresolved challenge. By\nleveraging the equivalence between autoregressive language models and Markov\nchains, this paper offers the first theoretical result on how to identify the\nideal depth for safety alignment, and demonstrates how permutation-based data\naugmentation can tighten these bounds. Crucially, we reveal a fundamental\ninteraction between alignment depth and ensemble width-indicating that broader\nensembles can compensate for shallower alignments. These insights provide a\ntheoretical foundation for designing more robust, scalable safety strategies\nthat complement existing alignment approaches, opening new avenues for research\ninto safer, more reliable LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.00669v1",
    "published": "2025-02-02T04:43:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00668v1",
    "title": "Hardening of Ni-O bond-stretching phonons in LaNiO$_2$",
    "authors": [
      "Yilin Wang"
    ],
    "abstract": "We demonstrate that dynamical electron correlation and fluctuating local\nmagnetic moments are crucial for the phonon spectra of the infinite-layer\nnickelate superconductor, LaNiO$_2$, using DFT plus dynamical mean-field theory\n(DFT+DMFT) calculations. We find significant hardening of optical Ni-O\nbond-stretching phonons when going from non-magnetic to paramagnetic state, and\nincreasing Coulomb interaction will make them even harder. The electron\ncorrelation is found to be sensitive to the Ni-O bond-stretching distortions,\nindicating strong interplay between electron correlation and lattice. We find\nthat the strong local electron correlation will not favor charge orders that\ncouple to the Ni-O bond-stretching phonons, in support of the recent experiment\nthat a $3a_0$ charge order is absent in the infinite-layer nickelates. Our\nresults emphasize that the effects of local magnetic fluctuations should be\nfully taken into account when describing the lattice dynamics of the\ninfinite-layer nickelates without long-range magnetic orders, and also provide\nevidence to ascribe the kink observed in the recent angle-resolved\nphotoemission experiment to possible strong electron coupling to the Ni-O\nbond-stretching phonons.",
    "pdf_url": "http://arxiv.org/pdf/2502.00668v1",
    "published": "2025-02-02T04:41:52+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.00667v1",
    "title": "Preorder induced by rainbow forbidden subgraphs",
    "authors": [
      "Shun-ichi Maezawa",
      "Akira Saito"
    ],
    "abstract": "A subgraph $H$ of an edge-colored graph $G$ is rainbow if all the edges of\n$H$ receive different colors. If $G$ does not contain a rainbow subgraph\nisomorphic to $H$, we say that $G$ is rainbow $H$-free. For connected graphs\n$H_1$ and $H_2$, if every rainbow $H_1$-free edge-colored complete graph\ncolored in sufficiently many colors is rainbow $H_2$-free, we write $H_1\\le\nH_2$. The binary relation $\\le$ is reflexive and transitive, and hence it is a\npreorder. If $H_1$ is a subgraph of $H_2$, then trivially $H_1\\le H_2$ holds.\nOn the other hand, there exists a pair $(H_1, H_2)$ such that $H_1$ is a proper\nsupergraph of $H_2$ and $H_1\\le H_2$ holds. Cui et al.~[Discrete\nMath.~\\textbf{344} (2021) Article Number 112267] characterized these pairs. In\nthis paper, we investigate the pairs $(H_1, H_2)$ with $H_1\\le H_2$ when\nneither $H_1$ nor $H_2$ is a subgraph of the other. We prove that there are\nmany such pairs and investigate their structure with respect to $\\le$.",
    "pdf_url": "http://arxiv.org/pdf/2502.00667v1",
    "published": "2025-02-02T04:40:24+00:00",
    "categories": [
      "math.CO",
      "05C15"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00666v2",
    "title": "Avoiding $\\mathbf{exp(R_{max})}$ scaling in RLHF through Preference-based Exploration",
    "authors": [
      "Mingyu Chen",
      "Yiding Chen",
      "Wen Sun",
      "Xuezhou Zhang"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a pivotal\ntechnique for large language model (LLM) alignment. This paper studies the\nsetting of online RLHF and focus on improving sample efficiency. All existing\nalgorithms in online RLHF, whether doing passive exploration or active\nexploration, suffer from a sample complexity that scales exponentially with the\nscale of the reward function. This fundamental limitation hinders their\neffectiveness in scenarios with heavily skewed preferences, e.g. questions with\na unique correct solution. To address this, we introduce Self-Exploring\nPreference-Incentive Online Preference Optimization (SE-POPO), an online RLHF\nalgorithm that for the first time achieves a sample complexity that scales\npolynomially with the reward scale, answering an open problem raised by Xie et\nal. (2024).. Theoretically, we demonstrate that the sample complexity of\nSE-POPO dominates that of existing exploration algorithms. Empirically, our\nsystematic evaluation confirms that SE-POPO is more sample-efficient than both\nexploratory and non-exploratory baselines, in two primary application scenarios\nof RLHF as well as on public benchmarks, marking a significant step forward in\nRLHF algorithm design. The code is available at\nhttps://github.com/MYC000801/SE-POPO.",
    "pdf_url": "http://arxiv.org/pdf/2502.00666v2",
    "published": "2025-02-02T04:40:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00665v1",
    "title": "Cross-Modal Synergies: Unveiling the Potential of Motion-Aware Fusion Networks in Handling Dynamic and Static ReID Scenarios",
    "authors": [
      "Fuxi Ling",
      "Hongye Liu",
      "Guoqiang Huang",
      "Jing Li",
      "Hong Wu",
      "Zhihao Tang"
    ],
    "abstract": "Navigating the complexities of person re-identification (ReID) in varied\nsurveillance scenarios, particularly when occlusions occur, poses significant\nchallenges. We introduce an innovative Motion-Aware Fusion (MOTAR-FUSE) network\nthat utilizes motion cues derived from static imagery to significantly enhance\nReID capabilities. This network incorporates a dual-input visual adapter\ncapable of processing both images and videos, thereby facilitating more\neffective feature extraction. A unique aspect of our approach is the\nintegration of a motion consistency task, which empowers the motion-aware\ntransformer to adeptly capture the dynamics of human motion. This technique\nsubstantially improves the recognition of features in scenarios where\nocclusions are prevalent, thereby advancing the ReID process. Our comprehensive\nevaluations across multiple ReID benchmarks, including holistic, occluded, and\nvideo-based scenarios, demonstrate that our MOTAR-FUSE network achieves\nsuperior performance compared to existing approaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.00665v1",
    "published": "2025-02-02T04:37:25+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00664v1",
    "title": "Topological flow data analysis for transient flow patterns: a graph-based approach",
    "authors": [
      "Takashi Sakajo",
      "Takeshi Matsumoto",
      "Shizuo Kaji",
      "Tomoo Yokoyama",
      "Tomoki Uda"
    ],
    "abstract": "We introduce a time-series analysis method for transient two-dimensional flow\npatterns based on Topological Flow Data Analysis (TFDA), a new approach to\ntopological data analysis. TFDA identifies local topological flow structures\nfrom an instantaneous streamline pattern and describes their global connections\nas a unique planar tree and its string representation. With TFDA, the evolution\nof two-dimensional flow patterns is reduced to a discrete dynamical system\nrepresented as a transition graph between topologically equivalent streamline\npatterns. We apply this method to study the lid-driven cavity flow at Reynolds\nnumbers ranging from $Re=14000$ to $Re=16000$, a benchmark problem in fluid\ndynamics data analysis. Our approach reveals the transition from periodic to\nchaotic flow at a critical Reynolds number when the reduced dynamical system is\nmodelled as a Markov process on the transition graph. Additionally, we perform\nan observational causal inference to analyse changes in local flow patterns at\nthe cavity corners and discuss differences with a standard interventional\nsensitivity analysis. This work demonstrates the potential of TFDA-based\ntime-series analysis for uncovering complex dynamical behaviours in fluid flow\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2502.00664v1",
    "published": "2025-02-02T04:36:33+00:00",
    "categories": [
      "physics.flu-dyn",
      "math.DS"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.00663v1",
    "title": "Enhanced Convolutional Neural Networks for Improved Image Classification",
    "authors": [
      "Xiaoran Yang",
      "Shuhan Yu",
      "Wenxi Xu"
    ],
    "abstract": "Image classification is a fundamental task in computer vision with diverse\napplications, ranging from autonomous systems to medical imaging. The CIFAR-10\ndataset is a widely used benchmark to evaluate the performance of\nclassification models on small-scale, multi-class datasets. Convolutional\nNeural Networks (CNNs) have demonstrated state-of-the-art results; however,\nthey often suffer from overfitting and suboptimal feature representation when\napplied to challenging datasets like CIFAR-10. In this paper, we propose an\nenhanced CNN architecture that integrates deeper convolutional blocks, batch\nnormalization, and dropout regularization to achieve superior performance. The\nproposed model achieves a test accuracy of 84.95%, outperforming baseline CNN\narchitectures. Through detailed ablation studies, we demonstrate the\neffectiveness of the enhancements and analyze the hierarchical feature\nrepresentations. This work highlights the potential of refined CNN\narchitectures for tackling small-scale image classification problems\neffectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.00663v1",
    "published": "2025-02-02T04:32:25+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00662v1",
    "title": "Mitigating the Modality Gap: Few-Shot Out-of-Distribution Detection with Multi-modal Prototypes and Image Bias Estimation",
    "authors": [
      "Yimu Wang",
      "Evelien Riddell",
      "Adrian Chow",
      "Sean Sedwards",
      "Krzysztof Czarnecki"
    ],
    "abstract": "Existing vision-language model (VLM)-based methods for out-of-distribution\n(OOD) detection typically rely on similarity scores between input images and\nin-distribution (ID) text prototypes. However, the modality gap between image\nand text often results in high false positive rates, as OOD samples can exhibit\nhigh similarity to ID text prototypes. To mitigate the impact of this modality\ngap, we propose incorporating ID image prototypes along with ID text\nprototypes. We present theoretical analysis and empirical evidence indicating\nthat this approach enhances VLM-based OOD detection performance without any\nadditional training. To further reduce the gap between image and text, we\nintroduce a novel few-shot tuning framework, SUPREME, comprising biased prompts\ngeneration (BPG) and image-text consistency (ITC) modules. BPG enhances\nimage-text fusion and improves generalization by conditioning ID text\nprototypes on the Gaussian-based estimated image domain bias; ITC reduces the\nmodality gap by minimizing intra- and inter-modal distances. Moreover, inspired\nby our theoretical and empirical findings, we introduce a novel OOD score\n$S_{\\textit{GMP}}$, leveraging uni- and cross-modal similarities. Finally, we\npresent extensive experiments to demonstrate that SUPREME consistently\noutperforms existing VLM-based OOD detection methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.00662v1",
    "published": "2025-02-02T04:30:51+00:00",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00661v2",
    "title": "EKF-Based Radar-Inertial Odometry with Online Temporal Calibration",
    "authors": [
      "Changseung Kim",
      "Geunsik Bae",
      "Woojae Shin",
      "Sen Wang",
      "Hyondong Oh"
    ],
    "abstract": "Accurate time synchronization between heterogeneous sensors is crucial for\nensuring robust state estimation in multi-sensor fusion systems. Sensor delays\noften cause discrepancies between the actual time when the event was captured\nand the time of sensor measurement, leading to temporal misalignment (time\noffset) between sensor measurement streams. In this paper, we propose an\nextended Kalman filter (EKF)-based radar-inertial odometry (RIO) framework that\nestimates the time offset online. The radar ego-velocity measurement model,\nderived from a single radar scan, is formulated to incorporate the time offset\ninto the update. By leveraging temporal calibration, the proposed RIO enables\naccurate propagation and measurement updates based on a common time stream.\nExperiments on both simulated and real-world datasets demonstrate the accurate\ntime offset estimation of the proposed method and its impact on RIO\nperformance, validating the importance of sensor time synchronization. Our\nimplementation of the EKF-RIO with online temporal calibration is available at\nhttps://github.com/spearwin/EKF-RIO-TC.",
    "pdf_url": "http://arxiv.org/pdf/2502.00661v2",
    "published": "2025-02-02T04:25:08+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.01679v1",
    "title": "LIBRA: Measuring Bias of Large Language Model from a Local Context",
    "authors": [
      "Bo Pang",
      "Tingrui Qiao",
      "Caroline Walker",
      "Chris Cunningham",
      "Yun Sing Koh"
    ],
    "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing applications, yet their widespread use raises concerns regarding\ninherent biases that may reduce utility or harm for particular social groups.\nDespite the advancement in addressing LLM bias, existing research has two major\nlimitations. First, existing LLM bias evaluation focuses on the U.S. cultural\ncontext, making it challenging to reveal stereotypical biases of LLMs toward\nother cultures, leading to unfair development and use of LLMs. Second, current\nbias evaluation often assumes models are familiar with the target social\ngroups. When LLMs encounter words beyond their knowledge boundaries that are\nunfamiliar in their training data, they produce irrelevant results in the local\ncontext due to hallucinations and overconfidence, which are not necessarily\nindicative of inherent bias. This research addresses these limitations with a\nLocal Integrated Bias Recognition and Assessment Framework (LIBRA) for\nmeasuring bias using datasets sourced from local corpora without crowdsourcing.\nImplementing this framework, we develop a dataset comprising over 360,000 test\ncases in the New Zealand context. Furthermore, we propose the Enhanced\nIdealized CAT Score (EiCAT), integrating the iCAT score with a beyond knowledge\nboundary score (bbs) and a distribution divergence-based bias measurement to\ntackle the challenge of LLMs encountering words beyond knowledge boundaries.\nOur results show that the BERT family, GPT-2, and Llama-3 models seldom\nunderstand local words in different contexts. While Llama-3 exhibits larger\nbias, it responds better to different cultural contexts. The code and dataset\nare available at: https://github.com/ipangbo/LIBRA.",
    "pdf_url": "http://arxiv.org/pdf/2502.01679v1",
    "published": "2025-02-02T04:24:57+00:00",
    "categories": [
      "cs.CY",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.00660v3",
    "title": "A normalized Ricci flow on surfaces with boundary towards the complete hyperbolic metric",
    "authors": [
      "Gang Li"
    ],
    "abstract": "Let $(\\overline{M},g_0)$ be a $2$-D compact surface with boundary $\\partial\nM$ and its interior $M$. We show that for a large class of initial and boundary\ndata, the initial-boundary value problem of the normalized Ricci flow\n$(1.10)-(1.12)$, with prescribed geodesic curvature $\\psi$ on $\\partial M$, has\na unique solution for all $t>0$, and it converges to the complete hyperbolic\nmetric locally uniformly in $M$. Here the natural condition that $\\psi>0$\ncauses the main difficulty in the a priori estimates in the corresponding\ninitial-boundary problem $(1.15)-(1.17)$ of the parabolic equations, for which\nan auxiliary Cauchy-Dirichlet problem is introduced. We also provide examples\nof the boundary data $\\psi$ which fits well with the natural asymptotic\nbehavior of the geodesic curvature, but the solution to $(1.10)-(1.12)$ fails\nto converge to the complete hyperbolic metric.",
    "pdf_url": "http://arxiv.org/pdf/2502.00660v3",
    "published": "2025-02-02T04:23:51+00:00",
    "categories": [
      "math.DG",
      "math.AP"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00659v1",
    "title": "Energy, enstrophy and helicity transfers in polymeric turbulence",
    "authors": [
      "Alessandro Chiarini",
      "Rahul K. Singh",
      "Marco E. Rosti"
    ],
    "abstract": "We characterise the scale-by-scale transfers of energy, enstrophy and\nhelicity in homogeneous and isotropic polymeric turbulence using direct\nnumerical simulations. The microscale Reynolds number is set to $Re_\\lambda\n\\approx 460$, and the Deborah number $De = \\tau_p/\\tau_f$ is varied between\n$1/9 \\le De \\le 9$; $\\tau_p$ is the polymeric relaxation time and $\\tau_f$ is\nthe turnover time of the largest scales of the flow. The study relies on the\nexact scale-by-scale budget equations (derived from the the governing model\nequations) for energy, enstrophy and helicity, which account for the\nback-reaction of the polymers on the flow. Polymers act as a sink/source in the\nflow, and provide alternative routes for the scale-by-scale transfers of the\nthree quantities, whose relevance changes with $De$. We find that polymers\ndeplete the nonlinear energy cascade mainly at smaller scales, by weakening\nboth the extreme forward as well as reverse local events. The new\npolymer-driven energy flux dominates at small scales for $De \\ge 1$, and on\naverage transfers energy from larger to smaller scales with localised\nbackscatter events. Polymers weaken the stretching of vorticity with the\nenstrophy being mainly generated by the fluid-polymer interaction, especially\nwhen $De \\ge 1$. Accordingly, an inspection of the small-scale flow topology\nshows that polymers favour events with two-dimensional state of straining, and\npromote/inhibit extreme extension/rotation events: in polymeric turbulence\nshear and planar extensional flows are more probable. The helicity injected at\nthe largest scales shows a similar transfer process to as energy, being mainly\ndriven by the nonlinear cascade at large scales and by the polymer-driven flux\nat small scales. Polymers are found to favour events that break the small-scale\nmirror symmetry, with the relative helicity monotonically increasing with $De$\nat all scales.",
    "pdf_url": "http://arxiv.org/pdf/2502.00659v1",
    "published": "2025-02-02T04:20:17+00:00",
    "categories": [
      "physics.flu-dyn",
      "nlin.CD"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.00658v1",
    "title": "Multi-Hazard Bayesian Hierarchical Model for Damage Prediction",
    "authors": [
      "Mary Lai O. Salvaña"
    ],
    "abstract": "A fundamental theoretical limitation undermines current disaster risk models:\nexisting approaches suffer from two critical constraints. First, conventional\ndamage prediction models remain predominantly deterministic, relying on fixed\nparameters established through expert judgment rather than learned from data.\nSecond, probabilistic frameworks are fundamentally restricted by their\nunderlying assumption of hazard independence, which directly contradicts the\nobserved reality of cascading and compound disasters. By relying on fixed\nexpert parameters and treating hazards as independent phenomena, these models\ndangerously misrepresent the true risk landscape. This work addresses this\nchallenge by developing the Multi-Hazard Bayesian Hierarchical Model (MH-BHM),\nwhich reconceptualizes the classical risk equation beyond its deterministic\norigins. The model's core theoretical contribution lies in reformulating a\nclassical risk formula as a fully probabilistic model that naturally\naccommodates hazard interactions through its hierarchical structure while\npreserving the traditional hazard-exposure-vulnerability framework. Using\ntropical cyclone damage data (1952-2020) from the Philippines as a test case,\nwith out-of-sample validation on recent events (2020-2022), the model\ndemonstrates significant empirical advantages. Key findings include a reduction\nin damage prediction error by 61% compared to a single-hazard model, and 80%\ncompared to a benchmark deterministic model. This corresponds to an improvement\nin damage estimation accuracy of USD 0.8 billion and USD 2 billion,\nrespectively. The improved accuracy enables more effective disaster risk\nmanagement across multiple domains, from optimized insurance pricing and\nnational resource allocation to local adaptation strategies, fundamentally\nimproving society's capacity to prepare for and respond to disasters.",
    "pdf_url": "http://arxiv.org/pdf/2502.00658v1",
    "published": "2025-02-02T04:19:43+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.01678v2",
    "title": "LEAD: Large Foundation Model for EEG-Based Alzheimer's Disease Detection",
    "authors": [
      "Yihe Wang",
      "Nan Huang",
      "Nadia Mammone",
      "Marco Cecchi",
      "Xiang Zhang"
    ],
    "abstract": "Electroencephalogram (EEG) provides a non-invasive, highly accessible, and\ncost-effective solution for Alzheimer's Disease (AD) detection. However,\nexisting methods, whether based on manual feature extraction or deep learning,\nface two major challenges: the lack of large-scale datasets for robust feature\nlearning and evaluation, and poor detection performance due to inter-subject\nvariations. To address these challenges, we curate an EEG-AD corpus containing\n813 subjects, which forms the world's largest EEG-AD dataset to the best of our\nknowledge. Using this unique dataset, we propose LEAD, the first large\nfoundation model for EEG-based AD detection. Our method encompasses an entire\npipeline, from data selection and preprocessing to self-supervised contrastive\npretraining, fine-tuning, and key setups such as subject-independent evaluation\nand majority voting for subject-level detection. We pre-train the model on 11\nEEG datasets and unified fine-tune it on 5 AD datasets. Our self-supervised\npre-training design includes sample-level and subject-level contrasting to\nextract useful general EEG features. Fine-tuning is performed on 5\nchannel-aligned datasets together. The backbone encoder incorporates temporal\nand channel embeddings to capture features across both temporal and spatial\ndimensions. Our method demonstrates outstanding AD detection performance,\nachieving up to a 9.86% increase in F1 score at the sample-level and up to a\n9.31% at the subject-level compared to state-of-the-art methods. The results of\nour model strongly confirm the effectiveness of contrastive pre-training and\nchannel-aligned unified fine-tuning for addressing inter-subject variation. The\nsource code is at https://github.com/DL4mHealth/LEAD.",
    "pdf_url": "http://arxiv.org/pdf/2502.01678v2",
    "published": "2025-02-02T04:19:35+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00657v2",
    "title": "LLM Safety Alignment is Divergence Estimation in Disguise",
    "authors": [
      "Rajdeep Haldar",
      "Ziyi Wang",
      "Qifan Song",
      "Guang Lin",
      "Yue Xing"
    ],
    "abstract": "We present a theoretical framework showing that popular LLM alignment\nmethods, including RLHF and its variants, can be understood as divergence\nestimators between aligned (safe or preferred) and unaligned (harmful or less\npreferred) distributions. This perspective explains the emergence of separation\nin the latent space between safe and harmful prompts after alignment. As an\napplication of our general divergence framework, we propose KLDO, a novel KL\ndivergence-based alignment method, and empirically validate its effectiveness.\nWe further show that using compliance-refusal datasets, rather than standard\npreference-based datasets, leads to stronger separation and improved safety\nalignment. Finally, to quantify the separation effect, we propose a\ndistance-based metric in the prompt representation space, which also acts as a\nstatistically significant indicator for model safety.",
    "pdf_url": "http://arxiv.org/pdf/2502.00657v2",
    "published": "2025-02-02T04:09:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00656v1",
    "title": "Generalized Calderón-Zygmund operators on the Hardy space $H^1_ρ(\\mathcal X)$",
    "authors": [
      "Luong Dang Ky"
    ],
    "abstract": "Let $(\\mathcal X, d,\\mu)$ be an RD-space, and let $\\rho$ be an admissible\nfunction on $\\mathcal X$. We establish necessary and sufficient conditions for\nthe boundedness of a new class of generalized Calder\\'on-Zygmund operators of\nlog-Dini type on the Hardy space $H^1_\\rho(\\mathcal X)$, introduced by Yang and\nZhou. Our results extend and unify some recent results, providing further\ninsights into the study of singular integral operators in this setting.",
    "pdf_url": "http://arxiv.org/pdf/2502.00656v1",
    "published": "2025-02-02T04:08:15+00:00",
    "categories": [
      "math.CA",
      "42B20, 42B30, 42B35"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00655v1",
    "title": "Parameter Choices for Sparse Multi-Parameter Regularization with the $\\ell_1$ Norm",
    "authors": [
      "Qianru Liu",
      "Rui Wang",
      "Yuesheng Xu"
    ],
    "abstract": "This paper introduces a multi-parameter regularization approach using the\n$\\ell_1$ norm, designed to better adapt to complex data structures and problem\ncharacteristics while offering enhanced flexibility in promoting sparsity in\nregularized solutions. As data volumes grow, sparse representations of learned\nfunctions become critical for reducing computational costs during function\noperations. We investigate how the selection of multiple regularization\nparameters influences the sparsity of regularized solutions. Specifically, we\ncharacterize the relationship between these parameters and the sparsity of\nsolutions under transform matrices, enabling the development of an iterative\nscheme for selecting parameters that achieve prescribed sparsity levels.\nSpecial attention is given to scenarios where the fidelity term is\nnon-differentiable, and the transform matrix lacks full row rank. In such\ncases, the regularized solution, along with two auxiliary vectors arising in\nthe sparsity characterization, are essential components of the multi-parameter\nselection strategy. To address this, we propose a fixed-point proximity\nalgorithm that simultaneously determines these three vectors. This algorithm,\ncombined with our sparsity characterization, forms the basis of a practical\nmulti-parameter selection strategy. Numerical experiments demonstrate the\neffectiveness of the proposed approach, yielding regularized solutions with\nboth predetermined sparsity levels and satisfactory approximation accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2502.00655v1",
    "published": "2025-02-02T04:07:29+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00654v1",
    "title": "EmoTalkingGaussian: Continuous Emotion-conditioned Talking Head Synthesis",
    "authors": [
      "Junuk Cha",
      "Seongro Yoon",
      "Valeriya Strizhkova",
      "Francois Bremond",
      "Seungryul Baek"
    ],
    "abstract": "3D Gaussian splatting-based talking head synthesis has recently gained\nattention for its ability to render high-fidelity images with real-time\ninference speed. However, since it is typically trained on only a short video\nthat lacks the diversity in facial emotions, the resultant talking heads\nstruggle to represent a wide range of emotions. To address this issue, we\npropose a lip-aligned emotional face generator and leverage it to train our\nEmoTalkingGaussian model. It is able to manipulate facial emotions conditioned\non continuous emotion values (i.e., valence and arousal); while retaining\nsynchronization of lip movements with input audio. Additionally, to achieve the\naccurate lip synchronization for in-the-wild audio, we introduce a\nself-supervised learning method that leverages a text-to-speech network and a\nvisual-audio synchronization network. We experiment our EmoTalkingGaussian on\npublicly available videos and have obtained better results than\nstate-of-the-arts in terms of image quality (measured in PSNR, SSIM, LPIPS),\nemotion expression (measured in V-RMSE, A-RMSE, V-SA, A-SA, Emotion Accuracy),\nand lip synchronization (measured in LMD, Sync-E, Sync-C), respectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.00654v1",
    "published": "2025-02-02T04:01:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00653v1",
    "title": "Towards Robust Multimodal Large Language Models Against Jailbreak Attacks",
    "authors": [
      "Ziyi Yin",
      "Yuanpu Cao",
      "Han Liu",
      "Ting Wang",
      "Jinghui Chen",
      "Fenhlong Ma"
    ],
    "abstract": "While multimodal large language models (MLLMs) have achieved remarkable\nsuccess in recent advancements, their susceptibility to jailbreak attacks has\ncome to light. In such attacks, adversaries exploit carefully crafted prompts\nto coerce models into generating harmful or undesirable content. Existing\ndefense mechanisms often rely on external inference steps or safety alignment\ntraining, both of which are less effective and impractical when facing\nsophisticated adversarial perturbations in white-box scenarios. To address\nthese challenges and bolster MLLM robustness, we introduce SafeMLLM by adopting\nan adversarial training framework that alternates between an attack step for\ngenerating adversarial noise and a model updating step. At the attack step,\nSafeMLLM generates adversarial perturbations through a newly proposed\ncontrastive embedding attack (CoE-Attack), which optimizes token embeddings\nunder a contrastive objective. SafeMLLM then updates model parameters to\nneutralize the perturbation effects while preserving model utility on benign\ninputs. We evaluate SafeMLLM across six MLLMs and six jailbreak methods\nspanning multiple modalities. Experimental results show that SafeMLLM\neffectively defends against diverse attacks, maintaining robust performance and\nutilities.",
    "pdf_url": "http://arxiv.org/pdf/2502.00653v1",
    "published": "2025-02-02T03:45:49+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00652v1",
    "title": "Reformulation is All You Need: Addressing Malicious Text Features in DNNs",
    "authors": [
      "Yi Jiang",
      "Oubo Ma",
      "Yong Yang",
      "Tong Zhang",
      "Shouling Ji"
    ],
    "abstract": "Human language encompasses a wide range of intricate and diverse implicit\nfeatures, which attackers can exploit to launch adversarial or backdoor\nattacks, compromising DNN models for NLP tasks. Existing model-oriented\ndefenses often require substantial computational resources as model size\nincreases, whereas sample-oriented defenses typically focus on specific attack\nvectors or schemes, rendering them vulnerable to adaptive attacks. We observe\nthat the root cause of both adversarial and backdoor attacks lies in the\nencoding process of DNN models, where subtle textual features, negligible for\nhuman comprehension, are erroneously assigned significant weight by less robust\nor trojaned models. Based on it we propose a unified and adaptive defense\nframework that is effective against both adversarial and backdoor attacks. Our\napproach leverages reformulation modules to address potential malicious\nfeatures in textual inputs while preserving the original semantic integrity.\nExtensive experiments demonstrate that our framework outperforms existing\nsample-oriented defense baselines across a diverse range of malicious textual\nfeatures.",
    "pdf_url": "http://arxiv.org/pdf/2502.00652v1",
    "published": "2025-02-02T03:39:43+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00651v1",
    "title": "Integrating Cybersecurity Frameworks into IT Security: A Comprehensive Analysis of Threat Mitigation Strategies and Adaptive Technologies",
    "authors": [
      "Amit Lokare",
      "Shripad Bankar",
      "Padmajeet Mhaske"
    ],
    "abstract": "The cybersecurity threat landscape is constantly actively making it\nimperative to develop sound frameworks to protect the IT structures. Based on\nthis introduction, this paper aims to discuss the application of cybersecurity\nframeworks into the IT security with focus placed on the role of such\nframeworks in addressing the changing nature of cybersecurity threats. It\nexplores widely used models, including the NIST Cybersecurity Framework, Zero\nTrust Architecture, and the ISO/IEC 27001, and how they apply to industries\nincluding finance, healthcare and government. The discussion also singles out\nsuch technologies as Artificial Intelligence (AI) and Machine Learning (ML) as\nthe core for real-time threat detection and response mechanisms. As these\nintegration challenges demonstrate, the study provides tangible and proven\napproaches to tackle framework implementation issues such as legitimate\nsecurity issues, limited availability of funds and resources, and compliance\nwith legal requirements. By capturing current trends and exposures, the\nfindings promote strong, portfolio-based and risk-appropriate security\napproaches adjusted for organizational goals and capable to prevent advanced\ncyber threats.",
    "pdf_url": "http://arxiv.org/pdf/2502.00651v1",
    "published": "2025-02-02T03:38:48+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00650v1",
    "title": "Conformal Mappings Through the Lens of Invariant Metrics",
    "authors": [
      "Bharathi Thiruvengadam",
      "Jaikrishnan Janardhanan"
    ],
    "abstract": "The main objective of this paper is to show that balls under invariant\nmetrics on hyperbolic planar domains are finitely-connected. As applications,\nwe give new and transparent proofs of classical results on conformal mappings\nof planar domains. In particular, we show that any conformal self-map of a\nhyperbolic planar domain with three fixed points is the identity. We also give\na new and very simple proof of the theorem by Aumann and Carath\\'eodory that\nstates that the isotropy groups of a hyperbolic planar domain are either finite\nor the domain is simply-connected.",
    "pdf_url": "http://arxiv.org/pdf/2502.00650v1",
    "published": "2025-02-02T03:37:40+00:00",
    "categories": [
      "math.CV",
      "30C35, 30F45, 32H50"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00649v2",
    "title": "SIGNALS on the mixing of oxygen and nitrogen in the spiral galaxy NGC 6946",
    "authors": [
      "Fabio Bresolin",
      "David Fernández-Arenas",
      "Laurie Rousseau-Nepton",
      "Ray Garner III",
      "Almudena Zurita",
      "Carmelle Robert",
      "Laurent Drissen",
      "René Pierre Martin",
      "Philippe Amram",
      "Salvador Duarte Puertas",
      "Gabriel Savard",
      "Sébastien Vicens",
      "Mykola Posternak"
    ],
    "abstract": "As part of the SIGNALS survey, which comprises a sample of approximately 40\nnearby galaxies observed with the Fourier transform spectrometer SITELLE, we\npresent a study of metal mixing in the spiral galaxy NGC 6946. Taking advantage\nof the blue sensitivity of our setup, we measure the oxygen and nitrogen\nabundances of 638 H II regions, and focus our analysis on the abundance\nfluctuations about the radial gradients. We detect an azimuthal variation of\nabout 0.1 dex in these abundances across the NE spiral arm, with the leading\nedge being more metal-poor than the trailing edge. This result aligns with\ngalaxy simulations, where radial gas flows along the spiral arms lead to\ndilution on the leading edge and enrichment on the trailing edge, due to the\npresence of radial metallicity gradients. Our 2D analysis reveals that oxygen\nand nitrogen exhibit comparable spatial correlation scales, despite the\ndifferent injection energies and distinct nucleosynthetic origins --\ncore-collapse supernovae in the case of oxygen and primarily AGB stars for\nnitrogen. The observed similarity suggests that stellar processes drive these\ntwo elements into the ISM over equivalent spatial scales.",
    "pdf_url": "http://arxiv.org/pdf/2502.00649v2",
    "published": "2025-02-02T03:36:31+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00648v1",
    "title": "Agency in the Age of AI",
    "authors": [
      "Samarth Swarup"
    ],
    "abstract": "There is significant concern about the impact of generative AI on society.\nModern AI tools are capable of generating ever more realistic text, images, and\nvideos, and functional code, from minimal prompts. Accompanying this rise in\nability and usability, there is increasing alarm about the misuses to which\nthese tools can be put, and the intentional and unintentional harms to\nindividuals and society that may result. In this paper, we argue that\n\\emph{agency} is the appropriate lens to study these harms and benefits, but\nthat doing so will require advancement in the theory of agency, and advancement\nin how this theory is applied in (agent-based) models.",
    "pdf_url": "http://arxiv.org/pdf/2502.00648v1",
    "published": "2025-02-02T03:27:19+00:00",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00646v1",
    "title": "TrojanTime: Backdoor Attacks on Time Series Classification",
    "authors": [
      "Chang Dong",
      "Zechao Sun",
      "Guangdong Bai",
      "Shuying Piao",
      "Weitong Chen",
      "Wei Emma Zhang"
    ],
    "abstract": "Time Series Classification (TSC) is highly vulnerable to backdoor attacks,\nposing significant security threats. Existing methods primarily focus on data\npoisoning during the training phase, designing sophisticated triggers to\nimprove stealthiness and attack success rate (ASR). However, in practical\nscenarios, attackers often face restrictions in accessing training data.\nMoreover, it is a challenge for the model to maintain generalization ability on\nclean test data while remaining vulnerable to poisoned inputs when data is\ninaccessible. To address these challenges, we propose TrojanTime, a novel\ntwo-step training algorithm. In the first stage, we generate a pseudo-dataset\nusing an external arbitrary dataset through target adversarial attacks. The\nclean model is then continually trained on this pseudo-dataset and its poisoned\nversion. To ensure generalization ability, the second stage employs a carefully\ndesigned training strategy, combining logits alignment and batch norm freezing.\nWe evaluate TrojanTime using five types of triggers across four TSC\narchitectures in UCR benchmark datasets from diverse domains. The results\ndemonstrate the effectiveness of TrojanTime in executing backdoor attacks while\nmaintaining clean accuracy. Finally, to mitigate this threat, we propose a\ndefensive unlearning strategy that effectively reduces the ASR while preserving\nclean accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2502.00646v1",
    "published": "2025-02-02T03:24:24+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "I.2.0"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00645v1",
    "title": "General Coded Computing in a Probabilistic Straggler Regime",
    "authors": [
      "Parsa Moradi",
      "Mohammad Ali Maddah-Ali"
    ],
    "abstract": "Coded computing has demonstrated promising results in addressing straggler\nresiliency in distributed computing systems. However, most coded computing\nschemes are designed for exact computation, requiring the number of responding\nservers to exceed a certain recovery threshold. Additionally, these schemes are\ntailored for highly structured functions. Recently, new coded computing schemes\nfor general computing functions, where exact computation is replaced with\napproximate computation, have emerged. In these schemes, the availability of\nadditional results corresponds to more accurate estimation of computational\ntasks. This flexibility introduces new questions that need to be addressed.\nThis paper addresses the practically important scenario in the context of\ngeneral coded computing, where each server may become a straggler with a\nprobability $p$, independently from others. We theoretically analyze the\napproximation error of two existing general coded computing schemes: Berrut\nApproximate Coded Computing (BACC) and Learning Theoretic Coded Computing\n(LeTCC). Under the probabilistic straggler configuration, we demonstrate that\nthe average approximation error for BACC and LeTCC converge to zero with the\nrate of at least $\\mathcal{O}(\\log^3_{\\frac{1}{p}}(N)\\cdot{N^{-3}})$ and\n$\\mathcal{O}(\\log^4_{\\frac{1}{p}}(N)\\cdot{N^{-2}})$, respectively. This is\nperhaps surprising, as earlier results does not indicate a convergence when the\nnumber of stragglers scales with the total number of servers $N$. However, in\nthis case, despite the average number of stragglers being $Np$, the\nindependence of servers in becoming stragglers allows the approximation error\nto converge to zero. These theoretical results are validated through\nexperiments on various computing functions, including deep neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.00645v1",
    "published": "2025-02-02T03:24:05+00:00",
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00644v1",
    "title": "A Two-Stage Trip Inference Model of Purposes and Socio-Economic Attributes of Regular Public Transit Users",
    "authors": [
      "Yitong Chen",
      "Wentao Dong",
      "Chengcheng Yu",
      "Quan Yuan",
      "Chao Yang"
    ],
    "abstract": "Data-driven research is becoming a new paradigm in transportation, but the\nnatural lack of individual socio-economic attributes in transportation data\nmakes research such as activity purpose inference and mobility pattern\nidentification lack convincingness and verifiability. In this paper, a\ntwo-stage trip purpose and socio-economic attributes inference model is\nproposed based on travel resident survey and smart card data. In the first\nstage, the trip purpose of each trip is inferred by a combination of rule-based\nand XGBoost models. In the second stage, based on the trip purpose, a\nmachine-learning model is built to inference the socio-economic attributes of\nindividuals. A teacher-student model based on self-training is then applied on\nthe models above to transfer them to smart card data. The impact of independent\nvariables of socio-economic attributes inference model is also investigated.\nThe results show that models for inferring trip purposes and socio-economic\nattributes have overall accuracies of 92.7% and 76.3%, respectively. Travel\ntime, arrival time, departure time and purpose of the first two trips are most\nimportant factors on age and job status, while the land price of jobs-housing\nare significant to the inference of individual incomes.",
    "pdf_url": "http://arxiv.org/pdf/2502.00644v1",
    "published": "2025-02-02T03:18:53+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.00642v1",
    "title": "Light-induced reorientation transition in an antiferromagnetic semiconductor",
    "authors": [
      "Bryan T. Fichera",
      "Baiqing Lv",
      "Karna Morey",
      "Zongqi Shen",
      "Changmin Lee",
      "Elizabeth Donoway",
      "Alex Liebman-Pelaez",
      "Anshul Kogar",
      "Takashi Kurumaji",
      "Martin Rodriguez-Vega",
      "Rodrigo Humberto Aguilera del Toro",
      "Mikel Arruabarrena",
      "Batyr Ilyas",
      "Tianchuang Luo",
      "Peter Muller",
      "Aritz Leonardo",
      "Andres Ayuela",
      "Gregory A. Fiete",
      "Joseph G. Checkelsky",
      "Joseph Orenstein",
      "Nuh Gedik"
    ],
    "abstract": "Due to the lack of a net magnetic moment, antiferromagnets possess a unique\nrobustness to external magnetic fields and are thus predicted to play an\nimportant role in future magnetic technologies. However, this robustness also\nmakes them quite difficult to control, and the development of novel methods to\nmanipulate these systems with external stimuli is a fundamental goal of\nantiferromagnetic spintronics. In this work, we report evidence for a\nmetastable reorientation of the order parameter in an antiferromagnetic\nsemiconductor triggered by an ultrafast quench of the equilibrium order via\nphotoexcitation above the band gap. The metastable state forms less than 10 ps\nafter the excitation pulse, and persists for longer than 150 ps before decaying\nto the ground state via thermal fluctuations. Importantly, this transition\ncannot be induced thermodynamically, and requires the system to be driven out\nof equilibrium. Broadly speaking, this phenomenology is ultimately the result\nof large magnetoelastic coupling in combination with a relatively low symmetry\nof the magnetic ground state. Since neither of these properties are\nparticularly uncommon in magnetic materials, the observations presented here\nimply a generic path toward novel device technology enabled by ultrafast\ndynamics in antiferromagnets.",
    "pdf_url": "http://arxiv.org/pdf/2502.00642v1",
    "published": "2025-02-02T03:08:09+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.00641v2",
    "title": "Evaluating Small Language Models for News Summarization: Implications and Factors Influencing Performance",
    "authors": [
      "Borui Xu",
      "Yao Chen",
      "Zeyi Wen",
      "Weiguo Liu",
      "Bingsheng He"
    ],
    "abstract": "The increasing demand for efficient summarization tools in\nresource-constrained environments highlights the need for effective solutions.\nWhile large language models (LLMs) deliver superior summarization quality,\ntheir high computational resource requirements limit practical use\napplications. In contrast, small language models (SLMs) present a more\naccessible alternative, capable of real-time summarization on edge devices.\nHowever, their summarization capabilities and comparative performance against\nLLMs remain underexplored. This paper addresses this gap by presenting a\ncomprehensive evaluation of 19 SLMs for news summarization across 2,000 news\nsamples, focusing on relevance, coherence, factual consistency, and summary\nlength. Our findings reveal significant variations in SLM performance, with\ntop-performing models such as Phi3-Mini and Llama3.2-3B-Ins achieving results\ncomparable to those of 70B LLMs while generating more concise summaries.\nNotably, SLMs are better suited for simple prompts, as overly complex prompts\nmay lead to a decline in summary quality. Additionally, our analysis indicates\nthat instruction tuning does not consistently enhance the news summarization\ncapabilities of SLMs. This research not only contributes to the understanding\nof SLMs but also provides practical insights for researchers seeking efficient\nsummarization solutions that balance performance and resource use.",
    "pdf_url": "http://arxiv.org/pdf/2502.00641v2",
    "published": "2025-02-02T03:07:45+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00640v3",
    "title": "CollabLLM: From Passive Responders to Active Collaborators",
    "authors": [
      "Shirley Wu",
      "Michel Galley",
      "Baolin Peng",
      "Hao Cheng",
      "Gavin Li",
      "Yao Dou",
      "Weixin Cai",
      "James Zou",
      "Jure Leskovec",
      "Jianfeng Gao"
    ],
    "abstract": "Large Language Models are typically trained with next-turn rewards, limiting\ntheir ability to optimize for long-term interaction. As a result, they often\nrespond passively to ambiguous or open-ended user requests, failing to help\nusers reach their ultimate intents and leading to inefficient conversations. To\naddress these limitations, we introduce CollabLLM, a novel and general training\nframework that enhances multiturn human-LLM collaboration. Its key innovation\nis a collaborative simulation that estimates the long-term contribution of\nresponses using Multiturn-aware Rewards. By reinforcement fine-tuning these\nrewards, CollabLLM goes beyond responding to user requests, and actively\nuncovers user intent and offers insightful suggestions-a key step towards more\nhuman-centered AI. We also devise a multiturn interaction benchmark with three\nchallenging tasks such as document creation. CollabLLM significantly\noutperforms our baselines with averages of 18.5% higher task performance and\n46.3% improved interactivity by LLM judges. Finally, we conduct a large user\nstudy with 201 judges, where CollabLLM increases user satisfaction by 17.6% and\nreduces user spent time by 10.4%.",
    "pdf_url": "http://arxiv.org/pdf/2502.00640v3",
    "published": "2025-02-02T03:05:52+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00639v2",
    "title": "Zeroth-order Informed Fine-Tuning for Diffusion Model: A Recursive Likelihood Ratio Optimizer",
    "authors": [
      "Tao Ren",
      "Zishi Zhang",
      "Zehao Li",
      "Jingyang Jiang",
      "Shentao Qin",
      "Guanghao Li",
      "Yan Li",
      "Yi Zheng",
      "Xinping Li",
      "Min Zhan",
      "Yijie Peng"
    ],
    "abstract": "The probabilistic diffusion model (DM), generating content by inferencing\nthrough a recursive chain structure, has emerged as a powerful framework for\nvisual generation. After pre-training on enormous unlabeled data, the model\nneeds to be properly aligned to meet requirements for downstream applications.\nHow to efficiently align the foundation DM is a crucial task. Contemporary\nmethods are either based on Reinforcement Learning (RL) or truncated\nBackpropagation (BP). However, RL and truncated BP suffer from low sample\nefficiency and biased gradient estimation respectively, resulting in limited\nimprovement or, even worse, complete training failure. To overcome the\nchallenges, we propose the Recursive Likelihood Ratio (RLR) optimizer, a\nzeroth-order informed fine-tuning paradigm for DM. The zeroth-order gradient\nestimator enables the computation graph rearrangement within the recursive\ndiffusive chain, making the RLR's gradient estimator an unbiased one with the\nlower variance than other methods. We provide theoretical guarantees for the\nperformance of the RLR. Extensive experiments are conducted on image and video\ngeneration tasks to validate the superiority of the RLR. Furthermore, we\npropose a novel prompt technique that is natural for the RLR to achieve a\nsynergistic effect.",
    "pdf_url": "http://arxiv.org/pdf/2502.00639v2",
    "published": "2025-02-02T03:00:26+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00638v2",
    "title": "Cycles and Cuts in Supersingular L-Isogeny Graphs",
    "authors": [
      "Sarah Arpin",
      "Ross Bowden",
      "James Clements",
      "Wissam Ghantous",
      "Jason T. LeGrow",
      "Krystal Maughan"
    ],
    "abstract": "Supersingular elliptic curve isogeny graphs underlie isogeny-based\ncryptography. For isogenies of a single prime degree $\\ell$, their structure\nhas been investigated graph-theoretically. We generalise the notion of\n$\\ell$-isogeny graphs to $L$-isogeny graphs (studied in the prime field case by\nDelfs and Galbraith), where $L$ is a set of small primes dictating the allowed\nisogeny degrees in the graph. We analyse the graph-theoretic structure of\n$L$-isogeny graphs. Our approaches may be put into two categories: cycles and\ngraph cuts.\n  On the topic of cycles, we provide: a count for the number of cycles in the\n$L$-isogeny graph with cyclic kernels using traces of Brandt matrices; an\nefficiently computable estimate based on this approach; and a third\nideal-theoretic count for a certain subclass of $L$-isogeny cycles. We provide\ncode to compute each of these three counts.\n  On the topic of graph cuts, we compare several algorithms to compute graph\ncuts which minimise a measure called the edge expansion, outlining a\ncryptographic motivation for doing so. Our results show that a greedy neighbour\nalgorithm out-performs standard spectral algorithms for computing optimal graph\ncuts. We provide code and study explicit examples.\n  Furthermore, we describe several directions of active and future research.",
    "pdf_url": "http://arxiv.org/pdf/2502.00638v2",
    "published": "2025-02-02T02:57:06+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00637v1",
    "title": "Constructing AI ethics narratives based on real-world data: Human-AI collaboration in data-driven visual storytelling",
    "authors": [
      "Mengyi Wei",
      "Chenjing Jiao",
      "Chenyu Zuo",
      "Lorenz Hurni",
      "Liqiu Meng"
    ],
    "abstract": "AI ethics narratives have the potential to shape the public accurate\nunderstanding of AI technologies and promote communication among different\nstakeholders. However, AI ethics narratives are largely lacking. Existing\nlimited narratives tend to center on works of science fiction or corporate\nmarketing campaigns of large technology companies. Misuse of \"socio-technical\nimaginary\" can blur the line between speculation and reality for the public,\nundermining the responsibility and regulation of technology development.\nTherefore, constructing authentic AI ethics narratives is an urgent task. The\nemergence of generative AI offers new possibilities for building narrative\nsystems. This study is dedicated to data-driven visual storytelling about AI\nethics relying on the human-AI collaboration. Based on the five key elements of\nstory models, we proposed a conceptual framework for human-AI collaboration,\nexplored the roles of generative AI and humans in the creation of visual\nstories. We implemented the conceptual framework in a real AI news case. This\nresearch leveraged advanced generative AI technologies to provide a reference\nfor constructing genuine AI ethics narratives. Our goal is to promote active\npublic engagement and discussions through authentic AI ethics narratives,\nthereby contributing to the development of better AI policies.",
    "pdf_url": "http://arxiv.org/pdf/2502.00637v1",
    "published": "2025-02-02T02:56:07+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.00636v2",
    "title": "Starobinsky Inflation with T-Model Kaehler Geometries",
    "authors": [
      "C. Pallis"
    ],
    "abstract": "We present novel implementations of Starobisky-like inflation within\nSupergravity adopting Kaehler potentials for the inflaton which parameterize\nhyperbolic geometries known from the T-model inflation. The associated\nsuperpotentials are consistent with an R and a global or gauge U(1)_X\nsymmetries. The inflaton is represented by a gauge-singlet or non-singlet\nsuperfield and is accompanied by a gauge-singlet superfield successfully\nstabilized thanks to its compact contribution into the total Kaehler potential.\nKeeping the Kaehler manifold intact, a conveniently violated shift symmetry is\nintroduced which allows for a slight variation of the predictions of\nStarobinsky inflation: The (scalar) spectral index exhibits an upper bound\nwhich lies close to its central observational value whereas the constant scalar\ncurvature of the inflaton-sector Kaehler manifold increases with the\ntensor-to-scalar ratio.",
    "pdf_url": "http://arxiv.org/pdf/2502.00636v2",
    "published": "2025-02-02T02:56:05+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00635v1",
    "title": "Magneto-plasmonic pesponse of nickel nano-rings prepared by electroless method",
    "authors": [
      "Akram Poursharif",
      "Peyman Sahebsara",
      "Seyyed Mahmood Monirvaghefi",
      "Seyedeh Mehri Hamidi Mahshid Kharaziha",
      "Masih Bagheri"
    ],
    "abstract": "Magneto-plasmonic nanostructures have emerged as promising candidates for\nadvanced sensing applications. However, conventional fabrication methods, such\nas lithography and sputtering, often involve high costs and complex processes.\nThis study introduces a novel approach for fabricating nickel nano-rings\n(200-600 nm in diameter) utilizing nanosphere lithography and selective\nelectroless deposition on ITO substrates. The resulting nickel-silver-boron\n(Ni-Ag-B) nanoarrays exhibit uniform, durable coatings with robust covalent\nbonds, providing a simpler, more cost-effective alternative to traditional\nmethods. The unique ring-shaped geometry of the nano-rings enhances plasmonic\neffects by concentrating the electromagnetic field, thus outperforming other\nnanostructures. Unlike thin films, these nano-rings demonstrate surface plasmon\nresonance (SPR) within the 470-614 nm range when illuminated at a 45$^{\\deg}$\nincident angle. Moreover, ellipsometry parameter calculations and\nMagneto-Optical Kerr Effect (MOKE) measurements revealed narrow Full Width at\nHalf Maximum (FWHM) peaks at 512 nm and 560 nm, indicating superior sensitivity\nfor detection compared to conventional SPR and ellipsometry-SPR techniques.\nFinite element simulations using COMSOL provided valuable insight into the\ninfluence of magnetic fields on the electromagnetic response of the nano-rings,\nconfirming their potential for optical communication and highly sensitive\nsensing technologies. This study addresses limitations in existing\nmagneto-plasmonic systems, offering a scalable and innovative solution for the\ndevelopment of next-generation sensing applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.00635v1",
    "published": "2025-02-02T02:54:55+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "physics.optics"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.00634v2",
    "title": "SimulPL: Aligning Human Preferences in Simultaneous Machine Translation",
    "authors": [
      "Donglei Yu",
      "Yang Zhao",
      "Jie Zhu",
      "Yangyifan Xu",
      "Yu Zhou",
      "Chengqing Zong"
    ],
    "abstract": "Simultaneous Machine Translation (SiMT) generates translations while\nreceiving streaming source inputs. This requires the SiMT model to learn a\nread/write policy, deciding when to translate and when to wait for more source\ninput. Numerous linguistic studies indicate that audiences in SiMT scenarios\nhave distinct preferences, such as accurate translations, simpler syntax, and\nno unnecessary latency. Aligning SiMT models with these human preferences is\ncrucial to improve their performances. However, this issue still remains\nunexplored. Additionally, preference optimization for SiMT task is also\nchallenging. Existing methods focus solely on optimizing the generated\nresponses, ignoring human preferences related to latency and the optimization\nof read/write policy during the preference optimization phase. To address these\nchallenges, we propose Simultaneous Preference Learning (SimulPL), a preference\nlearning framework tailored for the SiMT task. In the SimulPL framework, we\ncategorize SiMT human preferences into five aspects: \\textbf{translation\nquality preference}, \\textbf{monotonicity preference}, \\textbf{key point\npreference}, \\textbf{simplicity preference}, and \\textbf{latency preference}.\nBy leveraging the first four preferences, we construct human preference prompts\nto efficiently guide GPT-4/4o in generating preference data for the SiMT task.\nIn the preference optimization phase, SimulPL integrates \\textbf{latency\npreference} into the optimization objective and enables SiMT models to improve\nthe read/write policy, thereby aligning with human preferences more\neffectively. Experimental results indicate that SimulPL exhibits better\nalignment with human preferences across all latency levels in\nZh$\\rightarrow$En, De$\\rightarrow$En and En$\\rightarrow$Zh SiMT tasks. Our data\nand code will be available at https://github.com/EurekaForNLP/SimulPL.",
    "pdf_url": "http://arxiv.org/pdf/2502.00634v2",
    "published": "2025-02-02T02:47:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00633v1",
    "title": "Lipschitz Lifelong Monte Carlo Tree Search for Mastering Non-Stationary Tasks",
    "authors": [
      "Zuyuan Zhang",
      "Tian Lan"
    ],
    "abstract": "Monte Carlo Tree Search (MCTS) has proven highly effective in solving complex\nplanning tasks by balancing exploration and exploitation using Upper Confidence\nBound for Trees (UCT). However, existing work have not considered MCTS-based\nlifelong planning, where an agent faces a non-stationary series of tasks --\ne.g., with varying transition probabilities and rewards -- that are drawn\nsequentially throughout the operational lifetime. This paper presents LiZero\nfor Lipschitz lifelong planning using MCTS. We propose a novel concept of\nadaptive UCT (aUCT) to transfer knowledge from a source task to the\nexploration/exploitation of a new task, depending on both the Lipschitz\ncontinuity between tasks and the confidence of knowledge in in Monte Carlo\naction sampling. We analyze LiZero's acceleration factor in terms of improved\nsampling efficiency and also develop efficient algorithms to compute aUCT in an\nonline fashion by both data-driven and model-based approaches, whose sampling\ncomplexity and error bounds are also characterized. Experiment results show\nthat LiZero significantly outperforms existing MCTS and lifelong learning\nbaselines in terms of much faster convergence (3$\\sim$4x) to optimal rewards.\nOur results highlight the potential of LiZero to advance decision-making and\nplanning in dynamic real-world environments.",
    "pdf_url": "http://arxiv.org/pdf/2502.00633v1",
    "published": "2025-02-02T02:45:20+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00632v1",
    "title": "Patterns and Purposes: A Cross-Journal Analysis of AI Tool Usage in Academic Writing",
    "authors": [
      "Ziyang Xu"
    ],
    "abstract": "This study investigates the use of AI tools in academic writing through\nanalysis of AI usage declarations in journals. Using a mixed-methods approach\ncombining content analysis, statistical analysis, and text mining, this\nresearch analyzed 168 AI declarations from 8,859 articles across 27 categories.\nResults show that ChatGPT dominates academic writing assistance (77% usage),\nwith significant differences in tool usage between native and non-native\nEnglish speakers (p = 0.0483) and between international and non-international\nteams (p = 0.0012). The study reveals that improving readability (51%) and\ngrammar checking (22%) are the primary purposes of AI tool usage. These\nfindings provide insights for journal policy development and understanding the\nevolving role of AI in academic writing.",
    "pdf_url": "http://arxiv.org/pdf/2502.00632v1",
    "published": "2025-02-02T02:44:33+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.00631v2",
    "title": "MedConv: Convolutions Beat Transformers on Long-Tailed Bone Density Prediction",
    "authors": [
      "Xuyin Qi",
      "Zeyu Zhang",
      "Huazhan Zheng",
      "Mingxi Chen",
      "Numan Kutaiba",
      "Ruth Lim",
      "Cherie Chiang",
      "Zi En Tham",
      "Xuan Ren",
      "Wenxin Zhang",
      "Lei Zhang",
      "Hao Zhang",
      "Wenbing Lv",
      "Guangzhen Yao",
      "Renda Han",
      "Kangsheng Wang",
      "Mingyuan Li",
      "Hongtao Mao",
      "Yu Li",
      "Zhibin Liao",
      "Yang Zhao",
      "Minh-Son To"
    ],
    "abstract": "Bone density prediction via CT scans to estimate T-scores is crucial,\nproviding a more precise assessment of bone health compared to traditional\nmethods like X-ray bone density tests, which lack spatial resolution and the\nability to detect localized changes. However, CT-based prediction faces two\nmajor challenges: the high computational complexity of transformer-based\narchitectures, which limits their deployment in portable and clinical settings,\nand the imbalanced, long-tailed distribution of real-world hospital data that\nskews predictions. To address these issues, we introduce MedConv, a\nconvolutional model for bone density prediction that outperforms transformer\nmodels with lower computational demands. We also adapt Bal-CE loss and post-hoc\nlogit adjustment to improve class balance. Extensive experiments on our\nAustinSpine dataset shows that our approach achieves up to 21% improvement in\naccuracy and 20% in ROC AUC over previous state-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.00631v2",
    "published": "2025-02-02T02:43:40+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00630v1",
    "title": "Self-Prompt SAM: Medical Image Segmentation via Automatic Prompt SAM Adaptation",
    "authors": [
      "Bin Xie",
      "Hao Tang",
      "Dawen Cai",
      "Yan Yan",
      "Gady Agam"
    ],
    "abstract": "Segment Anything Model (SAM) has demonstrated impressive zero-shot\nperformance and brought a range of unexplored capabilities to natural image\nsegmentation tasks. However, as a very important branch of image segmentation,\nthe performance of SAM remains uncertain when applied to medical image\nsegmentation due to the significant differences between natural images and\nmedical images. Meanwhile, it is harsh to meet the SAM's requirements of extra\nprompts provided, such as points or boxes to specify medical regions. In this\npaper, we propose a novel self-prompt SAM adaptation framework for medical\nimage segmentation, named Self-Prompt-SAM. We design a multi-scale prompt\ngenerator combined with the image encoder in SAM to generate auxiliary masks.\nThen, we use the auxiliary masks to generate bounding boxes as box prompts and\nuse Distance Transform to select the most central points as point prompts.\nMeanwhile, we design a 3D depth-fused adapter (DfusedAdapter) and inject the\nDFusedAdapter into each transformer in the image encoder and mask decoder to\nenable pre-trained 2D SAM models to extract 3D information and adapt to 3D\nmedical images. Extensive experiments demonstrate that our method achieves\nstate-of-the-art performance and outperforms nnUNet by 2.3% on AMOS2022, 1.6%\non ACDCand 0.5% on Synapse datasets.",
    "pdf_url": "http://arxiv.org/pdf/2502.00630v1",
    "published": "2025-02-02T02:42:24+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00629v1",
    "title": "Advanced Weakly-Supervised Formula Exploration for Neuro-Symbolic Mathematical Reasoning",
    "authors": [
      "Yuxuan Wu",
      "Hideki Nakayama"
    ],
    "abstract": "In recent years, neuro-symbolic methods have become a popular and powerful\napproach that augments artificial intelligence systems with the capability to\nperform abstract, logical, and quantitative deductions with enhanced precision\nand controllability. Recent studies successfully performed symbolic reasoning\nby leveraging various machine learning models to explicitly or implicitly\npredict intermediate labels that provide symbolic instructions. However, these\nintermediate labels are not always prepared for every task as a part of\ntraining data, and pre-trained models, represented by Large Language Models\n(LLMs), also do not consistently generate valid symbolic instructions with\ntheir intrinsic knowledge. On the other hand, existing work developed\nalternative learning techniques that allow the learning system to autonomously\nuncover optimal symbolic instructions. Nevertheless, their performance also\nexhibits limitations when faced with relatively huge search spaces or more\nchallenging reasoning problems. In view of this, in this work, we put forward\nan advanced practice for neuro-symbolic reasoning systems to explore the\nintermediate labels with weak supervision from problem inputs and final\noutputs. Our experiments on the Mathematics dataset illustrated the\neffectiveness of our proposals from multiple aspects.",
    "pdf_url": "http://arxiv.org/pdf/2502.00629v1",
    "published": "2025-02-02T02:34:36+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00628v2",
    "title": "One-loop corrections to the E-type $α$-attractor models of inflation and primordial black hole production",
    "authors": [
      "Daniel Frolovsky",
      "Sergei V. Ketov"
    ],
    "abstract": "The one-loop corrections (1LC) to the power spectrum of scalar perturbations\narising from cubic interactions in the single-field E-type $\\alpha$-attractor\nmodels of inflation and primordial black hole (PBH) production are numerically\ncalculated. The results demonstrate the 1LC contributes merely a few percent to\nthe tree-level power spectrum. The model parameters are chosen to predict the\nPBH masses in the asteroid-mass range, while maintaining consistency with the\ncosmic microwave background (CMB) observations within 1$\\sigma$ confidence\nlevels, and obeying the upper limits on $\\mu$-distortions. The PBHs formed on\nscales smaller than the inflation scale can constitute a significant fraction\nof the present dark matter (DM). The PBH-induced gravitational waves (GW) may\nbe detectable by the future space-based gravitational interferometers. We also\nconsider a reconstruction of the scalar potential from possible GW observations\nand present a numerical approach tested in the model parameter space.",
    "pdf_url": "http://arxiv.org/pdf/2502.00628v2",
    "published": "2025-02-02T02:25:55+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.00627v1",
    "title": "Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024)",
    "authors": [
      "Yan Aquino",
      "Pedro Bento",
      "Arthur Buzelin",
      "Lucas Dayrell",
      "Samira Malaquias",
      "Caio Santana",
      "Victoria Estanislau",
      "Pedro Dutenhefner",
      "Guilherme H. G. Evangelista",
      "Luisa G. Porfírio",
      "Caio Souza Grossi",
      "Pedro B. Rigueira",
      "Virgilio Almeida",
      "Gisele L. Pappa",
      "Wagner Meira Jr"
    ],
    "abstract": "Discord has evolved from a gaming-focused communication tool into a versatile\nplatform supporting diverse online communities. Despite its large user base and\nactive public servers, academic research on Discord remains limited due to data\naccessibility challenges. This paper introduces Discord Unveiled: A\nComprehensive Dataset of Public Communication (2015-2024), the most extensive\nDiscord public server's data to date. The dataset comprises over 2.05 billion\nmessages from 4.74 million users across 3,167 public servers, representing\napproximately 10% of servers listed in Discord's Discovery feature. Spanning\nfrom Discord's launch in 2015 to the end of 2024, it offers a robust temporal\nand thematic framework for analyzing decentralized moderation, community\ngovernance, information dissemination, and social dynamics. Data was collected\nthrough Discord's public API, adhering to ethical guidelines and privacy\nstandards via anonymization techniques. Organized into structured JSON files,\nthe dataset facilitates seamless integration with computational social science\nmethodologies. Preliminary analyses reveal significant trends in user\nengagement, bot utilization, and linguistic diversity, with English\npredominating alongside substantial representations of Spanish, French, and\nPortuguese. Additionally, prevalent community themes such as social, art,\nmusic, and memes highlight Discord's expansion beyond its gaming origins.",
    "pdf_url": "http://arxiv.org/pdf/2502.00627v1",
    "published": "2025-02-02T02:17:14+00:00",
    "categories": [
      "cs.SI",
      "cs.DB"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.01677v2",
    "title": "Position: AI Scaling: From Up to Down and Out",
    "authors": [
      "Yunke Wang",
      "Yanxi Li",
      "Chang Xu"
    ],
    "abstract": "AI Scaling has traditionally been synonymous with Scaling Up, which builds\nlarger and more powerful models. However, the growing demand for efficiency,\nadaptability, and collaboration across diverse applications necessitates a\nbroader perspective. This position paper presents a holistic framework for AI\nscaling, encompassing Scaling Up, Scaling Down, and Scaling Out. It argues that\nwhile Scaling Up of models faces inherent bottlenecks, the future trajectory of\nAI scaling lies in Scaling Down and Scaling Out. These paradigms address\ncritical technical and societal challenges, such as reducing carbon footprint,\nensuring equitable access, and enhancing cross-domain collaboration. We explore\ntransformative applications in healthcare, smart manufacturing, and content\ncreation, demonstrating how AI Scaling can enable breakthroughs in efficiency,\npersonalization, and global connectivity. Additionally, we highlight key\nchallenges, including balancing model complexity with interpretability,\nmanaging resource constraints, and fostering ethical development. By\nsynthesizing these approaches, we propose a unified roadmap that redefines the\nfuture of AI research and application, paving the way for advancements toward\nArtificial General Intelligence (AGI).",
    "pdf_url": "http://arxiv.org/pdf/2502.01677v2",
    "published": "2025-02-02T02:14:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00626v2",
    "title": "Lifting the Winding Number: Precise Discontinuities in Neural Fields for Physics Simulation",
    "authors": [
      "Yue Chang",
      "Mengfei Liu",
      "Zhecheng Wang",
      "Peter Yichen Chen",
      "Eitan Grinspun"
    ],
    "abstract": "Cutting thin-walled deformable structures is common in daily life, but poses\nsignificant challenges for simulation due to the introduced spatial\ndiscontinuities. Traditional methods rely on mesh-based domain representations,\nwhich require frequent remeshing and refinement to accurately capture evolving\ndiscontinuities. These challenges are further compounded in reduced-space\nsimulations, where the basis functions are inherently geometry- and\nmesh-dependent, making it difficult or even impossible for the basis to\nrepresent the diverse family of discontinuities introduced by cuts.\n  Recent advances in representing basis functions with neural fields offer a\npromising alternative, leveraging their discretization-agnostic nature to\nrepresent deformations across varying geometries. However, the inherent\ncontinuity of neural fields is an obstruction to generalization, particularly\nif discontinuities are encoded in neural network weights.\n  We present Wind Lifter, a novel neural representation designed to accurately\nmodel complex cuts in thin-walled deformable structures. Our approach\nconstructs neural fields that reproduce discontinuities precisely at specified\nlocations, without baking in the position of the cut line. Crucially, our\napproach does not embed the discontinuity in the neural network's weights,\nopening avenues to generalization of cut placement.\n  Our method achieves real-time simulation speeds and supports dynamic updates\nto cut line geometry during the simulation. Moreover, the explicit\nrepresentation of discontinuities makes our neural field intuitive to control\nand edit, offering a significant advantage over traditional neural fields,\nwhere discontinuities are embedded within the network's weights, and enabling\nnew applications that rely on general cut placement.",
    "pdf_url": "http://arxiv.org/pdf/2502.00626v2",
    "published": "2025-02-02T01:51:56+00:00",
    "categories": [
      "cs.GR"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2502.00625v1",
    "title": "Nonlinear bubble behaviours of compressible Rayleigh-Taylor instability with isothermal stratification in cylindrical geometry",
    "authors": [
      "Ming Yuan",
      "Zhiye Zhao",
      "Luoqin Liu",
      "Pei Wang",
      "Nan-Sheng Liu",
      "Xi-Yun Lu"
    ],
    "abstract": "Nonlinear evolutions of two-dimensional single-mode compressible\nRayleigh--Taylor instability (RTI) with isothermal stratification are\ninvestigated in cylindrical geometry via direct numerical simulation for\ndifferent Atwood numbers ($A_T=0.1-0.9$) and Mach numbers ($Ma=0.1-0.9$). It is\nfound that the nonlinear bubble growth involves the effects of density\nstratification, vorticity accumulation and flow compressibility and shows\nconsiderable differences between convergent (acceleration acting radially\ninward) and divergent (acceleration acting radially outward) cases.\nSpecifically, the density stratification leads to non-acceleration at low $A_T$\nand high $Ma$. The accelerations in convergent cases are dominated by vorticity\naccumulation at low $A_T$ and low $Ma$ and by flow compressibility at high\n$A_T$ and high $Ma$ whereas the accelerations in divergent cases are purely\ninduced by flow compressibility at high $A_T$ and high $Ma$. Based on the\nnonlinear theory of incompressible cylindrical RTI with uniform-density\nbackground~(Zhao et al., J. Fluid Mech., vol. 900, 2020, A24), an improved\nmodel is proposed by taking the density variation, vorticity accumulation and\nflow compressibility into consideration. This model is verified by numerical\nresults and well reproduces the bubble evolution for different $A_T$ and $Ma$\nfrom linear to highly nonlinear regimes.",
    "pdf_url": "http://arxiv.org/pdf/2502.00625v1",
    "published": "2025-02-02T01:51:02+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.00624v1",
    "title": "Expressing the difference of two Hurwitz zeta functions by a linear combination of the Gauss hypergeometric functions",
    "authors": [
      "Feng Qi"
    ],
    "abstract": "In the paper, the author expresses the difference\n$2^m\\bigl[\\zeta\\bigl(-m,\\frac{1+x}{2}\\bigr)-\\zeta\\bigl(-m,\\frac{2+x}{2}\\bigr)\\bigr]$\nin terms of a linear combination of the function\n$\\Gamma(m+1){\\,}_2F_1(-m,-x;1;2)$ for $m\\in\\mathbb{N}_0$ and $x\\in(-1,\\infty)$\nin the form of matrix equations, where $\\Gamma(z)$, $\\zeta(z,\\alpha)$, and\n${}_2F_1(a,b;c;z)$ stand for the classical Euler gamma function, the Hurwitz\nzeta function, and the Gauss hypergeometric function, respectively. This\nproblem originates from the Landau level quantization in solid state materials.",
    "pdf_url": "http://arxiv.org/pdf/2502.00624v1",
    "published": "2025-02-02T01:45:32+00:00",
    "categories": [
      "math.CA",
      "Primary 11M35, Secondary 15A09, 33C05"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00623v1",
    "title": "On compact Kähler manifolds with pseudo-effective tangent bundle",
    "authors": [
      "Shin-ichi Matsumura",
      "Chenghao Qing"
    ],
    "abstract": "In this paper, we prove that a compact K\\\"ahler manifold $X$ with\npseudo-effective (resp. singular positively curved) tangent bundle admits a\nsmooth (resp. locally constant) rationally connected fibration $\\phi \\colon X\n\\to Y$ onto a finite \\'etale quotient $Y$ of a compact complex torus. This\nresult extends the structure theorem previously established for smooth\nprojective varieties to compact K\\\"ahler manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2502.00623v1",
    "published": "2025-02-02T01:32:44+00:00",
    "categories": [
      "math.AG",
      "math.CV",
      "math.DG",
      "Primary 32J25, Secondary 14F35, 58A30"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00622v2",
    "title": "Strengthening Generative Robot Policies through Predictive World Modeling",
    "authors": [
      "Han Qi",
      "Haocheng Yin",
      "Aris Zhu",
      "Yilun Du",
      "Heng Yang"
    ],
    "abstract": "We present generative predictive control (GPC), a learning control framework\nthat (i) clones a generative diffusion-based policy from expert demonstrations,\n(ii) trains a predictive action-conditioned world model from both expert\ndemonstrations and random explorations, and (iii) synthesizes an online planner\nthat ranks and optimizes the action proposals from (i) by looking ahead into\nthe future using the world model from (ii). Across a variety of robotic\nmanipulation tasks, we demonstrate that GPC consistently outperforms behavior\ncloning in both state-based and vision-based settings, in simulation and in the\nreal world.",
    "pdf_url": "http://arxiv.org/pdf/2502.00622v2",
    "published": "2025-02-02T01:21:19+00:00",
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.00621v2",
    "title": "Congruent elliptic curves over some $p$-adic Lie extensions",
    "authors": [
      "Dac-Nhan-Tam Nguyen",
      "Ramdorai Sujatha"
    ],
    "abstract": "Let $p$ be an odd prime number. In this article, we study the variation of\nIwasawa invariants among $p$-congruent elliptic curves over certain $p$-adic\nLie extensions. We investigate both the classical Selmer group as well as the\nfine Selmer group.",
    "pdf_url": "http://arxiv.org/pdf/2502.00621v2",
    "published": "2025-02-02T01:20:08+00:00",
    "categories": [
      "math.NT",
      "11G05 (Primary) 11R23, 11R34 (Secondary)"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00620v4",
    "title": "Representations Shape Weak-to-Strong Generalization: Theoretical Insights and Empirical Predictions",
    "authors": [
      "Yihao Xue",
      "Jiping Li",
      "Baharan Mirzasoleiman"
    ],
    "abstract": "Weak-to-Strong Generalization (W2SG), where a weak model supervises a\nstronger one, serves as an important analogy for understanding how humans might\nguide superhuman intelligence in the future. Promising empirical results\nrevealed that a strong model can surpass its weak supervisor. While recent work\nhas offered theoretical insights into this phenomenon, a clear understanding of\nthe interactions between weak and strong models that drive W2SG remains\nelusive. We investigate W2SG through a theoretical lens and show that it can be\ncharacterized using kernels derived from the principal components of weak and\nstrong models' internal representations. These kernels can be used to define a\nspace that, at a high level, captures what the weak model is unable to learn\nbut is learnable by the strong model. The projection of labels onto this space\nquantifies how much the strong model falls short of its full potential due to\nweak supervision. This characterization also provides insights into how certain\nerrors in weak supervision can be corrected by the strong model, regardless of\noverfitting. Our theory has significant practical implications, providing a\nrepresentation-based metric that predicts W2SG performance trends without\nrequiring labels, as shown in experiments on molecular predictions with\ntransformers and 5 NLP tasks involving 52 LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.00620v4",
    "published": "2025-02-02T01:11:51+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00619v2",
    "title": "Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective",
    "authors": [
      "Yujin Oh",
      "Pengfei Jin",
      "Sangjoon Park",
      "Sekeun Kim",
      "Siyeop Yoon",
      "Kyungsang Kim",
      "Jin Sung Kim",
      "Xiang Li",
      "Quanzheng Li"
    ],
    "abstract": "Ensuring fairness in medical image segmentation is critical due to biases in\nimbalanced clinical data acquisition caused by demographic attributes (e.g.,\nage, sex, race) and clinical factors (e.g., disease severity). To address these\nchallenges, we introduce Distribution-aware Mixture of Experts (dMoE), inspired\nby optimal control theory. We provide a comprehensive analysis of its\nunderlying mechanisms and clarify dMoE's role in adapting to heterogeneous\ndistributions in medical image segmentation. Furthermore, we integrate dMoE\ninto multiple network architectures, demonstrating its broad applicability\nacross diverse medical image analysis tasks. By incorporating demographic and\nclinical factors, dMoE achieves state-of-the-art performance on two 2D\nbenchmark datasets and a 3D in-house dataset. Our results highlight the\neffectiveness of dMoE in mitigating biases from imbalanced distributions,\noffering a promising approach to bridging control theory and medical image\nsegmentation within fairness learning paradigms. The source code will be made\navailable. The source code is available at https://github.com/tvseg/dMoE.",
    "pdf_url": "http://arxiv.org/pdf/2502.00619v2",
    "published": "2025-02-02T01:10:31+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00618v2",
    "title": "DesCLIP: Robust Continual Learning via General Attribute Descriptions for VLM-Based Visual Recognition",
    "authors": [
      "Chiyuan He",
      "Zihuan Qiu",
      "Fanman Meng",
      "Linfeng Xu",
      "Qingbo Wu",
      "Hongliang Li"
    ],
    "abstract": "Continual learning of vision-language models (VLMs) focuses on leveraging\ncross-modal pretrained knowledge to incrementally adapt to expanding downstream\ntasks and datasets, while tackling the challenge of knowledge forgetting.\nExisting research often focuses on connecting visual features with specific\nclass text in downstream tasks, overlooking the latent relationships between\ngeneral and specialized knowledge. Our findings reveal that forcing models to\noptimize inappropriate visual-text matches exacerbates forgetting of VLM's\nrecognition ability. To tackle this issue, we propose DesCLIP, which leverages\ngeneral attribute (GA) descriptions to guide the understanding of specific\nclass objects, enabling VLMs to establish robust vision-GA-class trilateral\nassociations rather than relying solely on vision-class connections.\nSpecifically, we introduce a language assistant to generate concrete GA\ndescription candidates via proper request prompts. Then, an anchor-based\nembedding filter is designed to obtain highly relevant GA description\nembeddings, which are leveraged as the paired text embeddings for\nvisual-textual instance matching, thereby tuning the visual encoder.\nCorrespondingly, the class text embeddings are gradually calibrated to align\nwith these shared GA description embeddings. Extensive experiments demonstrate\nthe advancements and efficacy of our proposed method, with comprehensive\nempirical evaluations highlighting its superior performance in VLM-based\nrecognition compared to existing continual learning methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.00618v2",
    "published": "2025-02-02T01:06:02+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.00617v1",
    "title": "Efficient Language Modeling for Low-Resource Settings with Hybrid RNN-Transformer Architectures",
    "authors": [
      "Gabriel Lindenmaier",
      "Sean Papay",
      "Sebastian Padó"
    ],
    "abstract": "Transformer-based language models have recently been at the forefront of\nactive research in text generation. However, these models' advances come at the\nprice of prohibitive training costs, with parameter counts in the billions and\ncompute requirements measured in petaflop/s-decades. In this paper, we\ninvestigate transformer-based architectures for improving model performance in\na low-data regime by selectively replacing attention layers with feed-forward\nand quasi-recurrent neural network layers. We test these architectures on the\nstandard Enwik8 and Wikitext-103 corpora. Our results show that our reduced\narchitectures outperform existing models with a comparable number of\nparameters, and obtain comparable performance to larger models while\nsignificantly reducing the number of parameters.",
    "pdf_url": "http://arxiv.org/pdf/2502.00617v1",
    "published": "2025-02-02T01:05:09+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00616v1",
    "title": "Congestion Management in High-Performance Interconnection Networks Using Adaptive Routing Notifications",
    "authors": [
      "Jose Rocher-Gonzalez",
      "Jesus Escudero-Sahuquillo",
      "Pedro J. Garcia",
      "Francisco J. Quiles"
    ],
    "abstract": "The interconnection network is a crucial subsystem in High-Performance\nComputing clusters and Data-centers, guaranteeing high bandwidth and low\nlatency to the applications' communication operations. Unfortunately,\ncongestion situations may spoil network performance unless the network design\napplies specific countermeasures. Adaptive routing algorithms are a traditional\napproach to dealing with congestion since they provide traffic flows with\nalternative routes that bypass congested areas. However, adaptive routing\ndecisions at switches are typically based on local information without a global\nnetwork traffic perspective, leading to congestion spreading throughout the\nnetwork beyond the original congested areas. In this paper, we propose a new\nefficient congestion management strategy that leverages adaptive routing\nnotifications currently available in some interconnect technologies and\nefficiently isolates the congesting flows in reserved spaces at switch buffers.\nThe experiment results based on simulations of realistic traffic scenarios show\nthat our proposal removes the congestion impact.",
    "pdf_url": "http://arxiv.org/pdf/2502.00616v1",
    "published": "2025-02-02T01:02:17+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.00615v2",
    "title": "Understanding Abandonment and Slowdown Dynamics in the Maven Ecosystem",
    "authors": [
      "Kazi Amit Hasan",
      "Jerin Yasmin",
      "Huizi Hao",
      "Yuan Tian",
      "Safwat Hassan",
      "Steven Ding"
    ],
    "abstract": "The sustainability of libraries is critical for modern software development,\nyet many libraries face abandonment, posing significant risks to dependent\nprojects. This study explores the prevalence and patterns of library\nabandonment in the Maven ecosystem. We investigate abandonment trends over the\npast decade, revealing that approximately one in four libraries fail to survive\nbeyond their creation year. We also analyze the release activities of\nlibraries, focusing on their lifespan and release speed, and analyze the\nevolution of these metrics within the lifespan of libraries. We find that while\nslow release speed and relatively long periods of inactivity are often\nprecursors to abandonment, some abandoned libraries exhibit bursts of high\nfrequent release activity late in their life cycle. Our findings contribute to\na new understanding of library abandonment dynamics and offer insights for\npractitioners to identify and mitigate risks in software ecosystems.",
    "pdf_url": "http://arxiv.org/pdf/2502.00615v2",
    "published": "2025-02-02T00:47:55+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.00614v1",
    "title": "A coupled finite and boundary spectral element method for linear water-wave propagation problems",
    "authors": [
      "Antonio Cerrato",
      "Luis Rodríguez-Tembleque",
      "José A. González",
      "M. H. Ferri Aliabadi"
    ],
    "abstract": "A coupled boundary spectral element method (BSEM) and spectral element method\n(SEM) formulation for the propagation of small-amplitude water waves over\nvariable bathymetries is presented in this work. The wave model is based on the\nmild-slope equation (MSE), which provides a good approximation of the\npropagation of water waves over irregular bottom surfaces with slopes up to\n1:3. In unbounded domains or infinite regions, space can be divided into two\ndifferent areas: a central region of interest, where an irregular bathymetry is\nincluded, and an exterior infinite region with straight and parallel\nbathymetric lines. The SEM allows us to model the central region, where any\nvariation of the bathymetry can be considered, while the exterior infinite\nregion is modelled by the BSEM which, combined with the fundamental solution\npresented by Cerrato et al. [A. Cerrato, J. A. Gonz\\'alez, L.\nRodr\\'iguez-Tembleque, Boundary element formulation of the mild-slope equation\nfor harmonic water waves propagating over unidirectional variable bathymetries,\nEng. Anal. Boundary Elem. 62 (2016) 22-34.] can include bathymetries with\nstraight and parallel contour lines. This coupled model combines important\nadvantages of both methods; it benefits from the flexibility of the SEM for the\ninterior region and, at the same time, includes the fulfilment of the\nSommerfeld's radiation condition for the exterior problem, that is provided by\nthe BSEM. The solution approximation inside the elements is constructed by high\norder Legendre polynomials associated with Legendre-Gauss-Lobatto quadrature\npoints, providing a spectral convergence for both methods. The proposed\nformulation has been validated in three different benchmark cases with\ndifferent shapes of the bottom surface. The solutions exhibit the typical\np-convergence of spectral methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.00614v1",
    "published": "2025-02-02T00:43:47+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00613v1",
    "title": "Affordances and Challenges of Incorporating a Remote, Cloud-accessible Quantum Experiment into Undergraduate Courses",
    "authors": [
      "Victoria Borish",
      "H. J. Lewandowski"
    ],
    "abstract": "As quantum technologies transition from the research laboratory into\ncommercial development, the opportunities for students to begin their careers\nin this new quantum industry are increasing. With these new career pathways,\nmore and more people are considering the best ways to educate students about\nquantum concepts and relevant skills. In particular, the quantum industry is\nlooking for new employees with experimental skills, but the instructional labs,\ncapstone projects, research experiences, and internships that provide\nexperiences where students can learn these skills are often resource-intensive\nand not available at all institutions. The quantum company, Infleqtion,\nrecently made its online quantum matter machine Oqtant publicly available, so\npeople around the world could send commands to create and manipulate\nBose-Einstein condensates and receive back real experimental data. Making a\ncomplex quantum experiment accessible to anyone has the potential to extend the\nopportunity to work with quantum experiments to students at less-resourced\ninstitutions. As a first step in understanding the potential benefits of using\nsuch a platform in educational settings, we collected data from instructors and\nstudents who were interested in using, or had used, Oqtant. In this study, we\ninvestigate instructors' views about reasons they would like to use Oqtant and\nchallenges they would face in doing so. We also provide a concrete example of\nhow Oqtant was used in an upper-division undergraduate quantum mechanics course\nand the instructor's perception of its benefits. We complement this with the\nstudent perspective, discussing student experiences interacting with Oqtant in\ntheir course or through think-aloud interviews outside of a course. These\nresults will help the community consider the potential value for students of\ncreating more opportunities to access remote quantum experiments.",
    "pdf_url": "http://arxiv.org/pdf/2502.00613v1",
    "published": "2025-02-02T00:42:19+00:00",
    "categories": [
      "physics.ed-ph"
    ],
    "primary_category": "physics.ed-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.00612v2",
    "title": "Using Causality for Enhanced Prediction of Web Traffic Time Series",
    "authors": [
      "Chang Tian",
      "Mingzhe Xing",
      "Zenglin Shi",
      "Matthew B. Blaschko",
      "Yinliang Yue",
      "Marie-Francine Moens"
    ],
    "abstract": "Predicting web service traffic has significant social value, as it can be\napplied to various practical scenarios, including but not limited to dynamic\nresource scaling, load balancing, system anomaly detection, service-level\nagreement compliance, and fraud detection. Web service traffic is characterized\nby frequent and drastic fluctuations over time and are influenced by\nheterogeneous web user behaviors, making accurate prediction a challenging\ntask. Previous research has extensively explored statistical approaches, and\nneural networks to mine features from preceding service traffic time series for\nprediction. However, these methods have largely overlooked the causal\nrelationships between services. Drawing inspiration from causality in\necological systems, we empirically recognize the causal relationships between\nweb services. To leverage these relationships for improved web service traffic\nprediction, we propose an effective neural network module, CCMPlus, designed to\nextract causal relationship features across services. This module can be\nseamlessly integrated with existing time series models to consistently enhance\nthe performance of web service traffic predictions. We theoretically justify\nthat the causal correlation matrix generated by the CCMPlus module captures\ncausal relationships among services. Empirical results on real-world datasets\nfrom Microsoft Azure, Alibaba Group, and Ant Group confirm that our method\nsurpasses state-of-the-art approaches in Mean Squared Error (MSE) and Mean\nAbsolute Error (MAE) for predicting service traffic time series. These findings\nhighlight the efficacy of leveraging causal relationships for improved\npredictions.",
    "pdf_url": "http://arxiv.org/pdf/2502.00612v2",
    "published": "2025-02-02T00:36:40+00:00",
    "categories": [
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00611v1",
    "title": "Enhancing Code Consistency in AI Research with Large Language Models and Retrieval-Augmented Generation",
    "authors": [
      "Rajat Keshri",
      "Arun George Zachariah",
      "Michael Boone"
    ],
    "abstract": "Ensuring that code accurately reflects the algorithms and methods described\nin research papers is critical for maintaining credibility and fostering trust\nin AI research. This paper presents a novel system designed to verify code\nimplementations against the algorithms and methodologies outlined in\ncorresponding research papers. Our system employs Retrieval-Augmented\nGeneration to extract relevant details from both the research papers and code\nbases, followed by a structured comparison using Large Language Models. This\napproach improves the accuracy and comprehensiveness of code implementation\nverification while contributing to the transparency, explainability, and\nreproducibility of AI research. By automating the verification process, our\nsystem reduces manual effort, enhances research credibility, and ultimately\nadvances the state of the art in code verification.",
    "pdf_url": "http://arxiv.org/pdf/2502.00611v1",
    "published": "2025-02-02T00:35:42+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.00610v2",
    "title": "A parametric study of the pipeline hammer phenomenon in plastic Bingham slurry flows using the finite element method",
    "authors": [
      "Felipe Galarce",
      "Francisco Martinez"
    ],
    "abstract": "We conduct a numerical study of the transient phenomenon in pipelines\ntransporting plastic Bingham slurry flows, using a lowest-order finite element\nmethod (FEM). While most pipeline hammer studies focus on Newtonian fluids, the\ntransient dynamics in Bingham fluids remains elusive and poorly afforded,\ndespite their significant industrial impact, particularly in mining. A detailed\nparametric study assesses the effects of the slurry yield stress and the valve\nclosure times on both pressure and velocity distributions along the pipeline,\nusing an adaptive friction model to account for turbulent slurries. Results\nreveal that yield stress enhances flow resistance and accelerates pressure peak\nattenuation, underscoring the damping role of Bingham rheology compared to\nNewtonian flows. These insights emphasize the need for advanced FEM-based\nschemes in non-Newtonian shockwave modeling, with implications for industrial\npipeline design and operational safety.",
    "pdf_url": "http://arxiv.org/pdf/2502.00610v2",
    "published": "2025-02-02T00:35:19+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.00609v1",
    "title": "Normal-normal continuous symmetric stress approximation in three-dimensional linear elasticity",
    "authors": [
      "Carsten Carstensen",
      "Norbert Heuer"
    ],
    "abstract": "We present a conforming setting for a mixed formulation of linear elasticity\nwith symmetric stress that has normal-normal continuous components across faces\nof tetrahedral meshes. We provide a stress element for this formulation with 30\ndegrees of freedom that correspond to standard boundary conditions. The\nresulting scheme converges quasi-optimally and is locking free. Numerical\nexperiments illustrate the performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.00609v1",
    "published": "2025-02-02T00:34:05+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65N30, 74G15, 74S05"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.00608v1",
    "title": "Dielectric nanotomography based on electrostatic force microscopy: A numerical analysis",
    "authors": [
      "Rene Fabregas",
      "Gabriel Gomila"
    ],
    "abstract": "Electrostatic force microscopy (EFM) can image nanoscale objects buried below\nthe surface. Here, we theoretically show that this capability can be used to\nobtain nanotomographic information, i.e., the physical dimensions and\ndielectric properties, of buried nano-objects. These results constitute a first\nstep toward implementing a nondestructive dielectric nanotomography technique\nbased on EFM with applications in materials sciences and life sciences.",
    "pdf_url": "http://arxiv.org/pdf/2502.00608v1",
    "published": "2025-02-02T00:32:39+00:00",
    "categories": [
      "physics.ins-det",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2502.00607v3",
    "title": "PAC Learning is just Bipartite Matching (Sort of)",
    "authors": [
      "Shaddin Dughmi"
    ],
    "abstract": "The main goal of this article is to convince you, the reader, that supervised\nlearning in the Probably Approximately Correct (PAC) model is closely related\nto -- of all things -- bipartite matching! En-route from PAC learning to\nbipartite matching, I will overview a particular transductive model of\nlearning, and associated one-inclusion graphs, which can be viewed as a\ngeneralization of some of the hat puzzles that are popular in recreational\nmathematics. Whereas this transductive model is far from new, it has recently\nseen a resurgence of interest as a tool for tackling deep questions in learning\ntheory. A secondary purpose of this article could be as a (biased) tutorial on\nthe connections between the PAC and transductive models of learning.",
    "pdf_url": "http://arxiv.org/pdf/2502.00607v3",
    "published": "2025-02-02T00:28:22+00:00",
    "categories": [
      "cs.LG",
      "cs.DS",
      "stat.ML",
      "F.0"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00606v1",
    "title": "A Unified Bayesian Nonparametric Framework for Ordinal, Survival, and Density Regression Using the Complementary Log-Log Link",
    "authors": [
      "Entejar Alam",
      "Antonio R. Linero"
    ],
    "abstract": "In this work, we develop applications of the complementary log-log (cloglog)\nlink to problems in Bayesian nonparametrics. Although less commonly used than\nthe probit or logit links, we find that the cloglog link is computationally and\ntheoretically well-suited to several commonly used Bayesian nonparametric\nmethods. Our starting point is a Bayesian nonparametric model for ordinal\nregression. We first review how the cloglog link uniquely sits at the\nintersection of the cumulative link and continuation ratio approaches to\nordinal regression. Then, we develop a convenient computational method for\nfitting these ordinal models using Bayesian additive regression trees. Next, we\nuse our ordinal regression model to build a Bayesian nonparametric\nstick-breaking process and show that, under a proportional hazards assumption,\nour stick-breaking process can be used to construct a weight-dependent\nDirichlet process mixture model. Again, Bayesian additive regression trees lead\nto convenient computations. We then extend these models to allow for Bayesian\nnonparametric survival analysis in both discrete and continuous time. Our\nmodels have desirable theoretical properties, and we illustrate this analyzing\nthe posterior contraction rate of our ordinal models. Finally, we demonstrate\nthe practical utility of our cloglog models through a series of illustrative\nexamples.",
    "pdf_url": "http://arxiv.org/pdf/2502.00606v1",
    "published": "2025-02-02T00:26:37+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.00605v1",
    "title": "The Query/Hit Model for Sequential Hypothesis Testing",
    "authors": [
      "Mahshad Shariatnasab",
      "Stefano Rini",
      "Farhad Shirani",
      "S. Sitharama Iyengar"
    ],
    "abstract": "This work introduces the Query/Hit (Q/H) learning model. The setup consists\nof two agents. One agent, Alice, has access to a streaming source, while the\nother, Bob, does not have direct access to the source. Communication occurs\nthrough sequential Q/H pairs: Bob sends a sequence of source symbols (queries),\nand Alice responds with the waiting time until each query appears in the source\nstream (hits). This model is motivated by scenarios with communication,\ncomputation, and privacy constraints that limit real-time access to the source.\nThe error exponent for sequential hypothesis testing under the Q/H model is\ncharacterized, and a querying strategy, the Dynamic Scout-Sentinel Algorithm\n(DSSA), is proposed. The strategy employs a mutual information neural estimator\nto compute the error exponent associated with each query and to select the\nquery with the highest efficiency. Extensive empirical evaluations on both\nsynthetic and real-world datasets -- including mouse movement trajectories,\ntypesetting patterns, and touch-based user interactions -- are provided to\nevaluate the performance of the proposed strategy in comparison with baselines,\nin terms of probability of error, query choice, and time-to-detection.",
    "pdf_url": "http://arxiv.org/pdf/2502.00605v1",
    "published": "2025-02-02T00:23:28+00:00",
    "categories": [
      "cs.IT",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.00604v1",
    "title": "Gradient Alignment in Physics-informed Neural Networks: A Second-Order Optimization Perspective",
    "authors": [
      "Sifan Wang",
      "Ananyae Kumar Bhartari",
      "Bowen Li",
      "Paris Perdikaris"
    ],
    "abstract": "Multi-task learning through composite loss functions is fundamental to modern\ndeep learning, yet optimizing competing objectives remains challenging. We\npresent new theoretical and practical approaches for addressing directional\nconflicts between loss terms, demonstrating their effectiveness in\nphysics-informed neural networks (PINNs) where such conflicts are particularly\nchallenging to resolve. Through theoretical analysis, we demonstrate how these\nconflicts limit first-order methods and show that second-order optimization\nnaturally resolves them through implicit gradient alignment. We prove that\nSOAP, a recently proposed quasi-Newton method, efficiently approximates the\nHessian preconditioner, enabling breakthrough performance in PINNs:\nstate-of-the-art results on 10 challenging PDE benchmarks, including the first\nsuccessful application to turbulent flows with Reynolds numbers up to 10,000,\nwith 2-10x accuracy improvements over existing methods. We also introduce a\nnovel gradient alignment score that generalizes cosine similarity to multiple\ngradients, providing a practical tool for analyzing optimization dynamics. Our\nfindings establish frameworks for understanding and resolving gradient\nconflicts, with broad implications for optimization beyond scientific\ncomputing.",
    "pdf_url": "http://arxiv.org/pdf/2502.00604v1",
    "published": "2025-02-02T00:21:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00603v1",
    "title": "Hades: Hierarchical Adaptable Decoding for Efficient and Elastic vRAN",
    "authors": [
      "Jincao Zhu",
      "Kobus Van Der Merwe",
      "Xenofon Foukas",
      "Bozidar Radunovic"
    ],
    "abstract": "In cellular networks, virtualized Radio Access Networks (vRANs) enable\nreplacing traditional specialized hardware at cell sites with software running\non commodity servers distributed across edge and remote clouds. However, some\nvRAN functions (e.g., forward error correction (FEC) decoding) require\nexcessive edge compute resources due to their intensive computational demands\nand inefficiencies caused by workload fluctuations. This high demand for\ncomputational power significantly drives up the costs associated with edge\ncomputing, posing a major challenge for deploying 5G/6G vRAN solutions. To\naddress this challenge, we propose Hades, a hierarchical architecture for vRAN\nthat enables the distribution of uplink FEC decoding processing across edge and\nremote clouds. Hades refactors the vRAN stack and introduces mechanisms that\nallow controlling and managing the workload over these hierarchical cloud\nresources. More specifically, Hades splits the traditional non-stop\nrun-to-completion iterative FEC decoding process into latency-critical early\ndecoding iterations, i.e., related to MAC processing and early pre-parsing for\ncontent identification, and completion decoding iterations, i.e., decoding\ntasks with larger decoding delay budgets for final data bits extraction. This\npartitioning provides Hades the flexibility to utilize the available midhaul\n(MH) network for offloading the latency tolerant part of decoding to remote\ncloud instances, while performing time-sensitive decoding at the edge cloud\nlocations for low-delay processing. Hades controls decoding load distribution\nbetween the edge and remote clouds, based on the edge decoding capacity and the\noffload network bandwidth, thus improving the utilization of edge compute.",
    "pdf_url": "http://arxiv.org/pdf/2502.00603v1",
    "published": "2025-02-02T00:21:10+00:00",
    "categories": [
      "cs.NI",
      "ACM C.2.1"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.14873v1",
    "title": "Well-posedness and trivial solutions to inverse eigenstrain problems",
    "authors": [
      "Christopher Wensrich",
      "Sean Holman",
      "William Lionheart",
      "Vladimir Luzin",
      "Dylan Cuskelly",
      "Oliver Kirstein",
      "Filomena Salvemini"
    ],
    "abstract": "We examine the well-posedness of inverse eigenstrain problems for residual\nstress analysis from the perspective of the non-uniqueness of solutions,\nstructure of the corresponding null space and associated orthogonal range-null\ndecompositions. Through this process we highlight the existence of a trivial\nsolution to all inverse eigenstrain problems, with all other solutions\ndiffering from this trivial version by an unobservable null component. From one\nperspective, this implies that no new information can be gained though\neigenstrain analysis, however we also highlight the utility of the eigenstrain\nframework for enforcing equilibrium while estimating residual stress from\nincomplete experimental data. Two examples based on measured experimental data\nare given; one axisymmetric system involving ancient Roman medical tools, and\none more-general system involving an additively manufactured Inconel sample. We\nconclude by drawing a link between eigenstrain and reconstruction formulas\nrelated to strain tomography based on the Longitudinal Ray Transform (LRT).\nThrough this link, we establish a potential means for tomographic\nreconstruction of residual stress from LRT measurements.",
    "pdf_url": "http://arxiv.org/pdf/2502.14873v1",
    "published": "2025-02-02T00:17:35+00:00",
    "categories": [
      "math.GM",
      "74G75"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2502.06803v1",
    "title": "Emotion Recognition and Generation: A Comprehensive Review of Face, Speech, and Text Modalities",
    "authors": [
      "Rebecca Mobbs",
      "Dimitrios Makris",
      "Vasileios Argyriou"
    ],
    "abstract": "Emotion recognition and generation have emerged as crucial topics in\nArtificial Intelligence research, playing a significant role in enhancing\nhuman-computer interaction within healthcare, customer service, and other\nfields. Although several reviews have been conducted on emotion recognition and\ngeneration as separate entities, many of these works are either fragmented or\nlimited to specific methodologies, lacking a comprehensive overview of recent\ndevelopments and trends across different modalities. In this survey, we provide\na holistic review aimed at researchers beginning their exploration in emotion\nrecognition and generation. We introduce the fundamental principles underlying\nemotion recognition and generation across facial, vocal, and textual\nmodalities. This work categorises recent state-of-the-art research into\ndistinct technical approaches and explains the theoretical foundations and\nmotivations behind these methodologies, offering a clearer understanding of\ntheir application. Moreover, we discuss evaluation metrics, comparative\nanalyses, and current limitations, shedding light on the challenges faced by\nresearchers in the field. Finally, we propose future research directions to\naddress these challenges and encourage further exploration into developing\nrobust, effective, and ethically responsible emotion recognition and generation\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2502.06803v1",
    "published": "2025-02-02T00:11:19+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "I.2.10"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.00602v2",
    "title": "Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing",
    "authors": [
      "Tianci Liu",
      "Ruirui Li",
      "Zihan Dong",
      "Hui Liu",
      "Xianfeng Tang",
      "Qingyu Yin",
      "Linjun Zhang",
      "Haoyu Wang",
      "Jing Gao"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable performance on various\nnatural language tasks. However, they are trained on static corpora and their\nknowledge can become outdated quickly in the fast-changing world. This\nmotivates the development of knowledge editing (KE) to update specific\nknowledge in LLMs without changing unrelated others or compromising their\npre-trained capabilities. Previous efforts sought to update a small amount of\nparameters of a LLM and proved effective for making selective updates.\nNonetheless, the edited LLM often exhibits degraded ability to reason about the\nnew knowledge. In this work, we identify a key issue: heterogeneous token\noverfitting (HTO), where the LLM overfits different tokens in the provided\nknowledge at varying rates. To tackle this, we propose OVERTONE, a token-level\nsmoothing method that mitigates HTO by adaptively refining the target\ndistribution. Theoretically, OVERTONE offers better parameter updates with\nnegligible computation overhead. It also induces an implicit DPO but does not\nrequire preference data pairs. Extensive experiments across four editing\nmethods, two LLMs, and diverse scenarios demonstrate the effectiveness and\nversatility of our method.",
    "pdf_url": "http://arxiv.org/pdf/2502.00602v2",
    "published": "2025-02-02T00:10:51+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.00601v2",
    "title": "Enhancing Offline Reinforcement Learning with Curriculum Learning-Based Trajectory Valuation",
    "authors": [
      "Amir Abolfazli",
      "Zekun Song",
      "Avishek Anand",
      "Wolfgang Nejdl"
    ],
    "abstract": "The success of deep reinforcement learning (DRL) relies on the availability\nand quality of training data, often requiring extensive interactions with\nspecific environments. In many real-world scenarios, where data collection is\ncostly and risky, offline reinforcement learning (RL) offers a solution by\nutilizing data collected by domain experts and searching for a\nbatch-constrained optimal policy. This approach is further augmented by\nincorporating external data sources, expanding the range and diversity of data\ncollection possibilities. However, existing offline RL methods often struggle\nwith challenges posed by non-matching data from these external sources. In this\nwork, we specifically address the problem of source-target domain mismatch in\nscenarios involving mixed datasets, characterized by a predominance of source\ndata generated from random or suboptimal policies and a limited amount of\ntarget data generated from higher-quality policies. To tackle this problem, we\nintroduce Transition Scoring (TS), a novel method that assigns scores to\ntransitions based on their similarity to the target domain, and propose\nCurriculum Learning-Based Trajectory Valuation (CLTV), which effectively\nleverages these transition scores to identify and prioritize high-quality\ntrajectories through a curriculum learning approach. Our extensive experiments\nacross various offline RL methods and MuJoCo environments, complemented by\nrigorous theoretical analysis, demonstrate that CLTV enhances the overall\nperformance and transferability of policies learned by offline RL algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2502.00601v2",
    "published": "2025-02-02T00:03:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  }
]