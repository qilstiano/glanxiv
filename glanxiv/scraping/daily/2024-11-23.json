[
  {
    "id": "http://arxiv.org/abs/2411.15673v1",
    "title": "Semantic Shield: Defending Vision-Language Models Against Backdooring and Poisoning via Fine-grained Knowledge Alignment",
    "authors": [
      "Alvi Md Ishmam",
      "Christopher Thomas"
    ],
    "abstract": "In recent years there has been enormous interest in vision-language models\ntrained using self-supervised objectives. However, the use of large-scale\ndatasets scraped from the web for training also makes these models vulnerable\nto potential security threats, such as backdooring and poisoning attacks. In\nthis paper, we propose a method for mitigating such attacks on contrastively\ntrained vision-language models. Our approach leverages external knowledge\nextracted from a language model to prevent models from learning correlations\nbetween image regions which lack strong alignment with external knowledge. We\ndo this by imposing constraints to enforce that attention paid by the model to\nvisual regions is proportional to the alignment of those regions with external\nknowledge. We conduct extensive experiments using a variety of recent\nbackdooring and poisoning attacks on multiple datasets and architectures. Our\nresults clearly demonstrate that our proposed approach is highly effective at\ndefending against such attacks across multiple settings, while maintaining\nmodel utility and without requiring any changes at inference time",
    "pdf_url": "http://arxiv.org/pdf/2411.15673v1",
    "published": "2024-11-23T23:51:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.00048v1",
    "title": "The Hexagonal Tiling Honeycomb",
    "authors": [
      "John C. Baez"
    ],
    "abstract": "The hexagonal tiling honeycomb is a beautiful structure in 3-dimensional\nhyperbolic space. It is called {6,3,3} because each hexagon has 6 edges, 3\nhexagons meet at each vertex in a Euclidean plane tiled by regular hexagons,\nand 3 such planes meet along each edge of this honeycomb. It also appears\nnaturally in algebraic geometry. If $\\mathbb{E}$ denotes the Eisenstein\nintegers, the N\\'eron-Severi group of the abelian surface\n$\\mathbb{C}^2/\\mathbb{E}^2$ is isomorphic to the lattice\n$\\mathfrak{h}_2(\\mathbb{E})$ consisting of $2 \\times 2$ hermitian matrices with\nEisenstein integer entries. The points $A \\in \\mathfrak{h}_2(\\mathbb{E})$ with\n$\\mathrm{tr}(A) \\gt 0$ and $\\det(A) \\gt 0$ come from ample line bundles on\n$\\mathbb{C}^2/\\mathbb{E}^2$, and among these points, those with $\\det(A) = 1$\ncorrespond to principal polarizations. But these points are precisely the\ncenters of the hexagons in the hexagonal tiling honeycomb!",
    "pdf_url": "http://arxiv.org/pdf/2412.00048v1",
    "published": "2024-11-23T23:45:44+00:00",
    "categories": [
      "math.HO",
      "math.AG",
      "math.MG"
    ],
    "primary_category": "math.HO"
  },
  {
    "id": "http://arxiv.org/abs/2411.15672v1",
    "title": "IRSKG: Unified Intrusion Response System Knowledge Graph Ontology for Cyber Defense",
    "authors": [
      "Damodar Panigrahi",
      "Shaswata Mitra",
      "Subash Neupane",
      "Sudip Mittal",
      "Benjamin A. Blakely"
    ],
    "abstract": "Cyberattacks are becoming increasingly difficult to detect and prevent due to\ntheir sophistication. In response, Autonomous Intelligent Cyber-defense Agents\n(AICAs) are emerging as crucial solutions. One prominent AICA agent is the\nIntrusion Response System (IRS), which is critical for mitigating threats after\ndetection. IRS uses several Tactics, Techniques, and Procedures (TTPs) to\nmitigate attacks and restore the infrastructure to normal operations.\nContinuous monitoring of the enterprise infrastructure is an essential TTP the\nIRS uses. However, each system serves different purposes to meet operational\nneeds. Integrating these disparate sources for continuous monitoring increases\npre-processing complexity and limits automation, eventually prolonging critical\nresponse time for attackers to exploit. We propose a unified IRS Knowledge\nGraph ontology (IRSKG) that streamlines the onboarding of new enterprise\nsystems as a source for the AICAs. Our ontology can capture system monitoring\nlogs and supplemental data, such as a rules repository containing the\nadministrator-defined policies to dictate the IRS responses. Besides, our\nontology permits us to incorporate dynamic changes to adapt to the evolving\ncyber-threat landscape. This robust yet concise design allows machine learning\nmodels to train effectively and recover a compromised system to its desired\nstate autonomously with explainability.",
    "pdf_url": "http://arxiv.org/pdf/2411.15672v1",
    "published": "2024-11-23T23:31:55+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15671v1",
    "title": "Best of Both Worlds: Advantages of Hybrid Graph Sequence Models",
    "authors": [
      "Ali Behrouz",
      "Ali Parviz",
      "Mahdi Karami",
      "Clayton Sanford",
      "Bryan Perozzi",
      "Vahab Mirrokni"
    ],
    "abstract": "Modern sequence models (e.g., Transformers, linear RNNs, etc.) emerged as\ndominant backbones of recent deep learning frameworks, mainly due to their\nefficiency, representational power, and/or ability to capture long-range\ndependencies. Adopting these sequence models for graph-structured data has\nrecently gained popularity as the alternative to Message Passing Neural\nNetworks (MPNNs). There is, however, a lack of a common foundation about what\nconstitutes a good graph sequence model, and a mathematical description of the\nbenefits and deficiencies in adopting different sequence models for learning on\ngraphs. To this end, we first present Graph Sequence Model (GSM), a unifying\nframework for adopting sequence models for graphs, consisting of three main\nsteps: (1) Tokenization, which translates the graph into a set of sequences;\n(2) Local Encoding, which encodes local neighborhoods around each node; and (3)\nGlobal Encoding, which employs a scalable sequence model to capture long-range\ndependencies within the sequences. This framework allows us to understand,\nevaluate, and compare the power of different sequence model backbones in graph\ntasks. Our theoretical evaluations of the representation power of Transformers\nand modern recurrent models through the lens of global and local graph tasks\nshow that there are both negative and positive sides for both types of models.\nBuilding on this observation, we present GSM++, a fast hybrid model that uses\nthe Hierarchical Affinity Clustering (HAC) algorithm to tokenize the graph into\nhierarchical sequences, and then employs a hybrid architecture of Transformer\nto encode these sequences. Our theoretical and experimental results support the\ndesign of GSM++, showing that GSM++ outperforms baselines in most benchmark\nevaluations.",
    "pdf_url": "http://arxiv.org/pdf/2411.15671v1",
    "published": "2024-11-23T23:24:42+00:00",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15670v1",
    "title": "Skoda's $L^2$ division theorem for $L^2$-optimal pairs",
    "authors": [
      "Zhuo Liu",
      "Xujun Zhang"
    ],
    "abstract": "We establish a Skoda-type $L^2$ division theorem for $L^2$-optimal pairs,\nusing a technique that combines a new Bochner-type inequality derived from the\n$L^2$-optimal conditions and Skoda's basic inequality. As applications, we\nprovide some new characterizations of domains of holomorphy.",
    "pdf_url": "http://arxiv.org/pdf/2411.15670v1",
    "published": "2024-11-23T23:18:13+00:00",
    "categories": [
      "math.CV",
      "32W05, 32U05, 32D05, 32Q28, 14F18"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.16747v1",
    "title": "FollowGen: A Scaled Noise Conditional Diffusion Model for Car-Following Trajectory Prediction",
    "authors": [
      "Junwei You",
      "Rui Gan",
      "Weizhe Tang",
      "Zilin Huang",
      "Jiaxi Liu",
      "Zhuoyu Jiang",
      "Haotian Shi",
      "Keshu Wu",
      "Keke Long",
      "Sicheng Fu",
      "Sikai Chen",
      "Bin Ran"
    ],
    "abstract": "Vehicle trajectory prediction is crucial for advancing autonomous driving and\nadvanced driver assistance systems (ADAS). Although deep learning-based\napproaches - especially those utilizing transformer-based and generative models\n- have markedly improved prediction accuracy by capturing complex, non-linear\npatterns in vehicle dynamics and traffic interactions, they frequently overlook\ndetailed car-following behaviors and the inter-vehicle interactions critical\nfor real-world driving applications, particularly in fully autonomous or mixed\ntraffic scenarios. To address the issue, this study introduces a scaled noise\nconditional diffusion model for car-following trajectory prediction, which\nintegrates detailed inter-vehicular interactions and car-following dynamics\ninto a generative framework, improving both the accuracy and plausibility of\npredicted trajectories. The model utilizes a novel pipeline to capture\nhistorical vehicle dynamics by scaling noise with encoded historical features\nwithin the diffusion process. Particularly, it employs a cross-attention-based\ntransformer architecture to model intricate inter-vehicle dependencies,\neffectively guiding the denoising process and enhancing prediction accuracy.\nExperimental results on diverse real-world driving scenarios demonstrate the\nstate-of-the-art performance and robustness of the proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2411.16747v1",
    "published": "2024-11-23T23:13:45+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15669v2",
    "title": "Implicit High-Order Moment Tensor Estimation and Learning Latent Variable Models",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane"
    ],
    "abstract": "We study the task of learning latent-variable models. A common algorithmic\ntechnique for this task is the method of moments. Unfortunately, moment-based\napproaches are hampered by the fact that the moment tensors of super-constant\ndegree cannot even be written down in polynomial time. Motivated by such\nlearning applications, we develop a general efficient algorithm for {\\em\nimplicit moment tensor computation}. Our framework generalizes the work\nof~\\cite{LL21-opt} which developed an efficient algorithm for the specific\nmoment tensors that arise in clustering mixtures of spherical Gaussians.\n  By leveraging our implicit moment estimation algorithm, we obtain the first\n$\\mathrm{poly}(d, k)$-time learning algorithms for the following models.\n  * {\\bf Mixtures of Linear Regressions} We give a $\\mathrm{poly}(d, k,\n1/\\epsilon)$-time algorithm for this task, where $\\epsilon$ is the desired\nerror.\n  * {\\bf Mixtures of Spherical Gaussians} For density estimation, we give a\n$\\mathrm{poly}(d, k, 1/\\epsilon)$-time learning algorithm, where $\\epsilon$ is\nthe desired total variation error, under the condition that the means lie in a\nball of radius $O(\\sqrt{\\log k})$. For parameter estimation, we give a\n$\\mathrm{poly}(d, k, 1/\\epsilon)$-time algorithm under the {\\em optimal} mean\nseparation of $\\Omega(\\log^{1/2}(k/\\epsilon))$.\n  * {\\bf Positive Linear Combinations of Non-Linear Activations} We give a\ngeneral algorithm for this task with complexity $\\mathrm{poly}(d, k)\ng(\\epsilon)$, where $\\epsilon$ is the desired error and the function $g$\ndepends on the Hermite concentration of the target class of functions.\nSpecifically, for positive linear combinations of ReLU activations, our\nalgorithm has complexity $\\mathrm{poly}(d, k) 2^{\\mathrm{poly}(1/\\epsilon)}$.",
    "pdf_url": "http://arxiv.org/pdf/2411.15669v2",
    "published": "2024-11-23T23:13:24+00:00",
    "categories": [
      "cs.DS",
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2411.15668v1",
    "title": "Advances in understanding vacuum break dynamics in liquid helium-cooled tubes for accelerator beamline applications",
    "authors": [
      "Yinghe Qi",
      "Wei Guo"
    ],
    "abstract": "Understanding air propagation and condensation following a catastrophic\nvacuum break in particle accelerator beamlines cooled by liquid helium is\nessential for ensuring operational safety. This review summarizes experimental\nand theoretical work conducted in our cryogenics lab to address this issue.\nSystematic measurements were performed to study nitrogen gas propagation in\nuniform copper tubes cooled by both normal liquid helium (He I) and superfluid\nhelium (He II). These experiments revealed a nearly exponential deceleration of\nthe gas front, with stronger deceleration observed in He II-cooled tubes. To\ninterpret these results, a one-dimensional (1D) theoretical model was\ndeveloped, incorporating gas dynamics, heat transfer, and condensation\nmechanisms. The model successfully reproduced key experimental observations in\nthe uniform tube system. However, recent experiments involving a bulky copper\ncavity designed to mimic the geometry of a superconducting radio-frequency\n(SRF) cavity revealed strong anisotropic flow patterns of nitrogen gas within\nthe cavity, highlighting limitations in extrapolating results from simplified\ntube geometries to real accelerator beamlines. To address these complexities,\nwe outline plans for systematic studies using tubes with multiple bulky\ncavities and the development of a two-dimensional (2D) model to simulate gas\ndynamics in these more intricate configurations. These efforts aim to provide a\ncomprehensive understanding of vacuum breaks in particle accelerators and\nimprove predictive capabilities for their operational safety.",
    "pdf_url": "http://arxiv.org/pdf/2411.15668v1",
    "published": "2024-11-23T23:13:23+00:00",
    "categories": [
      "physics.acc-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15667v1",
    "title": "NN-AE-VQE: Neural network parameter prediction on autoencoded variational quantum eigensolvers",
    "authors": [
      "Koen Mesman",
      "Yinglu Tang",
      "Matthias Moller",
      "Boyang Chen",
      "Sebastian Feld"
    ],
    "abstract": "A longstanding computational challenge is the accurate simulation of\nmany-body particle systems. Especially for deriving key characteristics of\nhigh-impact but complex systems such as battery materials and high entropy\nalloys (HEA). While simple models allow for simulations of the required scale,\nthese methods often fail to capture the complex dynamics that determine the\ncharacteristics. A long-theorized approach is to use quantum computers for this\npurpose, which allows for a more efficient encoding of quantum mechanical\nsystems. In recent years, the field of quantum computing has become\nsignificantly more mature. Furthermore, the rise in integration of machine\nlearning with quantum computing further pushes to a near-term advantage. In\nthis work we aim to improve the well-established quantum computing method for\ncalculating the inter-atomic potential, the variational quantum eigensolver, by\npresenting an auto-encoded VQE with neural-network predictions: NN-AE-VQE. We\napply a quantum autoencoder for a compressed quantum state representation of\nthe atomic system, to which a naive circuit ansatz is applied. This reduces the\nnumber of circuit parameters to optimize, while still minimal reduction in\naccuracy. Additionally, we train a classical neural network to predict the\ncircuit parameters to avoid computationally expensive parameter optimization.\nWe demonstrate these methods on a $H_2$ molecule, achieving chemical accuracy.\nWe believe this method shows promise of efficiently capturing highly accurate\nsystems while omitting current bottlenecks of variational quantum algorithms.\nFinally, we explore options for exploiting the algorithm structure and further\nalgorithm improvements.",
    "pdf_url": "http://arxiv.org/pdf/2411.15667v1",
    "published": "2024-11-23T23:09:22+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15666v1",
    "title": "Ontology-Constrained Generation of Domain-Specific Clinical Summaries",
    "authors": [
      "Gaya Mehenni",
      "Amal Zouaq"
    ],
    "abstract": "Large Language Models (LLMs) offer promising solutions for text\nsummarization. However, some domains require specific information to be\navailable in the summaries. Generating these domain-adapted summaries is still\nan open challenge. Similarly, hallucinations in generated content is a major\ndrawback of current approaches, preventing their deployment. This study\nproposes a novel approach that leverages ontologies to create domain-adapted\nsummaries both structured and unstructured. We employ an ontology-guided\nconstrained decoding process to reduce hallucinations while improving\nrelevance. When applied to the medical domain, our method shows potential in\nsummarizing Electronic Health Records (EHRs) across different specialties,\nallowing doctors to focus on the most relevant information to their domain.\nEvaluation on the MIMIC-III dataset demonstrates improvements in generating\ndomain-adapted summaries of clinical notes and hallucination reduction.",
    "pdf_url": "http://arxiv.org/pdf/2411.15666v1",
    "published": "2024-11-23T23:05:48+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15665v1",
    "title": "High temperature melting of dense molecular hydrogen from machine-learning interatomic potentials trained on quantum Monte Carlo",
    "authors": [
      "Shubhang Goswami",
      "Scott Jensen",
      "Yubo Yang",
      "Markus Holzmann",
      "Carlo Pierleoni",
      "David M. Ceperley"
    ],
    "abstract": "We present results and discuss methods for computing the melting temperature\nof dense molecular hydrogen using a machine learned model trained on quantum\nMonte Carlo data. In this newly trained model, we emphasize the importance of\naccurate total energies in the training. We integrate a two phase method for\nestimating the melting temperature with estimates from the Clausius-Clapeyron\nrelation to provide a more accurate melting curve from the model. We make\ndetailed predictions of the melting temperature, solid and liquid volumes,\nlatent heat and internal energy from 50 GPa to 180 GPa for both classical\nhydrogen and quantum hydrogen. At pressures of roughly 173 GPa and 1635K, we\nobserve molecular dissociation in the liquid phase. We compare with previous\nsimulations and experimental measurements.",
    "pdf_url": "http://arxiv.org/pdf/2411.15665v1",
    "published": "2024-11-23T22:56:31+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.00047v1",
    "title": "A Python Framework Enhancement for Neutrosophic Topologies",
    "authors": [
      "Giorgio Nordo",
      "Saeid Jafari",
      "Maikel Yelandi Leyva Vazquez"
    ],
    "abstract": "This paper introduces an extension to the Python Neutrosophic Sets (PYNS)\nframework, originally detailed in Nordo et al. 2024, with the addition of the\nNSfamily class for constructing and manipulating neutrosophic topologies.\nBuilding on existing classes like NSuniverse and NSset, the NSfamily class\nenables the definition and testing of neutrosophic families as basis and\nsub-basis for neutrosophic topological spaces. This extension provides tools\nfor verifying closure properties under union and intersection, and for\ndetermining whether a given family constitutes a neutrosophic topology. Through\nimplemented algorithms, the framework automates the generation of topologies\nfrom families of neutrosophic sets, offering an efficient tool for advancing\nresearch in neutrosophic topology. Practical applications are demonstrated with\ndetailed examples, showcasing how this class enhances the scope and flexibility\nof neutrosophic modeling within the PYNS framework.",
    "pdf_url": "http://arxiv.org/pdf/2412.00047v1",
    "published": "2024-11-23T22:47:21+00:00",
    "categories": [
      "math.GM",
      "03E72, 54A40, 54D99, 68W99"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15664v1",
    "title": "Enabling Efficient Serverless Inference Serving for LLM (Large Language Model) in the Cloud",
    "authors": [
      "Himel Ghosh"
    ],
    "abstract": "This review report discusses the cold start latency in serverless inference\nand existing solutions. It particularly reviews the ServerlessLLM method, a\nsystem designed to address the cold start problem in serverless inference for\nlarge language models. Traditional serverless approaches struggle with high\nlatency due to the size of LLM checkpoints and the overhead of initializing GPU\nresources. ServerlessLLM introduces a multitier checkpoint loading system,\nleveraging underutilized GPU memory and storage to reduce startup times by\n6--8x compared to existing methods. It also proposes live inference migration\nand a startup-time-optimized model scheduler, ensuring efficient resource\nallocation and minimizing delays. This system significantly improves\nperformance and scalability in serverless environments for LLM workloads.\nBesides ServerlessLLM, several other methods from recent research literature,\nincluding Rainbowcake, are reviewed in this paper. Further discussions explore\nhow FaaS providers tackle cold starts and the possible future scopes.",
    "pdf_url": "http://arxiv.org/pdf/2411.15664v1",
    "published": "2024-11-23T22:19:37+00:00",
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15663v1",
    "title": "A Note on the Growth of Sha in Dihedral Extensions",
    "authors": [
      "Jamie Bell"
    ],
    "abstract": "We provide a formula for the order of the Tate--Shafarevich group of elliptic\ncurves over dihedral extensions of number fields of order $2n$, up to $4^{th}$\npowers and primes dividing $n$. Specifically, for odd $n$ it is equal to the\norder of the Tate--Shafarevich group over the quadratic subextension. A similar\nformula holds for even $n$.",
    "pdf_url": "http://arxiv.org/pdf/2411.15663v1",
    "published": "2024-11-23T22:19:06+00:00",
    "categories": [
      "math.NT",
      "11G05 (Primary), 11G40 (Secondary)"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15662v1",
    "title": "Gaps Between Research and Practice When Measuring Representational Harms Caused by LLM-Based Systems",
    "authors": [
      "Emma Harvey",
      "Emily Sheng",
      "Su Lin Blodgett",
      "Alexandra Chouldechova",
      "Jean Garcia-Gathright",
      "Alexandra Olteanu",
      "Hanna Wallach"
    ],
    "abstract": "To facilitate the measurement of representational harms caused by large\nlanguage model (LLM)-based systems, the NLP research community has produced and\nmade publicly available numerous measurement instruments, including tools,\ndatasets, metrics, benchmarks, annotation instructions, and other techniques.\nHowever, the research community lacks clarity about whether and to what extent\nthese instruments meet the needs of practitioners tasked with developing and\ndeploying LLM-based systems in the real world, and how these instruments could\nbe improved. Via a series of semi-structured interviews with practitioners in a\nvariety of roles in different organizations, we identify four types of\nchallenges that prevent practitioners from effectively using publicly available\ninstruments for measuring representational harms caused by LLM-based systems:\n(1) challenges related to using publicly available measurement instruments; (2)\nchallenges related to doing measurement in practice; (3) challenges arising\nfrom measurement tasks involving LLM-based systems; and (4) challenges specific\nto measuring representational harms. Our goal is to advance the development of\ninstruments for measuring representational harms that are well-suited to\npractitioner needs, thus better facilitating the responsible development and\ndeployment of LLM-based systems.",
    "pdf_url": "http://arxiv.org/pdf/2411.15662v1",
    "published": "2024-11-23T22:13:38+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2411.15661v2",
    "title": "Improving Next Tokens via Second-to-Last Predictions with Generate and Refine",
    "authors": [
      "Johannes Schneider"
    ],
    "abstract": "Autoregressive language models like GPT aim to predict next tokens, while\nautoencoding models such as BERT are trained on tasks such as predicting masked\ntokens. We train a decoder-only architecture for predicting the second to last\ntoken for a sequence of tokens. Our approach yields higher computational\ntraining efficiency than BERT-style models by employing a structured\ndeterministic approach to masking tokens. We use our model to improve the next\ntoken predictions of a standard GPT by combining both predictions in a\n``generate-then-refine'' approach. We demonstrate on different variants of\nGPT-2 and different datasets that (not unexpectedly) second to last token\npredictions are much more accurate, i.e., more than 15\\% higher accuracy than\nstandard next token predictions. The ``generate-then-refine'' approach also\ndemonstrates notable improvements in next-token predictions, yielding smaller\nyet consistent and significant gains.",
    "pdf_url": "http://arxiv.org/pdf/2411.15661v2",
    "published": "2024-11-23T22:09:58+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15660v1",
    "title": "Federated PCA and Estimation for Spiked Covariance Matrices: Optimal Rates and Efficient Algorithm",
    "authors": [
      "Jingyang Li",
      "T. Tony Cai",
      "Dong Xia",
      "Anru R. Zhang"
    ],
    "abstract": "Federated Learning (FL) has gained significant recent attention in machine\nlearning for its enhanced privacy and data security, making it indispensable in\nfields such as healthcare, finance, and personalized services. This paper\ninvestigates federated PCA and estimation for spiked covariance matrices under\ndistributed differential privacy constraints. We establish minimax rates of\nconvergence, with a key finding that the central server's optimal rate is the\nharmonic mean of the local clients' minimax rates. This guarantees consistent\nestimation at the central server as long as at least one local client provides\nconsistent results. Notably, consistency is maintained even if some local\nestimators are inconsistent, provided there are enough clients. These findings\nhighlight the robustness and scalability of FL for reliable statistical\ninference under privacy constraints. To establish minimax lower bounds, we\nderive a matrix version of van Trees' inequality, which is of independent\ninterest. Furthermore, we propose an efficient algorithm that preserves\ndifferential privacy while achieving near-optimal rates at the central server,\nup to a logarithmic factor. We address significant technical challenges in\nanalyzing this algorithm, which involves a three-layer spectral decomposition.\nNumerical performance of the proposed algorithm is investigated using both\nsimulated and real data.",
    "pdf_url": "http://arxiv.org/pdf/2411.15660v1",
    "published": "2024-11-23T21:57:50+00:00",
    "categories": [
      "math.ST",
      "cs.IT",
      "math.IT",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2411.15659v1",
    "title": "SMM-Conv: Scalar Matrix Multiplication with Zero Packing for Accelerated Convolution",
    "authors": [
      "Amir Ofir",
      "Gil Ben-Artzi"
    ],
    "abstract": "We present a novel approach for accelerating convolutions during inference\nfor CPU-based architectures. The most common method of computation involves\npacking the image into the columns of a matrix (im2col) and performing general\nmatrix multiplication (GEMM) with a matrix of weights. This results in two main\ndrawbacks: (a) im2col requires a large memory buffer and can experience\ninefficient memory access, and (b) while GEMM is highly optimized for\nscientific matrices multiplications, it is not well suited for convolutions. We\npropose an approach that takes advantage of scalar-matrix multiplication and\nreduces memory overhead. Our experiments with commonly used network\narchitectures demonstrate a significant speedup compared to existing indirect\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2411.15659v1",
    "published": "2024-11-23T21:43:38+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15658v3",
    "title": "Existence and Uniqueness of Local and Global Solutions for a Partial Differential-Algebraic Equation of Index One",
    "authors": [
      "Seyyid Ali Benabdallah",
      "Messoud Souilah"
    ],
    "abstract": "In this paper, we use the theory of nonlinear semigroups to establish the\nexistence and uniqueness of both local and global solutions for a partial\ndifferential-algebraic equation (PDAE) of index one. This method is applied to\na reaction-diffusion system coupled with an elliptic equation in one dimension\nby transforming the PDAE into a system of linear evolution equations with a\nLipschitz-continuous perturbation",
    "pdf_url": "http://arxiv.org/pdf/2411.15658v3",
    "published": "2024-11-23T21:43:16+00:00",
    "categories": [
      "math.AP",
      "47B01, 47F05, 47H20, 47N60"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15657v1",
    "title": "Training an Open-Vocabulary Monocular 3D Object Detection Model without 3D Data",
    "authors": [
      "Rui Huang",
      "Henry Zheng",
      "Yan Wang",
      "Zhuofan Xia",
      "Marco Pavone",
      "Gao Huang"
    ],
    "abstract": "Open-vocabulary 3D object detection has recently attracted considerable\nattention due to its broad applications in autonomous driving and robotics,\nwhich aims to effectively recognize novel classes in previously unseen domains.\nHowever, existing point cloud-based open-vocabulary 3D detection models are\nlimited by their high deployment costs. In this work, we propose a novel\nopen-vocabulary monocular 3D object detection framework, dubbed OVM3D-Det,\nwhich trains detectors using only RGB images, making it both cost-effective and\nscalable to publicly available data. Unlike traditional methods, OVM3D-Det does\nnot require high-precision LiDAR or 3D sensor data for either input or\ngenerating 3D bounding boxes. Instead, it employs open-vocabulary 2D models and\npseudo-LiDAR to automatically label 3D objects in RGB images, fostering the\nlearning of open-vocabulary monocular 3D detectors. However, training 3D models\nwith labels directly derived from pseudo-LiDAR is inadequate due to imprecise\nboxes estimated from noisy point clouds and severely occluded objects. To\naddress these issues, we introduce two innovative designs: adaptive\npseudo-LiDAR erosion and bounding box refinement with prior knowledge from\nlarge language models. These techniques effectively calibrate the 3D labels and\nenable RGB-only training for 3D detectors. Extensive experiments demonstrate\nthe superiority of OVM3D-Det over baselines in both indoor and outdoor\nscenarios. The code will be released.",
    "pdf_url": "http://arxiv.org/pdf/2411.15657v1",
    "published": "2024-11-23T21:37:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15656v1",
    "title": "Machine-agnostic Automated Lumbar MRI Segmentation using a Cascaded Model Based on Generative Neurons",
    "authors": [
      "Promit Basak",
      "Rusab Sarmun",
      "Saidul Kabir",
      "Israa Al-Hashimi",
      "Enamul Hoque Bhuiyan",
      "Anwarul Hasan",
      "Muhammad Salman Khan",
      "Muhammad E. H. Chowdhury"
    ],
    "abstract": "Automated lumbar spine segmentation is very crucial for modern diagnosis\nsystems. In this study, we introduce a novel machine-agnostic approach for\nsegmenting lumbar vertebrae and intervertebral discs from MRI images, employing\na cascaded model that synergizes an ROI detection and a Self-organized\nOperational Neural Network (Self-ONN)-based encoder-decoder network for\nsegmentation. Addressing the challenge of diverse MRI modalities, our\nmethodology capitalizes on a unique dataset comprising images from 12 scanners\nand 34 subjects, enhanced through strategic preprocessing and data augmentation\ntechniques. The YOLOv8 medium model excels in ROI extraction, achieving an\nexcellent performance of 0.916 mAP score. Significantly, our Self-ONN-based\nmodel, combined with a DenseNet121 encoder, demonstrates excellent performance\nin lumbar vertebrae and IVD segmentation with a mean Intersection over Union\n(IoU) of 83.66%, a sensitivity of 91.44%, and Dice Similarity Coefficient (DSC)\nof 91.03%, as validated through rigorous 10-fold cross-validation. This study\nnot only showcases an effective approach to MRI segmentation in spine-related\ndisorders but also sets the stage for future advancements in automated\ndiagnostic tools, emphasizing the need for further dataset expansion and model\nrefinement for broader clinical applicability.",
    "pdf_url": "http://arxiv.org/pdf/2411.15656v1",
    "published": "2024-11-23T21:34:29+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG",
      "I.4.6"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15655v1",
    "title": "Machine Learning-based sEMG Signal Classification for Hand Gesture Recognition",
    "authors": [
      "Parshuram N. Aarotale",
      "Ajita Rattani"
    ],
    "abstract": "EMG-based hand gesture recognition uses electromyographic~(EMG) signals to\ninterpret and classify hand movements by analyzing electrical activity\ngenerated by muscle contractions. It has wide applications in prosthesis\ncontrol, rehabilitation training, and human-computer interaction. Using\nelectrodes placed on the skin, the EMG sensor captures muscle signals, which\nare processed and filtered to reduce noise. Numerous feature extraction and\nmachine learning algorithms have been proposed to extract and classify muscle\nsignals to distinguish between various hand gestures. This paper aims to\nbenchmark the performance of EMG-based hand gesture recognition using novel\nfeature extraction methods, namely, fused time-domain descriptors,\ntemporal-spatial descriptors, and wavelet transform-based features, combined\nwith the state-of-the-art machine and deep learning models. Experimental\ninvestigations on the Grabmyo dataset demonstrate that the 1D Dilated CNN\nperformed the best with an accuracy of $97\\%$ using fused time-domain\ndescriptors such as power spectral moments, sparsity, irregularity factor and\nwaveform length ratio. Similarly, on the FORS-EMG dataset, random forest\nperformed the best with an accuracy of $94.95\\%$ using temporal-spatial\ndescriptors (which include time domain features along with additional features\nsuch as coefficient of variation (COV), and Teager-Kaiser energy operator\n(TKEO)).",
    "pdf_url": "http://arxiv.org/pdf/2411.15655v1",
    "published": "2024-11-23T21:29:51+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15654v1",
    "title": "Cooperative motion in equilibrium phases across two-dimension melting in pure and disordered systems",
    "authors": [
      "Saikat Dutta",
      "Prashanti Jami",
      "Pinaki Chaudhuri",
      "Chandan Dasgupta",
      "Amit Ghosal"
    ],
    "abstract": "We uncover the dynamics of particles with Gaussian core interactions across\nmelting in pure and disordered two-dimensional (2D) systems. Intriguing\nsignatures of cooperative motion of particles in string-like paths are found at\nlow temperatures. Such a motion, while common to glasses and supercooled\nliquids, are realized here in traditional equilibrium phases, including in pure\nsystems. We explore the interplay of such motion and impurities and report\ntheir repercussions on spatiotemporal correlations. In particular, cooperative\nmotion seems to cause a departure from the diffusive dynamics, causing slow\nrelaxation.",
    "pdf_url": "http://arxiv.org/pdf/2411.15654v1",
    "published": "2024-11-23T21:29:04+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2411.15653v1",
    "title": "OCDet: Object Center Detection via Bounding Box-Aware Heatmap Prediction on Edge Devices with NPUs",
    "authors": [
      "Chen Xin",
      "Thomas Motz",
      "Andreas Hartel",
      "Enkelejda Kasneci"
    ],
    "abstract": "Real-time object localization on edge devices is fundamental for numerous\napplications, ranging from surveillance to industrial automation. Traditional\nframeworks, such as object detection, segmentation, and keypoint detection,\nstruggle in resource-constrained environments, often resulting in substantial\ntarget omissions. To address these challenges, we introduce OCDet, a\nlightweight Object Center Detection framework optimized for edge devices with\nNPUs. OCDet predicts heatmaps representing object center probabilities and\nextracts center points through peak identification. Unlike prior methods using\nfixed Gaussian distribution, we introduce Generalized Centerness (GC) to\ngenerate ground truth heatmaps from bounding box annotations, providing finer\nspatial details without additional manual labeling. Built on NPU-friendly\nSemantic FPN with MobileNetV4 backbones, OCDet models are trained by our\nBalanced Continuous Focal Loss (BCFL), which alleviates data imbalance and\nfocuses training on hard negative examples for probability regression tasks.\nLeveraging the novel Center Alignment Score (CAS) with Hungarian matching, we\ndemonstrate that OCDet consistently outperforms YOLO11 in object center\ndetection, achieving up to 23% higher CAS while requiring 42% fewer parameters,\n34% less computation, and 64% lower NPU latency. When compared to keypoint\ndetection frameworks, OCDet achieves substantial CAS improvements up to 186%\nusing identical models. By integrating GC, BCFL, and CAS, OCDet establishes a\nnew paradigm for efficient and robust object center detection on edge devices\nwith NPUs. The code is released at https://github.com/chen-xin-94/ocdet.",
    "pdf_url": "http://arxiv.org/pdf/2411.15653v1",
    "published": "2024-11-23T21:17:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15652v1",
    "title": "Circumbinary disks in post common envelope binary systems with compact objects",
    "authors": [
      "Lotem Unger",
      "Aldana Grichener",
      "Noam Soker"
    ],
    "abstract": "We conduct a population synthesis study using the binary population synthesis\ncode compas to explore the formation of circumbinary disks (CBDs) following the\ncommon envelope evolution (CEE) phase of a giant star and a neutron star (NS)\nor black hole (BH). We focus on massive binary systems that evolve into double\ncompact object (DCO) binaries after the exposed core of the giant collapses to\nform a second NS or BH. A CBD around the binary system of the giant's core and\nthe compact object lives for a short time at the termination of the CEE phase\nand alters the orbital evolution of the binary. We parameterize the conditions\nfor CBD formation in post-CEE binaries and present characteristics of DCO\nprogenitors that are likely or unlikely to form CBDs. We find that CBD\nformation is most common in BH-BH binaries and NS-NS binaries that are expected\nto merge within Hubble time. Furthermore, we find that the interaction of the\nCBD with the core - NS/BH system at the termination of the CEE reduces the\nexpected rate of DCO mergers, regardless of whether these binaries tighten or\nexpand due to this interaction. If the binary system loses angular momentum to\nthe CBD, it may produce a luminous transient due to a merger between the NS/BH\nand the core of the giant rather than gravitational wave sources. Thus,\naccounting for post-CEE CBD formation and its interaction with the binary\nsystem in population synthesis studies is significant for obtaining reliable\npredictions of the gravitational wave event rates expected by current\ndetectors.",
    "pdf_url": "http://arxiv.org/pdf/2411.15652v1",
    "published": "2024-11-23T21:11:20+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15651v1",
    "title": "Model Predictive Trees: Sample-Efficient Receding Horizon Planning with Reusable Tree Search",
    "authors": [
      "John Lathrop",
      "Benjamin Rivi`ere",
      "Jedidiah Alindogan",
      "Soon-Jo Chung"
    ],
    "abstract": "We present Model Predictive Trees (MPT), a receding horizon tree search\nalgorithm that improves its performance by reusing information efficiently.\nWhereas existing solvers reuse only the highest-quality trajectory from the\nprevious iteration as a \"hotstart\", our method reuses the entire optimal\nsubtree, enabling the search to be simultaneously guided away from the\nlow-quality areas and towards the high-quality areas. We characterize the\nrestrictions on tree reuse by analyzing the induced tracking error under\ntime-varying dynamics, revealing a tradeoff between the search depth and the\ntimescale of the changing dynamics. In numerical studies, our algorithm\noutperforms state-of-the-art sampling-based cross-entropy methods with\nhotstarting. We demonstrate our planner on an autonomous vehicle testbed\nperforming a nonprehensile manipulation task: pushing a target object through\nan obstacle field. Code associated with this work will be made available at\nhttps://github.com/jplathrop/mpt.",
    "pdf_url": "http://arxiv.org/pdf/2411.15651v1",
    "published": "2024-11-23T21:06:26+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2411.15650v1",
    "title": "Beryllium: The smoking gun of a rejuvenated star",
    "authors": [
      "Anne Rathsam",
      "Jorge Mel√©ndez",
      "Amanda I. Karakas"
    ],
    "abstract": "Context. The chemistry and Galactic velocity components of the star HD 65907\nsuggest that despite its young isochronal age of $\\sim$5 Gyr, it is in fact a\nmerger of two old Population II stars. Its low Li abundance is also consistent\nwith a mass accretion episode. Aims. We determine Li and Be abundances for this\nstar and evaluate its radial velocity time series, activity cycle, and spectral\nenergy distribution in search of clues regarding the origin of this enigmatic\nstar. Methods. Li and Be abundances were determined via spectral synthesis of\ntheir resonance lines using HARPS and UVES spectra, respectively. HARPS data\nwere also used to study variations in the star's radial velocity and activity\nlevels. Photometric data were adopted to evaluate the stellar spectral energy\ndistribution. Results. HD 65908 is severely Li- and Be-depleted. Its radial\nvelocity is nearly constant ($\\sigma =$ 2 m/s), with a small modulation likely\nassociated with stellar activity, and the star shows no further signs of an\nundetected close companion. The excess infrared emission is consistent with a\n30 K blackbody, which is interpreted as a debris disk surrounding the star. The\npost-merger mass, rotation rate, and evolution of this star are discussed.\nConclusions. The low Li and Be abundances, in addition to the lack of evidence\nfor a companion, are strong pieces of evidence in favor of the stellar merger\nscenario. In this context, Be can be used to confirm other blue stragglers\namong field solar-type stars, as proposed in the literature.",
    "pdf_url": "http://arxiv.org/pdf/2411.15650v1",
    "published": "2024-11-23T21:04:33+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15649v1",
    "title": "3-uniform monotone paths and multicolor Ramsey numbers",
    "authors": [
      "Andrew Suk",
      "Ji Zeng"
    ],
    "abstract": "The monotone path $P_{n+2}$ is an ordered 3-uniform hypergraph whose vertex\nset has size $n+2$ and edge set consists of all consecutive triples. In this\nnote, we consider the collection $\\mathcal{J}_n$ of ordered 3-uniform\nhypergraphs named monotone paths with $n$ jumps, and we prove the following\nrelation \\begin{equation*} r(3;n) \\leq R(P_{n+2},\\mathcal{J}_n) \\leq 4^n \\cdot\nr(3;n), \\end{equation*} where $r(3;n)$ is the multicolor Ramsey number for\ntriangles and $R(P_{n+2},\\mathcal{J}_n)$ is the hypergraph Ramsey number for\n$P_{n+2}$ versus any member of $\\mathcal{J}_n$. In particular, whether $r(3;n)$\nis exponential, which is a very old problem of Erd\\H{o}s, is equivalent to\nwhether $R(P_{n+2},\\mathcal{J}_n)$ is exponential.",
    "pdf_url": "http://arxiv.org/pdf/2411.15649v1",
    "published": "2024-11-23T20:49:06+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2411.16746v4",
    "title": "LoBAM: LoRA-Based Backdoor Attack on Model Merging",
    "authors": [
      "Ming Yin",
      "Jingyang Zhang",
      "Jingwei Sun",
      "Minghong Fang",
      "Hai Li",
      "Yiran Chen"
    ],
    "abstract": "Model merging is an emerging technique that integrates multiple models\nfine-tuned on different tasks to create a versatile model that excels in\nmultiple domains. This scheme, in the meantime, may open up backdoor attack\nopportunities where one single malicious model can jeopardize the integrity of\nthe merged model. Existing works try to demonstrate the risk of such attacks by\nassuming substantial computational resources, focusing on cases where the\nattacker can fully fine-tune the pre-trained model. Such an assumption,\nhowever, may not be feasible given the increasing size of machine learning\nmodels. In practice where resources are limited and the attacker can only\nemploy techniques like Low-Rank Adaptation (LoRA) to produce the malicious\nmodel, it remains unclear whether the attack can still work and pose threats.\nIn this work, we first identify that the attack efficacy is significantly\ndiminished when using LoRA for fine-tuning. Then, we propose LoBAM, a method\nthat yields high attack success rate with minimal training resources. The key\nidea of LoBAM is to amplify the malicious weights in an intelligent way that\neffectively enhances the attack efficacy. We demonstrate that our design can\nlead to improved attack success rate through extensive empirical experiments\nacross various model merging scenarios. Moreover, we show that our method is\nhighly stealthy and is difficult to detect and defend against.",
    "pdf_url": "http://arxiv.org/pdf/2411.16746v4",
    "published": "2024-11-23T20:41:24+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15648v2",
    "title": "Sample- and Parameter-Efficient Auto-Regressive Image Models",
    "authors": [
      "Elad Amrani",
      "Leonid Karlinsky",
      "Alex Bronstein"
    ],
    "abstract": "We introduce XTRA, a vision model pre-trained with a novel auto-regressive\nobjective that significantly enhances both sample and parameter efficiency\ncompared to previous auto-regressive image models. Unlike contrastive or masked\nimage modeling methods, which have not been demonstrated as having consistent\nscaling behavior on unbalanced internet data, auto-regressive vision models\nexhibit scalable and promising performance as model and dataset size increase.\nIn contrast to standard auto-regressive models, XTRA employs a Block Causal\nMask, where each Block represents k $\\times$ k tokens rather than relying on a\nstandard causal mask. By reconstructing pixel values block by block, XTRA\ncaptures higher-level structural patterns over larger image regions. Predicting\non blocks allows the model to learn relationships across broader areas of\npixels, enabling more abstract and semantically meaningful representations than\ntraditional next-token prediction. This simple modification yields two key\nresults. First, XTRA is sample-efficient. Despite being trained on 152$\\times$\nfewer samples (13.1M vs. 2B), XTRA ViT-H/14 surpasses the top-1 average\naccuracy of the previous state-of-the-art auto-regressive model across 15\ndiverse image recognition benchmarks. Second, XTRA is parameter-efficient.\nCompared to auto-regressive models trained on ImageNet-1k, XTRA ViT-B/16\noutperforms in linear and attentive probing tasks, using 7-16$\\times$ fewer\nparameters (85M vs. 1.36B/0.63B).",
    "pdf_url": "http://arxiv.org/pdf/2411.15648v2",
    "published": "2024-11-23T20:40:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15647v1",
    "title": "Circuit design in biology and machine learning. II. Anomaly detection",
    "authors": [
      "Steven A. Frank"
    ],
    "abstract": "Anomaly detection is a well-established field in machine learning,\nidentifying observations that deviate from typical patterns. The principles of\nanomaly detection could enhance our understanding of how biological systems\nrecognize and respond to atypical environmental inputs. However, this approach\nhas received limited attention in analyses of cellular and physiological\ncircuits. This study builds on machine learning techniques -- such as\ndimensionality reduction, boosted decision trees, and anomaly classification --\nto develop a conceptual framework for biological circuits. One problem is that\nmachine learning circuits tend to be unrealistically large for use by cellular\nand physiological systems. I therefore focus on minimal circuits inspired by\nmachine learning concepts, reduced to cellular scale. Through illustrative\nmodels, I demonstrate that small circuits can provide useful classification of\nanomalies. The analysis also shows how principles from machine learning -- such\nas temporal and atemporal anomaly detection, multivariate signal integration,\nand hierarchical decision-making cascades -- can inform hypotheses about the\ndesign and evolution of cellular circuits. This interdisciplinary approach\nenhances our understanding of cellular circuits and highlights the universal\nnature of computational strategies across biological and artificial systems.",
    "pdf_url": "http://arxiv.org/pdf/2411.15647v1",
    "published": "2024-11-23T20:36:57+00:00",
    "categories": [
      "q-bio.PE",
      "cs.LG"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2411.15646v1",
    "title": "On the Existence of Long-Period Decayless Oscillations in Short Active Region Loops",
    "authors": [
      "Arpit Kumar Shrivastav",
      "Vaibhav Pant",
      "Rohan Kumar",
      "David Berghmans",
      "Tom Van Doorsselaere",
      "Dipankar Banerjee",
      "Elena Petrova",
      "Daye Lim"
    ],
    "abstract": "Decayless kink oscillations, characterized by their lack of decay in\namplitude, have been detected in coronal loops of varying scales in active\nregions, quiet Sun and coronal holes. Short-period (< 50 s) decayless\noscillations have been detected in short loops (< 50 Mm) within active regions.\nNevertheless, long-period decayless oscillations in these loops remain\nrelatively unexplored and crucial for understanding the wave modes and\nexcitation mechanisms of decayless oscillations. We present the statistical\nanalysis of decayless oscillations from two active regions observed by the\nExtreme Ultraviolet Imager (EUI) onboard Solar Orbiter. The average loop length\nand period of the detected oscillations are 19 Mm and 151 seconds,\nrespectively. We find 82 long-period and 23 short-period oscillations in these\nloops. We do not obtain a significant correlation between loop length and\nperiod. We discuss the possibility of different wave modes in short loops,\nalthough standing waves can not be excluded from possible wave modes.\nFurthermore, a different branch exists for active region short loops in the\nloop length vs period relation, similar to decayless waves in short loops in\nquiet Sun and coronal holes. The magnetic fields derived from MHD seismology,\nbased on standing kink modes, show lower values for multiple oscillations\ncompared to previous estimates for long loops in active regions. Additionally,\nthe comparison of period distributions in short loops across different coronal\nregions indicates that different excitation mechanisms may trigger short-period\nkink oscillations in active regions compared to the quiet Sun and coronal\nholes.",
    "pdf_url": "http://arxiv.org/pdf/2411.15646v1",
    "published": "2024-11-23T20:36:24+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15645v2",
    "title": "MC-NEST: Enhancing Mathematical Reasoning in Large Language Models leveraging a Monte Carlo Self-Refine Tree",
    "authors": [
      "Gollam Rabby",
      "Farhana Keya",
      "S√∂ren Auer"
    ],
    "abstract": "Mathematical reasoning presents significant challenges for large language\nmodels (LLMs). To enhance their capabilities, we propose Monte Carlo\nSelf-Refine Tree (MC-NEST), an extension of Monte Carlo Tree Search that\nintegrates LLM-based self-refinement and self-evaluation for improved\ndecision-making in complex reasoning tasks. MC-NEST balances exploration and\nexploitation using Upper Confidence Bound (UCT) scores combined with diverse\nselection policies. Through iterative critique and refinement, LLMs learn to\nreason more strategically. Empirical results demonstrate that MC-NEST with an\nimportance sampling policy substantially improves GPT-4o's performance,\nachieving state-of-the-art pass@1 scores on Olympiad-level benchmarks.\nSpecifically, MC-NEST attains a pass@1 of 38.6 on AIME and 12.6 on MathOdyssey.\nThe solution quality for MC-NEST using GPT-4o and Phi-3-mini reaches 84.0\\% and\n82.08\\%, respectively, indicating robust consistency across different LLMs.\nMC-NEST performs strongly across Algebra, Geometry, and Number Theory,\nbenefiting from its ability to handle abstraction, logical deduction, and\nmulti-step reasoning -- core skills in mathematical problem solving.",
    "pdf_url": "http://arxiv.org/pdf/2411.15645v2",
    "published": "2024-11-23T20:31:58+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.16745v1",
    "title": "On quasi-convex smooth optimization problems by a comparison oracle",
    "authors": [
      "A. V. Gasnikov",
      "M. S. Alkousa",
      "A. V. Lobanov",
      "Y. V. Dorn",
      "F. S. Stonyakin",
      "I. A. Kuruzov",
      "S. R. Singh"
    ],
    "abstract": "Frequently, when dealing with many machine learning models, optimization\nproblems appear to be challenging due to a limited understanding of the\nconstructions and characterizations of the objective functions in these\nproblems. Therefore, major complications arise when dealing with first-order\nalgorithms, in which gradient computations are challenging or even impossible\nin various scenarios. For this reason, we resort to derivative-free methods\n(zeroth-order methods). This paper is devoted to an approach to minimizing\nquasi-convex functions using a recently proposed comparison oracle only. This\noracle compares function values at two points and tells which is larger, thus\nby the proposed approach, the comparisons are all we need to solve the\noptimization problem under consideration. The proposed algorithm to solve the\nconsidered problem is based on the technique of comparison-based gradient\ndirection estimation and the comparison-based approximation normalized gradient\ndescent. The normalized gradient descent algorithm is an adaptation of gradient\ndescent, which updates according to the direction of the gradients, rather than\nthe gradients themselves. We proved the convergence rate of the proposed\nalgorithm when the objective function is smooth and strictly quasi-convex in\n$\\mathbb{R}^n$, this algorithm needs $\\mathcal{O}\\left( \\left(n\nD^2/\\varepsilon^2 \\right) \\log\\left(n D / \\varepsilon\\right)\\right)$ comparison\nqueries to find an $\\varepsilon$-approximate of the optimal solution, where $D$\nis an upper bound of the distance between all generated iteration points and an\noptimal solution.",
    "pdf_url": "http://arxiv.org/pdf/2411.16745v1",
    "published": "2024-11-23T20:24:56+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15644v2",
    "title": "Triple Evolution Pathways to Black Hole Low-Mass X-ray Binaries: Insights from V404 Cygni",
    "authors": [
      "Cheyanne Shariat",
      "Smadar Naoz",
      "Kareem El-Badry",
      "Kyle Akira Rocha",
      "Vicky Kalogera",
      "Alexander P. Stephan",
      "Kevin B. Burdge",
      "Isabel Angelo"
    ],
    "abstract": "A recent discovery shows that V404 Cygni, a prototypical black hole low-mass\nX-ray binary (BH-LMXB) is a hierarchical triple: the BH and donor star are\norbited by a $1.2$ M$_{\\odot}$ tertiary at a distance of at least $3500$ au.\nMotivated by this system, we evolve a grid of $\\sim50,000$ triple star systems,\nspanning a broad range of initial orbits. Our calculations employ {\\tt MESA}\nstellar evolution models, using {\\tt POSYDON}, and self-consistently track the\neffects of eccentric Kozai-Lidov (EKL) oscillations, mass loss, tides, and BH\nnatal kicks. In our simulations, the progenitors of V404 Cygni-like systems\nhave initial outer separations of $1000 - 10000$ au and inner separations of\n$\\sim100$ au, such that they avoid Roche lobe overflow most of the time. Later\non, EKL oscillations drive the inner binary to high eccentricities until tides\nshrink the orbit and mass transfer begins. Notably, such systems only form in\nsimulations with very weak black hole natal kicks ($\\lesssim 5\\,{\\rm\nkm\\,s^{-1}}$) because stronger kicks unbind the tertiaries. Our simulations\nalso predict a population of BH-LMXB triples that form via the classical\ncommon-envelope channel, when the BH progenitor does overflow its Roche lobe.\nThe formation rate for this channel is also higher in triples than in isolated\nbinaries because early EKL oscillations cause inner binaries with a wider range\nof initial separations to enter and survive a common envelope. Our calculations\ndemonstrate that at least some stellar BHs form with extremely weak kicks, and\nthat triple evolution is a significant formation channel for BH-LMXBs.",
    "pdf_url": "http://arxiv.org/pdf/2411.15644v2",
    "published": "2024-11-23T20:18:20+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15643v2",
    "title": "Safe PDE Boundary Control with Neural Operators",
    "authors": [
      "Hanjiang Hu",
      "Changliu Liu"
    ],
    "abstract": "The physical world dynamics are generally governed by underlying partial\ndifferential equations (PDEs) with unknown analytical forms in science and\nengineering problems. Neural network based data-driven approaches have been\nheavily studied in simulating and solving PDE problems in recent years, but it\nis still challenging to move forward from understanding to controlling the\nunknown PDE dynamics. PDE boundary control instantiates a simplified but\nimportant problem by only focusing on PDE boundary conditions as the control\ninput and output. However, current model-free PDE controllers cannot ensure the\nboundary output satisfies some given user-specified safety constraint. To this\nend, we propose a safety filtering framework to guarantee the boundary output\nstays within the safe set for current model-free controllers. Specifically, we\nfirst introduce a neural boundary control barrier function (BCBF) to ensure the\nfeasibility of the trajectory-wise constraint satisfaction of boundary output.\nBased on the neural operator modeling the transfer function from boundary\ncontrol input to output trajectories, we show that the change in the BCBF\ndepends linearly on the change in input boundary, so quadratic\nprogramming-based safety filtering can be done for pre-trained model-free\ncontrollers. Extensive experiments under challenging hyperbolic, parabolic and\nNavier-Stokes PDE dynamics environments validate the plug-and-play\neffectiveness of the proposed method by achieving better general performance\nand boundary constraint satisfaction compared to the vanilla and constrained\nmodel-free controller baselines. The code is available at\nhttps://github.com/intelligent-control-lab/safe-pde-control.",
    "pdf_url": "http://arxiv.org/pdf/2411.15643v2",
    "published": "2024-11-23T20:15:51+00:00",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.NE",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2411.15642v1",
    "title": "Central derivations of low-dimensional Zinbiel algebras",
    "authors": [
      "Basdouri Imed",
      "Jean Lerbet",
      "Bouzid Mosbahi"
    ],
    "abstract": "The study of central derivations in low-dimensional algebraic structures is a\ncrucial area of research in mathematics, with applications in understanding the\ninternal symmetries and deformations of these structures. In this article, we\ninvestigate the central derivations of complex Zinbiel algebras of dimension\n$\\leq 4$. Key properties of the central derivation algebras are presented,\nincluding their structures and dimensions. The results are summarized in a\ntabular format, providing a clear classification of decomposable and\nindecomposable centroids based on these derivations. Specifically, we show that\nthe centroid of two-dimensional Zinbiel algebras is indecomposable, while in\nthree-dimensional Zinbiel algebras, centroids such as $\\A_3^3$, $\\A_4^3$,\n$\\A_6^3$, and $\\A_7^3$ are decomposable. For four-dimensional Zinbiel algebras,\ncentroids including $\\A_1^4$, $\\A_3^4$, $\\A_5^4$, $\\A_9^4$, $\\A_{10}^4$,\n$\\A_{11}^4$, and $\\A_{16}^4$ are decomposable. Furthermore, the dimensions of\ncentral derivation algebras vary across different dimensions: two-dimensional\nZinbiel algebras have central derivation dimensions of one, while in\nthree-dimensional and four-dimensional cases, these dimensions range from zero\nto nine.",
    "pdf_url": "http://arxiv.org/pdf/2411.15642v1",
    "published": "2024-11-23T20:06:57+00:00",
    "categories": [
      "math.RA"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2411.16744v1",
    "title": "From Exponential to Polynomial Complexity: Efficient Permutation Counting with Subword Constraints",
    "authors": [
      "Martin Mathew",
      "Javier Noda"
    ],
    "abstract": "Counting distinct permutations with replacement, especially when involving\nmultiple subwords, is a longstanding challenge in combinatorial analysis, with\ncritical applications in cryptography, bioinformatics, and statistical\nmodeling. This paper introduces a novel framework that presents closed-form\nformulas for calculating distinct permutations with replacement, fundamentally\nreducing the time complexity from exponential to linear relative to the\nsequence length for single-subword calculations. We then extend our\nfoundational formula to handle multiple subwords through the development of an\nadditional formula. Unlike traditional methods relying on brute-force\nenumeration or recursive algorithms, our approach leverages novel combinatorial\nconstructs and advanced mathematical techniques to achieve unprecedented\nefficiency. This comprehensive advancement in reducing computational complexity\nnot only simplifies permutation counting but also establishes a new benchmark\nfor scalability and versatility. We also demonstrate the practical utility of\nour formulas through diverse applications, including the simultaneous\nidentification of multiple genetic motifs in DNA sequences and complex pattern\nanalysis in cryptographic systems, using a computer program that runs the\nproposed formulae.",
    "pdf_url": "http://arxiv.org/pdf/2411.16744v1",
    "published": "2024-11-23T19:52:11+00:00",
    "categories": [
      "cs.CR",
      "q-bio.GN"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15641v2",
    "title": "Theory of internal conversion of the thorium-229 nuclear isomer in solid-state hosts",
    "authors": [
      "H. W. T. Morgan",
      "H. B. Tran Tan",
      "R. Elwell",
      "A. N. Alexandrova",
      "Eric R. Hudson",
      "Andrei Derevianko"
    ],
    "abstract": "Laser excitation of thorium-229 nuclei in doped wide bandgap crystals has\nbeen demonstrated recently, opening the possibility of developing ultrastable\nsolid-state clocks and sensitive searches for new physics. We develop a\nquantitative theory of the internal conversion of isomeric thorium-229 in\nsolid-state hosts. The internal conversion of the isomer proceeds by resonantly\nexciting a valence band electron to a defect state, accompanied by multi-phonon\nemission. We demonstrate that, if the process is energetically allowed, it\ngenerally quenches the isomer on timescales much faster than the isomer's\nradiative lifetime, despite thorium being in the +4 charge state in the valence\nband.",
    "pdf_url": "http://arxiv.org/pdf/2411.15641v2",
    "published": "2024-11-23T19:47:22+00:00",
    "categories": [
      "physics.atom-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15640v3",
    "title": "AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset",
    "authors": [
      "Tobi Olatunji",
      "Charles Nimo",
      "Abraham Owodunni",
      "Tassallah Abdullahi",
      "Emmanuel Ayodele",
      "Mardhiyah Sanni",
      "Chinemelu Aka",
      "Folafunmi Omofoye",
      "Foutse Yuehgoh",
      "Timothy Faniran",
      "Bonaventure F. P. Dossou",
      "Moshood Yekini",
      "Jonas Kemp",
      "Katherine Heller",
      "Jude Chidubem Omeke",
      "Chidi Asuzu MD",
      "Naome A. Etori",
      "Aim√©rou Ndiaye",
      "Ifeoma Okoh",
      "Evans Doe Ocansey",
      "Wendy Kinara",
      "Michael Best",
      "Irfan Essa",
      "Stephen Edward Moore",
      "Chris Fourie",
      "Mercy Nyamewaa Asiedu"
    ],
    "abstract": "Recent advancements in large language model(LLM) performance on medical\nmultiple choice question (MCQ) benchmarks have stimulated interest from\nhealthcare providers and patients globally. Particularly in low-and\nmiddle-income countries (LMICs) facing acute physician shortages and lack of\nspecialists, LLMs offer a potentially scalable pathway to enhance healthcare\naccess and reduce costs. However, their effectiveness in the Global South,\nespecially across the African continent, remains to be established. In this\nwork, we introduce AfriMed-QA, the first large scale Pan-African English\nmulti-specialty medical Question-Answering (QA) dataset, 15,000 questions (open\nand closed-ended) sourced from over 60 medical schools across 16 countries,\ncovering 32 medical specialties. We further evaluate 30 LLMs across multiple\naxes including correctness and demographic bias. Our findings show significant\nperformance variation across specialties and geographies, MCQ performance\nclearly lags USMLE (MedQA). We find that biomedical LLMs underperform general\nmodels and smaller edge-friendly LLMs struggle to achieve a passing score.\nInterestingly, human evaluations show a consistent consumer preference for LLM\nanswers and explanations when compared with clinician answers.",
    "pdf_url": "http://arxiv.org/pdf/2411.15640v3",
    "published": "2024-11-23T19:43:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.16743v1",
    "title": "Accelerated Bregman gradient methods for relatively smooth and relatively Lipschitz continuous minimization problems",
    "authors": [
      "O. S. Savchuk",
      "M. S. Alkousa",
      "A. S. Shushko",
      "A. A. Vyguzov",
      "F. S. Stonyakin",
      "D. A. Pasechnyuk",
      "A. V. Gasnikov"
    ],
    "abstract": "In this paper, we propose some accelerated methods for solving optimization\nproblems under the condition of relatively smooth and relatively Lipschitz\ncontinuous functions with an inexact oracle. We consider the problem of\nminimizing the convex differentiable and relatively smooth function concerning\na reference convex function. The first proposed method is based on a similar\ntriangles method with an inexact oracle, which uses a special triangular\nscaling property for the used Bregman divergence. The other proposed methods\nare non-adaptive and adaptive (tuning to the relative smoothness parameter)\naccelerated Bregman proximal gradient methods with an inexact oracle. These\nmethods are universal in the sense that they are applicable not only to\nrelatively smooth but also to relatively Lipschitz continuous optimization\nproblems. We also introduced an adaptive intermediate Bregman method which\ninterpolates between slower but more robust algorithms non-accelerated and\nfaster, but less robust accelerated algorithms. We conclude the paper with the\nresults of numerical experiments demonstrating the advantages of the proposed\nalgorithms for the Poisson inverse problem.",
    "pdf_url": "http://arxiv.org/pdf/2411.16743v1",
    "published": "2024-11-23T19:42:23+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2412.06801v1",
    "title": "Dual-Axis Beam-Steering OPA with purely Passive Phase Shifters",
    "authors": [
      "Venus Kakdarvishi",
      "Bowen Yu",
      "Yasha Yi"
    ],
    "abstract": "In this work, we present a multi-layer optical phased array (OPA) designed\nfor dual-axis beam steering on a silicon (Si) platform, utilizing only\nwavelength tuning. Our design eliminates the need for grating couplers,\ncommonly required for dual-axis beam steering, thereby reducing energy losses\ndue to substrate leakage. It also features the unique capability of achieving a\npositive or negative phase slope profile. This three-dimensional architecture\nenhances output efficiency by emitting light from the device edge, providing\ngreater flexibility and improved performance in beam steering. This approach\nopens up new possibilities for on-chip photonic systems, enabling faster, more\naccurate, and broader beam steering range.",
    "pdf_url": "http://arxiv.org/pdf/2412.06801v1",
    "published": "2024-11-23T19:42:12+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2411.15639v1",
    "title": "Ordering groups and the Identity Problem",
    "authors": [
      "Corentin Bodart",
      "Laura Ciobanu",
      "George Metcalfe"
    ],
    "abstract": "In this paper, the Identity Problem for certain groups, which asks if the\nsubsemigroup generated by a given finite set of elements contains the identity\nelement, is related to problems regarding ordered groups. Notably, the Identity\nProblem for a torsion-free nilpotent group corresponds to the problem asking if\na given finite set of elements extends to the positive cone of a left-order on\nthe group, and thereby also to the Word Problem for a related lattice-ordered\ngroup.\n  A new (independent) proof is given showing that the Identity and Subgroup\nProblems are decidable for every finitely presented nilpotent group,\nestablishing also the decidability of the Word Problem for a family of\nlattice-ordered groups. A related problem, the Fixed-Target Submonoid\nMembership Problem, is shown to be undecidable in nilpotent groups.\n  Decidability of the Normal Identity Problem (with `subsemigroup' replaced by\n`normal subsemigroup') for free nilpotent groups is established using the\n(known) decidability of the Word Problem for certain lattice-ordered groups.\nConnections between orderability and the Identity Problem for a class of\ntorsion-free metabelian groups are also explored.",
    "pdf_url": "http://arxiv.org/pdf/2411.15639v1",
    "published": "2024-11-23T19:37:44+00:00",
    "categories": [
      "math.GR",
      "cs.CC",
      "cs.DM"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15638v2",
    "title": "Learning state and proposal dynamics in state-space models using differentiable particle filters and neural networks",
    "authors": [
      "Benjamin Cox",
      "Santiago Segarra",
      "Victor Elvira"
    ],
    "abstract": "State-space models are a popular statistical framework for analysing\nsequential data. Within this framework, particle filters are often used to\nperform inference on non-linear state-space models. We introduce a new method,\nStateMixNN, that uses a pair of neural networks to learn the proposal\ndistribution and transition distribution of a particle filter. Both\ndistributions are approximated using multivariate Gaussian mixtures. The\ncomponent means and covariances of these mixtures are learnt as outputs of\nlearned functions. Our method is trained targeting the log-likelihood, thereby\nrequiring only the observation series, and combines the interpretability of\nstate-space models with the flexibility and approximation power of artificial\nneural networks. The proposed method significantly improves recovery of the\nhidden state in comparison with the state-of-the-art, showing greater\nimprovement in highly non-linear scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2411.15638v2",
    "published": "2024-11-23T19:30:56+00:00",
    "categories": [
      "cs.LG",
      "stat.CO",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15637v3",
    "title": "GraphGrad: Efficient Estimation of Sparse Polynomial Representations for General State-Space Models",
    "authors": [
      "Benjamin Cox",
      "Emilie Chouzenoux",
      "Victor Elvira"
    ],
    "abstract": "State-space models (SSMs) are a powerful statistical tool for modelling\ntime-varying systems via a latent state. In these models, the latent state is\nnever directly observed. Instead, a sequence of observations related to the\nstate is available. The state-space model is defined by the state dynamics and\nthe observation model, both of which are described by parametric distributions.\nEstimation of parameters of these distributions is a very challenging, but\nessential, task for performing inference and prediction. Furthermore, it is\ntypical that not all states of the system interact. We can therefore encode the\ninteraction of the states via a graph, usually not fully connected. However,\nmost parameter estimation methods do not take advantage of this feature. In\nthis work, we propose GraphGrad, a fully automatic approach for obtaining\nsparse estimates of the state interactions of a non-linear state-space model\nvia a polynomial approximation. This novel methodology unveils the latent\nstructure of the data-generating process, allowing us to infer both the\nstructure and value of a rich and efficient parameterisation of a general\nstate-space model. Our method utilises a differentiable particle filter to\noptimise a Monte Carlo likelihood estimator. It also promotes sparsity in the\nestimated system through the use of suitable proximity updates, known to be\nmore efficient and stable than subgradient methods. As shown in our paper, a\nnumber of well-known dynamical systems can be accurately represented and\nrecovered by our method, providing basis for application to real-world\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2411.15637v3",
    "published": "2024-11-23T19:27:49+00:00",
    "categories": [
      "stat.CO"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2411.15636v2",
    "title": "Convergence of Complementable Operators",
    "authors": [
      "Sachin Manjunath Naik",
      "P. Sam Johnson"
    ],
    "abstract": "Complementable operators extend classical matrix decompositions, such as the\nSchur complement, to the setting of infinite-dimensional Hilbert spaces,\nthereby broadening their applicability in various mathematical and physical\ncontexts. This paper focuses on the convergence properties of complementable\noperators, investigating when the limit of sequence of complementable operators\nremains complementable. We also explore the convergence of sequences and series\nof powers of complementable operators, providing new insights into their\nconvergence behavior. Additionally, we examine the conditions under which the\nset of complementable operators is the subset of set of boundary points of the\nset of non-complementable operators with respect to the strong operator\ntopology. The paper further explores the topological structure of the subset of\ncomplementable operators, offering a characterization of its closed subsets.",
    "pdf_url": "http://arxiv.org/pdf/2411.15636v2",
    "published": "2024-11-23T19:27:31+00:00",
    "categories": [
      "math.FA",
      "47A08, 47A64, 47B65, 47A58"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2411.16742v1",
    "title": "Text-to-SQL Calibration: No Need to Ask -- Just Rescale Model Probabilities",
    "authors": [
      "Ashwin Ramachandran",
      "Sunita Sarawagi"
    ],
    "abstract": "Calibration is crucial as large language models (LLMs) are increasingly\ndeployed to convert natural language queries into SQL for commercial databases.\nIn this work, we investigate calibration techniques for assigning confidence to\ngenerated SQL queries. We show that a straightforward baseline -- deriving\nconfidence from the model's full-sequence probability -- outperforms recent\nmethods that rely on follow-up prompts for self-checking and confidence\nverbalization. Our comprehensive evaluation, conducted across two widely-used\nText-to-SQL benchmarks and multiple LLM architectures, provides valuable\ninsights into the effectiveness of various calibration strategies.",
    "pdf_url": "http://arxiv.org/pdf/2411.16742v1",
    "published": "2024-11-23T19:20:24+00:00",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2411.15635v1",
    "title": "Computing marginal eigenvalue distributions for the Gaussian and Laguerre orthogonal ensembles",
    "authors": [
      "Peter J. Forrester",
      "Santosh Kumar",
      "Bo-Jian Shen"
    ],
    "abstract": "The Gaussian and Laguerre orthogonal ensembles are fundamental to random\nmatrix theory, and the marginal eigenvalue distributions are basic observable\nquantities. Notwithstanding a long history, a formulation providing high\nprecision numerical evaluations for $N$ large enough to probe asymptotic\nregimes, has not been provided. An exception is for the largest eigenvalue,\nwhere there is a formalism due to Chiani which uses a combination of the\nPfaffian structure underlying the ensembles, and a recursive computation of the\nmatrix elements. We augment this strategy by introducing a generating function\nfor the conditioned gap probabilities. A finite Fourier series approach is then\nused to extract the sequence of marginal eigenvalue distributions as a linear\ncombination of Pfaffians, with the latter then evaluated using an efficient\nnumerical procedure available in the literature. Applications are given to\nillustrating various asymptotic formulas, local central limit theorems, and\ncentral limit theorems, as well as to probing finite size corrections. Further,\nour data indicates that the mean values of the marginal distributions interlace\nwith the zeros of the Hermite polynomial (Gaussian ensemble) and a Laguerre\npolynomial (Laguerre ensemble).",
    "pdf_url": "http://arxiv.org/pdf/2411.15635v1",
    "published": "2024-11-23T19:19:47+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15634v1",
    "title": "\"All that Glitters\": Approaches to Evaluations with Unreliable Model and Human Annotations",
    "authors": [
      "Michael Hardy"
    ],
    "abstract": "\"Gold\" and \"ground truth\" human-mediated labels have error. The effects of\nthis error can escape commonly reported metrics of label quality or obscure\nquestions of accuracy, bias, fairness, and usefulness during model evaluation.\nThis study demonstrates methods for answering such questions even in the\ncontext of very low reliabilities from expert humans. We analyze human labels,\nGPT model ratings, and transformer encoder model annotations describing the\nquality of classroom teaching, an important, expensive, and currently only\nhuman task. We answer the question of whether such a task can be automated\nusing two Large Language Model (LLM) architecture families--encoders and GPT\ndecoders, using novel approaches to evaluating label quality across six\ndimensions: Concordance, Confidence, Validity, Bias, Fairness, and Helpfulness.\nFirst, we demonstrate that using standard metrics in the presence of poor\nlabels can mask both label and model quality: the encoder family of models\nachieve state-of-the-art, even \"super-human\", results across all classroom\nannotation tasks. But not all these positive results remain after using more\nrigorous evaluation measures which reveal spurious correlations and nonrandom\nracial biases across models and humans. This study then expands these methods\nto estimate how model use would change to human label quality if models were\nused in a human-in-the-loop context, finding that the variance captured in GPT\nmodel labels would worsen reliabilities for humans influenced by these models.\nWe identify areas where some LLMs, within the generalizability of the current\ndata, could improve the quality of expensive human ratings of classroom\ninstruction.",
    "pdf_url": "http://arxiv.org/pdf/2411.15634v1",
    "published": "2024-11-23T19:18:08+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15633v4",
    "title": "Orthogonal Subspace Decomposition for Generalizable AI-Generated Image Detection",
    "authors": [
      "Zhiyuan Yan",
      "Jiangming Wang",
      "Peng Jin",
      "Ke-Yue Zhang",
      "Chengchun Liu",
      "Shen Chen",
      "Taiping Yao",
      "Shouhong Ding",
      "Baoyuan Wu",
      "Li Yuan"
    ],
    "abstract": "AI-generated images (AIGIs), such as natural or face images, have become\nincreasingly important yet challenging. In this paper, we start from a new\nperspective to excavate the reason behind the failure generalization in AIGI\ndetection, named the \\textit{asymmetry phenomenon}, where a naively trained\ndetector tends to favor overfitting to the limited and monotonous fake\npatterns, causing the feature space to become highly constrained and\nlow-ranked, which is proved seriously limiting the expressivity and\ngeneralization. One potential remedy is incorporating the pre-trained knowledge\nwithin the vision foundation models (higher-ranked) to expand the feature\nspace, alleviating the model's overfitting to fake. To this end, we employ\nSingular Value Decomposition (SVD) to decompose the original feature space into\n\\textit{two orthogonal subspaces}. By freezing the principal components and\nadapting only the remained components, we preserve the pre-trained knowledge\nwhile learning fake patterns. Compared to existing full-parameters and\nLoRA-based tuning methods, we explicitly ensure orthogonality, enabling the\nhigher rank of the whole feature space, effectively minimizing overfitting and\nenhancing generalization. We finally identify a crucial insight: our method\nimplicitly learns \\textit{a vital prior that fakes are actually derived from\nthe real}, indicating a hierarchical relationship rather than independence.\nModeling this prior, we believe, is essential for achieving superior\ngeneralization. Our codes are publicly available at\n\\href{https://github.com/YZY-stack/Effort-AIGI-Detection}{GitHub}.",
    "pdf_url": "http://arxiv.org/pdf/2411.15633v4",
    "published": "2024-11-23T19:10:32+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15632v1",
    "title": "Measurement-induced entanglement entropy of gravitational wave detections",
    "authors": [
      "Preston Jones",
      "Quentin G. Bailey",
      "Andri Gretarsson",
      "Edward Poon"
    ],
    "abstract": "Research on the projective measurement of gravitons increasingly supports\nDysons conclusions that the detection of single gravitons is not physically\npossible. It is therefore prudent to consider alternative signatures of\nnon-classicality in gravitational wave detections to determine if gravity is\nquantized. Coincident multiple detector operations make it possible to consider\nthe bipartite measurement-induced entanglement, in the detection process, as a\nsignature of non-classicality. By developing a model of measurement-induced\nentanglement, based on a fixed number of gravitons for the bipartite system, we\ndemonstrate that the entanglement entropy is on the order of a few percent of\nthe mean number of gravitons interacting with the detectors. The bipartite\nmeasurement-induced entanglement is part of the detection process, which avoids\nthe challenges associated with developing signatures of production-induced\nentanglement, due to the extremely low gravitational wave detector\nefficiencies. The calculation of normalized measurement-induced entanglement\nentropy demonstrates the potential of developing physically meaningful\nsignatures of non-classicality based on bipartite detections of gravitational\nradiation. This result is in stark contrast to the discouraging calculations\nbased on single-point detections.",
    "pdf_url": "http://arxiv.org/pdf/2411.15632v1",
    "published": "2024-11-23T19:03:21+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2411.15631v1",
    "title": "Understanding and Estimating the Execution Time of Quantum Programs",
    "authors": [
      "Ning Ma",
      "Heng Li"
    ],
    "abstract": "Due to the scarcity of quantum computing resources, researchers and\ndevelopers have very limited access to real quantum computers. Therefore,\njudicious planning and utilization of quantum computer runtime are essential to\nensure smooth execution and completion of projects. Accurate estimation of a\nquantum program's execution time is thus necessary to prevent unexpectedly\nexceeding the anticipated runtime or the maximum capacity of the quantum\ncomputers; it also allows quantum computing platforms to make precisely\ninformed provisioning and prioritization of quantum computing jobs.\n  In this paper, we first study the characteristics of quantum programs'\nruntime on simulators and real quantum computers. Then, we introduce an\ninnovative method that employs a graph transformer-based model, utilizing the\ngraph information and global information of quantum programs to estimate their\nexecution time. We selected a benchmark dataset comprising over 1510 quantum\nprograms, initially predicting their execution times on simulators, which\nyielded promising results with an R-squared value over 95%. Subsequently, for\nthe estimation of execution times on quantum computers, we applied active\nlearning to select 340 samples with a confidence level of 95% to build and\nevaluate our approach, achieving an average R-squared value exceeding 90%. Our\napproach can be integrated into quantum computing platforms to provide an\naccurate estimation of quantum execution time and be used as a reference for\nprioritizing quantum execution jobs.\n  In addition, our findings provide insights for quantum program developers to\noptimize their programs in terms of execution time consumption, for example, by\nprioritizing one-qubit gates over two-qubit gates.",
    "pdf_url": "http://arxiv.org/pdf/2411.15631v1",
    "published": "2024-11-23T19:02:10+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2411.15630v1",
    "title": "A 400Gbit Ethernet core enabling High Data Rate Streaming from FPGAs to Servers and GPUs in Radio Astronomy",
    "authors": [
      "Wei Liu",
      "Mitchell C. Burnett",
      "Dan Werthimer",
      "Jonathon Kocz"
    ],
    "abstract": "The increased bandwidth coupled with the large numbers of antennas of several\nnew radio telescope arrays has resulted in an exponential increase in the\namount of data that needs to be recorded and processed. In many cases, it is\nnecessary to process this data in real time, as the raw data volumes are too\nhigh to be recorded and stored. Due to the ability of graphics processing units\n(GPUs) to process data in parallel, GPUs are increasingly used for\ndata-intensive tasks. In most radio astronomy digital instrumentation (e.g.\ncorrelators for spectral imaging, beamforming, pulsar, fast radio burst and\nSETI searching), the processing power of modern GPUs is limited by the\ninput/output data rate, not by the GPU's computation ability. Techniques for\nstreaming ultra-high-rate data to GPUs, such as those described in this paper,\nreduce the number of GPUs and servers needed, and make significant reductions\nin the cost, power consumption, size, and complexity of GPU based radio\nastronomy backends. In this research, we developed and tested several different\ntechniques to stream data from network interface cards (NICs) to GPUs. We also\ndeveloped an open-source UDP/IPv4 400GbE wrapper for the AMD/Xilinx IP\ndemonstrating high-speed data stream transfer from a field programmable gate\narray (FPGA) to GPU.",
    "pdf_url": "http://arxiv.org/pdf/2411.15630v1",
    "published": "2024-11-23T18:54:19+00:00",
    "categories": [
      "astro-ph.IM",
      "cs.DC"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15629v1",
    "title": "Optimal Planning for Heterogeneous Smart Radio Environments",
    "authors": [
      "Reza Aghazadeh Ayoubi",
      "Eugenio Moro",
      "Marouan Mizmizi",
      "Dario Tagliaferri",
      "Ilario Filippini",
      "Umberto Spagnolini"
    ],
    "abstract": "Smart Radio Environment (SRE) is a central paradigms in 6G and beyond, where\nintegrating SRE components into the network planning process enables optimized\nperformance for high-frequency Radio Access Network (RAN). This paper presents\na comprehensive planning framework utilizing realistic urban scenarios and\nprecise channel models to analyze diverse SRE components, including\nReconfigurable Intelligent Surface (RIS), Network-Controlled Repeater (NCR),\nand advanced technologies like Simultaneous transmitting and reflecting RIS\n(STAR RIS) and trisectoral NCR (3SNCR). We propose two optimization methods,\nfull coverage minimum cost (FCMC) and maximum budget-constrained coverage\n(MBCC), that address key cost and coverage objectives by considering both\nphysical characteristics and scalable costs of each component, influenced by\nfactors such as NCR amplification gain and RIS dimensions. Extensive numerical\nresults demonstrate the significant impact of these models in enhancing network\nplanning efficiency for high-density urban environments.",
    "pdf_url": "http://arxiv.org/pdf/2411.15629v1",
    "published": "2024-11-23T18:51:06+00:00",
    "categories": [
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2411.15628v1",
    "title": "ACE: Action Concept Enhancement of Video-Language Models in Procedural Videos",
    "authors": [
      "Reza Ghoddoosian",
      "Nakul Agarwal",
      "Isht Dwivedi",
      "Behzad Darisuh"
    ],
    "abstract": "Vision-language models (VLMs) are capable of recognizing unseen actions.\nHowever, existing VLMs lack intrinsic understanding of procedural action\nconcepts. Hence, they overfit to fixed labels and are not invariant to unseen\naction synonyms. To address this, we propose a simple fine-tuning technique,\nAction Concept Enhancement (ACE), to improve the robustness and concept\nunderstanding of VLMs in procedural action classification. ACE continually\nincorporates augmented action synonyms and negatives in an auxiliary\nclassification loss by stochastically replacing fixed labels during training.\nThis creates new combinations of action labels over the course of fine-tuning\nand prevents overfitting to fixed action representations. We show the enhanced\nconcept understanding of our VLM, by visualizing the alignment of encoded\nembeddings of unseen action synonyms in the embedding space. Our experiments on\nthe ATA, IKEA and GTEA datasets demonstrate the efficacy of ACE in domains of\ncooking and assembly leading to significant improvements in zero-shot action\nclassification while maintaining competitive performance on seen actions.",
    "pdf_url": "http://arxiv.org/pdf/2411.15628v1",
    "published": "2024-11-23T18:49:49+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15627v2",
    "title": "Community detection for binary graphical models in high dimension",
    "authors": [
      "Julien Chevallier",
      "Guilherme Ost"
    ],
    "abstract": "Let $N$ components be partitioned into two communities, denoted ${\\cal P}_+$\nand ${\\cal P}_-$, possibly of different sizes. Assume that they are connected\nvia a directed and weighted Erd\\\"os-R\\'enyi random graph (DWER) with unknown\nparameter $ p \\in (0, 1).$ The weights assigned to the existing connections are\nof mean-field type, scaling as $N^{-1}$. At each time unit, we observe the\nstate of each component: either it sends some signal to its successors (in the\ndirected graph) or remains silent otherwise. In this paper, we show that it is\npossible to find the communities ${\\cal P}_+$ and ${\\cal P}_-$ based only on\nthe activity of the $N$ components observed over $T$ time units. More\nspecifically, we propose a simple algorithm for which the probability of {\\it\nexact recovery} converges to $1$ as long as $(N/T^{1/2})\\log(NT) \\to 0$, as $T$\nand $N$ diverge. Interestingly, this simple algorithm does not require any\nprior knowledge on the other model parameters (e.g. the edge probability $p$).\nThe key step in our analysis is to derive an asymptotic approximation of the\none unit time-lagged covariance matrix associated to the states of the $N$\ncomponents, as $N$ diverges. This asymptotic approximation relies on the study\nof the behavior of the solutions of a matrix equation of Stein type satisfied\nby the simultaneous (0-lagged) covariance matrix associated to the states of\nthe components. This study is challenging, specially because the simultaneous\ncovariance matrix is random since it depends on the underlying DWER random\ngraph.",
    "pdf_url": "http://arxiv.org/pdf/2411.15627v2",
    "published": "2024-11-23T18:45:16+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2411.15626v2",
    "title": "Aligning Generalisation Between Humans and Machines",
    "authors": [
      "Filip Ilievski",
      "Barbara Hammer",
      "Frank van Harmelen",
      "Benjamin Paassen",
      "Sascha Saralajew",
      "Ute Schmid",
      "Michael Biehl",
      "Marianna Bolognesi",
      "Xin Luna Dong",
      "Kiril Gashteovski",
      "Pascal Hitzler",
      "Giuseppe Marra",
      "Pasquale Minervini",
      "Martin Mundt",
      "Axel-Cyrille Ngonga Ngomo",
      "Alessandro Oltramari",
      "Gabriella Pasi",
      "Zeynep G. Saribatur",
      "Luciano Serafini",
      "John Shawe-Taylor",
      "Vered Shwartz",
      "Gabriella Skitalinskaya",
      "Clemens Stachl",
      "Gido M. van de Ven",
      "Thomas Villmann"
    ],
    "abstract": "Recent advances in AI -- including generative approaches -- have resulted in\ntechnology that can support humans in scientific discovery and forming\ndecisions, but may also disrupt democracies and target individuals. The\nresponsible use of AI and its participation in human-AI teams increasingly\nshows the need for AI alignment, that is, to make AI systems act according to\nour preferences. A crucial yet often overlooked aspect of these interactions is\nthe different ways in which humans and machines generalise. In cognitive\nscience, human generalisation commonly involves abstraction and concept\nlearning. In contrast, AI generalisation encompasses out-of-domain\ngeneralisation in machine learning, rule-based reasoning in symbolic AI, and\nabstraction in neurosymbolic AI. In this perspective paper, we combine insights\nfrom AI and cognitive science to identify key commonalities and differences\nacross three dimensions: notions of, methods for, and evaluation of\ngeneralisation. We map the different conceptualisations of generalisation in AI\nand cognitive science along these three dimensions and consider their role for\nalignment in human-AI teaming. This results in interdisciplinary challenges\nacross AI and cognitive science that must be tackled to provide a foundation\nfor effective and cognitively supported alignment in human-AI teaming\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2411.15626v2",
    "published": "2024-11-23T18:36:07+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2411.15625v1",
    "title": "Canonical Correlation Analysis: review",
    "authors": [
      "Anna Bykhovskaya",
      "Vadim Gorin"
    ],
    "abstract": "For over a century canonical correlations, variables, and related concepts\nhave been studied across various fields, with contributions dating back to\nJordan [1875] and Hotelling [1936]. This text surveys the evolution of\ncanonical correlation analysis, a fundamental statistical tool, beginning with\nits foundational theorems and progressing to recent developments and open\nresearch problems. Along the way we introduce and review methods, notions, and\nfundamental concepts from linear algebra, random matrix theory, and\nhigh-dimensional statistics, placing particular emphasis on rigorous\nmathematical treatment.\n  The survey is intended for technically proficient graduate students and other\nresearchers with an interest in this area. The content is organized into five\nchapters, supplemented by six sets of exercises found in Chapter 6. These\nexercises introduce additional material, reinforce key concepts, and serve to\nbridge ideas across chapters. We recommend the following sequence: first, solve\nProblem Set 0, then proceed with Chapter 1, solve Problem Set 1, and so on\nthrough the text.",
    "pdf_url": "http://arxiv.org/pdf/2411.15625v1",
    "published": "2024-11-23T18:34:26+00:00",
    "categories": [
      "stat.ME",
      "econ.EM",
      "math.PR",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2411.15624v1",
    "title": "Trans-Glasso: A Transfer Learning Approach to Precision Matrix Estimation",
    "authors": [
      "Boxin Zhao",
      "Cong Ma",
      "Mladen Kolar"
    ],
    "abstract": "Precision matrix estimation is essential in various fields, yet it is\nchallenging when samples for the target study are limited. Transfer learning\ncan enhance estimation accuracy by leveraging data from related source studies.\nWe propose Trans-Glasso, a two-step transfer learning method for precision\nmatrix estimation. First, we obtain initial estimators using a multi-task\nlearning objective that captures shared and unique features across studies.\nThen, we refine these estimators through differential network estimation to\nadjust for structural differences between the target and source precision\nmatrices. Under the assumption that most entries of the target precision matrix\nare shared with source matrices, we derive non-asymptotic error bounds and show\nthat Trans-Glasso achieves minimax optimality under certain conditions.\nExtensive simulations demonstrate Trans Glasso's superior performance compared\nto baseline methods, particularly in small-sample settings. We further validate\nTrans-Glasso in applications to gene networks across brain tissues and protein\nnetworks for various cancer subtypes, showcasing its effectiveness in\nbiological contexts. Additionally, we derive the minimax optimal rate for\ndifferential network estimation, representing the first such guarantee in this\narea.",
    "pdf_url": "http://arxiv.org/pdf/2411.15624v1",
    "published": "2024-11-23T18:30:56+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2412.16160v2",
    "title": "Online High-Frequency Trading Stock Forecasting with Automated Feature Clustering and Radial Basis Function Neural Networks",
    "authors": [
      "Adamantios Ntakaris",
      "Gbenga Ibikunle"
    ],
    "abstract": "This study presents an autonomous experimental machine learning protocol for\nhigh-frequency trading (HFT) stock price forecasting that involves a dual\ncompetitive feature importance mechanism and clustering via shallow neural\nnetwork topology for fast training. By incorporating the k-means algorithm into\nthe radial basis function neural network (RBFNN), the proposed method addresses\nthe challenges of manual clustering and the reliance on potentially\nuninformative features. More specifically, our approach involves a dual\ncompetitive mechanism for feature importance, combining the mean-decrease\nimpurity (MDI) method and a gradient descent (GD) based feature importance\nmechanism. This approach, tested on HFT Level 1 order book data for 20 S&P 500\nstocks, enhances the forecasting ability of the RBFNN regressor. Our findings\nsuggest that an autonomous approach to feature selection and clustering is\ncrucial, as each stock requires a different input feature space. Overall, by\nautomating the feature selection and clustering processes, we remove the need\nfor manual topological grid search and provide a more efficient way to predict\nLOB's mid-price.",
    "pdf_url": "http://arxiv.org/pdf/2412.16160v2",
    "published": "2024-11-23T18:30:04+00:00",
    "categories": [
      "q-fin.ST",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST"
  },
  {
    "id": "http://arxiv.org/abs/2411.15623v2",
    "title": "Multi-label Sequential Sentence Classification via Large Language Model",
    "authors": [
      "Mengfei Lan",
      "Lecheng Zheng",
      "Shufan Ming",
      "Halil Kilicoglu"
    ],
    "abstract": "Sequential sentence classification (SSC) in scientific publications is\ncrucial for supporting downstream tasks such as fine-grained information\nretrieval and extractive summarization. However, current SSC methods are\nconstrained by model size, sequence length, and single-label setting. To\naddress these limitations, this paper proposes LLM-SSC, a large language model\n(LLM)-based framework for both single- and multi-label SSC tasks. Unlike\nprevious approaches that employ small- or medium-sized language models, the\nproposed framework utilizes LLMs to generate SSC labels through designed\nprompts, which enhance task understanding by incorporating demonstrations and a\nquery to describe the prediction target. We also present a multi-label\ncontrastive learning loss with auto-weighting scheme, enabling the multi-label\nclassification task. To support our multi-label SSC analysis, we introduce and\nrelease a new dataset, biorc800, which mainly contains unstructured abstracts\nin the biomedical domain with manual annotations. Experiments demonstrate\nLLM-SSC's strong performance in SSC under both in-context learning and\ntask-specific tuning settings. We release biorc800 and our code at:\nhttps://github.com/ScienceNLP-Lab/LLM-SSC.",
    "pdf_url": "http://arxiv.org/pdf/2411.15623v2",
    "published": "2024-11-23T18:27:35+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.16741v3",
    "title": "On the Hidden Transient Interphase in Metal Anodes: Dynamic Precipitation Controls Electrochemical Interfaces in Batteries",
    "authors": [
      "Stephen T. Fuller",
      "J. -X. Kent Zheng"
    ],
    "abstract": "The Solid-Electrolyte Interphase, SEI, formed on a battery electrode has been\na central area of research for decades. This thin, complex layer profoundly\nimpacts the electrochemical deposition morphology and stability of the metal in\nbattery anodes. Departing from conventional approaches, we investigate metal\ndissolution, the reverse reaction of deposition, in battery environments using\na state-of-the-art electroanalytical system combining a rotating-disk electrode\nand in-operando visualization. Our key finding is the presence of a Transient\nSolid-Electrolyte Interphase, T-SEI, that forms during fast discharging at high\ndissolution rates. We attribute T-SEI formation to transient local\nsupersaturation and resultant electrolyte salt deposition. The T-SEI\nfundamentally alters the dissolution kinetics at the electrochemical interface,\nleading to a self-limiting morphological evolution and eventually yielding a\nflat, clean surface. Unlike a classical SEI formed due to electrolyte\ndecomposition, the T-SEI is fully relaxable upon removal of the enforced\ndissolution current. The formation of T-SEI, surprisingly, plays a critical\nrole in the subsequent electrodeposition. When the metal is redeposited on a\nfully relaxed T-SEI surface, the morphology is remarkably different from that\ndeposited on pristine or low-rate discharged metal electrodes. Electron\nbackscatter diffraction analysis suggests the deposition occurs via growth of\nthe original grains. This is in stark contrast to the isolated, particulate\nnuclei seen on standard metal electrodes without T-SEI formation. Our findings\nprovide important insights into the electrochemical kinetics at the\nmetal-electrolyte interface, particularly in concentrated or water-in-salt\nelectrolytes that are close to the salt saturation limit. The results suggest a\nnew dimension for electrochemical engineering in batteries.",
    "pdf_url": "http://arxiv.org/pdf/2411.16741v3",
    "published": "2024-11-23T18:24:20+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2411.15622v2",
    "title": "Distributionally Robust Safety Verification for Markov Decision Processes",
    "authors": [
      "Abhijit Mazumdar",
      "Yuting Hou",
      "Rafal Wisniewski"
    ],
    "abstract": "In this paper, we propose a distributionally robust safety verification\nmethod for Markov decision processes where only an ambiguous transition kernel\nis available instead of the precise transition kernel. We define the ambiguity\nset around the nominal distribution by considering a Wasserstein distance. To\nthis end, we introduce a robust safety function to characterize probabilistic\nsafety in the face of uncertain transition probability. First, we obtain an\nupper bound on the robust safety function in terms of a distributionally robust\nQ-function. Then, we present a convex program-based distributionally robust\nQ-iteration algorithm to compute the robust Q-function. By considering a\nnumerical example, we demonstrate our theoretical results.",
    "pdf_url": "http://arxiv.org/pdf/2411.15622v2",
    "published": "2024-11-23T18:18:06+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2411.15621v1",
    "title": "On the importance of local and global feature learning for automated measurable residual disease detection in flow cytometry data",
    "authors": [
      "Lisa Weijler",
      "Michael Reiter",
      "Pedro Hermosilla",
      "Margarita Maurer-Granofszky",
      "Michael Dworzak"
    ],
    "abstract": "This paper evaluates various deep learning methods for measurable residual\ndisease (MRD) detection in flow cytometry (FCM) data, addressing questions\nregarding the benefits of modeling long-range dependencies, methods of\nobtaining global information, and the importance of learning local features.\nBased on our findings, we propose two adaptations to the current\nstate-of-the-art (SOTA) model. Our contributions include an enhanced SOTA\nmodel, demonstrating superior performance on publicly available datasets and\nimproved generalization across laboratories, as well as valuable insights for\nthe FCM community, guiding future DL architecture designs for FCM data\nanalysis. The code is available at\n\\url{https://github.com/lisaweijler/flowNetworks}.",
    "pdf_url": "http://arxiv.org/pdf/2411.15621v1",
    "published": "2024-11-23T18:15:34+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.16740v3",
    "title": "Document Haystacks: Vision-Language Reasoning Over Piles of 1000+ Documents",
    "authors": [
      "Jun Chen",
      "Dannong Xu",
      "Junjie Fei",
      "Chun-Mei Feng",
      "Mohamed Elhoseiny"
    ],
    "abstract": "Large multimodal models (LMMs) have achieved impressive progress in\nvision-language understanding, yet they face limitations in real-world\napplications requiring complex reasoning over a large number of images.\nExisting benchmarks for multi-image question-answering are limited in scope,\neach question is paired with only up to 30 images, which does not fully capture\nthe demands of large-scale retrieval tasks encountered in the real-world\nusages. To reduce these gaps, we introduce two document haystack benchmarks,\ndubbed DocHaystack and InfoHaystack, designed to evaluate LMM performance on\nlarge-scale visual document retrieval and understanding. Additionally, we\npropose V-RAG, a novel, vision-centric retrieval-augmented generation (RAG)\nframework that leverages a suite of multimodal vision encoders, each optimized\nfor specific strengths, and a dedicated question-document relevance module.\nV-RAG sets a new standard, with a 9% and 11% improvement in Recall@1 on the\nchallenging DocHaystack-1000 and InfoHaystack-1000 benchmarks, respectively,\ncompared to the previous best baseline models. Additionally, integrating V-RAG\nwith LMMs enables them to efficiently operate across thousands of images,\nyielding significant improvements on our DocHaystack and InfoHaystack\nbenchmarks. Our code and datasets are available at\nhttps://github.com/Vision-CAIR/dochaystacks",
    "pdf_url": "http://arxiv.org/pdf/2411.16740v3",
    "published": "2024-11-23T18:14:42+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15620v1",
    "title": "Fine-Grained Open-Vocabulary Object Recognition via User-Guided Segmentation",
    "authors": [
      "Jinwoo Ahn",
      "Hyeokjoon Kwon",
      "Hwiyeon Yoo"
    ],
    "abstract": "Recent advent of vision-based foundation models has enabled efficient and\nhigh-quality object detection at ease. Despite the success of previous studies,\nobject detection models face limitations on capturing small components from\nholistic objects and taking user intention into account. To address these\nchallenges, we propose a novel foundation model-based detection method called\nFOCUS: Fine-grained Open-Vocabulary Object ReCognition via User-Guided\nSegmentation. FOCUS merges the capabilities of vision foundation models to\nautomate open-vocabulary object detection at flexible granularity and allow\nusers to directly guide the detection process via natural language. It not only\nexcels at identifying and locating granular constituent elements but also\nminimizes unnecessary user intervention yet grants them significant control.\nWith FOCUS, users can make explainable requests to actively guide the detection\nprocess in the intended direction. Our results show that FOCUS effectively\nenhances the detection capabilities of baseline models and shows consistent\nperformance across varying object types.",
    "pdf_url": "http://arxiv.org/pdf/2411.15620v1",
    "published": "2024-11-23T18:13:27+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15619v2",
    "title": "How parameter constraining can influence the mass accretion process of a Black Hole in the Generalized Rastall Gravity Theory ?",
    "authors": [
      "Puja Mukherjee",
      "Ujjal Debnath",
      "Himanshu Chaudhary",
      "G. Mustafa"
    ],
    "abstract": "Black holes, one of the greatest enigmas of our Universe, are challenging to\ndecipher. This work is dedicated to observing the changes in the mass of a\nnon-singular black hole with the evolution of the Universe in the generalized\nRastall gravity framework, considering the effects of parameter constraining.\nWe examine two recently developed dynamical dark-energy equation of state\nparameterization models:\nChaudhary-Bouali-Debnath-Roy-Mustafa-type~(CBDRM)~parameterization and\nChaudhary-Debnath-Mustafa-Maurya-Atamurotov-type~(CDMMA)~parameterization.\nStarting with the concept and fundamental equations of the generalized Rastall\ngravity theory, we introduce the two models along with their equations of\nstate, energy density equations, and corresponding Hubble parameter equations.\nWe then constrain the required parameters using Monte Carlo Markov chain (MCMC)\nanalyses to ensure the accuracy and reliability of our study. Next, we discuss\nthe non-singular black holes from the perspective of generalized Rastall\ngravity theory and some of their essential properties. Finally, we pursue the\nprimary goal of our work: analyzing the mass accretion process. We derive the\nmass equation for both models in terms of the redshift function, represent the\nresults graphically, and compare them with the standard $\\Lambda$CDM model of\nthe Universe. Our findings indicate that the accretion of both CBDRM~and~CDMMA\ndark energy parameterizations, considering constrained parameter values, leads\nto an increase in the mass of the black hole during the Universe's evolution\nwithin the generalized Rastall gravity theory, revealing the true nature of\ndark energy.",
    "pdf_url": "http://arxiv.org/pdf/2411.15619v2",
    "published": "2024-11-23T17:59:24+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2411.15618v1",
    "title": "Accelerated Hydration Site Localization and Thermodynamic Profiling",
    "authors": [
      "Florian B. Hinz",
      "Matthew R. Masters",
      "Julia N. Kieu",
      "Amr H. Mahmoud",
      "Markus A. Lill"
    ],
    "abstract": "Water plays a fundamental role in the structure and function of proteins and\nother biomolecules. The thermodynamic profile of water molecules surrounding a\nprotein are critical for ligand binding and recognition. Therefore, identifying\nthe location and thermodynamic behavior of relevant water molecules is\nimportant for generating and optimizing lead compounds for affinity and\nselectivity to a given target. Computational methods have been developed to\nidentify these hydration sites, but are largely limited to simplified models\nthat fail to capture multi-body interactions, or dynamics-based methods that\nrely on extensive sampling. Here we present a method for fast and accurate\nlocalization and thermodynamic profiling of hydration sites for protein\nstructures. The method is based on a geometric deep neural network trained on a\nlarge, novel dataset of explicit water molecular dynamics simulations. We\nconfirm the accuracy and robustness of our model on experimental data and\ndemonstrate it's utility on several case studies.",
    "pdf_url": "http://arxiv.org/pdf/2411.15618v1",
    "published": "2024-11-23T17:58:58+00:00",
    "categories": [
      "q-bio.BM",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15617v1",
    "title": "Non-Reciprocal Reconfigurable Intelligent Surfaces",
    "authors": [
      "Jiaqi Xu",
      "Haoyu Wang",
      "Rang Liu",
      "Josef A. Nossek",
      "A. Lee Swindlehurst"
    ],
    "abstract": "In contrast to conventional RIS, the scattering matrix of a non-reciprocal\nRIS (NR-RIS) is non-symmetric, leading to differences in the uplink and the\ndownlink components of NR-RIS cascaded channels. In this paper, a\nphysically-consistent device model is proposed in which an NR-RIS is composed\nof multiple groups of two-port elements inter-connected by non-reciprocal\ndevices. The resulting non-reciprocal scattering matrix is derived for various\ncases including two-element groups connected with isolators or gyrators, and\ngeneral three-element groups connected via circulators. Signal models are given\nfor NR-RIS operating in either reflecting-only or simultaneously transmitting\nand reflecting modes. The problem of NR-RIS design for non-reciprocal\nbeamsteering is formulated for three-element circulator implementations, and\nnumerical results confirm that non-reciprocal beamsteering can be achieved with\nminimal sidelobe power. We also show that our physically consistent NR-RIS\narchitecture is effective in implementing channel reciprocity attacks,\nachieving similar performance to that with idealized NR-RIS models.",
    "pdf_url": "http://arxiv.org/pdf/2411.15617v1",
    "published": "2024-11-23T17:43:30+00:00",
    "categories": [
      "eess.SP",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15616v1",
    "title": "A Scalable Approach to Covariate and Concept Drift Management via Adaptive Data Segmentation",
    "authors": [
      "Vennela Yarabolu",
      "Govind Waghmare",
      "Sonia Gupta",
      "Siddhartha Asthana"
    ],
    "abstract": "In many real-world applications, continuous machine learning (ML) systems are\ncrucial but prone to data drift, a phenomenon where discrepancies between\nhistorical training data and future test data lead to significant performance\ndegradation and operational inefficiencies. Traditional drift adaptation\nmethods typically update models using ensemble techniques, often discarding\ndrifted historical data, and focus primarily on either covariate drift or\nconcept drift. These methods face issues such as high resource demands,\ninability to manage all types of drifts effectively, and neglecting the\nvaluable context that historical data can provide. We contend that explicitly\nincorporating drifted data into the model training process significantly\nenhances model accuracy and robustness. This paper introduces an advanced\nframework that integrates the strengths of data-centric approaches with\nadaptive management of both covariate and concept drift in a scalable and\nefficient manner. Our framework employs sophisticated data segmentation\ntechniques to identify optimal data batches that accurately reflect test data\npatterns. These data batches are then utilized for training on test data,\nensuring that the models remain relevant and accurate over time. By leveraging\nthe advantages of both data segmentation and scalable drift management, our\nsolution ensures robust model accuracy and operational efficiency in\nlarge-scale ML deployments. It also minimizes resource consumption and\ncomputational overhead by selecting and utilizing relevant data subsets,\nleading to significant cost savings. Experimental results on classification\ntask on real-world and synthetic datasets show our approach improves model\naccuracy while reducing operational costs and latency. This practical solution\novercomes inefficiencies in current methods, providing a robust, adaptable, and\nscalable approach.",
    "pdf_url": "http://arxiv.org/pdf/2411.15616v1",
    "published": "2024-11-23T17:35:23+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15615v1",
    "title": "The Palatini formalism of the $f(R,\\mathcal{L}_{m},T)$ theory of gravity",
    "authors": [
      "J. G. de Lima J√∫nior",
      "P. H. R. S. Moraes",
      "E. Brito",
      "J. A. S. Fortunato"
    ],
    "abstract": "We present the first formulation of the recently proposed\n$f(R,\\mathcal{L}_m,T)$ theory of gravity within the Palatini formalism, a\nwell-known alternative variational approach where the metric and connection are\ntreated as independent variables. By applying this formalism, we derive a new\nset of field equations that exhibit, as expected, distinct properties compared\nto their metric formalism counterparts. We particularly present the Newtonian\nlimit of this formalism, as well as the resulting Friedmann-like equations. We\nhighlight that potential observational signatures may distinguish between the\nmetric and Palatini frameworks. Our results open new pathways for exploring the\nphenomenology of modified gravity theories and their testability with\nobservational data.",
    "pdf_url": "http://arxiv.org/pdf/2411.15615v1",
    "published": "2024-11-23T17:30:32+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2411.15614v1",
    "title": "Constructing topological biquandles via skew braces",
    "authors": [
      "Zhiyun Cheng"
    ],
    "abstract": "In this short note, we construct some nontrivial examples of topological\nbiquandle. The key ingredient of the construction is the notion of skew brace.",
    "pdf_url": "http://arxiv.org/pdf/2411.15614v1",
    "published": "2024-11-23T17:29:05+00:00",
    "categories": [
      "math.GT",
      "57K12, 16T25"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15613v1",
    "title": "On extracting coherent seismic wavefield using variational symmetric autoencoders",
    "authors": [
      "Pawan Bharadwaj"
    ],
    "abstract": "We discuss the variational formulation of the Symmetric Autoencoder (SymAE)\nand its role in achieving disentanglement within the latent space to extract\ncoherent information from a collection of seismic waveforms. Disentanglement\ninvolves separating the latent space into components for coherent information\nshared by all waveforms and components for waveform-specific nuisance\ninformation. SymAE employs a generative model that independently generates\nwaveforms based on coherent and nuisance components, and an inference model\nthat estimates these components from observed wavefield. By assuming the\nindependence of waveforms conditioned on coherent information, the model\neffectively accumulates this information across multiple waveforms. After\ntraining, a metric based on Kullback-Leibler divergence is used to evaluate the\ninformativeness of individual waveforms, enabling latent-space optimization and\nthe generation of synthetic seismograms with enhanced signal-to-noise ratios.\nTo demonstrate the efficacy of our proposed method, we applied it to a data set\nof teleseismic displacement waveforms of the P wave from deep-focus\nearthquakes. By training the SymAE model on high-magnitude events, we\nsuccessfully identified seismograms that contained robust source information.\nFurthermore, we generated high-resolution virtual seismograms enriched with\nrelevant coherent source information and less influenced by scattering noise,\nallowing a deeper understanding of the characteristics of the earthquake\nsource. Importantly, our method extracts coherent source information without\nrelying on deconvolution, which is often used in traditional source imaging.\nThis enables the analysis of complex earthquakes with multiple rupture\nepisodes, a capability that is not easily achievable with conventional\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2411.15613v1",
    "published": "2024-11-23T17:28:15+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15612v1",
    "title": "Faulty towers: recovering a functioning quantum random access memory in the presence of defective routers",
    "authors": [
      "D. K. Weiss",
      "Shifan Xu",
      "Shruti Puri",
      "Yongshan Ding",
      "S. M. Girvin"
    ],
    "abstract": "Proposals for quantum random access memory (QRAM) generally have a\nbinary-tree structure, and thus require hardware that is exponential in the\ndepth of the QRAM. For solid-state based devices, a fabrication yield that is\nless than $100\\%$ implies that certain addresses at the bottom of the tree\nbecome inaccessible if a router in the unique path to that address is faulty.\nWe discuss how to recover a functioning QRAM in the presence of faulty routers.\nWe present the \\texttt{IterativeRepair} algorithm, which constructs QRAMs layer\nby layer until the desired depth is reached. This algorithm utilizes ancilla\nflag qubits which reroute queries to faulty routers. We present a classical\nalgorithm \\texttt{FlagQubitMinimization} that attempts to minimize the required\nnumber of such ancilla. For a router failure rate of $1\\%$ and a QRAM of depth\n$n=13$, we expect that on average 430 addresses need repair: we require only\n1.5 ancilla flag qubits on average to perform this rerouting.",
    "pdf_url": "http://arxiv.org/pdf/2411.15612v1",
    "published": "2024-11-23T17:27:30+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15611v1",
    "title": "Knowledge Transfer Across Modalities with Natural Language Supervision",
    "authors": [
      "Carlo Alberto Barbano",
      "Luca Molinaro",
      "Emanuele Aiello",
      "Marco Grangetto"
    ],
    "abstract": "We present a way to learn novel concepts by only using their textual\ndescription. We call this method Knowledge Transfer. Similarly to human\nperception, we leverage cross-modal interaction to introduce new concepts. We\nhypothesize that in a pre-trained visual encoder there are enough low-level\nfeatures already learned (e.g. shape, appearance, color) that can be used to\ndescribe previously unknown high-level concepts. Provided with a textual\ndescription of the novel concept, our method works by aligning the known\nlow-level features of the visual encoder to its high-level textual description.\nWe show that Knowledge Transfer can successfully introduce novel concepts in\nmultimodal models, in a very efficient manner, by only requiring a single\ndescription of the target concept. Our approach is compatible with both\nseparate textual and visual encoders (e.g. CLIP) and shared parameters across\nmodalities. We also show that, following the same principle, Knowledge Transfer\ncan improve concepts already known by the model. Leveraging Knowledge Transfer\nwe improve zero-shot performance across different tasks such as classification,\nsegmentation, image-text retrieval, and captioning.",
    "pdf_url": "http://arxiv.org/pdf/2411.15611v1",
    "published": "2024-11-23T17:26:50+00:00",
    "categories": [
      "cs.CV",
      "68T45 (Primary) 68T50 (Secondary)",
      "I.2.6"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15610v1",
    "title": "Zippers",
    "authors": [
      "Danny Calegari",
      "Ino Loukidou"
    ],
    "abstract": "If $M$ is a hyperbolic 3-manifold fibering over the circle, the fundamental\ngroup of $M$ acts faithfully by homeomorphisms on a circle (the circle at\ninfinity of the universal cover of the fiber), preserving a pair of invariant\n(stable and unstable) laminations. Many different kinds of dynamical structures\n(e.g. taut foliations, quasigeodesic or pseudo-Anosov flows) are known to give\nrise to universal circles -- a circle with a faithful $\\pi_1(M)$ action\npreserving a pair of invariant laminations -- and these universal circles play\na key role in relating the dynamical structure to the geometry of $M$. In this\npaper we introduce the idea of zippers, which give a new and direct way to\nconstruct universal circles, streamlining the known constructions in many\ncases, and giving a host of new constructions in others. In particular, zippers\n(and their associated universal circles) may be constructed directly from\nuniform quasimorphisms or from uniform left orders.",
    "pdf_url": "http://arxiv.org/pdf/2411.15610v1",
    "published": "2024-11-23T17:18:55+00:00",
    "categories": [
      "math.GT",
      "math.DS",
      "math.GR"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15609v1",
    "title": "Expander representations of quivers",
    "authors": [
      "Markus Reineke"
    ],
    "abstract": "We propose a definition of expander representations of quivers, generalizing\ndimension (or linear algebra) expanders, as a qualitative refinement of slope\nstability. We prove existence of uniform expander representations for any wild\nquiver over an algebraically closed base field, using the concept of general\nsubrepresentations and spectral properties of Cartan matrices.",
    "pdf_url": "http://arxiv.org/pdf/2411.15609v1",
    "published": "2024-11-23T17:17:03+00:00",
    "categories": [
      "math.RT",
      "math.CO",
      "primary 16G20, secondary 05C48"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15608v1",
    "title": "Condensation of Magnetic Fluxes and Landscape of QCD Vacuum",
    "authors": [
      "George Savvidy"
    ],
    "abstract": "I discuss new non-perturbative solutions of the sourceless Yang-Mills\nequation representing the superposition of oppositely oriented chromomagnetic\nflux tubes (vortices) similar in their form to a lattice of superposed\nAbrikosov-Nielsen-Olesen chromomagnetic vortices. These solutions represent\nhighly degenerate classical vacua of the Yang Mills theory that are separated\nby potential barriers and are forming a complicated potential landscape of the\nQCD vacuum. It is suggested that the solutions describe a lattice of dense\nchromomagnetic vortices representing a dual analog of the Cooper pairs\ncondensate in a superconductor.",
    "pdf_url": "http://arxiv.org/pdf/2411.15608v1",
    "published": "2024-11-23T17:11:46+00:00",
    "categories": [
      "hep-th",
      "hep-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2412.00046v3",
    "title": "A comparison of arithmetical operations with $f$ correlated fuzzy numbers",
    "authors": [
      "Diogo Sampaio da Silva",
      "Roberto Antonio Cordeiro Prata"
    ],
    "abstract": "We present a brief introduction to a class of interactive fuzzy numbers,\ncalled $f$-correlated fuzzy numbers, which consist of pairs of fuzzy numbers\nwhere one is dependent on the other by a continuous monotone injective\nfunction. We have deduced some equations that can directly calculate the\nresults of the sums and products of $f$-correlated fuzzy numbers, using only\nbasic operations with real numbers, intervals on the real line and the function\nthat relates the fuzzy numbers being considered. We proved that their\ncorrelated and standard sum coincide, and that in a certain sense, the\ncorrelated product is contained in the standard product.",
    "pdf_url": "http://arxiv.org/pdf/2412.00046v3",
    "published": "2024-11-23T17:06:02+00:00",
    "categories": [
      "math.GM"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15607v1",
    "title": "On-chip 7 GHz acousto-optic modulators for visible wavelengths",
    "authors": [
      "Ji-Zhe Zhang",
      "Yu Zeng",
      "Qing Qin",
      "Yuan-Hao Yang",
      "Zheng-Hui Tian",
      "Jia-Qi Wang",
      "Chun-Hua Dong",
      "Xin-Biao Xu",
      "Ming-Yong Ye",
      "Guang-Can Guo",
      "Chang-Ling Zou"
    ],
    "abstract": "A chip-integrated acousto-optic phase modulator tailored for visible optical\nwavelengths has been developed. Utilizing the lithium niobate on sapphire\nplatform, the modulator employs a 7 GHz surface acoustic wave, excited by an\ninterdigital transducer and aligned perpendicular to the waveguide. This design\nachieves efficient phase modulation of visible light within a compact device\nlength of merely 200 microns, while holds the advantages of easy fabrication\nand high stability due to simple unsuspended structure. Remarkably, in this\nhigh-frequency acoustic regime, the acoustic wavelength becomes comparable to\nthe optical wavelength, resulting in a notable single-sideband modulation\nbehavior. This observation underscores the phase delay effects in the\nacousto-optics interactions, and opens up new aspects for realizing functional\nvisible photonic devices and its integration with atom- and ion-based quantum\nplatforms.",
    "pdf_url": "http://arxiv.org/pdf/2411.15607v1",
    "published": "2024-11-23T16:59:38+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2411.15606v1",
    "title": "A polyptych of multi-centered deformation spaces",
    "authors": [
      "Adrien Dubouloz",
      "Arnaud Mayeux"
    ],
    "abstract": "We study deformation spaces using multi-centered dilatations. Interpolating\nFulton simple deformation space and Rost asymmetric double deformation space,\nwe introduce (asymmetric) deformation spaces attached to chains of immersions\nof arbitrary lengths. One of the main results of this paper is the so-called\npanelization isomorphism, producing several isomorphisms between the\ndeformation space of length $n$ and deformation spaces of smaller lengths.\nCombining these isomorphisms, we get a polyptych $\\mathscr{P}(n)$ of\ndeformation spaces. Having these panelization isomorphisms allows to compute\nthe strata -- certain restrictions of special interests -- of deformation\nspaces.",
    "pdf_url": "http://arxiv.org/pdf/2411.15606v1",
    "published": "2024-11-23T16:54:04+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15605v2",
    "title": "GIFT: A Framework for Global Interpretable Faithful Textual Explanations of Vision Classifiers",
    "authors": [
      "√âloi Zablocki",
      "Valentin Gerard",
      "Amaia Cardiel",
      "Eric Gaussier",
      "Matthieu Cord",
      "Eduardo Valle"
    ],
    "abstract": "Understanding deep models is crucial for deploying them in safety-critical\napplications. We introduce GIFT, a framework for deriving post-hoc, global,\ninterpretable, and faithful textual explanations for vision classifiers. GIFT\nstarts from local faithful visual counterfactual explanations and employs\n(vision) language models to translate those into global textual explanations.\nCrucially, GIFT provides a verification stage measuring the causal effect of\nthe proposed explanations on the classifier decision. Through experiments\nacross diverse datasets, including CLEVR, CelebA, and BDD, we demonstrate that\nGIFT effectively reveals meaningful insights, uncovering tasks, concepts, and\nbiases used by deep vision classifiers. The framework is released at\nhttps://github.com/valeoai/GIFT.",
    "pdf_url": "http://arxiv.org/pdf/2411.15605v2",
    "published": "2024-11-23T16:52:22+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15604v2",
    "title": "FATE: Full-head Gaussian Avatar with Textural Editing from Monocular Video",
    "authors": [
      "Jiawei Zhang",
      "Zijian Wu",
      "Zhiyang Liang",
      "Yicheng Gong",
      "Dongfang Hu",
      "Yao Yao",
      "Xun Cao",
      "Hao Zhu"
    ],
    "abstract": "Reconstructing high-fidelity, animatable 3D head avatars from effortlessly\ncaptured monocular videos is a pivotal yet formidable challenge. Although\nsignificant progress has been made in rendering performance and manipulation\ncapabilities, notable challenges remain, including incomplete reconstruction\nand inefficient Gaussian representation. To address these challenges, we\nintroduce FATE, a novel method for reconstructing an editable full-head avatar\nfrom a single monocular video. FATE integrates a sampling-based densification\nstrategy to ensure optimal positional distribution of points, improving\nrendering efficiency. A neural baking technique is introduced to convert\ndiscrete Gaussian representations into continuous attribute maps, facilitating\nintuitive appearance editing. Furthermore, we propose a universal completion\nframework to recover non-frontal appearance, culminating in a\n360$^\\circ$-renderable 3D head avatar. FATE outperforms previous approaches in\nboth qualitative and quantitative evaluations, achieving state-of-the-art\nperformance. To the best of our knowledge, FATE is the first animatable and\n360$^\\circ$ full-head monocular reconstruction method for a 3D head avatar.",
    "pdf_url": "http://arxiv.org/pdf/2411.15604v2",
    "published": "2024-11-23T16:47:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15603v1",
    "title": "New radial velocities for 40 nearby dwarf galaxies",
    "authors": [
      "Igor D. Karachentsev",
      "Maxim I. Chazov",
      "Serafim S. Kaisin"
    ],
    "abstract": "The 6-meter BTA telescope has been used to determine radial velocities for 40\ngalaxies, recently identified in the DESI Legacy Imaging Surveys as nearby\nobjects. Half of them have kinematic distances within 11 Mpc being new probable\ncompanions to the bright Local Volume galaxies: NGC628, Maffei2, NGC2787, M81,\nNGC4605 and NGC4631. Six relatively isolated objects with heliocentric\nvelocities in the range of $[-150, +70]$km s$^{-1}$, together with the blue\ncompact dwarf NGC 6789, form a diffuse association of dwarf galaxies located in\nthe near part of the Local Void.",
    "pdf_url": "http://arxiv.org/pdf/2411.15603v1",
    "published": "2024-11-23T16:40:06+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15602v1",
    "title": "Enhancing Object Detection Accuracy in Autonomous Vehicles Using Synthetic Data",
    "authors": [
      "Sergei Voronin",
      "Abubakar Siddique",
      "Muhammad Iqbal"
    ],
    "abstract": "The rapid progress in machine learning models has significantly boosted the\npotential for real-world applications such as autonomous vehicles, disease\ndiagnoses, and recognition of emergencies. The performance of many machine\nlearning models depends on the nature and size of the training data sets. These\nmodels often face challenges due to the scarcity, noise, and imbalance in\nreal-world data, limiting their performance. Nonetheless, high-quality,\ndiverse, relevant and representative training data is essential to build\naccurate and reliable machine learning models that adapt well to real-world\nscenarios.\n  It is hypothesised that well-designed synthetic data can improve the\nperformance of a machine learning algorithm. This work aims to create a\nsynthetic dataset and evaluate its effectiveness to improve the prediction\naccuracy of object detection systems. This work considers autonomous vehicle\nscenarios as an illustrative example to show the efficacy of synthetic data.\nThe effectiveness of these synthetic datasets in improving the performance of\nstate-of-the-art object detection models is explored. The findings demonstrate\nthat incorporating synthetic data improves model performance across all\nperformance matrices.\n  Two deep learning systems, System-1 (trained on real-world data) and System-2\n(trained on a combination of real and synthetic data), are evaluated using the\nstate-of-the-art YOLO model across multiple metrics, including accuracy,\nprecision, recall, and mean average precision. Experimental results revealed\nthat System-2 outperformed System-1, showing a 3% improvement in accuracy,\nalong with superior performance in all other metrics.",
    "pdf_url": "http://arxiv.org/pdf/2411.15602v1",
    "published": "2024-11-23T16:38:02+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15601v1",
    "title": "Detection of Sulfur Dioxide by Broadband Cavity-Enhanced Absorption Spectroscopy (BBCEAS)",
    "authors": [
      "Ryan Thalman",
      "Nitish Bhardwaj",
      "Callum E. Flowerday",
      "Jaron C. Hansen"
    ],
    "abstract": "Sulfur dioxide ($\\mathrm{SO}_2$) is an important precursor for the formation\nof atmospheric sulfate aerosol and acid rain. We present an instrument using\nBroadband Cavity-Enhanced Absorption Spectroscopy (BBCEAS) for the measurement\nof $\\mathrm{SO}_2$ with a minimum limit of detection of 0.75 ppbv (3-$\\sigma$)\nusing the spectral range 305.5--312 nm and an averaging time of 5 min. The\ninstrument consists of high-reflectivity mirrors (0.9985 at 310 nm) and a deep\nUV light source (Light Emitting Diode). The effective absorption path length of\nthe instrument is 610 m with a 0.966 m base length. Published reference\nabsorption cross sections were used to fit and retrieve the $\\mathrm{SO}_2$\nconcentrations and were compared to fluorescence standard measurements for\n$\\mathrm{SO}_2$. The comparison was well correlated ($R^2 = 0.9998$) with a\ncorrelation slope of 1.04. Interferences for fluorescence measurements were\ntested, and the BBCEAS showed no interference, while ambient measurements\nresponded similarly to standard measurement techniques.",
    "pdf_url": "http://arxiv.org/pdf/2411.15601v1",
    "published": "2024-11-23T16:34:18+00:00",
    "categories": [
      "physics.ins-det",
      "physics.ao-ph"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2411.15600v1",
    "title": "How Texts Help? A Fine-grained Evaluation to Reveal the Role of Language in Vision-Language Tracking",
    "authors": [
      "Xuchen Li",
      "Shiyu Hu",
      "Xiaokun Feng",
      "Dailing Zhang",
      "Meiqi Wu",
      "Jing Zhang",
      "Kaiqi Huang"
    ],
    "abstract": "Vision-language tracking (VLT) extends traditional single object tracking by\nincorporating textual information, providing semantic guidance to enhance\ntracking performance under challenging conditions like fast motion and\ndeformations. However, current VLT trackers often underperform compared to\nsingle-modality methods on multiple benchmarks, with semantic information\nsometimes becoming a \"distraction.\" To address this, we propose VLTVerse, the\nfirst fine-grained evaluation framework for VLT trackers that comprehensively\nconsiders multiple challenge factors and diverse semantic information, hoping\nto reveal the role of language in VLT. Our contributions include: (1) VLTVerse\nintroduces 10 sequence-level challenge labels and 6 types of multi-granularity\nsemantic information, creating a flexible and multi-dimensional evaluation\nspace for VLT; (2) leveraging 60 subspaces formed by combinations of challenge\nfactors and semantic types, we conduct systematic fine-grained evaluations of\nthree mainstream SOTA VLT trackers, uncovering their performance bottlenecks\nacross complex scenarios and offering a novel perspective on VLT evaluation;\n(3) through decoupled analysis of experimental results, we examine the impact\nof various semantic types on specific challenge factors in relation to\ndifferent algorithms, providing essential guidance for enhancing VLT across\ndata, evaluation, and algorithmic dimensions. The VLTVerse, toolkit, and\nresults will be available at \\url{http://metaverse.aitestunion.com}.",
    "pdf_url": "http://arxiv.org/pdf/2411.15600v1",
    "published": "2024-11-23T16:31:40+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.00045v1",
    "title": "Properties of f correlated fuzzy numbers",
    "authors": [
      "Diogo Sampaio da Silva",
      "Roberto Antonio Cordeiro Prata"
    ],
    "abstract": "This paper presents some concepts of the theory of interactive fuzzy numbers,\nand mainly, a class of interactive fuzzy numbers, called $f$-correlated fuzzy\nnumbers. We start from the foundations of general fuzzy mathematics and go\nthrough operations and the notion of interactivity for fuzzy numbers. The main\nresult is that $f$-correlation preserve the shape of certains fuzzy numbers.\nMore specificaly, if two fuzzy numbers are $f$ correlated, and one is a LR-type\nfuzzy number, the other is also a LR-type fuzzy number. This paper also\npresents some operations with the $f$-correlated fuzzy numbers wich are\ninteresting to applications like biomathematics.",
    "pdf_url": "http://arxiv.org/pdf/2412.00045v1",
    "published": "2024-11-23T16:31:00+00:00",
    "categories": [
      "math.GM"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15599v1",
    "title": "The generalized Darboux matrices with the same poles and their applications",
    "authors": [
      "Yu-Yue Li",
      "Deng-Shan Wang"
    ],
    "abstract": "Darboux transformation plays a key role in constructing explicit closed-form\nsolutions of completely integrable systems. This paper provides an algebraic\nconstruction of generalized Darboux matrices with the same poles for the\n$2\\times2$ Lax pair, in which the coefficient matrices are polynomials of\nspectral parameter. The first-order monic Darboux matrix is constructed\nexplicitly and its classification theorem is presented. Then by using the\nsolutions of the corresponding adjoint Lax pair, the $n$-order monic Darboux\nmatrix and its inverse, both sharing the same unique pole, are derived\nexplicitly. Further, a theorem is proposed to describe the invariance of\nDarboux matrix regarding pole distributions in Darboux matrix and its inverse.\nFinally, a unified theorem is offered to construct formal Darboux\ntransformation in general form. All Darboux matrices expressible as the product\nof $n$ first-order monic Darboux matrices can be constructed in this way. The\nnonlocal focusing NLS equation, the focusing NLS equation and the\nKaup-Boussinesq equation are taken as examples to illustrate the application of\nthese Darboux transformations.",
    "pdf_url": "http://arxiv.org/pdf/2411.15599v1",
    "published": "2024-11-23T16:26:56+00:00",
    "categories": [
      "nlin.SI",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "nlin.SI"
  },
  {
    "id": "http://arxiv.org/abs/2411.15598v1",
    "title": "Optimizing Gesture Recognition for Seamless UI Interaction Using Convolutional Neural Networks",
    "authors": [
      "Qi Sun",
      "Tong Zhang",
      "Shang Gao",
      "Liuqingqing Yang",
      "Fenghua Shao"
    ],
    "abstract": "This study introduces an advanced gesture recognition and user interface (UI)\ninteraction system powered by deep learning, highlighting its transformative\nimpact on UI design and functionality. By utilizing optimized convolutional\nneural networks (CNNs), the system achieves high-precision gesture recognition,\nsignificantly improving user interactions with digital interfaces. The process\nbegins with preprocessing collected gesture images to meet CNN input\nrequirements, followed by sophisticated feature extraction and classification\ntechniques. To address class imbalance, we employ Focal Loss as the loss\nfunction, ensuring robust model performance across diverse gesture types.\nExperimental results demonstrate notable improvements in model metrics, with\nthe Area Under the Curve (AUC) and Recall metrics improving as we transition\nfrom simpler models like VGG16 to more advanced ones such as DenseNet. Our\nenhanced model achieves strong AUC and Recall values, outperforming standard\nbenchmarks. Notably, the system's ability to support real-time and efficient\ngesture recognition paves the way for a new era in UI design, where intuitive\nuser gestures can be seamlessly integrated into everyday technology use,\nreducing the learning curve and enhancing user satisfaction. The implications\nof this development extend beyond technical performance to fundamentally\nreshape user-technology interactions, underscoring the critical role of\ngesture-based interfaces in the next generation of UI development. Such\nadvancements promise to significantly enhance smart life experiences,\npositioning gesture recognition as a key driver in the evolution of\nuser-centric interfaces.",
    "pdf_url": "http://arxiv.org/pdf/2411.15598v1",
    "published": "2024-11-23T16:25:03+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2411.16739v1",
    "title": "Gradient-Guided Parameter Mask for Multi-Scenario Image Restoration Under Adverse Weather",
    "authors": [
      "Jilong Guo",
      "Haobo Yang",
      "Mo Zhou",
      "Xinyu Zhang"
    ],
    "abstract": "Removing adverse weather conditions such as rain, raindrop, and snow from\nimages is critical for various real-world applications, including autonomous\ndriving, surveillance, and remote sensing. However, existing multi-task\napproaches typically rely on augmenting the model with additional parameters to\nhandle multiple scenarios. While this enables the model to address diverse\ntasks, the introduction of extra parameters significantly complicates its\npractical deployment. In this paper, we propose a novel Gradient-Guided\nParameter Mask for Multi-Scenario Image Restoration under adverse weather,\ndesigned to effectively handle image degradation under diverse weather\nconditions without additional parameters. Our method segments model parameters\ninto common and specific components by evaluating the gradient variation\nintensity during training for each specific weather condition. This enables the\nmodel to precisely and adaptively learn relevant features for each weather\nscenario, improving both efficiency and effectiveness without compromising on\nperformance. This method constructs specific masks based on gradient\nfluctuations to isolate parameters influenced by other tasks, ensuring that the\nmodel achieves strong performance across all scenarios without adding extra\nparameters. We demonstrate the state-of-the-art performance of our framework\nthrough extensive experiments on multiple benchmark datasets. Specifically, our\nmethod achieves PSNR scores of 29.22 on the Raindrop dataset, 30.76 on the Rain\ndataset, and 29.56 on the Snow100K dataset. Code is available at:\n\\href{https://github.com/AierLab/MultiTask}{https://github.com/AierLab/MultiTask}.",
    "pdf_url": "http://arxiv.org/pdf/2411.16739v1",
    "published": "2024-11-23T16:16:27+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15597v1",
    "title": "Chatting with a Learning Analytics Dashboard: The Role of Generative AI Literacy on Learner Interaction with Conventional and Scaffolding Chatbots",
    "authors": [
      "Yueqiao Jin",
      "Kaixun Yang",
      "Lixiang Yan",
      "Vanessa Echeverria",
      "Linxuan Zhao",
      "Riordan Alfredo",
      "Mikaela Milesi",
      "Jie Fan",
      "Xinyu Li",
      "Dragan Ga≈°eviƒá",
      "Roberto Martinez-Maldonado"
    ],
    "abstract": "Learning analytics dashboards (LADs) simplify complex learner data into\naccessible visualisations, providing actionable insights for educators and\nstudents. However, their educational effectiveness has not always matched the\nsophistication of the technology behind them. Explanatory and interactive LADs,\nenhanced by generative AI (GenAI) chatbots, hold promise by enabling dynamic,\ndialogue-based interactions with data visualisations and offering personalised\nfeedback through text. Yet, the effectiveness of these tools may be limited by\nlearners' varying levels of GenAI literacy, a factor that remains underexplored\nin current research. This study investigates the role of GenAI literacy in\nlearner interactions with conventional (reactive) versus scaffolding\n(proactive) chatbot-assisted LADs. Through a comparative analysis of 81\nparticipants, we examine how GenAI literacy is associated with learners'\nability to interpret complex visualisations and their cognitive processes\nduring interactions with chatbot-assisted LADs. Results show that while both\nchatbots significantly improved learner comprehension, those with higher GenAI\nliteracy benefited the most, particularly with conventional chatbots,\ndemonstrating diverse prompting strategies. Findings highlight the importance\nof considering learners' GenAI literacy when integrating GenAI chatbots in LADs\nand educational technologies. Incorporating scaffolding techniques within GenAI\nchatbots can be an effective strategy, offering a more guided experience that\nreduces reliance on learners' GenAI literacy.",
    "pdf_url": "http://arxiv.org/pdf/2411.15597v1",
    "published": "2024-11-23T16:15:04+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15596v3",
    "title": "Comparative Analysis of Resource-Efficient CNN Architectures for Brain Tumor Classification",
    "authors": [
      "Md Ashik Khan",
      "Rafath Bin Zafar Auvee"
    ],
    "abstract": "Accurate brain tumor classification in MRI images is critical for timely\ndiagnosis and treatment planning. While deep learning models like ResNet-18,\nVGG-16 have shown high accuracy, they often come with increased complexity and\ncomputational demands. This study presents a comparative analysis of effective\nyet simple Convolutional Neural Network (CNN) architecture and pre-trained\nResNet18, and VGG16 model for brain tumor classification using two publicly\navailable datasets: Br35H:: Brain Tumor Detection 2020 and Brain Tumor MRI\nDataset. The custom CNN architecture, despite its lower complexity,\ndemonstrates competitive performance with the pre-trained ResNet18 and VGG16\nmodels. In binary classification tasks, the custom CNN achieved an accuracy of\n98.67% on the Br35H dataset and 99.62% on the Brain Tumor MRI Dataset. For\nmulti-class classification, the custom CNN, with a slight architectural\nmodification, achieved an accuracy of 98.09%, on the Brain Tumor MRI Dataset.\nComparatively, ResNet18 and VGG16 maintained high performance levels, but the\ncustom CNNs provided a more computationally efficient alternative.\nAdditionally,the custom CNNs were evaluated using few-shot learning (0, 5, 10,\n15, 20, 40, and 80 shots) to assess their robustness, achieving notable\naccuracy improvements with increased shots. This study highlights the potential\nof well-designed, less complex CNN architectures as effective and\ncomputationally efficient alternatives to deeper, pre-trained models for\nmedical imaging tasks, including brain tumor classification. This study\nunderscores the potential of custom CNNs in medical imaging tasks and\nencourages further exploration in this direction.",
    "pdf_url": "http://arxiv.org/pdf/2411.15596v3",
    "published": "2024-11-23T16:13:40+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "I.2.10 Vision and Scene Understanding, I.4.8 Scene Analysis, 92C55\n  Biomedical imaging and signal processing"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15595v2",
    "title": "An adversarial feature learning based semantic communication method for Human 3D Reconstruction",
    "authors": [
      "Shaojiang Liu",
      "Jiajun Zou",
      "Zhendan Liu",
      "Meixia Dong",
      "Zhiping Wan"
    ],
    "abstract": "With the widespread application of human body 3D reconstruction technology\nacross various fields, the demands for data transmission and processing\nefficiency continue to rise, particularly in scenarios where network bandwidth\nis limited and low latency is required. This paper introduces an Adversarial\nFeature Learning-based Semantic Communication method (AFLSC) for human body 3D\nreconstruction, which focuses on extracting and transmitting semantic\ninformation crucial for the 3D reconstruction task, thereby significantly\noptimizing data flow and alleviating bandwidth pressure. At the sender's end,\nwe propose a multitask learning-based feature extraction method to capture the\nspatial layout, keypoints, posture, and depth information from 2D human images,\nand design a semantic encoding technique based on adversarial feature learning\nto encode these feature information into semantic data. We also develop a\ndynamic compression technique to efficiently transmit this semantic data,\ngreatly enhancing transmission efficiency and reducing latency. At the\nreceiver's end, we design an efficient multi-level semantic feature decoding\nmethod to convert semantic data back into key image features. Finally, an\nimproved ViT-diffusion model is employed for 3D reconstruction, producing human\nbody 3D mesh models. Experimental results validate the advantages of our method\nin terms of data transmission efficiency and reconstruction quality,\ndemonstrating its excellent potential for application in bandwidth-limited\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2411.15595v2",
    "published": "2024-11-23T16:09:53+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15594v5",
    "title": "A Survey on LLM-as-a-Judge",
    "authors": [
      "Jiawei Gu",
      "Xuhui Jiang",
      "Zhichao Shi",
      "Hexiang Tan",
      "Xuehao Zhai",
      "Chengjin Xu",
      "Wei Li",
      "Yinghan Shen",
      "Shengjie Ma",
      "Honghao Liu",
      "Saizhuo Wang",
      "Kun Zhang",
      "Yuanzhuo Wang",
      "Wen Gao",
      "Lionel Ni",
      "Jian Guo"
    ],
    "abstract": "Accurate and consistent evaluation is crucial for decision-making across\nnumerous fields, yet it remains a challenging task due to inherent\nsubjectivity, variability, and scale. Large Language Models (LLMs) have\nachieved remarkable success across diverse domains, leading to the emergence of\n\"LLM-as-a-Judge,\" where LLMs are employed as evaluators for complex tasks. With\ntheir ability to process diverse data types and provide scalable,\ncost-effective, and consistent assessments, LLMs present a compelling\nalternative to traditional expert-driven evaluations. However, ensuring the\nreliability of LLM-as-a-Judge systems remains a significant challenge that\nrequires careful design and standardization. This paper provides a\ncomprehensive survey of LLM-as-a-Judge, addressing the core question: How can\nreliable LLM-as-a-Judge systems be built? We explore strategies to enhance\nreliability, including improving consistency, mitigating biases, and adapting\nto diverse assessment scenarios. Additionally, we propose methodologies for\nevaluating the reliability of LLM-as-a-Judge systems, supported by a novel\nbenchmark designed for this purpose. To advance the development and real-world\ndeployment of LLM-as-a-Judge systems, we also discussed practical applications,\nchallenges, and future directions. This survey serves as a foundational\nreference for researchers and practitioners in this rapidly evolving field.",
    "pdf_url": "http://arxiv.org/pdf/2411.15594v5",
    "published": "2024-11-23T16:03:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15593v1",
    "title": "Medillustrator: Improving Retrospective Learning in Physicians' Continuous Medical Education via Multimodal Diagnostic Data Alignment and Representation",
    "authors": [
      "Yuansong Xu",
      "Jiahe Dong",
      "Yijie Fan",
      "Yuheng Shao",
      "Chang Jiang",
      "Lixia Jin",
      "Yuanwu Cao",
      "Quan Li"
    ],
    "abstract": "Continuous Medical Education (CME) plays a vital role in physicians' ongoing\nprofessional development. Beyond immediate diagnoses, physicians utilize\nmultimodal diagnostic data for retrospective learning, engaging in\nself-directed analysis and collaborative discussions with peers. However,\nlearning from such data effectively poses challenges for novice physicians,\nincluding screening and identifying valuable research cases, achieving\nfine-grained alignment and representation of multimodal data at the semantic\nlevel, and conducting comprehensive contextual analysis aided by reference\ndata. To tackle these challenges, we introduce Medillustrator, a visual\nanalytics system crafted to facilitate novice physicians' retrospective\nlearning. Our structured approach enables novice physicians to explore and\nreview research cases at an overview level and analyze specific cases with\nconsistent alignment of multimodal and reference data. Furthermore, physicians\ncan record and review analyzed results to facilitate further retrospection. The\nefficacy of Medillustrator in enhancing physicians' retrospective learning\nprocesses is demonstrated through a comprehensive case study and a controlled\nin-lab between-subject user study.",
    "pdf_url": "http://arxiv.org/pdf/2411.15593v1",
    "published": "2024-11-23T16:02:54+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15592v2",
    "title": "Classifier Enhanced Deep Learning Model for Erythroblast Differentiation with Limited Data",
    "authors": [
      "Buddhadev Goswami",
      "Adithya B. Somaraj",
      "Prantar Chakrabarti",
      "Ravindra Gudi",
      "Nirmal Punjabi"
    ],
    "abstract": "Hematological disorders, which involve a variety of malignant conditions and\ngenetic diseases affecting blood formation, present significant diagnostic\nchallenges. One such major challenge in clinical settings is differentiating\nErythroblast from WBCs. Our approach evaluates the efficacy of various machine\nlearning (ML) classifiers$\\unicode{x2014}$SVM, XG-Boost, KNN, and Random\nForest$\\unicode{x2014}$using the ResNet-50 deep learning model as a backbone in\ndetecting and differentiating erythroblast blood smear images across training\nsplits of different sizes. Our findings indicate that the ResNet50-SVM\nclassifier consistently surpasses other models' overall test accuracy and\nerythroblast detection accuracy, maintaining high performance even with minimal\ntraining data. Even when trained on just 1% (168 images per class for eight\nclasses) of the complete dataset, ML classifiers such as SVM achieved a test\naccuracy of 86.75% and an erythroblast precision of 98.9%, compared to 82.03%\nand 98.6% of pre-trained ResNet-50 models without any classifiers. When limited\ndata is available, the proposed approach outperforms traditional deep learning\nmodels, thereby offering a solution for achieving higher classification\naccuracy for small and unique datasets, especially in resource-scarce settings.",
    "pdf_url": "http://arxiv.org/pdf/2411.15592v2",
    "published": "2024-11-23T15:51:15+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15591v1",
    "title": "Chemical Links between a Young M-type T Tauri Star and its Substellar Companion: Spectral Analysis and C/O Measurement of DH Tau A",
    "authors": [
      "Neda Hejazi",
      "Jerry W. Xuan",
      "David R. Coria",
      "Erica Sawczynec",
      "Ian J. M. Crossfield",
      "Paul I. Cristofari",
      "Zhoujian Zhang",
      "Maleah Rhem"
    ],
    "abstract": "The chemical abundance measurements of host stars and their substellar\ncompanions provide a powerful tool to trace the formation mechanism of the\nplanetary systems. We present a detailed high-resolution spectroscopic analysis\nof a young M-type star, DH Tau A, which is located in the Taurus molecular\ncloud belonging to the Taurus-Auriga star-forming region. This star is host to\na low-mass companion, DH Tau b, and both star and the companion are still in\ntheir accreting phase. We apply our technique (Hejazi et al. 2024) to measure\nthe abundances of carbon and oxygen using carbon- and oxygen-bearing molecules,\nsuch as CO and OH, respectively. We determine a near-solar carbon-to-oxygen\nabundance ratio of C/O=0.555$\\pm$0.063 for the host star DH Tau A. We compare\nthis stellar abundance ratio with that of the companion from our previous study\n(C/O=0.54$^{+0.06}_{-0.05}$, Xuan et al. 2024), which also has a near-solar\nvalue. This confirms the chemical homogeneity in the DH Tau system, which\nsuggests a formation scenario for the companion consistent with a direct and\nrelatively fast gravitational collapse, rather than a slow core accretion\nprocess.",
    "pdf_url": "http://arxiv.org/pdf/2411.15591v1",
    "published": "2024-11-23T15:37:58+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15589v1",
    "title": "Deep Learning for THz Channel Estimation and Beamforming Prediction via Sub-6GHz Channel",
    "authors": [
      "Sagnik Bhattacharya",
      "Abhishek K. Gupta"
    ],
    "abstract": "An efficient channel estimation is of vital importance to help THz\ncommunication systems achieve their full potential. Conventional uplink channel\nestimation methods, such as least square estimation, are practically\ninefficient for THz systems because of their large computation overhead. In\nthis paper, we propose an efficient convolutional neural network (CNN) based\nTHz channel estimator that estimates the THz channel factors using uplink\nsub-6GHz channel. Further, we use the estimated THz channel factors to predict\nthe optimal beamformer from a pre-given codebook, using a dense neural network.\nWe not only get rid of the overhead associated with the conventional methods,\nbut also achieve near-optimal spectral efficiency rates using the proposed\nbeamformer predictor. The proposed method also outperforms deep learning based\nbeamformer predictors accepting THz channel matrices as input, thus proving the\nvalidity and efficiency of our sub-6GHz based approach.",
    "pdf_url": "http://arxiv.org/pdf/2411.15589v1",
    "published": "2024-11-23T15:36:35+00:00",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15590v1",
    "title": "From Complexity to Parsimony: Integrating Latent Class Analysis to Uncover Multimodal Learning Patterns in Collaborative Learning",
    "authors": [
      "Lixiang Yan",
      "Dragan Ga≈°eviƒá",
      "Linxuan Zhao",
      "Vanessa Echeverria",
      "Yueqiao Jin",
      "Roberto Martinez-Maldonado"
    ],
    "abstract": "Multimodal Learning Analytics (MMLA) leverages advanced sensing technologies\nand artificial intelligence to capture complex learning processes, but\nintegrating diverse data sources into cohesive insights remains challenging.\nThis study introduces a novel methodology for integrating latent class analysis\n(LCA) within MMLA to map monomodal behavioural indicators into parsimonious\nmultimodal ones. Using a high-fidelity healthcare simulation context, we\ncollected positional, audio, and physiological data, deriving 17 monomodal\nindicators. LCA identified four distinct latent classes: Collaborative\nCommunication, Embodied Collaboration, Distant Interaction, and Solitary\nEngagement, each capturing unique monomodal patterns. Epistemic network\nanalysis compared these multimodal indicators with the original monomodal\nindicators and found that the multimodal approach was more parsimonious while\noffering higher explanatory power regarding students' task and collaboration\nperformances. The findings highlight the potential of LCA in simplifying the\nanalysis of complex multimodal data while capturing nuanced, cross-modality\nbehaviours, offering actionable insights for educators and enhancing the design\nof collaborative learning interventions. This study proposes a pathway for\nadvancing MMLA, making it more parsimonious and manageable, and aligning with\nthe principles of learner-centred education.",
    "pdf_url": "http://arxiv.org/pdf/2411.15590v1",
    "published": "2024-11-23T15:36:35+00:00",
    "categories": [
      "cs.LG",
      "cs.HC",
      "stat.ME"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15588v2",
    "title": "Addendum: Modeling the amplitude and energy decay of a weakly damped harmonic oscillator using the energy dissipation rate and a simple trick (2025 Eur. J. Phys. 46(1) 015004)",
    "authors": [
      "Karlo Lelas",
      "Robert Pezer"
    ],
    "abstract": "We show how to adapt the approach introduced for viscous damping in [1] to\nderive the approximate amplitude decay in the case of damping by a force of\nconstant magnitude (sliding friction) and in the case of damping by a force\nproportional to the square of velocity (air resistance). We obtain two\nfirst-order differential equations from which we obtain the approximate\ntime-dependent amplitudes corresponding to the considered damping forces. Our\napproach is suitable for first-year undergraduates, as it relies on the\nphysical concepts and mathematical techniques they are familiar with.",
    "pdf_url": "http://arxiv.org/pdf/2411.15588v2",
    "published": "2024-11-23T15:36:25+00:00",
    "categories": [
      "physics.class-ph"
    ],
    "primary_category": "physics.class-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.16738v2",
    "title": "Classifier-Free Guidance inside the Attraction Basin May Cause Memorization",
    "authors": [
      "Anubhav Jain",
      "Yuya Kobayashi",
      "Takashi Shibuya",
      "Yuhta Takida",
      "Nasir Memon",
      "Julian Togelius",
      "Yuki Mitsufuji"
    ],
    "abstract": "Diffusion models are prone to exactly reproduce images from the training\ndata. This exact reproduction of the training data is concerning as it can lead\nto copyright infringement and/or leakage of privacy-sensitive information. In\nthis paper, we present a novel perspective on the memorization phenomenon and\npropose a simple yet effective approach to mitigate it. We argue that\nmemorization occurs because of an attraction basin in the denoising process\nwhich steers the diffusion trajectory towards a memorized image. However, this\ncan be mitigated by guiding the diffusion trajectory away from the attraction\nbasin by not applying classifier-free guidance until an ideal transition point\noccurs from which classifier-free guidance is applied. This leads to the\ngeneration of non-memorized images that are high in image quality and\nwell-aligned with the conditioning mechanism. To further improve on this, we\npresent a new guidance technique, opposite guidance, that escapes the\nattraction basin sooner in the denoising process. We demonstrate the existence\nof attraction basins in various scenarios in which memorization occurs, and we\nshow that our proposed approach successfully mitigates memorization.",
    "pdf_url": "http://arxiv.org/pdf/2411.16738v2",
    "published": "2024-11-23T15:36:03+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15587v1",
    "title": "ConAIR:Consistency-Augmented Iterative Interaction Framework to Enhance the Reliability of Code Generation",
    "authors": [
      "Jinhao Dong",
      "Jun Sun",
      "Wenjie Zhang",
      "Jin Song Dong",
      "Dan Hao"
    ],
    "abstract": "Code generation techniques generate code snippets automatically based on the\nproblem requirements in natural language. Recently, large language models\n(LLMs) achieve the SOTA performance on code generation. However, LLMs still\nstruggle at times to generate accurate code, which diminishes their promised\nefficiency as developers must spend significant effort evaluating and debugging\nthe generated code. To improve the reliability and quality of the generated\ncodes, researchers propose to leverage Consistency to obtain a better code\nbased on generating and ranking multiple candidates. The existing approach is\nproblematic as Consistency thinks a code is better when (1) the code pass more\ntests (inter-consistency) (2) more codes share the same behavior\n(intra-consistency). However, because the tests are also generated by LLMs,\nthey could be wrong as well. As a result, majority voting based on testing\nresults is unreliable. Relying solely on consistency is insufficient to address\nthis issue; integrating user feedback is essential for effectively guiding\nconsistency. We show that with minimal human effort, performance can be\nsignificantly enhanced. We propose Consistency-Augmented Iterative Interaction\nFramework to Enhance the Reliability of Code Generation, ConAIR, which is an\napproach that aims to improve the performance of a code generator through two\ndistinctive ingredients, i.e., (1) lightweight user effort for validating the\ncorrectness of selected tests; and (2) a dynamic strategy for ranking,\nlocalizing and correcting multiple tests and codes. Overall, we propose a\nlightweight interaction framework that incorporates user feedback to correct\nidentified tests and guide the iterative process. The iteration rounds are only\n4 in average with the help of consistency. With only lightweight human efforts,\nwe can achieve an improvement of 33% towards the base model.",
    "pdf_url": "http://arxiv.org/pdf/2411.15587v1",
    "published": "2024-11-23T15:26:24+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2411.15586v1",
    "title": "Transparent but Powerful: Explainability, Accuracy, and Generalizability in ADHD Detection from Social Media Data",
    "authors": [
      "D. Wiechmann",
      "E. Kempa",
      "E. Kerz",
      "Y. Qiao"
    ],
    "abstract": "Attention-deficit/hyperactivity disorder (ADHD) is a prevalent mental health\ncondition affecting both children and adults, yet it remains severely\nunderdiagnosed. Recent advances in artificial intelligence, particularly in\nNatural Language Processing (NLP) and Machine Learning (ML), offer promising\nsolutions for scalable and non-invasive ADHD screening methods using social\nmedia data. This paper presents a comprehensive study on ADHD detection,\nleveraging both shallow machine learning models and deep learning approaches,\nincluding BiLSTM and transformer-based models, to analyze linguistic patterns\nin ADHD-related social media text. Our results highlight the trade-offs between\ninterpretability and performance across different models, with BiLSTM offering\na balance of transparency and accuracy. Additionally, we assess the\ngeneralizability of these models using cross-platform data from Reddit and\nTwitter, uncovering key linguistic features associated with ADHD that could\ncontribute to more effective digital screening tools.",
    "pdf_url": "http://arxiv.org/pdf/2411.15586v1",
    "published": "2024-11-23T15:26:01+00:00",
    "categories": [
      "cs.CL",
      "68T50",
      "I.2.7; I.5.1"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15585v1",
    "title": "Boosting Semi-Supervised Scene Text Recognition via Viewing and Summarizing",
    "authors": [
      "Yadong Qu",
      "Yuxin Wang",
      "Bangbang Zhou",
      "Zixiao Wang",
      "Hongtao Xie",
      "Yongdong Zhang"
    ],
    "abstract": "Existing scene text recognition (STR) methods struggle to recognize\nchallenging texts, especially for artistic and severely distorted characters.\nThe limitation lies in the insufficient exploration of character morphologies,\nincluding the monotonousness of widely used synthetic training data and the\nsensitivity of the model to character morphologies. To address these issues,\ninspired by the human learning process of viewing and summarizing, we\nfacilitate the contrastive learning-based STR framework in a self-motivated\nmanner by leveraging synthetic and real unlabeled data without any human cost.\nIn the viewing process, to compensate for the simplicity of synthetic data and\nenrich character morphology diversity, we propose an Online Generation Strategy\nto generate background-free samples with diverse character styles. By excluding\nbackground noise distractions, the model is encouraged to focus on character\nmorphology and generalize the ability to recognize complex samples when trained\nwith only simple synthetic data. To boost the summarizing process, we\ntheoretically demonstrate the derivation error in the previous character\ncontrastive loss, which mistakenly causes the sparsity in the intra-class\ndistribution and exacerbates ambiguity on challenging samples. Therefore, a new\nCharacter Unidirectional Alignment Loss is proposed to correct this error and\nunify the representation of the same characters in all samples by aligning the\ncharacter features in the student model with the reference features in the\nteacher model. Extensive experiment results show that our method achieves SOTA\nperformance (94.7\\% and 70.9\\% average accuracy on common benchmarks and\nUnion14M-Benchmark). Code will be available at https://github.com/qqqyd/ViSu.",
    "pdf_url": "http://arxiv.org/pdf/2411.15585v1",
    "published": "2024-11-23T15:24:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15584v1",
    "title": "FLD+: Data-efficient Evaluation Metric for Generative Models",
    "authors": [
      "Pranav Jeevan",
      "Neeraj Nixon",
      "Amit Sethi"
    ],
    "abstract": "We introduce a new metric to assess the quality of generated images that is\nmore reliable, data-efficient, compute-efficient, and adaptable to new domains\nthan the previous metrics, such as Fr\\'echet Inception Distance (FID). The\nproposed metric is based on normalizing flows, which allows for the computation\nof density (exact log-likelihood) of images from any domain. Thus, unlike FID,\nthe proposed Flow-based Likelihood Distance Plus (FLD+) metric exhibits\nstrongly monotonic behavior with respect to different types of image\ndegradations, including noise, occlusion, diffusion steps, and generative model\nsize. Additionally, because normalizing flow can be trained stably and\nefficiently, FLD+ achieves stable results with two orders of magnitude fewer\nimages than FID (which requires more images to reliably compute Fr\\'echet\ndistance between features of large samples of real and generated images). We\nmade FLD+ computationally even more efficient by applying normalizing flows to\nfeatures extracted in a lower-dimensional latent space instead of using a\npre-trained network. We also show that FLD+ can easily be retrained on new\ndomains, such as medical images, unlike the networks behind previous metrics --\nsuch as InceptionNetV3 pre-trained on ImageNet.",
    "pdf_url": "http://arxiv.org/pdf/2411.15584v1",
    "published": "2024-11-23T15:12:57+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV",
      "I.2.10; I.4.0; I.4.4; I.4.3; I.4.5; I.4.1; I.4.2; I.4.6; I.4.7;\n  I.4.8; I.4.9; I.4.10; I.2.10; I.5.1; I.5.2; I.5.4"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15583v1",
    "title": "Exploring Viewing Modalities in Cinematic Virtual Reality: A Systematic Review and Meta-Analysis of Challenges in Evaluating User Experience",
    "authors": [
      "Yawen Zhang",
      "Han Zhou",
      "Zhoumingju Jiang",
      "Zilu Tang",
      "Tao Luo",
      "Qinyuan Lei"
    ],
    "abstract": "Cinematic Virtual Reality (CVR) is a narrative-driven VR experience that uses\nhead-mounted displays with a 360-degree field of view. Previous research has\nexplored different viewing modalities to enhance viewers' CVR experience. This\nstudy conducted a systematic review and meta-analysis focusing on how different\nviewing modalities, including intervened rotation, avatar assistance, guidance\ncues, and perspective shifting, influence the CVR experience. The study has\nscreened 3444 papers (between 01/01/2013 and 17/06/2023) and selected 45 for\nsystematic review, 13 of which also for meta-analysis. We conducted separate\nrandom-effects meta-analysis and applied Robust Variance Estimation to examine\nCVR viewing modalities and user experience outcomes. Evidence from experiments\nwas synthesized as differences between standardized mean differences (SMDs) of\nuser experience of control group (\"Swivel-Chair\" CVR) and experiment groups. To\nour surprise, we found inconsistencies in the effect sizes across different\nstudies, even with the same viewing modalities. Moreover, in these studies,\nterms such as \"presence,\" \"immersion,\" and \"narrative engagement\" were often\nused interchangeably. Their irregular use of questionnaires, overreliance on\nself-developed questionnaires, and incomplete data reporting may have led to\nunrigorous evaluations of CVR experiences. This study contributes to\nHuman-Computer Interaction (HCI) research by identifying gaps in CVR research,\nemphasizing the need for standardization of terminologies and methodologies to\nenhance the reliability and comparability of future CVR research.",
    "pdf_url": "http://arxiv.org/pdf/2411.15583v1",
    "published": "2024-11-23T15:12:16+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15582v2",
    "title": "EMD: Explicit Motion Modeling for High-Quality Street Gaussian Splatting",
    "authors": [
      "Xiaobao Wei",
      "Qingpo Wuwu",
      "Zhongyu Zhao",
      "Zhuangzhe Wu",
      "Nan Huang",
      "Ming Lu",
      "Ningning MA",
      "Shanghang Zhang"
    ],
    "abstract": "Photorealistic reconstruction of street scenes is essential for developing\nreal-world simulators in autonomous driving. While recent methods based on\n3D/4D Gaussian Splatting (GS) have demonstrated promising results, they still\nencounter challenges in complex street scenes due to the unpredictable motion\nof dynamic objects. Current methods typically decompose street scenes into\nstatic and dynamic objects, learning the Gaussians in either a supervised\nmanner (e.g., w/ 3D bounding-box) or a self-supervised manner (e.g., w/o 3D\nbounding-box). However, these approaches do not effectively model the motions\nof dynamic objects (e.g., the motion speed of pedestrians is clearly different\nfrom that of vehicles), resulting in suboptimal scene decomposition. To address\nthis, we propose Explicit Motion Decomposition (EMD), which models the motions\nof dynamic objects by introducing learnable motion embeddings to the Gaussians,\nenhancing the decomposition in street scenes. The proposed plug-and-play EMD\nmodule compensates for the lack of motion modeling in self-supervised street\nGaussian splatting methods. We also introduce tailored training strategies to\nextend EMD to supervised approaches. Comprehensive experiments demonstrate the\neffectiveness of our method, achieving state-of-the-art novel view synthesis\nperformance in self-supervised settings. The code is available at:\nhttps://qingpowuwu.github.io/emd.",
    "pdf_url": "http://arxiv.org/pdf/2411.15582v2",
    "published": "2024-11-23T15:10:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15581v1",
    "title": "Manipulating the direction of turbulent energy flux via tensor geometry in a two-dimensional flow",
    "authors": [
      "Xinyu Si",
      "Filippo De Lillo",
      "Guido Boffetta",
      "Lei Fang"
    ],
    "abstract": "In turbulent flows, energy flux refers to the transfer of kinetic energy\nacross different scales of motion, a concept that is a cornerstone of\nturbulence theory. The direction of net energy flux is prescribed by the\ndimensionality of the fluid system.",
    "pdf_url": "http://arxiv.org/pdf/2411.15581v1",
    "published": "2024-11-23T15:08:21+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2411.15580v3",
    "title": "TKG-DM: Training-free Chroma Key Content Generation Diffusion Model",
    "authors": [
      "Ryugo Morita",
      "Stanislav Frolov",
      "Brian Bernhard Moser",
      "Takahiro Shirakawa",
      "Ko Watanabe",
      "Andreas Dengel",
      "Jinjia Zhou"
    ],
    "abstract": "Diffusion models have enabled the generation of high-quality images with a\nstrong focus on realism and textual fidelity. Yet, large-scale text-to-image\nmodels, such as Stable Diffusion, struggle to generate images where foreground\nobjects are placed over a chroma key background, limiting their ability to\nseparate foreground and background elements without fine-tuning. To address\nthis limitation, we present a novel Training-Free Chroma Key Content Generation\nDiffusion Model (TKG-DM), which optimizes the initial random noise to produce\nimages with foreground objects on a specifiable color background. Our proposed\nmethod is the first to explore the manipulation of the color aspects in initial\nnoise for controlled background generation, enabling precise separation of\nforeground and background without fine-tuning. Extensive experiments\ndemonstrate that our training-free method outperforms existing methods in both\nqualitative and quantitative evaluations, matching or surpassing fine-tuned\nmodels. Finally, we successfully extend it to other tasks (e.g., consistency\nmodels and text-to-video), highlighting its transformative potential across\nvarious generative applications where independent control of foreground and\nbackground is crucial.",
    "pdf_url": "http://arxiv.org/pdf/2411.15580v3",
    "published": "2024-11-23T15:07:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15579v3",
    "title": "Phase transition of degenerate Tur√°n problems in $p$-norms",
    "authors": [
      "Jun Gao",
      "Xizhi Liu",
      "Jie Ma",
      "Oleg Pikhurko"
    ],
    "abstract": "For a positive real number $p$, the $p$-norm $\\left\\lVert G \\right\\rVert_p$\nof a graph $G$ is the sum of the $p$-th powers of all vertex degrees. We study\nthe maximum $p$-norm $\\mathrm{ex}_{p}(n,F)$ of $F$-free graphs on $n$ vertices.\nF\\\"{u}redi and K\\\"{u}ndgen \\cite{FK06} show that for every bipartite graph $F$,\nthere exists a threshold $p_F$ such that for $p< p_{F}$, the order of\n$\\mathrm{ex}_{p}(n,F)$ is governed by pseudorandom constructions, while for $p\n> p_{F}$, it is governed by star-like constructions, assuming a mild assumption\non the growth rate of $\\mathrm{ex}(n,F)$. The main contribution of our paper is\nextending this result to hypergraph. Moreover, in the case of graph, our proof\ndiffers from that in \\cite{FK06}, offering the advantage of producing the\ncorrect constant factor when $p > p_{F}$.\n  When $p = p_F$, F\\\"{u}redi and K\\\"{u}ndgen proved a general upper bound on\n$\\mathrm{ex}_{p}(n,F)$, tight up to a $\\log n$ factor, and conjectured that\nthis factor is unnecessary. We confirm this conjecture for several well-studied\nbipartite graphs, including one-side degree-bounded graphs and families of\nshort even cycles.",
    "pdf_url": "http://arxiv.org/pdf/2411.15579v3",
    "published": "2024-11-23T14:56:35+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2411.15578v1",
    "title": "Functions of continuous Ces√°ro operators",
    "authors": [
      "Adolf Mirotin"
    ],
    "abstract": "We describe holomorphic functions and fractional powers of Ces\\'{a}ro\noperators in $L^2(\\mathbb{R})$, $L^2(\\mathbb{R}_+)$, and $L^2[0,1]$. Logarithms\nof Ces\\'{a}ro operators are introduced as well and their spectral properties\nare studied. Several examples are considered.",
    "pdf_url": "http://arxiv.org/pdf/2411.15578v1",
    "published": "2024-11-23T14:50:30+00:00",
    "categories": [
      "math.FA",
      "47G10 (Primary) 45P05, 47B15, 47B38 (Secondary)"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15577v2",
    "title": "From MTEB to MTOB: Retrieval-Augmented Classification for Descriptive Grammars",
    "authors": [
      "Albert Kornilov",
      "Tatiana Shavrina"
    ],
    "abstract": "Recent advances in language modeling have demonstrated significant\nimprovements in zero-shot capabilities, including in-context learning,\ninstruction following, and machine translation for extremely under-resourced\nlanguages (Tanzer et al., 2024). However, many languages with limited written\nresources rely primarily on formal descriptions of grammar and vocabulary.\n  In this paper, we introduce a set of benchmarks to evaluate how well models\ncan extract and classify information from the complex descriptions found in\nlinguistic grammars. We present a Retrieval-Augmented Generation (RAG)-based\napproach that leverages these descriptions for downstream tasks such as machine\ntranslation. Our benchmarks encompass linguistic descriptions for 248 languages\nacross 142 language families, focusing on typological features from WALS and\nGrambank.\n  This set of benchmarks offers the first comprehensive evaluation of language\nmodels' in-context ability to accurately interpret and extract linguistic\nfeatures, providing a critical resource for scaling NLP to low-resource\nlanguages. The code and data are publicly available at\n\\url{https://github.com/al-the-eigenvalue/RAG-on-grammars}.",
    "pdf_url": "http://arxiv.org/pdf/2411.15577v2",
    "published": "2024-11-23T14:47:10+00:00",
    "categories": [
      "cs.CL",
      "68-06, 68T50, 68T01",
      "G.3; I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15576v1",
    "title": "MulModSeg: Enhancing Unpaired Multi-Modal Medical Image Segmentation with Modality-Conditioned Text Embedding and Alternating Training",
    "authors": [
      "Chengyin Li",
      "Hui Zhu",
      "Rafi Ibn Sultan",
      "Hassan Bagher Ebadian",
      "Prashant Khanduri",
      "Chetty Indrin",
      "Kundan Thind",
      "Dongxiao Zhu"
    ],
    "abstract": "In the diverse field of medical imaging, automatic segmentation has numerous\napplications and must handle a wide variety of input domains, such as different\ntypes of Computed Tomography (CT) scans and Magnetic Resonance (MR) images.\nThis heterogeneity challenges automatic segmentation algorithms to maintain\nconsistent performance across different modalities due to the requirement for\nspatially aligned and paired images. Typically, segmentation models are trained\nusing a single modality, which limits their ability to generalize to other\ntypes of input data without employing transfer learning techniques.\nAdditionally, leveraging complementary information from different modalities to\nenhance segmentation precision often necessitates substantial modifications to\npopular encoder-decoder designs, such as introducing multiple branched encoding\nor decoding paths for each modality. In this work, we propose a simple\nMulti-Modal Segmentation (MulModSeg) strategy to enhance medical image\nsegmentation across multiple modalities, specifically CT and MR. It\nincorporates two key designs: a modality-conditioned text embedding framework\nvia a frozen text encoder that adds modality awareness to existing segmentation\nframeworks without significant structural modifications or computational\noverhead, and an alternating training procedure that facilitates the\nintegration of essential features from unpaired CT and MR inputs. Through\nextensive experiments with both Fully Convolutional Network and\nTransformer-based backbones, MulModSeg consistently outperforms previous\nmethods in segmenting abdominal multi-organ and cardiac substructures for both\nCT and MR modalities. The code is available in this\n{\\href{https://github.com/ChengyinLee/MulModSeg_2024}{link}}.",
    "pdf_url": "http://arxiv.org/pdf/2411.15576v1",
    "published": "2024-11-23T14:37:01+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15575v1",
    "title": "A hyperbolic relaxation system of the incompressible Navier-Stokes equations with artificial compressibility",
    "authors": [
      "Qian Huang",
      "Christian Rohde",
      "Wen-An Yong",
      "Ruixi Zhang"
    ],
    "abstract": "We introduce a new hyperbolic approximation to the incompressible\nNavier-Stokes equations by incorporating a first-order relaxation and using the\nartificial compressibility method. With two relaxation parameters in the model,\nwe rigorously prove the asymptotic limit of the system towards the\nincompressible Navier-Stokes equations as both parameters tend to zero.\nNotably, the convergence of the approximate pressure variable is achieved by\nthe help of a linear `auxiliary' system and energy-type error estimates of its\ndifferences with the two-parameter model and the Navier-Stokes equations.",
    "pdf_url": "http://arxiv.org/pdf/2411.15575v1",
    "published": "2024-11-23T14:36:52+00:00",
    "categories": [
      "math.AP",
      "35Q30, 76D05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15574v2",
    "title": "A Prototype-Based Framework to Design Scalable Heterogeneous SoCs with Fine-Grained DFS",
    "authors": [
      "Gabriele Montanaro",
      "Andrea Galimberti",
      "Davide Zoni"
    ],
    "abstract": "Frameworks for the agile development of modern system-on-chips are crucial to\ndealing with the complexity of designing such architectures. The open-source\nVespa framework for designing large, FPGA-based, multi-core heterogeneous\nsystem-on-chips enables a faster and more flexible design space exploration of\nsuch architectures and their run-time optimization. Vespa, built on ESP,\nintroduces the capabilities to instantiate multiple replicas of the same\naccelerator in a single network-on-chip node and to partition the\nsystem-on-chips into frequency islands with independent dynamic frequency\nscaling actuators, as well as a dedicated run-time monitoring infrastructure.\nExperiments on 4-by-4 tile-based system-on-chips demonstrate the possibility of\neffectively exploring a multitude of solutions that differ in the replication\nof accelerators, the clock frequencies of the frequency islands, and the tiles'\nplacement, as well as monitoring a variety of statistics related to the traffic\non the interconnect and the accelerators' performance at run time.",
    "pdf_url": "http://arxiv.org/pdf/2411.15574v2",
    "published": "2024-11-23T14:27:03+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2411.17736v1",
    "title": "Matrix representation of the resolvent operator in square-integrable basis and physical application",
    "authors": [
      "A. D. Alhaidari"
    ],
    "abstract": "We obtain simple formulas for the matrix elements of the resolvent operator\n(the Green's function) in any finite set of square integrable basis. These\nformulas are suitable for numerical computations whether the basis elements are\northogonal or not. A byproduct of our findings is an expression for the\nnormalized eigenvectors of a matrix in terms of its eigenvalues. We give a\nphysical application as an illustration of how useful these results can be.",
    "pdf_url": "http://arxiv.org/pdf/2411.17736v1",
    "published": "2024-11-23T14:25:57+00:00",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP",
      "math.SP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15573v1",
    "title": "Navigating Fog Federation: Classifying Current Research and Identifying Challenges",
    "authors": [
      "Dhairya Patel",
      "Shaifali P. Malukani"
    ],
    "abstract": "Fog computing has gained significant attention for its potential to enhance\nresource management and service delivery by bringing computation closer to the\nnetwork edge.While numerous surveys have explored various aspects of fog\ncomputing, there is a distinct gap in the literature when it comes to fog\nfederation, a crucial extension that enables collaboration and resource sharing\nacross multiple fog environments, enhancing scalability, service availability,\nand resource optimization.This paper provides a comprehensive survey of the\nexisting work on fog federation, classifying the contributions from its\ninception to the present.We analyze the various approaches, architectures, and\nmethodologies proposed for fog federation and identify the primary challenges\naddressed in this field.In addition, we explore the simulation tools and\nplatforms utilized in evaluating fog federation systems.Our survey uniquely\ncontributes to the literature by addressing the specific topic of fog\nfederation, offering insights into the current state of the art and\nhighlighting open research gaps and future directions.",
    "pdf_url": "http://arxiv.org/pdf/2411.15573v1",
    "published": "2024-11-23T14:25:00+00:00",
    "categories": [
      "cs.DC",
      "A.1"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15572v1",
    "title": "On Two Conservative HDG Schemes for Nonlinear Klein-Gordon Equation",
    "authors": [
      "Shipra Gupta",
      "Amiya Kumar Pani",
      "Sangita Yadav"
    ],
    "abstract": "In this article, a hybridizable discontinuous Galerkin (HDG) method is\nproposed and analyzed for the Klein-Gordon equation with local Lipschitz-type\nnon-linearity. {\\it A priori} error estimates are derived, and it is proved\nthat approximations of the flux and the displacement converge with order\n$O(h^{k+1}),$ where $h$ is the discretizing parameter and $k$ is the degree of\nthe piecewise polynomials to approximate both flux and displacement variables.\nAfter post-processing of the semi-discrete solution, it is shown that the\npost-processed solution converges with order $O(h^{k+2})$ for $k \\geq 1.$\nMoreover, a second-order conservative finite difference scheme is applied to\ndiscretize in time %second-order convergence in time. and it is proved that the\ndiscrete energy is conserved with optimal error estimates for the completely\ndiscrete method. %Since at each time step, one has to solve a nonlinear system\nof algebraic equations, To avoid solving a nonlinear system of algebraic\nequations at each time step, a non-conservative scheme is proposed, and its\nerror analysis is also briefly established. Moreover, another variant of the\nHDG scheme is analyzed, and error estimates are established. Finally, some\nnumerical experiments are conducted to confirm our theoretical findings.",
    "pdf_url": "http://arxiv.org/pdf/2411.15572v1",
    "published": "2024-11-23T14:15:51+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65N12, 65N22"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15571v1",
    "title": "Dephasing-assisted diffusive dynamics in superconducting quantum circuits",
    "authors": [
      "Yongqi Liang",
      "Changrong Xie",
      "Zechen Guo",
      "Peisheng Huang",
      "Wenhui Huang",
      "Yiting Liu",
      "Jiawei Qiu",
      "Xuandong Sun",
      "Zilin Wang",
      "Xiaohan Yang",
      "Jiawei Zhang",
      "Jiajian Zhang",
      "Libo Zhang",
      "Ji Chu",
      "Weijie Guo",
      "Ji Jiang",
      "Xiayu Linpeng",
      "Song Liu",
      "Jingjing Niu",
      "Yuxuan Zhou",
      "Wenhui Ren",
      "Ziyu Tao",
      "Youpeng Zhong",
      "Dapeng Yu"
    ],
    "abstract": "Random fluctuations caused by environmental noise can lead to decoherence in\nquantum systems. Exploring and controlling such dissipative processes is both\nfundamentally intriguing and essential for harnessing quantum systems to\nachieve practical advantages and deeper insights. In this Letter, we first\ndemonstrate the diffusive dynamics assisted by controlled dephasing noise in\nsuperconducting quantum circuits, contrasting with coherent evolution. We show\nthat dephasing can enhance localization in a superconducting qubit array with\nquasiperiodic order, even in the regime where all eigenstates remain spatially\nextended for the coherent counterpart. Furthermore, by preparing different\nexcitation distributions in the qubit array, we observe that a more localized\ninitial state relaxes to a uniformly distributed mixed state faster with\ndephasing noise, illustrating another counterintuitive phenomenon called Mpemba\neffect, i.e., a far-from-equilibrium state can relax toward the equilibrium\nfaster. These results deepen our understanding of diffusive dynamics at the\nmicroscopic level, and demonstrate controlled dissipative processes as a\nvaluable tool for investigating Markovian open quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2411.15571v1",
    "published": "2024-11-23T14:14:36+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15570v2",
    "title": "Single Antenna Tracking and Localization of RIS-enabled Vehicular Users",
    "authors": [
      "Somayeh Aghashahi",
      "Zolfa Zeinalpour-Yazdi",
      "Aliakbar Tadaion",
      "Mahdi Boloursaz Mashhadi",
      "Ahmed Elzanaty"
    ],
    "abstract": "Reconfigurable Intelligent Surfaces (RISs) are envisioned to be employed in\nnext generation wireless networks to enhance the communication and radio\nlocalization services. In this paper, we propose novel localization and\ntracking algorithms exploiting reflections through RISs at multiple receivers.\nWe utilize a single antenna transmitter (Tx) and multiple single antenna\nreceivers (Rxs) to estimate the position and the velocity of users (e.g.\nvehicles) equipped with RISs. Then, we design the RIS phase shifts to separate\nthe signals from different users. The proposed algorithms exploit the geometry\ninformation of the signal at the RISs to localize and track the users. We also\nconduct a comprehensive analysis of the Cramer-Rao lower bound (CRLB) of the\nlocalization system. Compared to the time of arrival (ToA)-based localization\napproach, the proposed method reduces the localization error by a factor up to\nthree. Also, the simulation results show the accuracy of the proposed tracking\napproach.",
    "pdf_url": "http://arxiv.org/pdf/2411.15570v2",
    "published": "2024-11-23T14:12:52+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15569v1",
    "title": "On the Hochschild Cohomology for Frobenius Kernels",
    "authors": [
      "Tekin Karadag",
      "Daniel K. Nakano"
    ],
    "abstract": "In this paper the authors investigate the structure of the Hochschild\ncohomology for Frobenius kernels. The authors first establish some fundamental\nconstructions to compute Hochschild cohomology by using spectral sequences.\nThis enables us to provide a complete description of the $G$-algebra structure\nof the Hochschild cohomology for the first Frobenius kernel $G_{1}$ where\n$G=SL_{2}$. This computation heavily relies on the calculation of the adjoint\naction on the restricted enveloping algebra.",
    "pdf_url": "http://arxiv.org/pdf/2411.15569v1",
    "published": "2024-11-23T14:10:53+00:00",
    "categories": [
      "math.RT",
      "math.GR",
      "math.RA",
      "20G10, 18G10"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15568v1",
    "title": "Primitive pairs of rational functions with prescribed traces over finite fields",
    "authors": [
      "Shikhamoni Nath",
      "Dhiren Kumar Basnet"
    ],
    "abstract": "Let $q$ be a positive integral power of some prime $p$ and $\\mathbb{F}_{q^m}$\nbe a finite field with $q^m$ elements for some $m \\in \\mathbb{N}$. Here we\nestablish a sufficient condition for the existence of a non-zero element\n$\\epsilon \\in \\mathbb{F}_{q^m}$, such that $(f(\\epsilon), g(\\epsilon))$ is a\nprimitive pair in $\\mathbb{F}_{q^m}$ with two prescribed traces,\n$\\Tr_{{\\mathbb{F}_{q^m}}/{\\mathbb{F}_q}}(\\epsilon)=a$ and\n$\\Tr_{{\\mathbb{F}_{q^m}}/{\\mathbb{F}_q}}(\\epsilon^{-1})=b$, where $f(x), g(x)\n\\in \\mathbb{F}_{q^m}(x)$ are rational functions with some restrictions and $a,\nb \\in \\mathbb{F}_q$. Also, we show that there exists an element $\\epsilon \\in\n\\mathbb{F}_{q^m}$ satisfying our desired properties in all but finitely many\nfields $\\mathbb{F}_{q^m}$ over $\\mathbb{F}_q$. We also calculate possible\nexceptional pairs explicitly for $m\\geq 9$, when degree sums of both the\nrational functions are taken to be 3.",
    "pdf_url": "http://arxiv.org/pdf/2411.15568v1",
    "published": "2024-11-23T14:05:22+00:00",
    "categories": [
      "math.NT",
      "12E20, 11T23"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15567v2",
    "title": "Regional consistency evaluation and sample size calculation under two MRCTs",
    "authors": [
      "Kunhai Qing",
      "Xinru Ren",
      "Shuping Jiang",
      "Ping Yang",
      "Menggang Yu",
      "Jin Xu"
    ],
    "abstract": "Multi-regional clinical trial (MRCT) has been common practice for drug\ndevelopment and global registration. The FDA guidance `Demonstrating\nSubstantial Evidence of Effectiveness for Human Drug and Biological Products\nGuidance for Industry' (FDA, 2019) requires that substantial evidence of\neffectiveness of a drug/biologic product to be demonstrated for market\napproval. In the situations where two pivotal MRCTs are needed to establish\neffectiveness of a specific indication for a drug or biological product, a\nsystematic approach of consistency evaluation for regional effect is crucial.\nIn this paper, we first present some existing regional consistency evaluations\nin a unified way that facilitates regional sample size calculation under the\nsimple fixed effects model. Second, we extend the two commonly used consistency\nassessment criteria of MHLW (2007) in the context of two MRCTs and provide\ntheir evaluation and regional sample size calculation. Numerical studies\ndemonstrate the proposed regional sample size attains the desired probability\nof showing regional consistency. A hypothetical example is presented to\nillustrate the application. We provide an R package for implementation.",
    "pdf_url": "http://arxiv.org/pdf/2411.15567v2",
    "published": "2024-11-23T14:00:30+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15566v1",
    "title": "Sensitivity Analysis on Interaction Effects of Policy-Augmented Bayesian Networks",
    "authors": [
      "Junkai Zhao",
      "Jun Luo",
      "Wei Xie",
      "Zixuan Bai"
    ],
    "abstract": "Biomanufacturing plays an important role in supporting public health and the\ngrowth of the bioeconomy. Modeling and studying the interaction effects among\nvarious input variables is very critical for obtaining a scientific\nunderstanding and process specification in biomanufacturing. In this paper, we\nuse the ShapleyOwen indices to measure the interaction effects for the\npolicy-augmented Bayesian network (PABN) model, which characterizes the risk-\nand science-based understanding of production bioprocess mechanisms. In order\nto facilitate efficient interaction effect quantification, we propose a\nsampling-based simulation estimation framework. In addition, to further improve\nthe computational efficiency, we develop a non-nested simulation algorithm with\nsequential sampling, which can dynamically allocate the simulation budget to\nthe interactions with high uncertainty and therefore estimate the interaction\neffects more accurately under a total fixed budget setting.",
    "pdf_url": "http://arxiv.org/pdf/2411.15566v1",
    "published": "2024-11-23T13:47:35+00:00",
    "categories": [
      "stat.ME",
      "stat.CO"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2411.15565v1",
    "title": "Stabilization of isogeometric finite element method with optimal test functions computed from $L_2$ norm residual minimization",
    "authors": [
      "Marcin ≈Åo≈õ",
      "Tomasz S≈Çu≈ºalec",
      "Maciej Paszy≈Ñski",
      "Eirik Valseth"
    ],
    "abstract": "We compare several stabilization methods in the context of isogeometric\nanalysis and B-spline basis functions, using an advection-dominated\nadvection\\revision{-}diffusion as a model problem. We derive (1) the\nleast-squares finite element method formulation using the framework of\nPetrov-Galerkin method with optimal test functions in the $L_2$ norm, which\nguarantee automatic preservation of the \\emph{inf-sup} condition of the\ncontinuous formulation. We also combine it with the standard Galerkin method to\nrecover (2) the Galerkin/least-squares formulation, and derive coercivity\nconstant bounds valid for B-spline basis functions. The resulting stabilization\nmethod are compared with the least-squares and (3) the Streamline-Upwind\nPetrov-Galerkin (SUPG)method using again the Eriksson-Johnson model problem.\nThe results indicate that least-squares (equivalent to Petrov-Galerkin with\n$L_2$-optimal test functions) outperforms the other stabilization methods for\nsmall P\\'eclet numbers, while strongly advection-dominated problems are better\nhandled with SUPG or Galerkin/least-squares.",
    "pdf_url": "http://arxiv.org/pdf/2411.15565v1",
    "published": "2024-11-23T13:46:48+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "35A25, 65M60, 65D99",
      "G.1.8; G.4; I.6.3"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15564v1",
    "title": "On $L^1$-$L^2$ dichotomy for flat symmetric spaces",
    "authors": [
      "Sanjeev Kumar Gupta",
      "Nico Spronk"
    ],
    "abstract": "For rank 1 flat symmetric spaces, continuous orbital measures admit\nabsolutely continuous convolution squares, except for Cartan type AI. Hence\n$L^1$-$L^2$ dichotomy for these spaces holds true in parallel to the compact\nand non-compact rank 1 symmetric spaces. We also study $L^1$-$L^2$ dichotomy\nfor flat symmetric spaces of ranks $p=2,3$ of type AIII, i.e.\\ associated with\n$SU(p,q)/S(U(p)\\times U(q))$ where $q\\geq p$. For continuous orbital measures\ngiven by regular points $L^1$-$L^2$ dichotomy holds. We study such measures\ngiven by certain singular points when $p=2$, and show that $L^1$-$L^2$\ndichotomy fails. This is the first time such results are observed for any type\nof symmetric spaces of rank 2.",
    "pdf_url": "http://arxiv.org/pdf/2411.15564v1",
    "published": "2024-11-23T13:46:45+00:00",
    "categories": [
      "math.RT",
      "43A90, 43A85, 22E30"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15563v1",
    "title": "In-beam $Œ≥$-ray spectroscopy of negative-parity states of $^{37}$K populated in dissipative reactions",
    "authors": [
      "T. Beck",
      "A. Gade",
      "B. A. Brown",
      "D. Weisshaar",
      "D. Bazin",
      "K. W. Brown",
      "R. J. Charity",
      "P. J. Farris",
      "S. A. Gillespie",
      "A. M. Hill",
      "J. Li",
      "B. Longfellow",
      "W. Reviol",
      "D. Rhodes"
    ],
    "abstract": "In-beam $\\gamma$-ray spectroscopy was used to study excited states of the\nneutron-deficient nucleus $^{37}$K populated in fast-beam inelastic-scattering\nand proton-removal reactions at high-momentum loss. New $\\gamma$-ray\ntransitions and $\\gamma\\gamma$ coincidence relationships were established using\nthe $\\gamma$-ray tracking array GRETINA. The extension of the level scheme up\nto the first $(13/2^-)$ state highlights the potential of this recently\ndemonstrated population pathway for studies of isospin symmetry involving\nmirror-energy differences. The nature of the newly identified states is\ndiscussed in comparison to shell-model calculations with the FSU cross-shell\neffective interaction. The calculated occupation numbers of individual orbitals\nare shown to offer a consistent explanation of the measured mirror-energy\ndifferences between $^{37}$K and $^{37}$Ar.",
    "pdf_url": "http://arxiv.org/pdf/2411.15563v1",
    "published": "2024-11-23T13:43:11+00:00",
    "categories": [
      "nucl-ex"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2411.15562v1",
    "title": "A unified mechanism for the origin and evolution of nuclear magicity",
    "authors": [
      "L. Heitz",
      "J. -P. Ebran",
      "E. Khan",
      "D. Verney"
    ],
    "abstract": "A simple pattern of organisation, the nuclear shell structure, emerges from\nthe complex interactions between nucleons in nuclei and determines, to some\nsignificant degree, nuclear structure properties. Recent experimental\ninvestigations of exotic nuclei revealed a shortfall in our current\nunderstanding of nuclear shell evolution and nuclear magicity. We introduce a\nnovel perspective where the Dirac mass kinetic term, which stems from the\nsingular participation of a spin-0 boson in the nuclear strong force, plays a\npivotal role in generating the nuclear shell structure. Namely, the combination\nof the Dirac mass kinetic Term with the spin-orbit term redefines magic numbers\nboth in stable and exotic nuclei. The identification of this mechanism allows\nto provide a broad understanding of the origin and evolution of nuclear magic\nnumbers.",
    "pdf_url": "http://arxiv.org/pdf/2411.15562v1",
    "published": "2024-11-23T13:42:35+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2411.15561v2",
    "title": "Mass-conserving weak solutions to the continuous nonlinear fragmentation equation in the presence of mass transfer",
    "authors": [
      "Ram Gopal Jaiswal",
      "Ankik Kumar Giri"
    ],
    "abstract": "A mathematical model for the continuous nonlinear fragmentation equation is\nconsidered in the presence of mass transfer. In this paper, we demonstrate the\nexistence of mass-conserving weak solutions to the nonlinear fragmentation\nequation with mass transfer for collision kernels of the form $\\Phi(x,y) =\n\\kappa(x^{{\\sigma_1}} y^{{\\sigma_2}} + y^{{\\sigma_1}} x^{{\\sigma_2}})$,\n$\\kappa>0$, $0 \\leq {\\sigma_1} \\leq {\\sigma_2} \\leq 1$, and ${\\sigma_1} \\neq 1$\nfor $(x, y) \\in \\mathbb{R}_+^2$, with integrable daughter distribution\nfunctions, thereby extending previous results obtained by Giri \\& Lauren\\c cot\n(2021). In particular, the existence of at least one global weak solution is\nshown when the collision kernel exhibits at least linear growth, and one local\nweak solution when the collision kernel exhibits sublinear growth. In both\ncases, finite superlinear moment bounds are obtained for positive times without\nrequiring the finiteness of initial superlinear moments. Additionally, the\nuniqueness of solutions is confirmed in both cases.",
    "pdf_url": "http://arxiv.org/pdf/2411.15561v2",
    "published": "2024-11-23T13:40:19+00:00",
    "categories": [
      "math.AP",
      "45K05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15560v2",
    "title": "Do LLMs Agree on the Creativity Evaluation of Alternative Uses?",
    "authors": [
      "Abdullah Al Rabeyah",
      "Fabr√≠cio G√≥es",
      "Marco Volpe",
      "Talles Medeiros"
    ],
    "abstract": "This paper investigates whether large language models (LLMs) show agreement\nin assessing creativity in responses to the Alternative Uses Test (AUT). While\nLLMs are increasingly used to evaluate creative content, previous studies have\nprimarily focused on a single model assessing responses generated by the same\nmodel or humans. This paper explores whether LLMs can impartially and\naccurately evaluate creativity in outputs generated by both themselves and\nother models. Using an oracle benchmark set of AUT responses, categorized by\ncreativity level (common, creative, and highly creative), we experiment with\nfour state-of-the-art LLMs evaluating these outputs. We test both scoring and\nranking methods and employ two evaluation settings (comprehensive and\nsegmented) to examine if LLMs agree on the creativity evaluation of alternative\nuses. Results reveal high inter-model agreement, with Spearman correlations\naveraging above 0.7 across models and reaching over 0.77 with respect to the\noracle, indicating a high level of agreement and validating the reliability of\nLLMs in creativity assessment of alternative uses. Notably, models do not\nfavour their own responses, instead they provide similar creativity assessment\nscores or rankings for alternative uses generated by other models. These\nfindings suggest that LLMs exhibit impartiality and high alignment in\ncreativity evaluation, offering promising implications for their use in\nautomated creativity assessment.",
    "pdf_url": "http://arxiv.org/pdf/2411.15560v2",
    "published": "2024-11-23T13:34:50+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2411.15559v1",
    "title": "Radio Halo Detection in MWA Data using Deep Neural Networks and Generative Data Augmentation",
    "authors": [
      "Ashutosh K. Mishra",
      "Emma Tolley",
      "Shreyam Parth Krishna",
      "Jean-Paul Kneib"
    ],
    "abstract": "Detecting diffuse radio emission, such as from halos, in galaxy clusters is\ncrucial for understanding large-scale structure formation in the universe.\nTraditional methods, which rely on X-ray and Sunyaev-Zeldovich (SZ) cluster\npre-selection, introduce biases that limit our understanding of the full\npopulation of diffuse radio sources. In this work, we provide a possible\nresolution for this astrophysical tension by developing a machine learning (ML)\nframework capable of unbiased detection of diffuse emission, using a limited\nreal dataset like those from the Murchison Widefield Array (MWA). We generate\nfor the first time radio halo images using Wasserstein Generative Adversarial\nNetworks (WGANs) and Denoising Diffusion Probabilistic Models (DDPMs), and\napply them to train a neural network classifier independent of pre-selection\nmethods. The halo images generated by DDPMs are of higher quality than those\nproduced by WGANs. The diffusion-supported classifier with a multi-head\nattention block achieved the best average validation accuracy of 95.93% over 10\nruns, using 36 clusters for training and 10 for testing, without further\nhyperparameter tuning. Using our classifier, we rediscovered 9/12 halos (75%\ndetection rate) from the MeerKAT Galaxy Cluster Legacy Survey (MGCLS)\nCatalogue, and 5/8 halos (63% detection rate) from the Planck Sunyaev-Zeldovich\nCatalogue 2 (PSZ2) within the GaLactic and Extragalactic All-sky MWA (GLEAM)\nsurvey. In addition, we identify 11 potential new halos, minihalos, or\ncandidates in the COSMOS field using XMM-chandra-detected clusters in GLEAM\ndata. This work demonstrates the potential of ML for unbiased detection of\ndiffuse emission and provides labeled datasets for further study.",
    "pdf_url": "http://arxiv.org/pdf/2411.15559v1",
    "published": "2024-11-23T13:31:20+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15558v1",
    "title": "Reassessing Layer Pruning in LLMs: New Insights and Methods",
    "authors": [
      "Yao Lu",
      "Hao Cheng",
      "Yujie Fang",
      "Zeyu Wang",
      "Jiaheng Wei",
      "Dongwei Xu",
      "Qi Xuan",
      "Xiaoniu Yang",
      "Zhaowei Zhu"
    ],
    "abstract": "Although large language models (LLMs) have achieved remarkable success across\nvarious domains, their considerable scale necessitates substantial\ncomputational resources, posing significant challenges for deployment in\nresource-constrained environments. Layer pruning, as a simple yet effective\ncompression method, removes layers of a model directly, reducing computational\noverhead. However, what are the best practices for layer pruning in LLMs? Are\nsophisticated layer selection metrics truly effective? Does the LoRA (Low-Rank\nApproximation) family, widely regarded as a leading method for pruned model\nfine-tuning, truly meet expectations when applied to post-pruning fine-tuning?\nTo answer these questions, we dedicate thousands of GPU hours to benchmarking\nlayer pruning in LLMs and gaining insights across multiple dimensions. Our\nresults demonstrate that a simple approach, i.e., pruning the final 25\\% of\nlayers followed by fine-tuning the \\texttt{lm\\_head} and the remaining last\nthree layer, yields remarkably strong performance. Following this guide, we\nprune Llama-3.1-8B-It and obtain a model that outperforms many popular LLMs of\nsimilar size, such as ChatGLM2-6B, Vicuna-7B-v1.5, Qwen1.5-7B and Baichuan2-7B.\nWe release the optimal model weights on Huggingface, and the code is available\non GitHub.",
    "pdf_url": "http://arxiv.org/pdf/2411.15558v1",
    "published": "2024-11-23T13:31:16+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15557v3",
    "title": "LAGUNA: LAnguage Guided UNsupervised Adaptation with structured spaces",
    "authors": [
      "Anxhelo Diko",
      "Antonino Furnari",
      "Luigi Cinque",
      "Giovanni Maria Farinella"
    ],
    "abstract": "Unsupervised domain adaptation remains a critical challenge in enabling the\nknowledge transfer of models across unseen domains. Existing methods struggle\nto balance the need for domain-invariant representations with preserving\ndomain-specific features, which is often due to alignment approaches that\nimpose the projection of samples with similar semantics close in the latent\nspace despite their drastic domain differences. We introduce LAGUNA - LAnguage\nGuided UNsupervised Adaptation with structured spaces, a novel approach that\nshifts the focus from aligning representations in absolute coordinates to\naligning the relative positioning of equivalent concepts in latent spaces.\nLAGUNA defines a domain-agnostic structure upon the semantic/geometric\nrelationships between class labels in language space and guides adaptation,\nensuring that the organization of samples in visual space reflects reference\ninter-class relationships while preserving domain-specific characteristics. We\nempirically demonstrate LAGUNA's superiority in domain adaptation tasks across\nfour diverse images and video datasets. Remarkably, LAGUNA surpasses previous\nworks in 18 different adaptation scenarios across four diverse image and video\ndatasets with average accuracy improvements of +3.32% on DomainNet, +5.75% in\nGeoPlaces, +4.77% on GeoImnet, and +1.94% mean class accuracy improvement on\nEgoExo4D.",
    "pdf_url": "http://arxiv.org/pdf/2411.15557v3",
    "published": "2024-11-23T13:26:53+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15556v2",
    "title": "ReWind: Understanding Long Videos with Instructed Learnable Memory",
    "authors": [
      "Anxhelo Diko",
      "Tinghuai Wang",
      "Wassim Swaileh",
      "Shiyan Sun",
      "Ioannis Patras"
    ],
    "abstract": "Vision-Language Models (VLMs) are crucial for applications requiring\nintegrated understanding textual and visual information. However, existing VLMs\nstruggle with long videos due to computational inefficiency, memory\nlimitations, and difficulties in maintaining coherent understanding across\nextended sequences. To address these challenges, we introduce ReWind, a novel\nmemory-based VLM designed for efficient long video understanding while\npreserving temporal fidelity. ReWind operates in a two-stage framework. In the\nfirst stage, ReWind maintains a dynamic learnable memory module with a novel\n\\textbf{read-perceive-write} cycle that stores and updates instruction-relevant\nvisual information as the video unfolds. This module utilizes learnable queries\nand cross-attentions between memory contents and the input stream, ensuring low\nmemory requirements by scaling linearly with the number of tokens. In the\nsecond stage, we propose an adaptive frame selection mechanism guided by the\nmemory content to identify instruction-relevant key moments. It enriches the\nmemory representations with detailed spatial information by selecting a few\nhigh-resolution frames, which are then combined with the memory contents and\nfed into a Large Language Model (LLM) to generate the final answer. We\nempirically demonstrate ReWind's superior performance in visual question\nanswering (VQA) and temporal grounding tasks, surpassing previous methods on\nlong video benchmarks. Notably, ReWind achieves a +13\\% score gain and a +12\\%\naccuracy improvement on the MovieChat-1K VQA dataset and an +8\\% mIoU increase\non Charades-STA for temporal grounding.",
    "pdf_url": "http://arxiv.org/pdf/2411.15556v2",
    "published": "2024-11-23T13:23:22+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15555v3",
    "title": "Improving the Transferability of Adversarial Attacks on Face Recognition with Diverse Parameters Augmentation",
    "authors": [
      "Fengfan Zhou",
      "Bangjie Yin",
      "Hefei Ling",
      "Qianyu Zhou",
      "Wenxuan Wang"
    ],
    "abstract": "Face Recognition (FR) models are vulnerable to adversarial examples that\nsubtly manipulate benign face images, underscoring the urgent need to improve\nthe transferability of adversarial attacks in order to expose the blind spots\nof these systems. Existing adversarial attack methods often overlook the\npotential benefits of augmenting the surrogate model with diverse\ninitializations, which limits the transferability of the generated adversarial\nexamples. To address this gap, we propose a novel method called Diverse\nParameters Augmentation (DPA) attack method, which enhances surrogate models by\nincorporating diverse parameter initializations, resulting in a broader and\nmore diverse set of surrogate models. Specifically, DPA consists of two key\nstages: Diverse Parameters Optimization (DPO) and Hard Model Aggregation (HMA).\nIn the DPO stage, we initialize the parameters of the surrogate model using\nboth pre-trained and random parameters. Subsequently, we save the models in the\nintermediate training process to obtain a diverse set of surrogate models.\nDuring the HMA stage, we enhance the feature maps of the diversified surrogate\nmodels by incorporating beneficial perturbations, thereby further improving the\ntransferability. Experimental results demonstrate that our proposed attack\nmethod can effectively enhance the transferability of the crafted adversarial\nface examples.",
    "pdf_url": "http://arxiv.org/pdf/2411.15555v3",
    "published": "2024-11-23T13:22:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15554v1",
    "title": "Small monoids generating varieties with uncountably many subvarieties",
    "authors": [
      "Sergey V. Gusev"
    ],
    "abstract": "An algebra that generates a variety with uncountably many subvarieties is\nsaid to be of type $2^{\\aleph_0}$. We show that the Rees quotient monoid\n$M(aabb)$ of order ten is of type $2^{\\aleph_0}$, thereby affirmatively\nanswering a recent question of Glasson. As a corollary, we exhibit a new\nexample of type $2^{\\aleph_0}$ monoid of order six, which turns out to be\nminimal and the first of its kind that is finitely based.",
    "pdf_url": "http://arxiv.org/pdf/2411.15554v1",
    "published": "2024-11-23T13:19:26+00:00",
    "categories": [
      "math.GR",
      "20M07"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15553v2",
    "title": "Improving Transferable Targeted Attacks with Feature Tuning Mixup",
    "authors": [
      "Kaisheng Liang",
      "Xuelong Dai",
      "Yanjie Li",
      "Dong Wang",
      "Bin Xiao"
    ],
    "abstract": "Deep neural networks (DNNs) exhibit vulnerability to adversarial examples\nthat can transfer across different DNN models. A particularly challenging\nproblem is developing transferable targeted attacks that can mislead DNN models\ninto predicting specific target classes. While various methods have been\nproposed to enhance attack transferability, they often incur substantial\ncomputational costs while yielding limited improvements. Recent clean feature\nmixup methods use random clean features to perturb the feature space but lack\noptimization for disrupting adversarial examples, overlooking the advantages of\nattack-specific perturbations. In this paper, we propose Feature Tuning Mixup\n(FTM), a novel method that enhances targeted attack transferability by\ncombining both random and optimized noises in the feature space. FTM introduces\nlearnable feature perturbations and employs an efficient stochastic update\nstrategy for optimization. These learnable perturbations facilitate the\ngeneration of more robust adversarial examples with improved transferability.\nWe further demonstrate that attack performance can be enhanced through an\nensemble of multiple FTM-perturbed surrogate models. Extensive experiments on\nthe ImageNet-compatible dataset across various DNN models demonstrate that our\nmethod achieves significant improvements over state-of-the-art methods while\nmaintaining low computational cost.",
    "pdf_url": "http://arxiv.org/pdf/2411.15553v2",
    "published": "2024-11-23T13:18:25+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15552v1",
    "title": "Self-diffusion anomalies of an odd tracer in soft-core media",
    "authors": [
      "Pietro Luigi Muzzeddu",
      "Erik Kalz",
      "Andrea Gambassi",
      "Abhinav Sharma",
      "Ralf Metzler"
    ],
    "abstract": "Odd-diffusive systems, characterised by broken time-reversal and/or parity\nsymmetry, have recently been shown to display counterintuitive features such as\ninteraction-enhanced dynamics in the dilute limit. Here we we extend the\ninvestigation to the high-density limit of an odd tracer embedded in a\nsoft-Gaussian core medium (GCM) using a field-theoretic approach based on the\nDean-Kawasaki equation. Our theory reveals that interactions can enhance the\ndynamics of an odd tracer even in dense systems. We demonstrate that oddness\nresults in a complete reversal of the well-known self-diffusion\n($D_\\mathrm{s}$) anomaly of the GCM. Ordinarily, $D_\\mathrm{s}$ exhibits a\nnon-monotonic trend with increasing density, approaching but remaining below\nthe interaction-free diffusion, $D_0$, ($D_\\mathrm{s} < D_0$) so that\n$D_\\mathrm{s} \\uparrow D_0$ at high densities. In contrast, for an odd tracer,\nself-diffusion is enhanced ($D_\\mathrm{s}> D_0$) and the GCM anomaly is\ninverted, displaying $D_\\mathrm{s} \\downarrow D_0$ at high densities. The\ntransition between the standard and reversed GCM anomaly is governed by the\ntracer's oddness, with a critical oddness value at which the tracer diffuses as\na free particle ($D_\\mathrm{s} \\approx D_0$) across all densities. We validate\nour theoretical predictions with Brownian dynamics simulations, finding strong\nagreement between the two.",
    "pdf_url": "http://arxiv.org/pdf/2411.15552v1",
    "published": "2024-11-23T13:17:34+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "physics.bio-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2411.15551v1",
    "title": "NeRF Inpainting with Geometric Diffusion Prior and Balanced Score Distillation",
    "authors": [
      "Menglin Zhang",
      "Xin Luo",
      "Yunwei Lan",
      "Chang Liu",
      "Rui Li",
      "Kaidong Zhang",
      "Ganlin Yang",
      "Dong Liu"
    ],
    "abstract": "Recent advances in NeRF inpainting have leveraged pretrained diffusion models\nto enhance performance. However, these methods often yield suboptimal results\ndue to their ineffective utilization of 2D diffusion priors. The limitations\nmanifest in two critical aspects: the inadequate capture of geometric\ninformation by pretrained diffusion models and the suboptimal guidance provided\nby existing Score Distillation Sampling (SDS) methods. To address these\nproblems, we introduce GB-NeRF, a novel framework that enhances NeRF inpainting\nthrough improved utilization of 2D diffusion priors. Our approach incorporates\ntwo key innovations: a fine-tuning strategy that simultaneously learns\nappearance and geometric priors and a specialized normal distillation loss that\nintegrates these geometric priors into NeRF inpainting. We propose a technique\ncalled Balanced Score Distillation (BSD) that surpasses existing methods such\nas Score Distillation (SDS) and the improved version, Conditional Score\nDistillation (CSD). BSD offers improved inpainting quality in appearance and\ngeometric aspects. Extensive experiments show that our method provides superior\nappearance fidelity and geometric consistency compared to existing approaches.",
    "pdf_url": "http://arxiv.org/pdf/2411.15551v1",
    "published": "2024-11-23T13:17:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.16737v2",
    "title": "Federated Learning in Chemical Engineering: A Tutorial on a Framework for Privacy-Preserving Collaboration Across Distributed Data Sources",
    "authors": [
      "Siddhant Dutta",
      "Iago Leal de Freitas",
      "Pedro Maciel Xavier",
      "Claudio Miceli de Farias",
      "David Esteban Bernal Neira"
    ],
    "abstract": "Federated Learning (FL) is a decentralized machine learning approach that has\ngained attention for its potential to enable collaborative model training\nacross clients while protecting data privacy, making it an attractive solution\nfor the chemical industry. This work aims to provide the chemical engineering\ncommunity with an accessible introduction to the discipline. Supported by a\nhands-on tutorial and a comprehensive collection of examples, it explores the\napplication of FL in tasks such as manufacturing optimization, multimodal data\nintegration, and drug discovery while addressing the unique challenges of\nprotecting proprietary information and managing distributed datasets. The\ntutorial was built using key frameworks such as $\\texttt{Flower}$ and\n$\\texttt{TensorFlow Federated}$ and was designed to provide chemical engineers\nwith the right tools to adopt FL in their specific needs. We compare the\nperformance of FL against centralized learning across three different datasets\nrelevant to chemical engineering applications, demonstrating that FL will often\nmaintain or improve classification performance, particularly for complex and\nheterogeneous data. We conclude with an outlook on the open challenges in\nfederated learning to be tackled and current approaches designed to remediate\nand improve this framework.",
    "pdf_url": "http://arxiv.org/pdf/2411.16737v2",
    "published": "2024-11-23T13:16:06+00:00",
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15550v1",
    "title": "Class Order Disorder in Wikidata and First Fixes",
    "authors": [
      "Peter F. Patel-Schneider",
      "Ege Atacan Doƒüan"
    ],
    "abstract": "Wikidata has a large ontology with classes at several orders. The Wikidata\nontology has long been known to have violations of class order and information\nrelated to class order that appears suspect. SPARQL queries were evaluated\nagainst Wikidata to determine the prevalence of several kinds of violations and\nsuspect information and the results analyzed. Some changes were manually made\nto Wikidata to remove some of these results and the queries rerun, showing the\neffect of the changes. Suggestions are provided on how the problems uncovered\nmight be addressed, either though better tooling or involvement of the Wikidata\ncommunity.",
    "pdf_url": "http://arxiv.org/pdf/2411.15550v1",
    "published": "2024-11-23T13:15:13+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15549v1",
    "title": "Mean equicontinuous factor maps",
    "authors": [
      "Till Hauser"
    ],
    "abstract": "Mean equicontinity is a well studied notion for actions. We propose a\ndefinition of mean equicontinuous factor maps that generalizes mean\nequicontinuity to the relative context. For this we work in the context of\ncountable amenable groups. We show that a factor map is equicontinuous, if and\nonly if it is mean equicontinuous and distal. Furthermore, we show that a\nfactor map is topo-isomorphic, if and only if it is mean equicontinuous and\nproximal. We present that the notions of topo-isomorphy and Banach proximality\ncoincide for all factor maps. In the second part of the paper we turn our\nattention to decomposition and composition properties. It is well known that a\nmean equicontinuous action is a topo-isomorphic extension of an equicontinuous\naction. In the context of minimal and the context of weakly mean equicontinuous\nactions, respectively, we show that any mean equicontinuous factor map can be\ndecomposed into an equicontinuous factor map after a topo-isomorphic factor\nmap. Furthermore, for factor maps between weakly mean equicontinuous actions we\nshow that a factor map is mean equicontinuous, if and only if it is the\ncomposition of an equicontinuous factor map after a topo-isomorphic factor map.\nWe will see that this decomposition is always unique up to conjugacy.",
    "pdf_url": "http://arxiv.org/pdf/2411.15549v1",
    "published": "2024-11-23T13:08:11+00:00",
    "categories": [
      "math.DS",
      "37B05"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2411.15548v2",
    "title": "An unconditional distribution learning advantage with shallow quantum circuits",
    "authors": [
      "N. Pirnay",
      "S. Jerbi",
      "J. -P. Seifert",
      "J. Eisert"
    ],
    "abstract": "One of the core challenges of research in quantum computing is concerned with\nthe question whether quantum advantages can be found for near-term quantum\ncircuits that have implications for practical applications. Motivated by this\nmindset, in this work, we prove an unconditional quantum advantage in the\nprobably approximately correct (PAC) distribution learning framework with\nshallow quantum circuit hypotheses. We identify a meaningful generative\ndistribution learning problem where constant-depth quantum circuits using one\nand two qubit gates (QNC^0) are superior compared to constant-depth bounded\nfan-in classical circuits (NC^0) as a choice for hypothesis classes. We hence\nprove a PAC distribution learning separation for shallow quantum circuits over\nshallow classical circuits. We do so by building on recent results by Bene\nWatts and Parham on unconditional quantum advantages for sampling tasks with\nshallow circuits, which we technically uplift to a hyperplane learning problem,\nidentifying non-local correlations as the origin of the quantum advantage.",
    "pdf_url": "http://arxiv.org/pdf/2411.15548v2",
    "published": "2024-11-23T13:03:22+00:00",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15547v1",
    "title": "On the $z$-classes of Palindromic automorphisms of Free Groups",
    "authors": [
      "Krishnendu Gongopadhyay",
      "Lokenath Kundu",
      "Shashank Vikram Singh"
    ],
    "abstract": "The palindromic automorphism group is a subgroup of the automorphism group\n$Aut(F_3).$ We establish a necessary and sufficient condition for a matrix in\n$GL_n(\\mathbb{Z})$ representing a palindromic automorphism of $F_n.$ We prove\nthat the number of the $z$-classes in $\\Pi A(F_n)$ is infinite. We further\nclassify the conjugacy classes of the reducible palindromic automorphisms.",
    "pdf_url": "http://arxiv.org/pdf/2411.15547v1",
    "published": "2024-11-23T13:03:05+00:00",
    "categories": [
      "math.GR",
      "20F28"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15546v2",
    "title": "Structure Functions of Rotation Measures Revealing the Origin of Fast Radio Bursts",
    "authors": [
      "Rui-Nan Li",
      "Zhen-Yin Zhao",
      "Qin Wu",
      "Shuang-Xi Yi",
      "Fa-Yin Wang"
    ],
    "abstract": "The structure function (SF) analysis is a powerful tool for studying plasma\nturbulence. Theoretically, the SF of Faraday rotation measure (RM) is expected\nto include a geometric component due to the relative orientation of sightlines\nthrough an ordered magnetic field. However, observational evidence for this\ncomponent remains elusive. Here, we report that the SFs of the binary PSR\nB1744-24A and the repeating fast radio burst (FRB) 20201124A exhibit both a\nperiodic geometric component, caused by binary orbital motion, and a flat\nstatistical component. The statistical component, induced by stochastic\nfluctuations in electron density and magnetic field, aligns with RM scatter\nderived from pulse depolarization. These findings indicate that FRB 20201124A\nhas a binary origin and suggest that the periodic geometric component can serve\nas a diagnostic tool to identify binary companions.",
    "pdf_url": "http://arxiv.org/pdf/2411.15546v2",
    "published": "2024-11-23T12:55:16+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2411.15545v1",
    "title": "Majority-Agreed Key Distribution using Absolutely Maximally Entangled Stabilizer States",
    "authors": [
      "Sowrabh Sudevan",
      "Ramij Rahaman",
      "Sourin Das"
    ],
    "abstract": "In [Phys. Rev. A 77, 060304(R),(2008)], Facchi et al. introduced absolutely\nmaximally entangled (AME) states and also suggested ``majority-agreed key\ndistribution\"(MAKD) as a possible application for such states. In MAKD, the\nqubits of an AME state are distributed one each to many spatially separated\nparties. AME property makes it necessary that quantum key distribution(QKD)\nbetween any two parties can only be performed with the cooperation of a\nmajority of parties. Our contributions to MAKD are, $(1)$ We recognize that\nstabilizer structure of the shared state is a useful addition to MAKD and prove\nthat the cooperation of any majority of parties(including the two communicants)\nis necessary and sufficient for QKD between any two parties sharing AME\nstabilizer states. Considering the rarity of qubit AME states, we extended this\nresult to the qudit case. $(2)$ We generalize to shared graph states that are\nnot necessarily AME. We show that the stabilizer structure of graph states\nallows for QKD between any inseparable bipartition of qubits. Inseparability in\ngraph states is visually apparent in the connectivity of its underlying\nmathematical graph. We exploit this connectivity to demonstrate conference keys\nand multiple independent keys per shared state. Recent experimental and\ntheoretical progress in graph state preparation and self-testing make these\nprotocols feasible in the near future.",
    "pdf_url": "http://arxiv.org/pdf/2411.15545v1",
    "published": "2024-11-23T12:54:19+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.16736v1",
    "title": "ChemSafetyBench: Benchmarking LLM Safety on Chemistry Domain",
    "authors": [
      "Haochen Zhao",
      "Xiangru Tang",
      "Ziran Yang",
      "Xiao Han",
      "Xuanzhi Feng",
      "Yueqing Fan",
      "Senhao Cheng",
      "Di Jin",
      "Yilun Zhao",
      "Arman Cohan",
      "Mark Gerstein"
    ],
    "abstract": "The advancement and extensive application of large language models (LLMs)\nhave been remarkable, including their use in scientific research assistance.\nHowever, these models often generate scientifically incorrect or unsafe\nresponses, and in some cases, they may encourage users to engage in dangerous\nbehavior. To address this issue in the field of chemistry, we introduce\nChemSafetyBench, a benchmark designed to evaluate the accuracy and safety of\nLLM responses. ChemSafetyBench encompasses three key tasks: querying chemical\nproperties, assessing the legality of chemical uses, and describing synthesis\nmethods, each requiring increasingly deeper chemical knowledge. Our dataset has\nmore than 30K samples across various chemical materials. We incorporate\nhandcrafted templates and advanced jailbreaking scenarios to enhance task\ndiversity. Our automated evaluation framework thoroughly assesses the safety,\naccuracy, and appropriateness of LLM responses. Extensive experiments with\nstate-of-the-art LLMs reveal notable strengths and critical vulnerabilities,\nunderscoring the need for robust safety measures. ChemSafetyBench aims to be a\npivotal tool in developing safer AI technologies in chemistry. Our code and\ndataset are available at https://github.com/HaochenZhao/SafeAgent4Chem.\nWarning: this paper contains discussions on the synthesis of controlled\nchemicals using AI models.",
    "pdf_url": "http://arxiv.org/pdf/2411.16736v1",
    "published": "2024-11-23T12:50:33+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15544v1",
    "title": "Stochastic calculus of run-and-tumble motion: an applied perspective",
    "authors": [
      "Paul C Bressloff"
    ],
    "abstract": "The run-and-tumble particle (RTP) is one of the simplest examples of an\nactive particle in which the direction of constant motion randomly switches. In\nthe one-dimensional (1D) case this means switching between rightward and\nleftward velocities. Most theoretical studies of RTPs are based on the analysis\nof the Chapman-Kolmogorov (CK) differential equation describing the evolution\nof the joint probability densities for particle position and velocity state. In\nthis paper we develop an alternative, probabilistic framework of 1D RTP motion\nbased on the stochastic calculus of Poisson and diffusion processes. In\nparticular, we show how a generalisation of It\\^o's lemma provides a direct\nlink between sample paths of an RTP and the underlying CK equation. This allows\nus to incorporate various non-trivial extensions in a systematic fashion,\nincluding stochastic resetting and partially absorbing sticky boundaries. The\nvelocity switching process and resetting process are represented by a pair of\nindependent Poisson processes, whereas a sticky boundary is modelled using a\nboundary layer. We then use the probabilistic formulation to calculate\nstochastic entropy production along individual trajectories of an RTP, and show\nhow the corresponding Gibbs-Shannon entropy is recovered by averaging over the\nensemble of sample paths. Finally, we extend the probabilistic framework to a\npopulation of RTPs and use this to explore the effects of global resetting.",
    "pdf_url": "http://arxiv.org/pdf/2411.15544v1",
    "published": "2024-11-23T12:48:02+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2411.15543v2",
    "title": "Observations of the galaxy cluster CL 0217+70 and its surrounding region at 1.4 GHz with the Sardinia Radio Telescope",
    "authors": [
      "P. Marchegiani",
      "V. Vacca",
      "F. Govoni",
      "M. Murgia",
      "F. Loi",
      "L. Feretti"
    ],
    "abstract": "We present the results of observations performed with the Sardinia Radio\nTelescope (SRT) at 1.3-1.8 GHz of the galaxy cluster CL 0217+70 and a $3^\\circ\n\\times 3^\\circ$ region around it. We combine the SRT data with archival Very\nLarge Array (VLA) data to obtain images having the VLA angular resolution, but\nsensitive up to largest scales. The SRT+VLA combination allows us to derive a\ncluster radio halo flux density higher by $\\sim14\\%$ compared to the VLA-only\ndata, although consistent within $1\\sigma$. We derive a spectral index map\nbetween 140 MHz and 1.4 GHz, finding an extended region with spectral index\n$\\alpha\\sim0.6$ on the external part of the south-eastern candidate relic,\nquestioning the real nature of this relic. Moreover, we detect an extended\nemission outside the cluster in the south-eastern area, having an angular\nextension of $\\sim50$ arcmin on the longer side, which would correspond to\n$\\sim10$ Mpc at the cluster distance; the emissivity that this region would\nhave if located at the cluster distance is in line with the one estimated in\ncandidate filaments of the cosmic web; however, the peculiar orientation of\nthis region, not pointed towards the cluster, and the low Galactic latitude of\nthis cluster suggest that its origin can be due to a foreground emission\noriginating in our Galaxy.",
    "pdf_url": "http://arxiv.org/pdf/2411.15543v2",
    "published": "2024-11-23T12:39:59+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2411.15542v1",
    "title": "Hierarchical Cross-Attention Network for Virtual Try-On",
    "authors": [
      "Hao Tang",
      "Bin Ren",
      "Pingping Wu",
      "Nicu Sebe"
    ],
    "abstract": "In this paper, we present an innovative solution for the challenges of the\nvirtual try-on task: our novel Hierarchical Cross-Attention Network (HCANet).\nHCANet is crafted with two primary stages: geometric matching and try-on, each\nplaying a crucial role in delivering realistic virtual try-on outcomes. A key\nfeature of HCANet is the incorporation of a novel Hierarchical Cross-Attention\n(HCA) block into both stages, enabling the effective capture of long-range\ncorrelations between individual and clothing modalities. The HCA block enhances\nthe depth and robustness of the network. By adopting a hierarchical approach,\nit facilitates a nuanced representation of the interaction between the person\nand clothing, capturing intricate details essential for an authentic virtual\ntry-on experience. Our experiments establish the prowess of HCANet. The results\nshowcase its performance across both quantitative metrics and subjective\nevaluations of visual realism. HCANet stands out as a state-of-the-art\nsolution, demonstrating its capability to generate virtual try-on results that\nexcel in accuracy and realism. This marks a significant step in advancing\nvirtual try-on technologies.",
    "pdf_url": "http://arxiv.org/pdf/2411.15542v1",
    "published": "2024-11-23T12:39:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15541v1",
    "title": "Derivation of recursive formulas for integrals of Hermite polynomial products and their applications",
    "authors": [
      "Phan Quang Son",
      "Tran Duong Anh-Tai",
      "Le Minh Khang",
      "Nguyen Duy Vy",
      "Vinh N. T. Pham"
    ],
    "abstract": "In this work, we derive three recursive formulas for the integrals of\nproducts of Hermite polynomials. The derivation is notably straightforward,\nrelying solely on the well-established properties of Hermite polynomials and\nthe technique of integration by parts. These results hold broad relevance\nacross various fields of physics and mathematics. Specifically, they would be\napplied to accurately compute two- and three-body matrix elements in ab initio\nsimulations of one-dimensional few-body systems confined in harmonic traps.\nAdditionally, we provide a numerical subroutine that implements these recursive\nformulas, which accompanies this work.",
    "pdf_url": "http://arxiv.org/pdf/2411.15541v1",
    "published": "2024-11-23T12:30:16+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15540v2",
    "title": "Optical-Flow Guided Prompt Optimization for Coherent Video Generation",
    "authors": [
      "Hyelin Nam",
      "Jaemin Kim",
      "Dohun Lee",
      "Jong Chul Ye"
    ],
    "abstract": "While text-to-video diffusion models have made significant strides, many\nstill face challenges in generating videos with temporal consistency. Within\ndiffusion frameworks, guidance techniques have proven effective in enhancing\noutput quality during inference; however, applying these methods to video\ndiffusion models introduces additional complexity of handling computations\nacross entire sequences. To address this, we propose a novel framework called\nMotionPrompt that guides the video generation process via optical flow.\nSpecifically, we train a discriminator to distinguish optical flow between\nrandom pairs of frames from real videos and generated ones. Given that prompts\ncan influence the entire video, we optimize learnable token embeddings during\nreverse sampling steps by using gradients from a trained discriminator applied\nto random frame pairs. This approach allows our method to generate visually\ncoherent video sequences that closely reflect natural motion dynamics, without\ncompromising the fidelity of the generated content. We demonstrate the\neffectiveness of our approach across various models.",
    "pdf_url": "http://arxiv.org/pdf/2411.15540v2",
    "published": "2024-11-23T12:26:52+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15539v2",
    "title": "Large Language Model with Region-guided Referring and Grounding for CT Report Generation",
    "authors": [
      "Zhixuan Chen",
      "Yequan Bie",
      "Haibo Jin",
      "Hao Chen"
    ],
    "abstract": "Computed tomography (CT) report generation is crucial to assist radiologists\nin interpreting CT volumes, which can be time-consuming and labor-intensive.\nExisting methods primarily only consider the global features of the entire\nvolume, making it struggle to focus on specific regions and potentially missing\nabnormalities. To address this issue, we propose Reg2RG, the first\nregion-guided referring and grounding framework for CT report generation, which\nenhances diagnostic performance by focusing on anatomical regions within the\nvolume. Specifically, we utilize masks from a universal segmentation module to\ncapture local features for each referring region. A local feature decoupling\n(LFD) strategy is proposed to preserve the local high-resolution details with\nlittle computational overhead. Then the local features are integrated with\nglobal features to capture inter-regional relationships within a cohesive\ncontext. Moreover, we propose a novel region-report alignment (RRA) training\nstrategy. It leverages the recognition of referring regions to guide the\ngeneration of region-specific reports, enhancing the model's referring and\ngrounding capabilities while also improving the report's interpretability. A\nlarge language model (LLM) is further employed as the language decoder to\ngenerate reports from integrated visual features, facilitating region-level\ncomprehension. Extensive experiments on two large-scale chest CT-report\ndatasets demonstrate the superiority of our method, which outperforms several\nstate-of-the-art methods in terms of both natural language generation and\nclinical efficacy metrics while preserving promising interpretability. The code\nis available at https://github.com/zhi-xuan-chen/Reg2RG.",
    "pdf_url": "http://arxiv.org/pdf/2411.15539v2",
    "published": "2024-11-23T12:25:06+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15538v1",
    "title": "That Flick is Sick: Gyroscope Integration in Xbox Controllers",
    "authors": [
      "Jhervey Edric Cheng",
      "Stacy Selena Kalaw",
      "James Patrick Kok",
      "Alyssa Ysabelle Meneses",
      "Richard Sy",
      "Jordan Aiko Deja"
    ],
    "abstract": "Gyroscope integration in Xbox controllers offers new possibilities for\nenhancing gaming experiences, particularly in first-person shooter (FPS) games.\nTo investigate its potential, we conducted an empirical study with 11\nparticipants, comparing aim precision and reaction times across three input\nmethods: a computer mouse, a standard Xbox controller, and a gyroscope-enabled\ncontroller. Participants completed an aim training task, revealing the mouse as\nthe most accurate device, followed by the standard controller. Interestingly,\nthe gyroscope-enabled controller showed reduced accuracy and slower reaction\ntimes, attributed to challenges in sensitivity and control. Participant\nfeedback highlighted areas for improvement, including refined sensitivity\nsettings, control stability, and software design. These findings underscore the\nneed for design innovations, such as camera rotation limits and optimized\nsensitivity thresholds, to make gyroscope-enabled controllers more competitive.\nFuture work should consider diverse gamer profiles and extended evaluation\ncontexts to better understand the role of gyroscopes in gaming interfaces.",
    "pdf_url": "http://arxiv.org/pdf/2411.15538v1",
    "published": "2024-11-23T12:21:15+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15537v4",
    "title": "MUNBa: Machine Unlearning via Nash Bargaining",
    "authors": [
      "Jing Wu",
      "Mehrtash Harandi"
    ],
    "abstract": "Machine Unlearning (MU) aims to selectively erase harmful behaviors from\nmodels while retaining the overall utility of the model. As a multi-task\nlearning problem, MU involves balancing objectives related to forgetting\nspecific concepts/data and preserving general performance. A naive integration\nof these forgetting and preserving objectives can lead to gradient conflicts\nand dominance, impeding MU algorithms from reaching optimal solutions. To\naddress the gradient conflict and dominance issue, we reformulate MU as a\ntwo-player cooperative game, where the two players, namely, the forgetting\nplayer and the preservation player, contribute via their gradient proposals to\nmaximize their overall gain and balance their contributions. To this end,\ninspired by the Nash bargaining theory, we derive a closed-form solution to\nguide the model toward the Pareto stationary point. Our formulation of MU\nguarantees an equilibrium solution, where any deviation from the final state\nwould lead to a reduction in the overall objectives for both players, ensuring\noptimality in each objective. We evaluate our algorithm's effectiveness on a\ndiverse set of tasks across image classification and image generation.\nExtensive experiments with ResNet, vision-language model CLIP, and\ntext-to-image diffusion models demonstrate that our method outperforms\nstate-of-the-art MU algorithms, achieving a better trade-off between forgetting\nand preserving. Our results also highlight improvements in forgetting\nprecision, preservation of generalization, and robustness against adversarial\nattacks.",
    "pdf_url": "http://arxiv.org/pdf/2411.15537v4",
    "published": "2024-11-23T12:18:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15536v1",
    "title": "Four-Qubit CHSH Games",
    "authors": [
      "Joaquim Jusseau",
      "Hamza Jaffali",
      "Fr√©d√©ric Holweck"
    ],
    "abstract": "In this paper, the CHSH quantum game is extended to four players. This is\nachieved by exploring all possible 4-variable Boolean functions to identify\nthose that yield a game scenario with a quantum advantage using a specific\nentangled state. Notably, two new four-player quantum games are presented. In\none game, the optimal quantum strategy is achieved when players share a\n$GHZ$-state, breaking the traditional 10\\% gain observed in 2 and 3 qubit CHSH\ngames and achieving a 22.5\\% gap. In the other game, players gain a greater\nadvantage using a $W$-state as their quantum resource. Quantum games with other\nfour-qubit entangled states are also explored. To demonstrate the results,\nthese game scenarios are implemented on an online quantum computer, and the\nadvantage of the respective quantum resource for each game is experimentally\nverified.",
    "pdf_url": "http://arxiv.org/pdf/2411.15536v1",
    "published": "2024-11-23T12:16:09+00:00",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15535v1",
    "title": "Teaching Shortest Path Algorithms With a Robot and Overlaid Projections",
    "authors": [
      "Pavel Jolakoski",
      "Jordan Aiko Deja",
      "Klen ƒåopiƒç Pucihar",
      "Matja≈æ Kljun"
    ],
    "abstract": "Robots have the potential to enhance teaching of advanced computer science\ntopics, making abstract concepts more tangible and interactive. In this paper,\nwe present Timmy-a GoPiGo robot augmented with projections to demonstrate\nshortest path algorithms in an interactive learning environment. We integrated\na JavaScript-based application that is projected around the robot, which allows\nusers to construct graphs and visualise three different shortest path\nalgorithms with colour-coded edges and vertices. Animated graph exploration and\ntraversal are augmented by robot movements. To evaluate Timmy, we conducted two\nuser studies. An initial study (n=10) to explore the feasibility of this type\nof teaching where participants were just observing both robot-synced and the\non-screen-only visualisations. And a pilot study (n=6) where participants\nactively interacted with the system, constructed graphs and selected desired\nalgorithms. In both studies we investigated the preferences towards the system\nand not the teaching outcome. Initial findings suggest that robots offer an\nengaging tool for teaching advanced algorithmic concepts, but highlight the\nneed for further methodological refinements and larger-scale studies to fully\nevaluate their effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2411.15535v1",
    "published": "2024-11-23T12:16:03+00:00",
    "categories": [
      "cs.RO",
      "cs.HC"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2411.15534v1",
    "title": "Kuramoto model with stochastic resetting and coupling through an external medium",
    "authors": [
      "Paul C Bressloff"
    ],
    "abstract": "Most studies of collective phenomena in oscillator networks focus on directly\ncoupled systems as exemplified by the classical Kuramoto model. However, there\nare growing number of examples in which oscillators interact indirectly via a\ncommon external medium, including bacterial quorum sensing (QS) networks,\npedestrians walking on a bridge, and centrally coupled lasers. In this paper we\nanalyze the effects of stochastic phase resetting on a Kuramoto model with\nindirect coupling. All the phases are simultaneously reset to their initial\nvalues at a random sequence of times generated from a Poisson process. On the\nother hand, the external environmental state is not reset. We first derive a\ncontinuity equation for the population density in the presence of resetting and\nshow how the resulting density equation is itself subject to stochastic\nresetting. We then use an Ott-Antonsen (OA) ansatz to reduce the\ninfinite-dimensional system to a four-dimensional piecewise deterministic\nsystem with subsystem resetting. The latter is used to explore how\nsynchronization depends on a cell density parameter. (In bacterial QS this\nrepresents the ratio of the population cell volume and the extracellular\nvolume.) At high densities we recover the OA dynamics of the classical Kuramoto\nmodel with global resetting. On the other hand, at low densities, we show how\nsubsystem resetting has a major effect on collective synchronization, ranging\nfrom noise-induced transitions to slow/fast dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2411.15534v1",
    "published": "2024-11-23T12:08:29+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "nlin.AO"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2411.15533v1",
    "title": "Development of a Low-Cost Prosthetic Hand Using Electromyography and Machine Learning",
    "authors": [
      "Mosab Diab",
      "Ashraf Mohammed",
      "Yinlai Jiang"
    ],
    "abstract": "Electromyography (EMG) is a measure of muscular electrical activity and is\nused in many clinical/biomedical disciplines and modern human computer\ninteraction. Myo-electric prosthetics analyze and classify the electrical\nsignals recorded from the residual limb. The classified output is then used to\ncontrol the position of motors in a robotic hand and a movement is produced.\nThe aim of this project is to develop a low-cost and effective myo-electric\nprosthetic hand that would meet the needs of amputees in developing countries.\nThe proposed prosthetic hand should be able to accurately classify five\ndifferent patterns (gestures) using EMG recordings from three muscles and\ncontrol a robotic hand accordingly. The robotic hand is composed of two servo\nmotors allowing for two degrees of freedom. After establishing an efficient\nsignal acquisition and amplification system, EMG signals were thoroughly\nanalyzed in the frequency and time domain. Features were extracted from both\ndomains and a shallow neural network was trained on the two sets of data.\nResults yielded an average classification accuracy of 97.25% and 95.85% for the\ntime and frequency domains respectively. Furthermore, results showed a faster\ncomputation and response for the time domain analysis; hence, it was adopted\nfor the classification system. A wrist rotation mechanism was designed and\ntested to add significant functionality to the prosthetic. The mechanism is\ncontrolled by two of the five gestures, one for each direction. Which added a\nthird degree of freedom to the overall design. Finally, a tactile sensory\nfeedback system which uses force sensors and vibration motors was developed to\nenable sensation of the force inflicted on the hand for the user.",
    "pdf_url": "http://arxiv.org/pdf/2411.15533v1",
    "published": "2024-11-23T12:05:14+00:00",
    "categories": [
      "cs.RO",
      "cs.HC"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2411.16735v1",
    "title": "Efficient Proton Transport Modelling for Proton Beam Therapy and Biological Quantification",
    "authors": [
      "Ben S. Ashby",
      "Veronika Chronholm",
      "Daniel K. Hajnal",
      "Alex Lukyanov",
      "Katherine MacKenzie",
      "Aaron Pim",
      "Tristan Pryer"
    ],
    "abstract": "In this work, we present a fundamental mathematical model for proton\ntransport, tailored to capture the key physical processes underpinning Proton\nBeam Therapy (PBT). The model provides a robust and computationally efficient\nframework for exploring various aspects of PBT, including dose delivery, linear\nenergy transfer, treatment planning and the evaluation of relative biological\neffectiveness. Our findings highlight the potential of this model as a\ncomplementary tool to more complex and computationally intensive simulation\ntechniques currently used in clinical practice.",
    "pdf_url": "http://arxiv.org/pdf/2411.16735v1",
    "published": "2024-11-23T12:02:56+00:00",
    "categories": [
      "physics.med-ph",
      "35Q92, 92C50, 49N90"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.01845v1",
    "title": "Statistical and Mathematical Evidence of Rigged Parliamentary Elections in Georgia, 2024",
    "authors": [
      "Lazare Osmanov",
      "Levan Ghaghanidze",
      "Saba Sigua",
      "Temur Begishvili",
      "Keso Bostoghanashvili"
    ],
    "abstract": "The official data provided by \"Central Election Commission\" was analyzed,\nrevealing irregularities that raised reasonable suspicion of election\nmanipulation by the winning ``Georgian Dream Party.\" However, these suspicions\nalone were insufficient to provide concrete evidence. A computational approach\nwas developed based on the official data to address this. Through this\nanalysis, one method estimated the number of manipulated votes to range between\n140,000 and 200,000, while another approach estimated a broader range of 90,000\nto 245,000 votes. Notably, both methods identified the most probable number of\nmanipulated votes as 175,000, providing a strong mathematical basis to\nsubstantiate the claim of election falsification.",
    "pdf_url": "http://arxiv.org/pdf/2412.01845v1",
    "published": "2024-11-23T11:57:31+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15532v1",
    "title": "FFT-Enhanced Low-Complexity Near-Field Super-Resolution Sensing",
    "authors": [
      "Yuxiao Wu",
      "Huizhi Wang",
      "Yong Zeng"
    ],
    "abstract": "In this letter, a fast Fourier transform (FFT)-enhanced low-complexity\nsuper-resolution sensing algorithm for near-field source localization with both\nangle and range estimation is proposed. Most traditional near-field source\nlocalization algorithms suffer from excessive computational complexity or\nincompatibility with existing array architectures. To address such issues, this\nletter proposes a novel near-field sensing algorithm that combines coarse and\nfine granularity of spectrum peak search. Specifically, a spectral pattern in\nthe angle domain is first constructed using FFT to identify potential angles\nwhere sources are present. Afterwards, a 1D beamforming is performed in the\ndistance domain to obtain potential distance regions. Finally, a refined 2D\nmultiple signal classification (MUSIC) is conducted within each narrowed\nangle-distance region to estimate the precise location of the sources.\nNumerical results demonstrate that the proposed algorithm can significantly\nreduce the computational complexity of 2D spectrum peak searches and achieve\ntarget localization with high-resolution.",
    "pdf_url": "http://arxiv.org/pdf/2411.15532v1",
    "published": "2024-11-23T11:55:14+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15531v2",
    "title": "The Gravito-Phononic Effect: A Quantum Signature of Linearised Gravity",
    "authors": [
      "Germain Tobar",
      "Oscar Berg"
    ],
    "abstract": "The photo-electric effect was a historic milestone in the development of\nquantum theory, revealing the first evidence of discrete energy of the\nelectromagnetic field through hallmark signatures such as the threshold\nfrequency, intensity-independent energy transfer, and the near instantaneous\nejection of photo-electrons. Here, we discuss the photo-electric effect through\nthe lens of semi-classical, quantum, and neo-classical models. We provide a\npedagogical outline for how two coupled harmonic oscillators, under a\nbeam-splitter interaction, can exhibit hallmark signatures analogous to the\nphoto-electric effect, including resonance conditions and quantised energy\nabsorption. We discuss the implications of this model for recently proposed\ngraviton detection protocols. This further clarifies that a gravitational\nversion of the photo-electric effect, modelled as discrete energy transfer\nbetween harmonic oscillators can provide the first evidence of the graviton.",
    "pdf_url": "http://arxiv.org/pdf/2411.15531v2",
    "published": "2024-11-23T11:50:35+00:00",
    "categories": [
      "quant-ph",
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15530v1",
    "title": "QEQR: An Exploration of Query Expansion Methods for Question Retrieval in CQA Services",
    "authors": [
      "Yasin Ghafourian",
      "Sajad Movahedi",
      "Azadeh Shakery"
    ],
    "abstract": "CQA services are valuable sources of knowledge that can be used to find\nanswers to users' information needs. In these services, question retrieval aims\nto help users with their information needs by finding similar questions to\ntheirs. However, finding similar questions is obstructed by the lexical gap\nthat exists between relevant questions. In this work, we target this problem by\nusing query expansion methods. We use word-similarity-based methods, propose a\nquestion-similarity-based method and selective expansion of these methods to\nexpand a question that's been submitted and mitigate the lexical gap problem.\nOur best method achieves a significant relative improvement of 1.8\\% compared\nto the best-performing baseline without query expansion.",
    "pdf_url": "http://arxiv.org/pdf/2411.15530v1",
    "published": "2024-11-23T11:47:03+00:00",
    "categories": [
      "cs.IR",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15529v1",
    "title": "Uplink Multiple Access with Heterogeneous Blocklength and Reliability Constraints: Discrete Signaling with Treating Interference as Noise",
    "authors": [
      "Min Qiu",
      "Yu-Chih Huang",
      "Jinhong Yuan"
    ],
    "abstract": "We consider the uplink multiple access of heterogeneous users, e.g.,\nultra-reliable low-latency communications (URLLC) and enhanced mobile broadband\n(eMBB) users. Each user has its own reliability requirement and blocklength\nconstraint, and users transmitting longer blocks suffer from heterogeneous\ninterference. On top of that, the decoding of URLLC messages cannot leverage\nsuccessive interference cancellation (SIC) owing to the stringent latency\nrequirements. This can significantly degrade the spectral efficiency of all\nURLLC users when the interference is strong. To overcome this issue, we propose\na new multiple access scheme employing discrete signaling and treating\ninterference as noise (TIN) decoding, i.e., without SIC. Specifically, to\nhandle heterogeneous interference while maintaining the single-user encoding\nand decoding complexities, each user uses a single channel code and maps its\ncoded bits onto sub-blocks of symbols, where the underlying constellations can\nbe different. We demonstrate theoretically and numerically that the proposed\nscheme employing quadrature amplitude modulations and TIN decoding can perform\nvery close to the benchmark scheme based on Gaussian signaling with perfect SIC\ndecoding. Interestingly, we show that the proposed scheme does not need to use\nall the transmit power budget, but also can sometimes even outperform the\nbenchmark scheme.",
    "pdf_url": "http://arxiv.org/pdf/2411.15529v1",
    "published": "2024-11-23T11:45:26+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15528v1",
    "title": "On the wave equation with variable exponent nonlinearity and distributive delay",
    "authors": [
      "Mohammad Kafini"
    ],
    "abstract": "In this work, we are concerned with a nonlinear wave equation with variable\nexponents. A distributive delay is imposed into the damping term with variable\nexponents nonlinearity. Firstly, we show that the global nonexistence time can\nbe dominated. Secondly, global existence of solutions is shown under some\nsuitable conditions on the initial data. Finally, the decay rates of that\nsolutions are established as well.",
    "pdf_url": "http://arxiv.org/pdf/2411.15528v1",
    "published": "2024-11-23T11:42:28+00:00",
    "categories": [
      "math.AP",
      "35B05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15527v1",
    "title": "Haar-Laplacian for directed graphs",
    "authors": [
      "Theodor-Adrian Badea",
      "Bogdan Dumitrescu"
    ],
    "abstract": "This paper introduces a novel Laplacian matrix aiming to enable the\nconstruction of spectral convolutional networks and to extend the signal\nprocessing applications for directed graphs. Our proposal is inspired by a\nHaar-like transformation and produces a Hermitian matrix which is not only in\none-to-one relation with the adjacency matrix, preserving both direction and\nweight information, but also enjoys desirable additional properties like\nscaling robustness, sensitivity, continuity, and directionality. We take a\ntheoretical standpoint and support the conformity of our approach with the\nspectral graph theory. Then, we address two use-cases: graph learning (by\nintroducing HaarNet, a spectral graph convolutional network built with our\nHaar-Laplacian) and graph signal processing. We show that our approach gives\nbetter results in applications like weight prediction and denoising on directed\ngraphs.",
    "pdf_url": "http://arxiv.org/pdf/2411.15527v1",
    "published": "2024-11-23T11:42:16+00:00",
    "categories": [
      "cs.LG",
      "cs.SI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15526v1",
    "title": "Multi-scale Cascaded Large-Model for Whole-body ROI Segmentation",
    "authors": [
      "Rui Hao",
      "Dayu Tan",
      "Yansen Su",
      "Chunhou Zheng"
    ],
    "abstract": "Organs-at-risk segmentation is critical for ensuring the safety and precision\nof radiotherapy and surgical procedures. However, existing methods for\norgans-at-risk image segmentation often suffer from uncertainties and biases in\ntarget selection, as well as insufficient model validation experiments,\nlimiting their generality and reliability in practical applications. To address\nthese issues, we propose an innovative cascaded network architecture called the\nMulti-scale Cascaded Fusing Network (MCFNet), which effectively captures\ncomplex multi-scale and multi-resolution features. MCFNet includes a Sharp\nExtraction Backbone and a Flexible Connection Backbone, which respectively\nenhance feature extraction in the downsampling and skip-connection stages. This\ndesign not only improves segmentation accuracy but also ensures computational\nefficiency, enabling precise detail capture even in low-resolution images. We\nconduct experiments using the A6000 GPU on diverse datasets from 671 patients,\nincluding 36,131 image-mask pairs across 10 different datasets. MCFNet\ndemonstrates strong robustness, performing consistently well across 10\ndatasets. Additionally, MCFNet exhibits excellent generalizability, maintaining\nhigh accuracy in different clinical scenarios. We also introduce an adaptive\nloss aggregation strategy to further optimize the model training process,\nimproving both segmentation accuracy and efficiency. Through extensive\nvalidation, MCFNet demonstrates superior performance compared to existing\nmethods, providing more reliable image-guided support. Our solution aims to\nsignificantly improve the precision and safety of radiotherapy and surgical\nprocedures, advancing personalized treatment. The code has been made available\non GitHub:https://github.com/Henry991115/MCFNet.",
    "pdf_url": "http://arxiv.org/pdf/2411.15526v1",
    "published": "2024-11-23T11:39:06+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15525v1",
    "title": "Botfip-LLM: An Enhanced Multimodal Scientific Computing Framework Leveraging Knowledge Distillation from Large Language Models",
    "authors": [
      "Tianhao Chen",
      "Pengbo Xu",
      "Pengbo Xu"
    ],
    "abstract": "In recent years, the introduction of AI technologies has brought\ntransformative changes to scientific computing. However, AI models typically\nfocus on single-task and single-modal data processing, limiting their\napplication. To address this, multimodal scientific computing frameworks have\nbecome a trend. The Botfip framework aligns function images with symbolic\noperation trees through multimodal training, extracting deep scientific\ninformation. However, Botfip struggles with processing Formula Strings, leading\nto inadequate understanding in multimodal learning. To enhance Botfip's\nlearning of Formula Strings and expand its applicability to related tasks, we\npropose the Botfip-LLM framework based on knowledge distillation, incorporating\npre-trained large language models for aligning symbolic tree data. Experimental\nanalysis shows that the choice of LLM is crucial, with ChatGLM-2 outperforming\nothers in training and testing. Botfip-LLM not only improves performance,\ngeneralization, and extrapolation over the original Botfip model but also\nsignificantly enhances applicability to Formula String-related tasks, enabling\nmore diverse task handling.",
    "pdf_url": "http://arxiv.org/pdf/2411.15525v1",
    "published": "2024-11-23T11:33:16+00:00",
    "categories": [
      "cs.SC"
    ],
    "primary_category": "cs.SC"
  },
  {
    "id": "http://arxiv.org/abs/2412.08650v1",
    "title": "Capacitive Touch Sensor Modeling With a Physics-informed Neural Network and Maxwell's Equations",
    "authors": [
      "Ganyong Mo",
      "Krishna Kumar Narayanan",
      "David Castells-Rufas",
      "Jordi Carrabina"
    ],
    "abstract": "Maxwell's equations are the fundamental equations for understanding electric\nand magnetic field interactions and play a crucial role in designing and\noptimizing sensor systems like capacitive touch sensors, which are widely\nprevalent in automotive switches and smartphones. Ensuring robust functionality\nand stability of the sensors in dynamic environments necessitates profound\ndomain expertise and computationally intensive multi-physics simulations. This\npaper introduces a novel approach using a Physics-Informed Neural Network\n(PINN) based surrogate model to accelerate the design process. The PINN model\nsolves the governing electrostatic equations describing the interaction between\na finger and a capacitive sensor. Inputs include spatial coordinates from a 3D\ndomain encompassing the finger, sensor, and PCB, along with finger distances.\nBy incorporating the electrostatic equations directly into the neural network's\nloss function, the model captures the underlying physics. The learned model\nthus serves as a surrogate sensor model on which inference can be carried out\nin seconds for different experimental setups without the need to run\nsimulations. Efficacy results evaluated on unseen test cases demonstrate the\nsignificant potential of PINNs in accelerating the development and design\noptimization of capacitive touch sensors.",
    "pdf_url": "http://arxiv.org/pdf/2412.08650v1",
    "published": "2024-11-23T11:22:24+00:00",
    "categories": [
      "physics.comp-ph",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15524v1",
    "title": "The Detection of H$_2$O Maser Emission from mid-IR Red Galaxies",
    "authors": [
      "C. Y. Kuo",
      "C. Y. Tai",
      "A. Constantin",
      "J. A. Braatz",
      "H. H. Chung",
      "B. Y. Chen",
      "D. W. Pesce",
      "C. M. V. Impellizzeri",
      "F. Gao",
      "Y. Y. Chang"
    ],
    "abstract": "We report the detection of H$_2$O maser emission in 4 out of 77 (5.2%) mid-IR\nred galaxies that meet the color criteria of $W1-W2 > 0.5$ and $W1-W4 > 7$ and\nare classified as Type-2 AGNs based on optical, near-IR, and mid-IR spectral\nenergy distribution (SED) fitting. Here, $W1$, $W2$, and $W4$ represent the IR\nmagnitudes at 3.4, 4.6, and 22 micron, respectively, as measured by the\nWide-field Infrared Survey Explorer. Three of the four newly identified maser\ngalaxies are classified as either Seyfert 2 or LINER systems, but none are disk\nmaser systems. Our analysis indicates that AGN identifications based solely on\nSED fitting are unreliable, resulting in an unexpectedly low detection rate. By\nrestricting our sample to optically classified Type 2 AGNs that satisfy the\nmid-IR color criteria, we achieve a maser detection rate of ~13-18%, aligning\nwith previous predictions for mid-IR red sources. These selection criteria are\nthe most effective to date for facilitating new maser detections, particularly\nin light of the recent identification of additional Type 2 AGNs identified from\nongoing galaxy and AGN surveys.",
    "pdf_url": "http://arxiv.org/pdf/2411.15524v1",
    "published": "2024-11-23T11:08:58+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15523v1",
    "title": "Enhancing Grammatical Error Detection using BERT with Cleaned Lang-8 Dataset",
    "authors": [
      "Rahul Nihalani",
      "Kushal Shah"
    ],
    "abstract": "This paper presents an improved LLM based model for Grammatical Error\nDetection (GED), which is a very challenging and equally important problem for\nmany applications. The traditional approach to GED involved hand-designed\nfeatures, but recently, Neural Networks (NN) have automated the discovery of\nthese features, improving performance in GED. Traditional rule-based systems\nhave an F1 score of 0.50-0.60 and earlier machine learning models give an F1\nscore of 0.65-0.75, including decision trees and simple neural networks.\nPrevious deep learning models, for example, Bi-LSTM, have reported F1 scores\nwithin the range from 0.80 to 0.90. In our study, we have fine-tuned various\ntransformer models using the Lang8 dataset rigorously cleaned by us. In our\nexperiments, the BERT-base-uncased model gave an impressive performance with an\nF1 score of 0.91 and accuracy of 98.49% on training data and 90.53% on testing\ndata, also showcasing the importance of data cleaning. Increasing model size\nusing BERT-large-uncased or RoBERTa-large did not give any noticeable\nimprovements in performance or advantage for this task, underscoring that\nlarger models are not always better. Our results clearly show how far rigorous\ndata cleaning and simple transformer-based models can go toward significantly\nimproving the quality of GED.",
    "pdf_url": "http://arxiv.org/pdf/2411.15523v1",
    "published": "2024-11-23T10:57:41+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15522v3",
    "title": "On the magnetic Dirichlet to Neumann operator on the disk -- strong diamagnetism and strong magnetic field limit--",
    "authors": [
      "Helffer Bernard",
      "Nicoleau Fran√ßois"
    ],
    "abstract": "Inspired by a paper by T. Chakradhar, K. Gittins, G. Habib and N.\nPeyerimhoff, we analyze their conjecture that the ground state energy of the\nmagnetic Dirichlet-to-Neumann operator on the disk tends to $+\\infty$ as the\nmagnetic field tends to $+\\infty$. This is an important step towards the\nanalysis of the curvature effect in the case of general domains in $\\mathbb\nR^2$.",
    "pdf_url": "http://arxiv.org/pdf/2411.15522v3",
    "published": "2024-11-23T10:56:17+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "math.SP",
      "35P20, 35Q40"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15521v1",
    "title": "An Affordable Experimental Technique for SRAM Write Margin Characterization for Nanometer CMOS Technologies",
    "authors": [
      "Bartomeu Alorda",
      "Cristian Carmona",
      "Gabriel Torrens",
      "Sebastia Bota"
    ],
    "abstract": "Increased process variability and reliability issues present a major\nchallenge for future SRAM trends. Non-intrusive and accurate SRAM stability\nmeasurement is crucial for estimating yield in large SRAM arrays. Conventional\nSRAM variability metrics require including test structures that cannot be used\nto investigate cell bit fails in functional SRAM arrays. This work proposes the\nWord Line Voltage Margin (WLVM), defined as the maximum allowed word-line\nvoltage drop during write operations, as a metric for the experimental\ncharacterization of write stability of SRAM cells. Their experimental\nmeasurement can be attained with minimal design modifications, while achieving\ngood correlation with existing writability metrics. To demonstrate its\nfeasibility, the distribution of WLVM values has been measured in an SRAM\nprototype implemented in 65 nm CMOS technology. The dependence of the metric\nwith the width of the transistors has been also analysed, demonstrating their\nutility in post-process write stability characterization.",
    "pdf_url": "http://arxiv.org/pdf/2411.15521v1",
    "published": "2024-11-23T10:48:35+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15520v1",
    "title": "Quiver presentations and Schur--Weyl duality for Khovanov arc algebras",
    "authors": [
      "Chris Bowman",
      "Maud De Visscher",
      "Alice Dell'Arciprete",
      "Amit Hazi",
      "Rob Muth",
      "Catharina Stroppel"
    ],
    "abstract": "We provide an ${\\rm Ext}$-quiver and relations presentation of the Khovanov\narc algebras and prove a precise analogue of the Kleshchev--Martin conjecture\nin this setting.",
    "pdf_url": "http://arxiv.org/pdf/2411.15520v1",
    "published": "2024-11-23T10:47:41+00:00",
    "categories": [
      "math.RT",
      "math.CO",
      "math.QA"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15519v1",
    "title": "Risk Management with Feature-Enriched Generative Adversarial Networks (FE-GAN)",
    "authors": [
      "Ling Chen"
    ],
    "abstract": "This paper investigates the application of Feature-Enriched Generative\nAdversarial Networks (FE-GAN) in financial risk management, with a focus on\nimproving the estimation of Value at Risk (VaR) and Expected Shortfall (ES).\nFE-GAN enhances existing GANs architectures by incorporating an additional\ninput sequence derived from preceding data to improve model performance. Two\nspecialized GANs models, the Wasserstein Generative Adversarial Network (WGAN)\nand the Tail Generative Adversarial Network (Tail-GAN), were evaluated under\nthe FE-GAN framework. The results demonstrate that FE-GAN significantly\noutperforms traditional architectures in both VaR and ES estimation. Tail-GAN,\nleveraging its task-specific loss function, consistently outperforms WGAN in ES\nestimation, while both models exhibit similar performance in VaR estimation.\nDespite these promising results, the study acknowledges limitations, including\nreliance on highly correlated temporal data and restricted applicability to\nother domains. Future research directions include exploring alternative input\ngeneration methods, dynamic forecasting models, and advanced neural network\narchitectures to further enhance GANs-based financial risk estimation.",
    "pdf_url": "http://arxiv.org/pdf/2411.15519v1",
    "published": "2024-11-23T10:46:52+00:00",
    "categories": [
      "q-fin.RM",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "q-fin.RM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15518v1",
    "title": "Developing Global Aerosol Models based on the Analysis of 30-Year Ground Measurements by AERONET (AEROEX models) and Implication on Satellite based Aerosol Retrievals",
    "authors": [
      "Manoj K Mishra",
      "Shameela S F",
      "Pradyuman Singh Rathore"
    ],
    "abstract": "The AErosol RObotic NETwork (AERONET), established in 1993 with limited\nglobal sites, has grown to over 900 locations, providing three decades of\ncontinuous aerosol data. While earlier studies based on shorter time periods\n(10-12 years) and fewer sites (approximately 250) made significant\ncontributions to aerosol research, the vast AERONET dataset (1993-2023) calls\nfor a comprehensive reevaluation to refine global aerosol models and improve\nsatellite retrievals. This is particularly important in light of major\nenvironmental changes such as industrialization, land use shifts, and natural\nevents like wildfires and dust storms. In this study, a set of fine and coarse\naerosol models called AERONET-Extended (AEROEX) models are developed based on\ncluster analysis of 30-years AERONET data, analyzing over 202,000 samples using\nGaussian Mixture Models to classify aerosol types by season and region.\nAerosols are categorized into spherical, spheroidal, and mixed types using\nparticle linear depolarization ratio and fine mode fraction. Four fine-mode\naerosol models were derived based on differences in scattering and absorption\nproperties, revealing regional/seasonal variations, particularly in North\nAmerica, Europe and Asia. Additionally, two coarse-mode aerosol models were\nidentified, separated by their absorbing properties in dust-prone and polluted\nregions. We performed simulation analysis showing that the new models\nsignificantly improve satellite-based aerosol optical depth retrievals compared\nto widely used dark target aerosol models. A global aerosol model map,\ngenerated at 1x1 degree resolution for each season using Random Forest and\nexpert refinement, provides valuable insights for climate and atmospheric\nstudies, improving satellite-based aerosol retrievals at global scale.",
    "pdf_url": "http://arxiv.org/pdf/2411.15518v1",
    "published": "2024-11-23T10:44:53+00:00",
    "categories": [
      "physics.ao-ph",
      "physics.geo-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15517v1",
    "title": "Manipulating the Optical Response of TaIrTe4 Heterostructures through Band Alignment Strategy",
    "authors": [
      "Longfei Guo",
      "Shaowen Xu",
      "Qilong Cui",
      "Qingmin Hu",
      "Ruixue Li",
      "Gaofeng Xu",
      "Fanhao Jia",
      "Yuan Li"
    ],
    "abstract": "Weyl semimetals, such as $TaIrTe_{4}$, characterized by their unique band\nstructures and exotic transport phenomena, have become a central focus in\nmodern electronics. Despite extensive research, a systematic understanding of\nthe impact of heterogeneous integration on the electronic and optical\nproperties of TaIrTe4 device remains elusive. We have carried out density\nfunctional theory combined with nonequilibrium Green's function formalism\ncalculations for $TaIrTe_{4}/WTe_{2}$, $TaIrTe_{4}/MoTe_{2}$ and\n$TaIrTe_{4}/h-BN$ heterostructures, aiming to understand the manipulation of\nphotoresponse through various band alignment strategies. The underlying impacts\nof interlayer interactions, charge transfer and build-in electric field on the\nelectronic properties are carefully investigated. We design a dual-probe\nphotodetector device to understand the overall photoresponse enhancement of the\nheterogeneous integration by decomposing into the specific strain, interlayer\ntransition, band overlap and symmetry lowering mechanics. These van der Waals\nintegrations provide an ideal platform for studying band alignment physics in\nself-powered optoelectronic devices.",
    "pdf_url": "http://arxiv.org/pdf/2411.15517v1",
    "published": "2024-11-23T10:43:06+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2411.15516v1",
    "title": "When Image Generation Goes Wrong: A Safety Analysis of Stable Diffusion Models",
    "authors": [
      "Matthias Schneider",
      "Thilo Hagendorff"
    ],
    "abstract": "Text-to-image models are increasingly popular and impactful, yet concerns\nregarding their safety and fairness remain. This study investigates the ability\nof ten popular Stable Diffusion models to generate harmful images, including\nNSFW, violent, and personally sensitive material. We demonstrate that these\nmodels respond to harmful prompts by generating inappropriate content, which\nfrequently displays troubling biases, such as the disproportionate portrayal of\nBlack individuals in violent contexts. Our findings demonstrate a complete lack\nof any refusal behavior or safety measures in the models observed. We emphasize\nthe importance of addressing this issue as image generation technologies\ncontinue to become more accessible and incorporated into everyday applications.",
    "pdf_url": "http://arxiv.org/pdf/2411.15516v1",
    "published": "2024-11-23T10:42:43+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2411.16734v1",
    "title": "Laplacian Spectrum of Super Graphs defined on Certain Non-abelian Groups",
    "authors": [
      "Varun J Kaushik",
      "Ekta",
      "Parveen",
      "Jitender Kumar"
    ],
    "abstract": "Given a graph $A$ on a group $G$ and an equivalence relation $B$ on $G$, the\n$B$ super$A$ graph, whose vertex set is $G$ and two vertices $g$, $h$ are\nadjacent if and only if there exist $g^{\\prime} \\in[g]$ and $h^{\\prime} \\in[h]$\nsuch that $g^{\\prime}$ and $h^{\\prime}$ are adjacent in $A$. Recently, Dalal\n\\emph{et al.} (Spectrum of super commuting graphs of some finite groups,\n\\textit{Computational and Applied Mathematics}, 43(6):348, 2024) obtain the\nLaplacian spectrum of supercommuting graphs of certain non-abelian groups\nincluding the dihedral group and the generalized quaternion group. In this\npaper, we continue the study of Laplacian spectrum of certian $B$ super$A$\ngraphs. We obtain the Laplacian spectrum of conjugacy superenhanced power\ngraphs of certain non-abelian groups, namely: dihedral group, generalized\nquaternion group and semidihedral group. Moreover to enhance the work of Dalal\n\\emph{et al}, we obtain the Laplacian spectrum of conjugacy supercommuting\ngraph of semidihedral group. We prove that graphs considered in this paper are\n$L$-integral.",
    "pdf_url": "http://arxiv.org/pdf/2411.16734v1",
    "published": "2024-11-23T10:42:40+00:00",
    "categories": [
      "math.CO",
      "math.GR",
      "05C25, 05C50"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2411.15515v1",
    "title": "Metamathematics of Resolution Lower Bounds: A TFNP Perspective",
    "authors": [
      "Jiawei Li",
      "Yuhao Li",
      "Hanlin Ren"
    ],
    "abstract": "This paper studies the *refuter* problems, a family of decision-tree\n$\\mathsf{TFNP}$ problems capturing the metamathematical difficulty of proving\nproof complexity lower bounds. Suppose $\\varphi$ is a hard tautology that does\nnot admit any length-$s$ proof in some proof system $P$. In the corresponding\nrefuter problem, we are given (query access to) a purported length-$s$ proof\n$\\pi$ in $P$ that claims to have proved $\\varphi$, and our goal is to find an\ninvalid derivation inside $\\pi$. As suggested by witnessing theorems in bounded\narithmetic, the *computational complexity* of these refuter problems is closely\ntied to the *metamathematics* of the underlying proof complexity lower bounds.\n  We focus on refuter problems corresponding to lower bounds for *resolution*,\nwhich is arguably the single most studied system in proof complexity. We\nintroduce a new class $\\mathrm{rwPHP}(\\mathsf{PLS})$ in decision-tree\n$\\mathsf{TFNP}$, which can be seen as a randomized version of $\\mathsf{PLS}$,\nand argue that this class effectively captures the metamathematics of proving\nresolution lower bounds.\n  We view these results as a contribution to the *bounded reverse mathematics*\nof complexity lower bounds: when interpreted in relativized bounded arithmetic,\nour results show that the theory $\\mathsf{T}^1_2(\\alpha) +\n\\mathrm{dwPHP}(\\mathsf{PV}(\\alpha))$ characterizes the \"reasoning power\"\nrequired to prove (the \"easiest\") resolution lower bounds. An intriguing\ncorollary of our results is that the combinatorial principle, \"the pigeonhole\nprinciple requires exponential-size resolution proofs\", captures the class of\n$\\mathsf{TFNP}$ problems whose totality is provable in $\\mathsf{T}^1_2 +\n\\mathrm{dwPHP}(\\mathsf{PV})$.",
    "pdf_url": "http://arxiv.org/pdf/2411.15515v1",
    "published": "2024-11-23T10:32:38+00:00",
    "categories": [
      "cs.CC",
      "cs.LO"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15514v1",
    "title": "CellPilot: A unified approach to automatic and interactive segmentation in histopathology",
    "authors": [
      "Philipp Endres",
      "Valentin Koch",
      "Julia A. Schnabel",
      "Carsten Marr"
    ],
    "abstract": "Histopathology, the microscopic study of diseased tissue, is increasingly\ndigitized, enabling improved visualization and streamlined workflows. An\nimportant task in histopathology is the segmentation of cells and glands,\nessential for determining shape and frequencies that can serve as indicators of\ndisease. Deep learning tools are widely used in histopathology. However,\nvariability in tissue appearance and cell morphology presents challenges for\nachieving reliable segmentation, often requiring manual correction to improve\naccuracy. This work introduces CellPilot, a framework that bridges the gap\nbetween automatic and interactive segmentation by providing initial automatic\nsegmentation as well as guided interactive refinement. Our model was trained on\nover 675,000 masks of nine diverse cell and gland segmentation datasets,\nspanning 16 organs. CellPilot demonstrates superior performance compared to\nother interactive tools on three held-out histopathological datasets while\nenabling automatic segmentation. We make the model and a graphical user\ninterface designed to assist practitioners in creating large-scale annotated\ndatasets available as open-source, fostering the development of more robust and\ngeneralized diagnostic models.",
    "pdf_url": "http://arxiv.org/pdf/2411.15514v1",
    "published": "2024-11-23T10:31:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15513v2",
    "title": "SPA: Efficient User-Preference Alignment against Uncertainty in Medical Image Segmentation",
    "authors": [
      "Jiayuan Zhu",
      "Junde Wu",
      "Cheng Ouyang",
      "Konstantinos Kamnitsas",
      "J. Alison Noble"
    ],
    "abstract": "Medical image segmentation data inherently contain uncertainty. This can stem\nfrom both imperfect image quality and variability in labeling preferences on\nambiguous pixels, which depend on annotator expertise and the clinical context\nof the annotations. For instance, a boundary pixel might be labeled as tumor in\ndiagnosis to avoid under-estimation of severity, but as normal tissue in\nradiotherapy to prevent damage to sensitive structures. As segmentation\npreferences vary across downstream applications, it is often desirable for an\nimage segmentation model to offer user-adaptable predictions rather than a\nfixed output. While prior uncertainty-aware and interactive methods offer\nadaptability, they are inefficient at test time: uncertainty-aware models\nrequire users to choose from numerous similar outputs, while interactive models\ndemand significant user input through click or box prompts to refine\nsegmentation. To address these challenges, we propose \\textbf{SPA}, a new\n\\textbf{S}egmentation \\textbf{P}reference \\textbf{A}lignment framework that\nefficiently adapts to diverse test-time preferences with minimal human\ninteraction. By presenting users with a select few, distinct segmentation\ncandidates that best capture uncertainties, it reduces the user workload to\nreach the preferred segmentation. To accommodate user preference, we introduce\na probabilistic mechanism that leverages user feedback to adapt a model's\nsegmentation preference. The proposed framework is evaluated on several medical\nimage segmentation tasks: color fundus images, lung lesion and kidney CT scans,\nMRI scans of brain and prostate. SPA shows 1) a significant reduction in user\ntime and effort compared to existing interactive segmentation approaches, 2)\nstrong adaptability based on human feedback, and 3) state-of-the-art image\nsegmentation performance across different imaging modalities and semantic\nlabels.",
    "pdf_url": "http://arxiv.org/pdf/2411.15513v2",
    "published": "2024-11-23T10:27:08+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2411.16733v1",
    "title": "Towards Satellite Image Road Graph Extraction: A Global-Scale Dataset and A Novel Method",
    "authors": [
      "Pan Yin",
      "Kaiyu Li",
      "Xiangyong Cao",
      "Jing Yao",
      "Lei Liu",
      "Xueru Bai",
      "Feng Zhou",
      "Deyu Meng"
    ],
    "abstract": "Recently, road graph extraction has garnered increasing attention due to its\ncrucial role in autonomous driving, navigation, etc. However, accurately and\nefficiently extracting road graphs remains a persistent challenge, primarily\ndue to the severe scarcity of labeled data. To address this limitation, we\ncollect a global-scale satellite road graph extraction dataset, i.e.\nGlobal-Scale dataset. Specifically, the Global-Scale dataset is $\\sim20 \\times$\nlarger than the largest existing public road extraction dataset and spans over\n13,800 $km^2$ globally. Additionally, we develop a novel road graph extraction\nmodel, i.e. SAM-Road++, which adopts a node-guided resampling method to\nalleviate the mismatch issue between training and inference in SAM-Road, a\npioneering state-of-the-art road graph extraction model. Furthermore, we\npropose a simple yet effective ``extended-line'' strategy in SAM-Road++ to\nmitigate the occlusion issue on the road. Extensive experiments demonstrate the\nvalidity of the collected Global-Scale dataset and the proposed SAM-Road++\nmethod, particularly highlighting its superior predictive power in unseen\nregions. The dataset and code are available at\n\\url{https://github.com/earth-insights/samroadplus}.",
    "pdf_url": "http://arxiv.org/pdf/2411.16733v1",
    "published": "2024-11-23T10:26:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15512v3",
    "title": "Synchronized motion of gold nanoparticles in an optothermal trap",
    "authors": [
      "Ashutosh Shukla",
      "Rahul Chand",
      "Sneha Boby",
      "G. V. Pavan Kumar"
    ],
    "abstract": "Optical tweezers have revolutionized particle manipulation at the micro- and\nnanoscale, playing a critical role in fields such as plasmonics, biophysics,\nand nanotechnology. While traditional optical trapping methods primarily rely\non optical forces to manipulate and organize particles, recent studies suggest\nthat optothermal traps in surfactant solutions can induce unconventional\neffects such as enhanced trapping stiffness and increased diffusion. Thus,\nthere is a need for further exploration of this system to gain a deeper\nunderstanding of the forces involved. This work investigates the behaviour of\ngold nanoparticles confined in an optothermal trap around a heated anchor\nparticle in a surfactant (CTAC) solution. We observe unexpected radial\nconfinement and synchronized rotational diffusion of particles at\nmicrometre-scale separations from the anchor particle. These dynamics differ\nfrom known optical binding and thermophoretic effects, suggesting unexplored\nforces facilitated by the surfactant environment. This study expands the\nunderstanding of optothermal trapping driven by anchor plasmonic particles and\nintroduces new possibilities for nanoparticle assembly, offering insights with\npotential applications in nanoscale fabrication and materials science.",
    "pdf_url": "http://arxiv.org/pdf/2411.15512v3",
    "published": "2024-11-23T10:24:56+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall",
      "cond-mat.soft"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2411.15511v1",
    "title": "Forecasting with Markovian max-stable fields in space and time: An application to wind gust speeds",
    "authors": [
      "Ryan Cotsakis",
      "Erwan Koch",
      "Christian-Yann Robert"
    ],
    "abstract": "Hourly maxima of 3-second wind gust speeds are prominent indicators of the\nseverity of wind storms, and accurately forecasting them is thus essential for\npopulations, civil authorities and insurance companies. Space-time max-stable\nmodels appear as natural candidates for this, but those explored so far are not\nsuited for forecasting and, more generally, the forecasting literature for\nmax-stable fields is limited. To fill this gap, we consider a specific\nspace-time max-stable model, more precisely a max-autoregressive model with\nadvection, that is well-adapted to model and forecast atmospheric variables. We\napply it, as well as our related forecasting strategy, to reanalysis 3-second\nwind gust data for France in 1999, and show good performance compared to a\ncompetitor model. On top of demonstrating the practical relevance of our model,\nwe meticulously study its theoretical properties and show the consistency and\nasymptotic normality of the space-time pairwise likelihood estimator which is\nused to calibrate the model.",
    "pdf_url": "http://arxiv.org/pdf/2411.15511v1",
    "published": "2024-11-23T10:21:21+00:00",
    "categories": [
      "stat.ME",
      "stat.AP",
      "62P12"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2411.15510v2",
    "title": "Possibility of BCS-BEC crossover in $Œ∫$-type organic superconductors",
    "authors": [
      "Hiroshi Watanabe",
      "Hiroaki Ikeda"
    ],
    "abstract": "The realization of BCS-BEC crossover in superconductors, which smoothly\nconnects Bardeen-Cooper-Schrieffer (BCS) theory with Bose-Einstein Condensation\n(BEC) in fermion systems, is an intriguing recent topic in strongly correlated\nelectron systems. The organic superconductor\n$\\kappa$-(BEDT-TTF)$_4$Hg$_{2.89}$Br$_8$ ($\\kappa$-HgBr) under pressure is one\nof the leading candidates, owing to its unique metallic spin-liquid nature and\ntunable electron correlation. We theoretically investigate the extended Hubbard\nmodel for $\\kappa$-HgBr and discuss the possibility of the BCS-BEC crossover by\nsystematically calculating superconducting correlation function, coherence\nlength, superfluid weight, and chemical potential. Our findings show that the\nBCS-BEC crossover can be observed when competing phases, such as Mott\ninsulators and charge and/or spin orders, are suppressed by appropriate hole\ndoping. $\\kappa$-HgBr is just the case because both the Mott insulating phase\nand magnetic orders are absent due to its nonstoichiometric Hg composition and\ngeometrical frustration. We further propose that other $\\kappa$-type organic\nsuperconductors could serve as potential candidates of the BCS-BEC crossover if\ntheir band fillings and degree of geometrical frustration are systematically\ntuned.",
    "pdf_url": "http://arxiv.org/pdf/2411.15510v2",
    "published": "2024-11-23T10:07:26+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2411.15509v1",
    "title": "Interactive Visual Assessment for Text-to-Image Generation Models",
    "authors": [
      "Xiaoyue Mi",
      "Fan Tang",
      "Juan Cao",
      "Qiang Sheng",
      "Ziyao Huang",
      "Peng Li",
      "Yang Liu",
      "Tong-Yee Lee"
    ],
    "abstract": "Visual generation models have achieved remarkable progress in computer\ngraphics applications but still face significant challenges in real-world\ndeployment. Current assessment approaches for visual generation tasks typically\nfollow an isolated three-phase framework: test input collection, model output\ngeneration, and user assessment. These fashions suffer from fixed coverage,\nevolving difficulty, and data leakage risks, limiting their effectiveness in\ncomprehensively evaluating increasingly complex generation models. To address\nthese limitations, we propose DyEval, an LLM-powered dynamic interactive visual\nassessment framework that facilitates collaborative evaluation between humans\nand generative models for text-to-image systems. DyEval features an intuitive\nvisual interface that enables users to interactively explore and analyze model\nbehaviors, while adaptively generating hierarchical, fine-grained, and diverse\ntextual inputs to continuously probe the capability boundaries of the models\nbased on their feedback. Additionally, to provide interpretable analysis for\nusers to further improve tested models, we develop a contextual reflection\nmodule that mines failure triggers of test inputs and reflects model potential\nfailure patterns supporting in-depth analysis using the logical reasoning\nability of LLM. Qualitative and quantitative experiments demonstrate that\nDyEval can effectively help users identify max up to 2.56 times generation\nfailures than conventional methods, and uncover complex and rare failure\npatterns, such as issues with pronoun generation and specific cultural context\ngeneration. Our framework provides valuable insights for improving generative\nmodels and has broad implications for advancing the reliability and\ncapabilities of visual generation systems across various domains.",
    "pdf_url": "http://arxiv.org/pdf/2411.15509v1",
    "published": "2024-11-23T10:06:18+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15508v1",
    "title": "Elucidating the nature of axial-vector charm-antibottom tetraquark states",
    "authors": [
      "U. √ñzdem"
    ],
    "abstract": "Investigating the electromagnetic characteristics of unconventional states\nmay offer new insights into their internal structures. In particular, the\nmagnetic moment attributes may serve as a crucial physical observable for\ndifferentiating exotic states with disparate configurations or spin-parity\nquantum numbers. As a promising avenue for research, encompassing both\nopportunities and challenges, an in-depth examination of the electromagnetic\nproperties of exotic states is crucial for advancing our understanding of\nunconventional states. Motivated by this, in this study, the magnetic moments\nof $ \\rm{I(J^{PC})} = 1(1^{+ \\pm})$ $Z_{\\bar b c}$ tetraquark states are\nanalyzed in the framework of QCD light-cone sum rules by considering the\ndiquark-antidiquark approximation, designated as type $3_c \\otimes \\bar 3_c$.\nEven though the $ \\rm{I(J^{PC})} = 1(1^{+-})$ and $ \\rm{I(J^{PC})} = 1(1^{++})$\n$Z_{\\bar b c}$ tetraquark states under examination in this study have an almost\nidentical mass, the results of the magnetic moments show a discrepancy. This\nmay facilitate the differentiation between quantum numbers associated with\nstates with identical quark content. The results show that heavy quarks\novercoming light quarks can determine both the sign and the magnitude of the\nmagnetic moments of these tetraquark states. The numerical results obtained in\nthis study suggest that the magnetic moments of $Z_{\\bar b c}$ tetraquark\nstates may reveal aspects of their underlying structure, which could\ndistinguish between their spin-parity quantum numbers and their internal\nstructure. The results obtained regarding the magnetic moments of the $Z_{\\bar\nb c}$ tetraquark states may be checked within the context of different\nphenomenological approaches.",
    "pdf_url": "http://arxiv.org/pdf/2411.15508v1",
    "published": "2024-11-23T10:00:22+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-lat"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.17735v5",
    "title": "3D-Mem: 3D Scene Memory for Embodied Exploration and Reasoning",
    "authors": [
      "Yuncong Yang",
      "Han Yang",
      "Jiachen Zhou",
      "Peihao Chen",
      "Hongxin Zhang",
      "Yilun Du",
      "Chuang Gan"
    ],
    "abstract": "Constructing compact and informative 3D scene representations is essential\nfor effective embodied exploration and reasoning, especially in complex\nenvironments over extended periods. Existing representations, such as\nobject-centric 3D scene graphs, oversimplify spatial relationships by modeling\nscenes as isolated objects with restrictive textual relationships, making it\ndifficult to address queries requiring nuanced spatial understanding. Moreover,\nthese representations lack natural mechanisms for active exploration and memory\nmanagement, hindering their application to lifelong autonomy. In this work, we\npropose 3D-Mem, a novel 3D scene memory framework for embodied agents. 3D-Mem\nemploys informative multi-view images, termed Memory Snapshots, to represent\nthe scene and capture rich visual information of explored regions. It further\nintegrates frontier-based exploration by introducing Frontier\nSnapshots-glimpses of unexplored areas-enabling agents to make informed\ndecisions by considering both known and potential new information. To support\nlifelong memory in active exploration settings, we present an incremental\nconstruction pipeline for 3D-Mem, as well as a memory retrieval technique for\nmemory management. Experimental results on three benchmarks demonstrate that\n3D-Mem significantly enhances agents' exploration and reasoning capabilities in\n3D environments, highlighting its potential for advancing applications in\nembodied AI.",
    "pdf_url": "http://arxiv.org/pdf/2411.17735v5",
    "published": "2024-11-23T09:57:43+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15507v1",
    "title": "Acoustic forces near elastic substrate",
    "authors": [
      "Vsevolod Kleshchenko",
      "Khristina Albitskaya",
      "Mihail Petrov"
    ],
    "abstract": "In this work, we study the acoustic forces acting on particles due to sound\nscattering at the interface with an elastic substrate. Utilizing the Green's\nfunction formalism, we predict that excitation of leaking Rayleigh wave results\nin strong modification of the acoustic pressure force acting on a monopole\nscatterer and changes the equilibrium position of particles above the substrate\nsurface. We also showed that the presence of a substrate changes the\nconfiguration of the acoustical binding of two particles due to multiple\nrescattering of acoustic wave from the interface. The reported results propose\nthe method of acoustic manipulation via surface waves excitation and\ndemonstrate the effect from elastic media in acoustical trapping of\nmicroobjects.",
    "pdf_url": "http://arxiv.org/pdf/2411.15507v1",
    "published": "2024-11-23T09:57:41+00:00",
    "categories": [
      "physics.class-ph"
    ],
    "primary_category": "physics.class-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.16732v1",
    "title": "Multi-Reranker: Maximizing performance of retrieval-augmented generation in the FinanceRAG challenge",
    "authors": [
      "Joohyun Lee",
      "Minji Roh"
    ],
    "abstract": "As Large Language Models (LLMs) increasingly address domain-specific\nproblems, their application in the financial sector has expanded rapidly. Tasks\nthat are both highly valuable and time-consuming, such as analyzing financial\nstatements, disclosures, and related documents, are now being effectively\ntackled using LLMs. This paper details the development of a high-performance,\nfinance-specific Retrieval-Augmented Generation (RAG) system for the ACM-ICAIF\n'24 FinanceRAG competition. We optimized performance through ablation studies\non query expansion and corpus refinement during the pre-retrieval phase. To\nenhance retrieval accuracy, we employed multiple reranker models. Notably, we\nintroduced an efficient method for managing long context sizes during the\ngeneration phase, significantly improving response quality without sacrificing\nperformance. We ultimately achieve 2nd place in the FinanceRAG Challenge. Our\nkey contributions include: (1) pre-retrieval ablation analysis, (2) an enhanced\nretrieval algorithm, and (3) a novel approach for long-context management. This\nwork demonstrates the potential of LLMs in effectively processing and analyzing\ncomplex financial data to generate accurate and valuable insights. The source\ncode and further details are available at https://github.com/cv-lee/FinanceRAG.",
    "pdf_url": "http://arxiv.org/pdf/2411.16732v1",
    "published": "2024-11-23T09:56:21+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15506v2",
    "title": "Null Stream Based Third-generation-ready Glitch Mitigation for Gravitational Wave Measurements",
    "authors": [
      "Harsh Narola",
      "Thibeau Wouters",
      "Luca Negri",
      "Melissa Lopez",
      "Tom Dooney",
      "Francesco Cireddu",
      "Milan Wils",
      "Isaac C. F. Wong",
      "Peter T. H. Pang",
      "Justin Janquart",
      "Anuradha Samajdar",
      "Chris Van Den Broeck",
      "Tjonnie G. F. Li"
    ],
    "abstract": "Gravitational Wave (GW) detectors routinely encounter transient noise bursts,\nknown as glitches, which are caused by either instrumental or environmental\nfactors. Due to their high occurrence rate, glitches can overlap with GW\nsignals, as in the notable case of GW170817, the first detection of a binary\nneutron star merger. Accurate reconstruction and subtraction of these glitches\nis a challenging problem that must be addressed to ensure that scientific\nconclusions drawn from the data are reliable. This problem will intensify with\nthird-generation observatories like the Einstein Telescope (ET) due to their\nhigher detection rates of GWs and the longer duration of signals within the\nsensitivity band of the detectors. Robust glitch mitigation algorithms are,\ntherefore, crucial for maximizing the scientific output of next-generation GW\nobservatories. For the first time, we demonstrate how the null stream inherent\nin ET's unique triangular configuration can be leveraged by state-of-the-art\nglitch characterization methodology to essentially undo the effect of glitches\nfor the purpose of estimating the parameters of the source. The null stream\nbased approach enables characterization and subtraction of glitches that occur\narbitrarily close to the peak of the signal without any significant effect on\nthe quality of parameter measurements, and achieves an order of magnitude\ncomputational speed-up compared to when the null stream is not available. By\ncontrast, without the null stream, significant biases can occur in the glitch\nreconstruction, which deteriorate the quality of subsequent measurements of the\nsource parameters. This demonstrates a clear edge which the null stream can\noffer for precision GW science in the ET era.",
    "pdf_url": "http://arxiv.org/pdf/2411.15506v2",
    "published": "2024-11-23T09:55:03+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.IM"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2411.16731v3",
    "title": "Non-Local Classical Field Theory with Fractional Operators on $\\mathbb{S}^3 \\times \\mathbb{R}^1$ Space",
    "authors": [
      "Abhi Savaliya",
      "Ayush Bidlan"
    ],
    "abstract": "We present a theoretical framework on non-local classical field theory using\nfractional integrodifferential operators. Due to the lack of easily manageable\nsymmetries in traditional fractional calculus and the difficulties that arise\nin the formalism of multi-fractional calculus over $\\mathbb{R}^{\\text{D}}$\nspace, we introduce a set of new fractional operators over the $\\mathbb{S}^3\n\\times \\mathbb{R}^1$ space. The redefined fractional integral operator results\nin the non-trivial measure canonically, and they can account for the spacetime\nsymmetries for the underlying space $\\mathbb{S}^3 \\times \\mathbb{R}^1$ with the\nLorentzian signature $(+, -, -, -, -)$. We conclude that the field equation for\nthe non-local classical field can be obtained as the consequence of the\noptimisation of the action by employing the non-local variations in the field\nafter defining the non-local Lagrangian density, namely,\n$\\mathcal{L}(\\phi_{a}\\left(x\\right), \\mathbb{\\eth}^\\alpha\n\\phi_{a}\\left(x\\right))$, as the function of the symmetric fractional\nderivative of the field, e.g. in the context of the kinetic term, and the field\nitself.",
    "pdf_url": "http://arxiv.org/pdf/2411.16731v3",
    "published": "2024-11-23T09:51:58+00:00",
    "categories": [
      "physics.class-ph",
      "hep-th",
      "math-ph",
      "math.FA",
      "math.GR",
      "math.MP",
      "math.OA"
    ],
    "primary_category": "physics.class-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15505v1",
    "title": "A Flexible Infrastructure-Sharing 5G Network Architecture Based on Network Slicing and Roaming",
    "authors": [
      "Joao P. Ferreira",
      "Vinicius C. Ferreira",
      "Sergio L. Nogueira",
      "Joao M. Faria",
      "Jose A. Afonso"
    ],
    "abstract": "The sharing of mobile network infrastructure has become a key topic with the\nintroduction of 5G due to the high costs of deploying such infrastructures,\nwith neutral host models coupled with features such as network function\nvirtualization (NFV) and network slicing emerging as viable solutions for the\nchallenges in this area. With this in mind, this work presents the design,\nimplementation, and test of a flexible infrastructure-sharing 5G network\narchitecture capable of providing services to any type of client, whether an\noperator or not. The proposed architecture leverages 5G's network slicing for\ntraffic isolation and compliance with the policies of different clients, with\nroaming employed for the authentication of users of operator clients. The\nproposed architecture was implemented and tested in a simulation environment\nusing the UERANSIM and Open5GS open-source tools. Qualitative tests\nsuccessfully validated the authentication and the traffic isolation features\nprovided by the slices for the two types of clients. Results also demonstrate\nthat the proposed architecture has a positive impact on the performance of the\nneutral host network infrastructure, achieving 61.8% higher throughput and\n96.8% lower packet loss ratio (PLR) in a scenario sharing the infrastructure\namong four clients and eight users when compared to a single client with all\nthe network resources.",
    "pdf_url": "http://arxiv.org/pdf/2411.15505v1",
    "published": "2024-11-23T09:51:05+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2411.15504v1",
    "title": "Effects of Muscle Synergy during Overhead Work with a Passive Shoulder Exoskeleton: A Case Study",
    "authors": [
      "Jin Tian",
      "Baichun Wei",
      "Chifu Yang",
      "Suo Luo",
      "Jiadong Feng",
      "Ping Li",
      "Changbing Chen",
      "Yingjie Liu",
      "Haiqi Zhu",
      "Chunzhi Yi"
    ],
    "abstract": "Objective: Shoulder exoskeletons can effectively assist with overhead work.\nHowever, their impacts on muscle synergy remain unclear. The objective is to\nsystematically investigate the effects of the shoulder exoskeleton on muscle\nsynergies during overhead work.Methods: Eight male participants were recruited\nto perform a screwing task both with (Intervention) and without (Normal) the\nexoskeleton. Eight muscles were monitored and muscle synergies were extracted\nusing non-negative matrix factorization and electromyographic topographic maps.\nResults: The number of synergies extracted was the same (n = 2) in both\nconditions. Specifically, the first synergies in both conditions were\nidentical, with the highest weight of AD and MD; while the second synergies\nwere different between conditions, with highest weight of PM and MD,\nrespectively. As for the first synergy in the Intervention condition, the\nactivation profile significantly decreased, and the average recruitment level\nand activation duration were significantly lower (p<0.05). The regression\nanalysis for the muscle synergies across conditions shows the changes of muscle\nsynergies did not influence the sparseness of muscle synergies (p=0.7341). In\nthe topographic maps, the mean value exhibited a significant decrease (p<0.001)\nand the entropy significantly increased (p<0.01). Conclusion: The exoskeleton\ndoes not alter the number of synergies and existing major synergies but may\ninduce new synergies. It can also significantly decrease neural activation and\nmay influence the heterogeneity of the distribution of monitored muscle\nactivations. Significance: This study provides insights into the potential\nmechanisms of exoskeleton-assisted overhead work and guidance on improving the\nperformance of exoskeletons.",
    "pdf_url": "http://arxiv.org/pdf/2411.15504v1",
    "published": "2024-11-23T09:50:34+00:00",
    "categories": [
      "physics.med-ph",
      "cs.RO"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15503v1",
    "title": "On the long-range order of the Spectre tilings",
    "authors": [
      "Michael Baake",
      "Franz G√§hler",
      "Jan Maz√°ƒç",
      "Lorenzo Sadun"
    ],
    "abstract": "The Spectre is an aperiodic monotile for the Euclidean plane that is truly\nchiral in the sense that it tiles the plane without any need for a reflected\ntile. The topological and dynamical properties of the Spectre tilings are very\nsimilar to those of the Hat tilings. Specifically, the Spectre sits within a\ncomplex $2$-dimensional family of tilings, most of which involve two shapes\nrather than one. All tilings in the family give topologically conjugate\ndynamics, up to an overall rescaling and rotation. They all have pure point\ndynamical spectrum with continuous eigenfunctions and may be obtained from a\n$4:2$ dimensional cut-and-project scheme with regular windows of Rauzy fractal\ntype. The diffraction measure of any Spectre tiling is pure point as well. For\nfixed scale and orientation, varying the shapes is MLD equivalent to merely\nvarying the projection direction. These properties all follow from the first\n\\v{C}ech cohomology being as small as it possibly could be, leaving no room for\nshape changes that alter the dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2411.15503v1",
    "published": "2024-11-23T09:46:22+00:00",
    "categories": [
      "math.DS",
      "math.MG",
      "52C20, 37D40, 55N05, 52C23"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2411.15502v1",
    "title": "Challenges in Comparing Code Maintainability across Different Programming Languages",
    "authors": [
      "Christophe Ponsard",
      "Gustavo Ospina",
      "Denis Darquennes"
    ],
    "abstract": "Comparing the quality of software written in different computer languages is\nrequired in a variety of scenarios, e.g. multi-language projects or application\nselection process among candidates in different languages. We focus on the\nchallenges related to comparing the maintainability quality typically through a\nmaintainability index or technical debt approaches. We identify and discuss how\nto manage a number of challenges to produce comparable maintainability\nassessments across languages related to the programming paradigm (purely\nprocedural vs OO vs multi-paradigm), the coverage of key quality dimensions,\nand the use of generic metrics vs more languages specific rules. Our work is\nbased on a set of code analysis carried out in Wallonia over the past 15 years.",
    "pdf_url": "http://arxiv.org/pdf/2411.15502v1",
    "published": "2024-11-23T09:41:53+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2411.15501v1",
    "title": "Instruct or Interact? Exploring and Eliciting LLMs' Capability in Code Snippet Adaptation Through Prompt Engineering",
    "authors": [
      "Tanghaoran Zhang",
      "Yue Yu",
      "Xinjun Mao",
      "Shangwen Wang",
      "Kang Yang",
      "Yao Lu",
      "Zhang Zhang",
      "Yuxin Zhao"
    ],
    "abstract": "Code snippet adaptation is a fundamental activity in the software development\nprocess. Unlike code generation, code snippet adaptation is not a \"free\ncreation\", which requires developers to tailor a given code snippet in order to\nfit specific requirements and the code context. Recently, large language models\n(LLMs) have confirmed their effectiveness in the code generation task with\npromising results. However, their performance on adaptation, a reuse-oriented\nand context-dependent code change prediction task, is still unclear. To bridge\nthis gap, we conduct an empirical study to investigate the performance and\nissues of LLMs on the adaptation task. We first evaluate the adaptation\nperformances of three popular LLMs and compare them to the code generation\ntask. Our result indicates that their adaptation ability is weaker than\ngeneration, with a nearly 15% decrease on pass@1 and more context-related\nerrors. By manually inspecting 200 cases, we further investigate the causes of\nLLMs' sub-optimal performance, which can be classified into three categories,\ni.e., Unclear Requirement, Requirement Misalignment and Context Misapplication.\nBased on the above empirical research, we propose an interactive prompting\napproach to eliciting LLMs' adaptation ability. Experimental result reveals\nthat our approach greatly improve LLMs' adaptation performance. The\nbest-performing Human-LLM interaction successfully solves 159 out of the 202\nidentified defects and improves the pass@1 and pass@5 by over 40% compared to\nthe initial instruction-based prompt. Considering human efforts, we suggest\nmulti-agent interaction as a trade-off, which can achieve comparable\nperformance with excellent generalization ability. We deem that our approach\ncould provide methodological assistance for autonomous code snippet reuse and\nadaptation with LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2411.15501v1",
    "published": "2024-11-23T09:40:36+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2411.16730v4",
    "title": "\"Moralized\" Multi-Step Jailbreak Prompts: Black-Box Testing of Guardrails in Large Language Models for Verbal Attacks",
    "authors": [
      "Libo Wang"
    ],
    "abstract": "As the application of large language models continues to expand in various\nfields, it poses higher challenges to the effectiveness of identifying harmful\ncontent generation and guardrail mechanisms. This research aims to evaluate the\nguardrail effectiveness of GPT-4o, Grok-2 Beta, Llama 3.1 (405B), Gemini 1.5,\nand Claude 3.5 Sonnet through black-box testing of seemingly ethical multi-step\njailbreak prompts. It conducts ethical attacks by designing an identical\nmulti-step prompts that simulates the scenario of \"corporate middle managers\ncompeting for promotions.\" The data results show that the guardrails of the\nabove-mentioned LLMs were bypassed and the content of verbal attacks was\ngenerated. Claude 3.5 Sonnet's resistance to multi-step jailbreak prompts is\nmore obvious. To ensure objectivity, the experimental process, black box test\ncode, and enhanced guardrail code are uploaded to the GitHub repository:\nhttps://github.com/brucewang123456789/GeniusTrail.git.",
    "pdf_url": "http://arxiv.org/pdf/2411.16730v4",
    "published": "2024-11-23T09:32:44+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15500v1",
    "title": "MolMetaLM: a Physicochemical Knowledge-Guided Molecular Meta Language Model",
    "authors": [
      "Yifan Wu",
      "Min Zeng",
      "Yang Li",
      "Yang Zhang",
      "Min Li"
    ],
    "abstract": "Most current molecular language models transfer the masked language model or\nimage-text generation model from natural language processing to molecular\nfield. However, molecules are not solely characterized by atom/bond symbols;\nthey encapsulate important physical/chemical properties. Moreover, normal\nlanguage models bring grammar rules that are irrelevant for understanding\nmolecules. In this study, we propose a novel physicochemical knowledge-guided\nmolecular meta language framework MolMetaLM. We design a molecule-specialized\nmeta language paradigm, formatted as multiple <S,P,O> (subject, predicate,\nobject) knowledge triples sharing the same S (i.e., molecule) to enhance\nlearning the semantic relationships between physicochemical knowledge and\nmolecules. By introducing different molecular knowledge and noises, the meta\nlanguage paradigm generates tens of thousands of pretraining tasks. By\nrecovering the token/sequence/order-level noises, MolMetaLM exhibits\nproficiency in large-scale benchmark evaluations involving property prediction,\nmolecule generation, conformation inference, and molecular optimization.\nThrough MolMetaLM, we offer a new insight for designing language models.",
    "pdf_url": "http://arxiv.org/pdf/2411.15500v1",
    "published": "2024-11-23T09:27:38+00:00",
    "categories": [
      "cs.ET",
      "cs.CL"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2411.15499v3",
    "title": "Asymmetric Errors",
    "authors": [
      "Roger Barlow",
      "Alessandra Brazzale",
      "Igor Volobouev"
    ],
    "abstract": "We present a procedure for handling asymmetric errors. Many results in\nparticle physics are presented as values with different positive and negative\nerrors, and there is no consistent procedure for handling them. We consider the\ndifference between errors quoted using pdfs and using likelihoods, and the\ndifference between the rms spread of a measurement and the 68\\% central\nconfidence region. We provide a comprehensive analysis of the possibilities,\nand software tools to enable their use.",
    "pdf_url": "http://arxiv.org/pdf/2411.15499v3",
    "published": "2024-11-23T09:21:39+00:00",
    "categories": [
      "stat.ME",
      "hep-ex",
      "hep-ph"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2411.15498v1",
    "title": "Optimal higher derivative estimates for solutions of the Lam√© system with closely spaced hard inclusions",
    "authors": [
      "Hongjie Dong",
      "Haigang Li",
      "Huaijun Teng",
      "Peihao Zhang"
    ],
    "abstract": "We investigate higher derivative estimates for the Lam\\'e system with hard\ninclusions embedded in a bounded domain in $\\mathbb{R}^{d}$. As the distance\n$\\varepsilon$ between two closely spaced hard inclusions approaches zero, the\nstress in the narrow regions between the inclusions increases significantly.\nThis stress is captured by the gradient of the solution. The key contribution\nof this paper is a detailed characterization of this singularity, achieved by\nderiving higher derivative estimates for solutions to the Lam\\'e system with\npartially infinite coefficients. These upper bounds are shown to be sharp in\ntwo and three dimensions when the domain exhibits certain symmetries. To the\nbest of our knowledge, this is the first work to precisely quantify the\nsingular behavior of higher derivatives in the Lam\\'e system with hard\ninclusions.",
    "pdf_url": "http://arxiv.org/pdf/2411.15498v1",
    "published": "2024-11-23T09:20:32+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15497v3",
    "title": "AeroGen: Enhancing Remote Sensing Object Detection with Diffusion-Driven Data Generation",
    "authors": [
      "Datao Tang",
      "Xiangyong Cao",
      "Xuan Wu",
      "Jialin Li",
      "Jing Yao",
      "Xueru Bai",
      "Dongsheng Jiang",
      "Yin Li",
      "Deyu Meng"
    ],
    "abstract": "Remote sensing image object detection (RSIOD) aims to identify and locate\nspecific objects within satellite or aerial imagery. However, there is a\nscarcity of labeled data in current RSIOD datasets, which significantly limits\nthe performance of current detection algorithms. Although existing techniques,\ne.g., data augmentation and semi-supervised learning, can mitigate this\nscarcity issue to some extent, they are heavily dependent on high-quality\nlabeled data and perform worse in rare object classes. To address this issue,\nthis paper proposes a layout-controllable diffusion generative model (i.e.\nAeroGen) tailored for RSIOD. To our knowledge, AeroGen is the first model to\nsimultaneously support horizontal and rotated bounding box condition\ngeneration, thus enabling the generation of high-quality synthetic images that\nmeet specific layout and object category requirements. Additionally, we propose\nan end-to-end data augmentation framework that integrates a\ndiversity-conditioned generator and a filtering mechanism to enhance both the\ndiversity and quality of generated data. Experimental results demonstrate that\nthe synthetic data produced by our method are of high quality and diversity.\nFurthermore, the synthetic RSIOD data can significantly improve the detection\nperformance of existing RSIOD models, i.e., the mAP metrics on DIOR, DIOR-R,\nand HRSC datasets are improved by 3.7%, 4.3%, and 2.43%, respectively. The code\nis available at https://github.com/Sonettoo/AeroGen.",
    "pdf_url": "http://arxiv.org/pdf/2411.15497v3",
    "published": "2024-11-23T09:04:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15496v1",
    "title": "Legendre transformations of a class of generalized Frobenius manifolds and the associated integrable hierarchies",
    "authors": [
      "Si-Qi Liu",
      "Haonan Qu",
      "Youjin Zhang"
    ],
    "abstract": "For two generalized Frobenius manifolds related by a Legendre-type\ntransformation, we show that the associated integrable hierarchies of\nhydrodynamic type, which are called the Legendre-extended Principal\nHierarchies, are related by a certain linear reciprocal transformation; we also\nshow, under the semisimplicity condition, that the topological deformations of\nthese Legendre-extended Principal Hierarchies are related by the same linear\nreciprocal transformation.",
    "pdf_url": "http://arxiv.org/pdf/2411.15496v1",
    "published": "2024-11-23T09:00:35+00:00",
    "categories": [
      "math-ph",
      "math.DG",
      "math.MP",
      "nlin.SI"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.06800v1",
    "title": "Secondary Use of Health Data: Centralized Structure and Information Security Frameworks in Finland",
    "authors": [
      "Hannu Vilpponen",
      "Antti Piirainen",
      "Miikka Kallberg",
      "Tommi Mikkonen"
    ],
    "abstract": "The utilization of health data for secondary purposes, such as research,\nsta-tistics, and development, has become increasingly significant in advancing\nhealthcare systems. To foster the above, Finland has established a framework\nfor the secondary use of health and social data through legislative measures\nand the creation of specialized institutions, which are the first of their kind\nin the world. In this paper, we give an overview of our implementation for\nusing secondary health and social data in a centralized fashion. As a technical\ncontribution, we also address key implementation aspects related to\nimplementing the framework.",
    "pdf_url": "http://arxiv.org/pdf/2412.06800v1",
    "published": "2024-11-23T08:49:29+00:00",
    "categories": [
      "cs.CY",
      "cs.SE"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2411.15495v1",
    "title": "SILVERRUSH. XIV. Lya Luminosity Functions and Angular Correlation Functions from ~20,000 Lya Emitters at z~2.2-7.3 from upto 24 ${\\rm deg}^2$ HSC-SSP and CHORUS Surveys: Linking the Post-Reionization Epoch to the Heart of Reionization",
    "authors": [
      "Hiroya Umeda",
      "Masami Ouchi",
      "Satoshi Kikuta",
      "Yuichi Harikane",
      "Yoshiaki Ono",
      "Takatoshi Shibuya",
      "Akio K. Inoue",
      "Kazuhiro Shimasaku",
      "Yongming Liang",
      "Akinori Matsumoto",
      "Shun Saito",
      "Haruka Kusakabe",
      "Yuta Kageura",
      "Minami Nakane"
    ],
    "abstract": "We present the luminosity functions (LFs) and angular correlation functions\n(ACFs) derived from 18,960 Ly$\\alpha$ emitters (LAEs) at $z=2.2-7.3$ over a\nwide survey area of $\\lesssim24 {\\rm deg^2}$ that are identified in the\nnarrowband data of the Hyper Suprime-Cam Subaru Strategic Program (HSC-SSP) and\nthe Cosmic HydrOgen Reionization Unveiled with Subaru (CHORUS) surveys.\nConfirming the large sample with the 241 spectroscopically identified LAEs, we\ndetermine Ly$\\alpha$ LFs and ACFs in the brighter luminosity range down to\n$0.5L_{\\star}$, and confirm that our measurements are consistent with previous\nstudies but offer significantly reduced statistical uncertainties. The improved\nprecision of our ACFs allows us to clearly detect one-halo terms at some\nredshifts, and provides large-scale bias measurements that indicate hosting\nhalo masses of $\\sim 10^{11} M_\\odot$ over $z\\simeq 2-7$. By comparing our\nLy$\\alpha$ LF (ACF) measurements with reionization models, we estimate the\nneutral hydrogen fractions in the intergalactic medium to be $x_{\\rm \\HI}<0.05$\n(=${0.06}^{+0.12}_{-0.03}$), $0.15^{+0.10}_{-0.08}$ (${0.21}^{+0.19}_{-0.14}$),\n$0.18^{+0.14}_{-0.12}$, and $0.75^{+0.09}_{-0.13}$ at $z=5.7$, $6.6$, $7.0$,\nand $7.3$, respectively. Our findings suggest that the neutral hydrogen\nfraction remains relatively low, $x_{\\rm \\HI} \\lesssim 0.2$, at $z=5-7$, but\nincreases sharply at $z > 7$, reaching $x_{\\rm \\HI} \\sim 0.9$ by $z \\simeq\n8-9$, as indicated by recent JWST studies. The combination of our results from\nLAE observations with recent JWST observations suggests that the major epoch of\nreionization occurred around $z \\sim 7-8$, likely driven by the emergence of\nmassive sources emitting significant ionizing photons.",
    "pdf_url": "http://arxiv.org/pdf/2411.15495v1",
    "published": "2024-11-23T08:41:25+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15494v1",
    "title": "SilentWood: Private Inference Over Gradient-Boosting Decision Forests",
    "authors": [
      "Ronny Ko",
      "Rasoul Akhavan Mahdavi",
      "Byoungwoo Yoon",
      "Makoto Onizuka",
      "Florian Kerschbaum"
    ],
    "abstract": "Gradient-boosting decision forests, as used by algorithms such as XGBoost or\nAdaBoost, offer higher accuracy and lower training times for large datasets\nthan decision trees. Protocols for private inference over decision trees can be\nused to preserve the privacy of the input data as well as the privacy of the\ntrees. However, naively extending private inference over decision trees to\nprivate inference over decision forests by replicating the protocols leads to\nimpractical running times. In this paper, we explore extending the private\ndecision inference protocol using homomorphic encryption by Mahdavi et al. (CCS\n2023) to decision forests. We present several optimizations that identify and\nthen remove (approximate) duplication between the trees in a forest and hence\nachieve significant improvements in communication and computation cost over the\nnaive approach. To the best of our knowledge, we present the first private\ninference protocol for highly scalable gradient-boosting decision forests. Our\noptimizations extend beyond Mahdavi et al.'s protocol to various private\ninference protocols for gradient-boosting decision trees. Our protocol's\ninference time is faster than the baseline of parallel running the protocol by\nMahdavi et al.~by up to 28.1x, and faster than Zama's Concrete ML XGBoost by up\nto 122.25x.",
    "pdf_url": "http://arxiv.org/pdf/2411.15494v1",
    "published": "2024-11-23T08:27:08+00:00",
    "categories": [
      "cs.CR",
      "cs.DB"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15493v2",
    "title": "Excitons and trions in CrSBr bilayers",
    "authors": [
      "M. A. Semina",
      "F. Tabataba-Vakili",
      "A. Rupp",
      "A. S. Baimuratov",
      "A. H√∂gele",
      "M. M. Glazov"
    ],
    "abstract": "We study theoretically the neutral and charged excitons in two-dimensional\nsemiconductors with anisotropic dispersion of charge carriers. Such a situation\nis realized in CrSBr-based van der Waals heterostructures. We calculate the\nbinding energies of excitons and trions and explore their dependence on the\nmass ratio, dielectric screening, and interlayer distance in bilayer\nstructures. We also address the effects of exciton-light coupling, including\nthe radiative decay and long-range electron-hole exchange interaction, and\nbriefly analyze correlations between the excitons and the Fermi sea of resident\nelectrons. The estimates for CrSBr bilayers are in reasonable agreement with\nrecent experiments.",
    "pdf_url": "http://arxiv.org/pdf/2411.15493v2",
    "published": "2024-11-23T08:25:04+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "cond-mat.other"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2411.15492v1",
    "title": "Reduced Basis Method for Few-body Bound State Emulation",
    "authors": [
      "R. Y. Cheng",
      "K. Godbey",
      "Y. B. Niu",
      "Y. G. Ma",
      "W. B. He",
      "S. M. Wang"
    ],
    "abstract": "Recent advances in both theoretical and computational methods have enabled\nlarge-scale, precision calculations of the properties of atomic nuclei. With\nthe growing complexity of modern nuclear theory, however, also comes the need\nfor novel methods to perform systematic studies and quantify the uncertainties\nof models when confronted with experimental data. This study presents an\napplication of such an approach, the reduced basis method, to substantially\nlower computational costs by constructing a significantly smaller Hamiltonian\nsubspace informed by previous solutions. Our method shows comparable efficiency\nand accuracy to other dimensionality reduction techniques on an artificial\nthree-body bound system while providing a richer representation of physical\ninformation in its projection and training subspace. This methodological\nadvancement can be applied in other contexts and has the potential to greatly\nimprove our ability to systematically explore theoretical models and thus\nenhance our understanding of the fundamental properties of nuclear systems.",
    "pdf_url": "http://arxiv.org/pdf/2411.15492v1",
    "published": "2024-11-23T08:24:24+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2411.15491v1",
    "title": "Traditional Chinese Medicine Case Analysis System for High-Level Semantic Abstraction: Optimized with Prompt and RAG",
    "authors": [
      "Peng Xu",
      "Hongjin Wu",
      "Jinle Wang",
      "Rongjia Lin",
      "Liwei Tan"
    ],
    "abstract": "This paper details a technical plan for building a clinical case database for\nTraditional Chinese Medicine (TCM) using web scraping. Leveraging multiple\nplatforms, including 360doc, we gathered over 5,000 TCM clinical cases,\nperformed data cleaning, and structured the dataset with crucial fields such as\npatient details, pathogenesis, syndromes, and annotations. Using the\n$Baidu\\_ERNIE\\_Speed\\_128K$ API, we removed redundant information and generated\nthe final answers through the $DeepSeekv2$ API, outputting results in standard\nJSON format. We optimized data recall with RAG and rerank techniques during\nretrieval and developed a hybrid matching scheme. By combining two-stage\nretrieval method with keyword matching via Jieba, we significantly enhanced the\naccuracy of model outputs.",
    "pdf_url": "http://arxiv.org/pdf/2411.15491v1",
    "published": "2024-11-23T08:24:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15490v1",
    "title": "Improving Factuality of 3D Brain MRI Report Generation with Paired Image-domain Retrieval and Text-domain Augmentation",
    "authors": [
      "Junhyeok Lee",
      "Yujin Oh",
      "Dahyoun Lee",
      "Hyon Keun Joh",
      "Chul-Ho Sohn",
      "Sung Hyun Baik",
      "Cheol Kyu Jung",
      "Jung Hyun Park",
      "Kyu Sung Choi",
      "Byung-Hoon Kim",
      "Jong Chul Ye"
    ],
    "abstract": "Acute ischemic stroke (AIS) requires time-critical management, with hours of\ndelayed intervention leading to an irreversible disability of the patient.\nSince diffusion weighted imaging (DWI) using the magnetic resonance image (MRI)\nplays a crucial role in the detection of AIS, automated prediction of AIS from\nDWI has been a research topic of clinical importance. While text radiology\nreports contain the most relevant clinical information from the image findings,\nthe difficulty of mapping across different modalities has limited the\nfactuality of conventional direct DWI-to-report generation methods. Here, we\npropose paired image-domain retrieval and text-domain augmentation (PIRTA), a\ncross-modal retrieval-augmented generation (RAG) framework for providing\nclinician-interpretative AIS radiology reports with improved factuality. PIRTA\nmitigates the need for learning cross-modal mapping, which poses difficulty in\nimage-to-text generation, by casting the cross-modal mapping problem as an\nin-domain retrieval of similar DWI images that have paired ground-truth text\nradiology reports. By exploiting the retrieved radiology reports to augment the\nreport generation process of the query image, we show by experiments with\nextensive in-house and public datasets that PIRTA can accurately retrieve\nrelevant reports from 3D DWI images. This approach enables the generation of\nradiology reports with significantly higher accuracy compared to direct\nimage-to-text generation using state-of-the-art multimodal language models.",
    "pdf_url": "http://arxiv.org/pdf/2411.15490v1",
    "published": "2024-11-23T08:18:55+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15489v1",
    "title": "Edge zeta function and closed cycles in the standard non-uniform complex from $\\operatorname{PGL}_3$",
    "authors": [
      "Soonki Hong",
      "Sanghoon Kwon"
    ],
    "abstract": "In this paper, we define the edge zeta function of weighted complex. We also\npresent the formula for the edge zeta function of the standard non-uniform\ncomplex\n$\\operatorname{PGL}(3,\\mathbb{F}_q[t])\\backslash\\operatorname{PGL}(3,\\mathbb{F}_q(\\!(t^{-1})\\!))/\\operatorname{PGL}(3,\\mathbb{F}_q[\\![t^{-1}]\\!])$,\narising from the group $\\operatorname{PGL}_3$, as a rational function. Applying\ntrunction in a specific direction is one of the main ingredient. As a result,\nwe obtain the exact formula for the number of closed cycles coming from\ngeodesics in the building.",
    "pdf_url": "http://arxiv.org/pdf/2411.15489v1",
    "published": "2024-11-23T08:16:58+00:00",
    "categories": [
      "math.GR",
      "math.CO",
      "math.DS",
      "math.GT",
      "math.NT",
      "math.RT",
      "Primary 37E15, 20E42, Secondary 22E50, 20G25"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15488v1",
    "title": "Automatic Evaluation for Text-to-image Generation: Task-decomposed Framework, Distilled Training, and Meta-evaluation Benchmark",
    "authors": [
      "Rong-Cheng Tu",
      "Zi-Ao Ma",
      "Tian Lan",
      "Yuehao Zhao",
      "Heyan Huang",
      "Xian-Ling Mao"
    ],
    "abstract": "Driven by the remarkable progress in diffusion models, text-to-image\ngeneration has made significant strides, creating a pressing demand for\nautomatic quality evaluation of generated images. Current state-of-the-art\nautomatic evaluation methods heavily rely on Multi-modal Large Language Models\n(MLLMs), particularly powerful commercial models like GPT-4o. While these\nmodels are highly effective, their substantial costs limit scalability in\nlarge-scale evaluations. Adopting open-source MLLMs is an alternative; however,\ntheir performance falls short due to significant limitations in processing\nmulti-modal data compared to commercial MLLMs. To tackle these problems, we\nfirst propose a task decomposition evaluation framework based on GPT-4o to\nautomatically construct a new training dataset, where the complex evaluation\ntask is decoupled into simpler sub-tasks, effectively reducing the learning\ncomplexity. Based on this dataset, we design innovative training strategies to\neffectively distill GPT-4o's evaluation capabilities into a 7B open-source\nMLLM, MiniCPM-V-2.6. Furthermore, to reliably and comprehensively assess prior\nworks and our proposed model, we manually annotate a meta-evaluation benchmark\nthat includes chain-of-thought explanations alongside quality scores for\ngenerated images. Experimental results demonstrate that our distilled\nopen-source MLLM significantly outperforms the current state-of-the-art\nGPT-4o-base baseline, VIEScore, with over 4.6\\% improvement in Spearman and\nKendall correlations with human judgments.",
    "pdf_url": "http://arxiv.org/pdf/2411.15488v1",
    "published": "2024-11-23T08:06:06+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.16729v1",
    "title": "DiM-Gestor: Co-Speech Gesture Generation with Adaptive Layer Normalization Mamba-2",
    "authors": [
      "Fan Zhang",
      "Siyuan Zhao",
      "Naye Ji",
      "Zhaohan Wang",
      "Jingmei Wu",
      "Fuxing Gao",
      "Zhenqing Ye",
      "Leyao Yan",
      "Lanxin Dai",
      "Weidong Geng",
      "Xin Lyu",
      "Bozuo Zhao",
      "Dingguo Yu",
      "Hui Du",
      "Bin Hu"
    ],
    "abstract": "Speech-driven gesture generation using transformer-based generative models\nrepresents a rapidly advancing area within virtual human creation. However,\nexisting models face significant challenges due to their quadratic time and\nspace complexities, limiting scalability and efficiency. To address these\nlimitations, we introduce DiM-Gestor, an innovative end-to-end generative model\nleveraging the Mamba-2 architecture. DiM-Gestor features a dual-component\nframework: (1) a fuzzy feature extractor and (2) a speech-to-gesture mapping\nmodule, both built on the Mamba-2. The fuzzy feature extractor, integrated with\na Chinese Pre-trained Model and Mamba-2, autonomously extracts implicit,\ncontinuous speech features. These features are synthesized into a unified\nlatent representation and then processed by the speech-to-gesture mapping\nmodule. This module employs an Adaptive Layer Normalization (AdaLN)-enhanced\nMamba-2 mechanism to uniformly apply transformations across all sequence\ntokens. This enables precise modeling of the nuanced interplay between speech\nfeatures and gesture dynamics. We utilize a diffusion model to train and infer\ndiverse gesture outputs. Extensive subjective and objective evaluations\nconducted on the newly released Chinese Co-Speech Gestures dataset corroborate\nthe efficacy of our proposed model. Compared with Transformer-based\narchitecture, the assessments reveal that our approach delivers competitive\nresults and significantly reduces memory usage, approximately 2.4 times, and\nenhances inference speeds by 2 to 4 times. Additionally, we released the CCG\ndataset, a Chinese Co-Speech Gestures dataset, comprising 15.97 hours (six\nstyles across five scenarios) of 3D full-body skeleton gesture motion performed\nby professional Chinese TV broadcasters.",
    "pdf_url": "http://arxiv.org/pdf/2411.16729v1",
    "published": "2024-11-23T08:02:03+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.GR",
      "cs.HC",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2411.16728v1",
    "title": "Maximizing the Impact of Deep Learning on Subseasonal-to-Seasonal Climate Forecasting: The Essential Role of Optimization",
    "authors": [
      "Yizhen Guo",
      "Tian Zhou",
      "Wanyi Jiang",
      "Bo Wu",
      "Liang Sun",
      "Rong Jin"
    ],
    "abstract": "Weather and climate forecasting is vital for sectors such as agriculture and\ndisaster management. Although numerical weather prediction (NWP) systems have\nadvanced, forecasting at the subseasonal-to-seasonal (S2S) scale, spanning 2 to\n6 weeks, remains challenging due to the chaotic and sparse atmospheric signals\nat this interval. Even state-of-the-art deep learning models struggle to\noutperform simple climatology models in this domain. This paper identifies that\noptimization, instead of network structure, could be the root cause of this\nperformance gap, and then we develop a novel multi-stage optimization strategy\nto close the gap. Extensive empirical studies demonstrate that our multi-stage\noptimization approach significantly improves key skill metrics, PCC and TCC,\nwhile utilizing the same backbone structure, surpassing the state-of-the-art\nNWP systems (ECMWF-S2S) by over \\textbf{19-91\\%}. Our research contests the\nrecent study that direct forecasting outperforms rolling forecasting for S2S\ntasks. Through theoretical analysis, we propose that the underperformance of\nrolling forecasting may arise from the accumulation of Jacobian matrix products\nduring training. Our multi-stage framework can be viewed as a form of teacher\nforcing to address this issue. Code is available at\n\\url{https://anonymous.4open.science/r/Baguan-S2S-23E7/}",
    "pdf_url": "http://arxiv.org/pdf/2411.16728v1",
    "published": "2024-11-23T08:01:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15487v1",
    "title": "Multi-soliton solutions of Klein-Gordon-Zakharov system",
    "authors": [
      "Vicente Alvarez",
      "Amin Esfahani"
    ],
    "abstract": "In this study, we investigate the Klein-Gordon-Zakharov system with a focus\non identifying multi-soliton solutions. Specifically, for a given number $N$ of\nsolitons, we demonstrate the existence of a multi-soliton solution that\nasymptotically converges, in the energy space, to the sum of these solitons.\nOur proof extends and builds upon the previous results in \\cite{cote, cotem,\nIA} concerning the nonlinear Schr\\\"{o}dinger equation and the generalized\nKlein-Gordon equation. In contrast to the method used in \\cite{cotem} to\nestablish the existence of multi-solitons for the Klein-Gordon equation, where\nthe difficulty arises from the directions imposed by the coercivity property,\nrequiring the identification of eigenfunctions of the coercivity operator to\nderive new control estimates, the structure of the present system allows for a\nmore refined result. Specifically, the directional constraints can be\neliminated by employing orthogonality arguments derived from localization and\nmodulation techniques.",
    "pdf_url": "http://arxiv.org/pdf/2411.15487v1",
    "published": "2024-11-23T07:57:39+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15486v2",
    "title": "Transition Network Analysis: A Novel Framework for Modeling, Visualizing, and Identifying the Temporal Patterns of Learners and Learning Processes",
    "authors": [
      "Mohammed Saqr",
      "Sonsoles L√≥pez-Pernas",
      "Tiina T√∂rm√§nen",
      "Rogers Kaliisa",
      "Kamila Misiejuk",
      "Santtu Tikka"
    ],
    "abstract": "This paper presents a novel learning analytics method: Transition Network\nAnalysis (TNA), a method that integrates Stochastic Process Mining and\nprobabilistic graph representation to model, visualize, and identify transition\npatterns in the learning process data. Combining the relational and temporal\naspects into a single lens offers capabilities beyond either framework,\nincluding centralities to capture important learning events, community\ndetection to identify behavior patterns, and clustering to reveal temporal\npatterns. Furthermore, TNA introduces several significance tests that go beyond\neither method and add rigor to the analysis. Here, we introduce the theoretical\nand mathematical foundations of TNA and we demonstrate the functionalities of\nTNA with a case study where students (n=191) engaged in small-group\ncollaboration to map patterns of group dynamics using the theories of\nco-regulation and socially-shared regulated learning. The analysis revealed\nthat TNA can map the regulatory processes as well as identify important events,\npatterns, and clusters. Bootstrap validation established the significant\ntransitions and eliminated spurious transitions. As such, TNA can capture\nlearning dynamics and provide a robust framework for investigating the temporal\nevolution of learning processes. Future directions include -- inter alia --\nexpanding estimation methods, reliability assessment, and building longitudinal\nTNA.",
    "pdf_url": "http://arxiv.org/pdf/2411.15486v2",
    "published": "2024-11-23T07:54:15+00:00",
    "categories": [
      "cs.SI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2411.15485v2",
    "title": "Stochastic Volterra Equations for Local Times of Spectrally Positive L√©vy Processes with Gaussian Components",
    "authors": [
      "Wei Xu"
    ],
    "abstract": "Following our previous work [68], this paper continues to investigate the\nevolution dynamics of local times of spectrally positive L\\'evy processes with\nGaussian components in the spatial direction. We prove that conditioned on the\nfiniteness of the first time at which the local time at zero exceeds a given\nvalue, local times at positive line are equal in law to the unique solution of\na stochastic Volterra equation driven by a Gaussian white noise and two Poisson\nrandom measures with convolution kernel given in terms of the scale function.\nAlso, we obtain several equivalent stochastic equations by using the potential\ntheoretic techniques and prove the strong existence and uniqueness by using the\ngeneralized Yamada-Watanabe theorems.\n  Armed with the stochastic Volterra representation, we then establish a\ncomparison principle for the local times of spectrally positive L\\'evy\nprocesses with various drifts or stopped when local times at zero exceed\ndifferent given values, which proposes a stochastic flow enjoying the branching\nproperty. And also, we explore some novel properties of local times in the\nspatial direction including uniform moment estimates,\n$(1/2-\\varepsilon)$-H\\\"older continuity and maximal inequality. By using the\nmethod of duality, we provide an exponential-affine representation of the\nLaplace functional in terms of the unique non-negative solution of a\npath-dependent nonlinear Volterra equation associated with the Laplace exponent\nof L\\'evy process. This gives another perspective on the evolution dynamics of\nlocal times in the spatial direction.",
    "pdf_url": "http://arxiv.org/pdf/2411.15485v2",
    "published": "2024-11-23T07:53:12+00:00",
    "categories": [
      "math.PR",
      "2020 subject classifications: Primary 60G51, 60J55, 60H20, secondary\n  60G22, 60F17, 60G55"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15484v1",
    "title": "Seed-Free Synthetic Data Generation Framework for Instruction-Tuning LLMs: A Case Study in Thai",
    "authors": [
      "Parinthapat Pengpun",
      "Can Udomcharoenchaikit",
      "Weerayut Buaphet",
      "Peerat Limkonchotiwat"
    ],
    "abstract": "We present a synthetic data approach for instruction-tuning large language\nmodels (LLMs) for low-resource languages in a data-efficient manner,\nspecifically focusing on Thai. We identify three key properties that contribute\nto the effectiveness of instruction-tuning datasets: fluency, diversity, and\ncultural context. We propose a seed-data-free framework for generating\nsynthetic instruction-tuning data that incorporates these essential properties.\nOur framework employs an LLM to generate diverse topics, retrieve relevant\ncontexts from Wikipedia, and create instructions for various tasks, such as\nquestion answering, summarization, and conversation. The experimental results\nshow that our best-performing synthetic dataset, which incorporates all three\nkey properties, achieves competitive performance using only 5,000 instructions\nwhen compared to state-of-the-art Thai LLMs trained on hundreds of thousands of\ninstructions. Our code and dataset are publicly available at\nhttps://github.com/parinzee/seed-free-synthetic-instruct.",
    "pdf_url": "http://arxiv.org/pdf/2411.15484v1",
    "published": "2024-11-23T07:50:59+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15483v1",
    "title": "Prob-cGAN: A Probabilistic Conditional Generative Adversarial Network for LSD1 Inhibitor Activity Prediction",
    "authors": [
      "Hanyang Wang"
    ],
    "abstract": "The inhibition of Lysine-Specific Histone Demethylase 1 (LSD1) is a promising\nstrategy for cancer treatment and targeting epigenetic mechanisms. This paper\nintroduces a Probabilistic Conditional Generative Adversarial Network\n(Prob-cGAN), designed to predict the activity of LSD1 inhibitors. The Prob-cGAN\nwas evaluated against state-of-the-art models using the ChEMBL database,\ndemonstrating superior performance. Specifically, it achieved a top-1 $R^2$ of\n0.739, significantly outperforming the Smiles-Transformer model at 0.591 and\nthe baseline cGAN at 0.488. Furthermore, it recorded a lower $RMSE$ of 0.562,\ncompared to 0.708 and 0.791 for the Smiles-Transformer and cGAN models\nrespectively. These results highlight the potential of Prob-cGAN to enhance\ndrug design and advance our understanding of complex biological systems through\nmachine learning and bioinformatics.",
    "pdf_url": "http://arxiv.org/pdf/2411.15483v1",
    "published": "2024-11-23T07:48:59+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2411.15482v2",
    "title": "SplatFlow: Self-Supervised Dynamic Gaussian Splatting in Neural Motion Flow Field for Autonomous Driving",
    "authors": [
      "Su Sun",
      "Cheng Zhao",
      "Zhuoyang Sun",
      "Yingjie Victor Chen",
      "Mei Chen"
    ],
    "abstract": "Most existing Dynamic Gaussian Splatting methods for complex dynamic urban\nscenarios rely on accurate object-level supervision from expensive manual\nlabeling, limiting their scalability in real-world applications. In this paper,\nwe introduce SplatFlow, a Self-Supervised Dynamic Gaussian Splatting within\nNeural Motion Flow Fields (NMFF) to learn 4D space-time representations without\nrequiring tracked 3D bounding boxes, enabling accurate dynamic scene\nreconstruction and novel view RGB/depth/flow synthesis. SplatFlow designs a\nunified framework to seamlessly integrate time-dependent 4D Gaussian\nrepresentation within NMFF, where NMFF is a set of implicit functions to model\ntemporal motions of both LiDAR points and Gaussians as continuous motion flow\nfields. Leveraging NMFF, SplatFlow effectively decomposes static background and\ndynamic objects, representing them with 3D and 4D Gaussian primitives,\nrespectively. NMFF also models the correspondences of each 4D Gaussian across\ntime, which aggregates temporal features to enhance cross-view consistency of\ndynamic components. SplatFlow further improves dynamic object identification by\ndistilling features from 2D foundation models into 4D space-time\nrepresentation. Comprehensive evaluations conducted on the Waymo and KITTI\nDatasets validate SplatFlow's state-of-the-art (SOTA) performance for both\nimage reconstruction and novel view synthesis in dynamic urban scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2411.15482v2",
    "published": "2024-11-23T07:39:30+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15481v1",
    "title": "Energy-efficient Federated Learning with Dynamic Model Size Allocation",
    "authors": [
      "M S Chaitanya Kumar",
      "Sai Satya Narayana J",
      "Yunkai Bao",
      "Xin Wang",
      "Steve Drew"
    ],
    "abstract": "Federated Learning (FL) presents a paradigm shift towards distributed model\ntraining across isolated data repositories or edge devices without explicit\ndata sharing. Despite of its advantages, FL is inherently less efficient than\ncentralized training models, leading to increased energy consumption and,\nconsequently, higher carbon emissions. In this paper, we propose CAMA, a\ncarbon-aware FL framework, promoting the operation on renewable excess energy\nand spare computing capacity, aiming to minimize operational carbon emissions.\nCAMA introduces a dynamic model adaptation strategy which adapts the model\nsizes based on the availability of energy and computing resources. Ordered\ndropout is integratged to enable the aggregation with varying model sizes.\nEmpirical evaluations on real-world energy and load traces demonstrate that our\nmethod achieves faster convergence and ensures equitable client participation,\nwhile scaling efficiently to handle large numbers of clients. The source code\nof CAMA is available at https://github.com/denoslab/CAMA.",
    "pdf_url": "http://arxiv.org/pdf/2411.15481v1",
    "published": "2024-11-23T07:29:36+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15480v1",
    "title": "An upgraded GMRT and MeerKAT study of radio relics in the low mass merging cluster PSZ2 G200.95-28.16",
    "authors": [
      "Arpan Pal",
      "Ruta Kale",
      "Qian H. S. Wang",
      "Daniel R. Wik"
    ],
    "abstract": "Diffuse radio sources known as radio relics are direct tracers of shocks in\nthe outskirts of merging galaxy clusters. PSZ2 G200.95-28.16, a low-mass\nmerging cluster($\\textrm{M}_{500} = (2.7 \\pm 0.2) \\times\n10^{14}~\\mathrm{M}_{\\odot}$) features a prominent radio relic, first identified\nby Kale et al. 2017. We name this relic as the Seahorse. The MeerKAT Galaxy\nCluster Legacy Survey has confirmed two additional radio relics, R2 and R3 in\nthis cluster. We present new observations of this cluster with the Upgraded\nGMRT at 400 and 650 MHz paired with the Chandra X-ray data. The largest linear\nsizes for the three relics are~1.53 Mpc, 1.12~kpc, and 340~kpc. All three radio\nrelics are polarized at 1283~MHz. Assuming the diffusive shock acceleration\nmodel, the spectral indices of the relics imply shock Mach Numbers of $3.1 \\pm\n0.8$ and $2.8 \\pm 0.9$ for the Seahorse and R2, respectively. The Chandra X-ray\nsurface brightness map shows two prominent subclusters, but the relics are not\nperpendicular to the likely merger axis as typically observed; no shocks are\ndetected at the locations of the relics. We discuss the possible merger\nscenarios in light of the low mass of the cluster and the radio and X-ray\nproperties of the relics. The relic R2 follows the correlation known in the\nradio relic power and cluster mass plane, but the Seahorse and R3 relics are\noutliers. We have also discovered a radio ring in our 650~MHz uGMRT image that\ncould be an Odd radio circle candidate.",
    "pdf_url": "http://arxiv.org/pdf/2411.15480v1",
    "published": "2024-11-23T07:28:55+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15479v3",
    "title": "Sparse Polynomial Matrix Optimization",
    "authors": [
      "Jared Miller",
      "Jie Wang",
      "Feng Guo"
    ],
    "abstract": "A polynomial matrix inequality is a formula asserting that a polynomial\nmatrix is positive semidefinite. Polynomial matrix optimization concerns\nminimizing the smallest eigenvalue of a symmetric polynomial matrix subject to\na tuple of polynomial matrix inequalities. This work explores the use of\nsparsity methods in reducing the complexity of sum-of-squares based methods in\nverifying polynomial matrix inequalities or solving polynomial matrix\noptimization. In the unconstrained setting, Newton polytopes can be employed to\nsparsify the monomial basis, resulting in smaller semidefinite programs. In the\ngeneral setting, we show how to exploit different types of sparsity (term\nsparsity, correlative sparsity, matrix sparsity) encoded in polynomial matrices\nto derive sparse semidefinite programming relaxations for polynomial matrix\noptimization. For term sparsity, we show that the block structures of the term\nsparsity iterations with maximal chordal extensions converge to the one\ndetermined by PMI sign symmetries. For correlative sparsity, unlike the scalar\ncase, we provide a counterexample showing that asymptotic convergence does not\nhold under the Archimedean condition and the running intersection property. By\nemploying the theory of matrix-valued measures, we establish several results on\ndetecting global optimality and retrieving optimal solutions under correlative\nsparsity. The effectiveness of sparsity methods on reducing computational\ncomplexity is demonstrated on various examples of polynomial matrix\noptimization.",
    "pdf_url": "http://arxiv.org/pdf/2411.15479v3",
    "published": "2024-11-23T07:23:17+00:00",
    "categories": [
      "math.OC",
      "90C23, 90C17, 90C22, 90C26"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15478v1",
    "title": "Excitation and stability of nonlinear compressible G√∂rtler vortices and streaks induced by free-stream vortical disturbances",
    "authors": [
      "Dongdong Xu",
      "Pierre Ricco",
      "Elena Marensi"
    ],
    "abstract": "We study the generation, nonlinear development and secondary instability of\nunsteady G\\\"ortler vortices and streaks in compressible boundary layers exposed\nto free-stream vortical disturbances and evolving over concave, flat and convex\nwalls. The formation and evolution of the disturbances are governed by the\ncompressible nonlinear boundary-region equations, supplemented by initial and\nboundary conditions that characterise the impact of the free-stream\ndisturbances on the boundary layer. Computations are performed for parameters\ntypical of flows over high-pressure turbine blades, where the G\\\"ortler number,\na measure of the curvature effects, and the disturbance Reynolds number, a\nmeasure of the nonlinear effects, are order-one quantities. At moderate\nintensities of the free-stream disturbances, increasing the G\\\"ortler number\nrenders the boundary layer more unstable, while increasing the Mach number or\nthe frequency stabilises the flow. As the free-stream disturbances become more\nintense, vortices over concave surfaces no longer develop into the\ncharacteristic mushroom-shaped structures, while the flow over convex surfaces\nis destabilised. An occurrence map identifies G\\\"ortler vortices or streaks for\ndifferent levels of free-stream disturbances and G\\\"ortler numbers. Our\ncalculations capture well the experimental measurements of the enhanced skin\nfriction and wall-heat transfer over turbine-blade pressure surfaces. The\ntime-averaged wall-heat transfer modulations, termed hot fingers, are elongated\nin the streamwise direction and their spanwise wavelength is half of the\ncharacteristic wavelength of the free-stream disturbances. Nonlinearly\nsaturated disturbances are unstable to secondary high-frequencymodes, whose\ngrowth rate increases with the G\\\"ortler number. A new varicose even mode is\nreported, which may promote transition to turbulence at the stem of nonlinear\nstreaks.",
    "pdf_url": "http://arxiv.org/pdf/2411.15478v1",
    "published": "2024-11-23T07:20:40+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2411.15477v1",
    "title": "Towards Robust Evaluation of Unlearning in LLMs via Data Transformations",
    "authors": [
      "Abhinav Joshi",
      "Shaswati Saha",
      "Divyaksh Shukla",
      "Sriram Vema",
      "Harsh Jhamtani",
      "Manas Gaur",
      "Ashutosh Modi"
    ],
    "abstract": "Large Language Models (LLMs) have shown to be a great success in a wide range\nof applications ranging from regular NLP-based use cases to AI agents. LLMs\nhave been trained on a vast corpus of texts from various sources; despite the\nbest efforts during the data pre-processing stage while training the LLMs, they\nmay pick some undesirable information such as personally identifiable\ninformation (PII). Consequently, in recent times research in the area of\nMachine Unlearning (MUL) has become active, the main idea is to force LLMs to\nforget (unlearn) certain information (e.g., PII) without suffering from\nperformance loss on regular tasks. In this work, we examine the robustness of\nthe existing MUL techniques for their ability to enable leakage-proof\nforgetting in LLMs. In particular, we examine the effect of data transformation\non forgetting, i.e., is an unlearned LLM able to recall forgotten information\nif there is a change in the format of the input? Our findings on the TOFU\ndataset highlight the necessity of using diverse data formats to quantify\nunlearning in LLMs more reliably.",
    "pdf_url": "http://arxiv.org/pdf/2411.15477v1",
    "published": "2024-11-23T07:20:36+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.04491v2",
    "title": "Soft cells, Kelvin's foam and the minimal surfaces of Schwarz",
    "authors": [
      "G√°bor Domokos",
      "Alain Goriely",
      "√Åkos G. Horv√°th",
      "Krisztina Reg≈ës"
    ],
    "abstract": "Recently, we introduced a new class of shapes, called soft cells which fill\nspace as soft tilings without gaps and overlaps while minimizing the number of\nsharp corners. We introduced the edge bending algorithm that deforms a\npolyhedral tiling into a soft tiling and we proved that an infinite class of\npolyhedral tilings can be smoothly deformed into standard soft tilings. Here,\nwe demonstrate that certain triply periodic minimal surfaces naturally give\nrise to non-standard soft tilings. By extending the edge-bending algorithm, we\nfurther establish that the soft tilings derived from the Schwarz P and Schwarz\nD surfaces can be continuously transformed into one another through a\none-parameter family of intermediate non-standard soft tilings. Notably, by\ncarrying its combinatorial structure, both resulting tilings belong to the\nfirst order equivalence class of the Dirichlet-Voronoi tiling on the\nbody-centered cubic bcc lattice, highlighting a deep geometric connection\nunderlying these minimal surface configurations. By requiring identical\nend-tangents for edges in a first order class, we also define second order\nequivalence classes among tilings and prove that there exist exactly two such\nclasses among soft tilings which share the full symmetry group of the DV-bcc\ntiling. Additionally, we construct a one-parameter family of tilings bridging\nstandard and non-standard soft tilings, explicitly including the classic Kelvin\nfoam structure as an intermediate configuration. This construction highlights\nthat both the soft cells themselves and the geometric methods employed in their\ngeneration provide valuable insights into the structural principles underlying\nnatural forms. We also present the soft tiling induced by the gyroid structure.",
    "pdf_url": "http://arxiv.org/pdf/2412.04491v2",
    "published": "2024-11-23T07:11:04+00:00",
    "categories": [
      "cs.CG",
      "cond-mat.soft",
      "math.DG",
      "05B45 52C22 53A10 52C07"
    ],
    "primary_category": "cs.CG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15476v1",
    "title": "Gassidy: Gaussian Splatting SLAM in Dynamic Environments",
    "authors": [
      "Long Wen",
      "Shixin Li",
      "Yu Zhang",
      "Yuhong Huang",
      "Jianjie Lin",
      "Fengjunjie Pan",
      "Zhenshan Bing",
      "Alois Knoll"
    ],
    "abstract": "3D Gaussian Splatting (3DGS) allows flexible adjustments to scene\nrepresentation, enabling continuous optimization of scene quality during dense\nvisual simultaneous localization and mapping (SLAM) in static environments.\nHowever, 3DGS faces challenges in handling environmental disturbances from\ndynamic objects with irregular movement, leading to degradation in both camera\ntracking accuracy and map reconstruction quality. To address this challenge, we\ndevelop an RGB-D dense SLAM which is called Gaussian Splatting SLAM in Dynamic\nEnvironments (Gassidy). This approach calculates Gaussians to generate\nrendering loss flows for each environmental component based on a designed\nphotometric-geometric loss function. To distinguish and filter environmental\ndisturbances, we iteratively analyze rendering loss flows to detect features\ncharacterized by changes in loss values between dynamic objects and static\ncomponents. This process ensures a clean environment for accurate scene\nreconstruction. Compared to state-of-the-art SLAM methods, experimental results\non open datasets show that Gassidy improves camera tracking precision by up to\n97.9% and enhances map quality by up to 6%.",
    "pdf_url": "http://arxiv.org/pdf/2411.15476v1",
    "published": "2024-11-23T07:09:56+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2411.15475v1",
    "title": "Advancements in nonlinear exponential sampling: convergence, quantitative analysis and Voronovskaya-type formula",
    "authors": [
      "Danilo Costarelli",
      "Mariarosaria Natale"
    ],
    "abstract": "In this paper, we introduce the nonlinear exponential Kantorovich sampling\nseries. We establish pointwise and uniform convergence properties and a\nnonlinear asymptotic formula of the Voronovskaja-type given in terms of the\nlimsup. Furthermore, we extend these convergence results to Mellin-Orlicz\nspaces with respect to the logarithmic (Haar) measure. Quantitative results are\nalso given, using the log-modulus of continuity and the log-modulus of\nsmoothness, respectively, for log-uniformly continuous functions and for\nfunctions in Mellin-Orlicz spaces. Consequently, the qualitative order of\nconvergence can be obtained in case of functions belonging to suitable\nLipschitz (log-H\\\"olderian) classes.",
    "pdf_url": "http://arxiv.org/pdf/2411.15475v1",
    "published": "2024-11-23T07:07:33+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15474v2",
    "title": "Metallic transports from accelerating black holes",
    "authors": [
      "Dibakar Roychowdhury"
    ],
    "abstract": "We probe four dimensional accelerating black holes with D-brane and build up\nthe notion of metallic holography for spacetime with negative cosmological\nconstant. We explore various thermodynamic entities associated with the\nboundary QFT at low temperatures and finite chemical potential. The DC\nconductivity in the boundary QFT is enhanced due to the effects of black hole\nacceleration in the bulk counterpart. We further compute resistivity in\ndifferent temperature regime, which reveals a new quantum liquid phase with\ndynamic critical exponent $ z=3 $.",
    "pdf_url": "http://arxiv.org/pdf/2411.15474v2",
    "published": "2024-11-23T07:05:43+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2411.15473v2",
    "title": "Tilting theory for extended module categories",
    "authors": [
      "Yu Zhou"
    ],
    "abstract": "In extended hearts of bounded $t$-structures on a triangulated category, we\nprovide a Happel-Reiten-Smalo tilting theorem and a characterization for\n$s$-torsion pairs. Applying these to $m$-extended module categories, we\ncharacterize torsion pairs induced by $(m+1)$-term silting complexes. After\nestablishing Auslander-Reiten theory in extended module categories, we\nintroduce $\\tau_{[m]}$-tilting pairs and show bijections between\n$\\tau_{[m]}$-tilting pairs, $(m+1)$-term silting complexes, and functorially\nfinite $s$-torsion pairs.",
    "pdf_url": "http://arxiv.org/pdf/2411.15473v2",
    "published": "2024-11-23T07:01:23+00:00",
    "categories": [
      "math.RT",
      "math.CT",
      "math.RA"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15472v3",
    "title": "KinMo: Kinematic-aware Human Motion Understanding and Generation",
    "authors": [
      "Pengfei Zhang",
      "Pinxin Liu",
      "Pablo Garrido",
      "Hyeongwoo Kim",
      "Bindita Chaudhuri"
    ],
    "abstract": "Current human motion synthesis frameworks rely on global action descriptions,\ncreating a modality gap that limits both motion understanding and generation\ncapabilities. A single coarse description, such as run, fails to capture\ndetails such as variations in speed, limb positioning, and kinematic dynamics,\nleading to ambiguities between text and motion modalities. To address this\nchallenge, we introduce KinMo, a unified framework built on a hierarchical\ndescribable motion representation that extends beyond global actions by\nincorporating kinematic group movements and their interactions. We design an\nautomated annotation pipeline to generate high-quality, fine-grained\ndescriptions for this decomposition, resulting in the KinMo dataset and\noffering a scalable and cost-efficient solution for dataset enrichment. To\nleverage these structured descriptions, we propose Hierarchical Text-Motion\nAlignment that progressively integrates additional motion details, thereby\nimproving semantic motion understanding. Furthermore, we introduce a\ncoarse-to-fine motion generation procedure to leverage enhanced spatial\nunderstanding to improve motion synthesis. Experimental results show that KinMo\nsignificantly improves motion understanding, demonstrated by enhanced\ntext-motion retrieval performance and enabling more fine-grained motion\ngeneration and editing capabilities. Project Page:\nhttps://andypinxinliu.github.io/KinMo",
    "pdf_url": "http://arxiv.org/pdf/2411.15472v3",
    "published": "2024-11-23T06:50:11+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15471v1",
    "title": "Genus three Goeritz groups of connected sums of two lens spaces",
    "authors": [
      "Hao Chen",
      "YanQing Zou"
    ],
    "abstract": "We prove that the mapping class groups of the genus 3 Heegaard splittings of\nthe connected sum of two lens spaces are finitely generated, and the\ncorresponding reducing sphere complexes are all connected.",
    "pdf_url": "http://arxiv.org/pdf/2411.15471v1",
    "published": "2024-11-23T06:49:36+00:00",
    "categories": [
      "math.GT",
      "57K30, 57K20, 20F05"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2412.00044v1",
    "title": "Creating Hierarchical Dispositions of Needs in an Agent",
    "authors": [
      "Tofara Moyo"
    ],
    "abstract": "We present a novel method for learning hierarchical abstractions that\nprioritize competing objectives, leading to improved global expected rewards.\nOur approach employs a secondary rewarding agent with multiple scalar outputs,\neach associated with a distinct level of abstraction. The traditional agent\nthen learns to maximize these outputs in a hierarchical manner, conditioning\neach level on the maximization of the preceding level. We derive an equation\nthat orders these scalar values and the global reward by priority, inducing a\nhierarchy of needs that informs goal formation. Experimental results on the\nPendulum v1 environment demonstrate superior performance compared to a baseline\nimplementation.We achieved state of the art results.",
    "pdf_url": "http://arxiv.org/pdf/2412.00044v1",
    "published": "2024-11-23T06:41:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15470v1",
    "title": "A Preliminary Study of Multilingual Code Language Models for Code Generation Task Using Translated Benchmarks",
    "authors": [
      "Rohit Dandamudi",
      "Gema Rodr√≠guez-P√©rez"
    ],
    "abstract": "Evaluating the performance of Code Language Models (CLMs) for software\nengineering tasks, especially in multilingual and low-resource programming\nlanguage settings, poses significant challenges. These challenges are primarily\ndue to the lack of high-quality benchmarks across various programming languages\nand the imbalanced nature of the CLMs training corpus. Although recent advances\nin one of the common downstream tasks, code generation, have shown promise by\nintroducing translated benchmarks using different methodologies, there is a\ncurrent lack of empirical evidence assessing these benchmarks. To address this\ngap, we conducted a preliminary study to evaluate the performance of\nPoly-Coder, a pioneering open-source, multilingual CLM built for code\ngeneration. We utilized two existing state-of-the-art translations of the\npopular code generation benchmark, HumanEval, facilitated by the OctoPack and\nMultiPL-E studies. Our results suggest that the outcomes observed in these\ntranslated benchmarks align well with evaluation metrics used during the\ntraining phase, such as perplexity, thereby validating their effectiveness in\nestimating the performance of CLMs. However, we identified several\ninconsistencies in the CLMs' performance across the translated benchmarks and\nencountered challenges in replicating the results. These initial insights\nhighlight the need for more comprehensive empirical studies to fully understand\ntranslated benchmarks' methodological approaches, limitations, and\nreproducibility. Such studies are essential to ensure their reliability before\nthey are widely adopted.",
    "pdf_url": "http://arxiv.org/pdf/2411.15470v1",
    "published": "2024-11-23T06:40:47+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2411.15469v2",
    "title": "Mamba-CL: Optimizing Selective State Space Model in Null Space for Continual Learning",
    "authors": [
      "De Cheng",
      "Yue Lu",
      "Lingfeng He",
      "Shizhou Zhang",
      "Xi Yang",
      "Nannan Wang",
      "Xinbo Gao"
    ],
    "abstract": "Continual Learning (CL) aims to equip AI models with the ability to learn a\nsequence of tasks over time, without forgetting previously learned knowledge.\nRecently, State Space Models (SSMs), particularly the Mamba model, have\nachieved notable success in computer vision. Building on the strengths of SSMs,\nthis study explores leveraging the Mamba model for CL. Therefore, we introduce\nMamba-CL, a framework that continuously fine-tunes the core SSMs of the\nlarge-scale Mamba foundation model by updating parameters orthogonal to the\nfeature subspace of previous tasks. This approach theoretically guarantees the\nconsistency objective aiming to preserves consistent output for each SSM module\nacross both previous and current tasks, so as to overcome catastrophic\nforgetting issue. Specifically, we achieve this goal by deducing the overall\nconsistency constraints on four key time-invariant parameters in the Mamba\nmodel, streamlining its recurrent state-space structure and non-linear\ndiscretization process in SSM. In practice, we apply the null-space projection\nto efficiently implement the orthogonality within Mamba model. Extensive\nexperiments on four class-incremental benchmarks demonstrate the effectiveness\nof Mamba-CL for anti-forgetting, achieving superior performances to\nstate-of-the-art methods. Code is available in the supplementary materials.",
    "pdf_url": "http://arxiv.org/pdf/2411.15469v2",
    "published": "2024-11-23T06:36:16+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15468v1",
    "title": "SplatSDF: Boosting Neural Implicit SDF via Gaussian Splatting Fusion",
    "authors": [
      "Runfa Blark Li",
      "Keito Suzuki",
      "Bang Du",
      "Ki Myung Brian Lee",
      "Nikolay Atanasov",
      "Truong Nguyen"
    ],
    "abstract": "A signed distance function (SDF) is a useful representation for\ncontinuous-space geometry and many related operations, including rendering,\ncollision checking, and mesh generation. Hence, reconstructing SDF from image\nobservations accurately and efficiently is a fundamental problem. Recently,\nneural implicit SDF (SDF-NeRF) techniques, trained using volumetric rendering,\nhave gained a lot of attention. Compared to earlier truncated SDF (TSDF) fusion\nalgorithms that rely on depth maps and voxelize continuous space, SDF-NeRF\nenables continuous-space SDF reconstruction with better geometric and\nphotometric accuracy. However, the accuracy and convergence speed of\nscene-level SDF reconstruction require further improvements for many\napplications. With the advent of 3D Gaussian Splatting (3DGS) as an explicit\nrepresentation with excellent rendering quality and speed, several works have\nfocused on improving SDF-NeRF by introducing consistency losses on depth and\nsurface normals between 3DGS and SDF-NeRF. However, loss-level connections\nalone lead to incremental improvements. We propose a novel neural implicit SDF\ncalled \"SplatSDF\" to fuse 3DGSandSDF-NeRF at an architecture level with\nsignificant boosts to geometric and photometric accuracy and convergence speed.\nOur SplatSDF relies on 3DGS as input only during training, and keeps the same\ncomplexity and efficiency as the original SDF-NeRF during inference. Our method\noutperforms state-of-the-art SDF-NeRF models on geometric and photometric\nevaluation by the time of submission.",
    "pdf_url": "http://arxiv.org/pdf/2411.15468v1",
    "published": "2024-11-23T06:35:19+00:00",
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15467v1",
    "title": "The Updated Genome Warehouse: Enhancing Data Value, Security, and Usability to Address Data Expansion",
    "authors": [
      "Yingke Ma",
      "Xuetong Zhao",
      "Yaokai Jia",
      "Zhenxian Han",
      "Caixia Yu",
      "Zhuojing Fan",
      "Zhang Zhang",
      "Jingfa Xiao",
      "Wenming Zhao",
      "Yiming Bao",
      "Meili Chen"
    ],
    "abstract": "The Genome Warehouse (GWH), accessible at https://ngdc.cncb.ac.cn/gwh, is an\nextensively utilized public repository dedicated to the deposition, management\nand sharing of genome assembly sequences, annotations, and metadata. This paper\nhighlights noteworthy enhancements to the GWH since the 2021 version,\nemphasizing substantial advancements in web interfaces for data submission,\ndatabase functionality updates, and resource integration. Key updates include\nthe reannotation of released prokaryotic genomes, mirroring of genome resources\nfrom National Center for Biotechnology Information (NCBI) GenBank and RefSeq,\nintegration of Poxviridae sequences, implementation of an online batch\nsubmission system, enhancements to the quality control system, advanced search\ncapabilities, and the introduction of a controlled-access mechanism for human\ngenome data. These improvements collectively augment the ease and security of\ndata submission and access as well as genome data value, thereby fostering\nheightened convenience and utility for researchers in the genomic field.",
    "pdf_url": "http://arxiv.org/pdf/2411.15467v1",
    "published": "2024-11-23T06:24:34+00:00",
    "categories": [
      "q-bio.GN"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2411.15466v2",
    "title": "Large-Scale Text-to-Image Model with Inpainting is a Zero-Shot Subject-Driven Image Generator",
    "authors": [
      "Chaehun Shin",
      "Jooyoung Choi",
      "Heeseung Kim",
      "Sungroh Yoon"
    ],
    "abstract": "Subject-driven text-to-image generation aims to produce images of a new\nsubject within a desired context by accurately capturing both the visual\ncharacteristics of the subject and the semantic content of a text prompt.\nTraditional methods rely on time- and resource-intensive fine-tuning for\nsubject alignment, while recent zero-shot approaches leverage on-the-fly image\nprompting, often sacrificing subject alignment. In this paper, we introduce\nDiptych Prompting, a novel zero-shot approach that reinterprets as an\ninpainting task with precise subject alignment by leveraging the emergent\nproperty of diptych generation in large-scale text-to-image models. Diptych\nPrompting arranges an incomplete diptych with the reference image in the left\npanel, and performs text-conditioned inpainting on the right panel. We further\nprevent unwanted content leakage by removing the background in the reference\nimage and improve fine-grained details in the generated subject by enhancing\nattention weights between the panels during inpainting. Experimental results\nconfirm that our approach significantly outperforms zero-shot image prompting\nmethods, resulting in images that are visually preferred by users.\nAdditionally, our method supports not only subject-driven generation but also\nstylized image generation and subject-driven image editing, demonstrating\nversatility across diverse image generation applications. Project page:\nhttps://diptychprompting.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2411.15466v2",
    "published": "2024-11-23T06:17:43+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15465v1",
    "title": "Puzzling High-Velocity Calcium Absorption Features Of Type Ia Supernovae",
    "authors": [
      "Xulin Zhao"
    ],
    "abstract": "Absorption features Ca II NIR and Ca II H&K of type Ia supernovae (SNe Ia)\nare characterized by their strong high-velocity features (HVFs). We find that,\nfor these two features of calcium there is a puzzling anti-correlation between\nthe line strengths of HVF and photospheric (PHO) components, and an unexpected\npositive correlation between the velocity difference and line strength ratio of\nHVF and PHO components. In comparison, HVFs of Si II $\\lambda$6355 and O I\n$\\lambda$7773 show a positive correlation between the line strengths of HVF and\nPHO components, and no clear correlation between the velocity difference and\nline strength ratio of the two components. The differences may be associated\nwith the fact that calcium was mostly synthesized in deeper layers than silicon\nand oxygen, and thus experienced much more serious blocking by substances in\nouter layers. These observations can shed light on the physics of HVFs.",
    "pdf_url": "http://arxiv.org/pdf/2411.15465v1",
    "published": "2024-11-23T06:13:39+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2411.15464v2",
    "title": "Epitaxial PbGeSe thin films and their photoluminescence in the mid-wave infrared",
    "authors": [
      "Kelly Xiao",
      "Bryce Wong",
      "Jarod Meyer",
      "Leland Nordin",
      "Kunal Mukherjee"
    ],
    "abstract": "PbSe is a narrow bandgap IV-VI compound semiconductor with application in\nmid-wave infrared optoelectronics, thermoelectrics, and quantum devices.\nAlkaline earth or rare earth elements such as Sr and Eu can substitute Pb to\nwiden the bandgap of PbSe in heterostructure devices, but they come with\nchallenges such as deteriorating optical and electronic properties, even in\ndilute concentrations due to their dissimilar atomic nature. We substitute Pb\ninstead with column-IV Ge and assess the potential of rocksalt phase PbGeSe as\na wider bandgap semiconductor in thin films grown by molecular beam epitaxy on\nGaAs substrates. Low sticking of GeSe adatoms requires synthesis temperatures\nbelow 260 {\\deg}C to incorporate Ge, but this yields poor structural and\ncompositional uniformity as determined by X-ray diffraction. Consequently,\nas-grown films in the range Pb0.94Ge0.06Se to Pb0.83Ge0.17Se (6-17% Ge) show\nmuch less bandgap widening in photoluminescence than prior work on bulk\ncrystals using absorption. We observe that post-growth rapid thermal annealing\nat temperatures of 375-450 {\\deg}C improves the crystal quality and recovers\nbandgap widening. Rapid interdiffusion of Ge during annealing, however, remains\na challenge in harnessing such PbGeSe materials for compositionally sharp\nheterostructures. Annealed 17%-Ge films emit light at 3-3.1 um with minimal\nshift in wavelength versus temperature. These samples are wider in bandgap than\nPbSe films by 55 meV at room temperature and the widening increases to 160 meV\nat 80 K, thanks to sharply different dependence of bandgap on temperature in\nPbSe and PbGeSe.",
    "pdf_url": "http://arxiv.org/pdf/2411.15464v2",
    "published": "2024-11-23T06:10:29+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2411.15463v1",
    "title": "Minimizing breaks by minimizing odd cycle transversals",
    "authors": [
      "Koichi Fujii",
      "Tomomi Matsui"
    ],
    "abstract": "Constructing a suitable schedule for sports competitions is a crucial issue\nin sports scheduling. The round-robin tournament is a competition adopted in\nmany professional sports. For most round-robin tournaments, it is considered\nundesirable that a team plays consecutive away or home matches; such an\noccurrence is called a break. Accordingly, it is preferable to reduce the\nnumber of breaks in a tournament. A common approach is first to construct a\nschedule and then determine a home-away assignment based on the given schedule\nto minimize the number of breaks (first-schedule-then-break). In this study, we\nconcentrate on the problem that arises in the second stage of the\nfirst-schedule-then-break approach, namely, the break minimization\nproblem(BMP). We prove that this problem can be reduced to an odd cycle\ntransversal problem, the well-studied graph problem. These results lead to a\nnew approximation algorithm for the BMP.",
    "pdf_url": "http://arxiv.org/pdf/2411.15463v1",
    "published": "2024-11-23T05:57:56+00:00",
    "categories": [
      "cs.DM"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15462v3",
    "title": "HateDay: Insights from a Global Hate Speech Dataset Representative of a Day on Twitter",
    "authors": [
      "Manuel Tonneau",
      "Diyi Liu",
      "Niyati Malhotra",
      "Scott A. Hale",
      "Samuel P. Fraiberger",
      "Victor Orozco-Olvera",
      "Paul R√∂ttger"
    ],
    "abstract": "To address the global challenge of online hate speech, prior research has\ndeveloped detection models to flag such content on social media. However, due\nto systematic biases in evaluation datasets, the real-world effectiveness of\nthese models remains unclear, particularly across geographies. We introduce\nHateDay, the first global hate speech dataset representative of social media\nsettings, constructed from a random sample of all tweets posted on September\n21, 2022 and covering eight languages and four English-speaking countries.\nUsing HateDay, we uncover substantial variation in the prevalence and\ncomposition of hate speech across languages and regions. We show that\nevaluations on academic datasets greatly overestimate real-world detection\nperformance, which we find is very low, especially for non-European languages.\nOur analysis identifies key drivers of this gap, including models' difficulty\nto distinguish hate from offensive speech and a mismatch between the target\ngroups emphasized in academic datasets and those most frequently targeted in\nreal-world settings. We argue that poor model performance makes public models\nill-suited for automatic hate speech moderation and find that high moderation\nrates are only achievable with substantial human oversight. Our results\nunderscore the need to evaluate detection systems on data that reflects the\ncomplexity and diversity of real-world social media.",
    "pdf_url": "http://arxiv.org/pdf/2411.15462v3",
    "published": "2024-11-23T05:54:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15461v1",
    "title": "Project TAIPAN: Results from a Novel Gravity Gradiometer Field Test",
    "authors": [
      "Alexey V. Veryaskin",
      "Howard C. Golden",
      "Khyl J. McMahon",
      "Neil M. Provins",
      "Frank J. van Kann",
      "Thomas J. Meyer"
    ],
    "abstract": "Project TAIPAN has been carried out jointly by Trinity Research Lab and the\nFrequency and Quantum Metrology Research Group located at the School of\nPhysics, Mathematics and Computing of the University of Western Australia\n(UWA). Lockheed Martin Corporation (USA) has also been a partner in this joint\ncollaboration providing financial backing to the project and other support\nincluding advanced modelling, assessment of laboratory tests and data analysis.\nThe project aim was to develop a miniaturised gravity gradiometer to measure\nhorizontal mixed gradient components of the Earth gravity in a small,\nlightweight package that can be deployed in a fixed 4D mode, in a borehole, or\non moving exploration platforms including ground-based, airborne and\nsubmersible. The gradiometer design has evolved through a few prototypes\ncombining the design of its sensing element with ultra low noise microwave and\ncapacitive read out. The most recent prototype of the gradiometer using novel\nultra sensitive capacitive pick off metrology has been trialled in the harsh\nenvironment of Outback Western Australia over a known gravity anomaly\ndisplaying steep gradients. Despite adverse weather conditions, results of the\ntrial indicate that the gradiometer operated as expected, closely replicating\nthe gravity gradient profile extrapolated from a regional gravity survey.",
    "pdf_url": "http://arxiv.org/pdf/2411.15461v1",
    "published": "2024-11-23T05:45:42+00:00",
    "categories": [
      "physics.ins-det"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2412.07778v1",
    "title": "MIN: Multi-channel Interaction Network for Drug-Target Interaction with Protein Distillation",
    "authors": [
      "Shuqi Li",
      "Shufang Xie",
      "Hongda Sun",
      "Yuhan Chen",
      "Tao Qin",
      "Tianjun Ke",
      "Rui Yan"
    ],
    "abstract": "Traditional drug discovery processes are both time-consuming and require\nextensive professional expertise. With the accumulation of drug-target\ninteraction (DTI) data from experimental studies, leveraging modern\nmachine-learning techniques to discern patterns between drugs and target\nproteins has become increasingly feasible. In this paper, we introduce the\nMulti-channel Interaction Network (MIN), a novel framework designed to predict\nDTIs through two primary components: a representation learning module and a\nmulti-channel interaction module. The representation learning module features a\nC-Score Predictor-assisted screening mechanism, which selects critical residues\nto enhance prediction accuracy and reduce noise. The multi-channel interaction\nmodule incorporates a structure-agnostic channel, a structure-aware channel,\nand an extended-mixture channel, facilitating the identification of interaction\npatterns at various levels for optimal complementarity. Additionally,\ncontrastive learning is utilized to harmonize the representations of diverse\ndata types. Our experimental evaluations on public datasets demonstrate that\nMIN surpasses other strong DTI prediction methods. Furthermore, the case study\nreveals a high overlap between the residues selected by the C-Score Predictor\nand those in actual binding pockets, underscoring MIN's explainability\ncapability. These findings affirm that MIN is not only a potent tool for DTI\nprediction but also offers fresh insights into the prediction of protein\nbinding sites.",
    "pdf_url": "http://arxiv.org/pdf/2412.07778v1",
    "published": "2024-11-23T05:38:36+00:00",
    "categories": [
      "q-bio.QM",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15460v1",
    "title": "Single-Shot Ionization-Based Transverse Profile Monitor for Pulsed Electron Beams",
    "authors": [
      "Paul Denham",
      "Alex Ody",
      "Pietro Musumeci",
      "Nathan Burger",
      "Nathan Cook",
      "Gerard Andonian"
    ],
    "abstract": "We present an experimental demonstration of a single-shot, non-destructive\nelectron beam diagnostic based on the ionization of a low-density pulsed gas\njet. In our study, 7~MeV electron bunches from a radio frequency (RF)\nphotoinjector, carrying up to 100 pC of charge, traversed a localized\ndistribution of nitrogen gas (N$_2$). The interaction of the electron bunches\nwith the N$_2$ gas generated a correlated signature in the ionized particle\ndistribution, which was spatially magnified using a series of electrostatic\nlenses and recorded with a micro-channel-plate detector. Various modalities,\nincluding point-to-point imaging and velocity mapping, are investigated. A\ntemporal trace of the detector current enabled the identification of single-\nand double-ionization events. The characteristics of the ionization\ndistribution, dependence on gas density, total bunch charge, and other\nparameters, are described. Approaches to scaling to higher electron bunch\ndensity and energy are suggested. Additionally, the instrument proves useful\nfor comprehensive studies of the ionization process itself.",
    "pdf_url": "http://arxiv.org/pdf/2411.15460v1",
    "published": "2024-11-23T05:35:22+00:00",
    "categories": [
      "physics.ins-det",
      "physics.app-ph"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2411.15459v1",
    "title": "MambaVLT: Time-Evolving Multimodal State Space Model for Vision-Language Tracking",
    "authors": [
      "Xinqi Liu",
      "Li Zhou",
      "Zikun Zhou",
      "Jianqiu Chen",
      "Zhenyu He"
    ],
    "abstract": "The vision-language tracking task aims to perform object tracking based on\nvarious modality references. Existing Transformer-based vision-language\ntracking methods have made remarkable progress by leveraging the global\nmodeling ability of self-attention. However, current approaches still face\nchallenges in effectively exploiting the temporal information and dynamically\nupdating reference features during tracking. Recently, the State Space Model\n(SSM), known as Mamba, has shown astonishing ability in efficient long-sequence\nmodeling. Particularly, its state space evolving process demonstrates promising\ncapabilities in memorizing multimodal temporal information with linear\ncomplexity. Witnessing its success, we propose a Mamba-based vision-language\ntracking model to exploit its state space evolving ability in temporal space\nfor robust multimodal tracking, dubbed MambaVLT. In particular, our approach\nmainly integrates a time-evolving hybrid state space block and a selective\nlocality enhancement block, to capture contextual information for multimodal\nmodeling and adaptive reference feature update. Besides, we introduce a\nmodality-selection module that dynamically adjusts the weighting between visual\nand language references, mitigating potential ambiguities from either reference\ntype. Extensive experimental results show that our method performs favorably\nagainst state-of-the-art trackers across diverse benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2411.15459v1",
    "published": "2024-11-23T05:31:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15458v1",
    "title": "TANGNN: a Concise, Scalable and Effective Graph Neural Networks with Top-m Attention Mechanism for Graph Representation Learning",
    "authors": [
      "Jiawei E",
      "Yinglong Zhang",
      "Xuewen Xia",
      "Xing Xu"
    ],
    "abstract": "In the field of deep learning, Graph Neural Networks (GNNs) and Graph\nTransformer models, with their outstanding performance and flexible\narchitectural designs, have become leading technologies for processing\nstructured data, especially graph data. Traditional GNNs often face challenges\nin capturing information from distant vertices effectively. In contrast, Graph\nTransformer models are particularly adept at managing long-distance node\nrelationships. Despite these advantages, Graph Transformer models still\nencounter issues with computational and storage efficiency when scaled to large\ngraph datasets. To address these challenges, we propose an innovative Graph\nNeural Network (GNN) architecture that integrates a Top-m attention mechanism\naggregation component and a neighborhood aggregation component, effectively\nenhancing the model's ability to aggregate relevant information from both local\nand extended neighborhoods at each layer. This method not only improves\ncomputational efficiency but also enriches the node features, facilitating a\ndeeper analysis of complex graph structures. Additionally, to assess the\neffectiveness of our proposed model, we have applied it to citation sentiment\nprediction, a novel task previously unexplored in the GNN field. Accordingly,\nwe constructed a dedicated citation network, ArXivNet. In this dataset, we\nspecifically annotated the sentiment polarity of the citations (positive,\nneutral, negative) to enable in-depth sentiment analysis. Our approach has\nshown superior performance across a variety of tasks including vertex\nclassification, link prediction, sentiment prediction, graph regression, and\nvisualization. It outperforms existing methods in terms of effectiveness, as\ndemonstrated by experimental results on multiple datasets.",
    "pdf_url": "http://arxiv.org/pdf/2411.15458v1",
    "published": "2024-11-23T05:31:25+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.16727v3",
    "title": "An Information-Theoretic Regularizer for Lossy Neural Image Compression",
    "authors": [
      "Yingwen Zhang",
      "Meng Wang",
      "Xihua Sheng",
      "Peilin Chen",
      "Junru Li",
      "Li Zhang",
      "Shiqi Wang"
    ],
    "abstract": "Lossy image compression networks aim to minimize the latent entropy of images\nwhile adhering to specific distortion constraints. However, optimizing the\nneural network can be challenging due to its nature of learning quantized\nlatent representations. In this paper, our key finding is that minimizing the\nlatent entropy is, to some extent, equivalent to maximizing the conditional\nsource entropy, an insight that is deeply rooted in information-theoretic\nequalities. Building on this insight, we propose a novel structural\nregularization method for the neural image compression task by incorporating\nthe negative conditional source entropy into the training objective, such that\nboth the optimization efficacy and the model's generalization ability can be\npromoted. The proposed information-theoretic regularizer is interpretable,\nplug-and-play, and imposes no inference overheads. Extensive experiments\ndemonstrate its superiority in regularizing the models and further squeezing\nbits from the latent representation across various compression structures and\nunseen domains.",
    "pdf_url": "http://arxiv.org/pdf/2411.16727v3",
    "published": "2024-11-23T05:19:27+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15457v1",
    "title": "Hindi audio-video-Deepfake (HAV-DF): A Hindi language-based Audio-video Deepfake Dataset",
    "authors": [
      "Sukhandeep Kaur",
      "Mubashir Buhari",
      "Naman Khandelwal",
      "Priyansh Tyagi",
      "Kiran Sharma"
    ],
    "abstract": "Deepfakes offer great potential for innovation and creativity, but they also\npose significant risks to privacy, trust, and security. With a vast\nHindi-speaking population, India is particularly vulnerable to deepfake-driven\nmisinformation campaigns. Fake videos or speeches in Hindi can have an enormous\nimpact on rural and semi-urban communities, where digital literacy tends to be\nlower and people are more inclined to trust video content. The development of\neffective frameworks and detection tools to combat deepfake misuse requires\nhigh-quality, diverse, and extensive datasets. The existing popular datasets\nlike FF-DF (FaceForensics++), and DFDC (DeepFake Detection Challenge) are based\non English language.. Hence, this paper aims to create a first novel Hindi deep\nfake dataset, named ``Hindi audio-video-Deepfake'' (HAV-DF). The dataset has\nbeen generated using the faceswap, lipsyn and voice cloning methods. This\nmulti-step process allows us to create a rich, varied dataset that captures the\nnuances of Hindi speech and facial expressions, providing a robust foundation\nfor training and evaluating deepfake detection models in a Hindi language\ncontext. It is unique of its kind as all of the previous datasets contain\neither deepfake videos or synthesized audio. This type of deepfake dataset can\nbe used for training a detector for both deepfake video and audio datasets.\nNotably, the newly introduced HAV-DF dataset demonstrates lower detection\naccuracy's across existing detection methods like Headpose, Xception-c40, etc.\nCompared to other well-known datasets FF-DF, and DFDC. This trend suggests that\nthe HAV-DF dataset presents deeper challenges to detect, possibly due to its\nfocus on Hindi language content and diverse manipulation techniques. The HAV-DF\ndataset fills the gap in Hindi-specific deepfake datasets, aiding multilingual\ndeepfake detection development.",
    "pdf_url": "http://arxiv.org/pdf/2411.15457v1",
    "published": "2024-11-23T05:18:43+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR",
      "cs.GR",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2411.15456v1",
    "title": "Suppression of hydrodynamic escape of an H2-rich early Earth atmosphere by radiative cooling of carbon oxides",
    "authors": [
      "Tatsuya Yoshida",
      "Naoki Terada",
      "Kiyoshi Kuramoto"
    ],
    "abstract": "Radiative cooling by molecules is a crucial process for hydrodynamic escape,\nas it can efficiently remove the thermal energy driving the outflow, acquired\nthrough X-ray and extreme UV absorption. Carbon oxides, such as CO and CO2, and\ntheir photochemical products are anticipated to serve as vital radiative\ncooling sources not only in atmospheres dominated by carbon oxides but also in\nH2-rich atmospheres. However, their specific effects on the hydrodynamic\nescape, especially in H2-rich atmospheres, have been inadequately investigated.\nIn this study, we conduct 1-D hydrodynamic escape simulations for H2-rich\natmospheres incorporating CO, CO2, and their chemical products on an Earth-mass\nplanet. We consider detailed radiative cooling processes and chemical networks\nrelated to carbon oxides to elucidate their impacts on the hydrodynamic escape.\nIn the escape outflow, CO2 undergoes rapid photolysis, producing CO and atomic\noxygen, while CO exhibits photochemical stability compared to CO2. The H2\noxidation by atomic oxygen results in the production of OH and H2O.\nConsequently, the hydrodynamic escape is significantly suppressed by the\nradiative cooling effects of CO, H2O, OH, and H3+ even when the basal mixing\nfraction of CO and CO2 is lower than ~0.01. These mechanisms extend the\nlifetime of H2-rich atmospheres by about one order of magnitude compared to the\ncase of pure hydrogen atmospheres on early Earth, which also results in\nnegligible escape of heavier carbon- and nitrogen-bearing molecules and noble\ngases.",
    "pdf_url": "http://arxiv.org/pdf/2411.15456v1",
    "published": "2024-11-23T05:15:52+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15455v1",
    "title": "MUFM: A Mamba-Enhanced Feedback Model for Micro Video Popularity Prediction",
    "authors": [
      "Jiacheng Lu",
      "Mingyuan Xiao",
      "Weijian Wang",
      "Yuxin Du",
      "Yi Cui",
      "Jingnan Zhao",
      "Cheng Hua"
    ],
    "abstract": "The surge in micro-videos is transforming the concept of popularity. As\nresearchers delve into vast multi-modal datasets, there is a growing interest\nin understanding the origins of this popularity and the forces driving its\nrapid expansion. Recent studies suggest that the virality of short videos is\nnot only tied to their inherent multi-modal content but is also heavily\ninfluenced by the strength of platform recommendations driven by audience\nfeedback. In this paper, we introduce a framework for capturing long-term\ndependencies in user feedback and dynamic event interactions, based on the\nMamba Hawkes process. Our experiments on the large-scale open-source\nmulti-modal dataset show that our model significantly outperforms\nstate-of-the-art approaches across various metrics by 23.2%. We believe our\nmodel's capability to map the relationships within user feedback behavior\nsequences will not only contribute to the evolution of next-generation\nrecommendation algorithms and platform applications but also enhance our\nunderstanding of micro video dissemination and its broader societal impact.",
    "pdf_url": "http://arxiv.org/pdf/2411.15455v1",
    "published": "2024-11-23T05:13:27+00:00",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15454v1",
    "title": "Extremal bounds for Gaussian trace estimation",
    "authors": [
      "Eric Hallman"
    ],
    "abstract": "This work derives extremal tail bounds for the Gaussian trace estimator\napplied to a real symmetric matrix. We define a partial ordering on the\neigenvalues, so that when a matrix has greater spectrum under this ordering,\nits estimator will have worse tail bounds. This is done for two families of\nmatrices: positive semidefinite matrices with bounded effective rank, and\nindefinite matrices with bounded 2-norm and fixed Frobenius norm. In each case,\nthe tail region is defined rigorously and is constant for a given family.",
    "pdf_url": "http://arxiv.org/pdf/2411.15454v1",
    "published": "2024-11-23T05:10:05+00:00",
    "categories": [
      "math.ST",
      "cs.NA",
      "math.NA",
      "math.PR",
      "stat.TH",
      "60E15, 60E07, 65C05"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2411.15453v1",
    "title": "Enhancing Instruction-Following Capability of Visual-Language Models by Reducing Image Redundancy",
    "authors": [
      "Te Yang",
      "Jian Jia",
      "Xiangyu Zhu",
      "Weisong Zhao",
      "Bo Wang",
      "Yanhua Cheng",
      "Yan Li",
      "Shengyuan Liu",
      "Quan Chen",
      "Peng Jiang",
      "Kun Gai",
      "Zhen Lei"
    ],
    "abstract": "Large Language Models (LLMs) have strong instruction-following capability to\ninterpret and execute tasks as directed by human commands. Multimodal Large\nLanguage Models (MLLMs) have inferior instruction-following ability compared to\nLLMs. However, there is a significant gap in the instruction-following\ncapabilities between the MLLMs and LLMs. In this study, we conduct a pilot\nexperiment, which demonstrates that spatially down-sampling visual tokens\nsignificantly enhances the instruction-following capability of MLLMs. This is\nattributed to the substantial redundancy in visual modality. However, this\nintuitive method severely impairs the MLLM's multimodal understanding\ncapability. In this paper, we propose Visual-Modality Token Compression (VMTC)\nand Cross-Modality Attention Inhibition (CMAI) strategies to alleviate this gap\nbetween MLLMs and LLMs by inhibiting the influence of irrelevant visual tokens\nduring content generation, increasing the instruction-following ability of the\nMLLMs while retaining their multimodal understanding capacity. In VMTC module,\nthe primary tokens are retained and the redundant tokens are condensed by token\nclustering and merging. In CMAI process, we aggregate text-to-image attentions\nby text-to-text attentions to obtain a text-to-image focus score. Attention\ninhibition is performed on the text-image token pairs with low scores. Our\ncomprehensive experiments over instruction-following capabilities and VQA-V2,\nGQA, TextVQA, MME and MMBench five benchmarks, demonstrate that proposed\nstrategy significantly enhances the instruction following capability of MLLMs\nwhile preserving the ability to understand and process multimodal inputs.",
    "pdf_url": "http://arxiv.org/pdf/2411.15453v1",
    "published": "2024-11-23T05:03:32+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.12104v1",
    "title": "Reservoir Computing Generalized",
    "authors": [
      "Tomoyuki Kubota",
      "Yusuke Imai",
      "Sumito Tsunegi",
      "Kohei Nakajima"
    ],
    "abstract": "A physical neural network (PNN) has both the strong potential to solve\nmachine learning tasks and intrinsic physical properties, such as high-speed\ncomputation and energy efficiency. Reservoir computing (RC) is an excellent\nframework for implementing an information processing system with a dynamical\nsystem by attaching a trained readout, thus accelerating the wide use of\nunconventional materials for a PNN. However, RC requires the dynamics to\nreproducibly respond to input sequence, which limits the type of substance\navailable for building information processors. Here we propose a novel\nframework called generalized reservoir computing (GRC) by turning this\nrequirement on its head, making conventional RC a special case. Using\nsubstances that do not respond the same to identical inputs (e.g., a real\nspin-torque oscillator), we propose mechanisms aimed at obtaining a reliable\noutput and show that processed inputs in the unconventional substance are\nretrievable. Finally, we demonstrate that, based on our framework,\nspatiotemporal chaos, which is thought to be unusable as a computational\nresource, can be used to emulate complex nonlinear dynamics, including large\nscale spatiotemporal chaos. Overall, our framework removes the limitation to\nbuilding an information processing device and opens a path to constructing a\ncomputational system using a wider variety of physical dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2412.12104v1",
    "published": "2024-11-23T05:02:47+00:00",
    "categories": [
      "nlin.CD",
      "cs.LG"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2412.01844v1",
    "title": "Feature importance of socio-economic parameters in Tuberculosis modeling",
    "authors": [
      "Andrei Neverov",
      "Olga Krivorotko"
    ],
    "abstract": "This paper considers the problem of modeling epidemic outbreaks in different\nregions with a common model, that uses additional information about these\nregions to adjust its parameters and relieve us of mundanity of data\ncollecting, and inverse problem solving for each region separately. To that\nend, we study tuberculosis and HIV dynamics in regions of Russian Federation\nfrom 2009 to 2023 in connection with number of socio-economic parameters.\nSIR-like model was taken and modified as a dynamic model for tuberculosis-HIV\nco-infection and inverse problem of transfer rates between compartments was\nsolved, based on statistical data of diseases incidence. To shorten the list of\nsocio-economic parameters we make use of Shapley vector that allows us to\nestimate importance of these parameters in reconstruction of differential model\nparameters using regression algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2412.01844v1",
    "published": "2024-11-23T04:56:12+00:00",
    "categories": [
      "physics.soc-ph",
      "q-bio.PE",
      "65Z05"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15452v2",
    "title": "Beyond inherent robustness: strong stability of MPC despite plant-model mismatch",
    "authors": [
      "Steven J. Kuntz",
      "James B. Rawlings"
    ],
    "abstract": "In this technical report, we establish the asymptotic stability of MPC under\nplant-model mismatch for problems where the origin remains a steady state\ndespite mismatch. This class of problems includes, but is not limited to,\ninventory management, path-planning, and control of systems in deviation\nvariables. Our results differ from prior results on the inherent robustness of\nMPC, which guarantee only convergence to a neighborhood of the origin, the size\nof which scales with the magnitude of the mismatch. For MPC with quadratic\ncosts, continuous differentiability of the system dynamics is sufficient to\ndemonstrate exponential stability of the closed-loop system despite mismatch.\nFor MPC with general costs, a joint comparison function bound and scaling\ncondition guarantee asymptotic stability despite mismatch. The results are\nillustrated in numerical simulations, including the classic upright pendulum\nproblem. The tools developed to establish these results can address the\nstability of offset-free MPC, an open and interesting question in the MPC\nresearch literature.",
    "pdf_url": "http://arxiv.org/pdf/2411.15452v2",
    "published": "2024-11-23T04:49:41+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC",
      "93B45, 93D09, 93D30"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2411.15451v1",
    "title": "Quantitative Analysis of IITs' Research Growth and SDG Contributions",
    "authors": [
      "Kiran Sharma",
      "Akshat Nagori",
      "Manya",
      "Mehul Dubey",
      "Parul Khurana"
    ],
    "abstract": "The Indian Institutes of Technology (IITs) are vital to India's research\necosystem, advancing technology and engineering for industrial and societal\nbenefits. This study reviews the research performance of top IITs-Bombay,\nDelhi, Madras, Kharagpur, and Kanpur based on Scopus-indexed publications\n(1952-2024). Research output has grown exponentially, supported by increased\nfunding and collaborations. IIT-Kanpur excels in research impact, while\nIIT-Bombay and IIT-Madras are highly productive but show slightly lower\nper-paper impact. Internationally, IITs collaborate robustly with the USA,\nGermany, and the UK, alongside Asian nations like Japan and South Korea, with\nIIT-Madras leading inter-IIT partnerships. Research priorities align with SDG 3\n(Health), SDG 7 (Clean Energy), and SDG 11 (Sustainable Cities). Despite\nstrengths in fields like energy, fluid dynamics, and materials science,\nchallenges persist, including limited collaboration with newer IITs and gaps in\nemerging fields. Strengthening specialization and partnerships is crucial for\naddressing global challenges and advancing sustainable development.",
    "pdf_url": "http://arxiv.org/pdf/2411.15451v1",
    "published": "2024-11-23T04:45:18+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15450v1",
    "title": "Unveiling the Achilles' Heel: Backdoor Watermarking Forgery Attack in Public Dataset Protection",
    "authors": [
      "Zhiying Li",
      "Zhi Liu",
      "Dongjie Liu",
      "Shengda Zhuo",
      "Guanggang Geng",
      "Jian Weng",
      "Shanxiang Lyu",
      "Xiaobo Jin"
    ],
    "abstract": "High-quality datasets can greatly promote the development of technology.\nHowever, dataset construction is expensive and time-consuming, and public\ndatasets are easily exploited by opportunists who are greedy for quick gains,\nwhich seriously infringes the rights and interests of dataset owners. At\npresent, backdoor watermarks redefine dataset protection as proof of ownership\nand become a popular method to protect the copyright of public datasets, which\neffectively safeguards the rights of owners and promotes the development of\nopen source communities. In this paper, we question the reliability of backdoor\nwatermarks and re-examine them from the perspective of attackers. On the one\nhand, we refine the process of backdoor watermarks by introducing a third-party\njudicial agency to enhance its practical applicability in real-world scenarios.\nOn the other hand, by exploring the problem of forgery attacks, we reveal the\ninherent flaws of the dataset ownership verification process. Specifically, we\ndesign a Forgery Watermark Generator (FW-Gen) to generate forged watermarks and\ndefine a distillation loss between the original watermark and the forged\nwatermark to transfer the information in the original watermark to the forged\nwatermark. Extensive experiments show that forged watermarks have the same\nstatistical significance as original watermarks in copyright verification tests\nunder various conditions and scenarios, indicating that dataset ownership\nverification results are insufficient to determine infringement. These findings\nhighlight the unreliability of backdoor watermarking methods for dataset\nownership verification and suggest new directions for enhancing methods for\nprotecting public datasets.",
    "pdf_url": "http://arxiv.org/pdf/2411.15450v1",
    "published": "2024-11-23T04:39:52+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2411.16726v2",
    "title": "EmotiveTalk: Expressive Talking Head Generation through Audio Information Decoupling and Emotional Video Diffusion",
    "authors": [
      "Haotian Wang",
      "Yuzhe Weng",
      "Yueyan Li",
      "Zilu Guo",
      "Jun Du",
      "Shutong Niu",
      "Jiefeng Ma",
      "Shan He",
      "Xiaoyan Wu",
      "Qiming Hu",
      "Bing Yin",
      "Cong Liu",
      "Qingfeng Liu"
    ],
    "abstract": "Diffusion models have revolutionized the field of talking head generation,\nyet still face challenges in expressiveness, controllability, and stability in\nlong-time generation. In this research, we propose an EmotiveTalk framework to\naddress these issues. Firstly, to realize better control over the generation of\nlip movement and facial expression, a Vision-guided Audio Information\nDecoupling (V-AID) approach is designed to generate audio-based decoupled\nrepresentations aligned with lip movements and expression. Specifically, to\nachieve alignment between audio and facial expression representation spaces, we\npresent a Diffusion-based Co-speech Temporal Expansion (Di-CTE) module within\nV-AID to generate expression-related representations under multi-source emotion\ncondition constraints. Then we propose a well-designed Emotional Talking Head\nDiffusion (ETHD) backbone to efficiently generate highly expressive talking\nhead videos, which contains an Expression Decoupling Injection (EDI) module to\nautomatically decouple the expressions from reference portraits while\nintegrating the target expression information, achieving more expressive\ngeneration performance. Experimental results show that EmotiveTalk can generate\nexpressive talking head videos, ensuring the promised controllability of\nemotions and stability during long-time generation, yielding state-of-the-art\nperformance compared to existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2411.16726v2",
    "published": "2024-11-23T04:38:51+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15449v1",
    "title": "A Representation theoretic perspective of Koszul theory",
    "authors": [
      "Ales Bouhada",
      "Min Huang",
      "Zetao Lin",
      "Shiping Liu"
    ],
    "abstract": "We discover a new connection between Koszul theory and representation theory.\nLet $\\La$ be a quadratic algebra defined by a locally finite quiver with\nrelations. Firstly, we give a combinatorial description of the local Koszul\ncomplexes and the quadratic dual $\\La^!$, which enables us to describe the\nlinear projective resolutions and the colinear injective coresolutions of\ngraded simple $\\La$-modules in terms of $\\La^!$. As applications, we obtain a\nnew class of Koszul algebras and a stronger version of the Extension Conjecture\nfor finite dimensional Koszul algebras with a noetherian Koszul dual. Then we\nconstruct two Koszul functors, which induce a $2$-real-parameter family of\npairs of derived Koszul functors between categories derived from graded\n$\\La$-modules and those derived from graded $\\La^!$-modules. In case $\\La$ is\nKoszul, each pair of derived Koszul functors are mutually quasi-inverse, one of\nthe pairs is Beilinson, Ginzburg and Soergel's Koszul duality. If $\\La$ and\n$\\La^!$ are locally bounded on opposite sides, then the Koszul functors induce\ntwo equivalences of bounded derived categories: one for finitely\npiece-supported graded modules, and one for finite dimensional graded modules.\nAnd if $\\La$ and $\\La^!$ are both locally bounded, then the bounded derived\ncategory of finite dimensional graded $\\La$-modules has almost split triangles\nwith the Auslander-Reiten translations and the Serre functors given by\ncomposites of derived Koszul functors.",
    "pdf_url": "http://arxiv.org/pdf/2411.15449v1",
    "published": "2024-11-23T04:29:42+00:00",
    "categories": [
      "math.RT"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15448v1",
    "title": "HPCAdvisor: A Tool for Assisting Users in Selecting HPC Resources in the Cloud",
    "authors": [
      "Marco A. S. Netto"
    ],
    "abstract": "Cloud platforms are increasingly being used to run HPC workloads. Major cloud\nproviders offer a wide variety of virtual machine (VM) types, enabling users to\nfind the optimal balance between performance and cost. However, this extensive\nselection of VM types can also present challenges, as users must decide not\nonly which VM types to use but also how many nodes are required for a given\nworkload. Although benchmarking data is available for well-known applications\nfrom major cloud providers, the choice of resources is also influenced by the\nspecifics of the user's application input. This paper presents the vision and\ncurrent implementation of HPCAdvisor, a tool designed to assist users in\ndefining their HPC clusters in the cloud. It considers the application's input\nand utilizes a major cloud provider as a use case for its back-end component.",
    "pdf_url": "http://arxiv.org/pdf/2411.15448v1",
    "published": "2024-11-23T04:27:54+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15447v4",
    "title": "Gotta Hear Them All: Towards Sound Source Aware Audio Generation",
    "authors": [
      "Wei Guo",
      "Heng Wang",
      "Jianbo Ma",
      "Weidong Cai"
    ],
    "abstract": "Audio synthesis has broad applications in multimedia. Recent advancements\nhave made it possible to generate relevant audios from inputs describing an\naudio scene, such as images or texts. However, the immersiveness and\nexpressiveness of the generation are limited. One possible problem is that\nexisting methods solely rely on the global scene and overlook details of local\nsounding objects (i.e., sound sources). To address this issue, we propose a\nSound Source-Aware Audio (SS2A) generator. SS2A is able to locally perceive\nmultimodal sound sources from a scene with visual detection and cross-modality\ntranslation. It then contrastively learns a Cross-Modal Sound Source (CMSS)\nManifold to semantically disambiguate each source. Finally, we attentively mix\ntheir CMSS semantics into a rich audio representation, from which a pretrained\naudio generator outputs the sound. To model the CMSS manifold, we curate a\nnovel single-sound-source visual-audio dataset VGGS3 from VGGSound. We also\ndesign a Sound Source Matching Score to clearly measure localized audio\nrelevance. With the effectiveness of explicit sound source modeling, SS2A\nachieves state-of-the-art performance in extensive image-to-audio tasks. We\nalso qualitatively demonstrate SS2A's ability to achieve intuitive synthesis\ncontrol by compositing vision, text, and audio conditions. Furthermore, we show\nthat our sound source modeling can achieve competitive video-to-audio\nperformance with a straightforward temporal aggregation mechanism.",
    "pdf_url": "http://arxiv.org/pdf/2411.15447v4",
    "published": "2024-11-23T04:27:19+00:00",
    "categories": [
      "cs.MM",
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15446v1",
    "title": "freePruner: A Training-free Approach for Large Multimodal Model Acceleration",
    "authors": [
      "Bingxin Xu",
      "Yuzhang Shang",
      "Yunhao Ge",
      "Qian Lou",
      "Yan Yan"
    ],
    "abstract": "Large Multimodal Models (LMMs) have demonstrated impressive capabilities in\nvisual-language tasks but face significant deployment challenges due to their\nhigh computational demands. While recent token reduction methods show promise\nfor accelerating LMMs, they typically require extensive retraining or\nfine-tuning, making them impractical for many state-of-the-art models,\nespecially those with proprietary training data. We propose freePruner, a\ntraining-free token reduction approach that can be directly applied to any\nopen-source LMM without additional training. Unlike existing methods that rely\nheavily on token merging operations, freePruner employs a two-stage token\nselection strategy: (1) identifying pivotal tokens that capture high-level\nsemantic information using our designed contribution degree metric, and (2)\nselecting complementary tokens that preserve essential low-level visual details\nthrough attention pattern analysis. Extensive experiments demonstrate that\nfreePruner achieves 2x acceleration while maintaining comparable performance\nacross mainstream visual question-answering benchmarks in the training-free\nsetting. Moreover, freePruner is orthogonal to and can be combined with other\npost-training acceleration techniques, such as post-training quantization,\nproviding a practical solution for efficient LMM deployment.",
    "pdf_url": "http://arxiv.org/pdf/2411.15446v1",
    "published": "2024-11-23T04:25:16+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15445v1",
    "title": "Continuity Reinforcement Skeleton for Pixel-based Haptic Display",
    "authors": [
      "Xinyuan Wang",
      "Zhiqiang Meng",
      "Chang Qing Chen"
    ],
    "abstract": "Haptic displays are crucial for facilitating an immersive experience within\nvirtual reality. However, when displaying continuous movements of contact, such\nas stroking and exploration, pixel-based haptic devices suffer from losing\nhaptic information between pixels, leading to discontinuity. The trade-off\nbetween the travel distance of haptic elements and their pixel size in thin\nwearable devices hinders solutions that solely rely on increasing pixel\ndensity. Here we introduce a continuity reinforcement skeleton (CRS), which\nemploys physically driven interpolation to enhance haptic information. The CRS\nenables the off-plane displacement to move conformally and display haptic\ninformation between pixel gaps. Efforts are made to quantify haptic display\nquality using geometric, mechanical, and psychological criteria. The\ndevelopment and integration of one-dimensional (1D), two-dimensional (2D), and\ncurved CRS devices with virtual reality systems highlight the impact of CRS on\nhaptic display, showcasing its potential for improving haptic experience.",
    "pdf_url": "http://arxiv.org/pdf/2411.15445v1",
    "published": "2024-11-23T04:23:04+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15444v1",
    "title": "Chip-to-chip quantum photonic controlled-NOT gate teleportation",
    "authors": [
      "Lan-Tian Feng",
      "Ming Zhang",
      "Di Liu",
      "Yu-Jie Cheng",
      "Xin-Yu Song",
      "Yu-Yang Ding",
      "Dao-Xin Dai",
      "Guo-Ping Guo",
      "Guang-Can Guo",
      "Xi-Feng Ren"
    ],
    "abstract": "Quantum networks provide a novel framework for quantum information\nprocessing, significantly enhancing system capacity through the interconnection\nof modular quantum nodes. Beyond the capability to distribute quantum states,\nthe ability to remotely control quantum gates is a pivotal step for quantum\nnetworks. In this Letter, we implement high fidelity quantum controlled-NOT\n(CNOT) gate teleportation with state-of-the-art silicon photonic integrated\ncircuits. Based on on-chip generation of path-entangled quantum state, CNOT\ngate operation and chip-to-chip quantum photonic interconnect, the CNOT gate is\nteleported between two remote quantum nodes connected by the single-mode\noptical fiber. Equip with 5 m (1 km)-long interconnecting fiber, quantum gate\nteleportation is verified by entangling remote qubits with 95.69% +- 1.19%\n(94.07% +- 1.54%) average fidelity and gate tomography with 94.81% +- 0.81%\n(93.04% +- 1.09%) fidelity. These results advance the realization of\nlarge-scale and practical quantum networks with photonic integrated circuits.",
    "pdf_url": "http://arxiv.org/pdf/2411.15444v1",
    "published": "2024-11-23T04:22:33+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15443v1",
    "title": "String breaking mechanism in a lattice Schwinger model simulator",
    "authors": [
      "Ying Liu",
      "Wei-Yong Zhang",
      "Zi-Hang Zhu",
      "Ming-Gen He",
      "Zhen-Sheng Yuan",
      "Jian-Wei Pan"
    ],
    "abstract": "String breaking is a fundamental concept in gauge theories, describing the\ndecay of a flux string connecting two charges through the production of\nparticle-antiparticle pairs. This phenomenon is particularly important in\nparticle physics, notably in Quantum Chromodynamics, and plays a crucial role\nin condensed matter physics. However, achieving a theoretical understanding of\nthis non-perturbative effect is challenging, as conventional numerical\napproaches often fall short and require substantial computational resources. On\nthe experimental side, studying these effects necessitates advanced setups,\nsuch as high-energy colliders, which makes direct observation difficult. Here,\nwe report an experimental investigation of the string breaking mechanism in a\none-dimensional U(1) lattice gauge theory using an optical lattice quantum\nsimulator. By deterministically preparing initial states of varying lengths\nwith fixed charges at each end, and adiabatically tuning the mass and string\ntension, we observed in situ microscopic confined phases that exhibit either\nstring or brokenstring states. Further analysis reveals that string breaking\noccurs under a resonance condition, leading to the creation of new\nparticle-antiparticle pairs. These findings offer compelling evidence of string\nbreaking and provide valuable insights into the intricate dynamics of lattice\ngauge theories. Our work underscores the potential of optical lattices as\ncontrollable quantum simulators, enabling the exploration of complex gauge\ntheories and their associated phenomena.",
    "pdf_url": "http://arxiv.org/pdf/2411.15443v1",
    "published": "2024-11-23T03:57:43+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2411.16725v3",
    "title": "$\\textit{Revelio}$: Interpreting and leveraging semantic information in diffusion models",
    "authors": [
      "Dahye Kim",
      "Xavier Thomas",
      "Deepti Ghadiyaram"
    ],
    "abstract": "We study $\\textit{how}$ rich visual semantic information is represented\nwithin various layers and denoising timesteps of different diffusion\narchitectures. We uncover monosemantic interpretable features by leveraging\nk-sparse autoencoders (k-SAE). We substantiate our mechanistic interpretations\nvia transfer learning using light-weight classifiers on off-the-shelf diffusion\nmodels' features. On $4$ datasets, we demonstrate the effectiveness of\ndiffusion features for representation learning. We provide an in-depth analysis\nof how different diffusion architectures, pre-training datasets, and language\nmodel conditioning impacts visual representation granularity, inductive biases,\nand transfer learning capabilities. Our work is a critical step towards\ndeepening interpretability of black-box diffusion models. Code and\nvisualizations available at: https://github.com/revelio-diffusion/revelio",
    "pdf_url": "http://arxiv.org/pdf/2411.16725v3",
    "published": "2024-11-23T03:54:22+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15442v1",
    "title": "Automatic High-quality Verilog Assertion Generation through Subtask-Focused Fine-Tuned LLMs and Iterative Prompting",
    "authors": [
      "Mohammad Shahidzadeh",
      "Behnam Ghavami",
      "Steve Wilton",
      "Lesley Shannon"
    ],
    "abstract": "Formal Property Verification (FPV), using SystemVerilog Assertions (SVA), is\ncrucial for ensuring the completeness of design with respect to the\nspecification. However, writing SVA is a laborious task and has a steep\nlearning curve. In this work, we present a large language model (LLM) -based\nflow to automatically generate high-quality SVA from the design specification\ndocuments, named \\ToolName. We introduce a novel sub-task-focused fine-tuning\napproach that effectively addresses functionally incorrect assertions produced\nby baseline LLMs, leading to a remarkable 7.3-fold increase in the number of\nfunctionally correct assertions. Recognizing the prevalence of syntax and\nsemantic errors, we also developed an iterative refinement method that enhances\nthe LLM's initial outputs by systematically re-prompting it to correct\nidentified issues. This process is further strengthened by a custom compiler\nthat generates meaningful error messages, guiding the LLM towards improved\naccuracy. The experiments demonstrate a 26\\% increase in the number of\nassertions free from syntax errors using this approach, showcasing its\npotential to streamline the FPV process.",
    "pdf_url": "http://arxiv.org/pdf/2411.15442v1",
    "published": "2024-11-23T03:52:32+00:00",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15441v2",
    "title": "Study of $\\itŒõ_{\\it{b}}^\\rm{0}$ and $\\itŒû_{\\it{b}}^\\rm{0}$ decays to $\\itŒõ h^+h^{'-}$ and evidence for $CP$ violation in $\\itŒõ_{\\it{b}}^\\rm{0}\\to\\itŒõ K^+K^-$ decays",
    "authors": [
      "LHCb collaboration",
      "R. Aaij",
      "A. S. W. Abdelmotteleb",
      "C. Abellan Beteta",
      "F. Abudin√©n",
      "T. Ackernley",
      "A. A. Adefisoye",
      "B. Adeva",
      "M. Adinolfi",
      "P. Adlarson",
      "C. Agapopoulou",
      "C. A. Aidala",
      "Z. Ajaltouni",
      "S. Akar",
      "K. Akiba",
      "P. Albicocco",
      "J. Albrecht",
      "F. Alessio",
      "M. Alexander",
      "Z. Aliouche",
      "P. Alvarez Cartelle",
      "R. Amalric",
      "S. Amato",
      "J. L. Amey",
      "Y. Amhis",
      "L. An",
      "L. Anderlini",
      "M. Andersson",
      "A. Andreianov",
      "P. Andreola",
      "M. Andreotti",
      "D. Andreou",
      "A. Anelli",
      "D. Ao",
      "F. Archilli",
      "M. Argenton",
      "S. Arguedas Cuendis",
      "A. Artamonov",
      "M. Artuso",
      "E. Aslanides",
      "R. Ata√≠de Da Silva",
      "M. Atzeni",
      "B. Audurier",
      "D. Bacher",
      "I. Bachiller Perea",
      "S. Bachmann",
      "M. Bachmayer",
      "J. J. Back",
      "P. Baladron Rodriguez",
      "V. Balagura",
      "A. Balboni",
      "W. Baldini",
      "L. Balzani",
      "H. Bao",
      "J. Baptista de Souza Leite",
      "C. Barbero Pretel",
      "M. Barbetti",
      "I. R. Barbosa",
      "R. J. Barlow",
      "M. Barnyakov",
      "S. Barsuk",
      "W. Barter",
      "M. Bartolini",
      "J. Bartz",
      "J. M. Basels",
      "S. Bashir",
      "G. Bassi",
      "B. Batsukh",
      "P. B. Battista",
      "A. Bay",
      "A. Beck",
      "M. Becker",
      "F. Bedeschi",
      "I. B. Bediaga",
      "N. A. Behling",
      "S. Belin",
      "K. Belous",
      "I. Belov",
      "I. Belyaev",
      "G. Benane",
      "G. Bencivenni",
      "E. Ben-Haim",
      "A. Berezhnoy",
      "R. Bernet",
      "S. Bernet Andres",
      "A. Bertolin",
      "C. Betancourt",
      "F. Betti",
      "J. Bex",
      "Ia. Bezshyiko",
      "J. Bhom",
      "M. S. Bieker",
      "N. V. Biesuz",
      "P. Billoir",
      "A. Biolchini",
      "M. Birch",
      "F. C. R. Bishop",
      "A. Bitadze",
      "A. Bizzeti",
      "T. Blake",
      "F. Blanc",
      "J. E. Blank",
      "S. Blusk",
      "V. Bocharnikov",
      "J. A. Boelhauve",
      "O. Boente Garcia",
      "T. Boettcher",
      "A. Bohare",
      "A. Boldyrev",
      "C. S. Bolognani",
      "R. Bolzonella",
      "R. B. Bonacci",
      "N. Bondar",
      "A. Bordelius",
      "F. Borgato",
      "S. Borghi",
      "M. Borsato",
      "J. T. Borsuk",
      "S. A. Bouchiba",
      "M. Bovill",
      "T. J. V. Bowcock",
      "A. Boyer",
      "C. Bozzi",
      "A. Brea Rodriguez",
      "N. Breer",
      "J. Brodzicka",
      "A. Brossa Gonzalo",
      "J. Brown",
      "D. Brundu",
      "E. Buchanan",
      "A. Buonaura",
      "L. Buonincontri",
      "A. T. Burke",
      "C. Burr",
      "J. S. Butter",
      "J. Buytaert",
      "W. Byczynski",
      "S. Cadeddu",
      "H. Cai",
      "A. C. Caillet",
      "R. Calabrese",
      "S. Calderon Ramirez",
      "L. Calefice",
      "S. Cali",
      "M. Calvi",
      "M. Calvo Gomez",
      "P. Camargo Magalhaes",
      "J. I. Cambon Bouzas",
      "P. Campana",
      "D. H. Campora Perez",
      "A. F. Campoverde Quezada",
      "S. Capelli",
      "L. Capriotti",
      "R. Caravaca-Mora",
      "A. Carbone",
      "L. Carcedo Salgado",
      "R. Cardinale",
      "A. Cardini",
      "P. Carniti",
      "L. Carus",
      "A. Casais Vidal",
      "R. Caspary",
      "G. Casse",
      "M. Cattaneo",
      "G. Cavallero",
      "V. Cavallini",
      "S. Celani",
      "D. Cervenkov",
      "S. Cesare",
      "A. J. Chadwick",
      "I. Chahrour",
      "M. Charles",
      "Ph. Charpentier",
      "E. Chatzianagnostou",
      "M. Chefdeville",
      "C. Chen",
      "S. Chen",
      "Z. Chen",
      "A. Chernov",
      "S. Chernyshenko",
      "X. Chiotopoulos",
      "V. Chobanova",
      "S. Cholak",
      "M. Chrzaszcz",
      "A. Chubykin",
      "V. Chulikov",
      "P. Ciambrone",
      "X. Cid Vidal",
      "G. Ciezarek",
      "P. Cifra",
      "P. E. L. Clarke",
      "M. Clemencic",
      "H. V. Cliff",
      "J. Closier",
      "C. Cocha Toapaxi",
      "V. Coco",
      "J. Cogan",
      "E. Cogneras",
      "L. Cojocariu",
      "S. Collaviti",
      "P. Collins",
      "T. Colombo",
      "M. Colonna",
      "A. Comerma-Montells",
      "L. Congedo",
      "A. Contu",
      "N. Cooke",
      "I. Corredoira",
      "A. Correia",
      "G. Corti",
      "J. J. Cottee Meldrum",
      "B. Couturier",
      "D. C. Craik",
      "M. Cruz Torres",
      "E. Curras Rivera",
      "R. Currie",
      "C. L. Da Silva",
      "S. Dadabaev",
      "L. Dai",
      "X. Dai",
      "E. Dall'Occo",
      "J. Dalseno",
      "C. D'Ambrosio",
      "J. Daniel",
      "A. Danilina",
      "P. d'Argent",
      "G. Darze",
      "A. Davidson",
      "J. E. Davies",
      "A. Davis",
      "O. De Aguiar Francisco",
      "C. De Angelis",
      "F. De Benedetti",
      "J. de Boer",
      "K. De Bruyn",
      "S. De Capua",
      "M. De Cian",
      "U. De Freitas Carneiro Da Graca",
      "E. De Lucia",
      "J. M. De Miranda",
      "L. De Paula",
      "M. De Serio",
      "P. De Simone",
      "F. De Vellis",
      "J. A. de Vries",
      "F. Debernardis",
      "D. Decamp",
      "V. Dedu",
      "S. Dekkers",
      "L. Del Buono",
      "B. Delaney",
      "H. -P. Dembinski",
      "J. Deng",
      "V. Denysenko",
      "O. Deschamps",
      "F. Dettori",
      "B. Dey",
      "P. Di Nezza",
      "I. Diachkov",
      "S. Didenko",
      "S. Ding",
      "L. Dittmann",
      "V. Dobishuk",
      "A. D. Docheva",
      "C. Dong",
      "A. M. Donohoe",
      "F. Dordei",
      "A. C. dos Reis",
      "A. D. Dowling",
      "W. Duan",
      "P. Duda",
      "M. W. Dudek",
      "L. Dufour",
      "V. Duk",
      "P. Durante",
      "M. M. Duras",
      "J. M. Durham",
      "O. D. Durmus",
      "A. Dziurda",
      "A. Dzyuba",
      "S. Easo",
      "E. Eckstein",
      "U. Egede",
      "A. Egorychev",
      "V. Egorychev",
      "S. Eisenhardt",
      "E. Ejopu",
      "L. Eklund",
      "M. Elashri",
      "J. Ellbracht",
      "S. Ely",
      "A. Ene",
      "J. Eschle",
      "S. Esen",
      "T. Evans",
      "F. Fabiano",
      "L. N. Falcao",
      "Y. Fan",
      "B. Fang",
      "L. Fantini",
      "M. Faria",
      "K. Farmer",
      "D. Fazzini",
      "L. Felkowski",
      "M. Feng",
      "M. Feo",
      "A. Fernandez Casani",
      "M. Fernandez Gomez",
      "A. D. Fernez",
      "F. Ferrari",
      "F. Ferreira Rodrigues",
      "M. Ferrillo",
      "M. Ferro-Luzzi",
      "S. Filippov",
      "R. A. Fini",
      "M. Fiorini",
      "M. Firlej",
      "K. L. Fischer",
      "D. S. Fitzgerald",
      "C. Fitzpatrick",
      "T. Fiutowski",
      "F. Fleuret",
      "M. Fontana",
      "L. F. Foreman",
      "R. Forty",
      "D. Foulds-Holt",
      "V. Franco Lima",
      "M. Franco Sevilla",
      "M. Frank",
      "E. Franzoso",
      "G. Frau",
      "C. Frei",
      "D. A. Friday",
      "J. Fu",
      "Q. F√ºhring",
      "Y. Fujii",
      "T. Fulghesu",
      "E. Gabriel",
      "G. Galati",
      "M. D. Galati",
      "A. Gallas Torreira",
      "D. Galli",
      "S. Gambetta",
      "M. Gandelman",
      "P. Gandini",
      "B. Ganie",
      "H. Gao",
      "R. Gao",
      "T. Q. Gao",
      "Y. Gao",
      "Y. Gao",
      "Y. Gao",
      "L. M. Garcia Martin",
      "P. Garcia Moreno",
      "J. Garc√≠a Pardi√±as",
      "P. Gardner",
      "K. G. Garg",
      "L. Garrido",
      "C. Gaspar",
      "R. E. Geertsema",
      "L. L. Gerken",
      "E. Gersabeck",
      "M. Gersabeck",
      "T. Gershon",
      "S. Ghizzo",
      "Z. Ghorbanimoghaddam",
      "L. Giambastiani",
      "F. I. Giasemis",
      "V. Gibson",
      "H. K. Giemza",
      "A. L. Gilman",
      "M. Giovannetti",
      "A. Giovent√π",
      "L. Girardey",
      "P. Gironella Gironell",
      "C. Giugliano",
      "M. A. Giza",
      "E. L. Gkougkousis",
      "F. C. Glaser",
      "V. V. Gligorov",
      "C. G√∂bel",
      "E. Golobardes",
      "D. Golubkov",
      "A. Golutvin",
      "S. Gomez Fernandez",
      "W. Gomulka",
      "F. Goncalves Abrantes",
      "M. Goncerz",
      "G. Gong",
      "J. A. Gooding",
      "I. V. Gorelov",
      "C. Gotti",
      "J. P. Grabowski",
      "L. A. Granado Cardoso",
      "E. Graug√©s",
      "E. Graverini",
      "L. Grazette",
      "G. Graziani",
      "A. T. Grecu",
      "L. M. Greeven",
      "N. A. Grieser",
      "L. Grillo",
      "S. Gromov",
      "C. Gu",
      "M. Guarise",
      "L. Guerry",
      "M. Guittiere",
      "V. Guliaeva",
      "P. A. G√ºnther",
      "A. -K. Guseinov",
      "E. Gushchin",
      "Y. Guz",
      "T. Gys",
      "K. Habermann",
      "T. Hadavizadeh",
      "C. Hadjivasiliou",
      "G. Haefeli",
      "C. Haen",
      "M. Hajheidari",
      "G. Hallett",
      "M. M. Halvorsen",
      "P. M. Hamilton",
      "J. Hammerich",
      "Q. Han",
      "X. Han",
      "S. Hansmann-Menzemer",
      "L. Hao",
      "N. Harnew",
      "T. H. Harris",
      "M. Hartmann",
      "S. Hashmi",
      "J. He",
      "F. Hemmer",
      "C. Henderson",
      "R. D. L. Henderson",
      "A. M. Hennequin",
      "K. Hennessy",
      "L. Henry",
      "J. Herd",
      "P. Herrero Gascon",
      "J. Heuel",
      "A. Hicheur",
      "G. Hijano Mendizabal",
      "J. Horswill",
      "R. Hou",
      "Y. Hou",
      "N. Howarth",
      "J. Hu",
      "W. Hu",
      "X. Hu",
      "W. Huang",
      "W. Hulsbergen",
      "R. J. Hunter",
      "M. Hushchyn",
      "D. Hutchcroft",
      "M. Idzik",
      "D. Ilin",
      "P. Ilten",
      "A. Inglessi",
      "A. Iniukhin",
      "A. Ishteev",
      "K. Ivshin",
      "R. Jacobsson",
      "H. Jage",
      "S. J. Jaimes Elles",
      "S. Jakobsen",
      "E. Jans",
      "B. K. Jashal",
      "A. Jawahery",
      "V. Jevtic",
      "E. Jiang",
      "X. Jiang",
      "Y. Jiang",
      "Y. J. Jiang",
      "M. John",
      "A. John Rubesh Rajan",
      "D. Johnson",
      "C. R. Jones",
      "T. P. Jones",
      "S. Joshi",
      "B. Jost",
      "J. Juan Castella",
      "N. Jurik",
      "I. Juszczak",
      "D. Kaminaris",
      "S. Kandybei",
      "M. Kane",
      "Y. Kang",
      "C. Kar",
      "M. Karacson",
      "D. Karpenkov",
      "A. Kauniskangas",
      "J. W. Kautz",
      "M. K. Kazanecki",
      "F. Keizer",
      "M. Kenzie",
      "T. Ketel",
      "B. Khanji",
      "A. Kharisova",
      "S. Kholodenko",
      "G. Khreich",
      "T. Kirn",
      "V. S. Kirsebom",
      "O. Kitouni",
      "S. Klaver",
      "N. Kleijne",
      "K. Klimaszewski",
      "M. R. Kmiec",
      "S. Koliiev",
      "L. Kolk",
      "A. Konoplyannikov",
      "P. Kopciewicz",
      "P. Koppenburg",
      "M. Korolev",
      "I. Kostiuk",
      "O. Kot",
      "S. Kotriakhova",
      "A. Kozachuk",
      "P. Kravchenko",
      "L. Kravchuk",
      "M. Kreps",
      "P. Krokovny",
      "W. Krupa",
      "W. Krzemien",
      "O. Kshyvanskyi",
      "S. Kubis",
      "M. Kucharczyk",
      "V. Kudryavtsev",
      "E. Kulikova",
      "A. Kupsc",
      "B. K. Kutsenko",
      "D. Lacarrere",
      "P. Laguarta Gonzalez",
      "A. Lai",
      "A. Lampis",
      "D. Lancierini",
      "C. Landesa Gomez",
      "J. J. Lane",
      "R. Lane",
      "G. Lanfranchi",
      "C. Langenbruch",
      "J. Langer",
      "O. Lantwin",
      "T. Latham",
      "F. Lazzari",
      "C. Lazzeroni",
      "R. Le Gac",
      "H. Lee",
      "R. Lef√®vre",
      "A. Leflat",
      "S. Legotin",
      "M. Lehuraux",
      "E. Lemos Cid",
      "O. Leroy",
      "T. Lesiak",
      "E. D. Lesser",
      "B. Leverington",
      "A. Li",
      "C. Li",
      "H. Li",
      "K. Li",
      "L. Li",
      "M. Li",
      "P. Li",
      "P. -R. Li",
      "Q. Li",
      "S. Li",
      "T. Li",
      "T. Li",
      "Y. Li",
      "Y. Li",
      "Z. Lian",
      "X. Liang",
      "S. Libralon",
      "C. Lin",
      "T. Lin",
      "R. Lindner",
      "H. Linton",
      "V. Lisovskyi",
      "R. Litvinov",
      "F. L. Liu",
      "G. Liu",
      "K. Liu",
      "S. Liu",
      "W. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. L. Liu",
      "A. Lobo Salvia",
      "A. Loi",
      "T. Long",
      "J. H. Lopes",
      "A. Lopez Huertas",
      "S. L√≥pez Soli√±o",
      "Q. Lu",
      "C. Lucarelli",
      "D. Lucchesi",
      "M. Lucio Martinez",
      "V. Lukashenko",
      "Y. Luo",
      "A. Lupato",
      "E. Luppi",
      "K. Lynch",
      "X. -R. Lyu",
      "G. M. Ma",
      "S. Maccolini",
      "F. Machefert",
      "F. Maciuc",
      "B. Mack",
      "I. Mackay",
      "L. M. Mackey",
      "L. R. Madhan Mohan",
      "M. J. Madurai",
      "A. Maevskiy",
      "D. Magdalinski",
      "D. Maisuzenko",
      "M. W. Majewski",
      "J. J. Malczewski",
      "S. Malde",
      "L. Malentacca",
      "A. Malinin",
      "T. Maltsev",
      "G. Manca",
      "G. Mancinelli",
      "C. Mancuso",
      "R. Manera Escalero",
      "F. M. Manganella",
      "D. Manuzzi",
      "D. Marangotto",
      "J. F. Marchand",
      "R. Marchevski",
      "U. Marconi",
      "E. Mariani",
      "S. Mariani",
      "C. Marin Benito",
      "J. Marks",
      "A. M. Marshall",
      "L. Martel",
      "G. Martelli",
      "G. Martellotti",
      "L. Martinazzoli",
      "M. Martinelli",
      "D. Martinez Gomez",
      "D. Martinez Santos",
      "F. Martinez Vidal",
      "A. Martorell i Granollers",
      "A. Massafferri",
      "R. Matev",
      "A. Mathad",
      "V. Matiunin",
      "C. Matteuzzi",
      "K. R. Mattioli",
      "A. Mauri",
      "E. Maurice",
      "J. Mauricio",
      "P. Mayencourt",
      "J. Mazorra de Cos",
      "M. Mazurek",
      "M. McCann",
      "L. Mcconnell",
      "T. H. McGrath",
      "N. T. McHugh",
      "A. McNab",
      "R. McNulty",
      "B. Meadows",
      "G. Meier",
      "D. Melnychuk",
      "F. M. Meng",
      "M. Merk",
      "A. Merli",
      "L. Meyer Garcia",
      "D. Miao",
      "H. Miao",
      "M. Mikhasenko",
      "D. A. Milanes",
      "A. Minotti",
      "E. Minucci",
      "T. Miralles",
      "B. Mitreska",
      "D. S. Mitzel",
      "A. Modak",
      "R. A. Mohammed",
      "R. D. Moise",
      "S. Mokhnenko",
      "E. F. Molina Cardenas",
      "T. Momb√§cher",
      "M. Monk",
      "S. Monteil",
      "A. Morcillo Gomez",
      "G. Morello",
      "M. J. Morello",
      "M. P. Morgenthaler",
      "J. Moron",
      "W. Morren",
      "A. B. Morris",
      "A. G. Morris",
      "R. Mountain",
      "H. Mu",
      "Z. M. Mu",
      "E. Muhammad",
      "F. Muheim",
      "M. Mulder",
      "K. M√ºller",
      "F. Mu√±oz-Rojas",
      "R. Murta",
      "P. Naik",
      "T. Nakada",
      "R. Nandakumar",
      "T. Nanut",
      "I. Nasteva",
      "M. Needham",
      "N. Neri",
      "S. Neubert",
      "N. Neufeld",
      "P. Neustroev",
      "J. Nicolini",
      "D. Nicotra",
      "E. M. Niel",
      "N. Nikitin",
      "Q. Niu",
      "P. Nogarolli",
      "P. Nogga",
      "C. Normand",
      "J. Novoa Fernandez",
      "G. Nowak",
      "C. Nunez",
      "H. N. Nur",
      "A. Oblakowska-Mucha",
      "V. Obraztsov",
      "T. Oeser",
      "S. Okamura",
      "A. Okhotnikov",
      "O. Okhrimenko",
      "R. Oldeman",
      "F. Oliva",
      "M. Olocco",
      "C. J. G. Onderwater",
      "R. H. O'Neil",
      "D. Osthues",
      "J. M. Otalora Goicochea",
      "P. Owen",
      "A. Oyanguren",
      "O. Ozcelik",
      "F. Paciolla",
      "A. Padee",
      "K. O. Padeken",
      "B. Pagare",
      "P. R. Pais",
      "T. Pajero",
      "A. Palano",
      "M. Palutan",
      "X. Pan",
      "G. Panshin",
      "L. Paolucci",
      "A. Papanestis",
      "M. Pappagallo",
      "L. L. Pappalardo",
      "C. Pappenheimer",
      "C. Parkes",
      "D. Parmar",
      "B. Passalacqua",
      "G. Passaleva",
      "D. Passaro",
      "A. Pastore",
      "M. Patel",
      "J. Patoc",
      "C. Patrignani",
      "A. Paul",
      "C. J. Pawley",
      "A. Pellegrino",
      "J. Peng",
      "M. Pepe Altarelli",
      "S. Perazzini",
      "D. Pereima",
      "H. Pereira Da Costa",
      "A. Pereiro Castro",
      "P. Perret",
      "A. Perrevoort",
      "A. Perro",
      "M. J. Peters",
      "K. Petridis",
      "A. Petrolini",
      "J. P. Pfaller",
      "H. Pham",
      "L. Pica",
      "M. Piccini",
      "L. Piccolo",
      "B. Pietrzyk",
      "G. Pietrzyk",
      "D. Pinci",
      "F. Pisani",
      "M. Pizzichemi",
      "V. Placinta",
      "M. Plo Casasus",
      "T. Poeschl",
      "F. Polci",
      "M. Poli Lener",
      "A. Poluektov",
      "N. Polukhina",
      "I. Polyakov",
      "E. Polycarpo",
      "S. Ponce",
      "D. Popov",
      "S. Poslavskii",
      "K. Prasanth",
      "C. Prouve",
      "D. Provenzano",
      "V. Pugatch",
      "G. Punzi",
      "S. Qasim",
      "Q. Q. Qian",
      "W. Qian",
      "N. Qin",
      "S. Qu",
      "R. Quagliani",
      "R. I. Rabadan Trejo",
      "J. H. Rademacker",
      "M. Rama",
      "M. Ram√≠rez Garc√≠a",
      "V. Ramos De Oliveira",
      "M. Ramos Pernas",
      "M. S. Rangel",
      "F. Ratnikov",
      "G. Raven",
      "M. Rebollo De Miguel",
      "F. Redi",
      "J. Reich",
      "F. Reiss",
      "Z. Ren",
      "P. K. Resmi",
      "R. Ribatti",
      "G. R. Ricart",
      "D. Riccardi",
      "S. Ricciardi",
      "K. Richardson",
      "M. Richardson-Slipper",
      "K. Rinnert",
      "P. Robbe",
      "G. Robertson",
      "E. Rodrigues",
      "A. Rodriguez Alvarez",
      "E. Rodriguez Fernandez",
      "J. A. Rodriguez Lopez",
      "E. Rodriguez Rodriguez",
      "J. Roensch",
      "A. Rogachev",
      "A. Rogovskiy",
      "D. L. Rolf",
      "P. Roloff",
      "V. Romanovskiy",
      "A. Romero Vidal",
      "G. Romolini",
      "F. Ronchetti",
      "T. Rong",
      "M. Rotondo",
      "S. R. Roy",
      "M. S. Rudolph",
      "M. Ruiz Diaz",
      "R. A. Ruiz Fernandez",
      "J. Ruiz Vidal",
      "A. Ryzhikov",
      "J. Ryzka",
      "J. J. Saavedra-Arias",
      "J. J. Saborido Silva",
      "R. Sadek",
      "N. Sagidova",
      "D. Sahoo",
      "N. Sahoo",
      "B. Saitta",
      "M. Salomoni",
      "I. Sanderswood",
      "R. Santacesaria",
      "C. Santamarina Rios",
      "M. Santimaria",
      "L. Santoro",
      "E. Santovetti",
      "A. Saputi",
      "D. Saranin",
      "A. Sarnatskiy",
      "G. Sarpis",
      "M. Sarpis",
      "C. Satriano",
      "A. Satta",
      "M. Saur",
      "D. Savrina",
      "H. Sazak",
      "F. Sborzacchi",
      "L. G. Scantlebury Smead",
      "A. Scarabotto",
      "S. Schael",
      "S. Scherl",
      "M. Schiller",
      "H. Schindler",
      "M. Schmelling",
      "B. Schmidt",
      "S. Schmitt",
      "H. Schmitz",
      "O. Schneider",
      "A. Schopper",
      "N. Schulte",
      "S. Schulte",
      "M. H. Schune",
      "R. Schwemmer",
      "G. Schwering",
      "B. Sciascia",
      "A. Sciuccati",
      "I. Segal",
      "S. Sellam",
      "A. Semennikov",
      "T. Senger",
      "M. Senghi Soares",
      "A. Sergi",
      "N. Serra",
      "L. Sestini",
      "A. Seuthe",
      "Y. Shang",
      "D. M. Shangase",
      "M. Shapkin",
      "R. S. Sharma",
      "I. Shchemerov",
      "L. Shchutska",
      "T. Shears",
      "L. Shekhtman",
      "Z. Shen",
      "S. Sheng",
      "V. Shevchenko",
      "B. Shi",
      "Q. Shi",
      "Y. Shimizu",
      "E. Shmanin",
      "R. Shorkin",
      "J. D. Shupperd",
      "R. Silva Coutinho",
      "G. Simi",
      "S. Simone",
      "N. Skidmore",
      "T. Skwarnicki",
      "M. W. Slater",
      "J. C. Smallwood",
      "E. Smith",
      "K. Smith",
      "M. Smith",
      "A. Snoch",
      "L. Soares Lavra",
      "M. D. Sokoloff",
      "F. J. P. Soler",
      "A. Solomin",
      "A. Solovev",
      "I. Solovyev",
      "N. S. Sommerfeld",
      "R. Song",
      "Y. Song",
      "Y. Song",
      "Y. S. Song",
      "F. L. Souza De Almeida",
      "B. Souza De Paula",
      "E. Spadaro Norella",
      "E. Spedicato",
      "J. G. Speer",
      "E. Spiridenkov",
      "P. Spradlin",
      "V. Sriskaran",
      "F. Stagni",
      "M. Stahl",
      "S. Stahl",
      "S. Stanislaus",
      "E. N. Stein",
      "O. Steinkamp",
      "O. Stenyakin",
      "H. Stevens",
      "D. Strekalina",
      "Y. Su",
      "F. Suljik",
      "J. Sun",
      "L. Sun",
      "D. Sundfeld",
      "W. Sutcliffe",
      "P. N. Swallow",
      "K. Swientek",
      "F. Swystun",
      "A. Szabelski",
      "T. Szumlak",
      "Y. Tan",
      "Y. Tang",
      "M. D. Tat",
      "A. Terentev",
      "F. Terzuoli",
      "F. Teubert",
      "E. Thomas",
      "D. J. D. Thompson",
      "H. Tilquin",
      "V. Tisserand",
      "S. T'Jampens",
      "M. Tobin",
      "L. Tomassetti",
      "G. Tonani",
      "X. Tong",
      "D. Torres Machado",
      "L. Toscano",
      "D. Y. Tou",
      "C. Trippl",
      "G. Tuci",
      "N. Tuning",
      "L. H. Uecker",
      "A. Ukleja",
      "D. J. Unverzagt",
      "B. Urbach",
      "E. Ursov",
      "A. Usachov",
      "A. Ustyuzhanin",
      "U. Uwer",
      "V. Vagnoni",
      "V. Valcarce Cadenas",
      "G. Valenti",
      "N. Valls Canudas",
      "J. van Eldik",
      "H. Van Hecke",
      "E. van Herwijnen",
      "C. B. Van Hulse",
      "R. Van Laak",
      "M. van Veghel",
      "G. Vasquez",
      "R. Vazquez Gomez",
      "P. Vazquez Regueiro",
      "C. V√°zquez Sierra",
      "S. Vecchi",
      "J. J. Velthuis",
      "M. Veltri",
      "A. Venkateswaran",
      "M. Verdoglia",
      "M. Vesterinen",
      "D. Vico Benet",
      "P. Vidrier Villalba",
      "M. Vieites Diaz",
      "X. Vilasis-Cardona",
      "E. Vilella Figueras",
      "A. Villa",
      "P. Vincent",
      "F. C. Volle",
      "D. vom Bruch",
      "N. Voropaev",
      "K. Vos",
      "C. Vrahas",
      "J. Wagner",
      "J. Walsh",
      "E. J. Walton",
      "G. Wan",
      "C. Wang",
      "G. Wang",
      "H. Wang",
      "J. Wang",
      "J. Wang",
      "J. Wang",
      "J. Wang",
      "M. Wang",
      "N. W. Wang",
      "R. Wang",
      "X. Wang",
      "X. Wang",
      "X. W. Wang",
      "Y. Wang",
      "Y. W. Wang",
      "Z. Wang",
      "Z. Wang",
      "Z. Wang",
      "J. A. Ward",
      "M. Waterlaat",
      "N. K. Watson",
      "D. Websdale",
      "Y. Wei",
      "J. Wendel",
      "B. D. C. Westhenry",
      "C. White",
      "M. Whitehead",
      "E. Whiter",
      "A. R. Wiederhold",
      "D. Wiedner",
      "G. Wilkinson",
      "M. K. Wilkinson",
      "M. Williams",
      "M. J. Williams",
      "M. R. J. Williams",
      "R. Williams",
      "Z. Williams",
      "F. F. Wilson",
      "M. Winn",
      "W. Wislicki",
      "M. Witek",
      "L. Witola",
      "G. Wormser",
      "S. A. Wotton",
      "H. Wu",
      "J. Wu",
      "X. Wu",
      "Y. Wu",
      "Z. Wu",
      "K. Wyllie",
      "S. Xian",
      "Z. Xiang",
      "Y. Xie",
      "A. Xu",
      "J. Xu",
      "L. Xu",
      "L. Xu",
      "M. Xu",
      "Z. Xu",
      "Z. Xu",
      "Z. Xu",
      "K. Yang",
      "S. Yang",
      "X. Yang",
      "Y. Yang",
      "Z. Yang",
      "V. Yeroshenko",
      "H. Yeung",
      "H. Yin",
      "X. Yin",
      "C. Y. Yu",
      "J. Yu",
      "X. Yuan",
      "Y Yuan",
      "E. Zaffaroni",
      "M. Zavertyaev",
      "M. Zdybal",
      "F. Zenesini",
      "C. Zeng",
      "M. Zeng",
      "C. Zhang",
      "D. Zhang",
      "J. Zhang",
      "L. Zhang",
      "S. Zhang",
      "S. Zhang",
      "Y. Zhang",
      "Y. Z. Zhang",
      "Z. Zhang",
      "Y. Zhao",
      "A. Zharkova",
      "A. Zhelezov",
      "S. Z. Zheng",
      "X. Z. Zheng",
      "Y. Zheng",
      "T. Zhou",
      "X. Zhou",
      "Y. Zhou",
      "V. Zhovkovska",
      "L. Z. Zhu",
      "X. Zhu",
      "X. Zhu",
      "V. Zhukov",
      "J. Zhuo",
      "Q. Zou",
      "D. Zuliani",
      "G. Zunica"
    ],
    "abstract": "A study of $\\it{\\Lambda}_{\\it{b}}^\\rm{0}$ and $\\it{\\Xi}_{\\it{b}}^\\rm{0}$\ndecays to $\\it{\\Lambda} h^{+} h^{\\prime -}$ $(h^{(\\prime)}=\\pi, K)$ is\nperformed using $pp$ collision data collected by the LHCb experiment during LHC\nRuns 1$-$2, corresponding to an integrated luminosity of $9~\\rm{fb}^{-1}$. The\nbranching fractions for these decays are measured using the\n$\\it{\\Lambda}_{\\it{b}}^\\rm{0}\\to\\it{\\Lambda}_{\\it{c}}^+(\\to\\it{\\Lambda}\\pi^+)\\pi^-$\ndecay as control channel. The decays\n$\\it{\\Lambda}_{\\it{b}}^\\rm{0}\\to\\it{\\Lambda}\\pi^+\\pi^-$ and\n$\\it{\\Xi}_{\\it{b}}^\\rm{0}\\to\\it{\\Lambda}K^-\\pi^+$ are observed for the first\ntime. For decay modes with sufficient signal yields, $CP$ asymmetries are\nmeasured in the full and localized regions of the final-state phase space.\nEvidence is found for $CP$ violation in the\n$\\it{\\Lambda}_{\\it{b}}^\\rm{0}\\to\\it{\\Lambda}K^+K^-$ decay, interpreted as\noriginating primarily from an asymmetric $\\it{\\Lambda}_{\\it{b}}^\\rm{0} \\to\n\\it{N}^{*+} \\it{K}^-$ decay amplitude. The measured $CP$ asymmetries for the\nother decays are compatible with zero.",
    "pdf_url": "http://arxiv.org/pdf/2411.15441v2",
    "published": "2024-11-23T03:51:05+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2411.15440v1",
    "title": "From wicking to anti-wicking: A universal framework for capillary dynamics",
    "authors": [
      "Aniruddha Saha",
      "Sadaf Sobhani"
    ],
    "abstract": "The dynamics of capillary rise under different geometric and fluid conditions\nhave the common signatures of rapid rise followed by an equilibrium state that\ndescribe the underlying competing forces. We present a new interpretation of\ncapillary dynamics using a linear damped system where modulation of damping and\nforcing characteristics are achieved using axisymmetric channels with\nsinusoidal variation in radius. The complete axisymmetric design space ranging\nfrom hydrophilic channels that enable spontaneous imbibition to hydrophobic\nchannels, that required external pressure mechanisms is modeled and the force\ndynamics is split into simultaneous damping and forcing characteristics. We\nintroduce the product of damping and forcing terms as the new parameter that\neffectively characterizes rise dynamics across various geometric and flow\nconditions, encompassing both flow-enhancing and flow-inhibiting scenarios. The\nmonotonic nature of this parameter enables the development of a stochastic\noptimization method that can determine optimal channel geometries for\ncontrolled capillary rise.",
    "pdf_url": "http://arxiv.org/pdf/2411.15440v1",
    "published": "2024-11-23T03:49:50+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2411.15439v1",
    "title": "Twin Trigger Generative Networks for Backdoor Attacks against Object Detection",
    "authors": [
      "Zhiying Li",
      "Zhi Liu",
      "Guanggang Geng",
      "Shreyank N Gowda",
      "Shuyuan Lin",
      "Jian Weng",
      "Xiaobo Jin"
    ],
    "abstract": "Object detectors, which are widely used in real-world applications, are\nvulnerable to backdoor attacks. This vulnerability arises because many users\nrely on datasets or pre-trained models provided by third parties due to\nconstraints on data and resources. However, most research on backdoor attacks\nhas focused on image classification, with limited investigation into object\ndetection. Furthermore, the triggers for most existing backdoor attacks on\nobject detection are manually generated, requiring prior knowledge and\nconsistent patterns between the training and inference stages. This approach\nmakes the attacks either easy to detect or difficult to adapt to various\nscenarios. To address these limitations, we propose novel twin trigger\ngenerative networks in the frequency domain to generate invisible triggers for\nimplanting stealthy backdoors into models during training, and visible triggers\nfor steady activation during inference, making the attack process difficult to\ntrace. Specifically, for the invisible trigger generative network, we deploy a\nGaussian smoothing layer and a high-frequency artifact classifier to enhance\nthe stealthiness of backdoor implantation in object detectors. For the visible\ntrigger generative network, we design a novel alignment loss to optimize the\nvisible triggers so that they differ from the original patterns but still align\nwith the malicious activation behavior of the invisible triggers. Extensive\nexperimental results and analyses prove the possibility of using different\ntriggers in the training stage and the inference stage, and demonstrate the\nattack effectiveness of our proposed visible trigger and invisible trigger\ngenerative networks, significantly reducing the mAP_0.5 of the object detectors\nby 70.0% and 84.5%, including YOLOv5 and YOLOv7 with different settings,\nrespectively.",
    "pdf_url": "http://arxiv.org/pdf/2411.15439v1",
    "published": "2024-11-23T03:46:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15438v1",
    "title": "Efficient Ternary Weight Embedding Model: Bridging Scalability and Performance",
    "authors": [
      "Jiayi Chen",
      "Chen Wu",
      "Shaoqun Zhang",
      "Nan Li",
      "Liangjie Zhang",
      "Qi Zhang"
    ],
    "abstract": "Embedding models have become essential tools in both natural language\nprocessing and computer vision, enabling efficient semantic search,\nrecommendation, clustering, and more. However, the high memory and\ncomputational demands of full-precision embeddings pose challenges for\ndeployment in resource-constrained environments, such as real-time\nrecommendation systems. In this work, we propose a novel finetuning framework\nto ternary-weight embedding models, which reduces memory and computational\noverhead while maintaining high performance. To apply ternarization to\npre-trained embedding models, we introduce self-taught knowledge distillation\nto finalize the ternary-weights of the linear layers. With extensive\nexperiments on public text and vision datasets, we demonstrated that without\nsacrificing effectiveness, the ternarized model consumes low memory usage and\nhas low latency in the inference stage with great efficiency. In practical\nimplementations, embedding models are typically integrated with Approximate\nNearest Neighbor (ANN) search. Our experiments combining ternary embedding with\nANN search yielded impressive improvement in both accuracy and computational\nefficiency. The repository is available at here.",
    "pdf_url": "http://arxiv.org/pdf/2411.15438v1",
    "published": "2024-11-23T03:44:56+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15437v1",
    "title": "Faithful quantum teleportation via a nanophotonic nonlinear Bell state analyzer",
    "authors": [
      "Joshua Akin",
      "Yunlei Zhao",
      "Paul G. Kwiat",
      "Elizabeth A. Goldschmidt",
      "Kejie Fang"
    ],
    "abstract": "Quantum networking protocols, including quantum teleportation and\nentanglement swapping, use linear-optical Bell state measurements for heralding\nthe distribution and transfer of quantum information. However, a linear-optical\nBell state measurement requires identical photons and is susceptible to errors\ncaused by multiphoton emission, fundamentally limiting the efficiency and\nfidelity of quantum networking protocols. Here we show a nonlinear Bell state\nanalyzer for time-bin encoded photons based on a nanophotonic cavity with\nefficient sum-frequency generation to filter multiphoton emissions, and utilize\nit for faithful quantum teleportation involving spectrally distinct photons\nwith fidelities $\\geq 94\\%$ down to the single-photon level. Our result\ndemonstrates that nonlinear-optical entangling operations, empowered by our\nefficient nanophotonics platform, can realize faithful quantum information\nprotocols without requiring identical photons and without the fundamental limit\non the efficiency and fidelity of a Bell state measurement imposed by linear\noptics, which facilitates the realization of practical quantum networks.",
    "pdf_url": "http://arxiv.org/pdf/2411.15437v1",
    "published": "2024-11-23T03:44:06+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15436v1",
    "title": "ConsistentAvatar: Learning to Diffuse Fully Consistent Talking Head Avatar with Temporal Guidance",
    "authors": [
      "Haijie Yang",
      "Zhenyu Zhang",
      "Hao Tang",
      "Jianjun Qian",
      "Jian Yang"
    ],
    "abstract": "Diffusion models have shown impressive potential on talking head generation.\nWhile plausible appearance and talking effect are achieved, these methods still\nsuffer from temporal, 3D or expression inconsistency due to the error\naccumulation and inherent limitation of single-image generation ability. In\nthis paper, we propose ConsistentAvatar, a novel framework for fully consistent\nand high-fidelity talking avatar generation. Instead of directly employing\nmulti-modal conditions to the diffusion process, our method learns to first\nmodel the temporal representation for stability between adjacent frames.\nSpecifically, we propose a Temporally-Sensitive Detail (TSD) map containing\nhigh-frequency feature and contours that vary significantly along the time\naxis. Using a temporal consistent diffusion module, we learn to align TSD of\nthe initial result to that of the video frame ground truth. The final avatar is\ngenerated by a fully consistent diffusion module, conditioned on the aligned\nTSD, rough head normal, and emotion prompt embedding. We find that the aligned\nTSD, which represents the temporal patterns, constrains the diffusion process\nto generate temporally stable talking head. Further, its reliable guidance\ncomplements the inaccuracy of other conditions, suppressing the accumulated\nerror while improving the consistency on various aspects. Extensive experiments\ndemonstrate that ConsistentAvatar outperforms the state-of-the-art methods on\nthe generated appearance, 3D, expression and temporal consistency. Project\npage: https://njust-yang.github.io/ConsistentAvatar.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2411.15436v1",
    "published": "2024-11-23T03:43:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15435v2",
    "title": "What Makes a Scene ? Scene Graph-based Evaluation and Feedback for Controllable Generation",
    "authors": [
      "Zuyao Chen",
      "Jinlin Wu",
      "Zhen Lei",
      "Chang Wen Chen"
    ],
    "abstract": "While text-to-image generation has been extensively studied, generating\nimages from scene graphs remains relatively underexplored, primarily due to\nchallenges in accurately modeling spatial relationships and object\ninteractions. To fill this gap, we introduce Scene-Bench, a comprehensive\nbenchmark designed to evaluate and enhance the factual consistency in\ngenerating natural scenes. Scene-Bench comprises MegaSG, a large-scale dataset\nof one million images annotated with scene graphs, facilitating the training\nand fair comparison of models across diverse and complex scenes. Additionally,\nwe propose SGScore, a novel evaluation metric that leverages chain-of-thought\nreasoning capabilities of multimodal large language models (LLMs) to assess\nboth object presence and relationship accuracy, offering a more effective\nmeasure of factual consistency than traditional metrics like FID and CLIPScore.\nBuilding upon this evaluation framework, we develop a scene graph feedback\npipeline that iteratively refines generated images by identifying and\ncorrecting discrepancies between the scene graph and the image. Extensive\nexperiments demonstrate that Scene-Bench provides a more comprehensive and\neffective evaluation framework compared to existing benchmarks, particularly\nfor complex scene generation. Furthermore, our feedback strategy significantly\nenhances the factual consistency of image generation models, advancing the\nfield of controllable image generation.",
    "pdf_url": "http://arxiv.org/pdf/2411.15435v2",
    "published": "2024-11-23T03:40:25+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.16724v3",
    "title": "Devils in Middle Layers of Large Vision-Language Models: Interpreting, Detecting and Mitigating Object Hallucinations via Attention Lens",
    "authors": [
      "Zhangqi Jiang",
      "Junkai Chen",
      "Beier Zhu",
      "Tingjin Luo",
      "Yankun Shen",
      "Xu Yang"
    ],
    "abstract": "Hallucinations in Large Vision-Language Models (LVLMs) significantly\nundermine their reliability, motivating researchers to explore the causes of\nhallucination. However, most studies primarily focus on the language aspect\nrather than the visual. In this paper, we address how LVLMs process visual\ninformation and whether this process causes hallucination. Firstly, we use the\nattention lens to identify the stages at which LVLMs handle visual data,\ndiscovering that the middle layers are crucial. Moreover, we find that these\nlayers can be further divided into two stages: ''visual information\nenrichment'' and ''semantic refinement'' which respectively propagate visual\ndata to object tokens and interpret it through text. By analyzing attention\npatterns during the visual information enrichment stage, we find that real\ntokens consistently receive higher attention weights than hallucinated ones,\nserving as a strong indicator of hallucination. Further examination of\nmulti-head attention maps reveals that hallucination tokens often result from\nheads interacting with inconsistent objects. Based on these insights, we\npropose a simple inference-time method that adjusts visual attention by\nintegrating information across various heads. Extensive experiments demonstrate\nthat this approach effectively mitigates hallucinations in mainstream LVLMs\nwithout additional training costs. Code is available at\nhttps://github.com/ZhangqiJiang07/middle_layers_indicating_hallucinations.",
    "pdf_url": "http://arxiv.org/pdf/2411.16724v3",
    "published": "2024-11-23T03:40:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15434v1",
    "title": "2-dimensional Shephard groups",
    "authors": [
      "Katherine Goldman"
    ],
    "abstract": "The 2-dimensional Shephard groups are quotients of 2-dimensional Artin groups\nby powers of standard generators. We show that such a quotient is not\n$\\mathrm{CAT}(0)$ if the powers taken are sufficiently large. However, for a\ngiven 2-dimensional Shephard group, we construct a $\\mathrm{CAT}(0)$ piecewise\nEuclidean cell complex with a cocompact action (analogous to the Deligne\ncomplex for an Artin group) that allows us to determine other non-positive\ncurvature properties. Namely, we show the 2-dimensional Shephard groups are\nacylindrically hyperbolic (which was known for 2-dimensional Artin groups), and\nrelatively hyperbolic (which most Artin groups are known not to be). As an\napplication, we show that a broad class of 2-dimensional Artin groups are\nresidually finite.",
    "pdf_url": "http://arxiv.org/pdf/2411.15434v1",
    "published": "2024-11-23T03:34:59+00:00",
    "categories": [
      "math.GR",
      "math.AT",
      "math.MG",
      "20F65 (Primary) 57M60, 20E26, 20F67 (Secondary)"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15433v1",
    "title": "Enhancing the Quantification of Capacity and Throughput in Integrated Space and Terrestrial Network",
    "authors": [
      "Menglong Yang",
      "Weizheng Li",
      "Wei Li",
      "Binbin Liang",
      "Songchen Han",
      "Xiaodong Han",
      "Yibing Liu",
      "Xiangtong Wang"
    ],
    "abstract": "Quantification of network capacity and throughput is crucial for performance\nevaluation of integrated space and terrestrial network (ISTN).However, existing\nstudies mainly consider the maximum throughput as the network capacity, but\nsuch a definition would make it unreasonable that the value of the network\ncapacity would change with different employed routing algorithms and congestion\ncontrol policy, instead of being a constant quantity.\n  In this paper, we argue that the capacity of an ISTN is solely dependent on\nthe characteristics of the network infrastructure,and the throughput of an ISTN\nis the aggregate traffic transported by the network under a given traffic\nscenario. Then, we present a quantitative approach to assessing network\ncapacity in relation to an unreliable ISL model (cap-uISL), and a Constrained\nPath Expansion throughput calculation method (THP-CPE) based on a set of known\ntraffic paths. This method allows us to obtain the current throughput value of\nthe network based on any given traffic paths and load demand matrix. As the\ntraffic load increases, the throughput approaches its maximum value, which is\nnotably smaller than the network's capacity.\n  We experimentally determine the network capacity of CAP-uISL under various\nlink parameters and compare our throughput quantization method, THP-CPE, with\nother state-of-the-art methods under four emerging ISTNs. We find that,\ncompared with the THP-CPE, existing throughput calculation methods tend to be\noverestimated, while our proposed throughput calculation method maintains\nreasonable intervals in terms of path utilization ($<1$) under all load cases.",
    "pdf_url": "http://arxiv.org/pdf/2411.15433v1",
    "published": "2024-11-23T03:21:09+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2411.15432v2",
    "title": "Lifelong Knowledge Editing for Vision Language Models with Low-Rank Mixture-of-Experts",
    "authors": [
      "Qizhou Chen",
      "Chengyu Wang",
      "Dakan Wang",
      "Taolin Zhang",
      "Wangyue Li",
      "Xiaofeng He"
    ],
    "abstract": "Model editing aims to correct inaccurate knowledge, update outdated\ninformation, and incorporate new data into Large Language Models (LLMs) without\nthe need for retraining. This task poses challenges in lifelong scenarios where\nedits must be continuously applied for real-world applications. While some\neditors demonstrate strong robustness for lifelong editing in pure LLMs, Vision\nLLMs (VLLMs), which incorporate an additional vision modality, are not directly\nadaptable to existing LLM editors. In this paper, we propose LiveEdit, a\nLIfelong Vision language modEl Edit to bridge the gap between lifelong LLM\nediting and VLLMs. We begin by training an editing expert generator to\nindependently produce low-rank experts for each editing instance, with the goal\nof correcting the relevant responses of the VLLM. A hard filtering mechanism is\ndeveloped to utilize visual semantic knowledge, thereby coarsely eliminating\nvisually irrelevant experts for input queries during the inference stage of the\npost-edited model. Finally, to integrate visually relevant experts, we\nintroduce a soft routing mechanism based on textual semantic relevance to\nachieve multi-expert fusion. For evaluation, we establish a benchmark for\nlifelong VLLM editing. Extensive experiments demonstrate that LiveEdit offers\nsignificant advantages in lifelong VLLM editing scenarios. Further experiments\nvalidate the rationality and effectiveness of each module design in LiveEdit.",
    "pdf_url": "http://arxiv.org/pdf/2411.15432v2",
    "published": "2024-11-23T03:19:40+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15431v1",
    "title": "Ohno relation for regularized refined symmetric multiple zeta values",
    "authors": [
      "Minoru Hirose",
      "Hideki Murahara",
      "Shingo Saito"
    ],
    "abstract": "The Ohno relation is one of the most celebrated results in the theory of\nmultiple zeta values, which are iterated integrals from $0$ to $1$. In a\nprevious paper, the authors generalized the Ohno relation to regularized\nmultiple zeta values, which are non-admissible iterated integrals from $0$ to\n$1$. Meanwhile, Takeyama proved an analogue of the Ohno relation for refined\nsymmetric multiple zeta values, which are iterated integrals from $0$ to $0$.\nIn this paper, we generalize Takeyama's result to regularized refined symmetric\nmultiple zeta values, which are non-admissible iterated integrals from $0$ to\n$0$.",
    "pdf_url": "http://arxiv.org/pdf/2411.15431v1",
    "published": "2024-11-23T03:16:36+00:00",
    "categories": [
      "math.NT",
      "Primary 11M32"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2411.15430v1",
    "title": "The Landscape of Data Reuse in Interactive Information Retrieval: Motivations, Sources, and Evaluation of Reusability",
    "authors": [
      "Tianji Jiang",
      "Wenqi Li",
      "Jiqun Liu"
    ],
    "abstract": "Sharing and reusing research data can effectively reduce redundant efforts in\ndata collection and curation, especially for small labs and research teams\nconducting human-centered system research, and enhance the replicability of\nevaluation experiments. Building a sustainable data reuse process and culture\nrelies on frameworks that encompass policies, standards, roles, and\nresponsibilities, all of which must address the diverse needs of data\nproviders, curators, and reusers.\n  To advance the knowledge and accumulate empirical understandings on data\nreuse, this study investigated the data reuse practices of experienced\nresearchers from the area of Interactive Information Retrieval (IIR) studies,\nwhere data reuse has been strongly advocated but still remains a challenge. To\nenhance the knowledge on data reuse behavior and reusability assessment\nstrategies within IIR community, we conducted 21 semi-structured in-depth\ninterviews with IIR researchers from varying demographic backgrounds,\ninstitutions, and stages of careers on their motivations, experiences, and\nconcerns over data reuse. We uncovered the reasons, strategies of reusability\nassessments, and challenges faced by data reusers within the field of IIR as\nthey attempt to reuse researcher data in their studies. The empirical finding\nimproves our understanding of researchers' motivations for reusing data, their\napproaches to discovering reusable research data, as well as their concerns and\ncriteria for assessing data reusability, and also enriches the on-going\ndiscussions on evaluating user-generated data and research resources and\npromoting community-level data reuse culture and standards.",
    "pdf_url": "http://arxiv.org/pdf/2411.15430v1",
    "published": "2024-11-23T03:15:31+00:00",
    "categories": [
      "cs.IR",
      "cs.DL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15429v1",
    "title": "Generic density of periodic orbits of area-preserving maps on punctured surfaces",
    "authors": [
      "Shaoyang Zhou"
    ],
    "abstract": "We study the dynamics of area-preserving maps in a non-compact setting. We\nshow that the $C^{\\infty}$-closing lemma holds for area-preserving\ndiffeomorphisms on a closed surface with finitely many points removed. As a\ncorollary, a $C^{\\infty}$-generic area-preserving diffeomorphism on such a\nsurface has a dense set of periodic points. For area-preserving maps on a\nfinitely punctured 2-sphere, we establish a more quantitative result regarding\nthe equidistribution of periodic orbits. The proof of this result involves a\nPFH Weyl law for rational area-preserving homeomorphisms, which may be of\nindependent interest.",
    "pdf_url": "http://arxiv.org/pdf/2411.15429v1",
    "published": "2024-11-23T03:13:59+00:00",
    "categories": [
      "math.DS",
      "math.SG"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2411.15428v1",
    "title": "GeoAI-Enhanced Community Detection on Spatial Networks with Graph Deep Learning",
    "authors": [
      "Yunlei Liang",
      "Jiawei Zhu",
      "Wen Ye",
      "Song Gao"
    ],
    "abstract": "Spatial networks are useful for modeling geographic phenomena where spatial\ninteraction plays an important role. To analyze the spatial networks and their\ninternal structures, graph-based methods such as community detection have been\nwidely used. Community detection aims to extract strongly connected components\nfrom the network and reveal the hidden relationships between nodes, but they\nusually do not involve the attribute information. To consider edge-based\ninteractions and node attributes together, this study proposed a family of\nGeoAI-enhanced unsupervised community detection methods called region2vec based\non Graph Attention Networks (GAT) and Graph Convolutional Networks (GCN). The\nregion2vec methods generate node neural embeddings based on attribute\nsimilarity, geographic adjacency and spatial interactions, and then extract\nnetwork communities based on node embeddings using agglomerative clustering.\nThe proposed GeoAI-based methods are compared with multiple baselines and\nperform the best when one wants to maximize node attribute similarity and\nspatial interaction intensity simultaneously within the spatial network\ncommunities. It is further applied in the shortage area delineation problem in\npublic health and demonstrates its promise in regionalization problems.",
    "pdf_url": "http://arxiv.org/pdf/2411.15428v1",
    "published": "2024-11-23T03:09:34+00:00",
    "categories": [
      "cs.SI",
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2411.15427v1",
    "title": "Integrating optimal ridesharing matching into multimodal traffic model: Implications for policy and sustainable transport system",
    "authors": [
      "Yueqi Liu",
      "Ke Han",
      "Zhuoqian Yang",
      "Yanghong Yu",
      "Wen Ji"
    ],
    "abstract": "Integrating ridesharing matching explicitly into multimodal traffic models is\ncrucial for accurately assessing the impacts of multimodal transport (MT) on\nurban economic and environmental aspects. This paper integrates an optimal\nridesharing matching method into a path-based deterministic day-to-day traffic\nassignment framework, considers match cancellations, and captures the\ninteractions between various modes on the road. The model incorporates five\ntraffic modes (solo driving, ridesharing as a driver, ridesharing as a\npassenger, bus travel, and metro travel) and two groups of travelers based on\ntheir ownership status. Its steady state is determined through numerical\nexperiments. The sensitivity analyses reveal that the MT system's performance\nvaries with changes in ownership, bus fare, and ridesharing fare, demonstrating\ndiverse impacts on mode split, travel cost, and emissions across different\ngroups, road links, and regions. Our findings suggest that vehicle restrictions\nand pricing strategies have both benefits and drawbacks in managing MT system,\nemphasizing the need for careful consideration of trade-offs and social equity\nimplications in policy-making and implementation. This study not only enhances\nthe theoretical understanding of MT system but also provides valuable support\nfor urban transportation policy-making aimed at achieving efficient,\nsustainable, and socially equitable transport systems.",
    "pdf_url": "http://arxiv.org/pdf/2411.15427v1",
    "published": "2024-11-23T03:06:54+00:00",
    "categories": [
      "physics.soc-ph",
      "math.OC"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15426v1",
    "title": "LDM-Morph: Latent diffusion model guided deformable image registration",
    "authors": [
      "Jiong Wu",
      "Kuang Gong"
    ],
    "abstract": "Deformable image registration plays an essential role in various medical\nimage tasks. Existing deep learning-based deformable registration frameworks\nprimarily utilize convolutional neural networks (CNNs) or Transformers to learn\nfeatures to predict the deformations. However, the lack of semantic information\nin the learned features limits the registration performance. Furthermore, the\nsimilarity metric of the loss function is often evaluated only in the pixel\nspace, which ignores the matching of high-level anatomical features and can\nlead to deformation folding. To address these issues, in this work, we proposed\nLDM-Morph, an unsupervised deformable registration algorithm for medical image\nregistration. LDM-Morph integrated features extracted from the latent diffusion\nmodel (LDM) to enrich the semantic information. Additionally, a latent and\nglobal feature-based cross-attention module (LGCA) was designed to enhance the\ninteraction of semantic information from LDM and global information from\nmulti-head self-attention operations. Finally, a hierarchical metric was\nproposed to evaluate the similarity of image pairs in both the original pixel\nspace and latent-feature space, enhancing topology preservation while improving\nregistration accuracy. Extensive experiments on four public 2D cardiac image\ndatasets show that the proposed LDM-Morph framework outperformed existing\nstate-of-the-art CNNs- and Transformers-based registration methods regarding\naccuracy and topology preservation with comparable computational efficiency.\nOur code is publicly available at https://github.com/wujiong-hub/LDM-Morph.",
    "pdf_url": "http://arxiv.org/pdf/2411.15426v1",
    "published": "2024-11-23T03:04:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15425v1",
    "title": "Efficient Bitcoin Address Classification Using Quantum-Inspired Feature Selection",
    "authors": [
      "Ming-Fong Sie",
      "Yen-Jui Chang",
      "Chien-Lung Lin",
      "Ching-Ray Chang",
      "Shih-Wei Liao"
    ],
    "abstract": "Over 900 million Bitcoin transactions have been recorded, posing considerable\nchallenges for machine learning in terms of computation time and maintaining\nprediction accuracy. We propose an innovative approach using quantum-inspired\nalgorithms implemented with Simulated Annealing and Quantum Annealing to\naddress the challenge of local minima in solution spaces. This method\nefficiently identifies key features linked to mixer addresses, significantly\nreducing model training time. By categorizing Bitcoin addresses into six\nclasses: exchanges, faucets, gambling, marketplaces, mixers, and mining pools,\nand applying supervised learning methods, our results demonstrate that feature\nselection with SA reduced training time by 30.3% compared to using all features\nin a random forest model while maintaining a 91% F1-score for mixer addresses.\nThis highlights the potential of quantum-inspired algorithms to swiftly and\naccurately identify high-risk Bitcoin addresses based on transaction features.",
    "pdf_url": "http://arxiv.org/pdf/2411.15425v1",
    "published": "2024-11-23T03:03:57+00:00",
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15424v1",
    "title": "Discrepancy in Oil Displacement Mechanisms at the Equivalent Interfacial Tensions: Differentiating Contributions from Surfactant and Nanoparticles on Interfacial Activities",
    "authors": [
      "Suparit Tangparitkul",
      "Thakheru Akamine",
      "David Harbottle",
      "Falan Srisuriyachai",
      "Kai Yu"
    ],
    "abstract": "This study examines discrepancies in oil displacement mechanisms at\nequivalent interfacial tensions, focusing on the distinct contributions of\nsurfactants and nanoparticles. It was hypothesized that similar interfacial\nactivities would result in consistent displacement outcomes, while differences\nwould reflect unique interfacial behaviors. Micromodel experiments revealed\nthat at high interfacial tension (~20 mN/m), surfactants outperformed\nnanofluids in efficiency and ultimate oil recovery by reinforcing capillary\nforces. Conversely, nanofluids showed limited ability to modify interfacial\nforces. At lower interfacial tensions (6.5 mN/m for surfactants, 15.6 mN/m for\nnanofluids), both systems displayed similar displacement efficiencies and\nfingering patterns, driven by distinct mechanisms: capillary instability for\nsurfactants and expansive layer flow for nanofluids. These findings challenge\nthe assumption that nanofluids rely primarily on interfacial tension reduction\nfor enhanced oil recovery (EOR) and highlight the need to refine our\nunderstanding of nanoparticle interfacial activities. Future studies should\nextend these insights to core-scale experiments for a more comprehensive\nevaluation of two-phase flow dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2411.15424v1",
    "published": "2024-11-23T03:00:01+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2411.15423v1",
    "title": "Photoproduction of two charged pions off protons in the resonance region",
    "authors": [
      "A. V. Sarantsev",
      "E. Klempt",
      "K. V. Nikonov",
      "P. Achenbach",
      "V. D. Burkert",
      "V. Crede",
      "V. Mokeev"
    ],
    "abstract": "Photoproduction of charged pions pairs off protons is studied within the\ninvariant masses of the final state hadrons from 1.6 to 2.4 GeV at the Thomas\nJefferson National Accelerator Facility with the CLAS detector. The data are\nincluded in the Bonn-Gatchina coupled-channel analysis and provide the\ninformation necessary to determine the branching fractions for most known\nnucleon and Delta resonances. Branching ratios are obtained here from an event\nbased likelihood fit.",
    "pdf_url": "http://arxiv.org/pdf/2411.15423v1",
    "published": "2024-11-23T02:58:51+00:00",
    "categories": [
      "nucl-ex"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2411.15422v1",
    "title": "Learning a local trading strategy: deep reinforcement learning for grid-scale renewable energy integration",
    "authors": [
      "Caleb Ju",
      "Constance Crozier"
    ],
    "abstract": "Variable renewable generation increases the challenge of balancing power\nsupply and demand. Grid-scale batteries co-located with generation can help\nmitigate this misalignment. This paper explores the use of reinforcement\nlearning (RL) for operating grid-scale batteries co-located with solar power.\nOur results show RL achieves an average of 61% (and up to 96%) of the\napproximate theoretical optimal (non-causal) operation, outperforming advanced\ncontrol methods on average. Our findings suggest RL may be preferred when\nfuture signals are hard to predict. Moreover, RL has two significant advantages\ncompared to simpler rules-based control: (1) that solar energy is more\neffectively shifted towards high demand periods, and (2) increased diversity of\nbattery dispatch across different locations, reducing potential ramping issues\ncaused by super-position of many similar actions.",
    "pdf_url": "http://arxiv.org/pdf/2411.15422v1",
    "published": "2024-11-23T02:55:38+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15421v2",
    "title": "OphCLIP: Hierarchical Retrieval-Augmented Learning for Ophthalmic Surgical Video-Language Pretraining",
    "authors": [
      "Ming Hu",
      "Kun Yuan",
      "Yaling Shen",
      "Feilong Tang",
      "Xiaohao Xu",
      "Lin Zhou",
      "Wei Li",
      "Ying Chen",
      "Zhongxing Xu",
      "Zelin Peng",
      "Siyuan Yan",
      "Vinkle Srivastav",
      "Diping Song",
      "Tianbin Li",
      "Danli Shi",
      "Jin Ye",
      "Nicolas Padoy",
      "Nassir Navab",
      "Junjun He",
      "Zongyuan Ge"
    ],
    "abstract": "Surgical practice involves complex visual interpretation, procedural skills,\nand advanced medical knowledge, making surgical vision-language pretraining\n(VLP) particularly challenging due to this complexity and the limited\navailability of annotated data. To address the gap, we propose OphCLIP, a\nhierarchical retrieval-augmented vision-language pretraining framework\nspecifically designed for ophthalmic surgical workflow understanding. OphCLIP\nleverages the OphVL dataset we constructed, a large-scale and comprehensive\ncollection of over 375K hierarchically structured video-text pairs with tens of\nthousands of different combinations of attributes (surgeries,\nphases/operations/actions, instruments, medications, as well as more advanced\naspects like the causes of eye diseases, surgical objectives, and postoperative\nrecovery recommendations, etc). These hierarchical video-text correspondences\nenable OphCLIP to learn both fine-grained and long-term visual representations\nby aligning short video clips with detailed narrative descriptions and full\nvideos with structured titles, capturing intricate surgical details and\nhigh-level procedural insights, respectively. Our OphCLIP also designs a\nretrieval-augmented pretraining framework to leverage the underexplored\nlarge-scale silent surgical procedure videos, automatically retrieving\nsemantically relevant content to enhance the representation learning of\nnarrative videos. Evaluation across 11 datasets for phase recognition and\nmulti-instrument identification shows OphCLIP's robust generalization and\nsuperior performance.",
    "pdf_url": "http://arxiv.org/pdf/2411.15421v2",
    "published": "2024-11-23T02:53:08+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.16723v1",
    "title": "Two Heads Are Better Than One: Collaborative LLM Embodied Agents for Human-Robot Interaction",
    "authors": [
      "Mitchell Rosser",
      "Marc. G Carmichael"
    ],
    "abstract": "With the recent development of natural language generation models - termed as\nlarge language models (LLMs) - a potential use case has opened up to improve\nthe way that humans interact with robot assistants. These LLMs should be able\nto leverage their large breadth of understanding to interpret natural language\ncommands into effective, task appropriate and safe robot task executions.\nHowever, in reality, these models suffer from hallucinations, which may cause\nsafety issues or deviations from the task. In other domains, these issues have\nbeen improved through the use of collaborative AI systems where multiple LLM\nagents can work together to collectively plan, code and self-check outputs. In\nthis research, multiple collaborative AI systems were tested against a single\nindependent AI agent to determine whether the success in other domains would\ntranslate into improved human-robot interaction performance. The results show\nthat there is no defined trend between the number of agents and the success of\nthe model. However, it is clear that some collaborative AI agent architectures\ncan exhibit a greatly improved capacity to produce error-free code and to solve\nabstract problems.",
    "pdf_url": "http://arxiv.org/pdf/2411.16723v1",
    "published": "2024-11-23T02:47:12+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15420v1",
    "title": "Semi-supervised Single-view 3D Reconstruction via Multi Shape Prior Fusion Strategy and Self-Attention",
    "authors": [
      "Wei Zhoua",
      "Xinzhe Shia",
      "Yunfeng Shea",
      "Kunlong Liua",
      "Yongqin Zhanga"
    ],
    "abstract": "In the domain of single-view 3D reconstruction, traditional techniques have\nfrequently relied on expensive and time-intensive 3D annotation data. Facing\nthe challenge of annotation acquisition, semi-supervised learning strategies\noffer an innovative approach to reduce the dependence on labeled data. Despite\nthese developments, the utilization of this learning paradigm in 3D\nreconstruction tasks remains relatively constrained. In this research, we\ncreated an innovative semi-supervised framework for 3D reconstruction that\ndistinctively uniquely introduces a multi shape prior fusion strategy,\nintending to guide the creation of more realistic object structures.\nAdditionally, to improve the quality of shape generation, we integrated a\nself-attention module into the traditional decoder. In benchmark tests on the\nShapeNet dataset, our method substantially outperformed existing supervised\nlearning methods at diverse labeled ratios of 1\\%, 10\\%, and 20\\%. Moreover, it\nshowcased excellent performance on the real-world Pix3D dataset. Through\ncomprehensive experiments on ShapeNet, our framework demonstrated a 3.3\\%\nperformance improvement over the baseline. Moreover, stringent ablation studies\nfurther confirmed the notable effectiveness of our approach. Our code has been\nreleased on https://github.com/NWUzhouwei/SSMP",
    "pdf_url": "http://arxiv.org/pdf/2411.15420v1",
    "published": "2024-11-23T02:46:16+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15419v1",
    "title": "Communication-Efficient Sparsely-Activated Model Training via Sequence Migration and Token Condensation",
    "authors": [
      "Fahao Chen",
      "Peng Li",
      "Zicong Hong",
      "Zhou Su",
      "Song Guo"
    ],
    "abstract": "Mixture-of-Experts (MoE) is an emerging technique for scaling large models\nwith sparse activation. MoE models are typically trained in a distributed\nmanner with an expert parallelism scheme, where experts in each MoE layer are\ndistributed across multiple GPUs. However, the default expert parallelism\nsuffers from the heavy network burden due to the all-to-all intermediate data\nexchange among GPUs before and after the expert run. Some existing works have\nproposed to reduce intermediate data exchanges by transferring experts to\nreduce the network loads, however, which would decrease parallelism level of\nexpert execution and make computation inefficient. The weaknesses of existing\nworks motivate us to explore whether it is possible to reduce inter-GPU traffic\nwhile maintaining a high degree of expert parallelism. This paper gives a\npositive response by presenting Luffy, a communication-efficient distributed\nMoE training system with two new techniques. First, Luffy migrates sequences\namong GPUs to hide heavy token pulling paths within GPUs and avoid copying\nexperts over GPUs. Second, we propose token condensation that identifies\nsimilar tokens and then eliminates redundant transmissions. We implement Luffy\nbased on PyTorch and evaluate its performance on a testbed of 16 V100 GPUs.\nLuffy system can achieve a speedup of up to 2.73x compared to state-of-the-art\nMoE training systems.",
    "pdf_url": "http://arxiv.org/pdf/2411.15419v1",
    "published": "2024-11-23T02:41:34+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15418v2",
    "title": "Scaling Structure Aware Virtual Screening to Billions of Molecules with SPRINT",
    "authors": [
      "Andrew T. McNutt",
      "Abhinav K. Adduri",
      "Caleb N. Ellington",
      "Monica T. Dayao",
      "Eric P. Xing",
      "Hosein Mohimani",
      "David R. Koes"
    ],
    "abstract": "Virtual screening of small molecules against protein targets can accelerate\ndrug discovery and development by predicting drug-target interactions (DTIs).\nHowever, structure-based methods like molecular docking are too slow to allow\nfor broad proteome-scale screens, limiting their application in screening for\noff-target effects or new molecular mechanisms. Recently, vector-based methods\nusing protein language models (PLMs) have emerged as a complementary approach\nthat bypasses explicit 3D structure modeling. Here, we develop SPRINT, a\nvector-based approach for screening entire chemical libraries against whole\nproteomes for DTIs and novel mechanisms of action. SPRINT improves on prior\nwork by using a self-attention based architecture and structure-aware PLMs to\nlearn drug-target co-embeddings for binder prediction, search, and retrieval.\nSPRINT achieves SOTA enrichment factors in virtual screening on LIT-PCBA, DTI\nclassification benchmarks, and binding affinity prediction benchmarks, while\nproviding interpretability in the form of residue-level attention maps. In\naddition to being both accurate and interpretable, SPRINT is ultra-fast:\nquerying the whole human proteome against the ENAMINE Real Database (6.7B\ndrugs) for the 100 most likely binders per protein takes 16 minutes. SPRINT\npromises to enable virtual screening at an unprecedented scale, opening up new\nopportunities for in silico drug repurposing and development. SPRINT is\navailable on the web as ColabScreen: https://bit.ly/colab-screen",
    "pdf_url": "http://arxiv.org/pdf/2411.15418v2",
    "published": "2024-11-23T02:39:27+00:00",
    "categories": [
      "q-bio.BM",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2411.16722v1",
    "title": "Active Prompt Learning with Vision-Language Model Priors",
    "authors": [
      "Hoyoung Kim",
      "Seokhee Jin",
      "Changhwan Sung",
      "Jaechang Kim",
      "Jungseul Ok"
    ],
    "abstract": "Vision-language models (VLMs) have demonstrated remarkable zero-shot\nperformance across various classification tasks. Nonetheless, their reliance on\nhand-crafted text prompts for each task hinders efficient adaptation to new\ntasks. While prompt learning offers a promising solution, most studies focus on\nmaximizing the utilization of given few-shot labeled datasets, often\noverlooking the potential of careful data selection strategies, which enable\nhigher accuracy with fewer labeled data. This motivates us to study a\nbudget-efficient active prompt learning framework. Specifically, we introduce a\nclass-guided clustering that leverages the pre-trained image and text encoders\nof VLMs, thereby enabling our cluster-balanced acquisition function from the\ninitial round of active learning. Furthermore, considering the substantial\nclass-wise variance in confidence exhibited by VLMs, we propose a budget-saving\nselective querying based on adaptive class-wise thresholds. Extensive\nexperiments in active learning scenarios across nine datasets demonstrate that\nour method outperforms existing baselines.",
    "pdf_url": "http://arxiv.org/pdf/2411.16722v1",
    "published": "2024-11-23T02:34:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15417v3",
    "title": "Temperature dependent spin dynamics in La$_{0.67}$Sr$_{0.33}$MnO$_3$/Pt bilayers",
    "authors": [
      "Biswajit Sahoo",
      "Akilan K",
      "Katherine Matthews",
      "Alexandre Pofelski",
      "Alex Frano",
      "Eric E Fullerton",
      "Sebastien Petit-Watelot",
      "Juan-Carlos Rojas Sanchez",
      "Sarmistha Das"
    ],
    "abstract": "Complex ferromagnetic oxides such as La$_{0.67}$Sr$_{0.33}$MnO$_3$ (LSMO)\noffer pathways for creating energy efficient spintronic devices with new\nfunctionalities. LSMO exhibits high-temperature ferromagnetism, half\nmetallicity, sharp resonance linewidth, low damping and a large anisotropic\nmagnetoresistance response. Combined with Pt, a proven material with high\nspin-charge conversion efficiency, LSMO can be used to create robust\nnano-oscillators for neuromorphic computing. Ferromagnetic resonance (FMR) and\ndevice level spin-pumping FMR measurements are performed to investigate the\nmagnetization dynamics and spin transport in NdGaO3(110)/LSMO(15 nm)/Pt(0 and 5\nnm) thin films ranging from 300K to 90K and compare the device performance with\nPy(7 nm)/Pt(5 nm) sample. The spin current pumped into Pt is quantified to\ndetermine the temperature dependent influence of interfacial interactions. The\ngenerated spin current in the micro-device is maximum at 170K for the optimally\ngrown LSMO/Pt films. Additionally, this bilayer system exhibits low magnetic\nGilbert damping (0.002), small linewidth (12 Oe) and a large spin Hall angle\n($\\approx$ 3.2%) at 170K. By fine-tuning the LSMO/Pt interface quality and\nintegrating it into the device structure, the system exhibits a fourfold\nenhancement in signal output for LSMO/Pt devices compared to the Pt/Py system.\nSuch robust device level performance can pave way for energy-efficient\nspintronic based devices.",
    "pdf_url": "http://arxiv.org/pdf/2411.15417v3",
    "published": "2024-11-23T02:31:25+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2411.15416v1",
    "title": "Least Privilege Access for Persistent Storage Mechanisms in Web Browsers",
    "authors": [
      "Gayatri Priyadarsini Kancherla",
      "Dishank Goel",
      "Abhishek Bichhawat"
    ],
    "abstract": "Web applications often include third-party content and scripts to personalize\na user's online experience. These scripts have unrestricted access to a user's\nprivate data stored in the browser's persistent storage like cookies,\nlocalstorage and IndexedDB, associated with the host page. Various mechanisms\nhave been implemented to restrict access to these storage objects, e.g.,\ncontent security policy, the HttpOnly attribute with cookies, etc. However, the\nexisting mechanisms provide an all-or-none access and do not work in scenarios\nwhere web applications need to allow controlled access to cookies and\nlocalstorage objects by third-party scripts. If some of these scripts behave\nmaliciously, they can easily access and modify private user information that\nare stored in the browser objects. The goal of our work is to design a\nmechanism to enforce fine-grained control of persistent storage objects. We\nperform an empirical study of persistent storage access by third-party scripts\non Tranco's top 10,000 websites and find that 89.84% of all cookie accesses,\n90.98% of all localstorage accesses and 72.49% of IndexedDB accesses are done\nby third-party scripts. Our approach enforces least privilege access for\nthird-party scripts on these objects to ensure their security by attaching\nlabels to the storage objects that specify which domains are allowed to read\nfrom and write to these objects. We implement our approach on the Firefox\nbrowser and show that it effectively blocks scripts from other domains, which\nare not allowed access based on these labels, from accessing the storage\nobjects. We show that our enforcement results in some functionality breakage in\nwebsites with the default settings, which can be fixed by correctly labeling\nthe storage objects used by the third-party scripts.",
    "pdf_url": "http://arxiv.org/pdf/2411.15416v1",
    "published": "2024-11-23T02:25:43+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15415v1",
    "title": "Metal-Poor Stars in the Milky Way System",
    "authors": [
      "Anna Frebel"
    ],
    "abstract": "Ancient, long-lived stars remain present in all components of our home\ngalaxy, the Milky Way. Born a few hundred million after the Big Bang and during\na time that marked the very beginning of the chemical evolution, these stars\ndisplay very low abundances of elements heavier and hydrogen and helium, making\nthem \"metal-poor\". Studying the chemical composition of these stars reveals\ndirect information about the conditions of the early universe because each of\nthem has long preserved the local chemical signature of their individual birth\ngas clouds in their stellar atmosphere. There are many different types of\nmetal-poor stars, each of them providing information on a different element\nproduction history that occurred prior to their own births. Large samples of\nmetal-poor stars enable the reconstruction of nucleosynthesis and the chemical\nevolution of our Galaxy, early star formation processes, and various aspects of\nthe assembly and evolution of the Milky Way.",
    "pdf_url": "http://arxiv.org/pdf/2411.15415v1",
    "published": "2024-11-23T02:23:55+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15414v3",
    "title": "Measuring Compliance of Consent Revocation on the Web",
    "authors": [
      "Gayatri Priyadarsini Kancherla",
      "Nataliia Bielova",
      "Cristiana Santos",
      "Abhishek Bichhawat"
    ],
    "abstract": "The GDPR requires websites to facilitate the right to revoke consent from Web\nusers. While numerous studies measured compliance of consent with the various\nconsent requirements, no prior work has studied consent revocation on the Web.\nTherefore, it remains unclear how difficult it is to revoke consent on the\nwebsites' interfaces, nor whether revoked consent is properly stored and\ncommunicated behind the user interface. Our work aims to fill this gap by\nmeasuring compliance of consent revocation on the Web on the top-200 websites.\nWe found that 19.87% of websites make it difficult for users to revoke consent\nthroughout different interfaces, 20.5% of websites require more effort than\nacceptance, and 2.48% do not provide consent revocation at all, thus violating\nlegal requirements for valid consent. 57.5% websites do not delete the cookies\nafter consent revocation enabling continuous illegal processing of users' data.\nMoreover, we analyzed 281 websites implementing the IAB Europe TCF, and found\n22 websites that store a positive consent despite user's revocation.\nSurprisingly, we found that on 101 websites, third parties that have received\nconsent upon user's acceptance, are not informed of user's revocation, leading\nto the illegal processing of users' data by such third parties. Our findings\nemphasise the need for improved legal compliance of consent revocation, and\nproper, consistent, and uniform implementation of revocation communication and\ndata deletion practices.",
    "pdf_url": "http://arxiv.org/pdf/2411.15414v3",
    "published": "2024-11-23T02:23:01+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15413v1",
    "title": "FG-CXR: A Radiologist-Aligned Gaze Dataset for Enhancing Interpretability in Chest X-Ray Report Generation",
    "authors": [
      "Trong Thang Pham",
      "Ngoc-Vuong Ho",
      "Nhat-Tan Bui",
      "Thinh Phan",
      "Patel Brijesh",
      "Donald Adjeroh",
      "Gianfranco Doretto",
      "Anh Nguyen",
      "Carol C. Wu",
      "Hien Nguyen",
      "Ngan Le"
    ],
    "abstract": "Developing an interpretable system for generating reports in chest X-ray\n(CXR) analysis is becoming increasingly crucial in Computer-aided Diagnosis\n(CAD) systems, enabling radiologists to comprehend the decisions made by these\nsystems. Despite the growth of diverse datasets and methods focusing on report\ngeneration, there remains a notable gap in how closely these models' generated\nreports align with the interpretations of real radiologists. In this study, we\ntackle this challenge by initially introducing Fine-Grained CXR (FG-CXR)\ndataset, which provides fine-grained paired information between the captions\ngenerated by radiologists and the corresponding gaze attention heatmaps for\neach anatomy. Unlike existing datasets that include a raw sequence of gaze\nalongside a report, with significant misalignment between gaze location and\nreport content, our FG-CXR dataset offers a more grained alignment between gaze\nattention and diagnosis transcript. Furthermore, our analysis reveals that\nsimply applying black-box image captioning methods to generate reports cannot\nadequately explain which information in CXR is utilized and how long needs to\nattend to accurately generate reports. Consequently, we propose a novel\nexplainable radiologist's attention generator network (Gen-XAI) that mimics the\ndiagnosis process of radiologists, explicitly constraining its output to\nclosely align with both radiologist's gaze attention and transcript. Finally,\nwe perform extensive experiments to illustrate the effectiveness of our method.\nOur datasets and checkpoint is available at\nhttps://github.com/UARK-AICV/FG-CXR.",
    "pdf_url": "http://arxiv.org/pdf/2411.15413v1",
    "published": "2024-11-23T02:22:40+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15412v1",
    "title": "Symmetric Rearrangement and Geometric Inequalities on Riemannian Manifolds",
    "authors": [
      "Richard Stone"
    ],
    "abstract": "This paper starts by introducing results from geometric measure theory to\nprove symmetric decreasing rearrangement inequalities on $\\mathbb{R}^n$, which\ngive multiple proofs of the isoperimetric and P\\'{o}lya-Szeg\\H{o} inequalities.\nThen we consider smooth oriented Riemannian manifolds of the form $M^n =\n(0,\\infty)\\times \\Sigma^{n-1}$, and test what results carry over from the\n$\\mathbb{R}^n$ setting or what assumptions about $M^n$ need to be added. Of\nparticular interest was proving the smooth co-area formula in the Riemannian\nmanifolds setting and re-formulating particular geometric inequalities.",
    "pdf_url": "http://arxiv.org/pdf/2411.15412v1",
    "published": "2024-11-23T02:21:20+00:00",
    "categories": [
      "math.DG",
      "53C21 (Primary) 28A75 (Secondary)"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15411v1",
    "title": "FINECAPTION: Compositional Image Captioning Focusing on Wherever You Want at Any Granularity",
    "authors": [
      "Hang Hua",
      "Qing Liu",
      "Lingzhi Zhang",
      "Jing Shi",
      "Zhifei Zhang",
      "Yilin Wang",
      "Jianming Zhang",
      "Jiebo Luo"
    ],
    "abstract": "The advent of large Vision-Language Models (VLMs) has significantly advanced\nmultimodal tasks, enabling more sophisticated and accurate reasoning across\nvarious applications, including image and video captioning, visual question\nanswering, and cross-modal retrieval. Despite their superior capabilities, VLMs\nstruggle with fine-grained image regional composition information perception.\nSpecifically, they have difficulty accurately aligning the segmentation masks\nwith the corresponding semantics and precisely describing the compositional\naspects of the referred regions.\n  However, compositionality - the ability to understand and generate novel\ncombinations of known visual and textual components - is critical for\nfacilitating coherent reasoning and understanding across modalities by VLMs. To\naddress this issue, we propose FINECAPTION, a novel VLM that can recognize\narbitrary masks as referential inputs and process high-resolution images for\ncompositional image captioning at different granularity levels. To support this\nendeavor, we introduce COMPOSITIONCAP, a new dataset for multi-grained region\ncompositional image captioning, which introduces the task of compositional\nattribute-aware regional image captioning.\n  Empirical results demonstrate the effectiveness of our proposed model\ncompared to other state-of-the-art VLMs. Additionally, we analyze the\ncapabilities of current VLMs in recognizing various visual prompts for\ncompositional region image captioning, highlighting areas for improvement in\nVLM design and training.",
    "pdf_url": "http://arxiv.org/pdf/2411.15411v1",
    "published": "2024-11-23T02:20:32+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15410v1",
    "title": "Minimizing Nature's Cost: Exploring Data-Free Physics-Informed Neural Network Solvers for Fluid Mechanics Applications",
    "authors": [
      "Abdelrahman Elmaradny",
      "Ahmed Atallah",
      "Haithem Taha"
    ],
    "abstract": "In this paper, we present a novel approach for fluid dynamic simulations by\nharnessing the capabilities of Physics-Informed Neural Networks (PINNs) guided\nby the newly unveiled principle of minimum pressure gradient (PMPG). In a PINN\nformulation, the physics problem is converted into a minimization problem\n(typically least squares). The PMPG asserts that for incompressible flows, the\ntotal magnitude of the pressure gradient over the domain must be minimum at\nevery time instant, turning fluid mechanics into minimization problems, making\nit an excellent choice for PINNs formulation. Following the PMPG, the proposed\nPINN formulation seeks to construct a neural network for the flow field that\nminimizes Nature's cost function for incompressible flows in contrast to\ntraditional PINNs that minimize the residuals of the Navier-Stokes equations.\nThis technique eliminates the need to train a separate pressure model, thereby\nreducing training time and computational costs. We demonstrate the\neffectiveness of this approach through a case study of inviscid flow around a\ncylinder, showing its ability to capture the underlying physics, while reducing\ncomputational cost and training time. The proposed approach outperforms the\ntraditional PINNs approach in terms of Root Mean Square Error, training time,\nconvergence rate, and compliance with physical metrics. While demonstrated on a\nsimple geometry, the methodology is extendable to more complex flow fields\n(e.g., Three-Dimensional, unsteady, viscous flows) within the incompressible\nrealm, which is the region of applicability of the PMPG.",
    "pdf_url": "http://arxiv.org/pdf/2411.15410v1",
    "published": "2024-11-23T02:20:01+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.comp-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2411.15409v1",
    "title": "Exploring the Sparsity-Quantization Interplay on a Novel Hybrid SNN Event-Driven Architecture",
    "authors": [
      "Ilkin Aliyev",
      "Jesus Lopez",
      "Tosiron Adegbija"
    ],
    "abstract": "Spiking Neural Networks (SNNs) offer potential advantages in energy\nefficiency but currently trail Artificial Neural Networks (ANNs) in\nversatility, largely due to challenges in efficient input encoding. Recent work\nshows that direct coding achieves superior accuracy with fewer timesteps than\ntraditional rate coding. However, there is a lack of specialized hardware to\nfully exploit the potential of direct-coded SNNs, especially their mix of dense\nand sparse layers. This work proposes the first hybrid inference architecture\nfor direct-coded SNNs. The proposed hardware architecture comprises a dense\ncore to efficiently process the input layer and sparse cores optimized for\nevent-driven spiking convolutions. Furthermore, for the first time, we\ninvestigate and quantify the quantization effect on sparsity. Our experiments\non two variations of the VGG9 network and implemented on a Xilinx Virtex\nUltraScale+ FPGA (Field-Programmable Gate Array) reveal two novel findings.\nFirstly, quantization increases the network sparsity by up to 15.2% with\nminimal loss of accuracy. Combined with the inherent low power benefits, this\nleads to a 3.4x improvement in energy compared to the full-precision version.\nSecondly, direct coding outperforms rate coding, achieving a 10% improvement in\naccuracy and consuming 26.4x less energy per image. Overall, our accelerator\nachieves 51x higher throughput and consumes half the power compared to previous\nwork. Our accelerator code is available at:\nhttps://github.com/githubofaliyev/SNN-DSE/tree/DATE25",
    "pdf_url": "http://arxiv.org/pdf/2411.15409v1",
    "published": "2024-11-23T02:17:41+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2411.16721v3",
    "title": "Steering Away from Harm: An Adaptive Approach to Defending Vision Language Model Against Jailbreaks",
    "authors": [
      "Han Wang",
      "Gang Wang",
      "Huan Zhang"
    ],
    "abstract": "Vision Language Models (VLMs) can produce unintended and harmful content when\nexposed to adversarial attacks, particularly because their vision capabilities\ncreate new vulnerabilities. Existing defenses, such as input preprocessing,\nadversarial training, and response evaluation-based methods, are often\nimpractical for real-world deployment due to their high costs. To address this\nchallenge, we propose ASTRA, an efficient and effective defense by adaptively\nsteering models away from adversarial feature directions to resist VLM attacks.\nOur key procedures involve finding transferable steering vectors representing\nthe direction of harmful response and applying adaptive activation steering to\nremove these directions at inference time. To create effective steering\nvectors, we randomly ablate the visual tokens from the adversarial images and\nidentify those most strongly associated with jailbreaks. These tokens are then\nused to construct steering vectors. During inference, we perform the adaptive\nsteering method that involves the projection between the steering vectors and\ncalibrated activation, resulting in little performance drops on benign inputs\nwhile strongly avoiding harmful outputs under adversarial inputs. Extensive\nexperiments across multiple models and baselines demonstrate our\nstate-of-the-art performance and high efficiency in mitigating jailbreak risks.\nAdditionally, ASTRA exhibits good transferability, defending against unseen\nattacks (i.e., structured-based attack, perturbation-based attack with project\ngradient descent variants, and text-only attack). Our code is available at\n\\url{https://github.com/ASTRAL-Group/ASTRA}.",
    "pdf_url": "http://arxiv.org/pdf/2411.16721v3",
    "published": "2024-11-23T02:17:17+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15408v1",
    "title": "Exploring Large Language Models for Multimodal Sentiment Analysis: Challenges, Benchmarks, and Future Directions",
    "authors": [
      "Shezheng Song"
    ],
    "abstract": "Multimodal Aspect-Based Sentiment Analysis (MABSA) aims to extract aspect\nterms and their corresponding sentiment polarities from multimodal information,\nincluding text and images. While traditional supervised learning methods have\nshown effectiveness in this task, the adaptability of large language models\n(LLMs) to MABSA remains uncertain. Recent advances in LLMs, such as Llama2,\nLLaVA, and ChatGPT, demonstrate strong capabilities in general tasks, yet their\nperformance in complex and fine-grained scenarios like MABSA is underexplored.\nIn this study, we conduct a comprehensive investigation into the suitability of\nLLMs for MABSA. To this end, we construct a benchmark to evaluate the\nperformance of LLMs on MABSA tasks and compare them with state-of-the-art\nsupervised learning methods. Our experiments reveal that, while LLMs\ndemonstrate potential in multimodal understanding, they face significant\nchallenges in achieving satisfactory results for MABSA, particularly in terms\nof accuracy and inference time. Based on these findings, we discuss the\nlimitations of current LLMs and outline directions for future research to\nenhance their capabilities in multimodal sentiment analysis.",
    "pdf_url": "http://arxiv.org/pdf/2411.15408v1",
    "published": "2024-11-23T02:17:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.16720v2",
    "title": "Importance-Based Token Merging for Efficient Image and Video Generation",
    "authors": [
      "Haoyu Wu",
      "Jingyi Xu",
      "Hieu Le",
      "Dimitris Samaras"
    ],
    "abstract": "Token merging can effectively accelerate various vision systems by processing\ngroups of similar tokens only once and sharing the results across them.\nHowever, existing token grouping methods are often ad hoc and random,\ndisregarding the actual content of the samples. We show that preserving\nhigh-information tokens during merging - those essential for semantic fidelity\nand structural details - significantly improves sample quality, producing finer\ndetails and more coherent, realistic generations. Despite being simple and\nintuitive, this approach remains underexplored.\n  To do so, we propose an importance-based token merging method that\nprioritizes the most critical tokens in computational resource allocation,\nleveraging readily available importance scores, such as those from\nclassifier-free guidance in diffusion models. Experiments show that our\napproach significantly outperforms baseline methods across multiple\napplications, including text-to-image synthesis, multi-view image generation,\nand video generation with various model architectures such as Stable Diffusion,\nZero123++, AnimateDiff, or PixArt-$\\alpha$.",
    "pdf_url": "http://arxiv.org/pdf/2411.16720v2",
    "published": "2024-11-23T02:01:49+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15407v1",
    "title": "Assouad and lower dimensions of graph-directed Bedford-McMullen carpets",
    "authors": [
      "Hua Qiu",
      "Qi Wang",
      "Shufang Wang"
    ],
    "abstract": "We calculate the Assouad and lower dimensions of graph-directed\nBedford-McMullen carpets, which reflect the extreme local scaling laws of the\nsets, in contrasting with known results on Hausdorff and box dimensions. We\nalso investigate the relationship between distinct dimensions. In particular,\nwe identify an equivalent condition when the box and Assouad dimension\ncoincide, and show that under this condition, the Hausdorff dimension attains\nthe same value.",
    "pdf_url": "http://arxiv.org/pdf/2411.15407v1",
    "published": "2024-11-23T01:55:03+00:00",
    "categories": [
      "math.CA",
      "28A80"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2411.15406v1",
    "title": "Uniform-in-Time Estimates on the Size of Chaos for Interacting Particle Systems",
    "authors": [
      "Pengzhi Xie"
    ],
    "abstract": "For any weakly interacting particle system with bounded kernel, we give\nuniform-in-time estimates of the $L^2$ norm of correlation functions, provided\nthat the diffusion coefficient is large enough. When the condition on the\nkernels is more restrictive, we can remove the dependence of the lower bound\nfor diffusion coefficient on the initial data and estimate the size of chaos in\na weaker sense. Based on these estimates, we may study fluctuation around the\nmean-field limit.",
    "pdf_url": "http://arxiv.org/pdf/2411.15406v1",
    "published": "2024-11-23T01:38:51+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "math.PR",
      "35Q70, 35Q83, 60F17, 60H10"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2411.15405v1",
    "title": "ML-SPEAK: A Theory-Guided Machine Learning Method for Studying and Predicting Conversational Turn-taking Patterns",
    "authors": [
      "Lisa R. O'Bryan",
      "Madeline Navarro",
      "Juan Segundo Hevia",
      "Santiago Segarra"
    ],
    "abstract": "Predicting team dynamics from personality traits remains a fundamental\nchallenge for the psychological sciences and team-based organizations.\nUnderstanding how team composition generates team processes can significantly\nadvance team-based research along with providing practical guidelines for team\nstaffing and training. Although the Input-Process-Output (IPO) model has been\nuseful for studying these connections, the complex nature of team member\ninteractions demands a more dynamic approach. We develop a computational model\nof conversational turn-taking within self-organized teams that can provide\ninsight into the relationships between team member personality traits and team\ncommunication dynamics. We focus on turn-taking patterns between team members,\nindependent of content, which can significantly influence team emergent states\nand outcomes while being objectively measurable and quantifiable. As our model\nis trained on conversational data from teams of given trait compositions, it\ncan learn the relationships between individual traits and speaking behaviors\nand predict group-wide patterns of communication based on team trait\ncomposition alone. We first evaluate the performance of our model using\nsimulated data and then apply it to real-world data collected from\nself-organized student teams. In comparison to baselines, our model is more\naccurate at predicting speaking turn sequences and can reveal new relationships\nbetween team member traits and their communication patterns. Our approach\noffers a more data-driven and dynamic understanding of team processes. By\nbridging the gap between individual personality traits and team communication\npatterns, our model has the potential to inform theories of team processes and\nprovide powerful insights into optimizing team staffing and training.",
    "pdf_url": "http://arxiv.org/pdf/2411.15405v1",
    "published": "2024-11-23T01:27:01+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15404v1",
    "title": "A Comparative Analysis of Transformer and LSTM Models for Detecting Suicidal Ideation on Reddit",
    "authors": [
      "Khalid Hasan",
      "Jamil Saquer"
    ],
    "abstract": "Suicide is a critical global health problem involving more than 700,000\ndeaths yearly, particularly among young adults. Many people express their\nsuicidal thoughts on social media platforms such as Reddit. This paper\nevaluates the effectiveness of the deep learning transformer-based models BERT,\nRoBERTa, DistilBERT, ALBERT, and ELECTRA and various Long Short-Term Memory\n(LSTM) based models in detecting suicidal ideation from user posts on Reddit.\nToward this objective, we curated an extensive dataset from diverse subreddits\nand conducted linguistic, topic modeling, and statistical analyses to ensure\ndata quality. Our results indicate that each model could reach high accuracy\nand F1 scores, but among them, RoBERTa emerged as the most effective model with\nan accuracy of 93.22% and F1 score of 93.14%. An LSTM model that uses attention\nand BERT embeddings performed as the second best, with an accuracy of 92.65%\nand an F1 score of 92.69%. Our findings show that transformer-based models have\nthe potential to improve suicide ideation detection, thereby providing a path\nto develop robust mental health monitoring tools from social media. This\nresearch, therefore, underlines the undeniable prospect of advanced techniques\nin Natural Language Processing (NLP) while improving suicide prevention\nefforts.",
    "pdf_url": "http://arxiv.org/pdf/2411.15404v1",
    "published": "2024-11-23T01:17:43+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15403v2",
    "title": "Partial Knowledge Distillation for Alleviating the Inherent Inter-Class Discrepancy in Federated Learning",
    "authors": [
      "Xiaoyu Gan",
      "Jingbo Jiang",
      "Jingyang Zhu",
      "Xiaomeng Wang",
      "Xizi Chen",
      "Chi-Ying Tsui"
    ],
    "abstract": "Substantial efforts have been devoted to alleviating the impact of the\nlong-tailed class distribution in federated learning. In this work, we observe\nan interesting phenomenon that certain weak classes consistently exist even for\nclass-balanced learning. These weak classes, different from the minority\nclasses in the previous works, are inherent to data and remain fairly\nconsistent for various network structures, learning paradigms, and data\npartitioning methods. The inherent inter-class accuracy discrepancy can reach\nover 36.9% for federated learning on the FashionMNIST and CIFAR-10 datasets,\neven when the class distribution is balanced both globally and locally. In this\nstudy, we empirically analyze the potential reason for this phenomenon.\nFurthermore, a partial knowledge distillation (PKD) method is proposed to\nimprove the model's classification accuracy for weak classes. In this approach,\nknowledge transfer is initiated upon the occurrence of specific\nmisclassifications within certain weak classes. Experimental results show that\nthe accuracy of weak classes can be improved by 10.7%, reducing the inherent\ninter-class discrepancy effectively.",
    "pdf_url": "http://arxiv.org/pdf/2411.15403v2",
    "published": "2024-11-23T01:16:46+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15402v2",
    "title": "Scale-invariant total decay width $Œì(H\\to b\\bar{b})$ using the novel method of characteristic operator",
    "authors": [
      "Jiang Yan",
      "Xing-Gang Wu",
      "Jian-Ming Shen",
      "Xu-Dong Huang",
      "Zhi-Fei Wu"
    ],
    "abstract": "In this paper, a novel method via using the characteristic operator~(CO)\n${\\cal \\hat{D}}_{n_{\\gamma}, n_{\\beta}}$ is proposed to extend the\napplicability of PMC, which is a theoretical generalization of previous PMC\nsingle-scale setting approach. Using the CO formulism, we are able to\nfacilitate the derivation of complex scenarios within a structured theoretical\nframework, leading to simpler procedures and more compact expressions. The CO\nframework not only streamlines derivations for complex scenarios, yielding\nsimplified procedures and more compact expressions, but also achieves a\nscheme-and-scale invariant pQCD series by fixing the correct effective\nmagnitude of $\\alpha_s$ and the running mass simultaneously. Both are well\nmatched with the expansion coefficients of the series, leading to the wanted\nscheme-and-scale invariant conformal series. As an example, we show the\nachievement of scale-invariant N$^{4}$LO total decay width $\\Gamma(H\\to\nb\\bar{b})$ under the $\\overline{\\rm MS}$-scheme. Using the CO framework, its\neffective coupling $\\alpha_{s}(Q_{*})$ and effective $b$-quark $\\overline{\\rm\nMS}$-mass $\\overline{m}_{b}(Q_{*})$ are determined by absorbing all\nnon-conformal $\\{\\beta_{i}\\}$-terms from the renormalization group equations\nfor either $\\alpha_s$ or $\\overline{m}_{b}$ simultaneously. The PMC scale is\nfixed up to N$^3$LL-accuracy, $Q_{*} = 55.2916$~GeV and a scale-invariant total\ndecay width is obtained, $\\Gamma(H \\to b\\bar{b}) = 2.3819\n_{-0.0231}^{+0.0230}$~MeV, whose errors are squared averages of the ones\nassociated with $\\Delta \\alpha_{s}(M_{Z}) = \\pm 0.0009$, $\\Delta M_{H} =\n0.11$~GeV, $\\Delta \\overline{m}_{b}(\\overline{m}_{b}) = \\pm 0.007$~GeV, and the\nuncalculated N$^{5}$LO contributions $\\Delta\\Gamma= \\pm0.0001$~MeV predicted\nvia Bayesian analysis with the degree-of-belief ${\\rm DoB}=95.5\\%$.",
    "pdf_url": "http://arxiv.org/pdf/2411.15402v2",
    "published": "2024-11-23T01:11:43+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15401v4",
    "title": "The reference interval in higher-order stochastic dominance",
    "authors": [
      "Ruodu Wang",
      "Qinyu Wu"
    ],
    "abstract": "Given two random variables taking values in a bounded interval, we study\nwhether one dominates the other in higher-order stochastic dominance depends on\nthe reference interval in the model setting. We obtain two results. First, the\nstochastic dominance relations get strictly stronger when the reference\ninterval shrinks if and only if the order of stochastic dominance is larger\nthan three. Second, for mean-preserving stochastic dominance relations, the\nreference interval is irrelevant if and only if the difference between the\ndegree of the stochastic dominance and the number of moments is no larger than\nthree. These results highlight complications arising from using higher-order\nstochastic dominance in economic applications.",
    "pdf_url": "http://arxiv.org/pdf/2411.15401v4",
    "published": "2024-11-23T01:07:45+00:00",
    "categories": [
      "math.PR",
      "econ.TH"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15400v1",
    "title": "Group-wise normalization in differential abundance analysis of microbiome samples",
    "authors": [
      "Dylan Clark-Boucher",
      "Brent A Coull",
      "Harrison T Reeder",
      "Fenglei Wang",
      "Qi Sun",
      "Jacqueline R Starr",
      "Kyu Ha Lee"
    ],
    "abstract": "A key challenge in differential abundance analysis of microbial samples is\nthat the counts for each sample are compositional, resulting in biased\ncomparisons of the absolute abundance across study groups. Normalization-based\ndifferential abundance analysis methods rely on external normalization factors\nthat account for the compositionality by standardizing the counts onto a common\nnumerical scale. However, existing normalization methods have struggled at\nmaintaining the false discovery rate in settings where the variance or\ncompositional bias is large. This article proposes a novel framework for\nnormalization that can reduce bias in differential abundance analysis by\nre-conceptualizing normalization as a group-level task. We present two\nnormalization methods within the group-wise framework: group-wise relative log\nexpression (G-RLE) and fold-truncated sum scaling (FTSS). G-RLE and FTSS\nachieve higher statistical power for identifying differentially abundant taxa\nthan existing methods in model-based and synthetic data simulation settings,\nwhile maintaining the false discovery rate in challenging scenarios where\nexisting methods suffer. The best results are obtained from using FTSS\nnormalization with the differential abundance analysis method MetagenomeSeq.\nCode for implementing the methods and replicating the analysis can be found at\nour GitHub page\n(https://github.com/dclarkboucher/microbiome_groupwise_normalization).",
    "pdf_url": "http://arxiv.org/pdf/2411.15400v1",
    "published": "2024-11-23T01:05:00+00:00",
    "categories": [
      "q-bio.GN"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2411.16719v3",
    "title": "Learn2Synth: Learning Optimal Data Synthesis Using Hypergradients for Brain Image Segmentation",
    "authors": [
      "Xiaoling Hu",
      "Xiangrui Zeng",
      "Oula Puonti",
      "Juan Eugenio Iglesias",
      "Bruce Fischl",
      "Yael Balbastre"
    ],
    "abstract": "Domain randomization through synthesis is a powerful strategy to train\nnetworks that are unbiased with respect to the domain of the input images.\nRandomization allows networks to see a virtually infinite range of intensities\nand artifacts during training, thereby minimizing overfitting to appearance and\nmaximizing generalization to unseen data. Although powerful, this approach\nrelies on the accurate tuning of a large set of hyperparameters that govern the\nprobabilistic distribution of the synthesized images. Instead of manually\ntuning these parameters, we introduce Learn2Synth, a novel procedure in which\nsynthesis parameters are learned using a small set of real labeled data. Unlike\nmethods that impose constraints to align synthetic data with real data (e.g.,\ncontrastive or adversarial techniques), which risk misaligning the image and\nits label map, we tune an augmentation engine such that a segmentation network\ntrained on synthetic data has optimal accuracy when applied to real data. This\napproach allows the training procedure to benefit from real labeled examples,\nwithout ever using these real examples to train the segmentation network, which\navoids biasing the network towards the properties of the training set.\nSpecifically, we develop parametric and nonparametric strategies to enhance\nsynthetic images in a way that improves the performance of the segmentation\nnetwork. We demonstrate the effectiveness of this learning strategy on\nsynthetic and real-world brain scans. Code is available at:\nhttps://github.com/HuXiaoling/Learn2Synth.",
    "pdf_url": "http://arxiv.org/pdf/2411.16719v3",
    "published": "2024-11-23T00:52:49+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15399v1",
    "title": "Less is More: Optimizing Function Calling for LLM Execution on Edge Devices",
    "authors": [
      "Varatheepan Paramanayakam",
      "Andreas Karatzas",
      "Iraklis Anagnostopoulos",
      "Dimitrios Stamoulis"
    ],
    "abstract": "The advanced function-calling capabilities of foundation models open up new\npossibilities for deploying agents to perform complex API tasks. However,\nmanaging large amounts of data and interacting with numerous APIs makes\nfunction calling hardware-intensive and costly, especially on edge devices.\nCurrent Large Language Models (LLMs) struggle with function calling at the edge\nbecause they cannot handle complex inputs or manage multiple tools effectively.\nThis results in low task-completion accuracy, increased delays, and higher\npower consumption. In this work, we introduce Less-is-More, a novel\nfine-tuning-free function-calling scheme for dynamic tool selection. Our\napproach is based on the key insight that selectively reducing the number of\ntools available to LLMs significantly improves their function-calling\nperformance, execution time, and power efficiency on edge devices. Experimental\nresults with state-of-the-art LLMs on edge hardware show agentic success rate\nimprovements, with execution time reduced by up to 70% and power consumption by\nup to 40%.",
    "pdf_url": "http://arxiv.org/pdf/2411.15399v1",
    "published": "2024-11-23T00:51:09+00:00",
    "categories": [
      "cs.PF",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.PF"
  },
  {
    "id": "http://arxiv.org/abs/2411.15398v2",
    "title": "The ultimate issue error in scientific inference: mistaking parameters for hypotheses",
    "authors": [
      "Stanley E. Lazic"
    ],
    "abstract": "Statistical inference often conflates the probability of a parameter with the\nprobability of a hypothesis, a critical misunderstanding termed the ultimate\nissue error. This error is pervasive across the social, biological, and medical\nsciences, where null hypothesis significance testing (NHST) is mistakenly\nunderstood to be testing hypotheses rather than evaluating parameter estimates.\nHere, we advocate for using the Weight of Evidence (WoE) approach, which\nintegrates quantitative data with qualitative background information for more\naccurate and transparent inference. Through a detailed example involving the\nrelationship between vitamin D (25-hydroxy vitamin D) levels and COVID-19 risk,\nwe demonstrate how WoE quantifies support for hypotheses while accounting for\nstudy design biases, power, and confounding factors. These findings emphasise\nthe necessity of combining statistical metrics with contextual evaluation. This\noffers a structured framework to enhance reproducibility, reduce false\ninterpretations, and foster robust scientific conclusions across disciplines.",
    "pdf_url": "http://arxiv.org/pdf/2411.15398v2",
    "published": "2024-11-23T00:47:29+00:00",
    "categories": [
      "stat.ME",
      "q-bio.QM",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2411.15397v3",
    "title": "Efficient Online Inference of Vision Transformers by Training-Free Tokenization",
    "authors": [
      "Leonidas Gee",
      "Wing Yan Li",
      "Viktoriia Sharmanska",
      "Novi Quadrianto"
    ],
    "abstract": "The cost of deploying vision transformers increasingly represents a barrier\nto wider industrial adoption. Existing compression techniques require\nadditional end-to-end fine-tuning or incur a significant drawback to runtime,\nmaking them ill-suited for online (real-time) inference, where a prediction is\nmade on any new input as it comes in. We introduce the $\\textbf{Visual Word\nTokenizer}$ (VWT), a training-free method for reducing power costs while\nretaining performance and runtime. The VWT groups visual subwords (image\npatches) that are frequently used into visual words while infrequent ones\nremain intact. To do so, $\\textit{intra}$-image or $\\textit{inter}$-image\nstatistics are leveraged to identify similar visual concepts for sequence\ncompression. Experimentally, we demonstrate a reduction in wattage of up to 25%\nwith only a 20% increase in runtime at most. Comparative approaches of 8-bit\nquantization and token merging achieve a lower or similar power efficiency but\nexact a higher toll on runtime (up to 100% or more). Our results indicate that\nVWTs are well-suited for efficient online inference with a marginal compromise\non performance.",
    "pdf_url": "http://arxiv.org/pdf/2411.15397v3",
    "published": "2024-11-23T00:47:13+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15396v1",
    "title": "The Decoy Dilemma in Online Medical Information Evaluation: A Comparative Study of Credibility Assessments by LLM and Human Judges",
    "authors": [
      "Jiqun Liu",
      "Jiangen He"
    ],
    "abstract": "Can AI be cognitively biased in automated information judgment tasks? Despite\nrecent progresses in measuring and mitigating social and algorithmic biases in\nAI and large language models (LLMs), it is not clear to what extent LLMs behave\n\"rationally\", or if they are also vulnerable to human cognitive bias triggers.\nTo address this open problem, our study, consisting of a crowdsourcing user\nexperiment and a LLM-enabled simulation experiment, compared the credibility\nassessments by LLM and human judges under potential decoy effects in an\ninformation retrieval (IR) setting, and empirically examined the extent to\nwhich LLMs are cognitively biased in COVID-19 medical (mis)information\nassessment tasks compared to traditional human assessors as a baseline. The\nresults, collected from a between-subject user experiment and a LLM-enabled\nreplicate experiment, demonstrate that 1) Larger and more recent LLMs tend to\nshow a higher level of consistency and accuracy in distinguishing credible\ninformation from misinformation. However, they are more likely to give higher\nratings for misinformation due to the presence of a more salient, decoy\nmisinformation result; 2) While decoy effect occurred in both human and LLM\nassessments, the effect is more prevalent across different conditions and\ntopics in LLM judgments compared to human credibility ratings. In contrast to\nthe generally assumed \"rationality\" of AI tools, our study empirically confirms\nthe cognitive bias risks embedded in LLM agents, evaluates the decoy impact on\nLLMs against human credibility assessments, and thereby highlights the\ncomplexity and importance of debiasing AI agents and developing\npsychology-informed AI audit techniques and policies for automated judgment\ntasks and beyond.",
    "pdf_url": "http://arxiv.org/pdf/2411.15396v1",
    "published": "2024-11-23T00:43:27+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC",
      "H.3.3; I.2.7"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2411.15395v1",
    "title": "ChatBCI: A P300 Speller BCI Leveraging Large Language Models for Improved Sentence Composition in Realistic Scenarios",
    "authors": [
      "Jiazhen Hong",
      "Weinan Wang",
      "Laleh Najafizadeh"
    ],
    "abstract": "P300 speller BCIs allow users to compose sentences by selecting target keys\non a GUI through the detection of P300 component in their EEG signals following\nvisual stimuli. Most P300 speller BCIs require users to spell words letter by\nletter, or the first few initial letters, resulting in high keystroke demands\nthat increase time, cognitive load, and fatigue. This highlights the need for\nmore efficient, user-friendly methods for faster sentence composition. In this\nwork, we introduce ChatBCI, a P300 speller BCI that leverages the zero-shot\nlearning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing\nkeystrokes and accelerating sentence composition. ChatBCI retrieves word\nsuggestions through remote queries to the GPT-3.5 API. A new GUI, displaying\nGPT-3.5 word suggestions as extra keys is designed. SWLDA is used for the P300\nclassification. Seven subjects completed two online spelling tasks: 1)\ncopy-spelling a self-composed sentence using ChatBCI, and 2) improvising a\nsentence using ChatBCI's word suggestions. Results demonstrate that in Task 1,\non average, ChatBCI outperforms letter-by-letter BCI spellers, reducing time\nand keystrokes by 62.14% and 53.22%, respectively, and increasing information\ntransfer rate by 198.96%. In Task 2, ChatBCI achieves 80.68% keystroke savings\nand a record 8.53 characters/min for typing speed. Overall, ChatBCI, by\nemploying remote LLM queries, enhances sentence composition in realistic\nscenarios, significantly outperforming traditional spellers without requiring\nlocal model training or storage. ChatBCI's (multi-) word predictions, combined\nwith its new GUI, pave the way for developing next-generation speller BCIs that\nare efficient and effective for real-time communication, especially for users\nwith communication and motor disabilities.",
    "pdf_url": "http://arxiv.org/pdf/2411.15395v1",
    "published": "2024-11-23T00:42:12+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.SY",
      "eess.SP",
      "eess.SY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2411.15394v2",
    "title": "Where is the Super-virial Gas? II: Insight from the Survey of Galactic Sightlines",
    "authors": [
      "Manami Roy",
      "Smita Mathur",
      "Sanskriti Das",
      "Armando Lara-DI",
      "Yair Krongold",
      "Anjali Gupta"
    ],
    "abstract": "Recent observations have revealed a super-virial temperature gas phase at\nlog(T/K) $\\sim7$ in the Milky Way, challenging existing galaxy-formation\nmodels. This hot gas phase was discovered toward extragalactic absorption\nsightlines and blank-sky emission fields, both at high galactic latitudes. The\nlocation of this hot component is unknown; is it in the extended circumgalactic\nmedium (CGM) or in the interstellar medium (ISM) instead? We analyzed X-ray\nspectra from Chandra's High-Energy Transmission Grating (HETG) observations of\n27 Galactic X-ray binaries (XRBs) to investigate whether the hot gas component\nis present in the ISM. We searched for absorption lines of SXVI K$\\alpha$,\nSiXIV K$\\alpha$, and NeX K$\\alpha$, which are the tell-tale signatures of the\nhot gas and which have been detected toward extragalactic sightlines. Of the 27\ntargets, these lines were detected in the spectra of only 7, with two sources\ndisplaying broad line features likely intrinsic to the XRB systems.\nAdditionally, most of the detected lines are time-variable, reinforcing their\nlikely association with the XRBs. Our results suggest that the super-virial\ntemperature gas is not a widespread component of the ISM but may instead be\nlocated in extraplanar regions or the extended CGM, in line with some recent\nsimulation results.",
    "pdf_url": "http://arxiv.org/pdf/2411.15394v2",
    "published": "2024-11-23T00:32:59+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2412.02704v1",
    "title": "Correlation Clustering with Overlap: a Heuristic Graph Editing Approach",
    "authors": [
      "Faisal N. Abu-Khzam",
      "Lucas Isenmann",
      "Sergio Thoumi"
    ],
    "abstract": "Correlation clustering seeks a partition of the vertex set of a given\ngraph/network into groups of closely related, or just close enough, vertices so\nthat elements of different groups are not close to each other. The problem has\nbeen previously modeled and studied as a graph editing problem, namely Cluster\nEditing, which assumes that closely related data elements must be adjacent. As\nsuch, the main objective (of the Cluster Editing problem) is to turn clusters\ninto cliques as a way to identify them. This is to be obtained via two main\nedge editing operations: additions and deletions. There are two problems with\nthe Cluster Editing model that we seek to address in this paper. First,\n``closely'' related does not necessarily mean ``directly'' related. So\ncloseness should be measured by relatively short distance. As such, we seek to\nturn clusters into (sub)graphs of small diameter. Second, in real applications,\na data element can belong, or have roles, in multiple groups. In some cases,\nwithout allowing data elements to belong to more than one cluster each, makes\nit hard to achieve any clustering via classical partition-based methods. We\naddress this latter problem by allowing vertex cloning, also known as vertex\nsplitting. Heuristic methods for the introduced problem are presented along\nwith experimental results showing the effectiveness of the proposed model and\nalgorithmic approach.",
    "pdf_url": "http://arxiv.org/pdf/2412.02704v1",
    "published": "2024-11-23T00:28:03+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2412.06799v1",
    "title": "From Quantum Cognition to Conceptuality Interpretation I: Tracing the Brussels Group's Intellectual Journey",
    "authors": [
      "Diederik Aerts",
      "Massimiliano Sassoli de Bianchi",
      "Sandro Sozzo"
    ],
    "abstract": "The conceptuality interpretation of quantum mechanics proposes that quantum\nentities have a conceptual nature, interacting with the material world through\nprocesses that are the physical counterpart of the meaning-based processes\nwhich typically occur in human cognition. This interpretation emerged from the\nearly developments in quantum cognition, a field that uses quantum mathematics\nto model human cognitive activity. It benefited from the specific approach\ntaken by the Brussels research group, modeling concepts themselves as quantum\nentities and minds as measuring apparatuses. The article sketches the essential\nsteps of the intellectual journey going from the first applications of quantum\nnotions and formalisms to human cognition to the proposal of a potentially\ngroundbreaking interpretation of quantum mechanics, offering profound\nexplanations for major quantum phenomena. This was done by drawing numerous\nparallels with the human conceptual domain and suggesting the existence of a\nlevel of cognitive activity that would underlie our physical reality. This\nmeans that an increased cross-fertilization between the conceptuality\ninterpretation and quantum cognition is to be expected in the future, both of\nwhich are synergistic in furthering our understanding of the nature of reality.\nThis is the first part of a two-part article. In the second part, which can be\nread independently of the first, the successes of the interpretation will be\ndescribed in a more systematic way, providing a brief overview of what has been\nachieved so far.",
    "pdf_url": "http://arxiv.org/pdf/2412.06799v1",
    "published": "2024-11-23T00:22:51+00:00",
    "categories": [
      "physics.hist-ph",
      "quant-ph"
    ],
    "primary_category": "physics.hist-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15393v1",
    "title": "Gradient-Free Classifier Guidance for Diffusion Model Sampling",
    "authors": [
      "Rahul Shenoy",
      "Zhihong Pan",
      "Kaushik Balakrishnan",
      "Qisen Cheng",
      "Yongmoon Jeon",
      "Heejune Yang",
      "Jaewon Kim"
    ],
    "abstract": "Image generation using diffusion models have demonstrated outstanding\nlearning capabilities, effectively capturing the full distribution of the\ntraining dataset. They are known to generate wide variations in sampled images,\nalbeit with a trade-off in image fidelity. Guided sampling methods, such as\nclassifier guidance (CG) and classifier-free guidance (CFG), focus sampling in\nwell-learned high-probability regions to generate images of high fidelity, but\neach has its limitations. CG is computationally expensive due to the use of\nback-propagation for classifier gradient descent, while CFG, being\ngradient-free, is more efficient but compromises class label alignment compared\nto CG. In this work, we propose an efficient guidance method that fully\nutilizes a pre-trained classifier without using gradient descent. By using the\nclassifier solely in inference mode, a time-adaptive reference class label and\ncorresponding guidance scale are determined at each time step for guided\nsampling. Experiments on both class-conditioned and text-to-image generation\ndiffusion models demonstrate that the proposed Gradient-free Classifier\nGuidance (GFCG) method consistently improves class prediction accuracy. We also\nshow GFCG to be complementary to other guided sampling methods like CFG. When\ncombined with the state-of-the-art Autoguidance (ATG), without additional\ncomputational overhead, it enhances image fidelity while preserving diversity.\nFor ImageNet 512$\\times$512, we achieve a record $\\text{FD}_{\\text{DINOv2}}$ of\n23.09, while simultaneously attaining a higher classification Precision (94.3%)\ncompared to ATG (90.2%)",
    "pdf_url": "http://arxiv.org/pdf/2411.15393v1",
    "published": "2024-11-23T00:22:21+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.10376v1",
    "title": "Estimations of Fourier Coefficients For Controlled Distortion of a Periodic Function",
    "authors": [
      "Vladimir Sluchak"
    ],
    "abstract": "There is a class of physical filtration processes where the input is\nadequately modeled by a continuous periodic function f (x) of bounded variation\nover its period, and the output depends only on certain harmonics of the\nFourier expansion of f (x) in the orthogonal basis of trigonometric functions.\nOne example is the discrete spectrum sound generation by a revolving body in a\nsteady fluid flow. This type of sound can be controlled through the amplitudes\nof certain harmonics of the circular distribution of the inflow velocity.\nAttainable goals of such a controlled distortion of f (x) are formulated as\nfuzzy targets and required inequalities relating the integral characteristics\nof f (x) with the coefficients of the corresponding Fourier expansion are\nproven.",
    "pdf_url": "http://arxiv.org/pdf/2412.10376v1",
    "published": "2024-11-23T00:19:45+00:00",
    "categories": [
      "math.GM"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15392v1",
    "title": "Decoding physics identity: A Spanish-language adaptation on an instrument and its correlation with STEM achievement",
    "authors": [
      "O. I. Gonz√°lez-Pe√±a",
      "G. Mor√°n-Soto",
      "B. M. Rodr√≠guez-Lara"
    ],
    "abstract": "The representation of Spanish-speaking students in STEM identity literature,\nparticularly in physics identity, is conspicuously minimal. This study\naddresses this gap with a two-pronged approach. First, a physics identity\ninstrument was adapted for Spanish-speaking STEM students to promote\ninclusivity in educational research. Data from 334 Mexican STEM students was\ncollected and analysed for validation through factor analyses and Cronbach's\nalpha, confirming the structural integrity and reliability of the adapted\ninstrument. Second, the instrument was employed to examine the correlation\nbetween physics identity and academic performance in a separate dataset from\n200 engineering students, using multivariate linear and logistic regressions.\n  The findings underscore gender's impact on physics course grades. Notably,\nvariations in physics identity among engineering students indicated a potential\nlink with their chosen field. Despite the importance of physics in engineering,\nphysics identity was lower than expected, and performance in physics courses\ndid not consistently correlate with a strong physics identity. However, the\n`interest in physics topics` subconstruct did correlate with physics course\ngrades.\n  This research fills a critical void by providing an adapted instrument for\nassessing physics identity in Spanish-speaking students and underscores the\nneed for pedagogical shifts to enhance physics identity and STEM outcomes for\nLatino students.",
    "pdf_url": "http://arxiv.org/pdf/2411.15392v1",
    "published": "2024-11-23T00:15:43+00:00",
    "categories": [
      "physics.ed-ph"
    ],
    "primary_category": "physics.ed-ph"
  },
  {
    "id": "http://arxiv.org/abs/2411.15391v4",
    "title": "Disk and Partial Disk Inspection: Worst- to Average-Case and Pareto Upper Bounds",
    "authors": [
      "James Conley",
      "Konstantinos Georgiou"
    ],
    "abstract": "We consider $n$ unit-speed mobile agents initially positioned at the center\nof a unit disk, tasked with inspecting all points on the disk's perimeter. A\nperimeter point is considered covered if an agent located outside the disk's\ninterior has unobstructed visibility of it, treating the disk itself as an\nobstacle. For $n=1$, this problem is known as the shoreline problem with a\nknown distance. Isbell (1957) derived an optimal trajectory that minimizes the\nworst-case inspection time for this problem, while Gluss (1961) proposed\nheuristics for its average-case version. The one-agent case was originally\nintroduced as a more tractable variant of Bellman's famous lost-in-the-forest\nproblem.\n  Our contributions are threefold. First, as a warm-up, we extend Isbell's\nfindings by deriving worst-case optimal trajectories for partial inspection of\na section of the disk, thereby providing an alternative proof of optimality for\ninspection with $n \\geq 2$ agents. Second, we improve Gluss's bounds on the\naverage-case inspection time under a uniform distribution of perimeter points\n(equivalent to randomized inspection algorithms), and we also strengthen the\nmethodology by combining spatial discretization with Nonlinear Programming\n(NLP) to build feasible solutions to the continuous problem and compare them\nwith NLP solutions. Third, we establish Pareto-optimal bounds for the\nmulti-objective problem of jointly minimizing the worst-case and average-case\ninspection times.",
    "pdf_url": "http://arxiv.org/pdf/2411.15391v4",
    "published": "2024-11-23T00:11:56+00:00",
    "categories": [
      "cs.DM",
      "cs.CG"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2411.15390v3",
    "title": "The Hatching-Box: A Novel System for Automated Monitoring and Quantification of Drosophila melanogaster Developmental Behavior",
    "authors": [
      "Julian Bigge",
      "Maite Ogueta",
      "Luis Garcia",
      "Benjamin Risse"
    ],
    "abstract": "In this paper we propose the Hatching-Box, a novel imaging and analysis\nsystem to automatically monitor and quantify the developmental behavior of\nDrosophila in standard rearing vials and during regular rearing routines,\nrendering explicit experiments obsolete. This is achieved by combining custom\ntailored imaging hardware with dedicated detection and tracking algorithms,\nenabling the quantification of larvae, filled/empty pupae and flies over\nmultiple days. Given the affordable and reproducible design of the Hatching-Box\nin combination with our generic client/server-based software, the system can\neasily be scaled to monitor an arbitrary amount of rearing vials\nsimultaneously. We evaluated our system on a curated image dataset comprising\nnearly 470,000 annotated objects and performed several studies on real world\nexperiments. We successfully reproduced results from well-established circadian\nexperiments by comparing the eclosion periods of wild type flies to the clock\nmutants $\\textit{per}^{short}$, $\\textit{per}^{long}$ and $\\textit{per}^0$\nwithout involvement of any manual labor. Furthermore we show, that the\nHatching-Box is able to extract additional information about group behavior as\nwell as to reconstruct the whole life-cycle of the individual specimens. These\nresults not only demonstrate the applicability of our system for long-term\nexperiments but also indicate its benefits for automated monitoring in the\ngeneral cultivation process.",
    "pdf_url": "http://arxiv.org/pdf/2411.15390v3",
    "published": "2024-11-23T00:09:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15389v2",
    "title": "Singularity categories and singular loci of certain quotient singularities",
    "authors": [
      "Xiaojun Chen",
      "Jieheng Zeng"
    ],
    "abstract": "Let $V$ be a finite dimensional $k$-vector space, where $k$ is an algebraic\nclosed field of characteristic zero. Let $G \\subseteq \\mathrm{SL}(V)$ be a\nfinite abelian group, and denote by $S$ the $G$-invariant subring of the\npolynomial ring $k[V]$. It is shown that the singularity category $D_{sg}(S)$\nrecovers the reduced singular locus of $\\mathrm{Spec}(S)$.",
    "pdf_url": "http://arxiv.org/pdf/2411.15389v2",
    "published": "2024-11-23T00:04:24+00:00",
    "categories": [
      "math.AG",
      "math.RA",
      "math.RT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2411.15388v2",
    "title": "A Contrast-Agnostic Method for Ultra-High Resolution Claustrum Segmentation",
    "authors": [
      "Chiara Mauri",
      "Ryan Fritz",
      "Jocelyn Mora",
      "Benjamin Billot",
      "Juan Eugenio Iglesias",
      "Koen Van Leemput",
      "Jean Augustinack",
      "Douglas N Greve"
    ],
    "abstract": "The claustrum is a band-like gray matter structure located between putamen\nand insula whose exact functions are still actively researched. Its sheet-like\nstructure makes it barely visible in in vivo Magnetic Resonance Imaging (MRI)\nscans at typical resolutions and neuroimaging tools for its study, including\nmethods for automatic segmentation, are currently very limited. In this paper,\nwe propose a contrast- and resolution-agnostic method for claustrum\nsegmentation at ultra-high resolution (0.35 mm isotropic); the method is based\non the SynthSeg segmentation framework (Billot et al., 2023), which leverages\nthe use of synthetic training intensity images to achieve excellent\ngeneralization. In particular, SynthSeg requires only label maps to be trained,\nsince corresponding intensity images are synthesized on the fly with random\ncontrast and resolution. We trained a deep learning network for automatic\nclaustrum segmentation, using claustrum manual labels obtained from 18\nultra-high resolution MRI scans (mostly ex vivo). We demonstrated the method to\nwork on these 18 high resolution cases (Dice score = 0.632, mean surface\ndistance = 0.458 mm, and volumetric similarity = 0.867 using 6-fold Cross\nValidation (CV)), and also on in vivo T1-weighted MRI scans at typical\nresolutions (~1 mm isotropic). We also demonstrated that the method is robust\nin a test-retest setting and when applied to multimodal imaging (T2-weighted,\nProton Density and quantitative T1 scans). To the best of our knowledge this is\nthe first accurate method for automatic ultra-high resolution claustrum\nsegmentation, which is robust against changes in contrast and resolution. The\nmethod is released at https://github.com/chiara-mauri/claustrum_segmentation\nand as part of the neuroimaging package Freesurfer (Fischl, 2012).",
    "pdf_url": "http://arxiv.org/pdf/2411.15388v2",
    "published": "2024-11-23T00:03:40+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2411.15387v2",
    "title": "From Jack of All Trades to Master of One: Specializing LLM-based Autoraters to a Test Set",
    "authors": [
      "Mara Finkelstein",
      "Dan Deutsch",
      "Parker Riley",
      "Juraj Juraska",
      "Geza Kovacs",
      "Markus Freitag"
    ],
    "abstract": "As LLMs continue to become more powerful and versatile, human evaluation has\nquickly become intractable at scale and reliance on automatic metrics has\nbecome the norm. Recently, it has been shown that LLMs are themselves\nstate-of-the-art evaluators for many tasks. These Autoraters are typically\ndesigned so that they generalize to new systems and test sets. In practice,\nhowever, evaluation is performed on a small set of fixed, canonical test sets,\nwhich are carefully curated to measure certain capabilities of interest and are\nnot changed frequently. In this work, we design a method which specializes a\nprompted Autorater to a given test set, by leveraging historical ratings on the\ntest set to construct in-context learning (ICL) examples. We evaluate our\nSpecialist method on the task of fine-grained machine translation evaluation,\nand show that it dramatically outperforms the state-of-the-art XCOMET metric by\n54% and 119% on the WMT'23 and WMT'24 test sets, respectively. We perform\nextensive analyses to understand the representations learned by our Specialist\nmetrics, and how variability in rater behavior affects their performance. We\nalso verify the generalizability and robustness of our Specialist method for\ndesigning automatic metrics across different numbers of ICL examples, LLM\nbackbones, systems to evaluate, and evaluation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2411.15387v2",
    "published": "2024-11-23T00:02:21+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2411.15386v1",
    "title": "Inducing Human-like Biases in Moral Reasoning Language Models",
    "authors": [
      "Artem Karpov",
      "Seong Hah Cho",
      "Austin Meek",
      "Raymond Koopmanschap",
      "Lucy Farnik",
      "Bogdan-Ionut Cirstea"
    ],
    "abstract": "In this work, we study the alignment (BrainScore) of large language models\n(LLMs) fine-tuned for moral reasoning on behavioral data and/or brain data of\nhumans performing the same task. We also explore if fine-tuning several LLMs on\nthe fMRI data of humans performing moral reasoning can improve the BrainScore.\nWe fine-tune several LLMs (BERT, RoBERTa, DeBERTa) on moral reasoning\nbehavioral data from the ETHICS benchmark [Hendrycks et al., 2020], on the\nmoral reasoning fMRI data from Koster-Hale et al. [2013], or on both. We study\nboth the accuracy on the ETHICS benchmark and the BrainScores between model\nactivations and fMRI data. While larger models generally performed better on\nboth metrics, BrainScores did not significantly improve after fine-tuning.",
    "pdf_url": "http://arxiv.org/pdf/2411.15386v1",
    "published": "2024-11-23T00:01:07+00:00",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2411.15385v1",
    "title": "Gradient dynamics for low-rank fine-tuning beyond kernels",
    "authors": [
      "Arif Kerem Dayi",
      "Sitan Chen"
    ],
    "abstract": "LoRA has emerged as one of the de facto methods for fine-tuning foundation\nmodels with low computational cost and memory footprint. The idea is to only\ntrain a low-rank perturbation to the weights of a pre-trained model, given\nsupervised data for a downstream task. Despite its empirical sucess, from a\nmathematical perspective it remains poorly understood what learning mechanisms\nensure that gradient descent converges to useful low-rank perturbations.\n  In this work we study low-rank fine-tuning in a student-teacher setting. We\nare given the weights of a two-layer base model $f$, as well as i.i.d. samples\n$(x,f^*(x))$ where $x$ is Gaussian and $f^*$ is the teacher model given by\nperturbing the weights of $f$ by a rank-1 matrix. This generalizes the setting\nof generalized linear model (GLM) regression where the weights of $f$ are zero.\n  When the rank-1 perturbation is comparable in norm to the weight matrix of\n$f$, the training dynamics are nonlinear. Nevertheless, in this regime we prove\nunder mild assumptions that a student model which is initialized at the base\nmodel and trained with online gradient descent will converge to the teacher in\n$dk^{O(1)}$ iterations, where $k$ is the number of neurons in $f$. Importantly,\nunlike in the GLM setting, the complexity does not depend on fine-grained\nproperties of the activation's Hermite expansion. We also prove that in our\nsetting, learning the teacher model \"from scratch'' can require significantly\nmore iterations.",
    "pdf_url": "http://arxiv.org/pdf/2411.15385v1",
    "published": "2024-11-23T00:00:28+00:00",
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG"
  }
]