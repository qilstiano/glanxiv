[
  {
    "id": "http://arxiv.org/abs/2412.12215v1",
    "title": "Imagined Speech State Classification for Robust Brain-Computer Interface",
    "authors": [
      "Byung-Kwan Ko",
      "Jun-Young Kim",
      "Seo-Hyun Lee"
    ],
    "abstract": "This study examines the effectiveness of traditional machine learning\nclassifiers versus deep learning models for detecting the imagined speech using\nelectroencephalogram data. Specifically, we evaluated conventional machine\nlearning techniques such as CSP-SVM and LDA-SVM classifiers alongside deep\nlearning architectures such as EEGNet, ShallowConvNet, and DeepConvNet. Machine\nlearning classifiers exhibited significantly lower precision and recall,\nindicating limited feature extraction capabilities and poor generalization\nbetween imagined speech and idle states. In contrast, deep learning models,\nparticularly EEGNet, achieved the highest accuracy of 0.7080 and an F1 score of\n0.6718, demonstrating their enhanced ability in automatic feature extraction\nand representation learning, essential for capturing complex neurophysiological\npatterns. These findings highlight the limitations of conventional machine\nlearning approaches in brain-computer interface (BCI) applications and advocate\nfor adopting deep learning methodologies to achieve more precise and reliable\nclassification of detecting imagined speech. This foundational research\ncontributes to the development of imagined speech-based BCI systems.",
    "pdf_url": "http://arxiv.org/pdf/2412.12215v1",
    "published": "2024-12-15T23:59:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11343v3",
    "title": "Temporal Logic Control for Nonlinear Stochastic Systems Under Unknown Disturbances",
    "authors": [
      "Ibon Gracia",
      "Luca Laurenti",
      "Manuel Mazo Jr.",
      "Alessandro Abate",
      "Morteza Lahijanian"
    ],
    "abstract": "In this paper, we present a novel framework to synthesize robust strategies\nfor discrete-time nonlinear systems with random disturbances that are unknown,\nagainst temporal logic specifications. The proposed framework is data-driven\nand abstraction-based: leveraging observations of the system, our approach\nlearns a high-confidence abstraction of the system in the form of an uncertain\nMarkov decision process (UMDP). The uncertainty in the resulting UMDP is used\nto formally account for both the error in abstracting the system and for the\nuncertainty coming from the data. Critically, we show that for any given\nstate-action pair in the resulting UMDP, the uncertainty in the transition\nprobabilities can be represented as a convex polytope obtained by a two-layer\nstate discretization and concentration inequalities. This allows us to obtain\ntighter uncertainty estimates compared to existing approaches, and guarantees\nefficiency, as we tailor a synthesis algorithm exploiting the structure of this\nUMDP. We empirically validate our approach on several case studies, showing\nsubstantially improved performance compared to the state-of-the-art.",
    "pdf_url": "http://arxiv.org/pdf/2412.11343v3",
    "published": "2024-12-15T23:55:55+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2412.11342v1",
    "title": "One-Shot Multilingual Font Generation Via ViT",
    "authors": [
      "Zhiheng Wang",
      "Jiarui Liu"
    ],
    "abstract": "Font design poses unique challenges for logographic languages like Chinese,\nJapanese, and Korean (CJK), where thousands of unique characters must be\nindividually crafted. This paper introduces a novel Vision Transformer\n(ViT)-based model for multi-language font generation, effectively addressing\nthe complexities of both logographic and alphabetic scripts. By leveraging ViT\nand pretraining with a strong visual pretext task (Masked Autoencoding, MAE),\nour model eliminates the need for complex design components in prior frameworks\nwhile achieving comprehensive results with enhanced generalizability.\nRemarkably, it can generate high-quality fonts across multiple languages for\nunseen, unknown, and even user-crafted characters. Additionally, we integrate a\nRetrieval-Augmented Guidance (RAG) module to dynamically retrieve and adapt\nstyle references, improving scalability and real-world applicability. We\nevaluated our approach in various font generation tasks, demonstrating its\neffectiveness, adaptability, and scalability.",
    "pdf_url": "http://arxiv.org/pdf/2412.11342v1",
    "published": "2024-12-15T23:52:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11341v1",
    "title": "Coupling-based Convergence Diagnostic and Stepsize Scheme for Stochastic Gradient Descent",
    "authors": [
      "Xiang Li",
      "Qiaomin Xie"
    ],
    "abstract": "The convergence behavior of Stochastic Gradient Descent (SGD) crucially\ndepends on the stepsize configuration. When using a constant stepsize, the SGD\niterates form a Markov chain, enjoying fast convergence during the initial\ntransient phase. However, when reaching stationarity, the iterates oscillate\naround the optimum without making further progress. In this paper, we study the\nconvergence diagnostics for SGD with constant stepsize, aiming to develop an\neffective dynamic stepsize scheme. We propose a novel coupling-based\nconvergence diagnostic procedure, which monitors the distance of two coupled\nSGD iterates for stationarity detection. Our diagnostic statistic is simple and\nis shown to track the transition from transience stationarity theoretically. We\nconduct extensive numerical experiments and compare our method against various\nexisting approaches. Our proposed coupling-based stepsize scheme is observed to\nachieve superior performance across a diverse set of convex and non-convex\nproblems. Moreover, our results demonstrate the robustness of our approach to a\nwide range of hyperparameters.",
    "pdf_url": "http://arxiv.org/pdf/2412.11341v1",
    "published": "2024-12-15T23:50:23+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11340v3",
    "title": "Fast Bayesian Functional Principal Components Analysis",
    "authors": [
      "Joseph Sartini",
      "Xinkai Zhou",
      "Liz Selvin",
      "Scott Zeger",
      "Ciprian Crainiceanu"
    ],
    "abstract": "Functional Principal Components Analysis (FPCA) is a widely used analytic\ntool for dimension reduction of functional data. Traditional implementations of\nFPCA estimate the principal components from the data, then treat these\nestimates as fixed in subsequent analyses. To account for the uncertainty of PC\nestimates, we propose FAST, a fully-Bayesian FPCA with three core components:\n(1) projection of eigenfunctions onto an orthonormal spline basis; (2)\nefficient sampling of the orthonormal spline coefficient matrix using polar\ndecomposition; and (3) ordering eigenvalues during sampling. Extensive\nsimulation studies show that FAST is very stable and performs better compared\nto existing methods. FAST is motivated by and applied to a study of the\nvariability in mealtime glucose from the Dietary Approaches to Stop\nHypertension for Diabetes Continuous Glucose Monitoring (DASH4D CGM) study. All\nrelevant STAN code and simulation routines are available as supplementary\nmaterial.",
    "pdf_url": "http://arxiv.org/pdf/2412.11340v3",
    "published": "2024-12-15T23:38:06+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2412.11339v1",
    "title": "Jordan-Wigner transformation constructed for spinful fermions at spin-1/2 in two dimensions",
    "authors": [
      "Zsolt Gulacsi"
    ],
    "abstract": "Recently a Jordan-Wigner transformation was constructed for spinful fermions\nat S=1/2 spins in one dimension connecting the spin-1/2 operators to genuine\nspinful canonical Fermi operators. In the presented paper this exact\ntransformation is generalized to two dimensions.",
    "pdf_url": "http://arxiv.org/pdf/2412.11339v1",
    "published": "2024-12-15T23:24:21+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2412.11338v2",
    "title": "A theoretical investigation provides an integrated understanding of the complex regulatory network controlling Arabidopsis root hair patterning",
    "authors": [
      "Hayley Mills",
      "George Janes",
      "Anthony Bishopp",
      "Natasha Savage"
    ],
    "abstract": "A complex regulatory network controlling Arabidopsis root hair patterning has\nbeen defined using data collected over decades. The network, embedded in the\nroot epidermis, contains positive and negative feedback loops, cell-cell\nsignalling within the epidermal tissue, and receives positional signalling from\nunderlying tissue. While there are extensive data regarding individual\ncomponents and their interactions within the network, the sufficiency of the\nregulatory network to produce robust epidermal patterning is not clear, nor is\nit clear how individual components and interactions work together to ensure\ncorrect epidermal patterning. Mathematical modelling was used to address the\nquestions of sufficiency, and to gain an integrated understanding of collective\nbehaviour emerging from individual components and interactions within the\nregulatory network. Theoretical experiments were performed on a model of the\nroot hair patterning regulatory network. It was found that our current\nunderstanding of the epidermal patterning network was insufficient to reproduce\nexperimental data. The model was used to hypothesise the existence of an\nadditional negative feedback loop which, when added to the currently understood\nregulatory network, enabled the model to reproduce wild type and mutant root\nhair patterning. Results of theoretical experiments on the modified regulatory\nnetwork were used to; define an essential relationship between diffusive\nmovement of two cell-cell signalling proteins; show that directed movement\ndysregulation of another cell-cell signalling protein causes root hair\npatterning to appear as though it no longer receives positional cues; and show\nthat cooperativity or oligomerisation within the regulatory network's positive\nfeedback loop are essential. This work presents an integrated, exploration of\nthe regulatory network controlling epidermal root hair patterning in\nArabidopsis.",
    "pdf_url": "http://arxiv.org/pdf/2412.11338v2",
    "published": "2024-12-15T23:18:48+00:00",
    "categories": [
      "q-bio.MN"
    ],
    "primary_category": "q-bio.MN"
  },
  {
    "id": "http://arxiv.org/abs/2412.12214v1",
    "title": "DLSOM: A Deep learning-based strategy for liver cancer subtyping",
    "authors": [
      "Fabio Zamio"
    ],
    "abstract": "Liver cancer is a leading cause of cancer-related mortality worldwide, with\nits high genetic heterogeneity complicating diagnosis and treatment. This study\nintroduces DLSOM, a deep learning framework utilizing stacked autoencoders to\nanalyze the complete somatic mutation landscape of 1,139 liver cancer samples,\ncovering 20,356 protein-coding genes. By transforming high-dimensional mutation\ndata into three low-dimensional features, DLSOM enables robust clustering and\nidentifies five distinct liver cancer subtypes with unique mutational,\nfunctional, and biological profiles. Subtypes SC1 and SC2 exhibit higher\nmutational loads, while SC3 has the lowest, reflecting mutational\nheterogeneity. Novel and COSMIC-associated mutational signatures reveal\nsubtype-specific molecular mechanisms, including links to hypermutation and\nchemotherapy resistance. Functional analyses further highlight the biological\nrelevance of each subtype. This comprehensive framework advances precision\nmedicine in liver cancer by enabling the development of subtype-specific\ndiagnostics, biomarkers, and therapies, showcasing the potential of deep\nlearning in addressing cancer complexity.",
    "pdf_url": "http://arxiv.org/pdf/2412.12214v1",
    "published": "2024-12-15T23:13:29+00:00",
    "categories": [
      "q-bio.GN",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2412.11337v1",
    "title": "Modality-Driven Design for Multi-Step Dexterous Manipulation: Insights from Neuroscience",
    "authors": [
      "Naoki Wake",
      "Atsushi Kanehira",
      "Daichi Saito",
      "Jun Takamatsu",
      "Kazuhiro Sasabuchi",
      "Hideki Koike",
      "Katsushi Ikeuchi"
    ],
    "abstract": "Multi-step dexterous manipulation is a fundamental skill in household\nscenarios, yet remains an underexplored area in robotics. This paper proposes a\nmodular approach, where each step of the manipulation process is addressed with\ndedicated policies based on effective modality input, rather than relying on a\nsingle end-to-end model. To demonstrate this, a dexterous robotic hand performs\na manipulation task involving picking up and rotating a box. Guided by insights\nfrom neuroscience, the task is decomposed into three sub-skills, 1)reaching,\n2)grasping and lifting, and 3)in-hand rotation, based on the dominant sensory\nmodalities employed in the human brain. Each sub-skill is addressed using\ndistinct methods from a practical perspective: a classical controller, a\nVision-Language-Action model, and a reinforcement learning policy with force\nfeedback, respectively. We tested the pipeline on a real robot to demonstrate\nthe feasibility of our approach. The key contribution of this study lies in\npresenting a neuroscience-inspired, modality-driven methodology for multi-step\ndexterous manipulation.",
    "pdf_url": "http://arxiv.org/pdf/2412.11337v1",
    "published": "2024-12-15T23:05:16+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11336v3",
    "title": "Hierarchical cell identities emerge from animal gene regulatory mechanisms",
    "authors": [
      "Anton Grishechkin",
      "Abhirup Mukherjee",
      "Omer Karin"
    ],
    "abstract": "The hierarchical organisation of cell identity is a fundamental feature of\nanimal development with rich and well-characterized experimental phenomenology,\nyet the mechanisms driving its emergence remain unknown. The regulation of cell\nidentity genes relies on a distinct mechanism involving higher-order\ninteractions of transcription factors on distant regulatory regions called\nenhancers. These interactions are mediated by epigenetic regulators that are\nbroadly shared between enhancers. Through the development of a new and\npredictive mathematical theory on the effects of epigenetic regulator activity\non gene network dynamics, we demonstrate that hierarchical identities are\nessential emergent properties of animal-specific gene regulatory mechanisms.\nHierarchical identities arise from the interplay between enhancer competition\nfor epigenetic readers and cooperation through activation of shared\ntranscriptional programs. We show that epigenetic regulatory mechanisms provide\nthe network with self-similar properties that enable multilineage priming and\nsignal-dependent control of progenitor states. The stabilisation of progenitor\nstates is predicted to be controlled by the balance in activities between\nepigenetic writers and erasers. Our model quantitatively predicts lineage\nrelationships, reconstructs all known blood progenitor states from terminal\nstates, and explains mechanisms of cell identity dysregulation in cancer and\nthe general differentiation effects of histone deacetylase inhibition. We\nidentify non-specific modulation of enhancer competition as a central\nregulatory axis, with implications for developmental biology, cancer, and\ndifferentiation therapy.",
    "pdf_url": "http://arxiv.org/pdf/2412.11336v3",
    "published": "2024-12-15T23:04:07+00:00",
    "categories": [
      "q-bio.CB",
      "q-bio.MN"
    ],
    "primary_category": "q-bio.CB"
  },
  {
    "id": "http://arxiv.org/abs/2412.11335v1",
    "title": "Generative AI regulation can learn from social media regulation",
    "authors": [
      "Ruth Elisabeth Appel"
    ],
    "abstract": "There is strong agreement that generative AI should be regulated, but strong\ndisagreement on how to approach regulation. While some argue that AI regulation\nshould mostly rely on extensions of existing laws, others argue that entirely\nnew laws and regulations are needed to ensure that generative AI benefits\nsociety. In this paper, I argue that the debates on generative AI regulation\ncan be informed by the debates and evidence on social media regulation. For\nexample, AI companies have faced allegations of political bias regarding the\nimages and text their models produce, similar to the allegations social media\ncompanies have faced regarding content ranking on their platforms. First, I\ncompare and contrast the affordances of generative AI and social media to\nhighlight their similarities and differences. Then, I discuss specific policy\nrecommendations based on the evolution of social media and their regulation.\nThese recommendations include investments in: efforts to counter bias and\nperceptions thereof (e.g., via transparency, researcher access, oversight\nboards, democratic input, research studies), specific areas of regulatory\nconcern (e.g., youth wellbeing, election integrity) and trust and safety,\ncomputational social science research, and a more global perspective. Applying\nlessons learnt from social media regulation to generative AI regulation can\nsave effort and time, and prevent avoidable mistakes.",
    "pdf_url": "http://arxiv.org/pdf/2412.11335v1",
    "published": "2024-12-15T23:00:29+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2412.11334v1",
    "title": "Optomechanically and Themo-optically driven Interactions between Gilded Vaterite Nanoparticles in Bubbles",
    "authors": [
      "Hod Gilad",
      "Andrey Ushkov",
      "Denis Kolchanov",
      "Andrey Machnev",
      "Toms Salgals",
      "Vjačeslavs Bobrovs",
      "Hani Barhum",
      "Pavel Ginzburg"
    ],
    "abstract": "The capability to tailor mutual interactions between colloidal nanoparticles\nstrongly depends on the length scales involved. While electrostatic and\noptomechanically driven interactions can cover nano and micron-scale\nlandscapes, controlling inter-particle dynamics at larger distances remains a\nchallenge. Small physical and electromagnetic cross-sections of nanoparticles\nmake long-range interactions, screened by a fluid environment, inefficient. To\nbypass the limitations, we demonstrate that forming micron-scale bubbles around\ngilded vaterite nanoparticles enables mediating long-range interactions via\nthermo-optical forces. Femtosecond laser illumination leads to the\nencapsulation of light-absorbing particles inside long-lasting micron-scale\nbubbles, which in turn behave as negative lenses refracting incident light. Our\nexperiments reveal the bubble-induced collimation of laser beams, traversing\nover mm-scale distances. The collimated beams are visualized with the aid of\nphase-contrast Schlieren imaging, which reveals refractive index variations,\ncaused by temperature gradients within the fluid. We demonstrate that the\nrefracted beams initiate the formation of secondary bubbles around nearby\ngilded vaterite particles. As the consequence, we demonstrate the ability to\ncontrol secondary bubble motion by pushing and pulling it with optical\nradiation pressure force and by thermocapillary Marangoni effect, respectively.\nThe latter facilitates interactions over millimeter-scale distances, which are\notherwise unachievable. Apart from exploring new physical effects, mediating\nlong-range interactions can find a use in a range of applications including\ndrug design and screening, photochemistry, design of colloidal suspensions, and\nmany others.",
    "pdf_url": "http://arxiv.org/pdf/2412.11334v1",
    "published": "2024-12-15T22:56:10+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2412.11333v2",
    "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models",
    "authors": [
      "Xiaochen Zhu",
      "Georgi Karadzhov",
      "Chenxi Whitehouse",
      "Andreas Vlachos"
    ],
    "abstract": "Diffusion models have shown promise in text generation, but often struggle\nwith generating long, coherent, and contextually accurate text. Token-level\ndiffusion doesn't model word-order dependencies explicitly and operates on\nshort, fixed output windows, while passage-level diffusion struggles with\nlearning robust representations for long-form text. To address these\nchallenges, we propose Segment-Level Diffusion (SLD), a framework that enhances\ndiffusion-based text generation through text segmentation, robust\nrepresentation training with adversarial and contrastive learning, and improved\nlatent-space guidance. By segmenting long-form outputs into multiple latent\nrepresentations and decoding them with an autoregressive decoder, SLD\nsimplifies diffusion predictions and improves scalability. Experiments on four\ndatasets demonstrate that, when compared to other diffusion and autoregressive\nbaselines SLD achieves competitive or superior fluency, coherence, and\ncontextual compatibility in automatic and human evaluations.",
    "pdf_url": "http://arxiv.org/pdf/2412.11333v2",
    "published": "2024-12-15T22:47:44+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11332v1",
    "title": "$p$-adic properties of Eisenstein-Kronecker cocycles over imaginary quadratic fields and $p$-adic interpolation",
    "authors": [
      "Jorge Flórez"
    ],
    "abstract": "We establish integrality and congruence properties for the\nEisenstein-Kronecker cocycle of Bergeron, Charollois and Garc\\'ia introduced in\n[arXiv:2107.01992v2 [math.NT]]. As a consequence, we recover the integrality of\nthe critical values of Hecke $L$-functions over imaginary quadratic fields in\nthe split case. Additionally, we construct a $p$-adic measure that interpolates\nthese critical values.",
    "pdf_url": "http://arxiv.org/pdf/2412.11332v1",
    "published": "2024-12-15T22:41:09+00:00",
    "categories": [
      "math.NT",
      "11F67 (primary), 11F20, 11R42 (secondary)"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2412.12213v1",
    "title": "The AI Black-Scholes: Finance-Informed Neural Network",
    "authors": [
      "Amine M. Aboussalah",
      "Xuanze Li",
      "Cheng Chi",
      "Raj Patel"
    ],
    "abstract": "In the realm of option pricing, existing models are typically classified into\nprinciple-driven methods, such as solving partial differential equations (PDEs)\nthat pricing function satisfies, and data-driven approaches, such as machine\nlearning (ML) techniques that parameterize the pricing function directly. While\nprinciple-driven models offer a rigorous theoretical framework, they often rely\non unrealistic assumptions, such as asset processes adhering to fixed\nstochastic differential equations (SDEs). Moreover, they can become\ncomputationally intensive, particularly in high-dimensional settings when\nanalytical solutions are not available and thus numerical solutions are needed.\nIn contrast, data-driven models excel in capturing market data trends, but they\noften lack alignment with core financial principles, raising concerns about\ninterpretability and predictive accuracy, especially when dealing with limited\nor biased datasets. This work proposes a hybrid approach to address these\nlimitations by integrating the strengths of both principled and data-driven\nmethodologies. Our framework combines the theoretical rigor and\ninterpretability of PDE-based models with the adaptability of machine learning\ntechniques, yielding a more versatile methodology for pricing a broad spectrum\nof options. We validate our approach across different volatility modeling\napproaches-both with constant volatility (Black-Scholes) and stochastic\nvolatility (Heston), demonstrating that our proposed framework,\nFinance-Informed Neural Network (FINN), not only enhances predictive accuracy\nbut also maintains adherence to core financial principles. FINN presents a\npromising tool for practitioners, offering robust performance across a variety\nof market conditions.",
    "pdf_url": "http://arxiv.org/pdf/2412.12213v1",
    "published": "2024-12-15T22:40:40+00:00",
    "categories": [
      "cs.LG",
      "q-fin.CP",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11331v1",
    "title": "On the borderline of fields and hyperfields, part II -- Enumeration and classification of the hyperfields of order 7",
    "authors": [
      "Christos G. Massouros",
      "Gerasimos G. Massouros"
    ],
    "abstract": "The quotient hyperfield is a landmark on the borderline of fields and\nhyperfields. In this paper, which is the second part of our previously\npublished paper, all the hyperfields of order 7 are constructed, enumerated and\npresented, in the course of which an important family of 7-element canonical\nhypergroups is revealed. The study of these hyperfields proved the existence of\nboth quotient and non-quotient ones among them. Their construction became\nfeasible because it is based on a new definition of the hyperfield with fewer\naxioms, which is introduced in this paper following our proof that the axiom of\nreversibility can derive from the other axioms of the hyperfield. Hence, the\nprocessing power needed for a computer to test whether a structure is a\nhyperfield or not is much less. This paper also proves properties and contains\nexamples of skew hyperfields, strongly canonical hyperfields/hyperrings and\nsuperiorly canonical hyperfields/hyperrings that wrap up and complete the\npreviously published conclusions and results of its first part.",
    "pdf_url": "http://arxiv.org/pdf/2412.11331v1",
    "published": "2024-12-15T22:21:11+00:00",
    "categories": [
      "math.RA",
      "16Y20, 12K99, 12E20, 20N20"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11330v4",
    "title": "Exact Verification of First-Order Methods via Mixed-Integer Linear Programming",
    "authors": [
      "Vinit Ranjan",
      "Jisun Park",
      "Stefano Gualandi",
      "Andrea Lodi",
      "Bartolomeo Stellato"
    ],
    "abstract": "We present exact mixed-integer linear programming formulations for verifying\nthe performance of first-order methods for parametric quadratic optimization.\nWe formulate the verification problem as a mixed-integer linear program where\nthe objective is to maximize the infinity norm of the fixed-point residual\nafter a given number of iterations. Our approach captures a wide range of\ngradient, projection, proximal iterations through affine or piecewise affine\nconstraints. We derive tight polyhedral convex hull formulations of the\nconstraints representing the algorithm iterations. To improve the scalability,\nwe develop a custom bound tightening technique combining interval propagation,\noperator theory, and optimization-based bound tightening. Numerical examples,\nincluding linear and quadratic programs from network optimization, sparse\ncoding using Lasso, and optimal control, show that our method provides several\norders of magnitude reductions in the worst-case fixed-point residuals, closely\nmatching the true worst-case performance.",
    "pdf_url": "http://arxiv.org/pdf/2412.11330v4",
    "published": "2024-12-15T22:20:22+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2412.19821v1",
    "title": "Nanoscaling Floating-Point (NxFP): NanoMantissa, Adaptive Microexponents, and Code Recycling for Direct-Cast Compression of Large Language Models",
    "authors": [
      "Yun-Chen Lo",
      "Gu-Yeon Wei",
      "David Brooks"
    ],
    "abstract": "As cutting-edge large language models (LLMs) continue to transform various\nindustries, their fast-growing model size and sequence length have led to\nmemory traffic and capacity challenges. Recently, AMD, Arm, Intel, Meta,\nMicrosoft, NVIDIA, and Qualcomm have proposed a Microscaling standard (Mx),\nwhich augments block floating-point with microexponents to achieve promising\nperplexity-to-footprint trade-offs. However, the Microscaling suffers from\nsignificant perplexity degradation on modern LLMs with less than six bits. This\npaper profiles modern LLMs and identifies three main challenges of low-bit\nMicroscaling format, i.e., inaccurate tracking of outliers, vacant quantization\nlevels, and wasted binary code. In response, Nanoscaling (NxFP) proposes three\ntechniques, i.e., NanoMantissa, Adaptive Microexponent, and Code Recycling to\nenable better accuracy and smaller memory footprint than state-of-the-art MxFP.\nExperimental results on direct-cast inference across various modern LLMs\ndemonstrate that our proposed methods outperform state-of-the-art MxFP by up to\n0.64 in perplexity and by up to 30% in accuracy on MMLU benchmarks.\nFurthermore, NxFP reduces memory footprint by up to 16% while achieving\ncomparable perplexity as MxFP.",
    "pdf_url": "http://arxiv.org/pdf/2412.19821v1",
    "published": "2024-12-15T22:18:20+00:00",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "I.2.7; E.4"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11329v1",
    "title": "Jitter Across 15 Years: Leveraging Precise Photometry from Kepler and TESS to Extract Exoplanets from Radial Velocity Time Series",
    "authors": [
      "Corey Beard",
      "Paul Robertson",
      "Jack Lubin",
      "Te Han",
      "Rae Holcomb",
      "Pranav Premnath",
      "R. Paul Butler",
      "Paul A. Dalba",
      "Brad Holden",
      "Cullen H. Blake",
      "Scott A. Diddams",
      "Arvind F. Gupta",
      "Samuel Halverson",
      "Daniel M. Krolikowski",
      "Dan Li",
      "Andrea S. J. Lin",
      "Sarah E. Logsdon",
      "Emily Lubar",
      "Suvrath Mahadevan",
      "Michael W. McElwain",
      "Joe P. Ninan",
      "Leonardo A. Paredes",
      "Arpita Roy",
      "Christian Schwab",
      "Gudmundur Stefansson",
      "Ryan C. Terrien",
      "Jason T. Wright"
    ],
    "abstract": "Stellar activity contamination of radial velocity (RV) data is one of the top\nchallenges plaguing the field of extreme precision RV (EPRV) science. Previous\nwork has shown that photometry can be very effective at removing such signals\nfrom RV data, especially stellar activity caused by rotating star spots and\nplage.The exact utility of photometry for removing RV activity contamination,\nand the best way to apply it, is not well known. We present a combination\nphotometric and RV study of eight Kepler/K2 FGK stars with known stellar\nvariability. We use NEID RVs acquired simultaneously with TESS photometry, and\nwe perform injection recovery tests to quantify the efficacy of recent TESS\nphotometry versus archival Kepler/K2 photometry for removing stellar\nvariability from RVs. We additionally experiment with different TESS sectors\nwhen training our models in order to quantify the real benefit of\nsimultaneously acquired RVs and photometry. We conclude that Kepler photometry\ntypically performs better than TESS at removing noise from RV data when it is\navailable, likely due to longer baseline and precision. In contrast, for\ntargets with available K2 photometry, especially those most active, and with\nhigh precision ($\\sigma_{NEID}$ $<$ 1 m s$^{-1}$) NEID RVs, TESS may be the\nmore informative dataset. However, contrary to expectations, we have found that\ntraining on simultaneous photometry does not always achieve the best results.",
    "pdf_url": "http://arxiv.org/pdf/2412.11329v1",
    "published": "2024-12-15T22:17:33+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11328v1",
    "title": "Zero-Shot Prompting Approaches for LLM-based Graphical User Interface Generation",
    "authors": [
      "Kristian Kolthoff",
      "Felix Kretzer",
      "Lennart Fiebig",
      "Christian Bartelt",
      "Alexander Maedche",
      "Simone Paolo Ponzetto"
    ],
    "abstract": "Graphical user interface (GUI) prototyping represents an essential activity\nin the development of interactive systems, which are omnipresent today. GUI\nprototypes facilitate elicitation of requirements and help to test, evaluate,\nand validate ideas with users and the development team. However, creating GUI\nprototypes is a time-consuming process and often requires extensive resources.\nWhile existing research for automatic GUI generation focused largely on\nresource-intensive training and fine-tuning of LLMs, mainly for low-fidelity\nGUIs, we investigate the potential and effectiveness of Zero-Shot (ZS)\nprompting for high-fidelity GUI generation. We propose a Retrieval-Augmented\nGUI Generation (RAGG) approach, integrated with an LLM-based GUI retrieval\nre-ranking and filtering mechanism based on a large-scale GUI repository. In\naddition, we adapt Prompt Decomposition (PDGG) and Self-Critique (SCGG) for GUI\ngeneration. To evaluate the effectiveness of the proposed ZS prompting\napproaches for GUI generation, we extensively evaluated the accuracy and\nsubjective satisfaction of the generated GUI prototypes. Our evaluation, which\nencompasses over 3,000 GUI annotations from over 100 crowd-workers with UI/UX\nexperience, shows that SCGG, in contrast to PDGG and RAGG, can lead to more\neffective GUI generation, and provides valuable insights into the defects that\nare produced by the LLMs in the generated GUI prototypes.",
    "pdf_url": "http://arxiv.org/pdf/2412.11328v1",
    "published": "2024-12-15T22:17:30+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11327v1",
    "title": "New BaBar studies of high-order radiation and the new landscape of data-driven HVP predictions of the muon g-2",
    "authors": [
      "Bogdan Malaescu"
    ],
    "abstract": "A measurement of additional radiation in $e^+e^- \\to \\mu^+\\mu^- \\gamma$ and\n$e^+e^- \\to \\pi^+\\pi^- \\gamma$ initial-state-radiation events is presented\nusing the full $BaBar$ data sample. For the first time results are presented at\nnext-to- and next-to-next-to-leading order, with one and two additional\nphotons, respectively, for radiation from the initial and final states. The\ncomparison with the predictions from Phokhara and AfkQed generators reveals\ndiscrepancies for the former in the one-photon rates and angular distributions.\nWhile this disagreement has a negligible effect on the $e^+e^- \\to \\pi^+\\pi^-\n(\\gamma)$ cross section measured by $BaBar$, the impact on the KLOE and BESIII\nmeasurements is estimated and found to be indicative of significant systematic\neffects. The findings shed a new light on the longstanding deviation among the\nmuon $g-2$ measurement, the Standard Model prediction using the data-driven\ndispersive approach for calculation of the hadronic vacuum polarization (HVP),\nand the comparison with lattice QCD calculations.",
    "pdf_url": "http://arxiv.org/pdf/2412.11327v1",
    "published": "2024-12-15T22:13:42+00:00",
    "categories": [
      "hep-ex",
      "hep-ph"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2412.12212v1",
    "title": "Finding a Wolf in Sheep's Clothing: Combating Adversarial Text-To-Image Prompts with Text Summarization",
    "authors": [
      "Portia Cooper",
      "Harshita Narnoli",
      "Mihai Surdeanu"
    ],
    "abstract": "Text-to-image models are vulnerable to the stepwise \"Divide-and-Conquer\nAttack\" (DACA) that utilize a large language model to obfuscate inappropriate\ncontent in prompts by wrapping sensitive text in a benign narrative. To\nmitigate stepwise DACA attacks, we propose a two-layer method involving text\nsummarization followed by binary classification. We assembled the Adversarial\nText-to-Image Prompt (ATTIP) dataset ($N=940$), which contained DACA-obfuscated\nand non-obfuscated prompts. From the ATTIP dataset, we created two summarized\nversions: one generated by a small encoder model and the other by a large\nlanguage model. Then, we used an encoder classifier and a GPT-4o classifier to\nperform content moderation on the summarized and unsummarized prompts. When\ncompared with a classifier that operated over the unsummarized data, our method\nimproved F1 score performance by 31%. Further, the highest recorded F1 score\nachieved (98%) was produced by the encoder classifier on a summarized ATTIP\nvariant. This study indicates that pre-classification text summarization can\ninoculate content detection models against stepwise DACA obfuscations.",
    "pdf_url": "http://arxiv.org/pdf/2412.12212v1",
    "published": "2024-12-15T22:12:36+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11326v1",
    "title": "Spatial Cross-Recurrence Quantification Analysis for Multi-Platform Contact Tracing and Epidemiology Research",
    "authors": [
      "K. J. Patten"
    ],
    "abstract": "Contact tracing is an essential tool in slowing and containing outbreaks of\ncontagious diseases. Current contact tracing methods range from interviews with\npublic health personnel to Bluetooth pings from smartphones. While all methods\noffer various benefits, it is difficult for different methods to integrate with\none another. Additionally, for contact tracing mobile applications, data\nprivacy is a concern to many as GPS data from users is saved to either a\ncentral server or the user's device. The current paper describes a method\ncalled spatial cross-recurrence quantification analysis (SpaRQ) that can\ncombine and analyze contact tracing data, regardless of how it has been\nobtained, and generate a risk profile for the user without storing GPS data.\nFurthermore, the plots from SpaRQ can be used to investigate the nature of the\ninfectious agent, such as how long it can remain viable in air or on surfaces\nafter an infected person has passed, the chance of infection based on exposure\ntime, and what type of exposure is maximally infective.",
    "pdf_url": "http://arxiv.org/pdf/2412.11326v1",
    "published": "2024-12-15T22:07:32+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2412.11325v1",
    "title": "Sonicmesh: Enhancing 3D Human Mesh Reconstruction in Vision-Impaired Environments With Acoustic Signals",
    "authors": [
      "Xiaoxuan Liang",
      "Wuyang Zhang",
      "Hong Zhou",
      "Zhaolong Wei",
      "Sicheng Zhu",
      "Yansong Li",
      "Rui Yin",
      "Jiantao Yuan",
      "Jeremy Gummeson"
    ],
    "abstract": "3D Human Mesh Reconstruction (HMR) from 2D RGB images faces challenges in\nenvironments with poor lighting, privacy concerns, or occlusions. These\nweaknesses of RGB imaging can be complemented by acoustic signals, which are\nwidely available, easy to deploy, and capable of penetrating obstacles.\nHowever, no existing methods effectively combine acoustic signals with RGB data\nfor robust 3D HMR. The primary challenges include the low-resolution images\ngenerated by acoustic signals and the lack of dedicated processing backbones.\nWe introduce SonicMesh, a novel approach combining acoustic signals with RGB\nimages to reconstruct 3D human mesh. To address the challenges of low\nresolution and the absence of dedicated processing backbones in images\ngenerated by acoustic signals, we modify an existing method, HRNet, for\neffective feature extraction. We also integrate a universal feature embedding\ntechnique to enhance the precision of cross-dimensional feature alignment,\nenabling SonicMesh to achieve high accuracy. Experimental results demonstrate\nthat SonicMesh accurately reconstructs 3D human mesh in challenging\nenvironments such as occlusions, non-line-of-sight scenarios, and poor\nlighting.",
    "pdf_url": "http://arxiv.org/pdf/2412.11325v1",
    "published": "2024-12-15T22:04:26+00:00",
    "categories": [
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11324v2",
    "title": "Drinfeld modular polynomials of level $T$",
    "authors": [
      "Florian Breuer",
      "Mahefason Heriniaina Razafinjatovo"
    ],
    "abstract": "We investigate Drinfeld modular polynomials parametrizing $T$-isogenies\nbetween Drinfeld $\\mathbb{F}_q[T]$-modules of rank $r\\geq 2$. By providing an\nexplicit classification of such isogenies, we derive explicit bounds on the\n$T$-degrees of the coefficients of the associated modular polynomials. In\nparticular, we obtain exact expressions for the height (i.e. degree of the\nlargest coefficient) of these modular polynomials. Numerical computations show\nthat the bounds on the smaller coefficients are often sharp, too.",
    "pdf_url": "http://arxiv.org/pdf/2412.11324v2",
    "published": "2024-12-15T22:03:24+00:00",
    "categories": [
      "math.NT",
      "11G09, 11F52"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11323v1",
    "title": "Small-time asymptotics for hypoelliptic diffusions",
    "authors": [
      "Juraj Földes",
      "David P. Herzog"
    ],
    "abstract": "An inductive procedure is developed to calculate the asymptotic behavior at\ntime zero of a diffusion with polynomial drift and degenerate, additive noise.\nThe procedure gives rise to two different rescalings of the process; namely, a\nfunctional law of the iterated logarithm rescaling and a distributional\nrescaling. The limiting behavior of these rescalings is studied, resulting in\ntwo related control problems which are solved in nontrivial examples using\nmethods from geometric control theory. The control information from these\nproblems gives rise to a practical criteria for points to be regular on the\nboundary of a domain in $\\mathbf{R}^n$ for such diffusions.",
    "pdf_url": "http://arxiv.org/pdf/2412.11323v1",
    "published": "2024-12-15T21:44:21+00:00",
    "categories": [
      "math.PR",
      "math.AP",
      "60H10, 35H10, 60F17, 60J50"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11322v2",
    "title": "Volume-surface systems with sub-quadratic intermediate sum on the surface: Global existence and boundedness",
    "authors": [
      "Juan Yang",
      "Bao Quoc Tang"
    ],
    "abstract": "The global existence and boundedness of solutions to volume-surface reaction\ndiffusion systems with a mass control condition are investigated. Such systems\narise typically in e.g. cell biology, ecology or fluid mechanics, when some\nconcentrations or densities are inside a domain and some others are on its\nboundary. Comparing to previous works, the difficulty of systems under\nconsideration here is that the nonlinearities on the surface can have a\nsub-quadratic growth rates in all dimensions. To overcome this, we first use\nthe Moser iteration to get some uniform bounds of the time integration of the\nsolutions. Then by combining these bounds with an $L^p$-energy method and a\nduality argument, we obtain the global existence of solutions. Moreover, under\nmass dissipation conditions, the solution is shown to be bounded uniformly in\ntime.",
    "pdf_url": "http://arxiv.org/pdf/2412.11322v2",
    "published": "2024-12-15T21:41:00+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11321v2",
    "title": "X-ray properties of coronal emission in radio quiet Active Galactic Nuclei",
    "authors": [
      "Sibasish Laha",
      "Claudio Ricci",
      "John C. Mather",
      "Ehud Behar",
      "Luigi C. Gallo",
      "Frederic Marin",
      "Rostom Mbarek",
      "Amelia Hankla"
    ],
    "abstract": "Active galactic nuclei (AGN) are powerful sources of panchromatic radiation.\nAll AGN emit in X-rays, contributing around $\\sim 5-10\\%$ of the AGN bolometric\nluminosity. The X-ray emitting region, popularly known as the corona, is\ngeometrically and radiatively compact with a size typically $\\lesssim 10 \\,\nR_{\\rm G}$ (gravitational radii). The rapid and extreme variability in X-rays\nalso suggest that the corona must be a dynamic structure. Decades of X-ray\nstudies have shed much light on the topic, but the nature and origin of AGN\ncorona are still not clearly understood. This is mostly due to the complexities\ninvolved in several physical processes at play in the high-gravity,\nhigh-density and high-temperature region in the vicinity of the supermassive\nblack hole (SMBH). It is still not clear how exactly the corona is\nenergetically and physically sustained near a SMBH. The ubiquity of coronal\nemission in AGN points to their fundamental role in black hole accretion\nprocesses. In this review we discuss the X-ray observational properties of\ncorona in radio quiet AGN.",
    "pdf_url": "http://arxiv.org/pdf/2412.11321v2",
    "published": "2024-12-15T21:39:03+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11320v1",
    "title": "First-Order Sweeping Processes and Extended Projected Dynamical Systems: Equivalence, Time-Discretization and Numerical Optimal Control",
    "authors": [
      "Anton Pozharskiy",
      "Armin Nurkanović",
      "Moritz Diehl"
    ],
    "abstract": "Constrained dynamical systems are systems such that, by some means, the state\nstays within a given set. Two such systems are the (perturbed) Moreau sweeping\nprocess and the recently proposed extended Projected Dynamical System (ePDS).\nWe show that under certain conditions solutions to the ePDS correspond to the\nsolutions of a dynamic complementarity system, similar to the one equivalent to\nordinary PDS. We then show that the perturbed sweeping process with time\nvarying set can, under similar conditions, be reformulated as an ePDS. In this\npaper, we leverage these equivalences to develop an accurate discretization\nmethod for perturbed first-order Moreau sweeping processes via the finite\nelements with switch detection method. This allows the efficient optimal\ncontrol of systems governed by ePDS and perturbed first-order sweeping\nprocesses.",
    "pdf_url": "http://arxiv.org/pdf/2412.11320v1",
    "published": "2024-12-15T21:34:27+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11319v2",
    "title": "Binary sequences meet the Fibonacci sequence",
    "authors": [
      "Piotr Miska",
      "Bartosz Sobolewski",
      "Maciej Ulas"
    ],
    "abstract": "We introduce a new family of meta-Fibonacci sequences\n$(f(n))_{n\\in\\mathbb{N}}$, governed by the recurrence relation\n$$f(n)=af(n-u_{n}-1)+bf(n-u_{n}-2),$$ where $\\mathbf{u}=(u_{n})_{n\\in\n\\mathbb{N}}$ is a sequence with values $0,1$. Our study focuses on the\nproperties of the sequence of quotients $h(n) = f(n+1)/f(n)$ and its set of\nvalues $\\mathcal{V}(f)=\\{h(n): n \\in \\mathbb{N}\\}$ for various $\\mathbf{u}$. We\ngive a sufficient condition for finiteness of $\\mathcal{V}(f)$ and automaticity\nof $(h(n))_{n \\in \\mathbb{N}}$, which holds in particular when $\\mathbf{u}$ is\nthe famous Prouhet-Thue-Morse sequence. In the automatic case, a constructive\napproach is used, with the help of the software \\texttt{Walnut}. On the other\nhand, we prove that the set $\\cal{V}(f)$ is infinite for other special binary\nsequences $\\mathbf{u}$, and obtain a trichotomy in its topological type when\n$\\mathbf{u}$ is eventually periodic.",
    "pdf_url": "http://arxiv.org/pdf/2412.11319v2",
    "published": "2024-12-15T21:30:24+00:00",
    "categories": [
      "math.NT",
      "11B37, 11B39, 11B83, 11B85"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11318v1",
    "title": "Generics are puzzling. Can language models find the missing piece?",
    "authors": [
      "Gustavo Cilleruelo Calderón",
      "Emily Allaway",
      "Barry Haddow",
      "Alexandra Birch"
    ],
    "abstract": "Generic sentences express generalisations about the world without explicit\nquantification. Although generics are central to everyday communication,\nbuilding a precise semantic framework has proven difficult, in part because\nspeakers use generics to generalise properties with widely different\nstatistical prevalence. In this work, we study the implicit quantification and\ncontext-sensitivity of generics by leveraging language models as models of\nlanguage. We create ConGen, a dataset of 2873 naturally occurring generic and\nquantified sentences in context, and define p-acceptability, a metric based on\nsurprisal that is sensitive to quantification. Our experiments show generics\nare more context-sensitive than determiner quantifiers and about 20% of\nnaturally occurring generics we analyze express weak generalisations. We also\nexplore how human biases in stereotypes can be observed in language models.",
    "pdf_url": "http://arxiv.org/pdf/2412.11318v1",
    "published": "2024-12-15T21:30:21+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11317v1",
    "title": "RoLargeSum: A Large Dialect-Aware Romanian News Dataset for Summary, Headline, and Keyword Generation",
    "authors": [
      "Andrei-Marius Avram",
      "Mircea Timpuriu",
      "Andreea Iuga",
      "Vlad-Cristian Matei",
      "Iulian-Marius Tăiatu",
      "Tudor Găină",
      "Dumitru-Clementin Cercel",
      "Florin Pop",
      "Mihaela-Claudia Cercel"
    ],
    "abstract": "Using supervised automatic summarisation methods requires sufficient corpora\nthat include pairs of documents and their summaries. Similarly to many tasks in\nnatural language processing, most of the datasets available for summarization\nare in English, posing challenges for developing summarization models in other\nlanguages. Thus, in this work, we introduce RoLargeSum, a novel large-scale\nsummarization dataset for the Romanian language crawled from various publicly\navailable news websites from Romania and the Republic of Moldova that were\nthoroughly cleaned to ensure a high-quality standard. RoLargeSum contains more\nthan 615K news articles, together with their summaries, as well as their\nheadlines, keywords, dialect, and other metadata that we found on the targeted\nwebsites. We further evaluated the performance of several BART variants and\nopen-source large language models on RoLargeSum for benchmarking purposes. We\nmanually evaluated the results of the best-performing system to gain insight\ninto the potential pitfalls of this data set and future development.",
    "pdf_url": "http://arxiv.org/pdf/2412.11317v1",
    "published": "2024-12-15T21:27:33+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11316v2",
    "title": "Torsion-free $H$-structures on almost Abelian solvmanifolds",
    "authors": [
      "Marco Freibert"
    ],
    "abstract": "In this article, we provide a general set-up for arbitrary linear Lie groups\n$H\\leq \\mathrm{GL}(n,\\mathbb{R})$ which allows to characterise the almost\nAbelian Lie algebras admitting a torsion-free $H$-structure. In more concrete\nterms, using that an $n$-dimensional almost Abelian Lie algebra\n$\\mathfrak{g}=\\mathfrak{g}_f$ is fully determined by an endomorphism $f$ of\n$\\mathbb{R}^{n-1}$, we give a description of the subspace\n$\\mathcal{F}_{\\mathfrak{h}}$ of all $f\\in\\mathrm{End}(\\mathbb{R}^{n-1})$ for\nwhich $\\mathfrak{g}_f$ admits a ``special'' torsion-free $H$-structure in terms\nof the image of a certain linear map. For large classes of linear Lie groups\n$H$, we are able to explicitly compute $\\mathcal{F}_{\\mathfrak{h}}$ and so give\ncharacterisations of the almost Abelian Lie algebras admitting a torsion-free\n$H$-structure.\n  Our results reprove all the known characterisations of the almost Abelian Lie\nalgebras admitting a torsion-free $H$-structure for different single linear Lie\ngroups $H$ and extends them to big classes of linear Lie groups $H$. For\nexample, we are able to provide characterisations in the case $n=2m$, $H\\leq\n\\mathrm{GL}(m,\\mathbb{C})$ and $H$ either being a complex Lie group or being\ntotally real, or in the case that $H$ preserves a pseudo-Riemannian metric. In\nmany cases, we show that the space $\\mathcal{F}_{\\mathfrak{h}}$ coincides with\nwhat we call the \\emph{characteristic subalgebra}\n$\\tilde{\\mathfrak{k}}_{\\mathfrak{h}}$ associated to $\\mathfrak{h}$, and that\nthen the torsion-free condition is equivalent to the left-invariant flatness\ncondition. In particular, we prove this to be the case if $H$ is a complex\nlinear Lie group or if $\\mathfrak{h}$ does not contain any elements of rank one\nor two and is either metric or totally real.",
    "pdf_url": "http://arxiv.org/pdf/2412.11316v2",
    "published": "2024-12-15T21:27:09+00:00",
    "categories": [
      "math.DG",
      "53C10 (Primary) 22E25, 53C15 (Secondary)"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11315v1",
    "title": "Simplified Weak Galerkin Finite Element Methods for Biharmonic Equations on Non-Convex Polytopal Meshes",
    "authors": [
      "Chunmei Wang"
    ],
    "abstract": "This paper presents a simplified weak Galerkin (WG) finite element method for\nsolving biharmonic equations avoiding the use of traditional stabilizers. The\nproposed WG method supports both convex and non-convex polytopal elements in\nfinite element partitions, utilizing bubble functions as a critical analytical\ntool. The simplified WG method is symmetric and positive definite.\nOptimal-order error estimates are established for WG approximations in both the\ndiscrete $H^2$ norm and the $L^2$ norm.",
    "pdf_url": "http://arxiv.org/pdf/2412.11315v1",
    "published": "2024-12-15T21:23:30+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65N30, 65N15, 65N12, 65N20"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11314v1",
    "title": "Reliable, Reproducible, and Really Fast Leaderboards with Evalica",
    "authors": [
      "Dmitry Ustalov"
    ],
    "abstract": "The rapid advancement of natural language processing (NLP) technologies, such\nas instruction-tuned large language models (LLMs), urges the development of\nmodern evaluation protocols with human and machine feedback. We introduce\nEvalica, an open-source toolkit that facilitates the creation of reliable and\nreproducible model leaderboards. This paper presents its design, evaluates its\nperformance, and demonstrates its usability through its Web interface,\ncommand-line interface, and Python API.",
    "pdf_url": "http://arxiv.org/pdf/2412.11314v1",
    "published": "2024-12-15T21:22:46+00:00",
    "categories": [
      "cs.CL",
      "62-04",
      "D.2.3"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11313v2",
    "title": "Stable Recovery of Regularized Linear Inverse Problems",
    "authors": [
      "Tran T. A. Nghia",
      "Huy N. Pham",
      "Nghia V. Vo"
    ],
    "abstract": "Recovering a low-complexity signal from its noisy observations by\nregularization methods is a cornerstone of inverse problems and compressed\nsensing. Stable recovery ensures that the original signal can be approximated\nlinearly by optimal solutions of the corresponding Morozov or Tikhonov\nregularized optimization problems. In this paper, we propose new\ncharacterizations for stable recovery in finite-dimensional spaces, uncovering\nthe role of nonsmooth second-order information. These insights enable a deeper\nunderstanding of stable recovery and their practical implications. As a\nconsequence, we apply our theory to derive new sufficient conditions for stable\nrecovery of the analysis group sparsity problems, including the group sparsity\nand isotropic total variation problems. Numerical experiments on these two\nproblems give favorable results about using our conditions to test stable\nrecovery.",
    "pdf_url": "http://arxiv.org/pdf/2412.11313v2",
    "published": "2024-12-15T21:22:43+00:00",
    "categories": [
      "math.OC",
      "49J52, 49J53, 49K40, 52A41, 90C25, 90C31"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11312v1",
    "title": "A hybrid classical-quantum approach to highly constrained Unit Commitment problems",
    "authors": [
      "Bruna Salgado",
      "André Sequeira",
      "Luis Paulo Santos"
    ],
    "abstract": "The unit commitment (UC) problem stands as a critical optimization challenge\nin the electrical power industry. It is classified as NP-hard, placing it among\nthe most intractable problems to solve. This paper introduces a novel hybrid\nquantum-classical algorithm designed to efficiently (approximately) solve the\nUC problem in polynomial time. In this approach, the UC problem is decomposed\ninto two subproblems: a QUBO (Quadratic Unconstrained Binary Optimization)\nproblem and a quadratic optimization problem. The algorithm employs the Quantum\nApproximate Optimization Algorithm (QAOA) to identify the optimal unit\ncombination and classical methods to determine individual unit powers. The\nproposed hybrid algorithm is the first to include both the spinning reserve\nconstraint (thus improving its applicability to real-world scenarios) and to\nexplore QAOA warm-start optimization in this context. The effectiveness of this\noptimization was illustrated for specific instances of the UC problem, not only\nin terms of solution accuracy but also by reducing the number of iterations\nrequired for QAOA convergence. Hybrid solutions achieved using a single-layer\nwarm-start QAOA (p=1) are within a 5.1 % margin of the reference (approximate)\nclassical solution, while guaranteeing polynomial time complexity on the number\nof power generation units and time intervals.",
    "pdf_url": "http://arxiv.org/pdf/2412.11312v1",
    "published": "2024-12-15T21:21:36+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11311v1",
    "title": "Simple Method for the Direct Measurement of Cohesive Forces Between Microscopic Particles",
    "authors": [
      "Johnathan Hoggarth",
      "Kari Dalnoki-Veress"
    ],
    "abstract": "We present a simple and inexpensive method for measuring weak cohesive\ninteractions. This technique is applied to the specific case of oil droplets\nwith a depletion interaction, dispersed in an aqueous solution. The\nexperimental setup involves creating a short string of droplets while\nimmobilizing a single droplet. The droplets are held together via depletion\ninteractions and a single cohesive bond holds together nearest neighbours.\nInitially, the buoyant droplets are held in a flat horizontal chamber. The\ndroplets float to the top of the chamber and are in contact with a flat glass\ninterface. In the horizontal configuration, there is no component of the\neffective buoyant force acting in the plane of the chamber. The angle of the\nchamber is gradually increased and the effective buoyant force acting on the\nstring of droplets slowly increases. At a critical point, when the combination\nof gravity and buoyancy is equal to the cohesive force, the droplet string will\ndetach from the immobile droplet. Our method allows for a simple direct\nmeasurement of cohesive forces on the tens of pico-Newton scale. To illustrate\nthe validity of this technique, the droplet radii and concentration of\ndepletant are varied, and their impact on the cohesive force is measured. This\nmethod offers a simple, accessible, and reproducible means of exploring\ncohesive interactions beyond the specific case of oil droplets and a depletion\ninteraction.",
    "pdf_url": "http://arxiv.org/pdf/2412.11311v1",
    "published": "2024-12-15T21:21:21+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2412.11310v1",
    "title": "GAP: Game Theory-Based Approach for Reliability and Power Management in Emerging Fog Computing",
    "authors": [
      "Abolfazl Younesi",
      "Mohsen Ansari",
      "Alireza Ejlali",
      "Mohammad Amin Fazli",
      "Muhammad Shafique",
      "Jörg Henkel"
    ],
    "abstract": "Fog computing brings about a transformative shift in data management,\npresenting unprecedented opportunities for enhanced performance and reduced\nlatency. However, one of the key aspects of fog computing revolves around\nensuring efficient power and reliability management. To address this challenge,\nwe have introduced a novel model that proposes a non-cooperative game\ntheory-based strategy to strike a balance between power consumption and\nreliability in decision-making processes. Our proposed model capitalizes on the\nCold Primary/Backup strategy (CPB) to guarantee reliability target by\nre-executing tasks to different nodes when a fault occurs, while also\nleveraging Dynamic Voltage and Frequency Scaling (DVFS) to reduce power\nconsumption during task execution and maximizing overall efficiency.\nNon-cooperative game theory plays a pivotal role in our model, as it\nfacilitates the development of strategies and solutions that uphold reliability\nwhile reducing power consumption. By treating the trade-off between power and\nreliability as a non-cooperative game, our proposed method yields significant\nenergy savings, with up to a 35% reduction in energy consumption, 41% decrease\nin wait time, and 31% shorter completion time compared to state-of-the-art\napproaches. Our findings underscore the value of game theory in optimizing\npower and reliability within fog computing environments, demonstrating its\npotential for driving substantial improvements",
    "pdf_url": "http://arxiv.org/pdf/2412.11310v1",
    "published": "2024-12-15T21:15:24+00:00",
    "categories": [
      "cs.DC",
      "cs.ET",
      "cs.GT"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11309v2",
    "title": "Singularities of square-free polynomials",
    "authors": [
      "Daniel Bath",
      "Mircea Mustaţă",
      "Uli Walther"
    ],
    "abstract": "We prove that hypersurfaces defined by irreducible square-free polynomials\nhave rational singularities. As an easy consequence, we deduce that certain\n(possibly non-square-free) polynomials associated to pairs of square-free\npolynomials define hypersurfaces with rational singularities. This extends\nresults on certain classes of polynomials associated to matroids and Feynman\ndiagrams in [BW].",
    "pdf_url": "http://arxiv.org/pdf/2412.11309v2",
    "published": "2024-12-15T21:07:23+00:00",
    "categories": [
      "math.AG",
      "math.AC",
      "14B05, 14J17, 32S25"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2412.12211v1",
    "title": "Nonadditive entropy of the gravitational wave signal from GW150914",
    "authors": [
      "Daniel B. de Freitas",
      "Cleo V. da Silva",
      "Mackson M. F. Nepomuceno"
    ],
    "abstract": "We study the first gravitational wave, GW150914, detected by advanced LIGO\nand constructed from the data of measurement of strain relative deformation of\nthe fabric of spacetime. We show that the time series from the gravitational\nwave obeys a nonadditive entropy, and its dynamics evolve with the three\nassociated Tsallis indices named q-triplet. This fact strongly suggests that\nthese black hole merger systems behave in a non-extensive framework.\nFurthermore, our results point out that the entropic indexes obtained as a\nfunction of frequency are proper statistical parameters to determine the\ndominant frequency when black hole coalescence is achieved.",
    "pdf_url": "http://arxiv.org/pdf/2412.12211v1",
    "published": "2024-12-15T21:03:33+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.HE"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2412.14201v2",
    "title": "The \"Huh?\" Button: Improving Understanding in Educational Videos with Large Language Models",
    "authors": [
      "Boris Ruf",
      "Marcin Detyniecki"
    ],
    "abstract": "We propose a simple way to use large language models (LLMs) in education.\nSpecifically, our method aims to improve individual comprehension by adding a\nnovel feature to online videos. We combine the low threshold for interactivity\nin digital experiences with the benefits of rephrased and elaborated\nexplanations typical of face-to-face interactions, thereby supporting to close\nknowledge gaps at scale. To demonstrate the technical feasibility of our\napproach, we conducted a proof-of-concept experiment and implemented a\nprototype which is available for testing online. Through the use case, we also\nshow how caching can be applied in LLM-powered applications to reduce their\ncarbon footprint.",
    "pdf_url": "http://arxiv.org/pdf/2412.14201v2",
    "published": "2024-12-15T21:02:16+00:00",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11308v1",
    "title": "datadriftR: An R Package for Concept Drift Detection in Predictive Models",
    "authors": [
      "Ugur Dar",
      "Mustafa Cavus"
    ],
    "abstract": "Predictive models often face performance degradation due to evolving data\ndistributions, a phenomenon known as data drift. Among its forms, concept\ndrift, where the relationship between explanatory variables and the response\nvariable changes, is particularly challenging to detect and adapt to.\nTraditional drift detection methods often rely on metrics such as accuracy or\nvariable distributions, which may fail to capture subtle but significant\nconceptual changes. This paper introduces drifter, an R package designed to\ndetect concept drift, and proposes a novel method called Profile Drift\nDetection (PDD) that enables both drift detection and an enhanced understanding\nof the cause behind the drift by leveraging an explainable AI tool - Partial\nDependence Profiles (PDPs). The PDD method, central to the package, quantifies\nchanges in PDPs through novel metrics, ensuring sensitivity to shifts in the\ndata stream without excessive computational costs. This approach aligns with\nMLOps practices, emphasizing model monitoring and adaptive retraining in\ndynamic environments. The experiments across synthetic and real-world datasets\ndemonstrate that PDD outperforms existing methods by maintaining high accuracy\nwhile effectively balancing sensitivity and stability. The results highlight\nits capability to adaptively retrain models in dynamic environments, making it\na robust tool for real-time applications. The paper concludes by discussing the\nadvantages, limitations, and future extensions of the package for broader use\ncases.",
    "pdf_url": "http://arxiv.org/pdf/2412.11308v1",
    "published": "2024-12-15T20:59:49+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2412.11307v1",
    "title": "A preconditioned inexact infeasible quantum interior point method for linear optimization",
    "authors": [
      "Zeguan Wu",
      "Xiu Yang",
      "Tamás Terlaky"
    ],
    "abstract": "Quantum Interior Point Methods (QIPMs) have been attracting significant\ninterests recently due to their potential of solving optimization problems\nsubstantially faster than state-of-the-art conventional algorithms. In general,\nQIPMs use Quantum Linear System Algorithms (QLSAs) to substitute classical\nlinear system solvers. However, the performance of QLSAs depends on the\ncondition numbers of the linear systems, which are typically proportional to\nthe square of the reciprocal of the duality gap in QIPMs. To improve\nconditioning, a preconditioned inexact infeasible QIPM (II-QIPM) based on\noptimal partition estimation is developed in this work. We improve the\ncondition number of the linear systems in II-QIPMs from quadratic dependence on\nthe reciprocal of the duality gap to linear, and obtain better dependence with\nrespect to the accuracy when compared to other II-QIPMs. Our method also\nattains better dependence with respect to the dimension when compared to other\ninexact infeasible Interior Point Methods.",
    "pdf_url": "http://arxiv.org/pdf/2412.11307v1",
    "published": "2024-12-15T20:54:31+00:00",
    "categories": [
      "math.OC",
      "81P68, 90C05, 90C51, 65F08"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11306v1",
    "title": "Unimodal and Multimodal Static Facial Expression Recognition for Virtual Reality Users with EmoHeVRDB",
    "authors": [
      "Thorben Ortmann",
      "Qi Wang",
      "Larissa Putzar"
    ],
    "abstract": "In this study, we explored the potential of utilizing Facial Expression\nActivations (FEAs) captured via the Meta Quest Pro Virtual Reality (VR) headset\nfor Facial Expression Recognition (FER) in VR settings. Leveraging the\nEmojiHeroVR Database (EmoHeVRDB), we compared several unimodal approaches and\nachieved up to 73.02% accuracy for the static FER task with seven emotion\ncategories. Furthermore, we integrated FEA and image data in multimodal\napproaches, observing significant improvements in recognition accuracy. An\nintermediate fusion approach achieved the highest accuracy of 80.42%,\nsignificantly surpassing the baseline evaluation result of 69.84% reported for\nEmoHeVRDB's image data. Our study is the first to utilize EmoHeVRDB's unique\nFEA data for unimodal and multimodal static FER, establishing new benchmarks\nfor FER in VR settings. Our findings highlight the potential of fusing\ncomplementary modalities to enhance FER accuracy in VR settings, where\nconventional image-based methods are severely limited by the occlusion caused\nby Head-Mounted Displays (HMDs).",
    "pdf_url": "http://arxiv.org/pdf/2412.11306v1",
    "published": "2024-12-15T20:49:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11305v1",
    "title": "$\\textit{Ab initio}$ electron-phonon coupling theory of elastic helium atom scattering",
    "authors": [
      "Cristóbal Méndez",
      "C. J. Thompson",
      "M. F. Van Duinen",
      "S. J. Sibener",
      "Tomás A. Arias"
    ],
    "abstract": "We propose a fully $ \\textit{ab initio} $ approach to predicting thermal\nattenuation in elastic helium atom scattering amplitudes, validated through\nstrong agreement with experiments on Nb(100) and (3$\\times$1)-O/Nb(100)\nsurfaces. Our results reveal the relative contributions from bulk, resonant,\nand surface phonon modes, as well as from different surface mode polarizations,\nproviding insights into differences between smooth and corrugated surfaces.\nThese findings advance understanding of surface dynamics and electron-phonon\ncoupling, laying groundwork for future studies on surface superconductivity.",
    "pdf_url": "http://arxiv.org/pdf/2412.11305v1",
    "published": "2024-12-15T20:47:53+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2412.11304v2",
    "title": "An Empirical Study of Fault Localisation Techniques for Deep Learning",
    "authors": [
      "Nargiz Humbatova",
      "Jinhan Kim",
      "Gunel Jahangirova",
      "Shin Yoo",
      "Paolo Tonella"
    ],
    "abstract": "With the increased popularity of Deep Neural Networks (DNNs), increases also\nthe need for tools to assist developers in the DNN implementation, testing and\ndebugging process. Several approaches have been proposed that automatically\nanalyse and localise potential faults in DNNs under test. In this work, we\nevaluate and compare existing state-of-the-art fault localisation techniques,\nwhich operate based on both dynamic and static analysis of the DNN. The\nevaluation is performed on a benchmark consisting of both real faults obtained\nfrom bug reporting platforms and faulty models produced by a mutation tool. Our\nfindings indicate that the usage of a single, specific ground truth (e.g., the\nhuman defined one) for the evaluation of DNN fault localisation tools results\nin pretty low performance (maximum average recall of 0.31 and precision of\n0.23). However, such figures increase when considering alternative, equivalent\npatches that exist for a given faulty DNN. Results indicate that \\dfd is the\nmost effective tool, achieving an average recall of 0.61 and precision of 0.41\non our benchmark.",
    "pdf_url": "http://arxiv.org/pdf/2412.11304v2",
    "published": "2024-12-15T20:47:03+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11303v1",
    "title": "Regularized Dikin Walks for Sampling Truncated Logconcave Measures, Mixed Isoperimetry and Beyond Worst-Case Analysis",
    "authors": [
      "Minhui Jiang",
      "Yuansi Chen"
    ],
    "abstract": "We study the problem of drawing samples from a logconcave distribution\ntruncated on a polytope, motivated by computational challenges in Bayesian\nstatistical models with indicator variables, such as probit regression.\nBuilding on interior point methods and the Dikin walk for sampling from uniform\ndistributions, we analyze the mixing time of regularized Dikin walks. Our\ncontributions are threefold. First, for a logconcave and log-smooth\ndistribution with condition number $\\kappa$, truncated on a polytope in\n$\\mathbb{R}^n$ defined with $m$ linear constraints, we prove that the\nsoft-threshold Dikin walk mixes in $\\widetilde{O}((m+\\kappa)n)$ iterations from\na warm initialization. It improves upon prior work which required the polytope\nto be bounded and involved a bound dependent on the radius of the bounded\nregion. Moreover, we introduce the regularized Dikin walk using Lewis weights\nfor approximating the John ellipsoid. We show that it mixes in\n$\\widetilde{O}((n^{2.5}+\\kappa n)$. Second, we extend the mixing time\nguarantees mentioned above to weakly log-concave distributions truncated on\npolytopes, provided that they have a finite covariance matrix. Third, going\nbeyond worst-case mixing time analysis, we demonstrate that soft-threshold\nDikin walk can mix significantly faster when only a limited number of\nconstraints intersect the high-probability mass of the distribution, improving\nthe $\\widetilde{O}((m+\\kappa)n)$ upper bound to $\\widetilde{O}(m + \\kappa n)$.\nAdditionally, per-iteration complexity of regularized Dikin walk and ways to\ngenerate a warm initialization are discussed to facilitate practical\nimplementation.",
    "pdf_url": "http://arxiv.org/pdf/2412.11303v1",
    "published": "2024-12-15T20:43:51+00:00",
    "categories": [
      "cs.DS",
      "cs.LG",
      "stat.CO",
      "stat.ML"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2412.11302v3",
    "title": "Sequence-Level Leakage Risk of Training Data in Large Language Models",
    "authors": [
      "Trishita Tiwari",
      "G. Edward Suh"
    ],
    "abstract": "This work quantifies the risk of training data leakage from LLMs (Large\nLanguage Models) using sequence-level probabilities. Computing extraction\nprobabilities for individual sequences provides finer-grained information than\nhas been studied in prior benchmarking work. We re-analyze the effects of\ndecoding schemes, model sizes, prefix lengths, partial sequence leakages, and\ntoken positions to uncover new insights that were not possible in previous\nworks due to their choice of metrics. We perform this study on two pre-trained\nmodels, Llama and OPT, trained on the Common Crawl and The Pile respectively.\nWe discover that 1) Extraction Rate, the predominant metric used in prior\nquantification work, underestimates the threat of leakage of training data in\nrandomized LLMs by as much as 2.14X. 2) Although on average, larger models and\nlonger prefixes can extract more data, this is not true for a substantial\nportion of individual sequences. 30.4-41.5% of our sequences are easier to\nextract with either shorter prefixes or smaller models. 3) Contrary to previous\nbeliefs, partial leakage in commonly used decoding schemes like top-k and top-p\nis not easier than leaking verbatim training data. The aim of this work is to\nencourage the adoption of this metric for future work on quantification of\ntraining data extraction.",
    "pdf_url": "http://arxiv.org/pdf/2412.11302v3",
    "published": "2024-12-15T20:27:45+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11301v1",
    "title": "Semi-Implicit Neural Ordinary Differential Equations",
    "authors": [
      "Hong Zhang",
      "Ying Liu",
      "Romit Maulik"
    ],
    "abstract": "Classical neural ODEs trained with explicit methods are intrinsically limited\nby stability, crippling their efficiency and robustness for stiff learning\nproblems that are common in graph learning and scientific machine learning. We\npresent a semi-implicit neural ODE approach that exploits the partitionable\nstructure of the underlying dynamics. Our technique leads to an implicit neural\nnetwork with significant computational advantages over existing approaches\nbecause of enhanced stability and efficient linear solves during time\nintegration. We show that our approach outperforms existing approaches on a\nvariety of applications including graph classification and learning complex\ndynamical systems. We also demonstrate that our approach can train challenging\nneural ODEs where both explicit methods and fully implicit methods are\nintractable.",
    "pdf_url": "http://arxiv.org/pdf/2412.11301v1",
    "published": "2024-12-15T20:21:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "K.3.2"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11300v2",
    "title": "Generative AI as a lab partner: a case study",
    "authors": [
      "Sebastian Kilde-Westberg",
      "Andreas Johansson",
      "Jonas Enger"
    ],
    "abstract": "Generative AI tools, including the popular ChatGPT, have had a significant\nimpact on discourses about future work and educational practices. Previous\nresearch in science education has highlighted the potential of generative AI in\nvarious education-related areas, including generating valuable discussion\nmaterial, solving physics problems, and acting as a tutor. However, little\nresearch has been done regarding the role of generative AI tools in laboratory\nwork, an essential part of science education, and physics education\nspecifically. Here we show various ways in which high school students use\nChatGPT during a physics laboratory session and discuss the relevance of using\ngenerative AI tools to investigate acoustic levitation and the speed of sound\nin air. Additionally, employing variation theory as a theoretical lens in the\nanalysis, we identify how generative AI can be used to further develop\nstudents' problem-solving skills in the physics laboratory. However, although\nour study shows that generative AI tools may handle some relevant questions and\nproblems during laboratory work, the teacher still plays a crucial role in\nidentifying students' needs and capabilities of understanding the potential and\nlimitations of generative AI. Finally, this study serves as an important point\nof discussion regarding the ways in which students need support and training to\nefficiently utilize generative AI to further their learning of physics.",
    "pdf_url": "http://arxiv.org/pdf/2412.11300v2",
    "published": "2024-12-15T20:20:48+00:00",
    "categories": [
      "physics.ed-ph"
    ],
    "primary_category": "physics.ed-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11299v1",
    "title": "How not to Stitch Representations to Measure Similarity: Task Loss Matching versus Direct Matching",
    "authors": [
      "András Balogh",
      "Márk Jelasity"
    ],
    "abstract": "Measuring the similarity of the internal representations of deep neural\nnetworks is an important and challenging problem. Model stitching has been\nproposed as a possible approach, where two half-networks are connected by\nmapping the output of the first half-network to the input of the second one.\nThe representations are considered functionally similar if the resulting\nstitched network achieves good task-specific performance. The mapping is\nnormally created by training an affine stitching layer on the task at hand\nwhile freezing the two half-networks, a method called task loss matching. Here,\nwe argue that task loss matching may be very misleading as a similarity index.\nFor example, it can indicate very high similarity between very distant layers,\nwhose representations are known to have different functional properties.\nMoreover, it can indicate very distant layers to be more similar than\narchitecturally corresponding layers. Even more surprisingly, when comparing\nlayers within the same network, task loss matching often indicates that some\nlayers are more similar to a layer than itself. We argue that the main reason\nbehind these problems is that task loss matching tends to create\nout-of-distribution representations to improve task-specific performance. We\ndemonstrate that direct matching (when the mapping minimizes the distance\nbetween the stitched representations) does not suffer from these problems. We\ncompare task loss matching, direct matching, and well-known similarity indices\nsuch as CCA and CKA. We conclude that direct matching strikes a good balance\nbetween the structural and functional requirements for a good similarity index.",
    "pdf_url": "http://arxiv.org/pdf/2412.11299v1",
    "published": "2024-12-15T20:18:49+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11298v1",
    "title": "The Impact of AI Explanations on Clinicians Trust and Diagnostic Accuracy in Breast Cancer",
    "authors": [
      "Olya Rezaeian",
      "Onur Asan",
      "Alparslan Emrah Bayrak"
    ],
    "abstract": "Advances in machine learning have created new opportunities to develop\nartificial intelligence (AI)-based clinical decision support systems using past\nclinical data and improve diagnosis decisions in life-threatening illnesses\nsuch breast cancer. Providing explanations for AI recommendations is a possible\nway to address trust and usability issues in black-box AI systems. This paper\npresents the results of an experiment to assess the impact of varying levels of\nAI explanations on clinicians' trust and diagnosis accuracy in a breast cancer\napplication and the impact of demographics on the findings. The study includes\n28 clinicians with varying medical roles related to breast cancer diagnosis.\nThe results show that increasing levels of explanations do not always improve\ntrust or diagnosis performance. The results also show that while some of the\nself-reported measures such as AI familiarity depend on gender, age and\nexperience, the behavioral assessments of trust and performance are independent\nof those variables.",
    "pdf_url": "http://arxiv.org/pdf/2412.11298v1",
    "published": "2024-12-15T20:17:07+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11297v1",
    "title": "A magneto-ionic synapse for reservoir computing",
    "authors": [
      "Sreeveni Das",
      "Rhodri Mansell",
      "Lukáš Flajšman",
      "Maria-Andromachi Syskaki",
      "Jürgen Langer",
      "Sebastiaan van Dijken"
    ],
    "abstract": "Neuromorphic computing aims to revolutionize large-scale data processing by\ndeveloping efficient methods and devices inspired by neural networks. Among\nthese, the control of magnetism through ion migration has emerged as a\npromising approach due to the inherent memory and nonlinearity of ionically\nconducting and magnetic materials. In this work, we present a lithium-ion-based\nmagneto-ionic device that uses applied voltages to control the magnetic domain\nstate of a perpendicularly magnetized ferromagnetic layer. This behavior\nemulates the analog and non-volatile properties of biological synapses and\nenables the creation of a simple reservoir computing system. To illustrate its\ncapabilities, the device is used in a waveform classification task, where the\nvoltage amplitude range and magnetic bias field are tuned to optimize the\nrecognition accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2412.11297v1",
    "published": "2024-12-15T20:14:05+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11296v1",
    "title": "Functorial transfer for reductive groups and central complexes",
    "authors": [
      "Tsao-Hsien Chen"
    ],
    "abstract": "A class of Weyl group equivariant $\\ell$-adic complexes on a torus, called\nthe central complexes, was introduced and studied in our previous work on\nBraverman-Kazhdan conjecture. In this note we show that the category of central\ncomplexes admits functorial monoidal transfers with respect to morphisms\nbetween the dual groups. Combining with the work of Bezrukavnikov-Deshpande, we\nshow that the $\\ell$-adic bi-Whittaker categories (resp. the category of\nvanishing complexes, the category of stable complexes) on reductive groups\nadmit functorial transfers. As an application, we give a new geometric proof of\nLaumon-Letellier's fromula for transfer maps of stable functions on finite\nreductive groups.",
    "pdf_url": "http://arxiv.org/pdf/2412.11296v1",
    "published": "2024-12-15T20:11:41+00:00",
    "categories": [
      "math.RT",
      "math.AG"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11295v1",
    "title": "The Relational Quotient Completion",
    "authors": [
      "Francesco Dagnino",
      "Fabio Pasquali"
    ],
    "abstract": "Taking a quotient roughly means changing the notion of equality on a given\nobject, set or type. In a quantitative setting, equality naturally generalises\nto a distance, measuring how much elements are similar instead of just stating\ntheir equivalence. Hence, quotients can be understood quantitatively as a\nchange of distance.\n  In this paper, we show how, combining Lawvere's doctrines and the calculus of\nrelations, one can unify quantitative and usual quotients in a common picture.\nMore in detail, we introduce relational doctrines as a functorial description\nof (the core of) the calculus of relations. Then, we define quotients and a\nuniversal construction adding them to any relational doctrine, generalising the\nquotient completion of existential elementary doctrine and also recovering many\nquantitative examples. This construction deals with an intensional notion of\nquotient and breaks extensional equality of morphisms. Then, we describe\nanother construction forcing extensionality, showing how it abstracts several\nnotions of separation in metric and topological structures. Combining these two\nconstructions, we get the extensional quotient completion, whose essential\nimage is characterized through the notion of projective cover. As an\napplication, we show that, under suitable conditions, relational doctrines of\nalgebras arise as the extensional quotient completion of free algebras.\nFinally, we compare relational doctrines to other categorical structures where\none can model the calculus of relations.",
    "pdf_url": "http://arxiv.org/pdf/2412.11295v1",
    "published": "2024-12-15T20:05:47+00:00",
    "categories": [
      "math.CT",
      "cs.LO",
      "math.LO"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11294v1",
    "title": "The Dirichlet problem on lower dimensional boundaries: Schauder estimates via perforated domains",
    "authors": [
      "Gabriele Fioravanti"
    ],
    "abstract": "In this paper, we investigate the Dirichlet problem on lower dimensional\nmanifolds for a class of weighted elliptic equations with coefficients that are\nsingular on such sets. Specifically, we study the problem \\[\\begin{cases} -{\\rm\ndiv}(|y|^a A(x,y) \\nabla u) = |y|^a f + {\\rm div}(|y|^a F), \\\\ u = \\psi, \\quad\n\\text{ on } \\Sigma_0, \\end{cases} \\] where $(x,y) \\in \\mathbb{R}^{d-n} \\times\n\\mathbb{R}^n$, $2 \\leq n \\leq d$, $a + n \\in (0,2)$, and $\\Sigma_0 = \\{|y| =\n0\\}$ is the lower dimensional manifold where the equation loses uniform\nellipticity. Our primary objective is to establish $C^{0,\\alpha}$ and\n$C^{1,\\alpha}$ regularity estimates up to $\\Sigma_0$, under suitable\nassumptions on the coefficients and the data. Our approach combines perforated\ndomain approximations, Liouville-type theorems and a fine blow-up argument.",
    "pdf_url": "http://arxiv.org/pdf/2412.11294v1",
    "published": "2024-12-15T19:58:47+00:00",
    "categories": [
      "math.AP",
      "35B65 (primary), 35J75, 35J25, 35B44, 35B53 (secondary)"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11293v2",
    "title": "A Comparative Study on Dynamic Graph Embedding based on Mamba and Transformers",
    "authors": [
      "Ashish Parmanand Pandey",
      "Alan John Varghese",
      "Sarang Patil",
      "Mengjia Xu"
    ],
    "abstract": "Dynamic graph embedding has emerged as an important technique for modeling\ncomplex time-evolving networks across diverse domains. While transformer-based\nmodels have shown promise in capturing long-range dependencies in temporal\ngraph data, they face scalability challenges due to quadratic computational\ncomplexity. This study presents a comparative analysis of dynamic graph\nembedding approaches using transformers and the recently proposed Mamba\narchitecture, a state-space model with linear complexity. We introduce three\nnovel models: TransformerG2G augment with graph convolutional networks,\n\\mathcal{DG}-Mamba, and \\mathcal{GDG}-Mamba with graph isomorphism network edge\nconvolutions. Our experiments on multiple benchmark datasets demonstrate that\nMamba-based models achieve comparable or superior performance to\ntransformer-based approaches in link prediction tasks while offering\nsignificant computational efficiency gains on longer sequences. Notably,\n\\mathcal{DG}-Mamba variants consistently outperform transformer-based models on\ndatasets with high temporal variability, such as UCI, Bitcoin, and Reality\nMining, while maintaining competitive performance on more stable graphs like\nSBM. We provide insights into the learned temporal dependencies through\nanalysis of attention weights and state matrices, revealing the models' ability\nto capture complex temporal patterns. By effectively combining state-space\nmodels with graph neural networks, our work addresses key limitations of\nprevious approaches and contributes to the growing body of research on\nefficient temporal graph representation learning. These findings offer\npromising directions for scaling dynamic graph embedding to larger, more\ncomplex real-world networks, potentially enabling new applications in areas\nsuch as social network analysis, financial modeling, and biological system\ndynamics.",
    "pdf_url": "http://arxiv.org/pdf/2412.11293v2",
    "published": "2024-12-15T19:56:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11292v1",
    "title": "Grassmannian Geometry Meets Dynamic Mode Decomposition in DMD-GEN: A New Metric for Mode Collapse in Time Series Generative Models",
    "authors": [
      "Amime Mohamed Aboussalah",
      "Yassine Abbahaddou"
    ],
    "abstract": "Generative models like Generative Adversarial Networks (GANs) and Variational\nAutoencoders (VAEs) often fail to capture the full diversity of their training\ndata, leading to mode collapse. While this issue is well-explored in image\ngeneration, it remains underinvestigated for time series data. We introduce a\nnew definition of mode collapse specific to time series and propose a novel\nmetric, DMD-GEN, to quantify its severity. Our metric utilizes Dynamic Mode\nDecomposition (DMD), a data-driven technique for identifying coherent\nspatiotemporal patterns, and employs Optimal Transport between DMD eigenvectors\nto assess discrepancies between the underlying dynamics of the original and\ngenerated data. This approach not only quantifies the preservation of essential\ndynamic characteristics but also provides interpretability by pinpointing which\nmodes have collapsed. We validate DMD-GEN on both synthetic and real-world\ndatasets using various generative models, including TimeGAN, TimeVAE, and\nDiffusionTS. The results demonstrate that DMD-GEN correlates well with\ntraditional evaluation metrics for static data while offering the advantage of\napplicability to dynamic data. This work offers for the first time a definition\nof mode collapse for time series, improving understanding, and forming the\nbasis of our tool for assessing and improving generative models in the time\nseries domain.",
    "pdf_url": "http://arxiv.org/pdf/2412.11292v1",
    "published": "2024-12-15T19:53:17+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11291v2",
    "title": "A computational study of certain Weyl modules for type $G_2$ in characteristic 2",
    "authors": [
      "Stephen Doty"
    ],
    "abstract": "Using the \\texttt{WeylModules} \\textsf{GAP} Package, we compute\n  structural information about certain Weyl modules for type $G_2$ in\n  characteristic $2$. This gives counterexamples to two conjectures\n  stated by S.~Donkin in 1990. It also illustrates capabilities of the\n  package, which can in principle be applied to Weyl modules for any\n  simple, simply-connected algebraic group in any characteristic,\n  subject of course to time and space limitations of computational\n  resources.",
    "pdf_url": "http://arxiv.org/pdf/2412.11291v2",
    "published": "2024-12-15T19:44:41+00:00",
    "categories": [
      "math.RT",
      "math.GR",
      "20G05"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11290v2",
    "title": "Left-Invariant Riemannian Distances on Higher-Rank Sol-Type Groups",
    "authors": [
      "Daniel N. Levitin"
    ],
    "abstract": "In this paper, we generalize the results of ($\\textit{Groups, Geom. Dyn.}$,\nforthcoming) to describe the split left-invariant Riemannian distances on\nhigher-rank Sol-type groups $G=\\mathbf{N}\\rtimes \\mathbb{R}^k$. We show that\nthe rough isometry type of such a distance is determined by a specific\nrestriction of the metric to $\\mathbb{R}^k$, and therefore the space of rough\nsimilarity types of distances is parameterized by the symmetric space\n$SL_k(\\mathbb{R})/SO_k(\\mathbb{R})$. In order to prove this result, we describe\na family of uniformly roughly geodesic paths, which arise by way of the new\ntechnique of $\\textit{Euclidean curve surgery}$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11290v2",
    "published": "2024-12-15T19:42:47+00:00",
    "categories": [
      "math.GR",
      "math.DG",
      "math.MG",
      "20F69, 22E25, 53C23,"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2412.15255v2",
    "title": "Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation",
    "authors": [
      "Jonibek Mansurov",
      "Akhmed Sakip",
      "Alham Fikri Aji"
    ],
    "abstract": "In this paper, we show that knowledge distillation can be subverted to\nmanipulate language model benchmark scores, revealing a critical vulnerability\nin current evaluation practices. We introduce \"Data Laundering,\" a process that\nenables the covert transfer of benchmark-specific knowledge through seemingly\nlegitimate intermediate training steps. Through extensive experiments with a\n2-layer BERT student model, we show how this approach can achieve substantial\nimprovements in benchmark accuracy (up to 75\\% on GPQA) without developing\ngenuine reasoning capabilities. Notably, this method can be exploited\nintentionally or even unintentionally, as researchers may inadvertently adopt\nthis method and inflate scores without realising the implications. While our\nfindings demonstrate the effectiveness of this technique, we present them as a\ncautionary tale highlighting the urgent need for more robust evaluation methods\nin AI. This work aims to contribute to the ongoing discussion about evaluation\nintegrity in AI development and the need for benchmarks that more accurately\nreflect true model capabilities. The code is available at\nhttps://github.com/mbzuai-nlp/data_laundering.",
    "pdf_url": "http://arxiv.org/pdf/2412.15255v2",
    "published": "2024-12-15T19:38:48+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11289v1",
    "title": "Continuously Learning Bug Locations",
    "authors": [
      "Paulina Stevia Nouwou Mindom",
      "Leuson Da Silva",
      "Amin Nikanjam",
      "Foutse Khomh"
    ],
    "abstract": "Automatically locating buggy changesets associated with bug reports is\ncrucial in the software development process. Deep Learning (DL)-based\ntechniques show promising results by leveraging structural information from the\ncode and learning links between changesets and bug reports. However, since\nsource code associated with changesets evolves, the performance of such models\ntends to degrade over time due to concept drift. Aiming to address this\nchallenge, in this paper, we evaluate the potential of using Continual Learning\n(CL) techniques in multiple sub-tasks setting for bug localization (each of\nwhich operates on either stationary or non-stationary data), comparing it\nagainst a bug localization technique that leverages the BERT model, a deep\nreinforcement learning-based technique that leverages the A2C algorithm, and a\nDL-based function-level interaction model for semantic bug localization.\nAdditionally, we enhanced the CL techniques by using logistic regression to\nidentify and integrate the most significant bug-inducing factors. Our empirical\nevaluation across seven widely used software projects shows that CL techniques\nperform better than DL-based techniques by up to 61% in terms of Mean\nReciprocal Rank (MRR), 44% in terms of Mean Average Precision (MAP), 83% in\nterms of top@1, 56% in terms of top@5, and 66% in terms of top@10 metrics in\nnon-stationary setting. Further, we show that the CL techniques we studied are\neffective at localizing changesets relevant to a bug report while being able to\nmitigate catastrophic forgetting across the studied tasks and require up to 5x\nless computational effort during training. Our findings demonstrate the\npotential of adopting CL for bug localization in non-stationary settings, and\nwe hope it helps to improve bug localization activities in Software Engineering\nusing CL techniques.",
    "pdf_url": "http://arxiv.org/pdf/2412.11289v1",
    "published": "2024-12-15T19:37:15+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11288v1",
    "title": "Towards Improved Polarization Uniformity in Ferroelectric Hf$_{0.5}$Zr$_{0.5}$O$_2$ Devices within Back End of Line Thermal Budget for Memory and Neuromorphic Applications",
    "authors": [
      "Padma Srivari",
      "Ella Paasio",
      "Xinye Li",
      "Sayani Majumdar"
    ],
    "abstract": "Thin film ferroelectric devices with ultralow power operation, non-volatile\ndata retention and fast and reliable switching are attractive for non-volatile\nmemory and as synaptic weight elements. However, low thermal budget\nferroelectric oxides suffer from crystalline inhomogeneity and defects that\nmakes their large-scale circuit integration challenging. Here, we report on the\nthermally engineered way to induce wafer-scale homogeneity in\nHf$_{0.5}$Zr$_{0.5}$O$_2$ capacitors that can lead to high device reliability\nmaking their integration possible in ultralow power memory and neuromorphic\ncomputing hardware.",
    "pdf_url": "http://arxiv.org/pdf/2412.11288v1",
    "published": "2024-12-15T19:32:10+00:00",
    "categories": [
      "physics.app-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.12210v2",
    "title": "Cosmic reverberations on a constrained $ f(Q,T) $-model of the Universe",
    "authors": [
      "Akanksha Singh",
      "Shaily",
      "J. K. Singh",
      "Ertan Güdekli"
    ],
    "abstract": "In this paper, we construct an isotropic cosmological model in the $ f(Q, T)\n$ theory of gravity in the frame of a flat FLRW spacetime being $ Q $ the\nnon-metricity tensor and $ T $ the trace of the energy-momentum tensor. The\ngravity function is taken to be a quadratic equation, $ f(Q, T)=\\zeta Q^2 +\n\\gamma T $, where $ \\zeta<0 $ and $ \\gamma $ are the arbitrary constants. We\nconstrain the model parameters $ \\alpha $ and $ H_0 $ using the recent\nobservational datasets: the Hubble dataset (OHD), the $ Pantheon $ dataset of $\n1048 $ points, and the joint dataset (OHD + $ Pantheon $). The universe model\ntransitions from an early deceleration state to an acceleration in late times.\nThis model also provides the ekpyrotic phase of the universe on the redshift $\nz>12.32 $. In this model, the Big Bang is described as a collision of branes,\nand thus, the Big Bang is not the beginning of time. Before the Big Bang, there\nis an ekpyrotic phase with the equation of state $ \\omega >> 1 $. In late\ntimes, the undeviating Hubble measurements reduce the $ H_0 $ tension in the\nreconstructed $ f(Q, T) $ function. Additionally, we study various physical\nparameters of the model. Finally, our model describes a quintessence dark\nenergy model at later times.",
    "pdf_url": "http://arxiv.org/pdf/2412.12210v2",
    "published": "2024-12-15T19:29:16+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2412.11287v1",
    "title": "Generalised nice sets",
    "authors": [
      "Cristina Draper",
      "Thomas L. Meyer",
      "Juana Sánchez-Ortega"
    ],
    "abstract": "A new combinatorial object, called generalised nice set, is classified up to\ncollineations of the Fano plane. This classification is necessary to find the\ngraded contractions of all the exceptional complex Lie algebras of dimension at\nleast 52, endowed with $\\mathbb Z_2^3$-gradings coming from the octonions. Our\nclassification is of purely combinatorial nature.",
    "pdf_url": "http://arxiv.org/pdf/2412.11287v1",
    "published": "2024-12-15T19:23:22+00:00",
    "categories": [
      "math.CO",
      "math.RA",
      "51E20"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11286v1",
    "title": "Detecting Daily Living Gait Amid Huntington's Disease Chorea using a Foundation Deep Learning Model",
    "authors": [
      "Dafna Schwartz",
      "Lori Quinn",
      "Nora E. Fritz",
      "Lisa M. Muratori",
      "Jeffery M. Hausdorff",
      "Ran Gilad Bachrach"
    ],
    "abstract": "Wearable sensors offer a non-invasive way to collect physical activity (PA)\ndata, with walking as a key component. Existing models often struggle to detect\ngait bouts in individuals with neurodegenerative diseases (NDDs) involving\ninvoluntary movements. We developed J-Net, a deep learning model inspired by\nU-Net, which uses a pre-trained self-supervised foundation model fine-tuned\nwith Huntington`s disease (HD) in-lab data and paired with a segmentation head\nfor gait detection. J-Net processes wrist-worn accelerometer data to detect\ngait during daily living. We evaluated J-Net on in-lab and daily-living data\nfrom HD, Parkinson`s disease (PD), and controls. J-Net achieved a 10-percentage\npoint improvement in ROC-AUC for HD over existing methods, reaching 0.97 for\nin-lab data. In daily-living environments, J-Net estimates showed no\nsignificant differences in median daily walking time between HD and controls (p\n= 0.23), in contrast to other models, which indicated counterintuitive results\n(p < 0.005). Walking time measured by J-Net correlated with the UHDRS-TMS\nclinical severity score (r=-0.52; p=0.02), confirming its clinical relevance.\nFine-tuning J-Net on PD data also improved gait detection over current methods.\nJ-Net`s architecture effectively addresses the challenges of gait detection in\nsevere chorea and offers robust performance in daily living. The dataset and\nJ-Net model are publicly available, providing a resource for further research\ninto NDD-related gait impairments.",
    "pdf_url": "http://arxiv.org/pdf/2412.11286v1",
    "published": "2024-12-15T19:19:39+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11285v1",
    "title": "Moderating the Mediation Bootstrap for Causal Inference",
    "authors": [
      "Kees Jan van Garderen",
      "Noud van Giersbergen"
    ],
    "abstract": "Mediation analysis is a form of causal inference that investigates indirect\neffects and causal mechanisms. Confidence intervals for indirect effects play a\ncentral role in conducting inference. The problem is non-standard leading to\ncoverage rates that deviate considerably from their nominal level. The default\ninference method in the mediation model is the paired bootstrap, which\nresamples directly from the observed data. However, a residual bootstrap that\nexplicitly exploits the assumed causal structure (X->M->Y) could also be\napplied. There is also a debate whether the bias-corrected (BC) bootstrap\nmethod is superior to the percentile method, with the former showing liberal\nbehavior (actual coverage too low) in certain circumstances. Moreover,\nbootstrap methods tend to be very conservative (coverage higher than required)\nwhen mediation effects are small. Finally, iterated bootstrap methods like the\ndouble bootstrap have not been considered due to their high computational\ndemands. We investigate the issues mentioned in the simple mediation model by a\nlarge-scale simulation. Results are explained using graphical methods and the\nnewly derived finite-sample distribution. The main findings are: (i)\nconservative behavior of the bootstrap is caused by extreme dependence of the\nbootstrap distribution's shape on the estimated coefficients (ii) this\ndependence leads to counterproductive correction of the the double bootstrap.\nThe added randomness of the BC method inflates the coverage in the absence of\nmediation, but still leads to (invalid) liberal inference when the mediation\neffect is small.",
    "pdf_url": "http://arxiv.org/pdf/2412.11285v1",
    "published": "2024-12-15T19:15:29+00:00",
    "categories": [
      "econ.EM"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2412.11284v1",
    "title": "Learning Normal Flow Directly From Event Neighborhoods",
    "authors": [
      "Dehao Yuan",
      "Levi Burner",
      "Jiayi Wu",
      "Minghui Liu",
      "Jingxi Chen",
      "Yiannis Aloimonos",
      "Cornelia Fermüller"
    ],
    "abstract": "Event-based motion field estimation is an important task. However, current\noptical flow methods face challenges: learning-based approaches, often\nframe-based and relying on CNNs, lack cross-domain transferability, while\nmodel-based methods, though more robust, are less accurate. To address the\nlimitations of optical flow estimation, recent works have focused on normal\nflow, which can be more reliably measured in regions with limited texture or\nstrong edges. However, existing normal flow estimators are predominantly\nmodel-based and suffer from high errors.\n  In this paper, we propose a novel supervised point-based method for normal\nflow estimation that overcomes the limitations of existing event learning-based\napproaches. Using a local point cloud encoder, our method directly estimates\nper-event normal flow from raw events, offering multiple unique advantages: 1)\nIt produces temporally and spatially sharp predictions. 2) It supports more\ndiverse data augmentation, such as random rotation, to improve robustness\nacross various domains. 3) It naturally supports uncertainty quantification via\nensemble inference, which benefits downstream tasks. 4) It enables training and\ninference on undistorted data in normalized camera coordinates, improving\ntransferability across cameras. Extensive experiments demonstrate our method\nachieves better and more consistent performance than state-of-the-art methods\nwhen transferred across different datasets. Leveraging this transferability, we\ntrain our model on the union of datasets and release it for public use.\nFinally, we introduce an egomotion solver based on a maximum-margin problem\nthat uses normal flow and IMU to achieve strong performance in challenging\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2412.11284v1",
    "published": "2024-12-15T19:09:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11283v2",
    "title": "Cyclic polytopes through the lens of iterated integrals",
    "authors": [
      "Felix Lotter",
      "Rosa Preiß"
    ],
    "abstract": "The volume of a cyclic polytope can be obtained by forming an iterated\nintegral along a suitable piecewise linear path running through its edges.\nDifferent choices of such a path are related by the action of a subgroup of the\ncombinatorial automorphisms of the polytope. Motivated by this observation, we\nlook for other linear combinations of iterated integrals that are invariant\nunder the subgroup action. This yields interesting polynomial attributes of the\ncyclic polytope. We prove that there are infinitely many of these invariants\nwhich are algebraically independent in the shuffle algebra.",
    "pdf_url": "http://arxiv.org/pdf/2412.11283v2",
    "published": "2024-12-15T19:08:29+00:00",
    "categories": [
      "math.RA",
      "math.CO",
      "60L10, 13A50, 52B05"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11282v1",
    "title": "A New Census of the Universe's Entropy",
    "authors": [
      "Stefano Profumo",
      "Liam Colombo-Murphy",
      "Gabriela Huckabee",
      "Maya Diaz Svensson",
      "Stuti Garg",
      "Ishan Kollipara",
      "Alison Weber"
    ],
    "abstract": "The question of what is the total entropy of the universe, how it compares to\nthe maximal entropy of de Sitter space, and how it is distributed across the\nuniverse's components, bears considerable importance for a number of reasons.\nHere, we first update the computation of the entropy associated with various\nsectors of the observed universe, including in the diffuse cosmic and late-time\ngamma-ray and neutrino backgrounds, in baryonic matter both in diffuse\ncomponents, in stars and stellar remnants, and in cosmic rays; we then update,\ncrucially, the estimate of entropy in stellar-mass and super-massive black\nholes, whose abundance and mass function has come into increasingly sharp\ndefinition with recent observations and with the rapidly growing statistics of\nblack-hole-black-hole mergers observed with gravity wave detectors. We also\nprovide a new, corrected estimate of the potential entropy associated with a\nstochastic gravitational wave background, with dark sector radiations, and with\nseveral dark matter models. Finally, we utilize the similarly recently updated\nconstraints on the abundance of hypothetical primordial black holes - black\nholes, that is, of non-stellar origin - to assess the maximal amount entropy\nthey could store. We find that if supermassive primordial black holes exist,\nthey can dominate the entropy budget of the universe consistently with current\nconstraints on their abundance and mass function, to a level potentially not\ndistant from the posited entropy associated with the cosmic event horizon of de\nSitter spacetime. The same conclusion holds for certain dark sector models\nfeaturing a large number of dark degrees of freedom.",
    "pdf_url": "http://arxiv.org/pdf/2412.11282v1",
    "published": "2024-12-15T19:07:22+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11281v2",
    "title": "Budget-optimal multi-robot layout design for box sorting",
    "authors": [
      "Peiyu Zeng",
      "Yijiang Huang",
      "Simon Huber",
      "Stelian Coros"
    ],
    "abstract": "Robotic systems are routinely used in the logistics industry to enhance\noperational efficiency, but the design of robot workspaces remains a complex\nand manual task, which limits the system's flexibility to changing demands.\nThis paper aims to automate robot workspace design by proposing a computational\nframework to generate a budget-minimizing layout by selectively placing\nstationary robots on a floor grid to sort packages from given input and output\nlocations. Finding a good layout that minimizes the hardware budget while\nensuring motion feasibility is a challenging combinatorial problem with\nnonconvex motion constraints. We propose a new optimization-based approach that\nmodels layout planning as a subgraph optimization problem subject to network\nflow constraints. Our core insight is to abstract away motion constraints from\nthe layout optimization by precomputing a kinematic reachability graph and then\nextract the optimal layout on this ground graph. We validate the motion\nfeasibility of our approach by proposing a simple task assignment and motion\nplanning technique. We benchmark our algorithm on problems with various grid\nresolutions and number of outputs and show improvements in memory efficiency\nover a heuristic search algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2412.11281v2",
    "published": "2024-12-15T19:05:26+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11280v3",
    "title": "Fabrication of low-loss Josephson parametric devices",
    "authors": [
      "K. E. Honasoge",
      "M. Handschuh",
      "W. K. Yam",
      "S. Gandorfer",
      "D. Bazulin",
      "N. Bruckmoser",
      "L. Koch",
      "A. Marx",
      "R. Gross",
      "K. G. Fedorov"
    ],
    "abstract": "Superconducting circuits incorporating Josephson elements represent a\npromising hardware platform for quantum technologies. Potential applications\ninclude scalable quantum computing, microwave quantum networks, and\nquantum-limited amplifiers. However, progress in Josephson junction-based\nquantum technologies is facing the ongoing challenge of minimizing loss\nchannels. This is also true for parametric superconducting devices based on\nnonlinear Josephson resonators. In this work, we report on the fabrication and\ncharacterization of low-loss Josephson parametric devices operated in the GHz\nfrequency range, showing record internal quality factors. Specifically, we\nachieve internal quality factors $Q_\\mathrm{int}$ significantly exceeding\n$10^5$ for both Josephson parametric converters and Josephson parametric\namplifiers in the single-photon regime by fitting the scattering data. We\nconfirm the extracted $Q_\\mathrm{int}$ values by analyzing purity of squeezed\nvacuum states generated by these devices. These low-loss devices mark a\nsignificant step forward in realizing high-performance quantum circuits,\nenabling further advancements in superconducting quantum technologies.",
    "pdf_url": "http://arxiv.org/pdf/2412.11280v3",
    "published": "2024-12-15T19:04:09+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.supr-con"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11279v1",
    "title": "VividFace: A Diffusion-Based Hybrid Framework for High-Fidelity Video Face Swapping",
    "authors": [
      "Hao Shao",
      "Shulun Wang",
      "Yang Zhou",
      "Guanglu Song",
      "Dailan He",
      "Shuo Qin",
      "Zhuofan Zong",
      "Bingqi Ma",
      "Yu Liu",
      "Hongsheng Li"
    ],
    "abstract": "Video face swapping is becoming increasingly popular across various\napplications, yet existing methods primarily focus on static images and\nstruggle with video face swapping because of temporal consistency and complex\nscenarios. In this paper, we present the first diffusion-based framework\nspecifically designed for video face swapping. Our approach introduces a novel\nimage-video hybrid training framework that leverages both abundant static image\ndata and temporal video sequences, addressing the inherent limitations of\nvideo-only training. The framework incorporates a specially designed diffusion\nmodel coupled with a VidFaceVAE that effectively processes both types of data\nto better maintain temporal coherence of the generated videos. To further\ndisentangle identity and pose features, we construct the Attribute-Identity\nDisentanglement Triplet (AIDT) Dataset, where each triplet has three face\nimages, with two images sharing the same pose and two sharing the same\nidentity. Enhanced with a comprehensive occlusion augmentation, this dataset\nalso improves robustness against occlusions. Additionally, we integrate 3D\nreconstruction techniques as input conditioning to our network for handling\nlarge pose variations. Extensive experiments demonstrate that our framework\nachieves superior performance in identity preservation, temporal consistency,\nand visual quality compared to existing methods, while requiring fewer\ninference steps. Our approach effectively mitigates key challenges in video\nface swapping, including temporal flickering, identity preservation, and\nrobustness to occlusions and pose variations.",
    "pdf_url": "http://arxiv.org/pdf/2412.11279v1",
    "published": "2024-12-15T18:58:32+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11278v2",
    "title": "VAR models with an index structure: A survey with new results",
    "authors": [
      "Gianluca Cubadda"
    ],
    "abstract": "The main aim of this paper is to review recent advances in the multivariate\nautoregressive index model [MAI], originally proposed by Reinsel (1983), and\ntheir applications to economic and financial time series. MAI has recently\ngained momentum because it can be seen as a link between two popular but\ndistinct multivariate time series approaches: vector autoregressive modeling\n[VAR] and the dynamic factor model [DFM]. Indeed, on the one hand, the MAI is a\nVAR model with a peculiar reduced-rank structure; on the other hand, it allows\nfor identification of common components and common shocks in a similar way as\nthe DFM. The focus is on recent developments of the MAI, which include\nextending the original model with individual autoregressive structures,\nstochastic volatility, time-varying parameters, high-dimensionality, and\ncointegration. In addition, new insights on previous contributions and a novel\nmodel are also provided.",
    "pdf_url": "http://arxiv.org/pdf/2412.11278v2",
    "published": "2024-12-15T18:55:09+00:00",
    "categories": [
      "econ.EM"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2412.11277v1",
    "title": "Macro2Micro: Cross-modal Magnetic Resonance Imaging Synthesis Leveraging Multi-scale Brain Structures",
    "authors": [
      "Sooyoung Kim",
      "Joonwoo Kwon",
      "Junbeom Kwon",
      "Sangyoon Bae",
      "Yuewei Lin",
      "Shinjae Yoo",
      "Jiook Cha"
    ],
    "abstract": "Spanning multiple scales-from macroscopic anatomy down to intricate\nmicroscopic architecture-the human brain exemplifies a complex system that\ndemands integrated approaches to fully understand its complexity. Yet, mapping\nnonlinear relationships between these scales remains challenging due to\ntechnical limitations and the high cost of multimodal Magnetic Resonance\nImaging (MRI) acquisition. Here, we introduce Macro2Micro, a deep learning\nframework that predicts brain microstructure from macrostructure using a\nGenerative Adversarial Network (GAN). Grounded in the scale-free, self-similar\nnature of brain organization-where microscale information can be inferred from\nmacroscale patterns-Macro2Micro explicitly encodes multiscale brain\nrepresentations into distinct processing branches. To further enhance image\nfidelity and suppress artifacts, we propose a simple yet effective auxiliary\ndiscriminator and learning objective. Our results show that Macro2Micro\nfaithfully translates T1-weighted MRIs into corresponding Fractional Anisotropy\n(FA) images, achieving a 6.8% improvement in the Structural Similarity Index\nMeasure (SSIM) compared to previous methods, while preserving the individual\nneurobiological characteristics.",
    "pdf_url": "http://arxiv.org/pdf/2412.11277v1",
    "published": "2024-12-15T18:49:20+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2412.12209v1",
    "title": "Challenges and Opportunities Associated with Technology Driven Biomechanical Simulations",
    "authors": [
      "Zartasha Mustansar",
      "Haider Ali",
      "Lee Margetts",
      "Saad Ahmad Khan",
      "Salma Sherbaz",
      "Rehan Zafar Paracha"
    ],
    "abstract": "This paper presents the principal challenges and opportunities associated\nwith computational biomechanics research. The underlying cognitive control\ninvolved in the process of human motion is inherently complex, dynamic,\nmultidimensional, and highly non-linear. The dynamics produced by the internal\nand external forces and the body's ability to react to them is biomechanics.\nComplex and non-rigid bodies, needs a lot of computing power and systems to\nexecute however, in the absence of adequate resources, one may rely on new\ntechnology, machine learning tools and model order reduction approaches. It is\nalso believed that machine learning approaches can enable us to embrace this\ncomplexity, if we could use three arms of ML i.e. predictive modeling,\nclassification, and dimensionality reduction. Biomechanics, since it deals with\nmotion and mobility come with a huge set of data over time. Using computational\n(Computer Solvers), Numerical approaches (MOR) and technological advances\n(Wearable sensors), can let us develop computationally inexpensive frameworks\nfor biomechanics focused studies dealing with a huge amount of data. A lot of\nmisunderstanding arises because of extensive data, standardization of the tools\nto process this, database for the material property definitions, validation and\nverification of biomechanical models and analytical tools to model various\nphenomena using computational and modelling techniques. Study of biomechanics\nthrough computational simulations can improve the prevention and treatment of\ndiseases, predict the injury to reduce the risk and hence can strengthen\npivotal sectors like sports and lifestyle. This is why we choose to present all\nthose challenges and problems associated with biomechanical simulation with\ncomplex geometries fail so as to help improve, analysis, performance and design\nfor better lifestyle.",
    "pdf_url": "http://arxiv.org/pdf/2412.12209v1",
    "published": "2024-12-15T18:48:36+00:00",
    "categories": [
      "physics.med-ph",
      "I.6; J.3"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11276v2",
    "title": "Wearable Accelerometer Foundation Models for Health via Knowledge Distillation",
    "authors": [
      "Salar Abbaspourazad",
      "Anshuman Mishra",
      "Joseph Futoma",
      "Andrew C. Miller",
      "Ian Shapiro"
    ],
    "abstract": "Modern wearable devices can conveniently record various biosignals in the\nmany different environments of daily living, enabling a rich view of individual\nhealth. However, not all biosignals are the same: high-fidelity biosignals,\nsuch as photoplethysmogram (PPG), contain more physiological information, but\nrequire optical sensors with a high power footprint. Alternatively, a\nlower-fidelity biosignal such as accelerometry has a significantly smaller\npower footprint and is available in almost any wearable device. While\naccelerometry is widely used for activity recognition and fitness, it is less\nexplored for health biomarkers and diagnosis. Here, we show that an\naccelerometry foundation model can predict a wide variety of health targets. To\nachieve improved performance, we distill representational knowledge from PPG\nencoders to accelerometery encoders using 20 million minutes of unlabeled data,\ncollected from ~172K participants in the Apple Heart and Movement Study under\ninformed consent. We observe strong cross-modal alignment on unseen data, e.g.,\n99.2% top-1 accuracy for retrieving PPG embeddings from accelerometry\nembeddings. We show that distilled accelerometry encoders have significantly\nmore informative representations compared to self-supervised or supervised\nencoders trained directly on accelerometry data, observed by at least 23%-49%\nimproved performance for predicting heart rate and heart rate variability. We\nalso show that distilled accelerometry encoders are readily predictive of a\nwide array of downstream health targets, i.e., they are generalist foundation\nmodels. We believe accelerometry foundation models for health may unlock new\nopportunities for developing digital biomarkers from any wearable device.",
    "pdf_url": "http://arxiv.org/pdf/2412.11276v2",
    "published": "2024-12-15T18:48:14+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11275v1",
    "title": "Adaptive Visual Perception for Robotic Construction Process: A Multi-Robot Coordination Framework",
    "authors": [
      "Jia Xu",
      "Manish Dixit",
      "Xi Wang"
    ],
    "abstract": "Construction robots operate in unstructured construction sites, where\neffective visual perception is crucial for ensuring safe and seamless\noperations. However, construction robots often handle large elements and\nperform tasks across expansive areas, resulting in occluded views from onboard\ncameras and necessitating the use of multiple environmental cameras to capture\nthe large task space. This study proposes a multi-robot coordination framework\nin which a team of supervising robots equipped with cameras adaptively adjust\ntheir poses to visually perceive the operation of the primary construction\nrobot and its surrounding environment. A viewpoint selection method is proposed\nto determine each supervising robot's camera viewpoint, optimizing visual\ncoverage and proximity while considering the visibility of the upcoming\nconstruction robot operation. A case study on prefabricated wooden frame\ninstallation demonstrates the system's feasibility, and further experiments are\nconducted to validate the performance and robustness of the proposed viewpoint\nselection method across various settings. This research advances visual\nperception of robotic construction processes and paves the way for integrating\ncomputer vision techniques to enable real-time adaption and responsiveness.\nSuch advancements contribute to the safe and efficient operation of\nconstruction robots in inherently unstructured construction sites.",
    "pdf_url": "http://arxiv.org/pdf/2412.11275v1",
    "published": "2024-12-15T18:41:34+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11274v2",
    "title": "Spin-Transfer Torque in Altermagnets with Magnetic Textures",
    "authors": [
      "Hamed Vakili",
      "Edward Schwartz",
      "Alexey A. Kovalev"
    ],
    "abstract": "We predict the existence of anisotropic spin-transfer torque effect in\ntextured altermagnets. To this end, we generalize the Zhang-Li torque to\nincorporate the symmetry associated with prototypical $d$-wave altermagnets and\nidentify the spin-splitter adiabatic and nonadiabatic torques. Applying our\nresults to domain wall dynamics induced by spin-transfer torque, we find that,\nin certain regimes, the spin-splitter adiabatic torque can induce domain wall\nprecession, significantly slowing down domain wall motion. The response of the\ndomain wall also becomes anisotropic, reflecting the $d$-wave symmetry of the\naltermagnet. Furthermore, we observe that the spin-splitter adiabatic torque\nmodifies skyrmion dynamics, inducing anisotropic skyrmion Hall effect. The\nabove phenomena can serve as a hallmark of altermagnetism in textured magnets,\ndistinguishing it from the behavior of ordinary antiferromagnets.",
    "pdf_url": "http://arxiv.org/pdf/2412.11274v2",
    "published": "2024-12-15T18:36:37+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2412.11273v2",
    "title": "NuSTAR broadband X-ray observation of EF Eri following its reawakening into a high accretion state",
    "authors": [
      "Luke W. Filor",
      "Kaya Mori",
      "Gabriel Bridges",
      "Charles J. Hailey",
      "David A. H. Buckley",
      "Gavin Ramsay",
      "Axel D. Schwope",
      "Valery F. Suleimanov",
      "Michael T. Wolff",
      "Kent S. Wood"
    ],
    "abstract": "We present the first NuSTAR X-ray observation of EF Eri, a well-known polar\nsystem. The NuSTAR observation was conducted in conjunction with NICER, shortly\nafter EF Eri entered a high accretion state following an unprecedented period\nof low activity lasting 26 years since 1997. NuSTAR detected hard X-ray\nemission up to 50 keV with an X-ray flux of $1.2\\times10^{-10}$ ergs s$^{-1}$\ncm$^{-2}$ ($3\\rm{-}50$ keV). Folded X-ray lightcurves exhibit a single peak\nwith $\\sim65\\%$ spin modulation throughout the $3\\rm{-}50$ keV band. We found\nno evidence of QPO signals at $\\nu = 0.1\\rm{-}100$ Hz with an upper limit on\nthe QPO amplitude below $5\\%$ ($90\\%$ CL) at $\\nu \\sim 0.5$ Hz where the\noptical QPO was previously detected. Our 1-D accretion column model, called\n$\\texttt{MCVSPEC}$, was fitted to the NuSTAR spectral data, yielding an\naccurate WD mass measurement of $M = (0.55\\rm{-}0.63) M_\\odot$. ${\\tt MCVSPEC}$\naccounts for radiative cooling by thermal bremsstrahlung and cyclotron\nemission, X-ray reflection off the WD surface, and a previously constrained\nrange of the accretion column area. The derived WD mass range is in excellent\nagreement with the previous measurement of $M = (0.55\\rm{-}0.65) M_\\odot$ in\nthe optical band. This demonstrates a combination of broadband X-ray spectral\nanalysis and the ${\\tt MCVSPEC}$ model that can be employed in our ongoing\nNuSTAR observation campaign of other polars to determine their WD masses\naccurately.",
    "pdf_url": "http://arxiv.org/pdf/2412.11273v2",
    "published": "2024-12-15T18:36:11+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2412.13218v1",
    "title": "The quantum electromagnetic field in the Weyl-Wigner representation",
    "authors": [
      "Emilio Santos"
    ],
    "abstract": "The quantum electromagnetic (EM) field is formulated in the Weyl-Wigner\nrepresentation (WW), which is equivalent to the standard Hilbert space one\n(HS). In principle it is possible to interpret within WW all experiments\ninvolving the EM field interacting with macroscopic bodies, the latter treated\nclassically. In the WW formalism the essential difference between classical\nelectrodynamics and the quantum theory of the EM field is\\ just the assumption\nthat there is a random EM field filling space\\QTR{it}{, }i.e. the existence of\na zero-point field with a Gaussian distribution for the field amplitudes. I\nanalyze a typical optical test of a Bell inequality. The model admits an\ninterpretation compatible with local realism, modulo a number of assumptions\nassumed plausible.",
    "pdf_url": "http://arxiv.org/pdf/2412.13218v1",
    "published": "2024-12-15T18:29:15+00:00",
    "categories": [
      "physics.gen-ph"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11272v2",
    "title": "WhisperFlow: speech foundation models in real time",
    "authors": [
      "Rongxiang Wang",
      "Zhiming Xu",
      "Felix Xiaozhu Lin"
    ],
    "abstract": "Speech foundation models, such as OpenAI's Whisper, become the state of the\nart in speech understanding due to their strong accuracy and generalizability.\nYet, their applications are mostly limited to processing pre-recorded speech,\nwhereas processing of streaming speech, in particular doing it efficiently,\nremains rudimentary. Behind this inefficiency are multiple fundamental reasons:\n(1) speech foundation models are trained to process long, fixed-length voice\ninputs (often 30 seconds); (2) encoding each voice input requires encoding as\nmany as 1,500 tokens with tens of transformer layers; (3) decoding each output\nentails an irregular, complex beam search. As such, streaming speech processing\non resource-constrained client devices is more expensive than other AI tasks,\ne.g., text generation.\n  To this end, we present a novel framework, WhisperFlow, which embodies both\nmodel and system optimizations. (1) Hush word as a short, learnable audio\nsegment; appended to a voice input, a hush word gracefully stops the speech\nmodel from processing more input without hallucination; (2) Beam pruning, which\naligns streaming audio buffers over time and reuses results from earlier\ndecoding rounds, therefore significantly accelerating decoding; and (3) CPU/GPU\npipelining, which not only maps to the encoding/decoding stages dynamically,\nbut also tunes to an optimal resource ratio, respecting the encoding/decoding\nspeed that varies across voice inputs, models, and hardware.\n  We test WhisperFlow on commodity ARM platforms with 4-12 CPU cores and 10-30\nGPU cores. It reduces per-word latency by 1.6x-4.7x to as low as 0.5 second,\nwhile seeing negligible accuracy degradation. On an entry-level MacBook Air,\nWhisperFlow can keep the per-word latency around 1 second, with the whole\ndevice drawing only 7 Watts in total.",
    "pdf_url": "http://arxiv.org/pdf/2412.11272v2",
    "published": "2024-12-15T18:27:37+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2412.11271v1",
    "title": "Timing of Seven Isolated Pulsars in the Globular Cluster Terzan 1",
    "authors": [
      "Justine Singleton",
      "Megan DeCesar",
      "Shi Dai",
      "Deven Bhakta",
      "Scott Ransom",
      "Jay Strader",
      "Laura Chomiuk",
      "James Miller-Jones"
    ],
    "abstract": "Globular clusters host large populations of millisecond pulsars (MSPs) due to\ntheir high gravitational encounter rates, producing many binary systems and\nthus MSPs via the recycling process. Seven pulsars with spin periods ranging\nfrom 3 ms to 134 ms have been discovered in Terzan 1, which was targeted for\npulsar searches with the Green Bank Telescope after Australia Telescope Compact\nArray imaging revealed steep-spectrum point sources in the cluster core. We\nhave obtained timing observations over seven years, for the first seven Green\nBank Telescope (GBT) discoveries (Terzan 1 A through G), using the GBT and\nMurriyang, CSIRO's Parkes radio telescope. All seven pulsars are isolated,\nconsistent with Terzan 1's classification as a core-collapsed cluster (core\ncollapse is predicted to disrupt, or ionize, binaries). With these timing\nsolutions, we measured the positions and observed period derivatives, dP/dt,\nfor each pulsar. The measured dP/dt values are composed of intrinsic spin-down\nand accelerations experienced by the pulsars (primarily from the cluster's\ngravitational potential), and they can be used to infer line-of-sight\naccelerations. We attempted to constrain the radius and density of the cluster\ncore using these inferred accelerations. A wide range of radii and densities\nare possible, pointing to the need for continued timing as well as new\ndiscoveries to better constrain these cluster properties. We additionally find\nthat Ter 1 A may be younger than the cluster and thus may have formed via a\nformation channel other than a core-collapse supernova. Theoretical formation\nmechanisms such as electron-capture supernovae from accretion- or\nmerger-induced collapse of white dwarfs could potentially explain these\npulsars' origins. It may therefore be a member of a small but growing class of\nglobular cluster pulsars that appear to be significantly younger than their\nhost clusters.",
    "pdf_url": "http://arxiv.org/pdf/2412.11271v1",
    "published": "2024-12-15T18:26:48+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11270v1",
    "title": "Monte Carlo Tree Search with Spectral Expansion for Planning with Dynamical Systems",
    "authors": [
      "Benjamin Riviere",
      "John Lathrop",
      "Soon-Jo Chung"
    ],
    "abstract": "The ability of a robot to plan complex behaviors with real-time computation,\nrather than adhering to predesigned or offline-learned routines, alleviates the\nneed for specialized algorithms or training for each problem instance. Monte\nCarlo Tree Search is a powerful planning algorithm that strategically explores\nsimulated future possibilities, but it requires a discrete problem\nrepresentation that is irreconcilable with the continuous dynamics of the\nphysical world. We present Spectral Expansion Tree Search (SETS), a real-time,\ntree-based planner that uses the spectrum of the locally linearized system to\nconstruct a low-complexity and approximately equivalent discrete representation\nof the continuous world. We prove SETS converges to a bound of the globally\noptimal solution for continuous, deterministic and differentiable Markov\nDecision Processes, a broad class of problems that includes underactuated\nnonlinear dynamics, non-convex reward functions, and unstructured environments.\nWe experimentally validate SETS on drone, spacecraft, and ground vehicle robots\nand one numerical experiment, each of which is not directly solvable with\nexisting methods. We successfully show SETS automatically discovers a diverse\nset of optimal behaviors and motion trajectories in real time.",
    "pdf_url": "http://arxiv.org/pdf/2412.11270v1",
    "published": "2024-12-15T18:24:26+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11269v1",
    "title": "Quantum Mechanics of Arc-Sine and Semi-Circle Distributions: A Unified Approach",
    "authors": [
      "Luigi Accardi",
      "Tarek Hamdi",
      "Yun Gang Lu"
    ],
    "abstract": "This paper continues the program of applying beyond physics the technique of\n\\textbf{probabilistic quantization} and extending to the quantum mechanics\nassociated with the arc--sine distributions our previous results on the\nsemi--circle distribution. We derive analytical expressions for the momentum\nand kinetic energy operators using the arc--sine weighted Hilbert transform and\nexpress corresponding evolutions as Neumann series of Bessel functions. These\nseries are applicable in various physical problems and in solving certain mixed\ndifference equations and differential equations. Moreover, exploiting the\nsimilarity between the Jacobi sequences of the semi-circle and arc-sine\nmeasures, we establish a unified formulation of their quantum mechanics. We\nintroduce the semicircle and arc--sine exponential vectors and the\ncorresponding coherent states and prove that, for both measures, the vacuum\ndistributions of the number operator in these states (arc--sine photon\nstatistics) are a \\textit{perturbation} of the geometric distribution (Gibbs\nstates in Boson physics: see the Introduction below for a discussion of the\nphysical meaning of this perturbation). The $*$--Lie algebra generated by\ncanonical creation and annihilation operators of both probability measures is\nisomorphic to the $*$--Lie algebra generated by all rank-one operators in\ncorresponding $L^2$-spaces. The paper concludes with appendices that discuss\nthe integral and Neumann series representations of the $1$--parameter unitary\ngroups generated by momentum in semi-circle and arc-sine cases.",
    "pdf_url": "http://arxiv.org/pdf/2412.11269v1",
    "published": "2024-12-15T18:15:54+00:00",
    "categories": [
      "math-ph",
      "math.FA",
      "math.MP",
      "math.OA",
      "81S05, 42A50"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11268v1",
    "title": "Complex investigations of an active star-formation region in southern part of Mon R2",
    "authors": [
      "T. A. Movsessian",
      "J. Bally",
      "T. Yu. Magakian",
      "A. V. Moiseev"
    ],
    "abstract": "We continue to present the results of a Byurakan Narrow Band Imaging Survey\n(BNBIS). In this work we present the results of the search and further detailed\ninvestigation of the objects, found in the course of the BNBIS survey in the\nsouthern part of the Mon R2 association. For the search of HH objects the\nnarrow band images, obtained with the 1-m Schmidt telescope of the Byurakan\nObservatory, were used. Newly found objects were imaged in optical and near-IR\nrange with the Apache Point Observatory 3.5 meter telescope, and observed\nspectrally with long-slit spectrograph and scanning Fabry-Perot interferometer\non 6 m telescope of Special Astrophysical Observatory of the Russian Academy of\nSciences using SCORPIO-2. We found three new HH groups: HH 1233, HH 1234 and HH\n1235, two of them represent extended collimated flows. HH 1233 is the C-shape\nbipolar outflow system associated with the 2MASS 06084223$-$0657385 source\nstar. HH 1234 is the helical chain of HH knots near the star V963 Mon. HH 1235\nis a separate compact knot, connected with the visible only in mid- and far-IR\nsource WISE J060856.57$-$070103.5. We found also several molecular hydrogen\noutflows, one of which coincides with HH 1233 and two other are associated with\nthe deeply embedded IR sources in the same field. One more probable bipolar\nH$_2$ outflow is related to WISE J060856.57$-$070103.5. The emission spectra\nand spectral energy distributions of the source stars were analyzed. According\nto them they should be under rather early evolutional stage.",
    "pdf_url": "http://arxiv.org/pdf/2412.11268v1",
    "published": "2024-12-15T18:15:43+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11267v1",
    "title": "P3LS: Point Process Partial Least Squares",
    "authors": [
      "Jamshid Namdari",
      "Robert T Krafty",
      "Amita K Manatunga"
    ],
    "abstract": "Many studies collect data that can be considered as a realization of a point\nprocess. Included are medical imaging data where photon counts are recorded by\na gamma camera from patients being injected with a gamma emitting tracer. It is\nof interest to develop analytic methods that can help with diagnosis as well as\nin the training of inexpert radiologists. Partial least squares (PLS) is a\npopular analytic approach that combines features from linear modeling as well\nas dimension reduction to provide parsimonious prediction and classification.\nHowever, existing PLS methodologies do not include the analysis of point\nprocess predictors. In this article, we introduce point process PLS (P3LS) for\nanalyzing latent time-varying intensity functions from collections of\ninhomogeneous point processes. A novel estimation procedure for $P^3LS$ is\ndeveloped that utilizes the properties of log-Gaussian Cox processes, and its\nempirical properties are examined in simulation studies. The method is used to\nanalyze kidney functionality in patients with renal disease in order to aid in\nthe diagnosis of kidney obstruction.",
    "pdf_url": "http://arxiv.org/pdf/2412.11267v1",
    "published": "2024-12-15T18:11:55+00:00",
    "categories": [
      "stat.ME",
      "stat.AP",
      "62-M10, 62P10, 62H25, 62R10"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2412.11266v1",
    "title": "Bayesian inference of mean velocity fields and turbulence models from flow MRI",
    "authors": [
      "A. Kontogiannis",
      "P. Nair",
      "M. Loecher",
      "D. B. Ennis",
      "A. Marsden",
      "M. P. Juniper"
    ],
    "abstract": "We solve a Bayesian inverse Reynolds-averaged Navier-Stokes (RANS) problem\nthat assimilates mean flow data by jointly reconstructing the mean flow field\nand learning its unknown RANS parameters. We devise an algorithm that learns\nthe most likely parameters of an algebraic effective viscosity model, and\nestimates their uncertainties, from mean flow data of a turbulent flow. We\nconduct a flow MRI experiment to obtain mean flow data of a confined turbulent\njet in an idealized medical device known as the FDA (Food and Drug\nAdministration) nozzle. The algorithm successfully reconstructs the mean flow\nfield and learns the most likely turbulence model parameters without\noverfitting. The methodology accepts any turbulence model, be it algebraic\n(explicit) or multi-equation (implicit), as long as the model is\ndifferentiable, and naturally extends to unsteady turbulent flows.",
    "pdf_url": "http://arxiv.org/pdf/2412.11266v1",
    "published": "2024-12-15T18:07:36+00:00",
    "categories": [
      "physics.flu-dyn",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2412.11265v1",
    "title": "Symplectization of certain Hamiltonian systems in fibered almost-symplectic manifolds",
    "authors": [
      "Francesco Fassò",
      "Nicola Sansonetto"
    ],
    "abstract": "There is an important difference between Hamiltonian-like vector fields in an\nalmost-symplectic manifold $(M,\\sigma)$, compared to the standard case of a\nsymplectic manifold: in the almost-symplectic case, a vector field such that\nthe contraction iX{\\sigma} is closed need not be a symmetry of $\\sigma$. We\nthus call partially-Hamiltonian those vector fields which have the former\nproperty and fully-Hamiltonian those which have both properties. We consider\n2n-dimensional almost symplectic manifolds with a fibration $\\pi : M\n\\longrightarrow B$ by Lagrangian tori. Trivially, all vertical\npartially-Hamiltonian vector fields are fully-Hamiltonian. We investigate the\nexistence and the properties of non-vertical fully-Hamiltonian vector fields.\nWe show that this class is non-empty, but under certain genericity conditions\nthat involve the Fourier spectrum of their Hamiltonian, these vector fields\nreduce, under a (possibly only semi-globally defined, if $n \\ge 4$) torus\naction, to families of standard symplectic-Hamiltonian vector fields.",
    "pdf_url": "http://arxiv.org/pdf/2412.11265v1",
    "published": "2024-12-15T18:02:45+00:00",
    "categories": [
      "math.SG",
      "math.DG",
      "math.DS",
      "nlin.SI",
      "53D15, 37J40, 70H08"
    ],
    "primary_category": "math.SG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11264v2",
    "title": "Simulation of square-root processes made simple: applications to the Heston model",
    "authors": [
      "Eduardo Abi Jaber"
    ],
    "abstract": "We introduce a simple, efficient and accurate nonnegative preserving\nnumerical scheme for simulating the square-root process. The novel idea is to\nsimulate the integrated square-root process first instead of the square-root\nprocess itself. Numerical experiments on realistic parameter sets, applied for\nthe integrated process and the Heston model, display high precision with a very\nlow number of time steps. As a bonus, our scheme yields the exact limiting\nInverse Gaussian distributions of the integrated square-root process with only\none single time-step in two scenarios: (i) for high mean-reversion and\nvolatility-of-volatility regimes, regardless of maturity; and (ii) for long\nmaturities, independent of the other parameters.",
    "pdf_url": "http://arxiv.org/pdf/2412.11264v2",
    "published": "2024-12-15T17:58:23+00:00",
    "categories": [
      "q-fin.MF",
      "q-fin.CP"
    ],
    "primary_category": "q-fin.MF"
  },
  {
    "id": "http://arxiv.org/abs/2412.11263v1",
    "title": "Twist-Induced Beam Steering and Blazing Effects in Photonic Crystal Devices",
    "authors": [
      "Nicolas Roy",
      "Beicheng Lou",
      "Shanhui Fan",
      "Alexandre Mayer",
      "Michaël Lobet"
    ],
    "abstract": "Twisted bilayer photonic crystals introduce a twist between two stacked\nphotonic crystal slabs, enabling strong modulation of their electromagnetic\nproperties. The change in the twist angle strongly influences the resonant\nfrequencies and available propagating diffraction orders with applications\nincluding sensing, lasing, slow light or wavefront engineering. In this work,\nwe design and analyze twisted bilayer crystals capable of steering light in a\ndirection controlled by the twist angle. In order to achieve beam steering, the\ndevice efficiently routes input power into a single, twist-dependent,\ntransmitted diffraction order. The outgoing light then follows the orientation\nof this diffraction order, externally controlled by the twist angle. The\noptimization is performed using high-efficiency heuristic optimization method\nwhich enabled a data-oriented approach to further understand the design\noperation. The optimized device demonstrates an efficiency above 90% across\ntwist angles ranging from 0 to 30 degrees for both TE and TM polarizations.\nExtending the optimization to include left- and right-handed polarizations\nyields overall accuracy nearing 90% when averaged across the entire 0 to 60\ndegrees control range. Finally, we show how the device resembles blazed\ngratings by effectively canceling the undesired diffraction orders. The\noptimized devices exhibit a shared slant dependent on the selected diffraction\norder. Our analysis is supported by a structural blazing model arising from the\ndata-oriented statistical analysis.",
    "pdf_url": "http://arxiv.org/pdf/2412.11263v1",
    "published": "2024-12-15T17:56:07+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2501.05456v1",
    "title": "LLM Based Input Space Partitioning Testing for Library APIs",
    "authors": [
      "Jiageng Li",
      "Zhen Dong",
      "Chong Wang",
      "Haozhen You",
      "Cen Zhang",
      "Yang Liu",
      "Xin Peng"
    ],
    "abstract": "Automated library APIs testing is difficult as it requires exploring a vast\nspace of parameter inputs that may involve objects with complex data types.\nExisting search based approaches, with limited knowledge of relations between\nobject states and program branches, often suffer from the low efficiency issue,\ni.e., tending to generate invalid inputs. Symbolic execution based approaches\ncan effectively identify such relations, but fail to scale to large programs.\nIn this work, we present an LLM-based input space partitioning testing\napproach, LISP, for library APIs. The approach leverages LLMs to understand the\ncode of a library API under test and perform input space partitioning based on\nits understanding and rich common knowledge. Specifically, we provide the\nsignature and code of the API under test to LLMs, with the expectation of\nobtaining a text description of each input space partition of theAPI under\ntest. Then, we generate inputs through employing the generated text description\nto sample inputs from each partition, ultimately resulting in test suites that\nsystematically explore the program behavior of the API. We evaluate LISP on\nmore than 2,205 library API methods taken from 10 popular open-source Java\nlibraries (e.g.,apache/commonslang with 2.6k stars, guava with 48.8k stars on\nGitHub). Our experiment results show that LISP is effective in library API\ntesting. It significantly outperforms state-of-the-art tool EvoSuite in terms\nof edge coverage. On average, LISP achieves 67.82% branch coverage, surpassing\nEvoSuite by 1.21 times. In total, LISP triggers 404 exceptions or errors in the\nexperiments, and discovers 13 previously unknown vulnerabilities during\nevaluation, which have been assigned CVE IDs.",
    "pdf_url": "http://arxiv.org/pdf/2501.05456v1",
    "published": "2024-12-15T17:50:50+00:00",
    "categories": [
      "cs.SE",
      "cs.CR",
      "D.2.5"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11262v1",
    "title": "Numerical Simulation of Polarized Light and Temperature in a Stratified Atmosphere with a Slowly Varying Refractive Index",
    "authors": [
      "Olivier Pironneau"
    ],
    "abstract": "This article is an attempt to elucidate the effect of a slowly varying\nrefractive index on the temperature in a stratified atmosphere, with a\nparticular focus on greenhouse gases such as CO2. It validates an iterative\nmethod for the vector radiative transfer equations (VVRTE) called Iterations on\nthe Source. As the system proposed by Chandrasekhar and Pomraning is not well\nposed for all rays directions when the refractive index varies, so instead we\nsolve an integral representation of VRTE without the problematic rays. A\nmathematical proof is given showing monotonicity, convergence of the iterations\nand existence and uniqueness. Furthermore the convergence is geometric if the\nabsorption is not too large. Some numerical tests are performed showing the\neffect of a layer of cloud with a refractive index greater than air,\npolarisation and scattering.",
    "pdf_url": "http://arxiv.org/pdf/2412.11262v1",
    "published": "2024-12-15T17:50:33+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11261v1",
    "title": "CATER: Leveraging LLM to Pioneer a Multidimensional, Reference-Independent Paradigm in Translation Quality Evaluation",
    "authors": [
      "Kurando IIDA",
      "Kenjiro MIMURA"
    ],
    "abstract": "This paper introduces the Comprehensive AI-assisted Translation Edit Ratio\n(CATER), a novel and fully prompt-driven framework for evaluating machine\ntranslation (MT) quality. Leveraging large language models (LLMs) via a\ncarefully designed prompt-based protocol, CATER expands beyond traditional\nreference-bound metrics, offering a multidimensional, reference-independent\nevaluation that addresses linguistic accuracy, semantic fidelity, contextual\ncoherence, stylistic appropriateness, and information completeness. CATER's\nunique advantage lies in its immediate implementability: by providing the\nsource and target texts along with a standardized prompt, an LLM can rapidly\nidentify errors, quantify edit effort, and produce category-level and overall\nscores. This approach eliminates the need for pre-computed references or\ndomain-specific resources, enabling instant adaptation to diverse languages,\ngenres, and user priorities through adjustable weights and prompt\nmodifications. CATER's LLM-enabled strategy supports more nuanced assessments,\ncapturing phenomena such as subtle omissions, hallucinations, and\ndiscourse-level shifts that increasingly challenge contemporary MT systems. By\nuniting the conceptual rigor of frameworks like MQM and DQF with the\nscalability and flexibility of LLM-based evaluation, CATER emerges as a\nvaluable tool for researchers, developers, and professional translators\nworldwide. The framework and example prompts are openly available, encouraging\ncommunity-driven refinement and further empirical validation.",
    "pdf_url": "http://arxiv.org/pdf/2412.11261v1",
    "published": "2024-12-15T17:45:34+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11260v1",
    "title": "Observational constraints on entropic cosmology",
    "authors": [
      "Javier Chagoya",
      "I. Díaz-Saldaña",
      "Mario H. Amante",
      "J. C. López-Domínguez",
      "M. Sabido"
    ],
    "abstract": "In this work, we derive a generalized modified Friedmann equation based on an\nentropy-area relation that incorporates established modifications, such as\nvolumetric, linear, and logarithmic terms, in addition to novel entropic\nmodifications that might yield to relevant cosmological implications at\ndifferent stages of the evolution of the Universe. Some of these modifications\nare capable of mimicking the effects of dark energy and describing the current\nstate of accelerated expansion of the Universe. We study particular cases of\nthe generalized Friedmann equation and constrain the free parameters using\nobservational datasets, including Hubble parameter measurements, baryon\nacoustic oscillations, and strong lensing systems. Our findings indicate that\nthe proposed models align well with current observational data, particularly in\nlow-redshift regimes; furthermore, these models are compatible with the value\nof $H_0$ obtained by the SH0ES program.",
    "pdf_url": "http://arxiv.org/pdf/2412.11260v1",
    "published": "2024-12-15T17:44:51+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2412.11259v1",
    "title": "Navigating through Economic Complexity: Phase Diagrams & Parameter Sloppiness",
    "authors": [
      "Jean-Philippe Bouchaud"
    ],
    "abstract": "We argue that establishing the phase diagram of Agent Based Models (ABM) is a\ncrucial first step, together with a qualitative understanding of how collective\nphenomena come about, before any calibration or more quantitative predictions\nare attempted. Computer-aided *gedanken* experiments are by themselves of\ngenuine value: if we are not able to make sense of emergent phenomena in a\nworld in which we set all the rules, how can we expect to be successful in the\nreal world? ABMs indeed often reveal the existence of Black Swans/Dark Corners\ni.e. discontinuity lines beyond which runaway instabilities appear, whereas\nmost classical economic/finance models are blind to such scenarii. Testing for\nthe overall robustness of the phase diagram against changes in heuristic rules\nis a way to ascertain the plausibility of such scenarii. Furthermore, exploring\nthe phase diagrams of ABM in high dimensions should benefit enormously from the\nidentification of ``stiff'' and ``sloppy'' directions in parameter space.",
    "pdf_url": "http://arxiv.org/pdf/2412.11259v1",
    "published": "2024-12-15T17:44:35+00:00",
    "categories": [
      "econ.TH",
      "cond-mat.stat-mech"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2412.11258v1",
    "title": "GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs",
    "authors": [
      "Xinli Xu",
      "Wenhang Ge",
      "Dicong Qiu",
      "ZhiFei Chen",
      "Dongyu Yan",
      "Zhuoyun Liu",
      "Haoyu Zhao",
      "Hanfeng Zhao",
      "Shunsi Zhang",
      "Junwei Liang",
      "Ying-Cong Chen"
    ],
    "abstract": "Estimating physical properties for visual data is a crucial task in computer\nvision, graphics, and robotics, underpinning applications such as augmented\nreality, physical simulation, and robotic grasping. However, this area remains\nunder-explored due to the inherent ambiguities in physical property estimation.\nTo address these challenges, we introduce GaussianProperty, a training-free\nframework that assigns physical properties of materials to 3D Gaussians.\nSpecifically, we integrate the segmentation capability of SAM with the\nrecognition capability of GPT-4V(ision) to formulate a global-local physical\nproperty reasoning module for 2D images. Then we project the physical\nproperties from multi-view 2D images to 3D Gaussians using a voting strategy.\nWe demonstrate that 3D Gaussians with physical property annotations enable\napplications in physics-based dynamic simulation and robotic grasping. For\nphysics-based dynamic simulation, we leverage the Material Point Method (MPM)\nfor realistic dynamic simulation. For robot grasping, we develop a grasping\nforce prediction strategy that estimates a safe force range required for object\ngrasping based on the estimated physical properties. Extensive experiments on\nmaterial segmentation, physics-based dynamic simulation, and robotic grasping\nvalidate the effectiveness of our proposed method, highlighting its crucial\nrole in understanding physical properties from visual data. Online demo, code,\nmore cases and annotated datasets are available on\n\\href{https://Gaussian-Property.github.io}{this https URL}.",
    "pdf_url": "http://arxiv.org/pdf/2412.11258v1",
    "published": "2024-12-15T17:44:10+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11257v3",
    "title": "Prediction-Enhanced Monte Carlo: A Machine Learning View on Control Variate",
    "authors": [
      "Fengpei Li",
      "Haoxian Chen",
      "Jiahe Lin",
      "Arkin Gupta",
      "Xiaowei Tan",
      "Honglei Zhao",
      "Gang Xu",
      "Yuriy Nevmyvaka",
      "Agostino Capponi",
      "Henry Lam"
    ],
    "abstract": "For many complex simulation tasks spanning areas such as healthcare,\nengineering, and finance, Monte Carlo (MC) methods are invaluable due to their\nunbiased estimates and precise error quantification. Nevertheless, Monte Carlo\nsimulations often become computationally prohibitive, especially for nested,\nmulti-level, or path-dependent evaluations lacking effective variance reduction\ntechniques. While machine learning (ML) surrogates appear as natural\nalternatives, naive replacements typically introduce unquantifiable biases. We\naddress this challenge by introducing Prediction-Enhanced Monte Carlo (PEMC), a\nframework that leverages modern ML models as learned predictors, using cheap\nand parallelizable simulation as features, to output unbiased evaluation with\nreduced variance and runtime. PEMC can also be viewed as a \"modernized\" view of\ncontrol variates, where we consider the overall computation-cost-aware variance\nreduction instead of per-replication reduction, while bypassing the closed-form\nmean function requirement and maintaining the advantageous unbiasedness and\nuncertainty quantifiability of Monte Carlo.\n  We illustrate PEMC's broader efficacy and versatility through three examples:\nfirst, equity derivatives such as variance swaps under stochastic local\nvolatility models; second, interest rate derivatives such as swaption pricing\nunder the Heath-Jarrow-Morton (HJM) interest-rate model. Finally, we showcase\nPEMC in a socially significant context - ambulance dispatch and hospital load\nbalancing - where accurate mortality rate estimates are key for ethically\nsensitive decision-making. Across these diverse scenarios, PEMC consistently\nreduces variance while preserving unbiasedness, highlighting its potential as a\npowerful enhancement to standard Monte Carlo baselines.",
    "pdf_url": "http://arxiv.org/pdf/2412.11257v3",
    "published": "2024-12-15T17:41:38+00:00",
    "categories": [
      "stat.ML",
      "cs.CE",
      "cs.LG",
      "q-fin.PR"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2412.12208v1",
    "title": "AI-Driven Innovations in Volumetric Video Streaming: A Review",
    "authors": [
      "Erfan Entezami",
      "Hui Guan"
    ],
    "abstract": "Recent efforts to enhance immersive and interactive user experiences have\ndriven the development of volumetric video, a form of 3D content that enables 6\nDoF. Unlike traditional 2D content, volumetric content can be represented in\nvarious ways, such as point clouds, meshes, or neural representations. However,\ndue to its complex structure and large amounts of data size, deploying this new\nform of 3D data presents significant challenges in transmission and rendering.\nThese challenges have hindered the widespread adoption of volumetric video in\ndaily applications. In recent years, researchers have proposed various\nAI-driven techniques to address these challenges and improve the efficiency and\nquality of volumetric content streaming. This paper provides a comprehensive\noverview of recent advances in AI-driven approaches to facilitate volumetric\ncontent streaming. Through this review, we aim to offer insights into the\ncurrent state-of-the-art and suggest potential future directions for advancing\nthe deployment of volumetric video streaming in real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2412.12208v1",
    "published": "2024-12-15T17:40:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11256v2",
    "title": "Compactifications of moduli spaces of K3 surfaces with a higher-order nonsymplectic automorphism",
    "authors": [
      "Valery Alexeev",
      "Anand Deopurkar",
      "Changho Han"
    ],
    "abstract": "We describe Baily-Borel, toroidal, and geometric -- using the KSBA stable\npairs -- compactifications of some moduli spaces of K3 surfaces with a\nnonsymplectic automorphism of order $3$ and $4$ for which the fixed locus of\nthe automorphism contains a curve of genus $\\ge2$. For order $3$, we treat all\nthe maximal-dimensional such families. We show that the toroidal and the KSBA\ncompactifications in these cases admit simple descriptions in terms of certain\n$ADE$ root lattices.",
    "pdf_url": "http://arxiv.org/pdf/2412.11256v2",
    "published": "2024-12-15T17:39:16+00:00",
    "categories": [
      "math.AG",
      "14D22, 14J28"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11255v1",
    "title": "Do Tutors Learn from Equity Training and Can Generative AI Assess It?",
    "authors": [
      "Danielle R. Thomas",
      "Conrad Borchers",
      "Sanjit Kakarla",
      "Jionghao Lin",
      "Shambhavi Bhushan",
      "Boyuan Guo",
      "Erin Gatz",
      "Kenneth R. Koedinger"
    ],
    "abstract": "Equity is a core concern of learning analytics. However, applications that\nteach and assess equity skills, particularly at scale are lacking, often due to\nbarriers in evaluating language. Advances in generative AI via large language\nmodels (LLMs) are being used in a wide range of applications, with this present\nwork assessing its use in the equity domain. We evaluate tutor performance\nwithin an online lesson on enhancing tutors' skills when responding to students\nin potentially inequitable situations. We apply a mixed-method approach to\nanalyze the performance of 81 undergraduate remote tutors. We find marginally\nsignificant learning gains with increases in tutors' self-reported confidence\nin their knowledge in responding to middle school students experiencing\npossible inequities from pretest to posttest. Both GPT-4o and GPT-4-turbo\ndemonstrate proficiency in assessing tutors ability to predict and explain the\nbest approach. Balancing performance, efficiency, and cost, we determine that\nfew-shot learning using GPT-4o is the preferred model. This work makes\navailable a dataset of lesson log data, tutor responses, rubrics for human\nannotation, and generative AI prompts. Future work involves leveling the\ndifficulty among scenarios and enhancing LLM prompts for large-scale grading\nand assessment.",
    "pdf_url": "http://arxiv.org/pdf/2412.11255v1",
    "published": "2024-12-15T17:36:40+00:00",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11254v3",
    "title": "Toponium: the smallest bound state and simplest hadron in quantum mechanics",
    "authors": [
      "Jing-Hang Fu",
      "Yu-Ji Li",
      "Hui-Min Yang",
      "Yu-Bo Li",
      "Yu-Jie Zhang",
      "Cheng-Ping Shen"
    ],
    "abstract": "We explore toponium, the smallest known quantum bound state of a top quark\nand its antiparticle, bound by the strong force. With a Bohr radius of $8\\times\n10^{-18}$~m and a lifetime of $2.5 \\times 10^{-25}$~s, toponium uniquely probes\nmicrophysics. Unlike all other hadrons, it is governed by ultraviolet freedom.\nThis distinction offers novel insights into quantum chromodynamics. Our\nanalysis reveals a toponium signal exceeding $5\\sigma$ in the distribution of\nthe cross section ratio between $e^+e^- \\rightarrow b\\bar{b}$ and $e^+e^-\n\\rightarrow q\\bar{q}$ ($q=b,c,s,d,u$), based on 400~fb$^{-1}$ of data collected\nat $\\sqrt{s}\\approx 341~{\\rm GeV}$. This discovery enables a top quark mass\nmeasurement with an uncertainty reduced by a factor of ten compared to current\nprecision levels. Moreover, this method improves the systematic uncertainty by\nat least a factor of 2.7 compared to any other possible methods.",
    "pdf_url": "http://arxiv.org/pdf/2412.11254v3",
    "published": "2024-12-15T17:34:00+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11253v1",
    "title": "Are Expressive Models Truly Necessary for Offline RL?",
    "authors": [
      "Guan Wang",
      "Haoyi Niu",
      "Jianxiong Li",
      "Li Jiang",
      "Jianming Hu",
      "Xianyuan Zhan"
    ],
    "abstract": "Among various branches of offline reinforcement learning (RL) methods,\ngoal-conditioned supervised learning (GCSL) has gained increasing popularity as\nit formulates the offline RL problem as a sequential modeling task, therefore\nbypassing the notoriously difficult credit assignment challenge of value\nlearning in conventional RL paradigm. Sequential modeling, however, requires\ncapturing accurate dynamics across long horizons in trajectory data to ensure\nreasonable policy performance. To meet this requirement, leveraging large,\nexpressive models has become a popular choice in recent literature, which,\nhowever, comes at the cost of significantly increased computation and inference\nlatency. Contradictory yet promising, we reveal that lightweight models as\nsimple as shallow 2-layer MLPs, can also enjoy accurate dynamics consistency\nand significantly reduced sequential modeling errors against large expressive\nmodels by adopting a simple recursive planning scheme: recursively planning\ncoarse-grained future sub-goals based on current and target information, and\nthen executes the action with a goal-conditioned policy learned from data\nrela-beled with these sub-goal ground truths. We term our method Recursive\nSkip-Step Planning (RSP). Simple yet effective, RSP enjoys great efficiency\nimprovements thanks to its lightweight structure, and substantially outperforms\nexisting methods, reaching new SOTA performances on the D4RL benchmark,\nespecially in multi-stage long-horizon tasks.",
    "pdf_url": "http://arxiv.org/pdf/2412.11253v1",
    "published": "2024-12-15T17:33:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11252v4",
    "title": "Robust methods to detect coupling among nonlinear dynamic time series",
    "authors": [
      "Timothy Sauer",
      "George Sugihara"
    ],
    "abstract": "Two numerical methods are proposed for detection of coupling between multiple\ntime series generated by deterministic nonlinear systems. The first detects\ninterdependence or the existence of coupling between time series. The second\nascertains directionality of coupling, or alternatively, latent coupling, the\ncase when multiple series are driven by another, unobserved system. In either\ncase, the driver and the recipients of the coupling may be periodic or\naperiodic, and in particular may be chaotic. The only inputs to the method are\ntwo or more simultaneously recorded time series. The methods rely solely on\nranking distances between states in time-delay reconstructions of the data, and\nfor that reason tend to be robust to observational noise.",
    "pdf_url": "http://arxiv.org/pdf/2412.11252v4",
    "published": "2024-12-15T17:33:43+00:00",
    "categories": [
      "nlin.CD"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2412.11251v1",
    "title": "Wasserstein Bounds for generative diffusion models with Gaussian tail targets",
    "authors": [
      "Xixian Wang",
      "Zhongjian Wang"
    ],
    "abstract": "We present an estimate of the Wasserstein distance between the data\ndistribution and the generation of score-based generative models, assuming an\n$\\epsilon$-accurate approximation of the score and a Gaussian-type tail\nbehavior of the data distribution. The complexity bound in dimension is\n$O(\\sqrt{d})$, with a logarithmic constant. Such Gaussian tail assumption\napplies to the distribution of a compact support target with early stopping\ntechnique and the Bayesian posterior with a bounded observation operator.\nCorresponding convergence and complexity bounds are derived.\n  The crux of the analysis lies in the Lipchitz bound of the score, which is\nrelated to the Hessian estimate of a viscous Hamilton-Jacobi equation (vHJ).\nThis latter is demonstrated by employing a dimension independent kernel\nestimate. Consequently, our complexity bound scales linearly (up to a\nlogarithmic constant) with the square root of the trace of the covariance\noperator, which relates to the invariant distribution of forward process. Our\nanalysis also extends to the probabilistic flow ODE, as the sampling process.",
    "pdf_url": "http://arxiv.org/pdf/2412.11251v1",
    "published": "2024-12-15T17:20:42+00:00",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.AP",
      "math.NA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11250v1",
    "title": "Beyond Discrete Personas: Personality Modeling Through Journal Intensive Conversations",
    "authors": [
      "Sayantan Pal",
      "Souvik Das",
      "Rohini K. Srihari"
    ],
    "abstract": "Large Language Models (LLMs) have significantly improved personalized\nconversational capabilities. However, existing datasets like Persona Chat,\nSynthetic Persona Chat, and Blended Skill Talk rely on static, predefined\npersonas. This approach often results in dialogues that fail to capture human\npersonalities' fluid and evolving nature. To overcome these limitations, we\nintroduce a novel dataset with around 400,000 dialogues and a framework for\ngenerating personalized conversations using long-form journal entries from\nReddit. Our approach clusters journal entries for each author and filters them\nby selecting the most representative cluster, ensuring that the retained\nentries best reflect the author's personality. We further refine the data by\ncapturing the Big Five personality traits --openness, conscientiousness,\nextraversion, agreeableness, and neuroticism --ensuring that dialogues\nauthentically reflect an individual's personality. Using Llama 3 70B, we\ngenerate high-quality, personality-rich dialogues grounded in these journal\nentries. Fine-tuning models on this dataset leads to an 11% improvement in\ncapturing personality traits on average, outperforming existing approaches in\ngenerating more coherent and personality-driven dialogues.",
    "pdf_url": "http://arxiv.org/pdf/2412.11250v1",
    "published": "2024-12-15T17:16:08+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11249v1",
    "title": "Time-dependent fluorescence by incoherently pumped polar quantum dot driven by a low-frequency monochromatic field",
    "authors": [
      "Andrey V. Soldatov"
    ],
    "abstract": "We studied time-dependent features of high-frequency fluorescent radiation\nfrom a two-level quantum system with broken inversion spatial symmetry. The\nsystem in question was modelled after a one-electron two-level asymmetric polar\nsemiconductor quantum dot whose electric dipole moment operator has permanent\nunequal diagonal matrix elements. The dot was permanently excited by incoherent\npumping of some sort. Our attention was focused on the evolution of the\nfluorescence spectrum following abrupt switching on of an additional driving\nmonochromatic field, which frequency is much lower than the optical transition\nfrequency of the quantum dot. An analytical expression for the fluorescence\nspectrum as a function of the amplitude, initial phase and frequency of the\nmonochromatic driving field, as well as of the pumping intensity and the\nelapsed time, was derived.",
    "pdf_url": "http://arxiv.org/pdf/2412.11249v1",
    "published": "2024-12-15T17:07:56+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11248v2",
    "title": "Multimodal Class-aware Semantic Enhancement Network for Audio-Visual Video Parsing",
    "authors": [
      "Pengcheng Zhao",
      "Jinxing Zhou",
      "Yang Zhao",
      "Dan Guo",
      "Yanxiang Chen"
    ],
    "abstract": "The Audio-Visual Video Parsing task aims to recognize and temporally localize\nall events occurring in either the audio or visual stream, or both. Capturing\naccurate event semantics for each audio/visual segment is vital. Prior works\ndirectly utilize the extracted holistic audio and visual features for intra-\nand cross-modal temporal interactions. However, each segment may contain\nmultiple events, resulting in semantically mixed holistic features that can\nlead to semantic interference during intra- or cross-modal interactions: the\nevent semantics of one segment may incorporate semantics of unrelated events\nfrom other segments. To address this issue, our method begins with a\nClass-Aware Feature Decoupling (CAFD) module, which explicitly decouples the\nsemantically mixed features into distinct class-wise features, including\nmultiple event-specific features and a dedicated background feature. The\ndecoupled class-wise features enable our model to selectively aggregate useful\nsemantics for each segment from clearly matched classes contained in other\nsegments, preventing semantic interference from irrelevant classes.\nSpecifically, we further design a Fine-Grained Semantic Enhancement module for\nencoding intra- and cross-modal relations. It comprises a Segment-wise Event\nCo-occurrence Modeling (SECM) block and a Local-Global Semantic Fusion (LGSF)\nblock. The SECM exploits inter-class dependencies of concurrent events within\nthe same timestamp with the aid of a new event co-occurrence loss. The LGSF\nfurther enhances the event semantics of each segment by incorporating relevant\nsemantics from more informative global video features. Extensive experiments\nvalidate the effectiveness of the proposed modules and loss functions,\nresulting in a new state-of-the-art parsing performance.",
    "pdf_url": "http://arxiv.org/pdf/2412.11248v2",
    "published": "2024-12-15T16:54:53+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11247v2",
    "title": "Interface and spectrum multiplexing ptychographic reflection microscopy",
    "authors": [
      "Yun Gao",
      "Qijun You",
      "Peixiang Lu",
      "Wei Cao"
    ],
    "abstract": "Reflective ptychography is a promising lensless imaging technique with a wide\nfield of view, offering significant potential for applications in semiconductor\nmanufacturing and detection. However, many semiconductor materials are coated\nwith different layers during processing, which leads to the reflected\ndiffraction light being a coherent superposition of multiple light beams.\nTraditional phase recovery methods often overlook the multi-layered nature of\nthese materials, resulting in artificial errors and, in some cases, failures in\nimage reconstruction. This limitation has hindered the broader application and\nadoption of reflection ptychography. Here, we propose and experimentally\ndemonstrate an innovative interface and spectrum multiplexing ptychographic\nreflection microscopy. By employing multi-wavelength light as the illumination\nsource, our approach enables the accurate extraction of the\nwavelength-dependent surface structure imaging and topography mapping of\nmaterials in a single experiment. This advancement offers a reliable technique\nfor element-specific detection of semiconductor materials, utilizing tabletop\nextreme ultraviolet light sources in the future.",
    "pdf_url": "http://arxiv.org/pdf/2412.11247v2",
    "published": "2024-12-15T16:52:51+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2412.11246v1",
    "title": "A Version of Exclusively Perturbative Quantum Field Theory",
    "authors": [
      "S. A. Larin"
    ],
    "abstract": "We suggest a version of renormalizable Quantum Field Theory which does not\ncontain non-perturbative effects. This is otained by the proper use of the\nboundary conditions in the functional integral of the generating functional of\nGreen functions. It is well known which boundary conditions are applied to the\nfields of the functional integral to get correct perturbation theory. We\npropose that these conditions should be used for all fields integrated in the\ngenerating functional integral. It is shown that in this case non-perturbative\neffects are absent. That is we assume that perturbation theory defines the\ncomplete generating functional integral. It allows, in particular, to formulate\nthe generating functional integral in a unique way as an exact compact\nmathematical formula.",
    "pdf_url": "http://arxiv.org/pdf/2412.11246v1",
    "published": "2024-12-15T16:52:40+00:00",
    "categories": [
      "physics.gen-ph"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11245v1",
    "title": "Transformer-Based Bearing Fault Detection using Temporal Decomposition Attention Mechanism",
    "authors": [
      "Marzieh Mirzaeibonehkhater",
      "Mohammad Ali Labbaf-Khaniki",
      "Mohammad Manthouri"
    ],
    "abstract": "Bearing fault detection is a critical task in predictive maintenance, where\naccurate and timely fault identification can prevent costly downtime and\nequipment damage. Traditional attention mechanisms in Transformer neural\nnetworks often struggle to capture the complex temporal patterns in bearing\nvibration data, leading to suboptimal performance. To address this limitation,\nwe propose a novel attention mechanism, Temporal Decomposition Attention (TDA),\nwhich combines temporal bias encoding with seasonal-trend decomposition to\ncapture both long-term dependencies and periodic fluctuations in time series\ndata. Additionally, we incorporate the Hull Exponential Moving Average (HEMA)\nfor feature extraction, enabling the model to effectively capture meaningful\ncharacteristics from the data while reducing noise. Our approach integrates TDA\ninto the Transformer architecture, allowing the model to focus separately on\nthe trend and seasonal components of the data. Experimental results on the Case\nWestern Reserve University (CWRU) bearing fault detection dataset demonstrate\nthat our approach outperforms traditional attention mechanisms and achieves\nstate-of-the-art performance in terms of accuracy and interpretability. The\nHEMA-Transformer-TDA model achieves an accuracy of 98.1%, with exceptional\nprecision, recall, and F1-scores, demonstrating its effectiveness in bearing\nfault detection and its potential for application in other time series tasks\nwith seasonal patterns or trends.",
    "pdf_url": "http://arxiv.org/pdf/2412.11245v1",
    "published": "2024-12-15T16:51:31+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11244v1",
    "title": "Growth Rate Gap for Stable Subgroups",
    "authors": [
      "Suzhen Han",
      "Qing Liu"
    ],
    "abstract": "We prove that stable subgroups of Morse local-to-global groups exhibit a\ngrowth gap. That is, the growth rate of an infinite-index stable subgroup is\nstrictly less than the growth rate of the ambient Morse local-to-global group.\nThis generalizes a result of Cordes, Russell, Spriano, and Zalloum in the sense\nthat we removed the additional torsion-free or residually finite assumptions.\nThe Morse local-to-global groups are a very broad class of groups, including\nmapping class groups, CAT(0) groups, closed $3$-manifold groups, certain\nrelatively hyperbolic groups, virtually solvable groups, etc.",
    "pdf_url": "http://arxiv.org/pdf/2412.11244v1",
    "published": "2024-12-15T16:50:32+00:00",
    "categories": [
      "math.GR",
      "20F65, 20F67"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11243v1",
    "title": "Fluorescence by a polar quantum system in a polychromatic field",
    "authors": [
      "Nikolai N. Bogolyubov, Jr.",
      "Andrey V. Soldatov"
    ],
    "abstract": "Spectral properties of fluorescent radiation from a two-level quantum system\nwith broken inversion spatial symmetry, which can be described by a model of an\none-electron two-level atom whose electric dipole moment operator has permanent\nunequal diagonal matrix elements, were studied. The case of the excitation of\nthis system by a polychromatic laser field, comprised of $N-1$ high-frequency\ncomponents with the frequencies close to or being in resonance with the atomic\ntransition frequency, and a low-frequency component whose frequency coincides\nwith the Rabi frequency of the high-frequency components, was considered.\nSpecial attention was given to the resonant bichromatic and nearly resonant\ntrichromatic excitation. In the former case it was shown that by changing the\nintensity of the low-frequency component, one can efficiently alter spectral\nproperties of the fluorescent radiation of the system in the high-frequency\nrange, while in the latter case it was found that the fluorescent behavior of\nthe system in question reveals a kind of an optoelectronic transistor effect.\nOptions for the experimental detection and practical usage of the effects under\nstudy were discussed.",
    "pdf_url": "http://arxiv.org/pdf/2412.11243v1",
    "published": "2024-12-15T16:48:21+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11242v2",
    "title": "TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs",
    "authors": [
      "Lanxiang Hu",
      "Tajana Rosing",
      "Hao Zhang"
    ],
    "abstract": "Specializing large language models (LLMs) for local deployment in\ndomain-specific use cases is necessary for strong performance while meeting\nlatency and privacy constraints. However, conventional task-specific adaptation\napproaches do not show simultaneous memory saving and inference speedup at\ndeployment time. Practical compression techniques like quantization and pruning\nrequire dedicated hardware or kernel support to achieve measured inference\nspeedup. We develop TrimLLM based on the layer-wise specialization phenomenon\nwe empirically observed and verified on contemporary LLMs. TrimLLM reduces the\ndepth of LLMs via progressive layer dropping. We show it retains LLMs' capacity\nin specific domains and achieves inference speedup irrespective of hardware and\ndeep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for\ninference; models adapted on medical, legal, and financial datasets all\ndemonstrate $2.1-5.7\\times$ inference speedup on consumer GPUs and up to\n$3.1\\times$ speedup on A100 when compared to state-of-the-art model compression\nalgorithms, with no loss in accuracy at 50$\\sim$60\\% model compression ratio.",
    "pdf_url": "http://arxiv.org/pdf/2412.11242v2",
    "published": "2024-12-15T16:47:16+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11241v1",
    "title": "Volumetric Mapping with Panoptic Refinement via Kernel Density Estimation for Mobile Robots",
    "authors": [
      "Khang Nguyen",
      "Tuan Dang",
      "Manfred Huber"
    ],
    "abstract": "Reconstructing three-dimensional (3D) scenes with semantic understanding is\nvital in many robotic applications. Robots need to identify which objects,\nalong with their positions and shapes, to manipulate them precisely with given\ntasks. Mobile robots, especially, usually use lightweight networks to segment\nobjects on RGB images and then localize them via depth maps; however, they\noften encounter out-of-distribution scenarios where masks over-cover the\nobjects. In this paper, we address the problem of panoptic segmentation quality\nin 3D scene reconstruction by refining segmentation errors using non-parametric\nstatistical methods. To enhance mask precision, we map the predicted masks into\na depth frame to estimate their distribution via kernel densities. The outliers\nin depth perception are then rejected without the need for additional\nparameters in an adaptive manner to out-of-distribution scenarios, followed by\n3D reconstruction using projective signed distance functions (SDFs). We\nvalidate our method on a synthetic dataset, which shows improvements in both\nquantitative and qualitative results for panoptic mapping. Through real-world\ntesting, the results furthermore show our method's capability to be deployed on\na real-robot system. Our source code is available at:\nhttps://github.com/mkhangg/refined panoptic mapping.",
    "pdf_url": "http://arxiv.org/pdf/2412.11241v1",
    "published": "2024-12-15T16:46:23+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11240v1",
    "title": "Revisiting altermagnetism in RuO2: a study of laser-pulse induced charge dynamics by time-domain terahertz spectroscopy",
    "authors": [
      "David T. Plouff",
      "Laura Scheuer",
      "Shreya Shrestha",
      "Weipeng Wu",
      "Nawsher J. Parvez",
      "Subhash Bhatt",
      "Xinhao Wang",
      "Lars Gundlach",
      "M. Benjamin Jungfleisch",
      "John Q. Xiao"
    ],
    "abstract": "Altermagnets are a recently discovered class of magnetic material with great\npotential for applications in the field of spintronics, owing to their\nnon-relativistic spin-splitting and simultaneous antiferromagnetic order. One\nof the most studied candidates for altermagnetic materials is rutile structured\nRuO2. However, it has recently come under significant scrutiny as evidence\nemerged for its lack of any magnetic order. In this work, we study bilayers of\nepitaxial RuO2 and ferromagnetic permalloy (Fe19Ni81) by time-domain terahertz\nspectroscopy, probing for three possible mechanisms of laser-induced charge\ndynamics: the inverse spin Hall effect (ISHE), electrical anisotropic\nconductivity (EAC), and inverse altermagnetic spin-splitting effect (IASSE). We\nexamine films of four common RuO2 layer orientations: (001), (100), (110), and\n(101). If RuO2 is altermagnetic, then the (100) and (101) oriented samples are\nexpected to produce anisotropic emission from the IASSE, however, our results\ndo not indicate the presence of IASSE for either as-deposited or field annealed\nsamples. The THz emission from all samples is instead consistent with charge\ndynamics induced by only the relativistic ISHE and the non-relativistic and\nnon-magnetic EAC, casting further doubt on the existence of altermagnetism in\nRuO2. In addition, we find that in the (101) oriented RuO2 sample, the\ncombination of ISHE and EAC emission mechanisms produces THz emission which is\ntunable between linear and elliptical polarization by modulation of the\nexternal magnetic field.",
    "pdf_url": "http://arxiv.org/pdf/2412.11240v1",
    "published": "2024-12-15T16:45:15+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2412.11239v2",
    "title": "Learning Set Functions with Implicit Differentiation",
    "authors": [
      "Gözde Özcan",
      "Chengzhi Shi",
      "Stratis Ioannidis"
    ],
    "abstract": "Ou et al. (2022) introduce the problem of learning set functions from data\ngenerated by a so-called optimal subset oracle. Their approach approximates the\nunderlying utility function with an energy-based model, whose parameters are\nestimated via mean-field variational inference. Ou et al. (2022) show this\nreduces to fixed point iterations; however, as the number of iterations\nincreases, automatic differentiation quickly becomes computationally\nprohibitive due to the size of the Jacobians that are stacked during\nbackpropagation. We address this challenge with implicit differentiation and\nexamine the convergence conditions for the fixed-point iterations. We\nempirically demonstrate the efficiency of our method on synthetic and\nreal-world subset selection applications including product recommendation, set\nanomaly detection and compound selection tasks.",
    "pdf_url": "http://arxiv.org/pdf/2412.11239v2",
    "published": "2024-12-15T16:42:09+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11238v1",
    "title": "Proportionally Fair Matching via Randomized Rounding",
    "authors": [
      "Sharmila Duppala",
      "Nathaniel Grammel",
      "Juan Luque",
      "Calum MacRury",
      "Aravind Srinivasan"
    ],
    "abstract": "Given an edge-colored graph, the goal of the proportional fair matching\nproblem is to find a maximum weight matching\n  while ensuring proportional representation (with respect to the number of\nedges) of each color. The colors may correspond to demographic groups or other\nprotected traits where we seek to ensure\n  roughly equal representation from each group.\n  It is known that, assuming ETH, it is impossible to approximate the problem\nwith $\\ell$ colors in time $2^{o(\\ell)} n^{\\mathcal{O}(1)}$ (i.e.,\nsubexponential in $\\ell$) even on \\emph{unweighted path graphs}. Further, even\ndetermining the existence of a non-empty matching satisfying proportionality is\nNP-Hard.\n  To overcome this hardness, we relax the stringent\n  proportional fairness constraints to a probabilistic notion. We introduce a\nnotion we call $\\delta$-\\textsc{ProbablyAlmostFair}, where we ensure\nproportionality up to a factor of at most $(1 \\pm \\delta)$ for some small\n$\\delta >0$ with high probability. The violation $\\delta$ can be brought\narbitrarily close to $0$ for some \\emph{good} instances with large values of\nmatching size.\n  We propose and analyze simple and fast algorithms for bipartite graphs that\nachieve\n  constant-factor approximation guarantees, and return a\n$\\delta$-\\textsc{ProbablyAlmostFair} matching.",
    "pdf_url": "http://arxiv.org/pdf/2412.11238v1",
    "published": "2024-12-15T16:38:17+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2412.12207v2",
    "title": "Spectral Representation and Simulation of Fractional Brownian Motion",
    "authors": [
      "Konstantin A. Rybakov"
    ],
    "abstract": "The paper gives a new representation for the fractional Brownian motion that\ncan be applied to simulate this self-similar random process in continuous time.\nSuch a representation is based on the spectral form of mathematical description\nand the spectral method. The Legendre polynomials are used as the orthonormal\nbasis. The paper contains all the necessary algorithms and their theoretical\nfoundation, as well as the results of numerical experiments.",
    "pdf_url": "http://arxiv.org/pdf/2412.12207v2",
    "published": "2024-12-15T16:35:52+00:00",
    "categories": [
      "math.PR",
      "60G22, 60H35",
      "G.3"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11237v1",
    "title": "On the Generalizability of Iterative Patch Selection for Memory-Efficient High-Resolution Image Classification",
    "authors": [
      "Max Riffi-Aslett",
      "Christina Fell"
    ],
    "abstract": "Classifying large images with small or tiny regions of interest (ROI) is\nchallenging due to computational and memory constraints. Weakly supervised\nmemory-efficient patch selectors have achieved results comparable with strongly\nsupervised methods. However, low signal-to-noise ratios and low entropy\nattention still cause overfitting. We explore these issues using a novel\ntestbed on a memory-efficient cross-attention transformer with Iterative Patch\nSelection (IPS) as the patch selection module. Our testbed extends the\nmegapixel MNIST benchmark to four smaller O2I (object-to-image) ratios ranging\nfrom 0.01% to 0.14% while keeping the canvas size fixed and introducing a noise\ngeneration component based on B\\'ezier curves. Experimental results generalize\nthe observations made on CNNs to IPS whereby the O2I threshold below which the\nclassifier fails to generalize is affected by the training dataset size. We\nfurther observe that the magnitude of this interaction differs for each task of\nthe Megapixel MNIST. For tasks \"Maj\" and \"Top\", the rate is at its highest,\nfollowed by tasks \"Max\" and \"Multi\" where in the latter, this rate is almost at\n0. Moreover, results show that in a low data setting, tuning the patch size to\nbe smaller relative to the ROI improves generalization, resulting in an\nimprovement of + 15% for the megapixel MNIST and + 5% for the Swedish traffic\nsigns dataset compared to the original object-to-patch ratios in IPS. Further\noutcomes indicate that the similarity between the thickness of the noise\ncomponent and the digits in the megapixel MNIST gradually causes IPS to fail to\ngeneralize, contributing to previous suspicions.",
    "pdf_url": "http://arxiv.org/pdf/2412.11237v1",
    "published": "2024-12-15T16:25:30+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11236v1",
    "title": "Logarithmic Positional Partition Interval Encoding",
    "authors": [
      "Vasileios Alevizos",
      "Nikitas Gerolimos",
      "Sabrina Edralin",
      "Clark Xu",
      "Akebu Simasiku",
      "Georgios Priniotakis",
      "George Papakostas",
      "Zongliang Yue"
    ],
    "abstract": "One requirement of maintaining digital information is storage. With the\nlatest advances in the digital world, new emerging media types have required\neven more storage space to be kept than before. In fact, in many cases it is\nrequired to have larger amounts of storage to keep up with protocols that\nsupport more types of information at the same time. In contrast, compression\nalgorithms have been integrated to facilitate the transfer of larger data.\nNumerical representations are construed as embodiments of information. However,\nthis correct association of a sequence could feasibly be inverted to signify an\nelongated series of numerals. In this work, a novel mathematical paradigm was\nintroduced to engineer a methodology reliant on iterative logarithmic\ntransformations, finely tuned to numeric sequences. Through this fledgling\napproach, an intricate interplay of polymorphic numeric manipulations was\nconducted. By applying repeated logarithmic operations, the data were condensed\ninto a minuscule representation. Approximately thirteen times surpassed the\ncompression method, ZIP. Such extreme compaction, achieved through iterative\nreduction of expansive integers until they manifested as single-digit entities,\nconferred a novel sense of informational embodiment. Instead of relegating data\nto classical discrete encodings, this method transformed them into a\nquasi-continuous, logarithmically. By contrast, this introduced approach\nrevealed that morphing data into deeply compressed numerical substrata beyond\nconventional boundaries was feasible. A holistic perspective emerges,\nvalidating that numeric data can be recalibrated into ephemeral sequences of\nlogarithmic impressions. It was not merely a matter of reducing digits, but of\nreinterpreting data through a resolute numeric vantage.",
    "pdf_url": "http://arxiv.org/pdf/2412.11236v1",
    "published": "2024-12-15T16:22:13+00:00",
    "categories": [
      "cs.DS",
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2412.11235v1",
    "title": "Symbolic powers of the generic linkage of maximal minors",
    "authors": [
      "Vaibhav Pandey",
      "Matteo Varbaro"
    ],
    "abstract": "Let $I$ be the ideal generated by the maximal minors of a matrix $X$ of\nindeterminates over a field and let $J$ denote the generic link, i.e., the most\ngeneral link, of $I$. The generators of the ideal $J$ are not known. We provide\nan explicit description of the lead terms of the generators of $J$ using\nGr\\\"obner degeneration: For a carefully chosen term order, the reduced\nGr\\\"obner basis of the generic link $J$ is a minimal set of its generators and\nthe initial ideal of $J$ is squarefree. We leverage this description of the\ninitial ideal to establish the equality of the symbolic and ordinary powers of\n$J$. Our analysis of the initial ideal readily yields the Gorenstein property\nof the associated graded ring of $J$, and, in positive characteristic, the\n$F$-rationality of the Rees algebra of $J$. Using the technique of $F$-split\nfiltrations, we further obtain the $F$-regularity of the blowup algebras of\n$J$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11235v1",
    "published": "2024-12-15T16:20:47+00:00",
    "categories": [
      "math.AC",
      "math.AG",
      "13C40, 13A35, 13A30, 14M06 (Primary) 14M10 ( Secondary)"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11234v1",
    "title": "New results for the detection of bicliques",
    "authors": [
      "George Manoussakis"
    ],
    "abstract": "Building on existing algorithms and results, we offer new insights and\nalgorithms for various problems related to detecting maximal and maximum\nbicliques. Most of these results focus on graphs with small maximum degree,\nproviding improved complexities when this parameter is constant; a common\ncharacteristic in real-world graphs.",
    "pdf_url": "http://arxiv.org/pdf/2412.11234v1",
    "published": "2024-12-15T16:19:23+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2412.11233v1",
    "title": "Structural and magnetic properties of CoTeMoO$_6$ revisited",
    "authors": [
      "Yu Li",
      "Jared Coles",
      "Xin Gui",
      "Hyowon Park",
      "Yan Wu",
      "Xinglong Chen",
      "Jing-han Chen",
      "Xiaoping Wang",
      "Huibo Cao",
      "Shane Stadler",
      "Omar Chmaissem",
      "David P. Young",
      "Stephan Rosenkranz",
      "John F. DiTusa"
    ],
    "abstract": "We have conducted a comprehensive investigation into the magnetic properties\nof the chiral multiferroic material CoTeMoO$_6$. In contrast with the previous\nclaim of canted antiferromagnetic order with ferromagnetic components, our\ninvestigation reveals an antiferromagnetic ground state with compensated\nmoments, providing an interesting platform for exploring exotic material\nproperties. Through careful measurements of magnetization under a series of\napplied field, we demonstrate that there exist two sequential field-induced\nmagnetic transitions in CoTeMoO$_6$, with one occurring at $H_{c1}$=460 Oe\nalong the a-axis, and the other at $H_{c2}$=1.16 T with the field along the\nb-axis. The values of $H_{c1}$ and $H_{c2}$ exhibit strong angular dependence\nand diverge with different rates as the applied field is rotated 90 degrees\nwithin the ab plane. This reflects the distinct nature of these transitions,\nwhich is further supported by the different critical behavior of $H_{c1}$ and\n$H_{c2}$, characterized by the values of $\\gamma$,in the function of\n$H_c=H_0\\times(1-\\frac{T}{T_c})^n$. Furthermore, we have demonstrated that\nthere exist structural and magnetic twin domains in CoTeMoO$_6$ that strongly\naffect the experimental measurement of their macroscopic properties.\nIntriguingly, these twin domains can be related to the\northorhombicity/chirality of the crystal structure with the space group $P2_1\n2_1 2$. We further explored the magnetic and structural domains with uniaxial\npressure and polarized light microscopy. Our results suggest that CoTeMoO$_6$\ncould be used as a unique platform for investigating the intriguing physics\ninvolving intertwined degrees of freedom. The tunability of the underlying\ndomain distribution and its strong anisotropy could also be useful for\ndeveloping functional devices and applications.",
    "pdf_url": "http://arxiv.org/pdf/2412.11233v1",
    "published": "2024-12-15T16:11:31+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2412.12206v1",
    "title": "Provably Secure Robust Image Steganography via Cross-Modal Error Correction",
    "authors": [
      "Yuang Qi",
      "Kejiang Chen",
      "Na Zhao",
      "Zijin Yang",
      "Weiming Zhang"
    ],
    "abstract": "The rapid development of image generation models has facilitated the\nwidespread dissemination of generated images on social networks, creating\nfavorable conditions for provably secure image steganography. However, existing\nmethods face issues such as low quality of generated images and lack of\nsemantic control in the generation process. To leverage provably secure\nsteganography with more effective and high-performance image generation models,\nand to ensure that stego images can accurately extract secret messages even\nafter being uploaded to social networks and subjected to lossy processing such\nas JPEG compression, we propose a high-quality, provably secure, and robust\nimage steganography method based on state-of-the-art autoregressive (AR) image\ngeneration models using Vector-Quantized (VQ) tokenizers. Additionally, we\nemploy a cross-modal error-correction framework that generates stego text from\nstego images to aid in restoring lossy images, ultimately enabling the\nextraction of secret messages embedded within the images. Extensive experiments\nhave demonstrated that the proposed method provides advantages in stego\nquality, embedding capacity, and robustness, while ensuring provable\nundetectability.",
    "pdf_url": "http://arxiv.org/pdf/2412.12206v1",
    "published": "2024-12-15T16:10:10+00:00",
    "categories": [
      "cs.MM",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2412.11232v3",
    "title": "Surveying optically addressable spin qubits for quantum information and sensing technology",
    "authors": [
      "Calysta A. Tesiman",
      "Mark Oxborrow",
      "Max Attwood"
    ],
    "abstract": "Quantum technologies offer ways to solve certain tasks more quickly,\nefficiently, and with greater precision than their classical counterparts. Yet\nsubstantial challenges remain in the construction of sufficiently error-free\nand scalable quantum platforms needed to unlock any real benefits to society.\nAcknowledging that this hardware can take vastly different forms, our review\nhere focuses on so-called spintronic (\\textit{i.e.}~spin-electronic) materials\nthat use electronic or nuclear spins to embody qubits. Towards helping the\nreader to spot trends and pick winners, we have surveyed the various families\nof optically addressable spin qubits and attempted to benchmark and identify\nthe most promising ones in each. We go on to reveal further trends that\ndemonstrate how qubit lifetimes depend on the material's synthesis, the\nconcentration/distribution of its embedded qubits, and the experimental\nconditions.",
    "pdf_url": "http://arxiv.org/pdf/2412.11232v3",
    "published": "2024-12-15T16:10:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11231v1",
    "title": "Smaller Language Models Are Better Instruction Evolvers",
    "authors": [
      "Tingfeng Hui",
      "Lulu Zhao",
      "Guanting Dong",
      "Yaqi Zhang",
      "Hua Zhou",
      "Sen Su"
    ],
    "abstract": "Instruction tuning has been widely used to unleash the complete potential of\nlarge language models. Notably, complex and diverse instructions are of\nsignificant importance as they can effectively align models with various\ndownstream tasks. However, current approaches to constructing large-scale\ninstructions predominantly favour powerful models such as GPT-4 or those with\nover 70 billion parameters, under the empirical presumption that such larger\nlanguage models (LLMs) inherently possess enhanced capabilities. In this study,\nwe question this prevalent assumption and conduct an in-depth exploration into\nthe potential of smaller language models (SLMs) in the context of instruction\nevolution. Extensive experiments across three scenarios of instruction\nevolution reveal that smaller language models (SLMs) can synthesize more\neffective instructions than LLMs. Further analysis demonstrates that SLMs\npossess a broader output space during instruction evolution, resulting in more\ncomplex and diverse variants. We also observe that the existing metrics fail to\nfocus on the impact of the instructions. Thus, we propose Instruction\nComplex-Aware IFD (IC-IFD), which introduces instruction complexity in the\noriginal IFD score to evaluate the effectiveness of instruction data more\naccurately. Our source code is available at:\n\\href{https://github.com/HypherX/Evolution-Analysis}{https://github.com/HypherX/Evolution-Analysis}",
    "pdf_url": "http://arxiv.org/pdf/2412.11231v1",
    "published": "2024-12-15T16:07:48+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.12205v2",
    "title": "Radiative Capture Reaction $d(α,γ)^{6}\\mathrm{Li} $ in Cluster Effective Field Theory",
    "authors": [
      "F. Nazari",
      "M. Radin",
      "M. Moeini Arani"
    ],
    "abstract": "In this study, we focus on the radiative capture process of the deuteron on\nalpha particle leading to the formation of $^6{\\textrm{Li}}$ in the two-body\nformalism through the cluster effective field theory~(CEFT). It was the\nprimitive nuclear reaction to produce ${^6 \\textrm{Li}}$ in a few minutes after\nthe Big Bang. In detail, we outline the calculation of the dominant $E1$ and\n$E2$ electromagnetic transition amplitudes of $d(\\alpha,\\gamma\n){^6\\textrm{Li}}$. Then, we obtain the astrophysical S-factor by fitting it to\nthe experimental data. Finally, we compare the obtained CEFT results for the\nastrophysical S-factor with the other theoretical results.",
    "pdf_url": "http://arxiv.org/pdf/2412.12205v2",
    "published": "2024-12-15T15:56:00+00:00",
    "categories": [
      "nucl-th",
      "astro-ph.SR"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2412.11230v1",
    "title": "Grey Wolf-Based Task Scheduling in Vehicular Fog Computing Systems",
    "authors": [
      "Maryam Taghizadeh",
      "Mahmood Ahmadi"
    ],
    "abstract": "Vehicular fog computing (VFC) can be considered as an important alternative\nto address the existing challenges in intelligent transportation systems (ITS).\nThe main purpose of VFC is to perform computational tasks through various\nvehicles. At present, VFCs include powerful computing resources that bring the\ncomputational resources nearer to the requesting devices. This paper presents a\nnew algorithm based on meta-heuristic optimization method for task scheduling\nproblem in VFC. The task scheduling in VFC is formulated as a multi-objective\noptimization problem, which aims to reduce makespan and monetary cost. The\nproposed method utilizes the grey wolf optimization (GWO) and assigns the\ndifferent priorities to static and dynamic fog nodes. Dynamic fog nodes\nrepresent the parked or moving vehicles and static fog nodes show the\nstationary servers. Afterwards, the tasks that require the most processing\nresources are chosen and allocated to fog nodes. The GWO-based method is\nextensively evaluated in more details. Furthermore, the effectiveness of\nvarious parameters in GWO algorithm is analyzed. We also assess the proposed\nalgorithm on real application and random data. The outcomes of our experiments\nconfirm that, in comparison to previous works, our algorithm is capable of\noffering the lowest monetary cost.",
    "pdf_url": "http://arxiv.org/pdf/2412.11230v1",
    "published": "2024-12-15T15:55:49+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2412.11229v1",
    "title": "Applications of Knot Theory for the Improvement of the AlphaFold Protein Database",
    "authors": [
      "Pranshu Jahagirdar"
    ],
    "abstract": "AlphaFold, a groundbreaking protein prediction model, has revolutionized\nprotein structure prediction, populating the AlphaFold Protein Database (AFDB)\nwith millions of predicted structures. However, AlphaFold's accuracy in\npredicting proteins with intricate topologies, such as knots, remains a\nconcern. This study investigates AlphaFold's performance in predicting knotted\nproteins and explores potential solutions to enhance the AFDB's reliability.\nForty-five experimentally verified knotted protein structures from the KnotProt\ndatabase were compared to their AlphaFold-generated counterparts. Knot analysis\nwas performed using PyKnot, a PyMOL plugin, employing both Gauss codes and\nAlexander-Briggs knot notations. Results showed 95.6% accuracy in predicting\nthe general shape of knots using Alexander-Briggs notation. However, Gauss code\nanalysis revealed a 55.6% discrepancy, indicating AlphaFold's limitations in\naccurately representing the intricate orientation and directionality of knots.\nThis Applications of Knot Theory for the improvement of the AlphaFold Protein\nDatabase suggests potential inaccuracies in a significant portion of the AFDB's\nknotted protein structures. The study underscores the need for improved knot\nrepresentation in AlphaFold and proposes potential solutions, including\ntransitioning to a single-module design or removing incorrectly predicted\nstructures from the AFDB. These findings highlight the importance of continuous\nrefinement for AI-based protein structure prediction tools to ensure the\naccuracy and reliability of protein databases for research and drug\ndevelopment.",
    "pdf_url": "http://arxiv.org/pdf/2412.11229v1",
    "published": "2024-12-15T15:52:05+00:00",
    "categories": [
      "q-bio.BM"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2412.11228v1",
    "title": "Uni-AdaFocus: Spatial-temporal Dynamic Computation for Video Recognition",
    "authors": [
      "Yulin Wang",
      "Haoji Zhang",
      "Yang Yue",
      "Shiji Song",
      "Chao Deng",
      "Junlan Feng",
      "Gao Huang"
    ],
    "abstract": "This paper presents a comprehensive exploration of the phenomenon of data\nredundancy in video understanding, with the aim to improve computational\nefficiency. Our investigation commences with an examination of spatial\nredundancy, which refers to the observation that the most informative region in\neach video frame usually corresponds to a small image patch, whose shape, size\nand location shift smoothly across frames. Motivated by this phenomenon, we\nformulate the patch localization problem as a dynamic decision task, and\nintroduce a spatially adaptive video recognition approach, termed AdaFocus. In\nspecific, a lightweight encoder is first employed to quickly process the full\nvideo sequence, whose features are then utilized by a policy network to\nidentify the most task-relevant regions. Subsequently, the selected patches are\ninferred by a high-capacity deep network for the final prediction. The full\nmodel can be trained in end-to-end conveniently. Furthermore, AdaFocus can be\nextended by further considering temporal and sample-wise redundancies, i.e.,\nallocating the majority of computation to the most task-relevant frames, and\nminimizing the computation spent on relatively \"easier\" videos. Our resulting\napproach, Uni-AdaFocus, establishes a comprehensive framework that seamlessly\nintegrates spatial, temporal, and sample-wise dynamic computation, while it\npreserves the merits of AdaFocus in terms of efficient end-to-end training and\nhardware friendliness. In addition, Uni-AdaFocus is general and flexible as it\nis compatible with off-the-shelf efficient backbones (e.g., TSM and X3D), which\ncan be readily deployed as our feature extractor, yielding a significantly\nimproved computational efficiency. Empirically, extensive experiments based on\nseven benchmark datasets and three application scenarios substantiate that\nUni-AdaFocus is considerably more efficient than the competitive baselines.",
    "pdf_url": "http://arxiv.org/pdf/2412.11228v1",
    "published": "2024-12-15T15:51:44+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11227v2",
    "title": "The Brascamp-Lieb inequality in Convex Geometry and in the Theory of Algorithms",
    "authors": [
      "Károly J. Böröczky"
    ],
    "abstract": "The Brascamp-Lieb inequality in harmonic analysis was proved by Brascamp and\nLieb in the rank one case in 1976, and by Lieb in 1990. It says that in a\ncertain inequality, the optimal constant can be determined by checking the\ninequality for centered Gaussian distributions. It was Keith M Ball's\npioneering work around 1990 that led to various applications of the inequality\nin Convex Geometry, and even in Discrete Geometry, like Brazitikos'\nquantitative fractional version of the Helly Theorem. On the other hand,\ndetermining the optimal constant and possible Gaussian extremizers for the\nBrascamp-Lieb inequality can be formulated as a problem in terms of positive\ndefinite matrices, and this problem has intimate links to the Theory of\nAlgorithms.",
    "pdf_url": "http://arxiv.org/pdf/2412.11227v2",
    "published": "2024-12-15T15:49:56+00:00",
    "categories": [
      "math.MG"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11226v1",
    "title": "Non-equilibrium dynamics in geometrically frustrated spin glass Bi$_2$Fe$_3$GaO$_9$ with a Cairo lattice",
    "authors": [
      "Desislava Mihaylova",
      "Xinglong Chen",
      "Daniel Phelan",
      "Stephan Rosenkranz",
      "Yu Li"
    ],
    "abstract": "We have explored the relaxation process of the spin glass phase in\nBi$_2$Fe$_3$GaO$_9$, a geometrically frustrated magnet with a unique structure\nconsisting of pentagonal building blocks known as the Cairo lattice. Using dc\nmagnetization measurements on single crystals, we estimate the relaxation time\nacross various temperatures and fields. Our results indicate that the\nrelaxation time of Bi$_2$Fe$_3$GaO$_9$ follows the Arrhenius law as a function\nof temperature but remains relatively constant as the applied magnetic field\nvaries. Further, through a carefully designed protocol, we observe significant\nrejuvenation and memory effects. Remarkably, the memory effects in\nBi$_2$Fe$_3$GaO$_9$ are found to be more similar to those observed in classical\nspin glasses rather than in spin jamming systems, both in terms of the\nmagnitude of the memory effect and the value of the exponent that describes the\nrelaxation behavior. Our findings suggest that Bi$_2$Fe$_3$GaO$_9$ provides an\nexcellent platform for investigating the time-dependent evolution of underlying\nmagnetism using neutron scattering, paving the way for future research.",
    "pdf_url": "http://arxiv.org/pdf/2412.11226v1",
    "published": "2024-12-15T15:49:00+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2412.15254v1",
    "title": "RIRO: Reshaping Inputs, Refining Outputs Unlocking the Potential of Large Language Models in Data-Scarce Contexts",
    "authors": [
      "Ali Hamdi",
      "Hozaifa Kassab",
      "Mohamed Bahaa",
      "Marwa Mohamed"
    ],
    "abstract": "Large language models (LLMs) have significantly advanced natural language\nprocessing, excelling in areas like text generation, summarization, and\nquestion-answering. Despite their capabilities, these models face challenges\nwhen fine-tuned on small, domain-specific datasets, often struggling to\ngeneralize and deliver accurate results with unfamiliar inputs. To tackle this\nissue, we introduce RIRO, a novel two-layer architecture designed to improve\nperformance in data-scarce environments. The first layer leverages advanced\nprompt engineering to reformulate inputs, ensuring better alignment with\ntraining data, while the second layer focuses on refining outputs to minimize\ninconsistencies. Through fine-tuning models like Phi-2, Falcon 7B, and Falcon\n1B, with Phi-2 outperforming the others. Additionally, we introduce a benchmark\nusing evaluation metrics such as cosine similarity, Levenshtein distance, BLEU\nscore, ROUGE-1, ROUGE-2, and ROUGE-L. While these advancements improve\nperformance, challenges like computational demands and overfitting persist,\nlimiting the potential of LLMs in data-scarce, high-stakes environments such as\nhealthcare, legal documentation, and software testing.",
    "pdf_url": "http://arxiv.org/pdf/2412.15254v1",
    "published": "2024-12-15T15:48:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11225v1",
    "title": "Cohomology of the diffeomorphism group of the connected sum of two generic lens spaces",
    "authors": [
      "Zoltán Lelkes"
    ],
    "abstract": "We consider the connected sum of two three-dimensional lens spaces\n$L_1\\#L_2$, where $L_1$ and $L_2$ are non-diffeomorphic and are of a certain\n\"generic\" type. Our main result is the calculation of the cohomology ring\n$H^\\ast(B\\text{Diff}(L_1\\#L_2);\\mathbb{Q})$, where $\\text{Diff}(L_1\\#L_2)$ is\nthe diffeomorphism group of $M$ equipped with the $C^\\infty$-topology. We know\nthe homotopy type of the diffeomorphism groups of generic lens spaces this,\ncombined with a theorem of Hatcher forms the basis of our argument.",
    "pdf_url": "http://arxiv.org/pdf/2412.11225v1",
    "published": "2024-12-15T15:42:09+00:00",
    "categories": [
      "math.GT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11224v3",
    "title": "GenLit: Reformulating Single-Image Relighting as Video Generation",
    "authors": [
      "Shrisha Bharadwaj",
      "Haiwen Feng",
      "Giorgio Becherini",
      "Victoria Fernandez Abrevaya",
      "Michael J. Black"
    ],
    "abstract": "Manipulating the illumination of a 3D scene within a single image represents\na fundamental challenge in computer vision and graphics. This problem has\ntraditionally been addressed using inverse rendering techniques, which involve\nexplicit 3D asset reconstruction and costly ray-tracing simulations. Meanwhile,\nrecent advancements in visual foundation models suggest that a new paradigm\ncould soon be possible -- one that replaces explicit physical models with\nnetworks that are trained on large amounts of image and video data. In this\npaper, we exploit the physical world understanding of a video diffusion model,\nparticularly Stable Video Diffusion, to relight a single image. We introduce\nGenLit, a framework that distills the ability of a graphics engine to perform\nlight manipulation into a video-generation model, enabling users to directly\ninsert and manipulate a point light in the 3D world within a given image, and\ngenerate results directly as a video sequence. We find that a model fine-tuned\non only a small synthetic dataset generalizes to real-world scenes, enabling\nsingle-image relighting with plausible and convincing shadows. Our results\nhighlight the ability of video foundation models to capture rich information\nabout lighting, material, and, shape and our findings indicate that such\nmodels, with minimal training, can be used to perform relighting without\nexplicit asset reconstruction or complex ray tracing. Project page:\nhttps://genlit.is.tue.mpg.de/.",
    "pdf_url": "http://arxiv.org/pdf/2412.11224v3",
    "published": "2024-12-15T15:40:40+00:00",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11223v2",
    "title": "Computing Young's Natural Representations for Generalized Symmetric Groups",
    "authors": [
      "Koushik Paul",
      "Götz Pfeiffer"
    ],
    "abstract": "We provide an algorithmic framework for the computation of explicit\nrepresenting matrices for all irreducible representations of a generalized\nsymmetric group $\\Grin_n$, i.e., a wreath product of cyclic group of order $r$\nwith the symmetric group $\\Symm_n$. The basic building block for this framework\nis the Specht matrix, a matrix with entries $0$ and $\\pm1$, defined in terms of\npairs of certain words. Combinatorial objects like Young diagrams and Young\ntableaus arise naturally from this setup. In the case $r = 1$, we recover\nYoung's natural representations of the symmetric group. For general $r$, a\nsuitable notion of pairs of $r$-words is used to extend the construction to\ngeneralized symmetric groups. Separately, for $r = 2$, where $\\Grin_n$ is the\nWeyl group of type $B_n$, a different construction is based on a notion of\npairs of biwords.",
    "pdf_url": "http://arxiv.org/pdf/2412.11223v2",
    "published": "2024-12-15T15:32:54+00:00",
    "categories": [
      "math.RT",
      "math.GR",
      "20C30, 20C15"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11222v2",
    "title": "A Short Proof that the number of $(a,b)$-parking functions of length n $a(a+bn)^{n-1}$",
    "authors": [
      "AJ Bu",
      "Doron Zeilberger"
    ],
    "abstract": "We give a very short proof of the fact that the number of $(a,b)$-parking\nfunctions of length $n$ equals $a(a+bn)^{n-1}$. This was first proved in 2003\nby Kung and Yan, via a very long and torturous route, as a corollary of a more\ngeneral result. This new version contains a reference to previous work kindly\ncommunicated by Richard Stanley",
    "pdf_url": "http://arxiv.org/pdf/2412.11222v2",
    "published": "2024-12-15T15:30:09+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11221v2",
    "title": "Shadowing property for set-valued map and its inverse limit",
    "authors": [
      "Zhengyu Yin"
    ],
    "abstract": "In this article, we investigate the relationship between the shadowing\nproperty of set-valued maps and their associated inverse limit systems. We show\nthat if a set-valued map is expansive and open in the context of set-valued\ndynamics, then certain induced inverse limit systems have the shadowing\nproperty. Additionally, we prove that a continuous set-valued map has the\nshadowing property if and only if some of its induced inverse limit system also\nhas shadowing property. Finally, we establish that the shadowing property of a\nset-valued map is equivalent to the shadowing property of its induced inverse\nset-valued system.",
    "pdf_url": "http://arxiv.org/pdf/2412.11221v2",
    "published": "2024-12-15T15:26:47+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2412.11220v1",
    "title": "Non-Markovian Noise Suppression Simplified through Channel Representation",
    "authors": [
      "Zhenhuan Liu",
      "Yunlong Xiao",
      "Zhenyu Cai"
    ],
    "abstract": "Non-Markovian noise, arising from the memory effect in the environment, poses\nsubstantial challenges to conventional quantum noise suppression protocols,\nincluding quantum error correction and mitigation. We introduce a channel\nrepresentation for arbitrary non-Markovian quantum dynamics, termed the Choi\nchannel, as it operates on the Choi states of the ideal gate layers. This\nrepresentation translates the complex dynamics of non-Markovian noise into the\nfamiliar picture of noise channels acting on ideal states, allowing us to\ndirectly apply many existing error suppression protocols originally designed\nfor Markovian noise. These protocols can then be translated from the Choi\nchannel picture back to the circuit picture, yielding non-Markovian noise\nsuppression protocols. With this framework, we have devised new protocols using\nPauli twirling, probabilistic error cancellation and virtual channel\npurification. In particular, Pauli twirling can transform any non-Markovian\nnoise into noise that exhibits only classical temporal correlations, thereby\nextending the proven noise resilience of single-shot quantum error correction\nto arbitrary non-Markovian noise. Through these examples, the Choi channel\ndemonstrates significant potential as a foundational bridge for connecting\nexisting techniques and inspiring the development of novel non-Markovian noise\nsuppression protocols.",
    "pdf_url": "http://arxiv.org/pdf/2412.11220v1",
    "published": "2024-12-15T15:26:07+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11219v1",
    "title": "Strings in abstract root systems",
    "authors": [
      "Victor Sanmartin-Lopez"
    ],
    "abstract": "Let $\\Phi$ be a subset of the simple roots of a (possibly non-reduced)\nabstract root system $\\Sigma$, and let $\\lambda \\in \\Sigma$. We define the\n$\\Phi$-string of $\\lambda$ as the set of elements in $\\Sigma \\cup \\{0\\}$ of the\nform $\\lambda + \\sum_{\\alpha \\in \\Phi} n_\\alpha \\alpha$, where $n_\\alpha$ is an\ninteger for each $\\alpha \\in \\Phi$. This notion can be regarded as some sort of\ngeneralization of the classical notion of $\\alpha$-string, where $\\alpha \\in\n\\Sigma$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11219v1",
    "published": "2024-12-15T15:22:42+00:00",
    "categories": [
      "math.RA",
      "math.DG"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11218v1",
    "title": "Distributed Bilevel Optimization via Adaptive Penalization with Time-Scale Separation",
    "authors": [
      "Youcheng Niu",
      "Jinming Xu",
      "Ying Sun",
      "Li Chai",
      "Jiming Chen"
    ],
    "abstract": "This paper studies a class of distributed bilevel optimization (DBO) problems\nwith a coupled inner-level subproblem. Existing approaches typically rely on\nhypergradient estimations involving computationally expensive Hessian\ninformation. To address this, we propose an equivalent constrained\nreformulation by treating the inner-level subproblem as an inequality\nconstraint, and introduce an adaptive penalty function to properly penalize\nboth inequality and consensus constraints based on subproblem properties.\nMoreover, we propose a loopless distributed algorithm, \\ALGNAME, that employs\nmultiple-timescale updates to solve each subproblem asymptotically without\nrequiring Hessian information. Theoretically, we establish convergence rates of\n$\\mathcal{O}(\\frac{\\kappa^4}{(1-\\rho)^2 K^{1/3}})$ for\nnonconvex-strongly-convex cases and $\\mathcal{O}(\\frac{\\kappa^2}{(1-\\rho)^2\nK^{2/3}})$ for distributed min-max problems. Our analysis shows the clear\ndependence of convergence performance on bilevel heterogeneity, the adaptive\npenalty parameter, and network connectivity, with a weaker assumption on\nheterogeneity requiring only bounded first-order heterogeneity at the optimum.\nNumerical experiments validate our theoretical findings.",
    "pdf_url": "http://arxiv.org/pdf/2412.11218v1",
    "published": "2024-12-15T15:15:35+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11217v3",
    "title": "A Syntactic Approach to Computing Complete and Sound Abstraction in the Situation Calculus",
    "authors": [
      "Liangda Fang",
      "Xiaoman Wang",
      "Zhang Chen",
      "Kailun Luo",
      "Zhenhe Cui",
      "Quanlong Guan"
    ],
    "abstract": "Abstraction is an important and useful concept in the field of artificial\nintelligence. To the best of our knowledge, there is no syntactic method to\ncompute a sound and complete abstraction from a given low-level basic action\ntheory and a refinement mapping. This paper aims to address this issue.To this\nend, we first present a variant of situation calculus,namely linear integer\nsituation calculus, which serves as the formalization of high-level basic\naction theory. We then migrate Banihashemi, De Giacomo, and Lesp\\'erance's\nabstraction framework to one from linear integer situation calculus to extended\nsituation calculus. Furthermore, we identify a class of Golog programs, namely\nguarded actions,that is used to restrict low-level Golog programs, and impose\nsome restrictions on refinement mappings. Finally, we design a syntactic\napproach to computing a sound and complete abstraction from a low-level basic\naction theory and a restricted refinement mapping.",
    "pdf_url": "http://arxiv.org/pdf/2412.11217v3",
    "published": "2024-12-15T15:14:35+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11216v2",
    "title": "Distribution-Consistency-Guided Multi-modal Hashing",
    "authors": [
      "Jin-Yu Liu",
      "Xian-Ling Mao",
      "Tian-Yi Che",
      "Rong-Cheng Tu"
    ],
    "abstract": "Multi-modal hashing methods have gained popularity due to their fast speed\nand low storage requirements. Among them, the supervised methods demonstrate\nbetter performance by utilizing labels as supervisory signals compared with\nunsupervised methods. Currently, for almost all supervised multi-modal hashing\nmethods, there is a hidden assumption that training sets have no noisy labels.\nHowever, labels are often annotated incorrectly due to manual labeling in\nreal-world scenarios, which will greatly harm the retrieval performance. To\naddress this issue, we first discover a significant distribution consistency\npattern through experiments, i.e., the 1-0 distribution of the presence or\nabsence of each category in the label is consistent with the high-low\ndistribution of similarity scores of the hash codes relative to category\ncenters. Then, inspired by this pattern, we propose a novel\nDistribution-Consistency-Guided Multi-modal Hashing (DCGMH), which aims to\nfilter and reconstruct noisy labels to enhance retrieval performance.\nSpecifically, the proposed method first randomly initializes several category\ncenters, which are used to compute the high-low distribution of similarity\nscores; Noisy and clean labels are then separately filtered out via the\ndiscovered distribution consistency pattern to mitigate the impact of noisy\nlabels; Subsequently, a correction strategy, which is indirectly designed via\nthe distribution consistency pattern, is applied to the filtered noisy labels,\ncorrecting high-confidence ones while treating low-confidence ones as unlabeled\nfor unsupervised learning, thereby further enhancing the model's performance.\nExtensive experiments on three widely used datasets demonstrate the superiority\nof the proposed method compared to state-of-the-art baselines in multi-modal\nretrieval tasks. The code is available at\nhttps://github.com/LiuJinyu1229/DCGMH.",
    "pdf_url": "http://arxiv.org/pdf/2412.11216v2",
    "published": "2024-12-15T15:13:14+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11215v3",
    "title": "Neural Port-Hamiltonian Differential Algebraic Equations for Compositional Learning of Electrical Networks",
    "authors": [
      "Cyrus Neary",
      "Nathan Tsao",
      "Ufuk Topcu"
    ],
    "abstract": "We develop compositional learning algorithms for coupled dynamical systems,\nwith a particular focus on electrical networks. While deep learning has proven\neffective at modeling complex relationships from data, compositional couplings\nbetween system components typically introduce algebraic constraints on state\nvariables, posing challenges to many existing data-driven approaches to\nmodeling dynamical systems. Towards developing deep learning models for\nconstrained dynamical systems, we introduce neural port-Hamiltonian\ndifferential algebraic equations (N-PHDAEs), which use neural networks to\nparameterize unknown terms in both the differential and algebraic components of\na port-Hamiltonian DAE. To train these models, we propose an algorithm that\nuses automatic differentiation to perform index reduction, automatically\ntransforming the neural DAE into an equivalent system of neural ordinary\ndifferential equations (N-ODEs), for which established model inference and\nbackpropagation methods exist. Experiments simulating the dynamics of nonlinear\ncircuits exemplify the benefits of our approach: the proposed N-PHDAE model\nachieves an order of magnitude improvement in prediction accuracy and\nconstraint satisfaction when compared to a baseline N-ODE over long prediction\ntime horizons. We also validate the compositional capabilities of our approach\nthrough experiments on a simulated DC microgrid: we train individual N-PHDAE\nmodels for separate grid components, before coupling them to accurately predict\nthe behavior of larger-scale networks.",
    "pdf_url": "http://arxiv.org/pdf/2412.11215v3",
    "published": "2024-12-15T15:13:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11214v2",
    "title": "Image Forgery Localization with State Space Models",
    "authors": [
      "Zijie Lou",
      "Gang Cao",
      "Kun Guo",
      "Shaowei Weng",
      "Lifang Yu"
    ],
    "abstract": "Pixel dependency modeling from tampered images is pivotal for image forgery\nlocalization. Current approaches predominantly rely on Convolutional Neural\nNetworks (CNNs) or Transformer-based models, which often either lack sufficient\nreceptive fields or entail significant computational overheads. Recently, State\nSpace Models (SSMs), exemplified by Mamba, have emerged as a promising\napproach. They not only excel in modeling long-range interactions but also\nmaintain a linear computational complexity. In this paper, we propose LoMa, a\nnovel image forgery localization method that leverages the selective SSMs.\nSpecifically, LoMa initially employs atrous selective scan to traverse the\nspatial domain and convert the tampered image into ordered patch sequences, and\nsubsequently applies multi-directional state space modeling. In addition, an\nauxiliary convolutional branch is introduced to enhance local feature\nextraction. Extensive experimental results validate the superiority of LoMa\nover CNN-based and Transformer-based state-of-the-arts. To our best knowledge,\nthis is the first image forgery localization model constructed based on the\nSSM-based model. We aim to establish a baseline and provide valuable insights\nfor the future development of more efficient and effective SSM-based forgery\nlocalization models. Code is available at\nhttps://github.com/multimediaFor/LoMa.",
    "pdf_url": "http://arxiv.org/pdf/2412.11214v2",
    "published": "2024-12-15T15:10:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11213v1",
    "title": "Giant Nernst Angle in Self-Intercalated van der Waals Magnet Cr$_{1.25}$Te$_2$",
    "authors": [
      "Shuvankar Gupta",
      "Olajumoke Oluwatobiloba Emmanuel",
      "Yasemin Ozbek",
      "Mingyu Xu",
      "Weiwei Xie",
      "Pengpeng Zhang",
      "Xianglin Ke"
    ],
    "abstract": "The discovery of two-dimensional van der Waals (vdW) magnetic materials has\npropelled advancements in technological devices. The Nernst effect, which\ngenerates a transverse electric voltage in the presence of a longitudinal\nthermal gradient, shows great promise for thermoelectric applications. In this\nwork, we report the electronic and thermoelectric transport properties of\nCr$_{1.25}$Te$_2$, a layered self-intercalated vdW material which exhibits an\nantiferromagnetic ordering at TN ~ 191 K followed by a ferromagnetic-like phase\ntransition at TC ~171 K. We observe a prominent topological Hall effect and\ntopological Nernst effect between TC and TN, which is ascribable to\nnon-coplanar spin textures inducing a real-space Berry phase due to competing\nferromagnetic and antiferromagnetic interactions. Furthermore, we show that\nCr$_{1.25}$Te$_2$ exhibits a substantial anomalous Nernst effect, featuring a\ngiant Nernst angle of ~37% near TC and a maximum Nernst thermoelectric\ncoefficient of 0.52 uV/K. These results surpass those of conventional\nferromagnets and other two-dimensional vdW materials, highlighting\nCr$_{1.25}$Te$_2$ as a promising candidate for advanced thermoelectric devices\nbased on the Nernst effect.",
    "pdf_url": "http://arxiv.org/pdf/2412.11213v1",
    "published": "2024-12-15T15:10:28+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2412.11212v1",
    "title": "Practical IMT and EESS Spectrum Sharing in the 7 to 8 GHz Band",
    "authors": [
      "Elliot Eichen",
      "Arvind Aradhya",
      "Oren Collaco"
    ],
    "abstract": "The 7.3 GHz (350 MHz bandwidth) Earth Observation Satellite (EOS) band, while\nnot protected, is used for Passive Sea Surface Temperature (P-SST) measurements\nthat provide important data for weather forecasts, coastal disaster prevention,\nclimate modeling, and oceanographic research. The full 7 GHz band (7.125 to 8.4\nGHz), which encompasses these EOS frequencies, is the largest contiguous block\nof potentially available mid-band spectrum and will play a significant role in\nmeeting the anticipated demand for wireless services. A Real Time Geofenced\nSpectrum Sharing (RGSS) system is shown to be a practical and near term\nsolution to spectrum sharing between P-SST measurements and 5G or 6G networks\nin the 7GHz band. RGSS enables IMT networks and EOS radiometers to share 350MHz\nof overlapping spectrum centered at 7.3 GHz. It prevents interference to P-SST\nmeasurements while simultaneously allowing IMT systems un-constrained access to\nthe shared spectrum greater than 99.9% of the time. Subscriber impact during\nthe less than 0.1 percent paused access time can be prevented by using 3GPP\ndefined capabilities and O-RAN APIs to move subscribers to other frequencies.\nPaused access time data from a proof-of-concept RGSS system is available to\nacademic, government, and industry researchers through a web or programmatic\ninterface.",
    "pdf_url": "http://arxiv.org/pdf/2412.11212v1",
    "published": "2024-12-15T15:06:18+00:00",
    "categories": [
      "eess.SP",
      "cs.CE"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11211v1",
    "title": "Deep Learning-based Approaches for State Space Models: A Selective Review",
    "authors": [
      "Jiahe Lin",
      "George Michailidis"
    ],
    "abstract": "State-space models (SSMs) offer a powerful framework for dynamical system\nanalysis, wherein the temporal dynamics of the system are assumed to be\ncaptured through the evolution of the latent states, which govern the values of\nthe observations. This paper provides a selective review of recent advancements\nin deep neural network-based approaches for SSMs, and presents a unified\nperspective for discrete time deep state space models and continuous time ones\nsuch as latent neural Ordinary Differential and Stochastic Differential\nEquations. It starts with an overview of the classical maximum likelihood based\napproach for learning SSMs, reviews variational autoencoder as a general\nlearning pipeline for neural network-based approaches in the presence of latent\nvariables, and discusses in detail representative deep learning models that\nfall under the SSM framework. Very recent developments, where SSMs are used as\nstandalone architectural modules for improving efficiency in sequence modeling,\nare also examined. Finally, examples involving mixed frequency and\nirregularly-spaced time series data are presented to demonstrate the advantage\nof SSMs in these settings.",
    "pdf_url": "http://arxiv.org/pdf/2412.11211v1",
    "published": "2024-12-15T15:04:35+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.OT"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2412.11210v2",
    "title": "ViPOcc: Leveraging Visual Priors from Vision Foundation Models for Single-View 3D Occupancy Prediction",
    "authors": [
      "Yi Feng",
      "Yu Han",
      "Xijing Zhang",
      "Tanghui Li",
      "Yanting Zhang",
      "Rui Fan"
    ],
    "abstract": "Inferring the 3D structure of a scene from a single image is an ill-posed and\nchallenging problem in the field of vision-centric autonomous driving. Existing\nmethods usually employ neural radiance fields to produce voxelized 3D\noccupancy, lacking instance-level semantic reasoning and temporal photometric\nconsistency. In this paper, we propose ViPOcc, which leverages the visual\npriors from vision foundation models (VFMs) for fine-grained 3D occupancy\nprediction. Unlike previous works that solely employ volume rendering for RGB\nand depth image reconstruction, we introduce a metric depth estimation branch,\nin which an inverse depth alignment module is proposed to bridge the domain gap\nin depth distribution between VFM predictions and the ground truth. The\nrecovered metric depth is then utilized in temporal photometric alignment and\nspatial geometric alignment to ensure accurate and consistent 3D occupancy\nprediction. Additionally, we also propose a semantic-guided non-overlapping\nGaussian mixture sampler for efficient, instance-aware ray sampling, which\naddresses the redundant and imbalanced sampling issue that still exists in\nprevious state-of-the-art methods. Extensive experiments demonstrate the\nsuperior performance of ViPOcc in both 3D occupancy prediction and depth\nestimation tasks on the KITTI-360 and KITTI Raw datasets. Our code is available\nat: \\url{https://mias.group/ViPOcc}.",
    "pdf_url": "http://arxiv.org/pdf/2412.11210v2",
    "published": "2024-12-15T15:04:27+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11209v1",
    "title": "A scattering construction for nonlinear wave equations on Kerr--Anti-de Sitter spacetimes",
    "authors": [
      "Gemma L. Hood"
    ],
    "abstract": "Existence of a large class of exponentially decaying solutions of the\nnonlinear massive wave equation $\\Box_g\\psi+\\alpha\\psi =\n\\mathcal{F}(\\psi,\\partial\\psi)$ on a Kerr--Anti-de Sitter exterior is\nestablished via a backwards scattering construction. Exponentially decaying\ndata is prescribed on the future event horizon, and Dirichlet data on the\ntimelike conformal boundary. The corresponding solutions exhibit the full\nfunctional degrees of freedom of the problem, but are exceptional in the sense\nthat (even) general solutions of the forward, linear ($\\mathcal{F}=0$) problem\nare known to decay at best inverse logarithmically. Our construction even\napplies outside of the \\textit{Hawking-Reall bound} on the spacetime angular\nmomentum, in which case, there exist exponentially growing mode solutions of\nthe forward problem. As for the analogous construction in the asymptotically\nflat case, the assumed exponential decay of the scattering data on the event\nhorizon is exploited to overcome the gravitational blueshift encountered in the\nbackwards construction.",
    "pdf_url": "http://arxiv.org/pdf/2412.11209v1",
    "published": "2024-12-15T14:58:26+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2412.11208v3",
    "title": "Point Cloud Deep Learning Methods for Particle Shower Reconstruction in the DHCAL",
    "authors": [
      "Maryna Borysova",
      "Shikma Bressler",
      "Eilam Gross",
      "Nilotpal Kakati",
      "Darina Zavazieva"
    ],
    "abstract": "Precision measurement of hadronic final states presents complex experimental\nchallenges. The study explores the concept of a gaseous Digital Hadronic\nCalorimeter (DHCAL) and discusses the potential benefits of employing Graph\nNeural Network (GNN) methods for future collider experiments. In particular, we\nuse GNN to describe calorimeter clusters as point clouds or a collection of\ndata points representing a three-dimensional object in space. Combined with\nGraph Attention Transformers (GATs) and DeepSets algorithms, this results in an\nimprovement over existing baseline techniques for particle identification and\nenergy resolution. We discuss the challenges encountered in implementing GNN\nmethods for energy measurement in digital calorimeters, e.g., the large variety\nof hadronic shower shapes and the hyper-parameter optimization. We also discuss\nthe dependency of the measured performance on the angle of the incoming\nparticle and on the detector granularity. Finally, we highlight potential\nfuture directions and applications of these techniques.",
    "pdf_url": "http://arxiv.org/pdf/2412.11208v3",
    "published": "2024-12-15T14:58:17+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11207v1",
    "title": "ProFe: Communication-Efficient Decentralized Federated Learning via Distillation and Prototypes",
    "authors": [
      "Pedro Miguel Sánchez Sánchez",
      "Enrique Tomás Martínez Beltrán",
      "Miguel Fernández Llamas",
      "Gérôme Bovet",
      "Gregorio Martínez Pérez",
      "Alberto Huertas Celdrán"
    ],
    "abstract": "Decentralized Federated Learning (DFL) trains models in a collaborative and\nprivacy-preserving manner while removing model centralization risks and\nimproving communication bottlenecks. However, DFL faces challenges in efficient\ncommunication management and model aggregation within decentralized\nenvironments, especially with heterogeneous data distributions. Thus, this\npaper introduces ProFe, a novel communication optimization algorithm for DFL\nthat combines knowledge distillation, prototype learning, and quantization\ntechniques. ProFe utilizes knowledge from large local models to train smaller\nones for aggregation, incorporates prototypes to better learn unseen classes,\nand applies quantization to reduce data transmitted during communication\nrounds. The performance of ProFe has been validated and compared to the\nliterature by using benchmark datasets like MNIST, CIFAR10, and CIFAR100.\nResults showed that the proposed algorithm reduces communication costs by up to\n~40-50% while maintaining or improving model performance. In addition, it adds\n~20% training time due to increased complexity, generating a trade-off.",
    "pdf_url": "http://arxiv.org/pdf/2412.11207v1",
    "published": "2024-12-15T14:49:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.NI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11206v1",
    "title": "An arithmetic algebraic regularity lemma",
    "authors": [
      "Anand Pillay",
      "Atticus Stonestrom"
    ],
    "abstract": "We give an 'arithmetic regularity lemma' for groups definable in finite\nfields, analogous to Tao's 'algebraic regularity lemma' for graphs definable in\nfinite fields. More specifically, we show that, for any $M>0$, any finite field\n$\\mathbf{F}$, and any definable group $(G,\\cdot)$ in $\\mathbf{F}$ and definable\nsubset $D\\subseteq G$, each of complexity at most $M$, there is a normal\ndefinable subgroup $H\\leqslant G$, of index and complexity $O_M(1)$, such that\nthe following holds: for any cosets $V,W$ of $H$, the bipartite graph\n$(V,W,xy^{-1}\\in D)$ is $O_M(|\\mathbf{F}|^{-1/2})$-quasirandom. Various\nanalogous regularity conditions follow; for example, for any $g\\in G$, the\nFourier coefficient $||\\widehat{1}_{H\\cap Dg}(\\pi)||_{\\mathrm{op}}$ is\n$O_M(|\\mathbf{F}|^{-1/8})$ for every non-trivial irreducible representation\n$\\pi$ of $H$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11206v1",
    "published": "2024-12-15T14:45:01+00:00",
    "categories": [
      "math.LO",
      "math.CO",
      "math.GR"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11205v1",
    "title": "Concept Learning in the Wild: Towards Algorithmic Understanding of Neural Networks",
    "authors": [
      "Elad Shoham",
      "Hadar Cohen",
      "Khalil Wattad",
      "Havana Rika",
      "Dan Vilenchik"
    ],
    "abstract": "Explainable AI (XAI) methods typically focus on identifying essential input\nfeatures or more abstract concepts for tasks like image or text classification.\nHowever, for algorithmic tasks like combinatorial optimization, these concepts\nmay depend not only on the input but also on the current state of the network,\nlike in the graph neural networks (GNN) case. This work studies concept\nlearning for an existing GNN model trained to solve Boolean satisfiability\n(SAT). \\textcolor{black}{Our analysis reveals that the model learns key\nconcepts matching those guiding human-designed SAT heuristics, particularly the\nnotion of 'support.' We demonstrate that these concepts are encoded in the top\nprincipal components (PCs) of the embedding's covariance matrix, allowing for\nunsupervised discovery. Using sparse PCA, we establish the minimality of these\nconcepts and show their teachability through a simplified GNN. Two direct\napplications of our framework are (a) We improve the convergence time of the\nclassical WalkSAT algorithm and (b) We use the discovered concepts to\n\"reverse-engineer\" the black-box GNN and rewrite it as a white-box textbook\nalgorithm. Our results highlight the potential of concept learning in\nunderstanding and enhancing algorithmic neural networks for combinatorial\noptimization tasks.",
    "pdf_url": "http://arxiv.org/pdf/2412.11205v1",
    "published": "2024-12-15T14:37:56+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11204v2",
    "title": "Analog model for Euclidean wormholes: Bose-Einstein condensate with dirty surfaces",
    "authors": [
      "Isaque P. de Freitas",
      "Nami F. Svaiter",
      "Gustavo O. Heymans"
    ],
    "abstract": "We study a Bose-Einstein condensate under the effects of the non-condensate\natomic cloud. We model the resulting linear interaction of the condensate with\nthe atomic gas as a quenched disorder. Using the distributional zeta function\nmethod, we obtain a representation for the quenched free energy as a series of\nintegral moments of the partition function. Assuming that the Bose-Einstein\ncondensate is confined between two planar surfaces, we show that random surface\nfields generate non-local terms in the effective action. The non-local effects\nin this condensed matter system define an analog model of a Euclidean wormhole.\nThe leading contribution of the non-local interactions to the Casimir pressure\nis obtained.",
    "pdf_url": "http://arxiv.org/pdf/2412.11204v2",
    "published": "2024-12-15T14:37:31+00:00",
    "categories": [
      "gr-qc",
      "cond-mat.dis-nn"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2412.11203v1",
    "title": "Task-Oriented Dialog Systems for the Senegalese Wolof Language",
    "authors": [
      "Derguene Mbaye",
      "Moussa Diallo"
    ],
    "abstract": "In recent years, we are seeing considerable interest in conversational agents\nwith the rise of large language models (LLMs). Although they offer considerable\nadvantages, LLMs also present significant risks, such as hallucination, which\nhinder their widespread deployment in industry. Moreover, low-resource\nlanguages such as African ones are still underrepresented in these systems\nlimiting their performance in these languages. In this paper, we illustrate a\nmore classical approach based on modular architectures of Task-oriented Dialog\nSystems (ToDS) offering better control over outputs. We propose a chatbot\ngeneration engine based on the Rasa framework and a robust methodology for\nprojecting annotations onto the Wolof language using an in-house machine\ntranslation system. After evaluating a generated chatbot trained on the Amazon\nMassive dataset, our Wolof Intent Classifier performs similarly to the one\nobtained for French, which is a resource-rich language. We also show that this\napproach is extensible to other low-resource languages, thanks to the intent\nclassifier's language-agnostic pipeline, simplifying the design of chatbots in\nthese languages.",
    "pdf_url": "http://arxiv.org/pdf/2412.11203v1",
    "published": "2024-12-15T14:35:49+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11202v2",
    "title": "Torsion of elliptic curves with rational $j$-invariant over the maximal elementary abelian 2-extension of $\\mathbb{Q}$",
    "authors": [
      "Lucas Hamada"
    ],
    "abstract": "In this paper, we classify the possible torsion subgroup structures of\nelliptic curves defined over the compositum of all quadratic extensions of the\nrational number field, whose $j$-invariant is a rational number not equal to 0\nor 1728.",
    "pdf_url": "http://arxiv.org/pdf/2412.11202v2",
    "published": "2024-12-15T14:33:58+00:00",
    "categories": [
      "math.NT",
      "math.AG",
      "11G05 (Primary) 12F05 (Secondary)"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11201v1",
    "title": "Phase diagram of Rydberg atoms in a two-leg rectangular ladder",
    "authors": [
      "Shu-Ao Liao",
      "Jin Zhang",
      "Li-Ping Yang"
    ],
    "abstract": "Using the density matrix renormalization group algorithm, we map the\nground-state phase diagram of a two-leg Rydberg ladder array with lattice\nspacings $a_x=2a_y$. We identify various density wave phases that spontaneously\nbreak the translational symmetry or the top-bottom reflection symmetry within\nthe ladder. By increasing the laser detuning from zero, where the system is in\na disordered phase that preserves all symmetries, we observe density wave\norders with spontaneous breaking of the translational $\\mathbb{Z}_p$ symmetries\nat intermediate detuning values, while the reflection symmetry is preserved.\nThese orders exhibit nonzero bond orders with positive expectation values on\nevery $p$th rung, thus labeled as $\\mathbb{Z}_p^+$ phases. At larger detuning\nvalues, another spontaneous breaking of the reflection symmetry, which\ndisrupted the bond orders on the rungs, occurs via an Ising phase transition.\nIn these phases, either the top or the bottom site is occupied in a staggered\nway on every $p$th rung, breaking the translational $\\mathbb{Z}_{2p}$ symmetry,\nthus labeled by $\\mathbb{Z}_{2p}$ phases. We locate and characterize the\n3-state Potts point and Ashkin-Teller point along the commensurate lines, as\nwell as the direct chiral phase transitions between the disordered phase and\nthe $\\mathbb{Z}_p^+$ ($p = 3, 4$) phases. Critical exponents $\\nu$ and $z$ are\ncalculated for both conformal and chiral phase transition points. We finally\nidentify two types of floating phases in the phase diagram: one characterized\nby a quasi-long-range incommensurate bond-order wave, and the other by a\nquasi-long-range incommensurate wave of density differences in the rungs. Our\nwork motivates further applications of Rydberg atom arrays in quantum\nsimulation.",
    "pdf_url": "http://arxiv.org/pdf/2412.11201v1",
    "published": "2024-12-15T14:28:59+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "hep-lat",
      "physics.atom-ph",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2412.11200v2",
    "title": "Spectrality of a class of moran measures on $\\mathbb{R}^2$",
    "authors": [
      "Jing-Cheng Liu",
      "Qiao-Qin Liu",
      "Jun Jason Luo",
      "Jia-jie Wang"
    ],
    "abstract": "We investigate spectral properties of planar Moran measures\n$\\mu_{\\{M_n\\},\\{D_n\\}}$ generated by sequences of expanding matrices\n$\\{M_n\\}\\subset GL(2,\\mathbb{Z})$ and digit sets $\\{D_n\\}\\subset\\mathbb{Z}^2$,\nwhere each digit set has the form\n  $$\n  D_n = \\left\\{\n  \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix},\n  \\begin{pmatrix} \\alpha_{n_1} \\\\ \\alpha_{n_2} \\end{pmatrix},\n  \\begin{pmatrix} \\beta_{n_1} \\\\ \\beta_{n_2} \\end{pmatrix},\n  \\begin{pmatrix} -\\alpha_{n_1}-\\beta_{n_1} \\\\ -\\alpha_{n_2}-\\beta_{n_2}\n\\end{pmatrix}\n  \\right\\}\n  $$\n  satisfying $\\alpha_{n_1}\\beta_{n_2}-\\alpha_{n_2}\\beta_{n_1} \\ne 0 \\pmod{2}$.\nUnder the hypotheses $|\\det(M_n)| > 4$ for all $n\\geq 1$, $\\sup_{n\\geq\n1}\\|M_n^{-1}\\| < 1$, and $\\{D_n\\}$ is finite, we establish the following\ncharacterization:\n  $$\n  \\mu_{\\{M_n\\},\\{D_n\\}} \\text{ is a spectral measure} \\Longleftrightarrow M_n\n\\in GL(2,2\\mathbb{Z}) \\text{ for all } n\\geq 2.\n  $$\n  Furthermore, for the critical case $|\\det(M_n)| = 4$, we derive a complete\nspectral criterion for a significant class of Moran measures through\ncombinatorial analysis of digit sets. These results extend current\nunderstanding of spectral self-affine measures to Moran-type constructions.",
    "pdf_url": "http://arxiv.org/pdf/2412.11200v2",
    "published": "2024-12-15T14:23:57+00:00",
    "categories": [
      "math.FA",
      "math.CA",
      "Primary 28A80, Secondary 42B10, 42C05"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11199v1",
    "title": "Arithmetic properties encoded in undermonoids",
    "authors": [
      "Felix Gotti",
      "Bangzheng Li"
    ],
    "abstract": "Let $M$ be a cancellative and commutative monoid. A submonoid $N$ of $M$ is\ncalled an undermonoid if the Grothendieck groups of $M$ and $N$ coincide. For a\ngiven property $\\mathfrak{p}$, we are interested in providing an answer to the\nfollowing main question: does it suffice to check that all undermonoids of $M$\nsatisfy $\\mathfrak{p}$ to conclude that all submonoids of $M$ satisfy\n$\\mathfrak{p}$? In this paper, we give a positive answer to this question for\nthe property of being atomic, and then we prove that if $M$ is hereditarily\natomic (i.e., every submonoid of $M$ is atomic), then $M$ must satisfy the\nACCP, proving a recent conjecture posed by Vulakh and the first author. We also\ngive positive answers to our main question for the following well-studied\nfactorization properties: the bounded factorization property,\nhalf-factoriality, and length-factoriality. Finally, we determine all the\nmonoids whose submonoids/undermonoids are half-factorial (or length-factorial).",
    "pdf_url": "http://arxiv.org/pdf/2412.11199v1",
    "published": "2024-12-15T14:22:00+00:00",
    "categories": [
      "math.AC",
      "Primary: 13F15, 13A05, Secondary: 20M13, 13F05"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11198v1",
    "title": "GEM: A Generalizable Ego-Vision Multimodal World Model for Fine-Grained Ego-Motion, Object Dynamics, and Scene Composition Control",
    "authors": [
      "Mariam Hassan",
      "Sebastian Stapf",
      "Ahmad Rahimi",
      "Pedro M B Rezende",
      "Yasaman Haghighi",
      "David Brüggemann",
      "Isinsu Katircioglu",
      "Lin Zhang",
      "Xiaoran Chen",
      "Suman Saha",
      "Marco Cannici",
      "Elie Aljalbout",
      "Botao Ye",
      "Xi Wang",
      "Aram Davtyan",
      "Mathieu Salzmann",
      "Davide Scaramuzza",
      "Marc Pollefeys",
      "Paolo Favaro",
      "Alexandre Alahi"
    ],
    "abstract": "We present GEM, a Generalizable Ego-vision Multimodal world model that\npredicts future frames using a reference frame, sparse features, human poses,\nand ego-trajectories. Hence, our model has precise control over object\ndynamics, ego-agent motion and human poses. GEM generates paired RGB and depth\noutputs for richer spatial understanding. We introduce autoregressive noise\nschedules to enable stable long-horizon generations. Our dataset is comprised\nof 4000+ hours of multimodal data across domains like autonomous driving,\negocentric human activities, and drone flights. Pseudo-labels are used to get\ndepth maps, ego-trajectories, and human poses. We use a comprehensive\nevaluation framework, including a new Control of Object Manipulation (COM)\nmetric, to assess controllability. Experiments show GEM excels at generating\ndiverse, controllable scenarios and temporal consistency over long generations.\nCode, models, and datasets are fully open-sourced.",
    "pdf_url": "http://arxiv.org/pdf/2412.11198v1",
    "published": "2024-12-15T14:21:19+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11197v1",
    "title": "The hydrodynamic approximation of the semiclassical dissipation kernel in stochastic gravity",
    "authors": [
      "Seema Satin"
    ],
    "abstract": "Semiclassical stochastic gravity is aimed at studying extended structure\nformation in the early universe. Rigorous developments in this area include the\nsemiclassical noise and dissipation kernels which are obtained in terms of\nquantum stress energy tensor composed of scalar fields. The present article\nforms an important step in an effort to extend the theory in the decoherence\nlimit and hydrodynamic approximation of the scalar fields. Such extensions will\nmake it possible to analyse the extended structure formation around the\ndecoherence era of the inflaton field in cosmology. On the other hand,\nmodelling dissipation in fluids and effective fluids is a challenge and long\nstanding mathematical physics related hurdles have posed difficulties for\nprogress in this direction.The present article marks the beginning of a new way\nto model dissipation in an effective fluid using the widely accepted\ncorrespondence between the semiclassical fields and effective fluid\napproximation. A similar approach has been recently carried out for noise\n(fluctuations) kernel correspondence between the two, we now touch upon\ndissipation in the relativistic effective fluids.",
    "pdf_url": "http://arxiv.org/pdf/2412.11197v1",
    "published": "2024-12-15T14:20:18+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2412.11196v1",
    "title": "Drawing the Line: Enhancing Trustworthiness of MLLMs Through the Power of Refusal",
    "authors": [
      "Yuhao Wang",
      "Zhiyuan Zhu",
      "Heyang Liu",
      "Yusheng Liao",
      "Hongcheng Liu",
      "Yanfeng Wang",
      "Yu Wang"
    ],
    "abstract": "Multimodal large language models (MLLMs) excel at multimodal perception and\nunderstanding, yet their tendency to generate hallucinated or inaccurate\nresponses undermines their trustworthiness. Existing methods have largely\noverlooked the importance of refusal responses as a means of enhancing MLLMs\nreliability. To bridge this gap, we present the Information Boundary-aware\nLearning Framework (InBoL), a novel approach that empowers MLLMs to refuse to\nanswer user queries when encountering insufficient information. To the best of\nour knowledge, InBoL is the first framework that systematically defines the\nconditions under which refusal is appropriate for MLLMs using the concept of\ninformation boundaries proposed in our paper. This framework introduces a\ncomprehensive data generation pipeline and tailored training strategies to\nimprove the model's ability to deliver appropriate refusal responses. To\nevaluate the trustworthiness of MLLMs, we further propose a user-centric\nalignment goal along with corresponding metrics. Experimental results\ndemonstrate a significant improvement in refusal accuracy without noticeably\ncompromising the model's helpfulness, establishing InBoL as a pivotal\nadvancement in building more trustworthy MLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2412.11196v1",
    "published": "2024-12-15T14:17:14+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11195v3",
    "title": "Deterministic Even-Cycle Detection in Broadcast CONGEST",
    "authors": [
      "Pierre Fraigniaud",
      "Maël Luce",
      "Frédéric Magniez",
      "Ioan Todinca"
    ],
    "abstract": "We show that, for every $k\\geq 2$, $C_{2k}$-freeness can be decided in\n$O(n^{1-1/k})$ rounds in the Broadcast CONGEST model, by a deterministic\nalgorithm. This (deterministic) round-complexity is optimal for $k=2$ up to\nlogarithmic factors thanks to the lower bound for $C_4$-freeness by Drucker et\nal. [PODC 2014], which holds even for randomized algorithms. Moreover it\nmatches the round-complexity of the best known randomized algorithms by\nCensor-Hillel et al. [DISC 2020] for $k\\in\\{3,4,5\\}$, and by Fraigniaud et al.\n[PODC 2024] for $k\\geq 6$. Our algorithm uses parallel BFS-explorations with\ndeterministic selections of the set of paths that are forwarded at each round,\nin a way similar to what was done for the detection of odd-length cycles, by\nKorhonen and Rybicki [OPODIS 2017]. However, the key element in the design and\nanalysis of our algorithm is a new combinatorial result bounding the \"local\ndensity\" of graphs without $2k$-cycles, which we believe is interesting on its\nown.",
    "pdf_url": "http://arxiv.org/pdf/2412.11195v3",
    "published": "2024-12-15T14:13:46+00:00",
    "categories": [
      "cs.DC",
      "cs.DS"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11194v1",
    "title": "SoK: On Closing the Applicability Gap in Automated Vulnerability Detection",
    "authors": [
      "Ezzeldin Shereen",
      "Dan Ristea",
      "Sanyam Vyas",
      "Shae McFadden",
      "Madeleine Dwyer",
      "Chris Hicks",
      "Vasilios Mavroudis"
    ],
    "abstract": "The frequent discovery of security vulnerabilities in both open-source and\nproprietary software underscores the urgent need for earlier detection during\nthe development lifecycle. Initiatives such as DARPA's Artificial Intelligence\nCyber Challenge (AIxCC) aim to accelerate Automated Vulnerability Detection\n(AVD), seeking to address this challenge by autonomously analyzing source code\nto identify vulnerabilities.\n  This paper addresses two primary research questions: (RQ1) How is current AVD\nresearch distributed across its core components? (RQ2) What key areas should\nfuture research target to bridge the gap in the practical applicability of AVD\nthroughout software development? To answer these questions, we conduct a\nsystematization over 79 AVD articles and 17 empirical studies, analyzing them\nacross five core components: task formulation and granularity, input\nprogramming languages and representations, detection approaches and key\nsolutions, evaluation metrics and datasets, and reported performance.\n  Our systematization reveals that the narrow focus of AVD research-mainly on\nspecific tasks and programming languages-limits its practical impact and\noverlooks broader areas crucial for effective, real-world vulnerability\ndetection. We identify significant challenges, including the need for\ndiversified problem formulations, varied detection granularities, broader\nlanguage support, better dataset quality, enhanced reproducibility, and\nincreased practical impact. Based on these findings we identify research\ndirections that will enhance the effectiveness and applicability of AVD\nsolutions in software security.",
    "pdf_url": "http://arxiv.org/pdf/2412.11194v1",
    "published": "2024-12-15T14:01:41+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11193v1",
    "title": "Light-T2M: A Lightweight and Fast Model for Text-to-motion Generation",
    "authors": [
      "Ling-An Zeng",
      "Guohong Huang",
      "Gaojie Wu",
      "Wei-Shi Zheng"
    ],
    "abstract": "Despite the significant role text-to-motion (T2M) generation plays across\nvarious applications, current methods involve a large number of parameters and\nsuffer from slow inference speeds, leading to high usage costs. To address\nthis, we aim to design a lightweight model to reduce usage costs. First, unlike\nexisting works that focus solely on global information modeling, we recognize\nthe importance of local information modeling in the T2M task by reconsidering\nthe intrinsic properties of human motion, leading us to propose a lightweight\nLocal Information Modeling Module. Second, we introduce Mamba to the T2M task,\nreducing the number of parameters and GPU memory demands, and we have designed\na novel Pseudo-bidirectional Scan to replicate the effects of a bidirectional\nscan without increasing parameter count. Moreover, we propose a novel Adaptive\nTextual Information Injector that more effectively integrates textual\ninformation into the motion during generation. By integrating the\naforementioned designs, we propose a lightweight and fast model named\nLight-T2M. Compared to the state-of-the-art method, MoMask, our Light-T2M model\nfeatures just 10\\% of the parameters (4.48M vs 44.85M) and achieves a 16\\%\nfaster inference time (0.152s vs 0.180s), while surpassing MoMask with an FID\nof \\textbf{0.040} (vs. 0.045) on HumanML3D dataset and 0.161 (vs. 0.228) on\nKIT-ML dataset. The code is available at\nhttps://github.com/qinghuannn/light-t2m.",
    "pdf_url": "http://arxiv.org/pdf/2412.11193v1",
    "published": "2024-12-15T13:58:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11192v1",
    "title": "From Votes to Volatility Predicting the Stock Market on Election Day",
    "authors": [
      "Igor L. R. Azevedo",
      "Toyotaro Suzumura"
    ],
    "abstract": "Stock market forecasting has been a topic of extensive research, aiming to\nprovide investors with optimal stock recommendations for higher returns. In\nrecent years, this field has gained even more attention due to the widespread\nadoption of deep learning models. While these models have achieved impressive\naccuracy in predicting stock behavior, tailoring them to specific scenarios has\nbecome increasingly important. Election Day represents one such critical\nscenario, characterized by intensified market volatility, as the winning\ncandidate's policies significantly impact various economic sectors and\ncompanies. To address this challenge, we propose the Election Day Stock Market\nForecasting (EDSMF) Model. Our approach leverages the contextual capabilities\nof large language models alongside specialized agents designed to analyze the\npolitical and economic consequences of elections. By building on a\nstate-of-the-art architecture, we demonstrate that EDSMF improves the\npredictive performance of the S&P 500 during this uniquely volatile day.",
    "pdf_url": "http://arxiv.org/pdf/2412.11192v1",
    "published": "2024-12-15T13:58:20+00:00",
    "categories": [
      "q-fin.CP",
      "cs.AI"
    ],
    "primary_category": "q-fin.CP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11191v1",
    "title": "Products of C*-algebras that do not embed into the Calkin algebra",
    "authors": [
      "Damian Głodkowski",
      "Piotr Koszmider"
    ],
    "abstract": "We consider the Calkin algebra $\\mathcal{Q}(\\ell_2)$, i.e., the quotient of\nthe algebra $\\mathcal B(\\ell_2)$ of all bounded linear operators on the\nseparable Hilbert space $\\ell_2$ divided by the ideal $\\mathcal K(\\ell_2)$ of\nall compact operators on $\\ell_2$. We show that in the Cohen model of set\ntheory ZFC there is no embedding of the product $(c_0(2^\\omega))^{\\mathbb{N}}$\nof infinitely many copies of the abelian C*-algebra $c_0(2^\\omega)$ into\n$\\mathcal{Q}(\\ell_2)$ (while $c_0(2^\\omega)$ always embeds into\n$\\mathcal{Q}(\\ell_2)$). This enlarges the collection of the known examples due\nto Vaccaro and to McKenney and Vignati of abelian algebras, asymptotic sequence\nalgebras, reduced products and coronas of stabilizations which consistently do\nnot embed into the Calkin algebra. As in the Cohen model the rigidity of\nquotient structures fails in general, our methods do not rely on these rigidity\nphenomena as is the case of most examples mentioned above. The results should\nbe considered in the context of the result of Farah, Hirshberg and Vignati\nwhich says that consistently all C*-algebras of density up to $2^\\omega$ do\nembed into $\\mathcal{Q}(\\ell_2)$. In particular, the algebra\n$(c_0(2^\\omega))^{\\mathbb{N}}$ consistently embeds into the Calkin algebra as\nwell.",
    "pdf_url": "http://arxiv.org/pdf/2412.11191v1",
    "published": "2024-12-15T13:53:32+00:00",
    "categories": [
      "math.OA",
      "math.FA",
      "math.LO"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11190v1",
    "title": "A one-dimensional planar Besicovitch-type set",
    "authors": [
      "Iqra Altaf"
    ],
    "abstract": "A $\\Gamma$-Besicovitch set is a set which contains a rotated copy of $\\Gamma$\nin every direction. Our main result is the construction of a non-trivial\n$1$-rectifiable set $\\Gamma$ in the plane, for which there exists a\n1-dimensional $\\Gamma$-Besicovitch set.",
    "pdf_url": "http://arxiv.org/pdf/2412.11190v1",
    "published": "2024-12-15T13:50:04+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11189v3",
    "title": "Leveraging Large Language Models for Active Merchant Non-player Characters",
    "authors": [
      "Byungjun Kim",
      "Minju Kim",
      "Dayeon Seo",
      "Bugeun Kim"
    ],
    "abstract": "We highlight two significant issues leading to the passivity of current\nmerchant non-player characters (NPCs): pricing and communication. While\nimmersive interactions with active NPCs have been a focus, price negotiations\nbetween merchant NPCs and players remain underexplored. First, passive pricing\nrefers to the limited ability of merchants to modify predefined item prices.\nSecond, passive communication means that merchants can only interact with\nplayers in a scripted manner. To tackle these issues and create an active\nmerchant NPC, we propose a merchant framework based on large language models\n(LLMs), called MART, which consists of an appraiser module and a negotiator\nmodule. We conducted two experiments to explore various implementation options\nunder different training methods and LLM sizes, considering a range of possible\ngame environments. Our findings indicate that finetuning methods, such as\nsupervised finetuning (SFT) and knowledge distillation (KD), are effective in\nusing smaller LLMs to implement active merchant NPCs. Additionally, we found\nthree irregular cases arising from the responses of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2412.11189v3",
    "published": "2024-12-15T13:48:39+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2412.11188v2",
    "title": "Assessing the Robustness and Resilience of U.S. Strategic Highways: A Network Science Perspective",
    "authors": [
      "Sukhwan Chung",
      "Daniel Sardak",
      "Jeffrey Cegan",
      "Igor Linkov"
    ],
    "abstract": "Network science is a powerful tool for analyzing transportation networks,\noffering insights into their structures and enabling the quantification of\nresilience and robustness. Understanding the underlying structures of\ntransportation networks is crucial for effective infrastructure planning and\nmaintenance. In military contexts, network science is valuable for analyzing\nlogistics networks, critical for the movement and supply of troops and\nequipment. The U.S. Army's logistical success, particularly in the\n\"fort-to-port\" phase, relies heavily on the Strategic Highway Network\n(STRAHNET) in the U.S., which is a system of public highways crucial for\nmilitary deployments. However, the shared nature of these networks with\ncivilian users introduces unique challenges, including vulnerabilities to\ncyberattacks and physical sabotage, which is highlighted by the concept of\ncontested logistics. This paper proposes a method using network science and\ngeographic information systems (GIS) to assess the robustness and resilience of\ntransportation networks, specifically applied to military logistics. Our\nfindings indicate that while the STRAHNET is robust against targeted\ndisruptions, it is more resilient to random disruptions.",
    "pdf_url": "http://arxiv.org/pdf/2412.11188v2",
    "published": "2024-12-15T13:45:11+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11187v1",
    "title": "Analyzing the Attention Heads for Pronoun Disambiguation in Context-aware Machine Translation Models",
    "authors": [
      "Paweł Mąka",
      "Yusuf Can Semerci",
      "Jan Scholtes",
      "Gerasimos Spanakis"
    ],
    "abstract": "In this paper, we investigate the role of attention heads in Context-aware\nMachine Translation models for pronoun disambiguation in the English-to-German\nand English-to-French language directions. We analyze their influence by both\nobserving and modifying the attention scores corresponding to the plausible\nrelations that could impact a pronoun prediction. Our findings reveal that\nwhile some heads do attend the relations of interest, not all of them influence\nthe models' ability to disambiguate pronouns. We show that certain heads are\nunderutilized by the models, suggesting that model performance could be\nimproved if only the heads would attend one of the relations more strongly.\nFurthermore, we fine-tune the most promising heads and observe the increase in\npronoun disambiguation accuracy of up to 5 percentage points which demonstrates\nthat the improvements in performance can be solidified into the models'\nparameters.",
    "pdf_url": "http://arxiv.org/pdf/2412.11187v1",
    "published": "2024-12-15T13:42:49+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.12560v1",
    "title": "Laboratory modeling of MHD accretion disks",
    "authors": [
      "Christophe Gissinger"
    ],
    "abstract": "This review article summarizes two decades of laboratory research aimed at\nunderstanding the dynamics of accretion disks, with particular emphasis on\nmagnetohydrodynamic experiments involving liquid metals and plasmas. First, the\nTaylor-Couette experiments demonstrated the generation of magnetorotational\ninstability (MRI) in liquid metals, and highlighted how this instability is\ncritically influenced by boundary conditions and the geometry of the applied\nmagnetic field. These experiments also highlight the nonlinear transition to\nturbulence in accretion disks, and their link with other MHD instabilities in\ncentrifugally-stable flows. A complementary approach, involving laboratory\nexperiments with volumetric fluid driving rather than rotating boundaries,\nenables a quantitative study of angular momentum transport by Keplerian\nturbulence. Collectively, these various laboratory studies offer new\nconstraints on the theoretical models designed to explain the dynamics of\naccretion disks. This is particularly true with regard to the role of Keplerian\nturbulence in protoplanetary disks, where recent observations from the ALMA\ntelescope have considerably revised previously expected values of the magnitude\nof the turbulent fluctuations. Finally, the paper discusses outstanding\nquestions and future prospects in laboratory modeling of accretion disks.",
    "pdf_url": "http://arxiv.org/pdf/2412.12560v1",
    "published": "2024-12-15T13:42:12+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP",
      "astro-ph.HE",
      "astro-ph.IM",
      "physics.plasm-ph"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2412.17834v1",
    "title": "EEG-GMACN: Interpretable EEG Graph Mutual Attention Convolutional Network",
    "authors": [
      "Haili Ye",
      "Stephan Goerttler",
      "Fei He"
    ],
    "abstract": "Electroencephalogram (EEG) is a valuable technique to record brain electrical\nactivity through electrodes placed on the scalp. Analyzing EEG signals\ncontributes to the understanding of neurological conditions and developing\nbrain-computer interface. Graph Signal Processing (GSP) has emerged as a\npromising method for EEG spatial-temporal analysis, by further considering the\ntopological relationships between electrodes. However, existing GSP studies\nlack interpretability of electrode importance and the credibility of prediction\nconfidence. This work proposes an EEG Graph Mutual Attention Convolutional\nNetwork (EEG-GMACN), by introducing an 'Inverse Graph Weight Module' to output\ninterpretable electrode graph weights, enhancing the clinical credibility and\ninterpretability of EEG classification results. Additionally, we incorporate a\nmutual attention mechanism module into the model to improve its capability to\ndistinguish critical electrodes and introduce credibility calibration to assess\nthe uncertainty of prediction results. This study enhances the transparency and\neffectiveness of EEG analysis, paving the way for its widespread use in\nclinical and neuroscience research.",
    "pdf_url": "http://arxiv.org/pdf/2412.17834v1",
    "published": "2024-12-15T13:37:20+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11186v1",
    "title": "Efficient Quantization-Aware Training on Segment Anything Model in Medical Images and Its Deployment",
    "authors": [
      "Haisheng Lu",
      "Yujie Fu",
      "Fan Zhang",
      "Le Zhang"
    ],
    "abstract": "Medical image segmentation is a critical component of clinical practice, and\nthe state-of-the-art MedSAM model has significantly advanced this field.\nNevertheless, critiques highlight that MedSAM demands substantial computational\nresources during inference. To address this issue, the CVPR 2024 MedSAM on\nLaptop Challenge was established to find an optimal balance between accuracy\nand processing speed. In this paper, we introduce a quantization-aware training\npipeline designed to efficiently quantize the Segment Anything Model for\nmedical images and deploy it using the OpenVINO inference engine. This pipeline\noptimizes both training time and disk storage. Our experimental results confirm\nthat this approach considerably enhances processing speed over the baseline,\nwhile still achieving an acceptable accuracy level. The training script,\ninference script, and quantized model are publicly accessible at\nhttps://github.com/AVC2-UESTC/QMedSAM.",
    "pdf_url": "http://arxiv.org/pdf/2412.11186v1",
    "published": "2024-12-15T13:35:07+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11185v1",
    "title": "Transliterated Zero-Shot Domain Adaptation for Automatic Speech Recognition",
    "authors": [
      "Han Zhu",
      "Gaofeng Cheng",
      "Qingwei Zhao",
      "Pengyuan Zhang"
    ],
    "abstract": "The performance of automatic speech recognition models often degenerates on\ndomains not covered by the training data. Domain adaptation can address this\nissue, assuming the availability of the target domain data in the target\nlanguage. However, such assumption does not stand in many real-world\napplications. To make domain adaptation more applicable, we address the problem\nof zero-shot domain adaptation (ZSDA), where target domain data is unavailable\nin the target language. Instead, we transfer the target domain knowledge from\nanother source language where the target domain data is more accessible. To do\nthat, we first perform cross-lingual pre-training (XLPT) to share domain\nknowledge across languages, then use target language fine-tuning to build the\nfinal model. One challenge in this practice is that the pre-trained knowledge\ncan be forgotten during fine-tuning, resulting in sub-optimal adaptation\nperformance. To address this issue, we propose transliterated ZSDA to achieve\nconsistent pre-training and fine-tuning labels, leading to maximum preservation\nof the pre-trained knowledge. Experimental results show that transliterated\nZSDA relatively decreases the word error rate by 9.2% compared with a wav2vec\n2.0 baseline. Moreover, transliterated ZSDA consistently outperforms\nself-supervised ZSDA and performs on par with supervised ZSDA, proving the\nsuperiority of transliteration-based pre-training labels.",
    "pdf_url": "http://arxiv.org/pdf/2412.11185v1",
    "published": "2024-12-15T13:32:08+00:00",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2412.11184v1",
    "title": "New Approximation Guarantees for The Economic Warehouse Lot Scheduling Problem",
    "authors": [
      "Danny Segev"
    ],
    "abstract": "In this paper, we present long-awaited algorithmic advances toward the\nefficient construction of near-optimal replenishment policies for a true\ninventory management classic, the economic warehouse lot scheduling problem.\nWhile this paradigm has accumulated a massive body of surrounding literature\nsince its inception in the late '50s, we are still very much in the dark as far\nas basic computational questions are concerned, perhaps due to the evasive\nnature of dynamic policies in this context. The latter feature forced earlier\nattempts to either study highly-structured classes of policies or to forgo\nprovably-good performance guarantees altogether; to this day, rigorously\nanalyzable results have been few and far between.\n  The current paper develops novel analytical foundations for directly\ncompeting against dynamic policies. Combined with further algorithmic progress\nand newly-gained insights, these ideas culminate to a polynomial-time\napproximation scheme for constantly-many commodities as well as to a\nproof-of-concept $(2-\\frac{17}{5000} + \\epsilon)$-approximation for general\nproblem instances. In this regard, the efficient design of $\\epsilon$-optimal\ndynamic policies appeared to have been out of reach, since beyond algorithmic\nchallenges by themselves, even the polynomial-space representation of such\npolicies has been a fundamental open question. On the other front, our\nsub-$2$-approximation constitutes the first improvement over the performance\nguarantees achievable via ``stationary order sizes and stationary intervals''\n(SOSI) policies, which have been state-of-the-art since the mid-'90s.",
    "pdf_url": "http://arxiv.org/pdf/2412.11184v1",
    "published": "2024-12-15T13:28:50+00:00",
    "categories": [
      "cs.DS",
      "math.OC"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2412.11183v2",
    "title": "OccScene: Semantic Occupancy-based Cross-task Mutual Learning for 3D Scene Generation",
    "authors": [
      "Bohan Li",
      "Xin Jin",
      "Jianan Wang",
      "Yukai Shi",
      "Yasheng Sun",
      "Xiaofeng Wang",
      "Zhuang Ma",
      "Baao Xie",
      "Chao Ma",
      "Xiaokang Yang",
      "Wenjun Zeng"
    ],
    "abstract": "Recent diffusion models have demonstrated remarkable performance in both 3D\nscene generation and perception tasks. Nevertheless, existing methods typically\nseparate these two processes, acting as a data augmenter to generate synthetic\ndata for downstream perception tasks. In this work, we propose OccScene, a\nnovel mutual learning paradigm that integrates fine-grained 3D perception and\nhigh-quality generation in a unified framework, achieving a cross-task win-win\neffect. OccScene generates new and consistent 3D realistic scenes only\ndepending on text prompts, guided with semantic occupancy in a joint-training\ndiffusion framework. To align the occupancy with the diffusion latent, a\nMamba-based Dual Alignment module is introduced to incorporate fine-grained\nsemantics and geometry as perception priors. Within OccScene, the perception\nmodule can be effectively improved with customized and diverse generated\nscenes, while the perception priors in return enhance the generation\nperformance for mutual benefits. Extensive experiments show that OccScene\nachieves realistic 3D scene generation in broad indoor and outdoor scenarios,\nwhile concurrently boosting the perception models to achieve substantial\nperformance improvements in the 3D perception task of semantic occupancy\nprediction.",
    "pdf_url": "http://arxiv.org/pdf/2412.11183v2",
    "published": "2024-12-15T13:26:51+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11182v1",
    "title": "Rational homotopy theory of operad modules through colored operads",
    "authors": [
      "Thomas Willwacher"
    ],
    "abstract": "We extend the rational homotopy theory of operads developed by B. Fresse to\nseveral types of modules over operads.",
    "pdf_url": "http://arxiv.org/pdf/2412.11182v1",
    "published": "2024-12-15T13:24:05+00:00",
    "categories": [
      "math.AT",
      "math.QA"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11181v1",
    "title": "Unveiling Magnon-Magnon Coupling and Its Dynamic Control in Nanomagnets",
    "authors": [
      "Siddhesh Sharad Kashid",
      "Sachin Verma",
      "Abhishek Maurya",
      "Manjushree Maity",
      "Kuldeep Kumar Shrivastava",
      "Rajeev Singh",
      "Biswanath Bhoi"
    ],
    "abstract": "Hybrid magnonics, exploring the coupling between magnons and quantum systems,\nis an exciting field for developing next-generation information technologies.\nAchieving a strong and tunable magnon-magnon coupling (MMC) in confined\nnanomagnets is crucial for the on-chip integration of these hybrid systems and\nadvancing the field. In this work, we numerically investigate the interactions\nbetween different magnon modes excited within an elliptical magnonic nano-disc\n(EMND), demonstrating an anti-crossing effect in the dispersion spectra. A\ncomprehensive theoretical framework was presented that explains this\nanti-crossing phenomenon as a result of MMC and provide estimates for the\nstrength of the coupling (g). Furthermore, we show that this intermodal\ncoupling can be tuned from a strong coupling regime (g = 300 MHz) to a weak\ncoupling regime by varying the direction of the external magnetic field and the\nintrinsic properties of the EMND. Our combined numerical and theoretical\nfindings offer new insights into MMC, significantly advancing the field of\nquantum magnonics and magnon-based quantum information technology.",
    "pdf_url": "http://arxiv.org/pdf/2412.11181v1",
    "published": "2024-12-15T13:21:51+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "physics.app-ph",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2412.11180v3",
    "title": "TINED: GNNs-to-MLPs by Teacher Injection and Dirichlet Energy Distillation",
    "authors": [
      "Ziang Zhou",
      "Zhihao Ding",
      "Jieming Shi",
      "Qing Li",
      "Shiqi Shen"
    ],
    "abstract": "Graph Neural Networks (GNNs) are pivotal in graph-based learning,\nparticularly excelling in node classification. However, their scalability is\nhindered by the need for multi-hop data during inference, limiting their\napplication in latency-sensitive scenarios. Recent efforts to distill GNNs into\nmulti-layer perceptrons (MLPs) for faster inference often underutilize the\nlayer-level insights of GNNs. In this paper, we present TINED, a novel approach\nthat distills GNNs to MLPs on a layer-by-layer basis using Teacher Injection\nand Dirichlet Energy Distillation techniques. We focus on two key operations in\nGNN layers: feature transformation (FT) and graph propagation (GP). We\nrecognize that FT is computationally equivalent to a fully-connected (FC) layer\nin MLPs. Thus, we propose directly transferring teacher parameters from an FT\nin a GNN to an FC layer in the student MLP, enhanced by fine-tuning. In TINED,\nthe FC layers in an MLP replicate the sequence of FTs and GPs in the GNN. We\nalso establish a theoretical bound for GP approximation. Furthermore, we note\nthat FT and GP operations in GNN layers often exhibit opposing smoothing\neffects: GP is aggressive, while FT is conservative. Using Dirichlet energy, we\ndevelop a DE ratio to measure these effects and propose Dirichlet Energy\nDistillation to convey these characteristics from GNN layers to MLP layers.\nExtensive experiments show that TINED outperforms GNNs and leading distillation\nmethods across various settings and seven datasets. Source code are available\nat https://github.com/scottjiao/TINED_ICML25/.",
    "pdf_url": "http://arxiv.org/pdf/2412.11180v3",
    "published": "2024-12-15T13:18:56+00:00",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.16190v1",
    "title": "Resilient Cloud cluster with DevSecOps security model, automates a data analysis, vulnerability search and risk calculation",
    "authors": [
      "Abed Saif Ahmed Alghawli",
      "Tamara Radivilova"
    ],
    "abstract": "Automated, secure software development is an important task of\ndigitalization, which is solved with the DevSecOps approach. An important part\nof the DevSecOps approach is continuous risk assessment, which is necessary to\nidentify and evaluate risk factors. Combining the development cycle with\ncontinuous risk assessment creates synergies in software development and\noperation and minimizes vulnerabilities. The article presents the main methods\nof deploying web applications, ways to increase the level of information\nsecurity at all stages of product development, compares different types of\ninfrastructures and cloud computing providers, and analyzes modern tools used\nto automate processes. The cloud cluster was deployed using Terraform and the\nJenkins pipeline, which is written in the Groovy programming language, which\nchecks program code for vulnerabilities and allows you to fix violations at the\nearliest stages of developing secure web applications. The developed cluster\nimplements the proposed algorithm for automated risk assessment based on the\ncalculation (modeling) of threats and vulnerabilities of cloud infrastructure,\nwhich operates in real time, periodically collecting all information and\nadjusting the system in accordance with the risk and applied controls. The\nalgorithm for calculating risk and losses is based on statistical data and the\nconcept of the FAIR information risk assessment methodology. The risk value\nobtained using the proposed method is quantitative, which allows more efficient\nforecasting of information security costs in software development.",
    "pdf_url": "http://arxiv.org/pdf/2412.16190v1",
    "published": "2024-12-15T13:11:48+00:00",
    "categories": [
      "cs.CR",
      "91G70",
      "C.2.4; H.4.4; K.6.4"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11179v1",
    "title": "Treatment Evaluation at the Intensive and Extensive Margins",
    "authors": [
      "Phillip Heiler",
      "Asbjørn Kaufmann",
      "Bezirgen Veliyev"
    ],
    "abstract": "This paper provides a solution to the evaluation of treatment effects in\nselective samples when neither instruments nor parametric assumptions are\navailable. We provide sharp bounds for average treatment effects under a\nconditional monotonicity assumption for all principal strata, i.e. units\ncharacterizing the complete intensive and extensive margins. Most importantly,\nwe allow for a large share of units whose selection is indifferent to\ntreatment, e.g. due to non-compliance. The existence of such a population is\ncrucially tied to the regularity of sharp population bounds and thus\nconventional asymptotic inference for methods such as Lee bounds can be\nmisleading. It can be solved using smoothed outer identification regions for\ninference. We provide semiparametrically efficient debiased machine learning\nestimators for both regular and smooth bounds that can accommodate\nhigh-dimensional covariates and flexible functional forms. Our study of active\nlabor market policy reveals the empirical prevalence of the aforementioned\nindifference population and supports results from previous impact analysis\nunder much weaker assumptions.",
    "pdf_url": "http://arxiv.org/pdf/2412.11179v1",
    "published": "2024-12-15T13:07:22+00:00",
    "categories": [
      "econ.EM"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2412.11178v1",
    "title": "A UV to X-ray view of soft excess in type 1 AGNs: I. sample selection and spectral profile",
    "authors": [
      "Shi-Jiang Chen",
      "Jun-Xian Wang",
      "Jia-Lai Kang",
      "Wen-Yong Kang",
      "Hao Sou",
      "Teng Liu",
      "Zhen-Yi Cai",
      "Zhen-Bo Su"
    ],
    "abstract": "A core sample of 59 unobscured type 1 AGNs with simultaneous XMM-Newton X-ray\nand UV observations is compiled from archive to probe the nature of soft X-ray\nexcess (SE). In the first paper of this series, our focus centers on\nscrutinizing the spectral profile of the soft excess. Of the sources, $\\approx$\n71% (42/59) exhibit powerlaw-like (po-like) soft excess, while $\\approx$ 29%\n(17/59) exhibit blackbody-like (bb-like) soft excess. We show a cut-off\npowerlaw could uniformly characterize both types of soft excesses, with median\nEcut of 1.40 keV for po-like and 0.14 keV for bb-like. For the first time, we\nreport a robust and quantitative correlation between the SE profile and SE\nstrength (the ratio of SE luminosity to that of the primary powerlaw continuum\nin 0.5 - 2.0 keV), indicating that stronger soft excess is more likely to be\npo-like, or effectively has a higher Ecut. This correlation cannot be explained\nby ionized disk reflection alone, which produces mostly bb-like soft excess\n(Ecut $\\sim$ 0.1 keV) as revealed by relxilllp simulation. Remarkably, we show\nwith simulations that a toy hybrid scenario, where both ionized disk reflection\n(relxilllp, with all reflection parameters fixed at default values except for\nionization of the disk) and warm corona (compTT, with temperature fixed at 1\nkeV) contribute to the observed soft excess, can successfully reproduce the\nobserved correlation. This highlights the ubiquitous hybrid nature of the soft\nX-ray excess in AGNs, and underscores the importance of considering both\ncomponents while fitting the spectra of soft excess.",
    "pdf_url": "http://arxiv.org/pdf/2412.11178v1",
    "published": "2024-12-15T13:04:48+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11177v2",
    "title": "A Progressive Transformer for Unifying Binary Code Embedding and Knowledge Transfer",
    "authors": [
      "Hanxiao Lu",
      "Hongyu Cai",
      "Yiming Liang",
      "Antonio Bianchi",
      "Z. Berkay Celik"
    ],
    "abstract": "Language model approaches have recently been integrated into binary analysis\ntasks, such as function similarity detection and function signature recovery.\nThese models typically employ a two-stage training process: pre-training via\nMasked Language Modeling (MLM) on machine code and fine-tuning for specific\ntasks. While MLM helps to understand binary code structures, it ignores\nessential code characteristics, including control and data flow, which\nnegatively affect model generalization. Recent work leverages domain-specific\nfeatures (e.g., control flow graphs and dynamic execution traces) in\ntransformer-based approaches to improve binary code semantic understanding.\nHowever, this approach involves complex feature engineering, a cumbersome and\ntime-consuming process that can introduce predictive uncertainty when dealing\nwith stripped or obfuscated code, leading to a performance drop. In this paper,\nwe introduce ProTST, a novel transformer-based methodology for binary code\nembedding. ProTST employs a hierarchical training process based on a unique\ntree-like structure, where knowledge progressively flows from fundamental tasks\nat the root to more specialized tasks at the leaves. This progressive\nteacher-student paradigm allows the model to build upon previously learned\nknowledge, resulting in high-quality embeddings that can be effectively\nleveraged for diverse downstream binary analysis tasks. The effectiveness of\nProTST is evaluated in seven binary analysis tasks, and the results show that\nProTST yields an average validation score (F1, MRR, and Recall@1) improvement\nof 14.8% compared to traditional two-stage training and an average validation\nscore of 10.7% compared to multimodal two-stage frameworks.",
    "pdf_url": "http://arxiv.org/pdf/2412.11177v2",
    "published": "2024-12-15T13:04:29+00:00",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11176v2",
    "title": "On sharpened singular Adams' type inequalities and applications to $(p,\\frac{n}{2})$-biharmonic equations",
    "authors": [
      "Deepak Kumar Mahanta",
      "Tuhina Mukherjee",
      "Abhishek Sarkar"
    ],
    "abstract": "The purpose of this article is to establish a sharp version of Adams' type\ninequality in a suitable higher order function space with singular weight in\n$\\mathbb{R}^n$. In addition, we also provide the proof of a sharp singular\nconcentration-compactness principle due to Lions' as an improvement of this\nsingular Adams' inequality. It is well known that such types of inequalities\ncan be classified in two different ways, for instance, critical sharp singular\nAdams' type inequality (involving Sobolev full norm as constraint) and\nsubcritical sharp singular Adams' type inequality (involving Sobolev partial\nnorm as constraint). Further, we shall establish that critical and subcritical\nsharp singular Adams' type inequalities are surprisingly equivalent. To be more\nprecisely, we also discuss about the asymptotic behavior of the lower and upper\nbounds of subcritical sharp singular Adams' type inequality and establish a\nrelation between the suprema of such types of critical and subcritical sharp\ninequalities. Despite this, we shall demonstrate a new compact embedding, which\nplays a crucial role in our arguments. Moreover, as an application of these\nresults, by employing the mountain pass theorem, we study the existence of\nnontrivial solutions to a class of nonhomogeneous quasilinear elliptic\nequations involving $(p,\\frac{n}{2})$-biharmonic operator with singular\nexponential growth as follows $$\n  \\Delta^2_p u+\\Delta^2_{\\frac{n}{2}}\nu=\\frac{g(x,u)}{|x|^\\gamma}\\quad\\text{in}\\quad \\mathbb{R}^n, $$ with $n\\geq 4$,\n$1<p<\\frac{n}{2}$, $\\gamma\\in(0,n)$ and the nonlinear term\n$g:\\mathbb{R}^n\\times \\mathbb{R}\\to \\mathbb{R}$ is a Carath\\'eodory function,\nwhich behaves like $\\exp{(\\alpha|s|^{\\frac{n}{n-2}})}$ as $|s|\\to~+\\infty$ for\nsome $\\alpha>0$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11176v2",
    "published": "2024-12-15T13:03:35+00:00",
    "categories": [
      "math.AP",
      "35A23, 35B33, 35J20, 35J30, 35J91"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11175v2",
    "title": "Knowledge Migration Framework for Smart Contract Vulnerability Detection",
    "authors": [
      "Luqi Wang",
      "Wenbao Jiang"
    ],
    "abstract": "As a cornerstone of blockchain technology in the 3.0 era, smart contracts\nplay a pivotal role in the evolution of blockchain systems. In order to address\nthe limitations of existing smart contract vulnerability detection models with\nregard to their generalisation capability, an AF-STip smart contract\nvulnerability detection framework incorporating efficient knowledge migration\nis proposed. AF-STip employs the teacher network as the main model and migrates\nthe knowledge processed by the smart contract to the student model using a\ndata-free knowledge distillation method. The student model utilises this\nknowledge to enhance its vulnerability detection capabilities. The approach\nmarkedly enhances the model's capacity for feature extraction and cross-class\nadaptation, while concurrently reducing computational overhead.In order to\nfurther enhance the extraction of vulnerability features, an adaptive fusion\nmodule is proposed in this paper, which aims to strengthen the interaction and\nfusion of feature information.The experimental results demonstrate that the\nSTip model attains an average F1 value detection score of 91.16% for the four\nvulnerabilities without disclosing the original smart contract data. To\nvalidate the viability of the proposed lightweight migration approach, the\nstudent model is deployed in a migration learning task targeting a novel\nvulnerability type, resulting in an accuracy of 91.02% and an F1 score of\n90.46%. To the best of our knowledge, AF-STip is the inaugural model to apply\ndata-free knowledge migration to smart contract vulnerability detection. While\nmarkedly reducing the computational overhead, the method still demonstrates\nexceptional performance in detecting novel vulnerabilities.",
    "pdf_url": "http://arxiv.org/pdf/2412.11175v2",
    "published": "2024-12-15T13:01:11+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11174v2",
    "title": "Semi-Supervised Risk Control via Prediction-Powered Inference",
    "authors": [
      "Bat-Sheva Einbinder",
      "Liran Ringel",
      "Yaniv Romano"
    ],
    "abstract": "The risk-controlling prediction sets (RCPS) framework is a general tool for\ntransforming the output of any machine learning model to design a predictive\nrule with rigorous error rate control. The key idea behind this framework is to\nuse labeled hold-out calibration data to tune a hyper-parameter that affects\nthe error rate of the resulting prediction rule. However, the limitation of\nsuch a calibration scheme is that with limited hold-out data, the tuned\nhyper-parameter becomes noisy and leads to a prediction rule with an error rate\nthat is often unnecessarily conservative. To overcome this sample-size barrier,\nwe introduce a semi-supervised calibration procedure that leverages unlabeled\ndata to rigorously tune the hyper-parameter without compromising statistical\nvalidity. Our procedure builds upon the prediction-powered inference framework,\ncarefully tailoring it to risk-controlling tasks. We demonstrate the benefits\nand validity of our proposal through two real-data experiments: few-shot image\nclassification and early time series classification.",
    "pdf_url": "http://arxiv.org/pdf/2412.11174v2",
    "published": "2024-12-15T13:00:23+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11173v1",
    "title": "Control of fusion by elementary abelian subgroups of rank at least 2",
    "authors": [
      "Lizhong Wang",
      "Xingzhong Xu",
      "Jiping Zhang"
    ],
    "abstract": "In this paper, we focus on the subgroups control $p$-fusion, and we improve\nthe Theorem B of [4] for odd prime. For odd prime, we prove that elementary\nabelian subgroups of rank at least 2 can control $p$-fusion(see our Theorem B).",
    "pdf_url": "http://arxiv.org/pdf/2412.11173v1",
    "published": "2024-12-15T12:55:36+00:00",
    "categories": [
      "math.GR"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11172v1",
    "title": "Unpacking the Resilience of SNLI Contradiction Examples to Attacks",
    "authors": [
      "Chetan Verma",
      "Archit Agarwal"
    ],
    "abstract": "Pre-trained models excel on NLI benchmarks like SNLI and MultiNLI, but their\ntrue language understanding remains uncertain. Models trained only on\nhypotheses and labels achieve high accuracy, indicating reliance on dataset\nbiases and spurious correlations. To explore this issue, we applied the\nUniversal Adversarial Attack to examine the model's vulnerabilities. Our\nanalysis revealed substantial drops in accuracy for the entailment and neutral\nclasses, whereas the contradiction class exhibited a smaller decline.\nFine-tuning the model on an augmented dataset with adversarial examples\nrestored its performance to near-baseline levels for both the standard and\nchallenge sets. Our findings highlight the value of adversarial triggers in\nidentifying spurious correlations and improving robustness while providing\ninsights into the resilience of the contradiction class to adversarial attacks.",
    "pdf_url": "http://arxiv.org/pdf/2412.11172v1",
    "published": "2024-12-15T12:47:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.15253v1",
    "title": "Using Machine Learning to Distinguish Human-written from Machine-generated Creative Fiction",
    "authors": [
      "Andrea Cristina McGlinchey",
      "Peter J Barclay"
    ],
    "abstract": "Following the universal availability of generative AI systems with the\nrelease of ChatGPT, automatic detection of deceptive text created by Large\nLanguage Models has focused on domains such as academic plagiarism and \"fake\nnews\". However, generative AI also poses a threat to the livelihood of creative\nwriters, and perhaps to literary culture in general, through reduction in\nquality of published material. Training a Large Language Model on writers'\noutput to generate \"sham books\" in a particular style seems to constitute a new\nform of plagiarism. This problem has been little researched. In this study, we\ntrained Machine Learning classifier models to distinguish short samples of\nhuman-written from machine-generated creative fiction, focusing on classic\ndetective novels. Our results show that a Naive Bayes and a Multi-Layer\nPerceptron classifier achieved a high degree of success (accuracy > 95%),\nsignificantly outperforming human judges (accuracy < 55%). This approach worked\nwell with short text samples (around 100 words), which previous research has\nshown to be difficult to classify. We have deployed an online proof-of-concept\nclassifier tool, AI Detective, as a first step towards developing lightweight\nand reliable applications for use by editors and publishers, with the aim of\nprotecting the economic and cultural contribution of human authors.",
    "pdf_url": "http://arxiv.org/pdf/2412.15253v1",
    "published": "2024-12-15T12:46:57+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2501.16332v1",
    "title": "Interference in Wireless Networks -- A Power Allocation Approach",
    "authors": [
      "Tzalik Maimon",
      "Shirley Alus",
      "Gil Kedar"
    ],
    "abstract": "Co-Channel Interference (CCI) is a fundamental problem in wireless\ncommunication networks. It is a well-studied problem in the field. As channels\nuse the same frequency, interference in the radio waves occurs which, in turn,\nreduces the capacity of the interfered channels. There is a need to use the\nleast number of frequencies as communication networks advance to 5G. In this\npaper, we present a novel technique to manage interference on channels. We use\ntime division for links of the same frequency and, as a result, we show a\nsignificant reduction in the number of frequencies used overall in the network.",
    "pdf_url": "http://arxiv.org/pdf/2501.16332v1",
    "published": "2024-12-15T12:45:44+00:00",
    "categories": [
      "eess.SP",
      "cs.NI"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11171v1",
    "title": "Learning Latent Spaces for Domain Generalization in Time Series Forecasting",
    "authors": [
      "Songgaojun Deng",
      "Maarten de Rijke"
    ],
    "abstract": "Time series forecasting is vital in many real-world applications, yet\ndeveloping models that generalize well on unseen relevant domains -- such as\nforecasting web traffic data on new platforms/websites or estimating e-commerce\ndemand in new regions -- remains underexplored. Existing forecasting models\noften struggle with domain shifts in time series data, as the temporal patterns\ninvolve complex components like trends, seasonality, etc. While some prior work\naddresses this by matching feature distributions across domains or\ndisentangling domain-shared features using label information, they fail to\nreveal insights into the latent temporal dependencies, which are critical for\nidentifying common patterns across domains and achieving generalization.\n  We propose a framework for domain generalization in time series forecasting\nby mining the latent factors that govern temporal dependencies across domains.\nOur approach uses a decomposition-based architecture with a new Conditional\n$\\beta$-Variational Autoencoder (VAE), wherein time series data is first\ndecomposed into trend-cyclical and seasonal components, each modeled\nindependently through separate $\\beta$-VAE modules. The $\\beta$-VAE aims to\ncapture disentangled latent factors that control temporal dependencies across\ndomains. We enhance the learning of domain-specific information with a\ndecoder-conditional design and introduce domain regularization to improve the\nseparation of domain-shared and domain-specific latent factors. Our proposed\nmethod is flexible and can be applied to various time series forecasting\nmodels, enabling effective domain generalization with simplicity and\nefficiency. We validate its effectiveness on five real-world time series\ndatasets, covering web traffic, e-commerce, finance and power consumption,\ndemonstrating improved generalization performance over state-of-the-art\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2412.11171v1",
    "published": "2024-12-15T12:41:53+00:00",
    "categories": [
      "cs.LG",
      "68T07 (Primary)"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11170v2",
    "title": "Benchmarking and Learning Multi-Dimensional Quality Evaluator for Text-to-3D Generation",
    "authors": [
      "Yujie Zhang",
      "Bingyang Cui",
      "Qi Yang",
      "Zhu Li",
      "Yiling Xu"
    ],
    "abstract": "Text-to-3D generation has achieved remarkable progress in recent years, yet\nevaluating these methods remains challenging for two reasons: i) Existing\nbenchmarks lack fine-grained evaluation on different prompt categories and\nevaluation dimensions. ii) Previous evaluation metrics only focus on a single\naspect (e.g., text-3D alignment) and fail to perform multi-dimensional quality\nassessment. To address these problems, we first propose a comprehensive\nbenchmark named MATE-3D. The benchmark contains eight well-designed prompt\ncategories that cover single and multiple object generation, resulting in 1,280\ngenerated textured meshes. We have conducted a large-scale subjective\nexperiment from four different evaluation dimensions and collected 107,520\nannotations, followed by detailed analyses of the results. Based on MATE-3D, we\npropose a novel quality evaluator named HyperScore. Utilizing hypernetwork to\ngenerate specified mapping functions for each evaluation dimension, our metric\ncan effectively perform multi-dimensional quality assessment. HyperScore\npresents superior performance over existing metrics on MATE-3D, making it a\npromising metric for assessing and improving text-to-3D generation. The project\nis available at https://mate-3d.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2412.11170v2",
    "published": "2024-12-15T12:41:44+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11169v1",
    "title": "Design Challenges for Robots in Industrial Applications",
    "authors": [
      "Nesreen Mufid"
    ],
    "abstract": "Nowadays, electric robots play big role in many fields as they can replace\nhumans and/or decrease the amount of load on humans. There are several types of\nrobots that are present in the daily life, some of them are fully controlled by\nhumans while others are programmed to be self-controlled. In addition there are\nself-control robots with partial human control. Robots can be classified into\nthree major kinds: industry robots, autonomous robots and mobile robots.\nIndustry robots are used in industries and factories to perform mankind tasks\nin the easier and faster way which will help in developing products. Typically\nindustrial robots perform difficult and dangerous tasks, as they lift heavy\nobjects, handle chemicals, paint and assembly work and so on. They are working\nall the time hour after hour, day by day with the same precision and they do\nnot get tired which means that they do not make errors due to fatigue. Indeed,\nthey are ideally suited to complete repetitive tasks.",
    "pdf_url": "http://arxiv.org/pdf/2412.11169v1",
    "published": "2024-12-15T12:40:36+00:00",
    "categories": [
      "cs.RO",
      "eess.SP"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11168v3",
    "title": "PGD-Imp: Rethinking and Unleashing Potential of Classic PGD with Dual Strategies for Imperceptible Adversarial Attacks",
    "authors": [
      "Jin Li",
      "Zitong Yu",
      "Ziqiang He",
      "Z. Jane Wang",
      "Xiangui Kang"
    ],
    "abstract": "Imperceptible adversarial attacks have recently attracted increasing research\ninterests. Existing methods typically incorporate external modules or loss\nterms other than a simple $l_p$-norm into the attack process to achieve\nimperceptibility, while we argue that such additional designs may not be\nnecessary. In this paper, we rethink the essence of imperceptible attacks and\npropose two simple yet effective strategies to unleash the potential of PGD,\nthe common and classical attack, for imperceptibility from an optimization\nperspective. Specifically, the Dynamic Step Size is introduced to find the\noptimal solution with minimal attack cost towards the decision boundary of the\nattacked model, and the Adaptive Early Stop strategy is adopted to reduce the\nredundant strength of adversarial perturbations to the minimum level. The\nproposed PGD-Imperceptible (PGD-Imp) attack achieves state-of-the-art results\nin imperceptible adversarial attacks for both untargeted and targeted\nscenarios. When performing untargeted attacks against ResNet-50, PGD-Imp\nattains 100$\\%$ (+0.3$\\%$) ASR, 0.89 (-1.76) $l_2$ distance, and 52.93 (+9.2)\nPSNR with 57s (-371s) running time, significantly outperforming existing\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2412.11168v3",
    "published": "2024-12-15T12:34:22+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11167v3",
    "title": "Cultural Palette: Pluralising Culture Alignment via Multi-agent Palette",
    "authors": [
      "Jiahao Yuan",
      "Zixiang Di",
      "Shangzixin Zhao",
      "Zhiqing Cui",
      "Hanqing Wang",
      "Guisong Yang",
      "Usman Naseem"
    ],
    "abstract": "Large language models (LLMs) face challenges in aligning with diverse\ncultural values despite their remarkable performance in generation, which stems\nfrom inherent monocultural biases and difficulties in capturing nuanced\ncultural semantics. Existing methods struggle to adapt to unknown culture after\nfine-tuning. Inspired by cultural geography across five continents, we propose\nCultural Palette, a multi-agent framework that redefines cultural alignment as\nan adaptive \"color-blending\" process for country-specific adaptation. Our\napproach harnesses cultural geography across five continents (Africa, America,\nAsia, Europe, Oceania) through three key steps: First, we synthesize the\nPentachromatic Cultural Palette Dataset using GPT-4o, refining\ncontinental-level dialogues with Hofstede's cultural dimensions to establish\nfoundational cultural representations. Second, five continent-level alignment\nagents form specialized cultural communities that generate region-specific\ndraft responses. Third, a Meta Agent employs Cultural MoErges to dynamically\nblend these cultural \"colors\" through attention-gated parameter merging, akin\nto mixing pigments on a palette, resolving conflicts while preserving cultural\nnuances to produce the final culturally-aligned response. Extensive experiments\nacross various countries demonstrate that Cultural Palette surpasses existing\nbaselines in cultural alignment.",
    "pdf_url": "http://arxiv.org/pdf/2412.11167v3",
    "published": "2024-12-15T12:30:52+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11166v2",
    "title": "Correspondence between quasinormal modes and grey-body factors of spherically symmetric traversable wormholes",
    "authors": [
      "S. V. Bolokhov",
      "Milena Skvortsova"
    ],
    "abstract": "A correspondence between two distinct spectral problems, quasinormal modes\nand grey-body factors, has recently been established for a wide class of black\nholes. Here, we demonstrate that a similar correspondence exists for a broad\nclass of traversable wormholes and verify it using several well-known examples.",
    "pdf_url": "http://arxiv.org/pdf/2412.11166v2",
    "published": "2024-12-15T12:29:32+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2412.11165v1",
    "title": "OTLRM: Orthogonal Learning-based Low-Rank Metric for Multi-Dimensional Inverse Problems",
    "authors": [
      "Xiangming Wang",
      "Haijin Zeng",
      "Jiaoyang Chen",
      "Sheng Liu",
      "Yongyong Chen",
      "Guoqing Chao"
    ],
    "abstract": "In real-world scenarios, complex data such as multispectral images and\nmulti-frame videos inherently exhibit robust low-rank property. This property\nis vital for multi-dimensional inverse problems, such as tensor completion,\nspectral imaging reconstruction, and multispectral image denoising. Existing\ntensor singular value decomposition (t-SVD) definitions rely on hand-designed\nor pre-given transforms, which lack flexibility for defining tensor nuclear\nnorm (TNN). The TNN-regularized optimization problem is solved by the singular\nvalue thresholding (SVT) operator, which leverages the t-SVD framework to\nobtain the low-rank tensor. However, it is quite complicated to introduce SVT\ninto deep neural networks due to the numerical instability problem in solving\nthe derivatives of the eigenvectors. In this paper, we introduce a novel\ndata-driven generative low-rank t-SVD model based on the learnable orthogonal\ntransform, which can be naturally solved under its representation. Prompted by\nthe linear algebra theorem of the Householder transformation, our learnable\northogonal transform is achieved by constructing an endogenously orthogonal\nmatrix adaptable to neural networks, optimizing it as arbitrary orthogonal\nmatrices. Additionally, we propose a low-rank solver as a generalization of\nSVT, which utilizes an efficient representation of generative networks to\nobtain low-rank structures. Extensive experiments highlight its significant\nrestoration enhancements.",
    "pdf_url": "http://arxiv.org/pdf/2412.11165v1",
    "published": "2024-12-15T12:28:57+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.19820v1",
    "title": "GaLore$+$: Boosting Low-Rank Adaptation for LLMs with Cross-Head Projection",
    "authors": [
      "Xutao Liao",
      "Shaohui Li",
      "Yuhui Xu",
      "Zhi Li",
      "Yu Liu",
      "You He"
    ],
    "abstract": "Recent low-rank training methods, such as GaLore, have significantly reduced\nthe memory required to optimize large language models (LLMs). However, these\nmethods often suffer from time-consuming low-rank projection estimations. In\nparticular, the singular value decomposition (SVD) in GaLore can consume more\nthan 80\\% of the total training time. To address this issue, we propose\nGaLore$+$, which uses cross-head low-rank projection to reduce the substantial\ntime consumption in estimating low-rank projections for multi-head attention.\nIn addition, we employ randomized subspace iteration to achieve fast SVD. To\nfurther enhance performance, we propose sparsely coded residuals to reduce the\nerrors caused by low-rank approximation on the first- and second-order moments\nof the optimizers and weight updates. We evaluate GaLore$+$ on arithmetic\nreasoning and natural language generation datasets. Our experiments demonstrate\nthat GaLore$+$ delivers superior performance while achieving approximately\n$4\\times$ fine-tuning speed compared to vanilla GaLore.",
    "pdf_url": "http://arxiv.org/pdf/2412.19820v1",
    "published": "2024-12-15T12:28:13+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11164v1",
    "title": "Missing data imputation for noisy time-series data and applications in healthcare",
    "authors": [
      "Lien P. Le",
      "Xuan-Hien Nguyen Thi",
      "Thu Nguyen",
      "Michael A. Riegler",
      "Pål Halvorsen",
      "Binh T. Nguyen"
    ],
    "abstract": "Healthcare time series data is vital for monitoring patient activity but\noften contains noise and missing values due to various reasons such as sensor\nerrors or data interruptions. Imputation, i.e., filling in the missing values,\nis a common way to deal with this issue. In this study, we compare imputation\nmethods, including Multiple Imputation with Random Forest (MICE-RF) and\nadvanced deep learning approaches (SAITS, BRITS, Transformer) for noisy,\nmissing time series data in terms of MAE, F1-score, AUC, and MCC, across\nmissing data rates (10 % - 80 %). Our results show that MICE-RF can effectively\nimpute missing data compared to deep learning methods and the improvement in\nclassification of data imputed indicates that imputation can have denoising\neffects. Therefore, using an imputation algorithm on time series with missing\ndata can, at the same time, offer denoising effects.",
    "pdf_url": "http://arxiv.org/pdf/2412.11164v1",
    "published": "2024-12-15T12:23:20+00:00",
    "categories": [
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11163v2",
    "title": "The Fine interior of dilations of a rational polytope",
    "authors": [
      "Martin Bohnert"
    ],
    "abstract": "A nondegenerate toric hypersurface of negative Kodaira dimension can be\ncharacterized by the empty Fine interior of its Newton polytope according to\nrecent work by Victor Batyrev, where the Fine interior is the rational\nsubpolytope consisting of all points which have an integral distance of at\nleast 1 to all integral supporting hyperplanes of the Newton polytope.\nMoreover, we get more information in this situation if we can describe how the\nFine interior behaves for dilations of the Newton polytope, e.g. if we can\ndetermine the smallest dilation with a non-empty Fine interior. Therefore, in\nthis article we give a purely combinatorial description of the Fine interiors\nof all dilations of a rational polytope, which allows us in particular to\ncompute this smallest dilation and to classify all lattice 3-polytopes with\nempty Fine interior, for which we have only one point as Fine interior of the\nsmallest dilation with non-empty Fine interior.",
    "pdf_url": "http://arxiv.org/pdf/2412.11163v2",
    "published": "2024-12-15T12:13:59+00:00",
    "categories": [
      "math.CO",
      "math.AG",
      "52B20 (Primary), 14M25, 14J70 (Secondary)"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11162v1",
    "title": "An FFT-accelerated PML-BIE Solver for Three-Dimensional Acoustic Wave Scattering in Layered Media",
    "authors": [
      "Hangya Wang",
      "Wangtao Lu"
    ],
    "abstract": "This paper is concerned with three-dimensional acoustic wave scattering in\ntwo-layer media, where the two homogeneous layers are separated by a locally\nperturbed plane featuring an axially symmetric perturbation. A fast novel\nboundary integral equation (BIE) method is proposed to solve the scattering\nproblem within a cylindrical perfectly matched layer (PML) truncation. We use\nPML-transformed Green's functions to derive BIEs in terms of single- and\ndouble-layer potentials for the wave field and its normal derivative on the\nboundary of each truncated homogeneous region. These BIEs, combined with\ninterface and PML boundary conditions, form a complete system that accurately\napproximates the scattering problem. An FFT-based approach is introduced to\nefficiently and accurately discretize the surface integral operators in the\nBIEs, where a new kernel splitting technique is developed to resolve\ninstabilities arising from the complex arguments in Green's functions.\nNumerical experiments demonstrate the efficiency and accuracy of the proposed\nmethod, as well as the exponential decay of truncation errors introduced by the\nPML.",
    "pdf_url": "http://arxiv.org/pdf/2412.11162v1",
    "published": "2024-12-15T12:09:47+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2501.00017v2",
    "title": "AI Across Borders: Exploring Perceptions and Interactions in Higher Education",
    "authors": [
      "Juliana Gerard",
      "Sahajpreet Singh",
      "Morgan Macleod",
      "Michael McKay",
      "Antoine Rivoire",
      "Tanmoy Chakraborty",
      "Muskaan Singh"
    ],
    "abstract": "This study investigates students' perceptions of Generative Artificial\nIntelligence (GenAI), with a focus on Higher Education institutions in Northern\nIreland and India. We collect quantitative Likert ratings and qualitative\ncomments from 1211 students on their awareness and perceptions of AI and\ninvestigate variations in attitudes toward AI across institutions and subject\nareas, as well as interactions between these variables with demographic\nvariables (focusing on gender). We found the following: (a) while perceptions\nvaried across institutions, responses for Computer Sciences students were\nsimilar, both in terms of topics and degree of positivity; and (b) after\ncontrolling for institution and subject area, we observed no effect of gender.\nThese results are consistent with previous studies, which find that students'\nperceptions are predicted by prior experience; crucially, however, the results\nof this study contribute to the literature by identifying important\ninteractions between key factors that can influence experience, revealing a\nmore nuanced picture of students' perceptions and the role of experience. We\nconsider the implications of these relations, and further considerations for\nthe role of experience.",
    "pdf_url": "http://arxiv.org/pdf/2501.00017v2",
    "published": "2024-12-15T12:02:14+00:00",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2412.12204v1",
    "title": "SEE: Sememe Entanglement Encoding for Transformer-bases Models Compression",
    "authors": [
      "Jing Zhang",
      "Shuzhen Sun",
      "Peng Zhang",
      "Guangxing Cao",
      "Hui Gao",
      "Xindian Ma",
      "Nan Xu",
      "Yuexian Hou"
    ],
    "abstract": "Transformer-based large language models exhibit groundbreaking capabilities,\nbut their storage and computational costs are prohibitively high, limiting\ntheir application in resource-constrained scenarios. An effective approach is\nto eliminate redundant model parameters and computational costs while\nincorporating efficient expert-derived knowledge structures to achieve a\nbalance between compression and performance. Therefore, we propose the\n\\textit{Sememe Entanglement Encoding (SEE)} algorithm. Guided by expert prior\nknowledge, the model is compressed through the low-rank approximation idea. In\nEntanglement Embedding, basic semantic units such as sememes are represented as\nlow-dimensional vectors, and then reconstructed into high-dimensional word\nembeddings through the combination of generalized quantum entanglement. We\nadapt the Sememe Entanglement Encoding algorithm to transformer-based models of\ndifferent magnitudes. Experimental results indicate that our approach achieves\nstable performance while compressing model parameters and computational costs.",
    "pdf_url": "http://arxiv.org/pdf/2412.12204v1",
    "published": "2024-12-15T12:01:43+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11161v1",
    "title": "Why and How: Knowledge-Guided Learning for Cross-Spectral Image Patch Matching",
    "authors": [
      "Chuang Yu",
      "Yunpeng Liu",
      "Jinmiao Zhao",
      "Xiangyu Yue"
    ],
    "abstract": "Recently, cross-spectral image patch matching based on feature relation\nlearning has attracted extensive attention. However, performance bottleneck\nproblems have gradually emerged in existing methods. To address this challenge,\nwe make the first attempt to explore a stable and efficient bridge between\ndescriptor learning and metric learning, and construct a knowledge-guided\nlearning network (KGL-Net), which achieves amazing performance improvements\nwhile abandoning complex network structures. Specifically, we find that there\nis feature extraction consistency between metric learning based on feature\ndifference learning and descriptor learning based on Euclidean distance. This\nprovides the foundation for bridge building. To ensure the stability and\nefficiency of the constructed bridge, on the one hand, we conduct an in-depth\nexploration of 20 combined network architectures. On the other hand, a\nfeature-guided loss is constructed to achieve mutual guidance of features. In\naddition, unlike existing methods, we consider that the feature mapping ability\nof the metric branch should receive more attention. Therefore, a hard negative\nsample mining for metric learning (HNSM-M) strategy is constructed. To the best\nof our knowledge, this is the first time that hard negative sample mining for\nmetric networks has been implemented and brings significant performance gains.\nExtensive experimental results show that our KGL-Net achieves SOTA performance\nin three different cross-spectral image patch matching scenarios. Our code are\navailable at https://github.com/YuChuang1205/KGL-Net.",
    "pdf_url": "http://arxiv.org/pdf/2412.11161v1",
    "published": "2024-12-15T11:59:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11160v1",
    "title": "Means of Hitting Times for Random Walks on Graphs: Connections, Computation, and Optimization",
    "authors": [
      "Haisong Xia",
      "Wanyue Xu",
      "Zuobai Zhang",
      "Zhongzhi Zhang"
    ],
    "abstract": "For random walks on graph $\\mathcal{G}$ with $n$ vertices and $m$ edges, the\nmean hitting time $H_j$ from a vertex chosen from the stationary distribution\nto vertex $j$ measures the importance for $j$, while the Kemeny constant\n$\\mathcal{K}$ is the mean hitting time from one vertex to another selected\nrandomly according to the stationary distribution. In this paper, we first\nestablish a connection between the two quantities, representing $\\mathcal{K}$\nin terms of $H_j$ for all vertices. We then develop an efficient algorithm\nestimating $H_j$ for all vertices and \\(\\mathcal{K}\\) in nearly linear time of\n$m$. Moreover, we extend the centrality $H_j$ of a single vertex to $H(S)$ of a\nvertex set $S$, and establish a link between $H(S)$ and some other quantities.\nWe further study the NP-hard problem of selecting a group $S$ of $k\\ll n$\nvertices with minimum $H(S)$, whose objective function is monotonic and\nsupermodular. We finally propose two greedy algorithms approximately solving\nthe problem. The former has an approximation factor\n$(1-\\frac{k}{k-1}\\frac{1}{e})$ and $O(kn^3)$ running time, while the latter\nreturns a $(1-\\frac{k}{k-1}\\frac{1}{e}-\\epsilon)$-approximation solution in\nnearly-linear time of $m$, for any parameter $0<\\epsilon <1$. Extensive\nexperiment results validate the performance of our algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2412.11160v1",
    "published": "2024-12-15T11:51:09+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2412.11159v2",
    "title": "A Report on Financial Regulations Challenge at COLING 2025",
    "authors": [
      "Keyi Wang",
      "Jaisal Patel",
      "Charlie Shen",
      "Daniel Kim",
      "Andy Zhu",
      "Alex Lin",
      "Luca Borella",
      "Cailean Osborne",
      "Matt White",
      "Steve Yang",
      "Kairong Xiao",
      "Xiao-Yang Liu Yanglet"
    ],
    "abstract": "Financial large language models (FinLLMs) have been applied to various tasks\nin business, finance, accounting, and auditing. Complex financial regulations\nand standards are critical to financial services, which LLMs must comply with.\nHowever, FinLLMs' performance in understanding and interpreting financial\nregulations has rarely been studied. Therefore, we organize the Regulations\nChallenge, a shared task at COLING 2025. It encourages the academic community\nto explore the strengths and limitations of popular LLMs. We create 9 novel\ntasks and corresponding question sets. In this paper, we provide an overview of\nthese tasks and summarize participants' approaches and results. We aim to raise\nawareness of FinLLMs' professional capability in financial regulations.",
    "pdf_url": "http://arxiv.org/pdf/2412.11159v2",
    "published": "2024-12-15T11:47:39+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11158v1",
    "title": "Early Concept Drift Detection via Prediction Uncertainty",
    "authors": [
      "Pengqian Lu",
      "Jie Lu",
      "Anjin Liu",
      "Guangquan Zhang"
    ],
    "abstract": "Concept drift, characterized by unpredictable changes in data distribution\nover time, poses significant challenges to machine learning models in streaming\ndata scenarios. Although error rate-based concept drift detectors are widely\nused, they often fail to identify drift in the early stages when the data\ndistribution changes but error rates remain constant. This paper introduces the\nPrediction Uncertainty Index (PU-index), derived from the prediction\nuncertainty of the classifier, as a superior alternative to the error rate for\ndrift detection. Our theoretical analysis demonstrates that: (1) The PU-index\ncan detect drift even when error rates remain stable. (2) Any change in the\nerror rate will lead to a corresponding change in the PU-index. These\nproperties make the PU-index a more sensitive and robust indicator for drift\ndetection compared to existing methods. We also propose a PU-index-based Drift\nDetector (PUDD) that employs a novel Adaptive PU-index Bucketing algorithm for\ndetecting drift. Empirical evaluations on both synthetic and real-world\ndatasets demonstrate PUDD's efficacy in detecting drift in structured and image\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2412.11158v1",
    "published": "2024-12-15T11:43:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11157v2",
    "title": "Polynomial potentials and nilpotent groups",
    "authors": [
      "W. Schweiger",
      "W. H. Klink"
    ],
    "abstract": "This paper deals with the partial solution of the energy-eigenvalue problem\nfor one-dimensional Schr\\\"odinger operators of the form $H_N=X_0^2+V_N$, where\n$V_N=X_N^2+\\alpha X_{N-1}$ is a polynomial potential of degree $(2N-2)$ and\n$X_i$ are the generators of an irreducible representation of a particular\nnilpotent group $\\mathcal{G}_N$. Algebraization of the eigenvalue problem is\nachieved for eigenfunctions of the form $\\sum_{k=0}^M a_k X_2^k \\exp(-\\int dx\\,\nX_N)$. It is shown that the overdetermined linear system of equations for the\ncoefficients $a_k$ has a nontrivial solution, if the parameter $\\alpha$ and\n$(N-3)$ Casimir invariants satisfy certain constraints. This general setting\nworks for even $N\\geq 2$ and can also be applied to odd $N\\geq 3$, if the\npotential is symmetrized by considering it as function of $|x|$ rather than\n$x$. It provides a unified approach to quasi-exactly solvable polynomial\ninteractions, including the harmonic oscillator, and extends corresponding\nresults known from the literature. Explicit expressions for energy eigenvalues\nand eigenfunctions are given for the quasi-exactly solvable sextic, octic and\ndecatic potentials. The case of $E=0$ solutions for general $N$ and $M$ is also\ndiscussed. As physical application, the movement of a charged particle in an\nelectromagnetic field of pertinent polynomial form is shortly sketched.",
    "pdf_url": "http://arxiv.org/pdf/2412.11157v2",
    "published": "2024-12-15T11:30:05+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11156v1",
    "title": "Galois orbits of torsion points over polytopes near atoral sets",
    "authors": [
      "Chenying Lin"
    ],
    "abstract": "Given an essentially atoral Laurent polynomial $P$, we show an\nequidistribution theorem for the function $\\operatorname{log}|P|$ on specific\nsubsets of Galois orbits of torsion points of the $d$-dimensional algebraic\ntorus $\\mathbb{G}^d_m(\\overline{\\mathbb{Q}})$. The specific subsets under\nconsideration are the preimages of $d$-dimensional polytopes within the\nhypercube $[0,1]^d$ under the cotropicalization map. This generalises an\nequidistribution theorem of V. Dimitrov and P. Habegger, who considered only\nall Galois orbits that correspond to the entire hypercube $[0,1]^d$. In\naddition, we provide an estimate for the convergence speed of this\nequidistribution, expressed as a negative power of the strictness degree. Our\napproach is to derive an alternative version of Koksma's inequality over\npolytopes.\n  As an application, we provide the convergence speed of heights on a sequence\nof projective points for a specific two-dimensional example, answering a\nquestion posed by R. Gualdi and M. Sombra. In the appendix, we present an\nalgorithm to compute the explicit value of the power of the strictness degree.",
    "pdf_url": "http://arxiv.org/pdf/2412.11156v1",
    "published": "2024-12-15T11:27:30+00:00",
    "categories": [
      "math.NT",
      "math.CO",
      "Primary 11J83, 11G50, Secondary 14G40, 37P30, 52B11"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2501.16331v1",
    "title": "Decoding OTC Government Bond Market Liquidity: An ABM Model for Market Dynamics",
    "authors": [
      "Alicia Vidler",
      "Toby Walsh"
    ],
    "abstract": "The over-the-counter (OTC) government bond markets are characterised by their\nbilateral trading structures, which pose unique challenges to understanding and\nensuring market stability and liquidity. In this paper, we develop a bespoke\nABM that simulates market-maker interactions within a stylised government bond\nmarket. The model focuses on the dynamics of liquidity and stability in the\nsecondary trading of government bonds, particularly in concentrated markets\nlike those found in Australia and the UK. Through this simulation, we test key\nhypotheses around improving market stability, focusing on the effects of agent\ndiversity, business costs, and client base size. We demonstrate that greater\nagent diversity enhances market liquidity and that reducing the costs of\nmarket-making can improve overall market stability. The model offers insights\ninto computational finance by simulating trading without price transparency,\nhighlighting how micro-structural elements can affect macro-level market\noutcomes. This research contributes to the evolving field of computational\nfinance by employing computational intelligence techniques to better understand\nthe fundamental mechanics of government bond markets, providing actionable\ninsights for both academics and practitioners.",
    "pdf_url": "http://arxiv.org/pdf/2501.16331v1",
    "published": "2024-12-15T11:22:25+00:00",
    "categories": [
      "q-fin.TR",
      "cs.AI"
    ],
    "primary_category": "q-fin.TR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11155v1",
    "title": "Partial Identifiability in Inverse Reinforcement Learning For Agents With Non-Exponential Discounting",
    "authors": [
      "Joar Skalse",
      "Alessandro Abate"
    ],
    "abstract": "The aim of inverse reinforcement learning (IRL) is to infer an agent's\npreferences from observing their behaviour. Usually, preferences are modelled\nas a reward function, $R$, and behaviour is modelled as a policy, $\\pi$. One of\nthe central difficulties in IRL is that multiple preferences may lead to the\nsame observed behaviour. That is, $R$ is typically underdetermined by $\\pi$,\nwhich means that $R$ is only partially identifiable. Recent work has\ncharacterised the extent of this partial identifiability for different types of\nagents, including optimal and Boltzmann-rational agents. However, work so far\nhas only considered agents that discount future reward exponentially: this is a\nserious limitation, especially given that extensive work in the behavioural\nsciences suggests that humans are better modelled as discounting\nhyperbolically. In this work, we newly characterise partial identifiability in\nIRL for agents with non-exponential discounting: our results are in particular\nrelevant for hyperbolical discounting, but they also more generally apply to\nagents that use other types of (non-exponential) discounting. We significantly\nshow that generally IRL is unable to infer enough information about $R$ to\nidentify the correct optimal policy, which entails that IRL alone can be\ninsufficient to adequately characterise the preferences of such agents.",
    "pdf_url": "http://arxiv.org/pdf/2412.11155v1",
    "published": "2024-12-15T11:08:58+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11154v2",
    "title": "From Easy to Hard: Progressive Active Learning Framework for Infrared Small Target Detection with Single Point Supervision",
    "authors": [
      "Chuang Yu",
      "Jinmiao Zhao",
      "Yunpeng Liu",
      "Sicheng Zhao",
      "Yimian Dai",
      "Xiangyu Yue"
    ],
    "abstract": "Recently, single-frame infrared small target (SIRST) detection with single\npoint supervision has drawn wide-spread attention. However, the latest label\nevolution with single point supervision (LESPS) framework suffers from\ninstability, excessive label evolution, and difficulty in exerting embedded\nnetwork performance. Inspired by organisms gradually adapting to their\nenvironment and continuously accumulating knowledge, we construct an innovative\nProgressive Active Learning (PAL) framework for single point supervision, which\ndrives the existing SIRST detection networks progressively and actively\nrecognizes and learns more hard samples to achieve significant performance\nimprovements. Specifically, to avoid the early low-performance model leading to\nthe wrong selection of hard samples, we propose a model pre-start concept,\nwhich focuses on automatically selecting a portion of easy samples and helping\nthe model have basic task-specific learning capabilities. Meanwhile, we propose\na refined dual-update strategy, which can promote reasonable learning of harder\nsamples and continuous refinement of pseudo-labels. In addition, to alleviate\nthe risk of excessive label evolution, a decay factor is reasonably introduced,\nwhich helps to achieve a dynamic balance between the expansion and contraction\nof target annotations. Extensive experiments show that existing SIRST detection\nnetworks equipped with our PAL framework have achieved state-of-the-art (SOTA)\nresults on multiple public datasets. Furthermore, our PAL framework can build\nan efficient and stable bridge between full supervision and single point\nsupervision tasks. Our code are available at\nhttps://github.com/YuChuang1205/PAL.",
    "pdf_url": "http://arxiv.org/pdf/2412.11154v2",
    "published": "2024-12-15T11:08:49+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11153v1",
    "title": "Balancing Accuracy and Costs in Cross-Temporal Hierarchies: Investigating Decision-Based and Validation-Based Reconciliation",
    "authors": [
      "Mahdi Abolghasemi",
      "Daniele Girolimetto",
      "Tommaso Di Fonzo"
    ],
    "abstract": "Wind power forecasting is essential for managing daily operations at wind\nfarms and enabling market operators to manage power uncertainty effectively in\ndemand planning. This paper explores advanced cross-temporal forecasting models\nand their potential to enhance forecasting accuracy. First, we propose a novel\napproach that leverages validation errors, rather than traditional in-sample\nerrors, for covariance matrix estimation and forecast reconciliation. Second,\nwe introduce decision-based aggregation levels for forecasting and\nreconciliation where certain horizons are based on the required decisions in\npractice. Third, we evaluate the forecasting performance of the models not only\non their ability to minimize errors but also on their effectiveness in reducing\ndecision costs, such as penalties in ancillary services. Our results show that\nstatistical-based hierarchies tend to adopt less conservative forecasts and\nreduce revenue losses. On the other hand, decision-based reconciliation offers\na more balanced compromise between accuracy and decision cost, making them\nattractive for practical use.",
    "pdf_url": "http://arxiv.org/pdf/2412.11153v1",
    "published": "2024-12-15T11:04:38+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2412.11152v1",
    "title": "Dual-Schedule Inversion: Training- and Tuning-Free Inversion for Real Image Editing",
    "authors": [
      "Jiancheng Huang",
      "Yi Huang",
      "Jianzhuang Liu",
      "Donghao Zhou",
      "Yifan Liu",
      "Shifeng Chen"
    ],
    "abstract": "Text-conditional image editing is a practical AIGC task that has recently\nemerged with great commercial and academic value. For real image editing, most\ndiffusion model-based methods use DDIM Inversion as the first stage before\nediting. However, DDIM Inversion often results in reconstruction failure,\nleading to unsatisfactory performance for downstream editing. To address this\nproblem, we first analyze why the reconstruction via DDIM Inversion fails. We\nthen propose a new inversion and sampling method named Dual-Schedule Inversion.\nWe also design a classifier to adaptively combine Dual-Schedule Inversion with\ndifferent editing methods for user-friendly image editing. Our work can achieve\nsuperior reconstruction and editing performance with the following advantages:\n1) It can reconstruct real images perfectly without fine-tuning, and its\nreversibility is guaranteed mathematically. 2) The edited object/scene conforms\nto the semantics of the text prompt. 3) The unedited parts of the object/scene\nretain the original identity.",
    "pdf_url": "http://arxiv.org/pdf/2412.11152v1",
    "published": "2024-12-15T11:04:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11151v2",
    "title": "An explicit spectral decomposition of the ADRT",
    "authors": [
      "Weilin Li",
      "Karl Otness",
      "Kui Ren",
      "Donsub Rim"
    ],
    "abstract": "The approximate discrete Radon transform (ADRT) is a hierarchical multiscale\napproximation of the Radon transform. In this paper, we factor the ADRT into a\nproduct of linear transforms that resemble convolutions, and derive an explicit\nspectral decomposition of each factor. We further show that this implies - for\ndata lying in the range of the ADRT - that the transform of an $N \\times N$\nimage can be formally inverted with complexity $\\mathcal{O}(N^2 \\log^2 N)$. We\nnumerically test the accuracy of the inverse on images of moderate sizes and\nfind that it is competitive with existing iterative algorithms in this special\nregime.",
    "pdf_url": "http://arxiv.org/pdf/2412.11151v2",
    "published": "2024-12-15T11:01:11+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.SP",
      "44A12, 65R10, 92C55, 68U05, 15A04"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11150v1",
    "title": "UAV-Enabled Passive 6D Movable Antennas: Joint Deployment and Beamforming Optimization",
    "authors": [
      "Changhao Liu",
      "Weidong Mei",
      "Peilan Wang",
      "Yinuo Meng",
      "Boyu Ning",
      "Zhi Chen"
    ],
    "abstract": "Intelligent reflecting surface (IRS) is composed of numerous passive\nreflecting elements and can be mounted on unmanned aerial vehicles (UAVs) to\nachieve six-dimensional (6D) movement by adjusting the UAV's three-dimensional\n(3D) location and 3D orientation simultaneously. Hence, in this paper, we\ninvestigate a new UAV-enabled passive 6D movable antenna (6DMA) architecture by\nmounting an IRS on a UAV and address the associated joint deployment and\nbeamforming optimization problem. In particular, we consider a passive\n6DMA-aided multicast system with a multi-antenna base station (BS) and multiple\nremote users, aiming to jointly optimize the IRS's location and 3D orientation,\nas well as its passive beamforming to maximize the minimum received\nsignal-to-noise ratio (SNR) among all users under the practical angle-dependent\nsignal reflection model. However, this optimization problem is challenging to\nbe optimally solved due to the intricate relationship between the users' SNRs\nand the IRS's location and orientation. To tackle this challenge, we first\nfocus on a simplified case with a single user, showing that one-dimensional\n(1D) orientation suffices to achieve the optimal performance. Next, we show\nthat for any given IRS's location, the optimal 1D orientation can be derived in\nclosed form, based on which several useful insights are drawn. To solve the\nmax-min SNR problem in the general multi-user case, we propose an alternating\noptimization (AO) algorithm by alternately optimizing the IRS's beamforming and\nlocation/orientation via successive convex approximation (SCA) and hybrid\ncoarse- and fine-grained search, respectively. To avoid undesirable local\nsub-optimal solutions, a Gibbs sampling (GS) method is proposed to generate new\nIRS locations and orientations for exploration in each AO iteration. Numerical\nresults validate our theoretical analyses.",
    "pdf_url": "http://arxiv.org/pdf/2412.11150v1",
    "published": "2024-12-15T10:53:20+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11149v1",
    "title": "A Comprehensive Survey of Action Quality Assessment: Method and Benchmark",
    "authors": [
      "Kanglei Zhou",
      "Ruizhi Cai",
      "Liyuan Wang",
      "Hubert P. H. Shum",
      "Xiaohui Liang"
    ],
    "abstract": "Action Quality Assessment (AQA) quantitatively evaluates the quality of human\nactions, providing automated assessments that reduce biases in human judgment.\nIts applications span domains such as sports analysis, skill assessment, and\nmedical care. Recent advances in AQA have introduced innovative methodologies,\nbut similar methods often intertwine across different domains, highlighting the\nfragmented nature that hinders systematic reviews. In addition, the lack of a\nunified benchmark and limited computational comparisons hinder consistent\nevaluation and fair assessment of AQA approaches. In this work, we address\nthese gaps by systematically analyzing over 150 AQA-related papers to develop a\nhierarchical taxonomy, construct a unified benchmark, and provide an in-depth\nanalysis of current trends, challenges, and future directions. Our hierarchical\ntaxonomy categorizes AQA methods based on input modalities (video, skeleton,\nmulti-modal) and their specific characteristics, highlighting the evolution and\ninterrelations across various approaches. To promote standardization, we\npresent a unified benchmark, integrating diverse datasets to evaluate the\nassessment precision and computational efficiency. Finally, we review emerging\ntask-specific applications and identify under-explored challenges in AQA,\nproviding actionable insights into future research directions. This survey aims\nto deepen understanding of AQA progress, facilitate method comparison, and\nguide future innovations. The project web page can be found at\nhttps://ZhouKanglei.github.io/AQA-Survey.",
    "pdf_url": "http://arxiv.org/pdf/2412.11149v1",
    "published": "2024-12-15T10:47:26+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11148v1",
    "title": "Redefining Normal: A Novel Object-Level Approach for Multi-Object Novelty Detection",
    "authors": [
      "Mohammadreza Salehi",
      "Nikolaos Apostolikas",
      "Efstratios Gavves",
      "Cees G. M. Snoek",
      "Yuki M. Asano"
    ],
    "abstract": "In the realm of novelty detection, accurately identifying outliers in data\nwithout specific class information poses a significant challenge. While current\nmethods excel in single-object scenarios, they struggle with multi-object\nsituations due to their focus on individual objects. Our paper suggests a novel\napproach: redefining `normal' at the object level in training datasets. Rather\nthan the usual image-level view, we consider the most dominant object in a\ndataset as the norm, offering a perspective that is more effective for\nreal-world scenarios. Adapting to our object-level definition of `normal', we\nmodify knowledge distillation frameworks, where a student network learns from a\npre-trained teacher network. Our first contribution, DeFeND(Dense Feature\nFine-tuning on Normal Data), integrates dense feature fine-tuning into the\ndistillation process, allowing the teacher network to focus on object-level\nfeatures with a self-supervised loss. The second is masked knowledge\ndistillation, where the student network works with partially hidden inputs,\nhoning its ability to deduce and generalize from incomplete data. This approach\nnot only fares well in single-object novelty detection but also considerably\nsurpasses existing methods in multi-object contexts. The implementation is\navailable at: https://github.com/SMSD75/Redefining_Normal_ACCV24/tree/main",
    "pdf_url": "http://arxiv.org/pdf/2412.11148v1",
    "published": "2024-12-15T10:47:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2501.04010v2",
    "title": "Pairs of Subspaces, Split Quaternions and the Modular Operator",
    "authors": [
      "Jan Naudts",
      "Jun Zhang"
    ],
    "abstract": "We revisit the work of Rieffel and van Daele on pairs of subspaces of a real\nHilbert space, while relaxing as much as possible the assumption that all the\nrelevant subspaces are in general positions with respect to each other. We work\nout, in detail, how two real projection operators lead to the construction of a\ncomplex Hilbert space where the theory of the modular operator is applicable,\nwith emphasis on the relevance of a central extension of the group of split\nquaternions. Two examples are given for which the subspaces have unequal\ndimension and therefore are not in generic position.",
    "pdf_url": "http://arxiv.org/pdf/2501.04010v2",
    "published": "2024-12-15T10:44:47+00:00",
    "categories": [
      "math-ph",
      "math.FA",
      "math.MP",
      "46C05"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11147v1",
    "title": "Functional equations of algebraic Rankin-Selberg $p$-adic $L$-functions",
    "authors": [
      "Kâzım Büyükboduk",
      "Manisha Ganguly"
    ],
    "abstract": "This article presents an approach to the algebraic functional equation for\nSelmer complexes, which in turn have applications in the Iwasawa theoretic\nstudy of Rankin-Selberg products of the Hida and Coleman families. Our\ntreatment establishes the functional equation for algebraic $p$-adic\n$L$-functions (which are given in terms of characteristic ideals of Selmer\ngroups, which arise as the cohomology of appropriately defined Selmer complexes\nin degree $2$). This is achieved by recovering the characteristic ideal as the\ndeterminant of the said Selmer complex, once we prove (under suitable but\nrather mild) hypotheses that the Selmer complex in question is perfect with\namplitude $[1,2]$, and its cohomology is concentrated in degree-2. The\nperfectness of these Selmer complexes turns out to be a delicate problem, and\nthe required properties require a study of Tamagawa factors in families, which\nmay be of independent interest.",
    "pdf_url": "http://arxiv.org/pdf/2412.11147v1",
    "published": "2024-12-15T10:41:43+00:00",
    "categories": [
      "math.NT",
      "11R23"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2412.14200v1",
    "title": "ActiveAI: Enabling K-12 AI Literacy Education & Analytics at Scale",
    "authors": [
      "Ruiwei Xiao",
      "Ying-Jui Tseng",
      "Hanqi Li",
      "Hsuan Nieu",
      "Guanze Liao",
      "John Stamper",
      "Kenneth Koedinger"
    ],
    "abstract": "Interest in K-12 AI Literacy education has surged in the past year, yet\nlarge-scale learning data remains scarce despite considerable efforts in\ndeveloping learning materials and running summer programs. To make larger scale\ndataset available and enable more replicable findings, we developed an\nintelligent online learning platform featuring AI Literacy modules and\nassessments, engaging 1,000 users from 12 secondary schools. Preliminary\nanalysis of the data reveals patterns in prior knowledge levels of AI Literacy,\ngender differences in assessment scores, and the effectiveness of instructional\nactivities. With open access to this de-identified dataset, researchers can\nperform secondary analyses, advancing the understanding in this emerging field\nof AI Literacy education.",
    "pdf_url": "http://arxiv.org/pdf/2412.14200v1",
    "published": "2024-12-15T10:35:14+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11146v1",
    "title": "Enhancing Multiagent Genetic Network Programming Performance Using Search Space Reduction",
    "authors": [
      "Ali Kohan",
      "Mohamad Roshanzamir",
      "Roohallah Alizadehsani"
    ],
    "abstract": "Genetic Network Programming (GNP) is an evolutionary algorithm that extends\nGenetic Programming (GP). It is typically used in agent control problems. In\ncontrast to GP, which employs a tree structure, GNP utilizes a directed graph\nstructure. During the evolutionary process, the connections between nodes\nchange to discover the optimal strategy. Due to the large number of node\nconnections, GNP has a large search space, making it challenging to identify an\nappropriate graph structure. One way to reduce this search space is by\nutilizing simplified operators that restrict the changeable node connections to\nthose participating in the fitness function. However, this method has not been\napplied to GNP structures that use separate graphs for each agent, such as\nsituation-based GNP (SBGNP). This paper proposes a method to apply simplified\noperators to SBGNP. To evaluate the performance of this method, we tested it on\nthe Tileworld benchmark, where the algorithm demonstrated improvements in\naverage fitness.",
    "pdf_url": "http://arxiv.org/pdf/2412.11146v1",
    "published": "2024-12-15T10:35:10+00:00",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11145v2",
    "title": "The Superalignment of Superhuman Intelligence with Large Language Models",
    "authors": [
      "Minlie Huang",
      "Yingkang Wang",
      "Shiyao Cui",
      "Pei Ke",
      "Jie Tang"
    ],
    "abstract": "We have witnessed superhuman intelligence thanks to the fast development of\nlarge language models and multimodal language models. As the application of\nsuch superhuman models becomes more and more popular, a critical question\narises here: how can we ensure superhuman models are still safe, reliable and\naligned well to human values? In this position paper, we discuss the concept of\nsuperalignment from the learning perspective to answer this question by\noutlining the learning paradigm shift from large-scale pretraining, supervised\nfine-tuning, to alignment training. We define superalignment as designing\neffective and efficient alignment algorithms to learn from noisy-labeled data\n(point-wise samples or pair-wise preference data) in a scalable way when the\ntask becomes very complex for human experts to annotate and the model is\nstronger than human experts. We highlight some key research problems in\nsuperalignment, namely, weak-to-strong generalization, scalable oversight, and\nevaluation. We then present a conceptual framework for superalignment, which\nconsists of three modules: an attacker which generates adversary queries trying\nto expose the weaknesses of a learner model; a learner which will refine itself\nby learning from scalable feedbacks generated by a critic model along with\nminimal human experts; and a critic which generates critics or explanations for\na given query-response pair, with a target of improving the learner by\ncriticizing. We discuss some important research problems in each component of\nthis framework and highlight some interesting research ideas that are closely\nrelated to our proposed framework, for instance, self-alignment, self-play,\nself-refinement, and more. Last, we highlight some future research directions\nfor superalignment, including identification of new emergent risks and\nmulti-dimensional alignment.",
    "pdf_url": "http://arxiv.org/pdf/2412.11145v2",
    "published": "2024-12-15T10:34:06+00:00",
    "categories": [
      "cs.CL",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11144v2",
    "title": "Study on the structure of the $Z_{c}(3900)$ state",
    "authors": [
      "Yan Ma",
      "De-Shun Zhang",
      "Cheng-Qun Pang",
      "Zhi-Feng Sun"
    ],
    "abstract": "In this work, we studied the $Z_{c}(3900)$ state within the framework of\neffective field theory. We firstly show the construction of the Lagrangian\ndescribing meson-meson-meson and meson-diquark-diquark interactions. By using\nthe Feynman rule, we calculate the effective potentials corresponding to the\ncoupled channels of $D\\bar{D}^{*}/D^{*}\\bar{D}$ and\n$S_{cq}\\bar{A}_{cq}/A_{cq}\\bar{S}_{cq}$ with $S_{cq}$ ($A_{cq}$) the scalar\n(axial vector) diquark composed of $c$ and $q$ quarks. After solving the\nBethe-Salpeter equation of the on-shell parametrized form and compare our\nnumerical results with the experimental mass and width of $Z_{c}(3900)$, we\nfind that the $Z_{c}(3900)$ state can be explained as the mixture of\n$D\\bar{D}^{*}/D^{*}\\bar{D}$ and $S_{cq}\\bar{A}_{cq}/A_{cq}\\bar{S}_{cq}$\ncomponents.",
    "pdf_url": "http://arxiv.org/pdf/2412.11144v2",
    "published": "2024-12-15T10:33:41+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11143v1",
    "title": "AstroSat timing and spectral analysis of the accretion-powered millisecond X-ray pulsar IGR J17591--2342",
    "authors": [
      "Akshay Singh",
      "Andrea Sanna",
      "Sudip Bhattacharyya",
      "Sudiip Chakraborty",
      "Sarita Jangle",
      "Tlak Katoch",
      "H. M. Antia",
      "Nitinkumar Bijewar"
    ],
    "abstract": "IGR J17591--2342, a transient accretion-powered millisecond X-ray pulsar, was\ndiscovered during its 2018 outburst. Here, we present a timing and spectral\nanalysis of the source using {\\it AstroSat} data of the same outburst. From the\ntiming analysis, we obtain updated values of binary orbital parameters, which\nreveal an average pulsar spin frequency of 527.4256984(8) Hz. The pulse\nprofiles can be fit well with four harmonically related sinusoidal components\nwith fractional amplitudes of fundamental and second, third, and fourth\nharmonics as $\\sim13$\\%, $\\sim$6\\%, $\\sim$0.9\\%, $\\sim$0.2\\%, respectively. The\nenergy-dependent study of pulse profiles in the range of $3-20$ keV shows that\nthe fractional amplitude of both the fundamental and first overtone is\nconsistent with being constant across the considered energy band. Besides, a\ndecaying trend has been observed for both the fundamental and first overtone in\nthe phase-delay versus energy relation resulting in soft X-ray (2.8-3.3 keV)\nphase lags of $\\sim$0.05 and $\\sim$0.13 with respect to $\\leq 15$ keV photons,\nfor the fundamental and first overtone, respectively. The combined spectra from\nthe Large Area X-ray Proportional Counters and the Soft X-ray Telescope aboard\n{\\it AstroSat} in the $1-18$ keV range can be fit well with an absorbed model\nconsisting of a Comptonization, a blackbody and a Gaussian emission line\ncomponent yielding as best-fit parameters a blackbody seed photon temperature\n$kT_{\\rm bb}$ $\\sim 0.95 \\pm 0.03$ keV, and an electron temperature $kT_{\\rm\ne}$ $\\sim 1.54 \\pm0.03$ keV. The spectral aspects suggest the scattering of\nphotons from the accretion disc or the neutron star's surface.",
    "pdf_url": "http://arxiv.org/pdf/2412.11143v1",
    "published": "2024-12-15T10:32:57+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11142v3",
    "title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection",
    "authors": [
      "Tiankai Yang",
      "Yi Nian",
      "Shawn Li",
      "Ruiyao Xu",
      "Yuangang Li",
      "Jiaqi Li",
      "Zhuo Xiao",
      "Xiyang Hu",
      "Ryan Rossi",
      "Kaize Ding",
      "Xia Hu",
      "Yue Zhao"
    ],
    "abstract": "Anomaly detection (AD) is an important machine learning task with many\nreal-world uses, including fraud detection, medical diagnosis, and industrial\nmonitoring. Within natural language processing (NLP), AD helps detect issues\nlike spam, misinformation, and unusual user activity. Although large language\nmodels (LLMs) have had a strong impact on tasks such as text generation and\nsummarization, their potential in AD has not been studied enough. This paper\nintroduces AD-LLM, the first benchmark that evaluates how LLMs can help with\nNLP anomaly detection. We examine three key tasks: (i) zero-shot detection,\nusing LLMs' pre-trained knowledge to perform AD without tasks-specific\ntraining; (ii) data augmentation, generating synthetic data and category\ndescriptions to improve AD models; and (iii) model selection, using LLMs to\nsuggest unsupervised AD models. Through experiments with different datasets, we\nfind that LLMs can work well in zero-shot AD, that carefully designed\naugmentation methods are useful, and that explaining model selection for\nspecific datasets remains challenging. Based on these results, we outline six\nfuture research directions on LLMs for AD.",
    "pdf_url": "http://arxiv.org/pdf/2412.11142v3",
    "published": "2024-12-15T10:22:14+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11141v1",
    "title": "Integrated density of states for the sub-Laplacian on Heisenberg groups",
    "authors": [
      "Zouhaïr Mouayn"
    ],
    "abstract": "We rederive the expression of the integrated density of states for \\ the\nsub-Laplacian on Heisenberg groups $\\mathbb{H}_{n}$ by using its resolvent\nkernel.",
    "pdf_url": "http://arxiv.org/pdf/2412.11141v1",
    "published": "2024-12-15T10:13:28+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11140v1",
    "title": "BUPD: A Bayesian under-parameterized basket design with the unit information prior in oncology trials",
    "authors": [
      "Ryo Kitabayashi",
      "Hiroyuki Sato",
      "Akihiro Hirakawa"
    ],
    "abstract": "Basket trials in oncology enroll multiple patients with cancer harboring\nidentical gene alterations and evaluate their response to targeted therapies\nacross cancer types. Several existing methods have extended a Bayesian\nhierarchical model borrowing information on the response rates in different\ncancer types to account for the heterogeneity of drug effects. However, these\nmethods rely on several pre-specified parameters to account for the\nheterogeneity of response rates among different cancer types. Here, we propose\na novel Bayesian under-parameterized basket design with a unit information\nprior (BUPD) that uses only one (or two) pre-specified parameters to control\nthe amount of information borrowed among cancer types, considering the\nheterogeneity of response rates. BUPD adapts the unit information prior\napproach, originally developed for borrowing information from historical\nclinical trial data, to enable mutual information borrowing between two cancer\ntypes. BUPD enables flexible controls of the type 1 error rate and power by\nexplicitly specifying the strength of borrowing while providing interpretable\nestimations of response rates. Simulation studies revealed that BUPD reduced\nthe type 1 error rate in scenarios with few ineffective cancer types and\nimproved the power in scenarios with few effective cancer types better than\nfive existing methods. This study also illustrated the efficiency of BUPD using\nresponse rates from a real basket trial.",
    "pdf_url": "http://arxiv.org/pdf/2412.11140v1",
    "published": "2024-12-15T10:06:26+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2412.11139v2",
    "title": "ViSymRe: Vision-guided Multimodal Symbolic Regression",
    "authors": [
      "Da Li",
      "Junping Yin",
      "Jin Xu",
      "Xinxin Li",
      "Juan Zhang"
    ],
    "abstract": "Extracting simple mathematical expression from an observational dataset to\ndescribe complex natural phenomena is one of the core objectives of artificial\nintelligence (AI). This field is known as symbolic regression (SR). Traditional\nSR models are based on genetic programming (GP) or reinforcement learning (RL),\nfacing well-known challenges, such as low efficiency and overfitting. Recent\nstudies have integrated SR with large language models (LLMs), enabling fast\nzero-shot inference by learning mappings from millions of dataset-expression\npairs. However, since the input and output are inherently different modalities,\nsuch models often struggle to converge effectively. In this paper, we introduce\nViSymRe, a vision-guided multimodal SR model that incorporates the third\nresource, expression graph, to bridge the modality gap. Different from\ntraditional multimodal models, ViSymRe is trained to extract vision, termed\nvirtual vision, from datasets, without relying on the global availability of\nexpression graphs, which addresses the essential challenge of visual SR, i.e.,\nexpression graphs are not available during inference. Evaluation results on\nmultiple mainstream benchmarks show that ViSymRe achieves more competitive\nperformance than the state-of-the-art dataset-only baselines. The expressions\npredicted by ViSymRe not only fit the dataset well but are also simple and\nstructurally accurate, goals that SR models strive to achieve.",
    "pdf_url": "http://arxiv.org/pdf/2412.11139v2",
    "published": "2024-12-15T10:05:31+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11138v1",
    "title": "Safe Reinforcement Learning using Finite-Horizon Gradient-based Estimation",
    "authors": [
      "Juntao Dai",
      "Yaodong Yang",
      "Qian Zheng",
      "Gang Pan"
    ],
    "abstract": "A key aspect of Safe Reinforcement Learning (Safe RL) involves estimating the\nconstraint condition for the next policy, which is crucial for guiding the\noptimization of safe policy updates. However, the existing Advantage-based\nEstimation (ABE) method relies on the infinite-horizon discounted advantage\nfunction. This dependence leads to catastrophic errors in finite-horizon\nscenarios with non-discounted constraints, resulting in safety-violation\nupdates. In response, we propose the first estimation method for finite-horizon\nnon-discounted constraints in deep Safe RL, termed Gradient-based Estimation\n(GBE), which relies on the analytic gradient derived along trajectories. Our\ntheoretical and empirical analyses demonstrate that GBE can effectively\nestimate constraint changes over a finite horizon. Constructing a surrogate\noptimization problem with GBE, we developed a novel Safe RL algorithm called\nConstrained Gradient-based Policy Optimization (CGPO). CGPO identifies feasible\noptimal policies by iteratively resolving sub-problems within trust regions.\nOur empirical results reveal that CGPO, unlike baseline algorithms,\nsuccessfully estimates the constraint functions of subsequent policies, thereby\nensuring the efficiency and feasibility of each update.",
    "pdf_url": "http://arxiv.org/pdf/2412.11138v1",
    "published": "2024-12-15T10:05:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11137v1",
    "title": "Decoding Drug Discovery: Exploring A-to-Z In silico Methods for Beginners",
    "authors": [
      "Hezha O. Rasul",
      "Dlzar D. Ghafour",
      "Bakhtyar K. Aziz",
      "Bryar A. Hassan",
      "Tarik A. Rashid",
      "Arif Kivrak"
    ],
    "abstract": "The drug development process is a critical challenge in the pharmaceutical\nindustry due to its time-consuming nature and the need to discover new drug\npotentials to address various ailments. The initial step in drug development,\ndrug target identification, often consumes considerable time. While valid,\ntraditional methods such as in vivo and in vitro approaches are limited in\ntheir ability to analyze vast amounts of data efficiently, leading to wasteful\noutcomes. To expedite and streamline drug development, an increasing reliance\non computer-aided drug design (CADD) approaches has merged. These sophisticated\nin silico methods offer a promising avenue for efficiently identifying viable\ndrug candidates, thus providing pharmaceutical firms with significant\nopportunities to uncover new prospective drug targets. The main goal of this\nwork is to review in silico methods used in the drug development process with a\nfocus on identifying therapeutic targets linked to specific diseases at the\ngenetic or protein level. This article thoroughly discusses A-to-Z in silico\ntechniques, which are essential for identifying the targets of bioactive\ncompounds and their potential therapeutic effects. This review intends to\nimprove drug discovery processes by illuminating the state of these\ncutting-edge approaches, thereby maximizing the effectiveness and duration of\nclinical trials for novel drug target investigation.",
    "pdf_url": "http://arxiv.org/pdf/2412.11137v1",
    "published": "2024-12-15T10:02:38+00:00",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2412.11136v1",
    "title": "Minimax Regret Estimation for Generalizing Heterogeneous Treatment Effects with Multisite Data",
    "authors": [
      "Yi Zhang",
      "Melody Huang",
      "Kosuke Imai"
    ],
    "abstract": "To test scientific theories and develop individualized treatment rules,\nresearchers often wish to learn heterogeneous treatment effects that can be\nconsistently found across diverse populations and contexts. We consider the\nproblem of generalizing heterogeneous treatment effects (HTE) based on data\nfrom multiple sites. A key challenge is that a target population may differ\nfrom the source sites in unknown and unobservable ways. This means that the\nestimates from site-specific models lack external validity, and a simple pooled\nanalysis risks bias. We develop a robust CATE (conditional average treatment\neffect) estimation methodology with multisite data from heterogeneous\npopulations. We propose a minimax-regret framework that learns a generalizable\nCATE model by minimizing the worst-case regret over a class of target\npopulations whose CATE can be represented as convex combinations of\nsite-specific CATEs. Using robust optimization, the proposed methodology\naccounts for distribution shifts in both individual covariates and treatment\neffect heterogeneity across sites. We show that the resulting CATE model has an\ninterpretable closed-form solution, expressed as a weighted average of\nsite-specific CATE models. Thus, researchers can utilize a flexible CATE\nestimation method within each site and aggregate site-specific estimates to\nproduce the final model. Through simulations and a real-world application, we\nshow that the proposed methodology improves the robustness and generalizability\nof existing approaches.",
    "pdf_url": "http://arxiv.org/pdf/2412.11136v1",
    "published": "2024-12-15T10:00:07+00:00",
    "categories": [
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2412.11135v2",
    "title": "Competing Orbital Magnetism and Superconductivity in electrostatically defined Josephson Junctions of Alternating Twisted Trilayer Graphene",
    "authors": [
      "Vishal Bhardwaj",
      "Lekshmi Rajagopal",
      "Lorenzo Arici",
      "Matan Bocarsly",
      "Alexey Ilin",
      "Gal Shavit",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Yuval Oreg",
      "Tobias Holder",
      "Yuval Ronen"
    ],
    "abstract": "The coexistence of superconductivity and magnetism within a single material\nsystem represents a long-standing goal in condensed matter physics. Van der\nWaals-based moir\\'e superlattices provide an exceptional platform for exploring\ncompeting and coexisting broken symmetry states. Alternating twisted trilayer\ngraphene (TTG) exhibits robust superconductivity at the magic angle of\n1.57{\\deg} and 1.3{\\deg}, with suppression at intermediate twist angles. In\nthis study, we investigate the intermediate regime and uncover evidence of\norbital magnetism. As previously reported, superconductivity is suppressed near\nthe charge neutrality point (CNP) and emerges at larger moir\\'e fillings.\nConversely, we find orbital magnetism most substantial near the CNP,\ndiminishing as superconductivity develops. This complementary behavior is\nsimilarly observed in the displacement field phase space, highlighting a\ncompetitive interplay between the two phases. Utilizing gate-defined Josephson\njunctions, we probe orbital magnetism by electrostatically tuning the weak\nlinks into the magnetic phase, revealing an asymmetric Fraunhofer interference\npattern. The estimated orbital ferromagnetic ordering temperature is\napproximately half the superconducting critical temperature, coinciding with\nthe onset of Fraunhofer asymmetry. Our findings suggest that the observed\norbital magnetism is driven by valley polarization and is distinct from the\nanomalous Hall effect reported at integer fillings in twisted graphene systems.\nThese results offer insights into the interplay between superconductivity and\nmagnetism in moir\\'e superlattices.",
    "pdf_url": "http://arxiv.org/pdf/2412.11135v2",
    "published": "2024-12-15T09:58:01+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2412.12203v1",
    "title": "Observational constraints on mutated hilltop inflation",
    "authors": [
      "Iraj Safaei",
      "Soma Heydari",
      "Milad Solbi",
      "Kayoomars Karami"
    ],
    "abstract": "Here, a single field inflationary model driven by a mutated hilltop\npotential, as a subclass of the hilltop models of inflation, is investigated.\nIn order to constrain the parameter space of the model, the $r-n_{\\rm s}$\nconstraint of Planck and BICEP/Keck 2018 data as well as the reheating\nparameters such as the duration $N_{\\rm{re}}$, the temperature $T_{\\rm{re}}$,\nand the equation of state parameter $\\omega_{\\rm{re}}$, are employed. In\naddition, a model independent bound on the duration of the radiation dominated\n(RD) era $N_{\\rm{rd}}$ is applied to improve the parameter space. Furthermore,\nthe density spectra of relic gravitational waves (GWs) in light of the\nsensitivity domains of GW detectors, for specific inflationary durations $N$,\nare analyzed. Finally, by combining constraints from the cosmic microwave\nbackground (CMB), reheating, RD era, and relic GWs, the permissible\ninflationary duration is constrained to $46\\leq N \\leq 56$ (95\\% CL) and\n$48.1\\leq N\\leq 56$ (68\\% CL). Moreover, the model parameter $\\alpha$ is\nconfined to $0.161\\leq\\alpha \\leq 0.890$ (95\\% CL) and $0.217\\leq\\alpha \\leq\n0.815$ (68\\% CL).",
    "pdf_url": "http://arxiv.org/pdf/2412.12203v1",
    "published": "2024-12-15T09:56:41+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11134v1",
    "title": "Diffusion Limit of the Low-Density Magnetic Lorentz Gas",
    "authors": [
      "Alessia Nota",
      "Dominik Nowak",
      "Chiara Saffirio"
    ],
    "abstract": "We consider the magnetic Lorentz gas proposed by Bobylev et al. [4], which\ndescribes a point particle moving in a random distribution of hard-disk\nobstacles in $\\mathbb{R}^2$ under the influence of a constant magnetic field\nperpendicular to the plane. We show that, in the coupled low-density and\ndiffusion limit, when the intensity of the magnetic field is smaller than\n$\\frac{8\\pi}{3}$, the non-Markovian effects induced by the magnetic field\nbecome sufficiently weak. Consequently, the particle's probability distribution\nconverges to the solution of the heat equation with a diffusion coefficient\ndependent on the magnetic field and given by the Green-Kubo formula. This\nformula is derived from the generator of the generalized Boltzmann process\nassociated with the generalized Boltzmann equation, as predicted in [4].",
    "pdf_url": "http://arxiv.org/pdf/2412.11134v1",
    "published": "2024-12-15T09:44:59+00:00",
    "categories": [
      "math-ph",
      "math.AP",
      "math.MP",
      "math.PR"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11133v1",
    "title": "Gauss maps of Möbius surfaces in the $n$-dimensional sphere",
    "authors": [
      "David Brander",
      "Shimpei Kobayashi",
      "Peng Wang"
    ],
    "abstract": "In this note we discuss Gauss maps for M\\\"obius surfaces in the $n$-sphere,\nand their applications in the study of Willmore surfaces. One such ``Gauss\nmap'', naturally associated to a Willmore surface that has a dual Willmore\nsurface, is the Lorentzian $2$-plane bundle given by a lift of the suface and\nits dual. More generally, we define the concept of a Lorentzian $2$-plane lift\nfor an arbitrary M\\\"obius surface, and show that the conformal harmonicity of\nthis lift is equivalent to the Willmore condition for the surface. This\nclarifies some previous work of F. H\\'elein, Q. Xia-Y Shen, X. Ma and others,\nand, for instance, allows for the treatment of the Bj\\\"orling problem for\nWillmore surfaces in the presence of umbilics.",
    "pdf_url": "http://arxiv.org/pdf/2412.11133v1",
    "published": "2024-12-15T09:37:19+00:00",
    "categories": [
      "math.DG",
      "Primary~53A31, 53C43, Secondary~58E20, 53C35"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11132v2",
    "title": "Entropy conservative and entropy stable solid wall boundary conditions for the resistive magnetohydrodynamic equations",
    "authors": [
      "Vladimir Pimanov",
      "Lisandro Dalcin",
      "Matteo Parsani"
    ],
    "abstract": "We present a novel technique for imposing non-linear entropy conservative and\nentropy stable wall boundary conditions for the resistive magnetohydrodynamic\nequations in the presence of an adiabatic wall or a wall with a prescribed heat\nentropy flow, addressing three scenarios: electrically insulating walls, thin\nwalls with finite conductivity, and perfectly conducting walls. The procedure\nrelies on the formalism and mimetic properties of diagonal-norm,\nsummation-by-parts, and simultaneous-approximation-term operators. Using the\nmethod of lines, a semi-discrete entropy estimate for the entire domain is\nobtained when the proposed numerical imposition of boundary conditions is\ncoupled with an entropy-conservative or entropy-stable discrete interior\noperator. The resulting estimate mimics the global entropy estimate obtained at\nthe continuous level. The boundary data at the wall are weakly imposed using a\npenalty flux approach and a simultaneous-approximation-term technique for both\nthe conservative variables and the gradient of the entropy variables.\nDiscontinuous spectral collocation operators (mass lumped nodal discontinuous\nGalerkin operators) on high-order unstructured grids are used to demonstrate\nthe new procedure's accuracy, robustness, and efficacy for weakly enforcing\nboundary conditions. Numerical simulations confirm the non-linear stability of\nthe proposed technique, with applications to three-dimensional flows. The\nprocedure described is compatible with any diagonal-norm summation-by-parts\nspatial operator, including finite element, finite difference, finite volume,\nnodal and modal discontinuous Galerkin, and flux reconstruction schemes.",
    "pdf_url": "http://arxiv.org/pdf/2412.11132v2",
    "published": "2024-12-15T09:36:51+00:00",
    "categories": [
      "math.NA",
      "cs.CE",
      "cs.NA",
      "physics.comp-ph"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11131v1",
    "title": "Kinetics of relativistic axionically active plasma in the field of dynamic aether. Part I: General formalism and new concept of equilibrium states",
    "authors": [
      "Alexander B. Balakin",
      "Kamil R. Valiullin"
    ],
    "abstract": "We establish an extended version of the kinetic theory of the relativistic\naxionically active multi-component plasma, which is based on the inclusion of a\nunit time-like vector field, associated with the velocity of dynamic aether,\ninto the scheme of interactions. The proposed extension of the plasma theory\ncan be indicated as semi-phenomenological. This term means that master\nequations for the gravitational, electromagnetic, pseudoscalar (axionic) and\nvector (aetheric) fields are derived using the Lagrange formalism, the kinetic\nequations for the distribution functions are obtained by the methods of the\ncovariant statistics, however, the relativistic forces acting from the listed\nfields on the plasma particles are reconstructed phenomenologically based on\nclassical analogies. We consider this work as a first part of a trilogy; here\nwe presented, first, the complete formalism of this extended theory, second,\nthe classification of forces, third, the new concept of equilibrium states in\nthe relativistic axionically - aetherically active plasma.",
    "pdf_url": "http://arxiv.org/pdf/2412.11131v1",
    "published": "2024-12-15T09:27:54+00:00",
    "categories": [
      "gr-qc",
      "physics.plasm-ph"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2412.11130v8",
    "title": "Investigation about a statement equivalent to Riemann Hypothesis (RH)",
    "authors": [
      "Giovanni Lodone"
    ],
    "abstract": "The idea is to compute a quantity like the angular momentum with respect to\nthe origin, of an unitary mass whose coordinates are real and imaginary\ncomponents of Xi(s) while s imaginary component is time, and, real s component\nis constant. If we impose that the derivative along real s, at points where\nreal s = 0.5, is grater than zero, then, we find exactly a known RH equivalence\nstatement about relative maxima and minima of Xi(s) along critical line. After\nrepresenting this fictitious angular momentum by Euler Product, and, using\nP.N.T. as a tool, it can be proved that this positivity condition is granted\neverywhere at least for Xi(s) not equal to 0 on critical line. So, if the above\nequivalence is true, it is found that off critical line zeros must be excluded\nfor Z(s) function along all critical strip. Besides the converging spectrum of\nprime numbers is highlighted as a by product.",
    "pdf_url": "http://arxiv.org/pdf/2412.11130v8",
    "published": "2024-12-15T09:27:42+00:00",
    "categories": [
      "math.GM",
      "11M06, 11M99"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2412.12202v1",
    "title": "A multi-theoretical kernel-based approach to social network-based recommendation",
    "authors": [
      "Xin Li",
      "Mengyue Wang",
      "T. -P. Liang"
    ],
    "abstract": "Recommender systems are a critical component of e-commercewebsites. The rapid\ndevelopment of online social networking services provides an opportunity to\nexplore social networks together with information used in traditional\nrecommender systems, such as customer demographics, product characteristics,\nand transactions. It also provides more applications for recommender systems.\nTo tackle this social network-based recommendation problem, previous studies\ngenerally built trust models in light of the social influence theory. This\nstudy inspects a spectrumof social network theories to systematicallymodel\nthemultiple facets of a social network and infer user preferences. In order to\neffectively make use of these heterogonous theories, we take a kernel-based\nmachine learning paradigm, design and select kernels describing individual\nsimilarities according to social network theories, and employ a non-linear\nmultiple kernel learning algorithm to combine the kernels into a unified model.\nThis design also enables us to consider multiple theories' interactions in\nassessing individual behaviors. We evaluate our proposed approach on a\nreal-world movie review data set. The experiments show that our approach\nprovides more accurate recommendations than trust-based methods and the\ncollaborative filtering approach. Further analysis shows that kernels derived\nfrom contagion theory and homophily theory contribute a larger portion of the\nmodel.",
    "pdf_url": "http://arxiv.org/pdf/2412.12202v1",
    "published": "2024-12-15T09:23:14+00:00",
    "categories": [
      "cs.SI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2412.11129v1",
    "title": "Disentangling Coherent and Incoherent Effects in Superconductor Photoemission Spectra via Machine Learning",
    "authors": [
      "K. H. Bohachov",
      "A. A. Kordyuk"
    ],
    "abstract": "Disentangling coherent and incoherent effects in the photoemission spectra of\nstrongly correlated materials is generally a challenging problem due to the\ninvolvement of numerous parameters. In this study, we employ machine learning\ntechniques, specifically Convolutional Neural Networks (CNNs), to address the\nlong-standing issue of the bilayer splitting in superconducting cuprates. We\ndemonstrate the effectiveness of CNN training on modeled spectra and confirm\nearlier findings that establish the presence of bilayer splitting across the\nentire doping range. Furthermore, we show that the magnitude of the splitting\ndoes not decrease with underdoping, contrary to expectations. This approach not\nonly highlights the potential of machine learning in tackling complex physical\nproblems but also provides a robust framework for advancing the analysis of\nelectronic properties in correlated superconductors.",
    "pdf_url": "http://arxiv.org/pdf/2412.11129v1",
    "published": "2024-12-15T09:23:03+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2412.11128v1",
    "title": "Closed dynamical recursion equations for correlation functions and the application on the construction of Liouvillian spectrum in Lindbladian systems",
    "authors": [
      "Xueliang Wang",
      "Shu Chen"
    ],
    "abstract": "For an open quantum system described by the Lindblad equation, full\ncharacterization of its dynamics typically needs the knowledge of the\nLiouvillian spectrum and correlation functions. Solving the Liouvillian\nspectrum and correlation functions are usually formidable tasks, and most\nprevious studies are constrained to simple models and lower-order correlations.\nIn this work, we derive a closed form of dynamical recursion equations for all\neven-order correlation functions associated with the quadratic Liouvillian\nsuperoperator, thus extending the Wick's theorem and enabling the\nreconstruction of the corresponding Liouvillian spectrum. Furthermore, we study\nthe quartic Liouvillian superoperator, establishing the necessary and\nsufficient conditions for the closure of second-order correlation functions.\nBuilding on this, the dynamical expressions for even-order correlation\nfunctions under quadratic dissipation are derived, culminating in a method for\nconstructing the Liouvillian spectrum in this extended framework.",
    "pdf_url": "http://arxiv.org/pdf/2412.11128v1",
    "published": "2024-12-15T09:22:34+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11127v1",
    "title": "Modeling the Heterogeneous Duration of User Interest in Time-Dependent Recommendation: A Hidden Semi-Markov Approach",
    "authors": [
      "Haidong Zhang",
      "Wancheng Ni",
      "Xin Li",
      "Yiping Yang"
    ],
    "abstract": "Recommender systems are widely used for suggesting books, education\nmaterials, and products to users by exploring their behaviors. In reality,\nusers' preferences often change over time, leading to studies on time-dependent\nrecommender systems. However, most existing approaches that deal with time\ninformation remain primitive. In this paper, we extend existing methods and\npropose a hidden semi-Markov model to track the change of users' interests.\nParticularly, this model allows for capturing the different durations of user\nstays in a (latent) interest state, which can better model the heterogeneity of\nuser interests and focuses. We derive an expectation maximization algorithm to\nestimate the parameters of the framework and predict users' actions.\nExperiments on three real-world datasets show that our model significantly\noutperforms the state-of-the-art time-dependent and static benchmark methods.\nFurther analyses of the experiment results indicate that the performance\nimprovement is related to the heterogeneity of state durations and the drift of\nuser interests in the dataset.",
    "pdf_url": "http://arxiv.org/pdf/2412.11127v1",
    "published": "2024-12-15T09:17:45+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11126v1",
    "title": "Limit error distributions of Milstein scheme for stochastic Volterra equations with singular kernels",
    "authors": [
      "Shanqi Liu",
      "Yaozhong Hu",
      "Hongjun Gao"
    ],
    "abstract": "For stochastic Volterra equations driven by standard Brownian and with\nsingular kernels $K(u)=u^{H-\\frac{1}{2}}/\\Gamma(H+1/2), H\\in (0,1/2)$, it is\nknown that the Milstein scheme has a convergence rate of $n^{-2H}$. In this\npaper, we show that this rate is optimal. Moreover, we show that the error\nnormalized by $n^{-2H}$ converge stably in law to the (nonzero) solution of a\ncertain linear Volterra equation of random coefficients with the same\nfractional kernel.",
    "pdf_url": "http://arxiv.org/pdf/2412.11126v1",
    "published": "2024-12-15T09:16:26+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11125v1",
    "title": "Feature engineering vs. deep learning for paper section identification: Toward applications in Chinese medical literature",
    "authors": [
      "Sijia Zhou",
      "Xin Li"
    ],
    "abstract": "Section identification is an important task for library science, especially\nknowledge management. Identifying the sections of a paper would help filter\nnoise in entity and relation extraction. In this research, we studied the paper\nsection identification problem in the context of Chinese medical literature\nanalysis, where the subjects, methods, and results are more valuable from a\nphysician's perspective. Based on previous studies on English literature\nsection identification, we experiment with the effective features to use with\nclassic machine learning algorithms to tackle the problem. It is found that\nConditional Random Fields, which consider sentence interdependency, is more\neffective in combining different feature sets, such as bag-of-words,\npart-of-speech, and headings, for Chinese literature section identification.\nMoreover, we find that classic machine learning algorithms are more effective\nthan generic deep learning models for this problem. Based on these\nobservations, we design a novel deep learning model, the Structural\nBidirectional Long Short-Term Memory (SLSTM) model, which models word and\nsentence interdependency together with the contextual information. Experiments\non a human-curated asthma literature dataset show that our approach outperforms\nthe traditional machine learning methods and other deep learning methods and\nachieves close to 90% precision and recall in the task. The model shows good\npotential for use in other text mining tasks. The research has significant\nmethodological and practical implications.",
    "pdf_url": "http://arxiv.org/pdf/2412.11125v1",
    "published": "2024-12-15T09:11:14+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11124v2",
    "title": "Combating Multimodal LLM Hallucination via Bottom-Up Holistic Reasoning",
    "authors": [
      "Shengqiong Wu",
      "Hao Fei",
      "Liangming Pan",
      "William Yang Wang",
      "Shuicheng Yan",
      "Tat-Seng Chua"
    ],
    "abstract": "Recent advancements in multimodal large language models (MLLMs) have shown\nunprecedented capabilities in advancing various vision-language tasks. However,\nMLLMs face significant challenges with hallucinations, and misleading outputs\nthat do not align with the input data. While existing efforts are paid to\ncombat MLLM hallucinations, several pivotal challenges are still unsolved.\nFirst, while current approaches aggressively focus on addressing errors at the\nperception level, another important type at the cognition level requiring\nfactual commonsense can be overlooked. In addition, existing methods might fall\nshort in finding a more effective way to represent visual input, which is yet a\nkey bottleneck that triggers visual hallucinations. Moreover, MLLMs can\nfrequently be misled by faulty textual inputs and cause hallucinations, while\nunfortunately, this type of issue has long been overlooked by existing studies.\nInspired by human intuition in handling hallucinations, this paper introduces a\nnovel bottom-up reasoning framework. Our framework systematically addresses\npotential issues in both visual and textual inputs by verifying and integrating\nperception-level information with cognition-level commonsense knowledge,\nensuring more reliable outputs. Extensive experiments demonstrate significant\nimprovements in multiple hallucination benchmarks after integrating MLLMs with\nthe proposed framework. In-depth analyses reveal the great potential of our\nmethods in addressing perception- and cognition-level hallucinations.",
    "pdf_url": "http://arxiv.org/pdf/2412.11124v2",
    "published": "2024-12-15T09:10:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11123v1",
    "title": "Hierarchical Bidirectional Transition Dispersion Entropy-based Lempel-Ziv Complexity and Its Application in Fault-Bearing Diagnosis",
    "authors": [
      "Runze Jiang",
      "Pengjian Shang"
    ],
    "abstract": "Lempel-Ziv complexity (LZC) is a key measure for detecting the irregularity\nand complexity of nonlinear time series and has seen various improvements in\nrecent decades. However, existing LZC-based metrics, such as Permutation\nLempel-Ziv complexity (PLZC) and Dispersion-Entropy based Lempel-Ziv complexity\n(DELZC), focus mainly on patterns of independent embedding vectors, often\noverlooking the transition patterns within the time series. To address this\ngap, this paper introduces a novel LZC-based method called Bidirectional\nTransition Dispersion Entropy-based Lempel-Ziv complexity (BT-DELZC).\nLeveraging Markov chain theory, this method integrates a bidirectional\ntransition network framework with DELZC to better capture dynamic signal\ninformation. Additionally, an improved hierarchical decomposition algorithm is\nused to extract features from various frequency components of the time series.\nThe proposed BT-DELZC method is first evaluated through four simulated\nexperiments, demonstrating its robustness and effectiveness in characterizing\nnonlinear time series. Additionally, two fault-bearing diagnosis experiments\nare conducted by combining the hierarchical BT-DELZC method with various\nclassifiers from the machine learning domain. The results indicate that\nBT-DELZC achieves the highest accuracy across both datasets, significantly\noutperforming existing methods such as LZC, PLZC, and DELZC in extracting\nfeatures related to fault bearings.",
    "pdf_url": "http://arxiv.org/pdf/2412.11123v1",
    "published": "2024-12-15T09:00:28+00:00",
    "categories": [
      "physics.data-an",
      "cs.LG",
      "eess.SP",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "physics.data-an"
  },
  {
    "id": "http://arxiv.org/abs/2412.11122v2",
    "title": "Paid with Models: Optimal Contract Design for Collaborative Machine Learning",
    "authors": [
      "Bingchen Wang",
      "Zhaoxuan Wu",
      "Fusheng Liu",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "Collaborative machine learning (CML) provides a promising paradigm for\ndemocratizing advanced technologies by enabling cost-sharing among\nparticipants. However, the potential for rent-seeking behaviors among parties\ncan undermine such collaborations. Contract theory presents a viable solution\nby rewarding participants with models of varying accuracy based on their\ncontributions. However, unlike monetary compensation, using models as rewards\nintroduces unique challenges, particularly due to the stochastic nature of\nthese rewards when contribution costs are privately held information. This\npaper formalizes the optimal contracting problem within CML and proposes a\ntransformation that simplifies the non-convex optimization problem into one\nthat can be solved through convex optimization algorithms. We conduct a\ndetailed analysis of the properties that an optimal contract must satisfy when\nmodels serve as the rewards, and we explore the potential benefits and welfare\nimplications of these contract-driven CML schemes through numerical\nexperiments.",
    "pdf_url": "http://arxiv.org/pdf/2412.11122v2",
    "published": "2024-12-15T08:55:16+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "econ.TH"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11121v1",
    "title": "Rethinking Software Misconfigurations in the Real World: An Empirical Study and Literature Analysis",
    "authors": [
      "Yuhao Liu",
      "Yingnan Zhou",
      "Hanfeng Zhang",
      "Zhiwei Chang",
      "Sihan Xu",
      "Yan Jia",
      "Wei Wang",
      "Zheli Liu"
    ],
    "abstract": "Software misconfiguration has consistently been a major reason for software\nfailures. Over the past twenty decades, much work has been done to detect and\ndiagnose software misconfigurations. However, there is still a gap between\nreal-world misconfigurations and the literature. It is desirable to investigate\nwhether existing taxonomy and tools are applicable for real-world\nmisconfigurations in modern software. In this paper, we conduct an empirical\nstudy on 823 real-world misconfiguration issues, based on which we propose a\nnovel classification of the root causes of software misconfigurations, i.e.,\nconstraint violation, resource unavailability, component-dependency error, and\nmisunderstanding of configuration effects. Then, we systematically review the\nliterature on misconfiguration troubleshooting, and study the trends of\nresearch and the practicality of the tools and datasets in this field. We find\nthat the research targets have changed from fundamental software to advanced\napplications (e.g., cloud service). In the meanwhile, the research on non-crash\nmisconfigurations such as performance degradation and security risks also has a\nsignificant growth. Despite the progress, a majority of studies lack\nreproducibility due to the unavailable tools and evaluation datasets. In total,\nonly six tools and two datasets are publicly available. However, the\nadaptability of these tools limit their practical use on real-world\nmisconfigurations. We also summarize the important challenges and several\nsuggestions to facilitate the research on software misconfiguration.",
    "pdf_url": "http://arxiv.org/pdf/2412.11121v1",
    "published": "2024-12-15T08:53:41+00:00",
    "categories": [
      "cs.SE",
      "D.2"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11120v2",
    "title": "Latent Reward: LLM-Empowered Credit Assignment in Episodic Reinforcement Learning",
    "authors": [
      "Yun Qu",
      "Yuhang Jiang",
      "Boyuan Wang",
      "Yixiu Mao",
      "Cheems Wang",
      "Chang Liu",
      "Xiangyang Ji"
    ],
    "abstract": "Reinforcement learning (RL) often encounters delayed and sparse feedback in\nreal-world applications, even with only episodic rewards. Previous approaches\nhave made some progress in reward redistribution for credit assignment but\nstill face challenges, including training difficulties due to redundancy and\nambiguous attributions stemming from overlooking the multifaceted nature of\nmission performance evaluation. Hopefully, Large Language Model (LLM)\nencompasses fruitful decision-making knowledge and provides a plausible tool\nfor reward redistribution. Even so, deploying LLM in this case is non-trivial\ndue to the misalignment between linguistic knowledge and the symbolic form\nrequirement, together with inherent randomness and hallucinations in inference.\nTo tackle these issues, we introduce LaRe, a novel LLM-empowered symbolic-based\ndecision-making framework, to improve credit assignment. Key to LaRe is the\nconcept of the Latent Reward, which works as a multi-dimensional performance\nevaluation, enabling more interpretable goal attainment from various\nperspectives and facilitating more effective reward redistribution. We examine\nthat semantically generated code from LLM can bridge linguistic knowledge and\nsymbolic latent rewards, as it is executable for symbolic objects. Meanwhile,\nwe design latent reward self-verification to increase the stability and\nreliability of LLM inference. Theoretically, reward-irrelevant redundancy\nelimination in the latent reward benefits RL performance from more accurate\nreward estimation. Extensive experimental results witness that LaRe (i)\nachieves superior temporal credit assignment to SOTA methods, (ii) excels in\nallocating contributions among multiple agents, and (iii) outperforms policies\ntrained with ground truth rewards for certain tasks.",
    "pdf_url": "http://arxiv.org/pdf/2412.11120v2",
    "published": "2024-12-15T08:51:14+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11119v1",
    "title": "Impact of Adversarial Attacks on Deep Learning Model Explainability",
    "authors": [
      "Gazi Nazia Nur",
      "Mohammad Ahnaf Sadat"
    ],
    "abstract": "In this paper, we investigate the impact of adversarial attacks on the\nexplainability of deep learning models, which are commonly criticized for their\nblack-box nature despite their capacity for autonomous feature extraction. This\nblack-box nature can affect the perceived trustworthiness of these models. To\naddress this, explainability techniques such as GradCAM, SmoothGrad, and LIME\nhave been developed to clarify model decision-making processes. Our research\nfocuses on the robustness of these explanations when models are subjected to\nadversarial attacks, specifically those involving subtle image perturbations\nthat are imperceptible to humans but can significantly mislead models. For\nthis, we utilize attack methods like the Fast Gradient Sign Method (FGSM) and\nthe Basic Iterative Method (BIM) and observe their effects on model accuracy\nand explanations. The results reveal a substantial decline in model accuracy,\nwith accuracies dropping from 89.94% to 58.73% and 45.50% under FGSM and BIM\nattacks, respectively. Despite these declines in accuracy, the explanation of\nthe models measured by metrics such as Intersection over Union (IoU) and Root\nMean Square Error (RMSE) shows negligible changes, suggesting that these\nmetrics may not be sensitive enough to detect the presence of adversarial\nperturbations.",
    "pdf_url": "http://arxiv.org/pdf/2412.11119v1",
    "published": "2024-12-15T08:41:37+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11118v1",
    "title": "A piecewise-linear fixed point theorem",
    "authors": [
      "David J. W. Simpson"
    ],
    "abstract": "We prove that if a continuous piecewise-smooth map on $\\mathbb{R}^n$ is\ncomprised of two linear functions, has a bounded orbit, and satisfies a certain\nnon-degeneracy condition, then it has a fixed point. The result has important\nconsequences to the bifurcation theory of nonsmooth dynamical systems, yet the\nproof requires only elementary linear algebra.",
    "pdf_url": "http://arxiv.org/pdf/2412.11118v1",
    "published": "2024-12-15T08:41:16+00:00",
    "categories": [
      "math.DS",
      "math.CA",
      "37C25, 39A28"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2412.11117v1",
    "title": "Global existence and decay rates of strong solutions to the diffusion approximation model in radiation hydrodynamics",
    "authors": [
      "Peng Jiang",
      "Fucai Li",
      "Jinkai Ni"
    ],
    "abstract": "In this paper, we study the global well-posedness and optimal time decay\nrates of strong solutions to the diffusion approximation model in radiation\nhydrodynamics in $\\mathbb{R}^3$. This model consists of the full compressible\nNavier-Stokes equations and the radiative diffusion equation which describes\nthe influence and interaction between thermal radiation and fluid motion.\nSupposing that the initial perturbation around the equilibrium is sufficiently\nsmall in $H^2$-norm, we obtain the global strong solutions by utilizing method\nof the frequency decomposition. Moreover, by performing Fourier analysis\ntechniques and using the delicate energy method, we consequently derive the\noptimal decay rates (including highest-order derivatives) of solutions for this\nmodel.",
    "pdf_url": "http://arxiv.org/pdf/2412.11117v1",
    "published": "2024-12-15T08:35:52+00:00",
    "categories": [
      "math.AP",
      "76N15, 76N10, 35B40"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11116v1",
    "title": "Experimental Study on the Effect of Synchronization Accuracy for Near-Field RF Wireless Power Transfer in Multi-Antenna Systems",
    "authors": [
      "Gilles Callebaut",
      "Jarne Van Mulders",
      "Bert Cox",
      "Benjamin J. B. Deutschmann",
      "Geoffrey Ottoy",
      "Lieven De Strycker",
      "Liesbet Van der Perre"
    ],
    "abstract": "Wireless power transfer (WPT) technologies hold promise for enhancing device\nautonomy, particularly for energy-limited IoT systems. This paper presents\nexperimental results on coherent and non-coherent transmit diversity approaches\nfor WPT, tested in the near field using the Techtile testbed. We demonstrate\nthat a fully synchronized beamfocusing system achieves a 14 dB gain over\nnon-coherent transmission, consistent with the theoretical 14.9 dB gain for a\n31-element array. Additionally, phase alignment errors below 20{\\deg} result in\nless than 1 dB of gain loss, while errors exceeding 40{\\deg} lead to losses\nover 3 dB. These findings suggest that phase coherency requirements for WPT can\nbe relaxed, and that scaling the number of antennas is a promising strategy for\nimproving power transfer efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2412.11116v1",
    "published": "2024-12-15T08:35:17+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11115v1",
    "title": "On the Ehrenfest theorem and centroids of relativistic particles",
    "authors": [
      "Konstantin Y. Bliokh"
    ],
    "abstract": "We consider relativistic versions of the Ehrenfest relation between the\nexpectation values of the coordinate and momentum of a quantum particle in free\nspace: $d\\langle {\\bf r} \\rangle /dt = \\langle {\\bf p} \\rangle/m$. We find that\nthe simple proportionality between the mean velocity and momentum holds true\nonly for the simplest quadratic dispersion (i.e., dependence of the energy on\nthe momentum). For relativistic dispersion, the mean velocity is generally not\ncollinear with the mean momentum, but velocity of the {\\it energy centroid} is\ndirected along the mean momentum. This is related to the conservation of the\nLorentz-boost momentum and has implications in possible decomposition of the\nmean orbital angular momentum into intrinsic and extrinsic parts. Neglecting\nspin/polarization effects, these properties depend solely on the dispersion\nrelation, and can be applied to any waves, including classical electromagnetic\nor acoustic fields.",
    "pdf_url": "http://arxiv.org/pdf/2412.11115v1",
    "published": "2024-12-15T08:27:56+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11114v1",
    "title": "Three forms of dimension reduction for border-collision bifurcations",
    "authors": [
      "David J. W. Simpson"
    ],
    "abstract": "For dynamical systems that switch between different modes of operation,\nparameter variation can cause periodic solutions to lose or acquire new\nswitching events. When this causes the eigenvalues (stability multipliers)\nassociated with the solution to change discontinuously, we show that if one\neigenvalue remains continuous then all local invariant sets of the\nleading-order approximation to the system occur on a lower dimensional\nmanifold. This allows us to analyse the dynamics with fewer variables, which is\nparticularly helpful when the dynamics is chaotic. We compare this to two other\ncodimension-two scenarios for which dimension reduction can be achieved.",
    "pdf_url": "http://arxiv.org/pdf/2412.11114v1",
    "published": "2024-12-15T08:27:43+00:00",
    "categories": [
      "math.DS",
      "nlin.CD",
      "39A28, 34C45, 37G35"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2501.14744v2",
    "title": "FSTA-SNN:Frequency-based Spatial-Temporal Attention Module for Spiking Neural Networks",
    "authors": [
      "Kairong Yu",
      "Tianqing Zhang",
      "Hongwei Wang",
      "Qi Xu"
    ],
    "abstract": "Spiking Neural Networks (SNNs) are emerging as a promising alternative to\nArtificial Neural Networks (ANNs) due to their inherent energy efficiency.\nOwing to the inherent sparsity in spike generation within SNNs, the in-depth\nanalysis and optimization of intermediate output spikes are often neglected.\nThis oversight significantly restricts the inherent energy efficiency of SNNs\nand diminishes their advantages in spatiotemporal feature extraction, resulting\nin a lack of accuracy and unnecessary energy expenditure. In this work, we\nanalyze the inherent spiking characteristics of SNNs from both temporal and\nspatial perspectives. In terms of spatial analysis, we find that shallow layers\ntend to focus on learning vertical variations, while deeper layers gradually\nlearn horizontal variations of features. Regarding temporal analysis, we\nobserve that there is not a significant difference in feature learning across\ndifferent time steps. This suggests that increasing the time steps has limited\neffect on feature learning. Based on the insights derived from these analyses,\nwe propose a Frequency-based Spatial-Temporal Attention (FSTA) module to\nenhance feature learning in SNNs. This module aims to improve the feature\nlearning capabilities by suppressing redundant spike features.The experimental\nresults indicate that the introduction of the FSTA module significantly reduces\nthe spike firing rate of SNNs, demonstrating superior performance compared to\nstate-of-the-art baselines across multiple datasets.",
    "pdf_url": "http://arxiv.org/pdf/2501.14744v2",
    "published": "2024-12-15T08:23:58+00:00",
    "categories": [
      "cs.NE",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11113v1",
    "title": "Optimal Strategy-proof Mechanisms on Single-crossing Domains",
    "authors": [
      "Mridu Prabal Goswami"
    ],
    "abstract": "We consider an economic environment with one buyer and one seller. For a\nbundle $(t,q)\\in [0,\\infty[\\times [0,1]=\\mathbb{Z}$, $q$ refers to the winning\nprobability of an object, and $t$ denotes the payment that the buyer makes. We\nconsider continuous and monotone preferences on $\\mathbb{Z}$ as the primitives\nof the buyer. These preferences can incorporate both quasilinear and\nnon-quasilinear preferences, and multidimensional pay-off relevant parameters.\nWe define rich single-crossing subsets of this class and characterize\nstrategy-proof mechanisms by using monotonicity of the mechanisms and\ncontinuity of the indirect preference correspondences. We also provide a\ncomputationally tractable optimization program to compute the optimal mechanism\nfor mechanisms with finite range. We do not use revenue equivalence and virtual\nvaluations as tools in our proofs. Our proof techniques bring out the geometric\ninteraction between the single-crossing property and the positions of bundles\n$(t,q)$s in the space $\\mathbb{Z}$. We also provide an extension of our\nanalysis to an $n-$buyer environment, and to the situation where $q$ is a\nqualitative variable.",
    "pdf_url": "http://arxiv.org/pdf/2412.11113v1",
    "published": "2024-12-15T08:23:15+00:00",
    "categories": [
      "cs.GT",
      "econ.TH",
      "54-08",
      "I.2.0"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11112v4",
    "title": "Populating cellular metamaterials on the extrema of attainable elasticity through neuroevolution",
    "authors": [
      "Maohua Yan",
      "Ruicheng Wang",
      "Ke Liu"
    ],
    "abstract": "The trade-offs between different mechanical properties of materials pose\nfundamental challenges in engineering material design, such as balancing\nstiffness versus toughness, weight versus energy-absorbing capacity, and among\nthe various elastic coefficients. Although gradient-based topology optimization\napproaches have been effective in finding specific designs and properties, they\nare not efficient tools for surveying the vast design space of metamaterials,\nand thus unable to reveal the attainable bound of interdependent material\nproperties. Other common methods, such as parametric design or data-driven\napproaches, are limited by either the lack of diversity in geometry or the\ndifficulty to extrapolate from known data, respectively. In this work, we\nformulate the simultaneous exploration of multiple competing material\nproperties as a multi-objective optimization (MOO) problem and employ a\nneuroevolution algorithm to efficiently solve it. The Compositional\nPattern-Producing Networks (CPPNs) is used as the generative model for unit\ncell designs, which provide very compact yet lossless encoding of geometry. A\nmodified Neuroevolution of Augmenting Topologies (NEAT) algorithm is employed\nto evolve the CPPNs such that they create metamaterial designs on the Pareto\nfront of the MOO problem, revealing empirical bounds of different combinations\nof elastic properties. Looking ahead, our method serves as a universal\nframework for the computational discovery of diverse metamaterials across a\nrange of fields, including robotics, biomedicine, thermal engineering, and\nphotonics.",
    "pdf_url": "http://arxiv.org/pdf/2412.11112v4",
    "published": "2024-12-15T08:18:30+00:00",
    "categories": [
      "cs.NE",
      "cs.CE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11111v1",
    "title": "Toward ultimate-efficiency frequency conversion in nonlinear optical microresonators",
    "authors": [
      "Zhi-Yan Wang",
      "Xiao Wu",
      "Xiao Xiong",
      "Chen Yang",
      "Zhengzhong Hao",
      "Qi-Fan Yang",
      "Yaowen Hu",
      "Fang Bo",
      "Qi-Tao Cao",
      "Yun-Feng Xiao"
    ],
    "abstract": "Integrated nonlinear photonics has emerged as a transformative platform,\nenabling nanoscale nonlinear optical processes with significant implications\nfor sensing, computation, and metrology. Achieving efficient nonlinear\nfrequency conversion in optical microresonators is paramount to fully unlocking\nthis potential, yet the absolute conversion efficiency (ACE) of many processes,\nsuch as second-harmonic generation (SHG), remains fundamentally constrained by\ndissipative losses and intrinsic nonlinear effects in the device. In this work,\nwe establish a unified theoretical framework for SHG in microresonators,\nidentifying a decisive factor M that predicts the upper limit of ACE under the\nnonlinear critical coupling (NCC) condition. Using this framework, we fabricate\nintegrated periodically poled lithium niobate microresonators and address the\ndispersive and dissipative suppression to approach the NCC condition. We\nachieve a record-high experimental ACE of 61.3% with milliwatt-level pump\npowers toward the ultimate efficiency, with the potential for even higher\nefficiency as the M factor increases. These results provide a versatile\nparadigm for high-efficiency nonlinear optical devices, offering new\nopportunities for advancements across classical and quantum photonic\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2412.11111v1",
    "published": "2024-12-15T08:16:48+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2412.11110v1",
    "title": "An explicit formula for Larmour's decomposition of hermitian forms",
    "authors": [
      "Amin Soofiani"
    ],
    "abstract": "Let $K$ be a complete discretely valued field whose residue field has\ncharacteristic different from $2$. Let $(D,\\sigma)$ be a $K-$division algebra\nwith involution of the first kind, and $h$ be a $K-$anisotropic\n$\\epsilon$-hermitian form over $(D,\\sigma)$. By a theorem due to Larmour, there\nis a decomposition $h=h_0 \\perp h_1$ such that the elements in a\ndiagonalization of $h_0$ are units, the elements in a diagonalization of $h_1$\nare uniformizers, and $h_0$, $h_1$ are determined uniquely up to $K-$isometry.\nIn this paper, we give an explicit description of the elements in the\ndiagonalization of $h_0$ and $h_1$ in the case of quaternion algebras. Then we\nwill derive explicit formulas for Larmour's isomorphism of Witt groups.",
    "pdf_url": "http://arxiv.org/pdf/2412.11110v1",
    "published": "2024-12-15T08:16:01+00:00",
    "categories": [
      "math.RA",
      "16K20"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11109v1",
    "title": "SpearBot: Leveraging Large Language Models in a Generative-Critique Framework for Spear-Phishing Email Generation",
    "authors": [
      "Qinglin Qi",
      "Yun Luo",
      "Yijia Xu",
      "Wenbo Guo",
      "Yong Fang"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly capable, aiding in tasks such\nas content generation, yet they also pose risks, particularly in generating\nharmful spear-phishing emails. These emails, crafted to entice clicks on\nmalicious URLs, threaten personal information security. This paper proposes an\nadversarial framework, SpearBot, which utilizes LLMs to generate spear-phishing\nemails with various phishing strategies. Through specifically crafted jailbreak\nprompts, SpearBot circumvents security policies and introduces other LLM\ninstances as critics. When a phishing email is identified by the critic,\nSpearBot refines the generated email based on the critique feedback until it\ncan no longer be recognized as phishing, thereby enhancing its deceptive\nquality. To evaluate the effectiveness of SpearBot, we implement various\nmachine-based defenders and assess how well the phishing emails generated could\ndeceive them. Results show these emails often evade detection to a large\nextent, underscoring their deceptive quality. Additionally, human evaluations\nof the emails' readability and deception are conducted through questionnaires,\nconfirming their convincing nature and the significant potential harm of the\ngenerated phishing emails.",
    "pdf_url": "http://arxiv.org/pdf/2412.11109v1",
    "published": "2024-12-15T08:13:12+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11108v1",
    "title": "Plug-and-Play Priors as a Score-Based Method",
    "authors": [
      "Chicago Y. Park",
      "Yuyang Hu",
      "Michael T. McCann",
      "Cristina Garcia-Cardona",
      "Brendt Wohlberg",
      "Ulugbek S. Kamilov"
    ],
    "abstract": "Plug-and-play (PnP) methods are extensively used for solving imaging inverse\nproblems by integrating physical measurement models with pre-trained deep\ndenoisers as priors. Score-based diffusion models (SBMs) have recently emerged\nas a powerful framework for image generation by training deep denoisers to\nrepresent the score of the image prior. While both PnP and SBMs use deep\ndenoisers, the score-based nature of PnP is unexplored in the literature due to\nits distinct origins rooted in proximal optimization. This letter introduces a\nnovel view of PnP as a score-based method, a perspective that enables the\nre-use of powerful SBMs within classical PnP algorithms without retraining. We\npresent a set of mathematical relationships for adapting popular SBMs as priors\nwithin PnP. We show that this approach enables a direct comparison between PnP\nand SBM-based reconstruction methods using the same neural network as the\nprior. Code is available at https://github.com/wustl-cig/score_pnp.",
    "pdf_url": "http://arxiv.org/pdf/2412.11108v1",
    "published": "2024-12-15T08:10:39+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11107v2",
    "title": "Quantum-Corrected Holographic Wilson Loop Expectation Values and Super-Yang-Mills Confinement",
    "authors": [
      "Xiao-Long Liu",
      "Cong-Yuan Yue",
      "Jun Nian",
      "Wenni Zheng"
    ],
    "abstract": "Confinement is a well-known phenomenon in the infrared regime of\n(supersymmetric) Yang-Mills theory. While both experimental observations and\nnumerical simulations have robustly confirmed its existence, the underlying\nphysical mechanism remains elusive. Unraveling the theoretical origin of\nconfinement continues to be a profound and longstanding challenge in both\nphysics and mathematics. Motivated by recent advances in quantum\nJackiw-Teitelboim gravity, we investigate the Wilson loop expectation values in\nthe large-$N$ limit of $\\mathscr{N}=4$ super-Yang-Mills theory at finite\nchemical potential, employing a holographic approach within the background of\nan extremal AdS$_5$ Reissner-Nordstr\\\"om black brane. Our results reveal that\nquantum gravitational fluctuations in the near-horizon region significantly\nmodify the holographic Wilson loop expectation values. These values exhibit an\narea-law behavior, indicative of a confining quark-antiquark potential. Within\nthis framework, our findings suggest that confinement in the super-Yang-Mills\ntheory arises as a consequence of near-horizon quantum gravity fluctuations in\nthe bulk extremal AdS$_5$ black brane geometry.",
    "pdf_url": "http://arxiv.org/pdf/2412.11107v2",
    "published": "2024-12-15T08:10:28+00:00",
    "categories": [
      "hep-th",
      "gr-qc",
      "hep-ph",
      "math-ph",
      "math.MP",
      "nucl-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2412.11106v1",
    "title": "Unpaired Multi-Domain Histopathology Virtual Staining using Dual Path Prompted Inversion",
    "authors": [
      "Bing Xiong",
      "Yue Peng",
      "RanRan Zhang",
      "Fuqiang Chen",
      "JiaYe He",
      "Wenjian Qin"
    ],
    "abstract": "Virtual staining leverages computer-aided techniques to transfer the style of\nhistochemically stained tissue samples to other staining types. In virtual\nstaining of pathological images, maintaining strict structural consistency is\ncrucial, as these images emphasize structural integrity more than natural\nimages. Even slight structural alterations can lead to deviations in diagnostic\nsemantic information. Furthermore, the unpaired characteristic of virtual\nstaining data may compromise the preservation of pathological diagnostic\ncontent. To address these challenges, we propose a dual-path inversion virtual\nstaining method using prompt learning, which optimizes visual prompts to\ncontrol content and style, while preserving complete pathological diagnostic\ncontent. Our proposed inversion technique comprises two key components: (1)\nDual Path Prompted Strategy, we utilize a feature adapter function to generate\nreference images for inversion, providing style templates for input image\ninversion, called Style Target Path. We utilize the inversion of the input\nimage as the Structural Target path, employing visual prompt images to maintain\nstructural consistency in this path while preserving style information from the\nstyle Target path. During the deterministic sampling process, we achieve\ncomplete content-style disentanglement through a plug-and-play embedding visual\nprompt approach. (2) StainPrompt Optimization, where we only optimize the null\nvisual prompt as ``operator'' for dual path inversion, rather than fine-tune\npre-trained model. We optimize null visual prompt for structual and style\ntrajectory around pivotal noise on each timestep, ensuring accurate dual-path\ninversion reconstruction. Extensive evaluations on publicly available\nmulti-domain unpaired staining datasets demonstrate high structural consistency\nand accurate style transfer results.",
    "pdf_url": "http://arxiv.org/pdf/2412.11106v1",
    "published": "2024-12-15T08:09:56+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11105v1",
    "title": "Multi-Graph Co-Training for Capturing User Intent in Session-based Recommendation",
    "authors": [
      "Zhe Yang",
      "Tiantian Liang"
    ],
    "abstract": "Session-based recommendation focuses on predicting the next item a user will\ninteract with based on sequences of anonymous user sessions. A significant\nchallenge in this field is data sparsity due to the typically short-term\ninteractions. Most existing methods rely heavily on users' current\ninteractions, overlooking the wealth of auxiliary information available. To\naddress this, we propose a novel model, the Multi-Graph Co-Training model\n(MGCOT), which leverages not only the current session graph but also similar\nsession graphs and a global item relation graph. This approach allows for a\nmore comprehensive exploration of intrinsic relationships and better captures\nuser intent from multiple views, enabling session representations to complement\neach other. Additionally, MGCOT employs multi-head attention mechanisms to\neffectively capture relevant session intent and uses contrastive learning to\nform accurate and robust session representations. Extensive experiments on\nthree datasets demonstrate that MGCOT significantly enhances the performance of\nsession-based recommendations, particularly on the Diginetica dataset,\nachieving improvements up to 2.00% in P@20 and 10.70% in MRR@20. Resources have\nbeen made publicly available in our GitHub repository\nhttps://github.com/liang-tian-tian/MGCOT.",
    "pdf_url": "http://arxiv.org/pdf/2412.11105v1",
    "published": "2024-12-15T08:08:07+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11104v1",
    "title": "ABC3: Active Bayesian Causal Inference with Cohn Criteria in Randomized Experiments",
    "authors": [
      "Taehun Cha",
      "Donghun Lee"
    ],
    "abstract": "In causal inference, randomized experiment is a de facto method to overcome\nvarious theoretical issues in observational study. However, the experimental\ndesign requires expensive costs, so an efficient experimental design is\nnecessary. We propose ABC3, a Bayesian active learning policy for causal\ninference. We show a policy minimizing an estimation error on conditional\naverage treatment effect is equivalent to minimizing an integrated posterior\nvariance, similar to Cohn criteria \\citep{cohn1994active}. We theoretically\nprove ABC3 also minimizes an imbalance between the treatment and control groups\nand the type 1 error probability. Imbalance-minimizing characteristic is\nespecially notable as several works have emphasized the importance of achieving\nbalance. Through extensive experiments on real-world data sets, ABC3 achieves\nthe highest efficiency, while empirically showing the theoretical results hold.",
    "pdf_url": "http://arxiv.org/pdf/2412.11104v1",
    "published": "2024-12-15T08:00:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11103v2",
    "title": "Counting Minimal Tori In Riemannian Manifolds",
    "authors": [
      "Narges Bagherifard"
    ],
    "abstract": "In this paper, we introduce a function which counts minimal tori in a Riemann\nmanifold $(M, g)$ with $\\mathrm{dim}\\, M \\ge 6$. Moreover, we show that this\ncount function is invariant under perturbations of the metric.",
    "pdf_url": "http://arxiv.org/pdf/2412.11103v2",
    "published": "2024-12-15T07:56:58+00:00",
    "categories": [
      "math.DG",
      "49Q05, 47B36"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11102v3",
    "title": "Empowering LLMs to Understand and Generate Complex Vector Graphics",
    "authors": [
      "Ximing Xing",
      "Juncheng Hu",
      "Guotao Liang",
      "Jing Zhang",
      "Dong Xu",
      "Qian Yu"
    ],
    "abstract": "The unprecedented advancements in Large Language Models (LLMs) have\nprofoundly impacted natural language processing but have yet to fully embrace\nthe realm of scalable vector graphics (SVG) generation. While LLMs encode\npartial knowledge of SVG data from web pages during training, recent findings\nsuggest that semantically ambiguous and tokenized representations within LLMs\nmay result in hallucinations in vector primitive predictions. Additionally, LLM\ntraining typically lacks modeling and understanding of the rendering sequence\nof vector paths, which can lead to occlusion between output vector primitives.\nIn this paper, we present LLM4SVG, an initial yet substantial step toward\nbridging this gap by enabling LLMs to better understand and generate vector\ngraphics. LLM4SVG facilitates a deeper understanding of SVG components through\nlearnable semantic tokens, which precisely encode these tokens and their\ncorresponding properties to generate semantically aligned SVG outputs. Using a\nseries of learnable semantic tokens, a structured dataset for instruction\nfollowing is developed to support comprehension and generation across two\nprimary tasks. Our method introduces a modular architecture to existing large\nlanguage models, integrating semantic tags, vector instruction encoders,\nfine-tuned commands, and powerful LLMs to tightly combine geometric,\nappearance, and language information. To overcome the scarcity of SVG-text\ninstruction data, we developed an automated data generation pipeline that\ncollected our SVGX-SFT Dataset, consisting of high-quality human-designed SVGs\nand 580k SVG instruction following data specifically crafted for LLM training,\nwhich facilitated the adoption of the supervised fine-tuning strategy popular\nin LLM development.",
    "pdf_url": "http://arxiv.org/pdf/2412.11102v3",
    "published": "2024-12-15T07:49:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11101v1",
    "title": "Universality in the tape-peeling trace",
    "authors": [
      "Keisuke Taga",
      "Akihiko Toda",
      "Yoshihiro Yamazaki"
    ],
    "abstract": "Spatiotemporal patterns, which are of interest in statistical physics and\nnonlinear dynamics, form on the tape-peeling trace. Recently, we have proposed\na mathematical model to describe these pattern formation in the tape-peeling\ntrace. In this paper, we further investigate the tape-peeling model from the\nperspective of its universality class. We confirm that our model belongs to the\n1-dimensional directed percolation universality class. Furthermore, the\nexperimental results from a previous study are re-analyzed, and it is suggested\nthat the tape-peeling trace can also be classified within the 1-dimensional\ndirected percolation universality class.",
    "pdf_url": "http://arxiv.org/pdf/2412.11101v1",
    "published": "2024-12-15T07:43:11+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "nlin.PS"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2412.11100v1",
    "title": "DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes",
    "authors": [
      "Jinxiu Liu",
      "Shaoheng Lin",
      "Yinxiao Li",
      "Ming-Hsuan Yang"
    ],
    "abstract": "The increasing demand for immersive AR/VR applications and spatial\nintelligence has heightened the need to generate high-quality scene-level and\n360{\\deg} panoramic video. However, most video diffusion models are constrained\nby limited resolution and aspect ratio, which restricts their applicability to\nscene-level dynamic content synthesis. In this work, we propose the\nDynamicScaler, addressing these challenges by enabling spatially scalable and\npanoramic dynamic scene synthesis that preserves coherence across panoramic\nscenes of arbitrary size. Specifically, we introduce a Offset Shifting\nDenoiser, facilitating efficient, synchronous, and coherent denoising panoramic\ndynamic scenes via a diffusion model with fixed resolution through a seamless\nrotating Window, which ensures seamless boundary transitions and consistency\nacross the entire panoramic space, accommodating varying resolutions and aspect\nratios. Additionally, we employ a Global Motion Guidance mechanism to ensure\nboth local detail fidelity and global motion continuity. Extensive experiments\ndemonstrate our method achieves superior content and motion quality in\npanoramic scene-level video generation, offering a training-free, efficient,\nand scalable solution for immersive dynamic scene creation with constant VRAM\nconsumption regardless of the output video resolution. Our project page is\navailable at \\url{https://dynamic-scaler.pages.dev/}.",
    "pdf_url": "http://arxiv.org/pdf/2412.11100v1",
    "published": "2024-12-15T07:42:26+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11099v1",
    "title": "Quasinormal mode as a foundational framework for all electromagnetic Fano resonances",
    "authors": [
      "Mikhail Bochkarev",
      "Nikolay Solodovchenko",
      "Kirill Samusev",
      "Mikhail Limonov",
      "Tong Wu",
      "Philippe Lalanne"
    ],
    "abstract": "Fano profiles are observed across various fields of wave physics. They emerge\nfrom interference phenomena and are quantified by the asymmetry parameter q. In\noptics, q is usually considered as a phenomenological coefficient obtained by\nfitting experimental or numerical data. In this work, we introduce an ab initio\nMaxwellian approach using quasinormal modes to analytically describe line\nshapes in light scattering problems. We show that the response of each\nindividual quasinormal mode inherently exhibits a Fano profile and derive an\nexplicit analytical formula for the Fano parameter. Experimental and numerical\nvalidations confirm the formula's accuracy across a broad spectrum of\nelectromagnetic systems. The general expression for q opens new possibilities\nfor fine-tuning and optimizing spectral line shapes in electromagnetism.",
    "pdf_url": "http://arxiv.org/pdf/2412.11099v1",
    "published": "2024-12-15T07:37:36+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2412.11098v1",
    "title": "Reliably Learn to Trim Multiparametric Quadratic Programs via Constraint Removal",
    "authors": [
      "Zhinan Hou",
      "Keyou You"
    ],
    "abstract": "In a wide range of applications, we are required to rapidly solve a sequence\nof convex multiparametric quadratic programs (mp-QPs) on resource-limited\nhardwares. This is a nontrivial task and has been an active topic for decades\nin control and optimization communities. Observe that the main computational\ncost of existing solution algorithms lies in addressing many linear inequality\nconstraints, though their majority are redundant and removing them will not\nchange the optimal solution. This work learns from the results of previously\nsolved mp-QP(s), based on which we propose novel methods to reliably trim\n(unsolved) mp-QPs via constraint removal, and the trimmed mp-QPs can be much\ncheaper to solve. Then, we extend to trim mp-QPs of model predictive control\n(MPC) whose parameter vectors are sampled from linear systems. Importantly,\nboth online and offline solved mp-QPs can be utilized to adaptively trim mp-QPs\nin the closed-loop system. We show that the number of linear inequalities in\nthe trimmed mp-QP of MPC decreases to zero in a finite timestep, which also can\nbe reduced by increasing offline computation. Finally, simulations are\nperformed to demonstrate the efficiency of our trimming method in removing\nredundant constraints.",
    "pdf_url": "http://arxiv.org/pdf/2412.11098v1",
    "published": "2024-12-15T07:36:10+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11097v4",
    "title": "Topology and Spectrum in Measurement-Induced Phase Transitions",
    "authors": [
      "Hisanori Oshima",
      "Ken Mochizuki",
      "Ryusuke Hamazaki",
      "Yohei Fuji"
    ],
    "abstract": "Competition among repetitive measurements of noncommuting observables and\nunitary dynamics can give rise to a wide variety of entanglement phases. Here,\nwe propose a general framework based on Lyapunov analysis to characterize\ntopological properties in monitored quantum systems through their spectrum and\nmany-body topological invariants. We illustrate this framework by analyzing\n(1+1)-dimensional monitored circuits for Majorana fermions, which are known to\nexhibit topological and trivial area-law entangled phases as well as a critical\nphase with sub-volume-law entanglement. Through the Lyapunov analysis, we\nidentify the presence (absence) of edge-localized zero modes inside the bulk\ngap in the topological (trivial) phase and a bulk gapless spectrum in the\ncritical phase. Furthermore, by suitably exploiting the fermion parity with\ntwisted measurement outcomes at the boundary, we construct a topological\ninvariant that distinguishes the two area-law phases and dynamically\ncharacterizes the critical phase. Our framework thus provides a general route\nto extend the notion of bulk-edge correspondence to monitored quantum dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2412.11097v4",
    "published": "2024-12-15T07:32:16+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11096v2",
    "title": "Reevaluating the $ψ(4160)$ Resonance Parameter Using $B^+\\to K^+μ^+μ^-$ Data in the Context of Unquenched Charmonium Spectroscopy",
    "authors": [
      "Tian-Cai Peng",
      "Zi-Yue Bai",
      "Jun-Zhang Wang",
      "Xiang Liu"
    ],
    "abstract": "A puzzling phenomenon, where the measured mass of the $\\psi(4160)$ is pushed\nhigher, presents a challenge to current theoretical models of hadron\nspectroscopy. This study suggests that the issue arises from analyses based on\nthe outdated quenched charmonium spectrum. In the past two decades, the\ndiscovery of new hadronic states has emphasized the importance of the\nunquenched effect. Under the unquenched picture, six vector charmonium\nstates-$\\psi(4040)$, $\\psi(4160)$, $\\psi(4220)$, $\\psi(4380)$, $\\psi(4415)$,\nand $\\psi(4500)$-are identified in the $4 \\sim 4.5$ GeV range, contrasting with\nthe three states predicted in the quenched model. We reevaluate the resonance\nparameters of the $\\psi(4160)$ using the di-muon invariant mass spectrum of\n$B^+ \\to K^+ \\mu^+ \\mu^-$ and unquenched charmonium spectroscopy. Our analysis\nfinds the $\\psi(4160)$ mass at $4145.76 \\pm 4.48$ MeV, indicating previous\noverestimations. This conclusion is supported by analyzing $e^+e^- \\to D_s\n\\bar{D}_s^*$. Our findings have significant implications for both hadron\nspectroscopy and search for new physics signals by $R_K$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11096v2",
    "published": "2024-12-15T07:31:09+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11095v1",
    "title": "Dynamic Graph Attention Networks for Travel Time Distribution Prediction in Urban Arterial Roads",
    "authors": [
      "Nooshin Yousefzadeh",
      "Rahul Sengupta",
      "Sanjay Ranka"
    ],
    "abstract": "Effective congestion management along signalized corridors is essential for\nimproving productivity and reducing costs, with arterial travel time serving as\na key performance metric. Traditional approaches, such as Coordinated Signal\nTiming and Adaptive Traffic Control Systems, often lack scalability and\ngeneralizability across diverse urban layouts. We propose Fusion-based Dynamic\nGraph Neural Networks (FDGNN), a structured framework for simultaneous modeling\nof travel time distributions in both directions along arterial corridors. FDGNN\nutilizes attentional graph convolution on dynamic, bidirectional graphs and\nintegrates fusion techniques to capture evolving spatiotemporal traffic\ndynamics. The framework is trained on extensive hours of simulation data and\nutilizes GPU computation to ensure scalability. The results demonstrate that\nour framework can efficiently and accurately model travel time as a normal\ndistribution on arterial roads leveraging a unique dynamic graph representation\nof corridor traffic states. This representation integrates sequential traffic\nsignal timing plans, local driving behaviors, temporal turning movement counts,\nand ingress traffic volumes, even when aggregated over intervals as short as a\nsingle cycle length. The results demonstrate resilience to effective traffic\nvariations, including cycle lengths, green time percentages, traffic density,\nand counterfactual routes. Results further confirm its stability under varying\nconditions at different intersections. This framework supports dynamic signal\ntiming, enhances congestion management, and improves travel time reliability in\nreal-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2412.11095v1",
    "published": "2024-12-15T07:30:01+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11094v2",
    "title": "An Onsager-type Theorem for General 2D Active Scalar Equations",
    "authors": [
      "Xuanxuan Zhao"
    ],
    "abstract": "This paper concerns the Onsager-type problem for general 2-dimensional active\nscalar equations of the form: $\\partial_t \\theta+u\\cdot\\nabla \\theta= 0$, with\n$u=T[\\theta]$ being a divergence-free velocity field and $T$ being a Fourier\nmultiplier operator with symbol $m$. It is shown that if $m$ is a odd and\nhomogeneous symbol of order $\\delta$: $m(\\lambda\\xi)=\\lambda^{\\delta} m(\\xi)$,\nwhere $\\lambda>0, -1\\le\\delta\\le0$, then there exists a nontrivial temporally\ncompact-supported weak solution $\\theta\\in C_t^0 C_x^{\\frac{2\\delta}{3}-}$,\nwhich fails to conserve Hamiltonian. This result is sharp since all weak\nsolutions of class $C_t^0C_x^{\\frac{2\\delta}{3}+}$ will necessarily conserve\nthe Hamiltonian (which is proved by P. Isett and A. Ma in arXiv:2403.08279,\n2024.) and thus resolves the flexible part of the generalized Onsager\nconjecture for general 2D odd active scalar equations. Also, in the appendix,\nanalogous results have been obtained for general 2D and 3D even active scalar\nequations. The proof is achieved by using convex integration scheme at the\nlevel $v=-\\nabla^{\\perp}\\cdot\\theta$ together with a Newton scheme recently\nintroduced by V. Giri and R. O. Radu (2D Onsager conjecture: a Newton-Nash\niteration. Invent. math. (2024).). Moreover, a novel algebraic lemma and sharp\nestimates for some complicated trilinear Fourier multipliers are established to\novercome the difficulties caused by the generality of the equations.",
    "pdf_url": "http://arxiv.org/pdf/2412.11094v2",
    "published": "2024-12-15T07:28:40+00:00",
    "categories": [
      "math.AP",
      "35B99"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11093v1",
    "title": "Decays $τ\\to f_0(π,K) ν_τ$ and $τ\\to 3 πν_τ$ accounting for the contribution of $f_0(500)$",
    "authors": [
      "M. K. Volkov",
      "A. A. Pivovarov",
      "K. Nurlan"
    ],
    "abstract": "In the $U(3) \\times U(3)$ quark NJL model, $\\tau$ lepton decays with the\nproduction of scalar mesons $f_0(\\pi,K])$ and neutrinos are studied, where\n$f_0=f_0(500), f_0(980)$. It is shown that these decays mainly occur via\ncontact channels and channels with axial-vector mesons $a_1$, $K_1(1270)$ and\n$K_1(1400)$. All mesons are considered as quark-antiquark states in this case.\nThe obtained results can be considered as predictions for future experiments.\nThe obtained estimates for the branching fractions of the $\\tau \\to \\pi^-2\\pi^0\n\\nu_\\tau$ decay taking into account the contributions of the $\\rho\\pi$ and\n$f_0(500)\\pi$ states are in satisfactory agreement with experimental data.",
    "pdf_url": "http://arxiv.org/pdf/2412.11093v1",
    "published": "2024-12-15T07:24:39+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11092v1",
    "title": "Thermodynamics and heat transport of quantum spin liquid candidates NaYbS$_2$ and NaYbSe$_2$",
    "authors": [
      "N. Li",
      "M. T. Xie",
      "Q. Huang",
      "Z. W. Zhuo",
      "Z. Zhang",
      "E. S. Choi",
      "Y. Y. Wang",
      "H. Liang",
      "Y. Sun",
      "D. D. Wu",
      "Q. J. Li",
      "H. D. Zhou",
      "G. Chen",
      "X. Zhao",
      "Q. M. Zhang",
      "X. F. Sun"
    ],
    "abstract": "We study the ultralow-temperature thermodynamics and thermal conductivity\n($\\kappa$) of the single-crystal rare-earth chalcogenides NaYbS$_2$ and\nNaYbSe$_2$, which have an ideal triangular lattice of the Yb$^{3+}$ ions and\nhave been proposed to be quantum spin liquid candidates. The magnetic specific\nheat divided by temperature $C_{\\rm{mag}}/T$ is nearly constant at $T <$ 200\nmK, which is indeed the indication of the gapless magnetic excitations with a\nconstant density of states. However, we observe a vanishingly small residual\nterm $\\kappa_0/T$, which points to the absence of mobile fermionic excitations\nin these materials. Both the weak temperature dependence of $\\kappa$ and the\nstrong magnetic-field dependence of $\\kappa$ suggest the significant scattering\nbetween the spinons and phonons, which actually supports the existence of\ngapless or tiny-gapped quantum spin liquid. Moreover, the $\\kappa(B)/\\kappa(0)$\nisotherms show a series of field-induced magnetic transitions for $B \\parallel\na$, confirming the easy-plane anisotropy, which is consistent with the results\nof ac magnetic susceptibility. We expect our results to inspire further\ninterests in the understanding of the spinon-phonon coupling in the spin liquid\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2412.11092v1",
    "published": "2024-12-15T07:23:19+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2412.11091v2",
    "title": "Identification Over Noisy Permutation Channels",
    "authors": [
      "Abhishek Sarkar",
      "Bikash Kumar Dey"
    ],
    "abstract": "We study message identification over the noisy permutation channel. For\ndiscrete memoryless channels (DMCs), the number of identifiable messages grows\ndoubly exponentially, and the maximum second-order exponent is same as the\nShannon capacity of the DMC. We consider a $q$-ary noisy permutation channel\nwhere the transmitted vector is first permuted by a permutation chosen\nuniformly at random, and then passed through a DMC with strictly positive\nentries in its transition probability matrix $U$. In an earlier work, we showed\nthat over $q$-ary noiseless permutation channel, $2^{c_n n^{q-1}}$ messages can\nbe identified if $c_n\\rightarrow 0$, and a strong converse holds for $2^{c_n\nn^{q-1}}$ messages if $c_n\\rightarrow \\infty$. For the $q$-ary noisy\npermutation channel, we show that message sizes growing as $2^{R_n \\left(\n\\frac{n}{\\log n}\\right)^{(r-1)/2}}$, where $r$ be the rank of $U$, are\nidentifiable for any $R_n\\rightarrow 0$. We also prove a strong converse result\nshowing that for any sequence of identification codes with $$2^{\\left(R_n\nn^{(q-1)/2}(\\log n)^{1+\\frac{(q-1)(q-2)}{2}}\\right)},$$ messages, where $R_n\n\\rightarrow \\infty$, the sum of Type-I and Type-II error probabilities\napproaches at least $1$ as $n\\rightarrow \\infty$. Our converse proof uses the\nidea of channel resolvability. We propose a novel deterministic quantization\nscheme for quantization of a distribution over the set of all\ncompositions/types by an $M$-type input distribution when the distortion is\nmeasured on the output distribution in total variation distance. This plays a\nkey role in the converse proof. We have also studied identification with\ndeterministic encoder and decoder, and proved tight achievability, weak\nconverse, and strong converse.",
    "pdf_url": "http://arxiv.org/pdf/2412.11091v2",
    "published": "2024-12-15T07:22:06+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11090v2",
    "title": "Hanprome: Modified Hangeul for Expression of foreign language pronunciation",
    "authors": [
      "Wonchan Kim",
      "Michelle Meehyun Kim"
    ],
    "abstract": "Hangeul was created as a phonetic alphabet and is known to have the best 1:1\ncorrespondence between letters and pronunciation among existing alphabets. In\nthis paper, we examine the possibility of modifying the basic form of Hangeul\nand using it as a kind of phonetic symbol. The core concept of this approach is\nto preserve the basic form of the alphabet, modifying only the shape of a\nstroke rather than the letter itself. To the best of our knowledge, no previous\nattempts in any language have been made to express pronunciations of an\nalphabet different from the original simply by changing the shape of the\nalphabet strokes, and this paper is probably the first attempt in this\ndirection.",
    "pdf_url": "http://arxiv.org/pdf/2412.11090v2",
    "published": "2024-12-15T07:15:58+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11089v2",
    "title": "The Lagrange Problem from the Viewpoint of Toric Geometry",
    "authors": [
      "Xiuting Tang"
    ],
    "abstract": "In this paper, I mainly prove the following results. For every energy value\nbelow the minimum of the first, second and third critical value, each bounded\ncomponent of the regularized energy hypersurface of the Lagrange problem under\nsome ranges of the parameters in the Hamiltonian function arises as the\nboundary of a strictly monotone toric domain, which is dynamically convex as a\ncorollary. For the Euler problem as a special case of the Lagrange problem,\nwhen the energy is less than the negative value of the sum of the two masses of\nthe fixed centers, the bounded component around the first fixed center of the\nregularized energy hypersurface of the Euler problem with two fixed centers\nwith one positive and one negative mass arises as the boundary of a convex\ntoric domain. Together with the result of Gabriella Pinzari, when the energy is\nless than the critical value, the toric domain defined above is concave for the\ncase that the second mass is nonnegative, convex for the case that the mass is\nnonpositive.",
    "pdf_url": "http://arxiv.org/pdf/2412.11089v2",
    "published": "2024-12-15T07:15:34+00:00",
    "categories": [
      "math.AP",
      "math.SG"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11088v1",
    "title": "Seeing the Forest and the Trees: Solving Visual Graph and Tree Based Data Structure Problems using Large Multimodal Models",
    "authors": [
      "Sebastian Gutierrez",
      "Irene Hou",
      "Jihye Lee",
      "Kenneth Angelikas",
      "Owen Man",
      "Sophia Mettille",
      "James Prather",
      "Paul Denny",
      "Stephen MacNeil"
    ],
    "abstract": "Recent advancements in generative AI systems have raised concerns about\nacademic integrity among educators. Beyond excelling at solving programming\nproblems and text-based multiple-choice questions, recent research has also\nfound that large multimodal models (LMMs) can solve Parsons problems based only\non an image. However, such problems are still inherently text-based and rely on\nthe capabilities of the models to convert the images of code blocks to their\ncorresponding text. In this paper, we further investigate the capabilities of\nLMMs to solve graph and tree data structure problems based only on images. To\nachieve this, we computationally construct and evaluate a novel benchmark\ndataset comprising 9,072 samples of diverse graph and tree data structure tasks\nto assess the performance of the GPT-4o, GPT-4v, Gemini 1.5 Pro, Gemini 1.5\nFlash, Gemini 1.0 Pro Vision, and Claude 3 model families. GPT-4o and Gemini\n1.5 Flash performed best on trees and graphs respectively. GPT-4o achieved\n87.6% accuracy on tree samples, while Gemini 1.5 Flash, achieved 56.2% accuracy\non graph samples. Our findings highlight the influence of structural and visual\nvariations on model performance. This research not only introduces an LMM\nbenchmark to facilitate replication and further exploration but also\nunderscores the potential of LMMs in solving complex computing problems, with\nimportant implications for pedagogy and assessment practices.",
    "pdf_url": "http://arxiv.org/pdf/2412.11088v1",
    "published": "2024-12-15T07:15:19+00:00",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.CY",
      "I.2.10; K.3.2"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2412.11087v1",
    "title": "Leveraging Large Vision-Language Model as User Intent-aware Encoder for Composed Image Retrieval",
    "authors": [
      "Zelong Sun",
      "Dong Jing",
      "Guoxing Yang",
      "Nanyi Fei",
      "Zhiwu Lu"
    ],
    "abstract": "Composed Image Retrieval (CIR) aims to retrieve target images from candidate\nset using a hybrid-modality query consisting of a reference image and a\nrelative caption that describes the user intent. Recent studies attempt to\nutilize Vision-Language Pre-training Models (VLPMs) with various fusion\nstrategies for addressing the task.However, these methods typically fail to\nsimultaneously meet two key requirements of CIR: comprehensively extracting\nvisual information and faithfully following the user intent. In this work, we\npropose CIR-LVLM, a novel framework that leverages the large vision-language\nmodel (LVLM) as the powerful user intent-aware encoder to better meet these\nrequirements. Our motivation is to explore the advanced reasoning and\ninstruction-following capabilities of LVLM for accurately understanding and\nresponding the user intent. Furthermore, we design a novel hybrid intent\ninstruction module to provide explicit intent guidance at two levels: (1) The\ntask prompt clarifies the task requirement and assists the model in discerning\nuser intent at the task level. (2) The instance-specific soft prompt, which is\nadaptively selected from the learnable prompt pool, enables the model to better\ncomprehend the user intent at the instance level compared to a universal prompt\nfor all instances. CIR-LVLM achieves state-of-the-art performance across three\nprominent benchmarks with acceptable inference efficiency. We believe this\nstudy provides fundamental insights into CIR-related fields.",
    "pdf_url": "http://arxiv.org/pdf/2412.11087v1",
    "published": "2024-12-15T07:09:02+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2412.15252v1",
    "title": "NER- RoBERTa: Fine-Tuning RoBERTa for Named Entity Recognition (NER) within low-resource languages",
    "authors": [
      "Abdulhady Abas Abdullah",
      "Srwa Hasan Abdulla",
      "Dalia Mohammad Toufiq",
      "Halgurd S. Maghdid",
      "Tarik A. Rashid",
      "Pakshan F. Farho",
      "Shadan Sh. Sabr",
      "Akar H. Taher",
      "Darya S. Hamad",
      "Hadi Veisi",
      "Aras T. Asaad"
    ],
    "abstract": "Nowadays, Natural Language Processing (NLP) is an important tool for most\npeople's daily life routines, ranging from understanding speech, translation,\nnamed entity recognition (NER), and text categorization, to generative text\nmodels such as ChatGPT. Due to the existence of big data and consequently large\ncorpora for widely used languages like English, Spanish, Turkish, Persian, and\nmany more, these applications have been developed accurately. However, the\nKurdish language still requires more corpora and large datasets to be included\nin NLP applications. This is because Kurdish has a rich linguistic structure,\nvaried dialects, and a limited dataset, which poses unique challenges for\nKurdish NLP (KNLP) application development. While several studies have been\nconducted in KNLP for various applications, Kurdish NER (KNER) remains a\nchallenge for many KNLP tasks, including text analysis and classification. In\nthis work, we address this limitation by proposing a methodology for\nfine-tuning the pre-trained RoBERTa model for KNER. To this end, we first\ncreate a Kurdish corpus, followed by designing a modified model architecture\nand implementing the training procedures. To evaluate the trained model, a set\nof experiments is conducted to demonstrate the performance of the KNER model\nusing different tokenization methods and trained models. The experimental\nresults show that fine-tuned RoBERTa with the SentencePiece tokenization method\nsubstantially improves KNER performance, achieving a 12.8% improvement in\nF1-score compared to traditional models, and consequently establishes a new\nbenchmark for KNLP.",
    "pdf_url": "http://arxiv.org/pdf/2412.15252v1",
    "published": "2024-12-15T07:07:17+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11086v2",
    "title": "Solitary wave formation in the compressible Euler equations",
    "authors": [
      "David I. Ketcheson",
      "Giovanni Russo"
    ],
    "abstract": "We study the behavior of perturbations in a compressible one-dimensional\ninviscid gas with an ambient state consisting of constant pressure and\nperiodically-varying density. We show through asymptotic analysis that\nlong-wavelength perturbations approximately obey a system of dispersive\nnonlinear wave equations. Computational experiments demonstrate that solutions\nof the 1D Euler equations agree well with this dispersive model, with solutions\nconsisting mainly of solitary waves. Shock formation seems to be avoided for\nmoderate-amplitude initial data, while shock formation occurs for larger\ninitial data. We investigate the threshold for transition between these\nbehaviors, validating a previously-proposed criterion based on further\ncomputational experiments. These results support the existence of large-time\nnon-breaking solutions to the 1D compressible Euler equations, as hypothesized\nin previous works.",
    "pdf_url": "http://arxiv.org/pdf/2412.11086v2",
    "published": "2024-12-15T07:06:17+00:00",
    "categories": [
      "math.AP",
      "nlin.PS",
      "physics.flu-dyn"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.15685v1",
    "title": "Active Large Language Model-based Knowledge Distillation for Session-based Recommendation",
    "authors": [
      "Yingpeng Du",
      "Zhu Sun",
      "Ziyan Wang",
      "Haoyan Chua",
      "Jie Zhang",
      "Yew-Soon Ong"
    ],
    "abstract": "Large language models (LLMs) provide a promising way for accurate\nsession-based recommendation (SBR), but they demand substantial computational\ntime and memory. Knowledge distillation (KD)-based methods can alleviate these\nissues by transferring the knowledge to a small student, which trains a student\nbased on the predictions of a cumbersome teacher. However, these methods\nencounter difficulties for \\textit{LLM-based KD in SBR}. 1) It is expensive to\nmake LLMs predict for all instances in KD. 2) LLMs may make ineffective\npredictions for some instances in KD, e.g., incorrect predictions for hard\ninstances or similar predictions as existing recommenders for easy instances.\nIn this paper, we propose an active LLM-based KD method in SBR, contributing to\nsustainable AI. To efficiently distill knowledge from LLMs with limited cost,\nwe propose to extract a small proportion of instances predicted by LLMs.\nMeanwhile, for a more effective distillation, we propose an active learning\nstrategy to extract instances that are as effective as possible for KD from a\ntheoretical view. Specifically, we first formulate gains based on potential\neffects (e.g., effective, similar, and incorrect predictions by LLMs) and\ndifficulties (e.g., easy or hard to fit) of instances for KD. Then, we propose\nto maximize the minimal gains of distillation to find the optimal selection\npolicy for active learning, which can largely avoid extracting ineffective\ninstances in KD. Experiments on real-world datasets show that our method\nsignificantly outperforms state-of-the-art methods for SBR.",
    "pdf_url": "http://arxiv.org/pdf/2502.15685v1",
    "published": "2024-12-15T06:56:13+00:00",
    "categories": [
      "cs.IR",
      "cs.LG",
      "H.4"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11085v1",
    "title": "GraphMoRE: Mitigating Topological Heterogeneity via Mixture of Riemannian Experts",
    "authors": [
      "Zihao Guo",
      "Qingyun Sun",
      "Haonan Yuan",
      "Xingcheng Fu",
      "Min Zhou",
      "Yisen Gao",
      "Jianxin Li"
    ],
    "abstract": "Real-world graphs have inherently complex and diverse topological patterns,\nknown as topological heterogeneity. Most existing works learn graph\nrepresentation in a single constant curvature space that is insufficient to\nmatch the complex geometric shapes, resulting in low-quality embeddings with\nhigh distortion. This also constitutes a critical challenge for graph\nfoundation models, which are expected to uniformly handle a wide variety of\ndiverse graph data. Recent studies have indicated that product manifold gains\nthe possibility to address topological heterogeneity. However, the product\nmanifold is still homogeneous, which is inadequate and inflexible for\nrepresenting the mixed heterogeneous topology. In this paper, we propose a\nnovel Graph Mixture of Riemannian Experts (GraphMoRE) framework to effectively\ntackle topological heterogeneity by personalized fine-grained topology geometry\npattern preservation. Specifically, to minimize the embedding distortion, we\npropose a topology-aware gating mechanism to select the optimal embedding space\nfor each node. By fusing the outputs of diverse Riemannian experts with learned\ngating weights, we construct personalized mixed curvature spaces for nodes,\neffectively embedding the graph into a heterogeneous manifold with varying\ncurvatures at different points. Furthermore, to fairly measure pairwise\ndistances between different embedding spaces, we present a concise and\neffective alignment strategy. Extensive experiments on real-world and synthetic\ndatasets demonstrate that our method achieves superior performance with lower\ndistortion, highlighting its potential for modeling complex graphs with\ntopological heterogeneity, and providing a novel architectural perspective for\ngraph foundation models.",
    "pdf_url": "http://arxiv.org/pdf/2412.11085v1",
    "published": "2024-12-15T06:52:40+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11084v1",
    "title": "BarcodeMamba: State Space Models for Biodiversity Analysis",
    "authors": [
      "Tiancheng Gao",
      "Graham W. Taylor"
    ],
    "abstract": "DNA barcodes are crucial in biodiversity analysis for building automatic\nidentification systems that recognize known species and discover unseen\nspecies. Unlike human genome modeling, barcode-based invertebrate\nidentification poses challenges in the vast diversity of species and taxonomic\ncomplexity. Among Transformer-based foundation models, BarcodeBERT excelled in\nspecies-level identification of invertebrates, highlighting the effectiveness\nof self-supervised pretraining on barcode-specific datasets. Recently,\nstructured state space models (SSMs) have emerged, with a time complexity that\nscales sub-quadratically with the context length. SSMs provide an efficient\nparameterization of sequence modeling relative to attention-based\narchitectures. Given the success of Mamba and Mamba-2 in natural language, we\ndesigned BarcodeMamba, a performant and efficient foundation model for DNA\nbarcodes in biodiversity analysis. We conducted a comprehensive ablation study\non the impacts of self-supervised training and tokenization methods, and\ncompared both versions of Mamba layers in terms of expressiveness and their\ncapacity to identify \"unseen\" species held back from training. Our study shows\nthat BarcodeMamba has better performance than BarcodeBERT even when using only\n8.3% as many parameters, and improves accuracy to 99.2% on species-level\naccuracy in linear probing without fine-tuning for \"seen\" species. In our\nscaling study, BarcodeMamba with 63.6% of BarcodeBERT's parameters achieved\n70.2% genus-level accuracy in 1-nearest neighbor (1-NN) probing for unseen\nspecies. The code repository to reproduce our experiments is available at\nhttps://github.com/bioscan-ml/BarcodeMamba.",
    "pdf_url": "http://arxiv.org/pdf/2412.11084v1",
    "published": "2024-12-15T06:52:18+00:00",
    "categories": [
      "cs.LG",
      "q-bio.GN",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11083v1",
    "title": "A Fundamental Theorem on Graph Operators",
    "authors": [
      "Severino V. Gervacio"
    ],
    "abstract": "A graph operator is a function $\\Gamma$ defined on some set of graphs such\nthat whenever two graphs $G$ and $H$ are isomorphic, written $G\\simeq H$, then\n$\\Gamma(G)\\simeq \\Gamma(H)$. For a graph $G$ not in the domain of $\\Gamma$, we\nput $\\Gamma(G)=\\emptyset$. Also, let us define $\\Gamma^0(G)=G$, and for any\nintegr $k\\ge1$, $\\Gamma^k(G)=\\Gamma(\\Gamma^{k-1}(G))$\n  We prove that if $\\Gamma$ is a graph operator, then the sequence $\\langle\n\\Gamma^k(G)\\rangle_{k=0}^\\infty$ has only three possible types of behaviour.\nEither $\\Gamma^k(G)=\\emptyset$ for some integer $k>0$, or\n$\\displaystyle\\lim_{k\\to\\infty}|V(\\Gamma^k(G))|=\\infty$, or there exist\nintegers $m\\ge0$, $p>0$ such that the graphs $\\Gamma^j(G)$ are non-isomorphic\n($0\\le j\\le m)$, and $\\Gamma^{n+p}\\simeq \\Gamma ^n(G)$ for all integers $n\\ge\nm$. We illustrate this using two new graph operators, namely, the path graph\noperator and the claw graph operator.",
    "pdf_url": "http://arxiv.org/pdf/2412.11083v1",
    "published": "2024-12-15T06:49:38+00:00",
    "categories": [
      "math.CO",
      "05C62"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11082v1",
    "title": "EquiFlow: Equivariant Conditional Flow Matching with Optimal Transport for 3D Molecular Conformation Prediction",
    "authors": [
      "Qingwen Tian",
      "Yuxin Xu",
      "Yixuan Yang",
      "Zhen Wang",
      "Ziqi Liu",
      "Pengju Yan",
      "Xiaolin Li"
    ],
    "abstract": "Molecular 3D conformations play a key role in determining how molecules\ninteract with other molecules or protein surfaces. Recent deep learning\nadvancements have improved conformation prediction, but slow training speeds\nand difficulties in utilizing high-degree features limit performance. We\npropose EquiFlow, an equivariant conditional flow matching model with optimal\ntransport. EquiFlow uniquely applies conditional flow matching in molecular 3D\nconformation prediction, leveraging simulation-free training to address slow\ntraining speeds. It uses a modified Equiformer model to encode Cartesian\nmolecular conformations along with their atomic and bond properties into\nhigher-degree embeddings. Additionally, EquiFlow employs an ODE solver,\nproviding faster inference speeds compared to diffusion models with SDEs.\nExperiments on the QM9 dataset show that EquiFlow predicts small molecule\nconformations more accurately than current state-of-the-art models.",
    "pdf_url": "http://arxiv.org/pdf/2412.11082v1",
    "published": "2024-12-15T06:48:22+00:00",
    "categories": [
      "cs.LG",
      "physics.chem-ph",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11081v1",
    "title": "Efficient hybrid-functional-based force and stress calculations for periodic systems with thousands of atoms",
    "authors": [
      "Peize Lin",
      "Yuyang Ji",
      "Lixin He",
      "Xinguo Ren"
    ],
    "abstract": "We present an efficient linear-scaling algorithm for evaluating the\nanalytical force and stress contributions derived from the exact-exchange\nenergy, a key component in hybrid functional calculations. The algorithm,\nworking equally well for molecular and periodic systems, is formulated within\nthe framework of numerical atomic orbital (NAO) basis sets and takes advantage\nof the localized resolution-of-identity (LRI) technique for treating the\ntwo-electron Coulomb repulsion integrals. The linear-scaling behavior is\nrealized by fully exploiting the sparsity of the expansion coefficients\nresulting from the strict locality of the NAOs and the LRI ansatz. Our\nimplementation is massively parallel, and enables efficient structural\nrelaxation based on hybrid density functionals for bulk materials containing\nthousands of atoms. In this work, we will present a detailed description of our\nalgorithm and benchmark the performance of our implementation using\nillustrating examples. By optimizing the structures of the pristine and doped\nhalide perovskite material CsSnI$_3$ with different functionals, we find that\nin the presence of lattice strain, hybrid functionals provide a more accurate\ndescription of the stereochemical expression of the lone pair.",
    "pdf_url": "http://arxiv.org/pdf/2412.11081v1",
    "published": "2024-12-15T06:45:34+00:00",
    "categories": [
      "physics.comp-ph"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11080v1",
    "title": "Deep Spectral Clustering via Joint Spectral Embedding and Kmeans",
    "authors": [
      "Wengang Guo",
      "Wei Ye"
    ],
    "abstract": "Spectral clustering is a popular clustering method. It first maps data into\nthe spectral embedding space and then uses Kmeans to find clusters. However,\nthe two decoupled steps prohibit joint optimization for the optimal solution.\nIn addition, it needs to construct the similarity graph for samples, which\nsuffers from the curse of dimensionality when the data are high-dimensional. To\naddress these two challenges, we introduce \\textbf{D}eep \\textbf{S}pectral\n\\textbf{C}lustering (\\textbf{DSC}), which consists of two main modules: the\nspectral embedding module and the greedy Kmeans module. The former module\nlearns to efficiently embed raw samples into the spectral embedding space using\ndeep neural networks and power iteration. The latter module improves the\ncluster structures of Kmeans on the learned spectral embeddings by a greedy\noptimization strategy, which iteratively reveals the direction of the worst\ncluster structures and optimizes embeddings in this direction. To jointly\noptimize spectral embeddings and clustering, we seamlessly integrate the two\nmodules and optimize them in an end-to-end manner. Experimental results on\nseven real-world datasets demonstrate that DSC achieves state-of-the-art\nclustering performance.",
    "pdf_url": "http://arxiv.org/pdf/2412.11080v1",
    "published": "2024-12-15T06:40:22+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11079v1",
    "title": "MAP-UOT: A Memory-Efficient Approach to Unbalanced Optimal Transport Implementation",
    "authors": [
      "Chengyu Sun",
      "Jinyu Hu",
      "Hong Jiang"
    ],
    "abstract": "Unbalanced optimal transport (UOT) has been widely used as a fundamental tool\nin many application domains, where it often dominates the application running\ntime. While many researchers have proposed various optimizations for UOT, few\nhave attempted to optimize it from a computer architecture's perspective. In\nthis paper, we first study the performance bottlenecks of UOT through a series\nof experiments, which reveals that UOT is heavily memory-bound. Guided by these\nfindings, we propose MAP-UOT, a Memory-efficient APproach to the implementation\nand optimization of UOT on CPU and GPU platforms. Our experimental evaluations\nshow that the proposed strategy consistently and significantly outperforms the\nstate-of-the-art (SOTA) implementations. Specifically, it provides\nsingle-threaded performance improvement over POT/COFFEE by up to 2.9X/2.4X,\nwith an average of 1.9X/1.6X. At the same time, it provides parallelized\nperformance improvement over POT/COFFEE by up to 2.4X/1.9X, with an average of\n2.2X/1.8X, on Intel Core i9-12900K; and over POT by up to 3.5X, with an average\nof 1.6X, on Nvidia GeForce RTX 3090 Ti. MAP-UOT also shows great performance\nimprovement on the Tianhe-1 supercomputer.",
    "pdf_url": "http://arxiv.org/pdf/2412.11079v1",
    "published": "2024-12-15T06:39:25+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11078v1",
    "title": "Global Dynamics of Ordinary Differential Equations: Wall Labelings, Conley Complexes, and Ramp Systems",
    "authors": [
      "Marcio Gameiro",
      "Tomáš Gedeon",
      "Hiroshi Kokubu",
      "Konstantin Mischaikow",
      "Hiroe Oka",
      "Bernardo Rivas",
      "Ewerton Vieira",
      "Daniel Gameiro"
    ],
    "abstract": "We introduce a combinatorial topological framework for characterizing the\nglobal dynamics of ordinary differential equations (ODEs). The approach is\nmotivated by the study of gene regulatory networks, which are often modeled by\nODEs that are not explicitly derived from first principles.\n  The proposed method involves constructing a combinatorial model from a set of\nparameters and then embedding the model into a continuous setting in such a way\nthat the algebraic topological invariants are preserved. In this manuscript, we\nbuild upon the software Dynamic Signatures Generated by Regulatory Networks\n(DSGRN), a software package that is used to explore the dynamics generated by a\nregulatory network. By extending its functionalities, we deduce the global\ndynamical information of the ODE and extract information regarding equilibria,\nperiodic orbits, connecting orbits and bifurcations.\n  We validate our results through algebraic topological tools and analytical\nbounds, and the effectiveness of this framework is demonstrated through several\nexamples and possible future directions.",
    "pdf_url": "http://arxiv.org/pdf/2412.11078v1",
    "published": "2024-12-15T06:32:36+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2412.11077v3",
    "title": "Reason-before-Retrieve: One-Stage Reflective Chain-of-Thoughts for Training-Free Zero-Shot Composed Image Retrieval",
    "authors": [
      "Yuanmin Tang",
      "Xiaoting Qin",
      "Jue Zhang",
      "Jing Yu",
      "Gaopeng Gou",
      "Gang Xiong",
      "Qingwei Ling",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Qi Wu"
    ],
    "abstract": "Composed Image Retrieval (CIR) aims to retrieve target images that closely\nresemble a reference image while integrating user-specified textual\nmodifications, thereby capturing user intent more precisely. Existing\ntraining-free zero-shot CIR (ZS-CIR) methods often employ a two-stage process:\nthey first generate a caption for the reference image and then use Large\nLanguage Models for reasoning to obtain a target description. However, these\nmethods suffer from missing critical visual details and limited reasoning\ncapabilities, leading to suboptimal retrieval performance. To address these\nchallenges, we propose a novel, training-free one-stage method, One-Stage\nReflective Chain-of-Thought Reasoning for ZS-CIR (OSrCIR), which employs\nMultimodal Large Language Models to retain essential visual information in a\nsingle-stage reasoning process, eliminating the information loss seen in\ntwo-stage methods. Our Reflective Chain-of-Thought framework further improves\ninterpretative accuracy by aligning manipulation intent with contextual cues\nfrom reference images. OSrCIR achieves performance gains of 1.80% to 6.44% over\nexisting training-free methods across multiple tasks, setting new\nstate-of-the-art results in ZS-CIR and enhancing its utility in vision-language\napplications. Our code will be available at\nhttps://github.com/Pter61/osrcir2024/.",
    "pdf_url": "http://arxiv.org/pdf/2412.11077v3",
    "published": "2024-12-15T06:22:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11076v3",
    "title": "MoRe: Class Patch Attention Needs Regularization for Weakly Supervised Semantic Segmentation",
    "authors": [
      "Zhiwei Yang",
      "Yucong Meng",
      "Kexue Fu",
      "Shuo Wang",
      "Zhijian Song"
    ],
    "abstract": "Weakly Supervised Semantic Segmentation (WSSS) with image-level labels\ntypically uses Class Activation Maps (CAM) to achieve dense predictions.\nRecently, Vision Transformer (ViT) has provided an alternative to generate\nlocalization maps from class-patch attention. However, due to insufficient\nconstraints on modeling such attention, we observe that the Localization\nAttention Maps (LAM) often struggle with the artifact issue, i.e., patch\nregions with minimal semantic relevance are falsely activated by class tokens.\nIn this work, we propose MoRe to address this issue and further explore the\npotential of LAM. Our findings suggest that imposing additional regularization\non class-patch attention is necessary. To this end, we first view the attention\nas a novel directed graph and propose the Graph Category Representation module\nto implicitly regularize the interaction among class-patch entities. It ensures\nthat class tokens dynamically condense the related patch information and\nsuppress unrelated artifacts at a graph level. Second, motivated by the\nobservation that CAM from classification weights maintains smooth localization\nof objects, we devise the Localization-informed Regularization module to\nexplicitly regularize the class-patch attention. It directly mines the token\nrelations from CAM and further supervises the consistency between class and\npatch tokens in a learnable manner. Extensive experiments are conducted on\nPASCAL VOC and MS COCO, validating that MoRe effectively addresses the artifact\nissue and achieves state-of-the-art performance, surpassing recent single-stage\nand even multi-stage methods. Code is available at\nhttps://github.com/zwyang6/MoRe.",
    "pdf_url": "http://arxiv.org/pdf/2412.11076v3",
    "published": "2024-12-15T06:20:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11075v1",
    "title": "Edge Contrastive Learning: An Augmentation-Free Graph Contrastive Learning Model",
    "authors": [
      "Yujun Li",
      "Hongyuan Zhang",
      "Yuan Yuan"
    ],
    "abstract": "Graph contrastive learning (GCL) aims to learn representations from unlabeled\ngraph data in a self-supervised manner and has developed rapidly in recent\nyears. However, edgelevel contrasts are not well explored by most existing GCL\nmethods. Most studies in GCL only regard edges as auxiliary information while\nupdating node features. One of the primary obstacles of edge-based GCL is the\nheavy computation burden. To tackle this issue, we propose a model that can\nefficiently learn edge features for GCL, namely AugmentationFree Edge\nContrastive Learning (AFECL) to achieve edgeedge contrast. AFECL depends on no\naugmentation consisting of two parts. Firstly, we design a novel edge feature\ngeneration method, where edge features are computed by embedding concatenation\nof their connected nodes. Secondly, an edge contrastive learning scheme is\ndeveloped, where edges connecting the same nodes are defined as positive pairs,\nand other edges are defined as negative pairs. Experimental results show that\ncompared with recent state-of-the-art GCL methods or even some supervised GNNs,\nAFECL achieves SOTA performance on link prediction and semi-supervised node\nclassification of extremely scarce labels. The source code is available at\nhttps://github.com/YujunLi361/AFECL.",
    "pdf_url": "http://arxiv.org/pdf/2412.11075v1",
    "published": "2024-12-15T06:16:01+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11074v3",
    "title": "Adapter-Enhanced Semantic Prompting for Continual Learning",
    "authors": [
      "Baocai Yin",
      "Ji Zhao",
      "Huajie Jiang",
      "Ningning Hou",
      "Yongli Hu",
      "Amin Beheshti",
      "Ming-Hsuan Yang",
      "Yuankai Qi"
    ],
    "abstract": "Continual learning (CL) enables models to adapt to evolving data streams. A\nmajor challenge of CL is catastrophic forgetting, where new knowledge will\noverwrite previously acquired knowledge. Traditional methods usually retain the\npast data for replay or add additional branches in the model to learn new\nknowledge, which has high memory requirements. In this paper, we propose a\nnovel lightweight CL framework, Adapter-Enhanced Semantic Prompting (AESP),\nwhich integrates prompt tuning and adapter techniques. Specifically, we design\nsemantic-guided prompts to enhance the generalization ability of visual\nfeatures and utilize adapters to efficiently fuse the semantic information,\naiming to learn more adaptive features for the continual learning task.\nFurthermore, to choose the right task prompt for feature adaptation, we have\ndeveloped a novel matching mechanism for prompt selection. Extensive\nexperiments on three CL datasets demonstrate that our approach achieves\nfavorable performance across multiple metrics, showing its potential for\nadvancing CL.",
    "pdf_url": "http://arxiv.org/pdf/2412.11074v3",
    "published": "2024-12-15T06:14:55+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11073v1",
    "title": "Ba-ZebraConf: A Three-Dimension Bayesian Framework for Efficient System Troubleshooting",
    "authors": [
      "Deyi Xing",
      "Weicong Chen",
      "Curtis Tatsuoka",
      "Xiaoyi Lu"
    ],
    "abstract": "The proliferation of heterogeneous configurations in distributed systems\npresents significant challenges in ensuring stability and efficiency.\nMisconfigurations, driven by complex parameter interdependencies, can lead to\ncritical failures. Group Testing (GT) has been leveraged to expedite\ntroubleshooting by reducing the number of tests, as demonstrated by methods\nlike ZebraConf. However, ZebraConf's binary-splitting strategy suffers from\nsequential testing, limited handling of parameter interdependencies, and\nsusceptibility to errors such as noise and dilution. We propose Ba-ZebraConf, a\nnovel three-dimensional Bayesian framework that addresses these limitations. It\nintegrates (1) Bayesian Group Testing (BGT), which employs probabilistic\nlattice models and the Bayesian Halving Algorithm (BHA) to dynamically refine\ntesting strategies, prioritizing high-informative parameters and adapting to\nreal-time outcomes. Bayesian optimization tunes hyperparameters, such as pool\nsizes and test thresholds, to maximize testing efficiency. (2) Bayesian\nOptimization (BO) to automate hyperparameter tuning for test efficiency, and\n(3) Bayesian Risk Refinement (BRR) to iteratively capture parameter\ninterdependencies and improve classification accuracy. Ba-ZebraConf adapts to\nnoisy environments, captures parameter interdependencies, and scales\neffectively for large configuration spaces. Experimental results show that\nBa-ZebraConf reduces test counts and execution time by 67% compared to\nZebraConf while achieving 0% false positives and false negatives. These results\nestablish Ba-ZebraConf as a robust and scalable solution for troubleshooting\nheterogeneous distributed systems.",
    "pdf_url": "http://arxiv.org/pdf/2412.11073v1",
    "published": "2024-12-15T06:13:11+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2412.11072v1",
    "title": "Navigating Towards Fairness with Data Selection",
    "authors": [
      "Yixuan Zhang",
      "Zhidong Li",
      "Yang Wang",
      "Fang Chen",
      "Xuhui Fan",
      "Feng Zhou"
    ],
    "abstract": "Machine learning algorithms often struggle to eliminate inherent data biases,\nparticularly those arising from unreliable labels, which poses a significant\nchallenge in ensuring fairness. Existing fairness techniques that address label\nbias typically involve modifying models and intervening in the training\nprocess, but these lack flexibility for large-scale datasets. To address this\nlimitation, we introduce a data selection method designed to efficiently and\nflexibly mitigate label bias, tailored to more practical needs. Our approach\nutilizes a zero-shot predictor as a proxy model that simulates training on a\nclean holdout set. This strategy, supported by peer predictions, ensures the\nfairness of the proxy model and eliminates the need for an additional holdout\nset, which is a common requirement in previous methods. Without altering the\nclassifier's architecture, our modality-agnostic method effectively selects\nappropriate training data and has proven efficient and effective in handling\nlabel bias and improving fairness across diverse datasets in experimental\nevaluations.",
    "pdf_url": "http://arxiv.org/pdf/2412.11072v1",
    "published": "2024-12-15T06:11:05+00:00",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11071v1",
    "title": "A Note on Valid Inequalities for PageRank Optimization with Edge Selection Constraints",
    "authors": [
      "Shang-Ru Yang",
      "Yung-Han Liao",
      "Chih-Ching Chien",
      "Hao-Hsiang Wu"
    ],
    "abstract": "Cs\\'{a}ji, Jungers, and Blondel prove that while a PageRank optimization\nproblem with edge selection constraints is NP-hard, it can be solved optimally\nin polynomial time for the unconstrained case. This theoretical result is\naccompanied by several observations, which we leverage to develop valid\ninequalities in polynomial time for this class of NP-hard problems.",
    "pdf_url": "http://arxiv.org/pdf/2412.11071v1",
    "published": "2024-12-15T06:04:20+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11070v1",
    "title": "HC-LLM: Historical-Constrained Large Language Models for Radiology Report Generation",
    "authors": [
      "Tengfei Liu",
      "Jiapu Wang",
      "Yongli Hu",
      "Mingjie Li",
      "Junfei Yi",
      "Xiaojun Chang",
      "Junbin Gao",
      "Baocai Yin"
    ],
    "abstract": "Radiology report generation (RRG) models typically focus on individual exams,\noften overlooking the integration of historical visual or textual data, which\nis crucial for patient follow-ups. Traditional methods usually struggle with\nlong sequence dependencies when incorporating historical information, but large\nlanguage models (LLMs) excel at in-context learning, making them well-suited\nfor analyzing longitudinal medical data. In light of this, we propose a novel\nHistorical-Constrained Large Language Models (HC-LLM) framework for RRG,\nempowering LLMs with longitudinal report generation capabilities by\nconstraining the consistency and differences between longitudinal images and\ntheir corresponding reports. Specifically, our approach extracts both\ntime-shared and time-specific features from longitudinal chest X-rays and\ndiagnostic reports to capture disease progression. Then, we ensure consistent\nrepresentation by applying intra-modality similarity constraints and aligning\nvarious features across modalities with multimodal contrastive and structural\nconstraints. These combined constraints effectively guide the LLMs in\ngenerating diagnostic reports that accurately reflect the progression of the\ndisease, achieving state-of-the-art results on the Longitudinal-MIMIC dataset.\nNotably, our approach performs well even without historical data during testing\nand can be easily adapted to other multimodal large models, enhancing its\nversatility.",
    "pdf_url": "http://arxiv.org/pdf/2412.11070v1",
    "published": "2024-12-15T06:04:16+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11069v1",
    "title": "On the sum of $Δ_{k}(n)$ in the Piltz divisor problem for $k=3$ and $k=4$",
    "authors": [
      "T. Makoto Minamide",
      "Yoshio Tanigawa",
      "Nigel Watt"
    ],
    "abstract": "Let $\\Delta_{k}(x)$ be the error term in the classical asymptotic formula for\nthe sum $\\sum_{n\\leq x}d_{k}(n)$, where $d_{k}(n)$ is the number of ways $n$\ncan be written as a product of $k$ factors. We study the analytic properties of\nthe Dirichlet series $\\sum_{n=1}^{\\infty}\\Delta_{k}(n)n^{-s}$ and use Perron's\nformula to estimate the sums $\\sum_{n\\leq x}\\Delta_{3}(n)$ and $\\sum_{n\\leq\nx}\\Delta_{4}(n)$ for large $x>0$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11069v1",
    "published": "2024-12-15T05:58:08+00:00",
    "categories": [
      "math.NT",
      "11N37, 11M06"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11067v3",
    "title": "CFSynthesis: Controllable and Free-view 3D Human Video Synthesis",
    "authors": [
      "Liyuan Cui",
      "Xiaogang Xu",
      "Wenqi Dong",
      "Zesong Yang",
      "Hujun Bao",
      "Zhaopeng Cui"
    ],
    "abstract": "Human video synthesis aims to create lifelike characters in various\nenvironments, with wide applications in VR, storytelling, and content creation.\nWhile 2D diffusion-based methods have made significant progress, they struggle\nto generalize to complex 3D poses and varying scene backgrounds. To address\nthese limitations, we introduce CFSynthesis, a novel framework for generating\nhigh-quality human videos with customizable attributes, including identity,\nmotion, and scene configurations. Our method leverages a texture-SMPL-based\nrepresentation to ensure consistent and stable character appearances across\nfree viewpoints. Additionally, we introduce a novel foreground-background\nseparation strategy that effectively decomposes the scene as foreground and\nbackground, enabling seamless integration of user-defined backgrounds.\nExperimental results on multiple datasets show that CFSynthesis not only\nachieves state-of-the-art performance in complex human animations but also\nadapts effectively to 3D motions in free-view and user-specified scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2412.11067v3",
    "published": "2024-12-15T05:57:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11068v1",
    "title": "RecSys Arena: Pair-wise Recommender System Evaluation with Large Language Models",
    "authors": [
      "Zhuo Wu",
      "Qinglin Jia",
      "Chuhan Wu",
      "Zhaocheng Du",
      "Shuai Wang",
      "Zan Wang",
      "Zhenhua Dong"
    ],
    "abstract": "Evaluating the quality of recommender systems is critical for algorithm\ndesign and optimization. Most evaluation methods are computed based on offline\nmetrics for quick algorithm evolution, since online experiments are usually\nrisky and time-consuming. However, offline evaluation usually cannot fully\nreflect users' preference for the outcome of different recommendation\nalgorithms, and the results may not be consistent with online A/B test.\nMoreover, many offline metrics such as AUC do not offer sufficient information\nfor comparing the subtle differences between two competitive recommender\nsystems in different aspects, which may lead to substantial performance\ndifferences in long-term online serving. Fortunately, due to the strong\ncommonsense knowledge and role-play capability of large language models (LLMs),\nit is possible to obtain simulated user feedback on offline recommendation\nresults. Motivated by the idea of LLM Chatbot Arena, in this paper we present\nthe idea of RecSys Arena, where the recommendation results given by two\ndifferent recommender systems in each session are evaluated by an LLM judger to\nobtain fine-grained evaluation feedback. More specifically, for each sample we\nuse LLM to generate a user profile description based on user behavior history\nor off-the-shelf profile features, which is used to guide LLM to play the role\nof this user and evaluate the relative preference for two recommendation\nresults generated by different models. Through extensive experiments on two\nrecommendation datasets in different scenarios, we demonstrate that many\ndifferent LLMs not only provide general evaluation results that are highly\nconsistent with canonical offline metrics, but also provide rich insight in\nmany subjective aspects. Moreover, it can better distinguish different\nalgorithms with comparable performance in terms of AUC and nDCG.",
    "pdf_url": "http://arxiv.org/pdf/2412.11068v1",
    "published": "2024-12-15T05:57:36+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11066v1",
    "title": "Learning Robust and Privacy-Preserving Representations via Information Theory",
    "authors": [
      "Binghui Zhang",
      "Sayedeh Leila Noorbakhsh",
      "Yun Dong",
      "Yuan Hong",
      "Binghui Wang"
    ],
    "abstract": "Machine learning models are vulnerable to both security attacks (e.g.,\nadversarial examples) and privacy attacks (e.g., private attribute inference).\nWe take the first step to mitigate both the security and privacy attacks, and\nmaintain task utility as well. Particularly, we propose an\ninformation-theoretic framework to achieve the goals through the lens of\nrepresentation learning, i.e., learning representations that are robust to both\nadversarial examples and attribute inference adversaries. We also derive novel\ntheoretical results under our framework, e.g., the inherent trade-off between\nadversarial robustness/utility and attribute privacy, and guaranteed attribute\nprivacy leakage against attribute inference adversaries.",
    "pdf_url": "http://arxiv.org/pdf/2412.11066v1",
    "published": "2024-12-15T05:51:48+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11065v1",
    "title": "Representation learning of dynamic networks",
    "authors": [
      "Haixu Wang",
      "Jiguo Cao",
      "Jian Pei"
    ],
    "abstract": "This study presents a novel representation learning model tailored for\ndynamic networks, which describes the continuously evolving relationships among\nindividuals within a population. The problem is encapsulated in the dimension\nreduction topic of functional data analysis. With dynamic networks represented\nas matrix-valued functions, our objective is to map this functional data into a\nset of vector-valued functions in a lower-dimensional learning space. This\nspace, defined as a metric functional space, allows for the calculation of\nnorms and inner products. By constructing this learning space, we address (i)\nattribute learning, (ii) community detection, and (iii) link prediction and\nrecovery of individual nodes in the dynamic network. Our model also\naccommodates asymmetric low-dimensional representations, enabling the separate\nstudy of nodes' regulatory and receiving roles. Crucially, the learning method\naccounts for the time-dependency of networks, ensuring that representations are\ncontinuous over time. The functional learning space we define naturally spans\nthe time frame of the dynamic networks, facilitating both the inference of\nnetwork links at specific time points and the reconstruction of the entire\nnetwork structure without direct observation. We validated our approach through\nsimulation studies and real-world applications. In simulations, we compared our\nmethods link prediction performance to existing approaches under various data\ncorruption scenarios. For real-world applications, we examined a dynamic social\nnetwork replicated across six ant populations, demonstrating that our\nlow-dimensional learning space effectively captures interactions, roles of\nindividual ants, and the social evolution of the network. Our findings align\nwith existing knowledge of ant colony behavior.",
    "pdf_url": "http://arxiv.org/pdf/2412.11065v1",
    "published": "2024-12-15T05:45:20+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2412.11064v2",
    "title": "Planet formation theory: an overview",
    "authors": [
      "Philip J. Armitage"
    ],
    "abstract": "The standard model for planet formation is a bottom-up process in which the\norigin of rocky and gaseous planets can be traced back to the collision of\nmicron-sized dust grains within the gas-rich environment of protoplanetary\ndisks. Key milestones along the way include disk formation, grain growth,\nplanetesimal formation, core growth, gas accretion, and planetary system\nevolution. I provide an introductory overview of planet formation, emphasizing\nthe main ideas and reviewing current theoretical understanding. Many of the\nphases of planet formation have a well-developed physical understanding, though\nthe complexity of the problem means that few can be quantitatively modeled with\ncomplete confidence. Transformative advances in disk imaging provide the first\ndirect information on the initial conditions for planet formation, while\nexoplanet data has motivated new formation models that are faster, more\nefficient, and lead to a more diverse set of architectures than their Solar\nSystem inspired forebears. Much remains to be learned, and I close with a\npersonal, incomplete list, of open problems.",
    "pdf_url": "http://arxiv.org/pdf/2412.11064v2",
    "published": "2024-12-15T05:42:30+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11063v1",
    "title": "LAW: Legal Agentic Workflows for Custody and Fund Services Contracts",
    "authors": [
      "William Watson",
      "Nicole Cho",
      "Nishan Srishankar",
      "Zhen Zeng",
      "Lucas Cecchi",
      "Daniel Scott",
      "Suchetha Siddagangappa",
      "Rachneet Kaur",
      "Tucker Balch",
      "Manuela Veloso"
    ],
    "abstract": "Legal contracts in the custody and fund services domain govern critical\naspects such as key provider responsibilities, fee schedules, and\nindemnification rights. However, it is challenging for an off-the-shelf Large\nLanguage Model (LLM) to ingest these contracts due to the lengthy unstructured\nstreams of text, limited LLM context windows, and complex legal jargon. To\naddress these challenges, we introduce LAW (Legal Agentic Workflows for Custody\nand Fund Services Contracts). LAW features a modular design that responds to\nuser queries by orchestrating a suite of domain-specific tools and text agents.\nOur experiments demonstrate that LAW, by integrating multiple specialized\nagents and tools, significantly outperforms the baseline. LAW excels\nparticularly in complex tasks such as calculating a contract's termination\ndate, surpassing the baseline by 92.9% points. Furthermore, LAW offers a\ncost-effective alternative to traditional fine-tuned legal LLMs by leveraging\nreusable, domain-specific tools.",
    "pdf_url": "http://arxiv.org/pdf/2412.11063v1",
    "published": "2024-12-15T05:40:57+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2412.11062v2",
    "title": "Fifty years of the Erdős similarity conjecture",
    "authors": [
      "Yeonwook Jung",
      "Chun-Kit Lai",
      "Yuveshen Mooroogen"
    ],
    "abstract": "Erd\\H{o}s similarity conjecture was proposed by P. Erd\\H{o}s in 1974. The\nconjecture remains open for exponentially decaying sequences as well as Cantor\nsets that have both Newhouse thickness and Hausdorff dimension zero. In this\narticle, written after 50 years of the conjecture being proposed, we review\nprogress on some new variants of the original problem: namely, the bi-Lipschitz\nvariant, the topological variant, and a variant ``in the large''. These\nproblems were recently studied by the authors and their collaborators. Each of\nthem offers new perspectives on the original conjecture.",
    "pdf_url": "http://arxiv.org/pdf/2412.11062v2",
    "published": "2024-12-15T05:35:15+00:00",
    "categories": [
      "math.CA",
      "math.MG"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11061v1",
    "title": "Classification Drives Geographic Bias in Street Scene Segmentation",
    "authors": [
      "Rahul Nair",
      "Gabriel Tseng",
      "Esther Rolf",
      "Bhanu Tokas",
      "Hannah Kerner"
    ],
    "abstract": "Previous studies showed that image datasets lacking geographic diversity can\nlead to biased performance in models trained on them. While earlier work\nstudied general-purpose image datasets (e.g., ImageNet) and simple tasks like\nimage recognition, we investigated geo-biases in real-world driving datasets on\na more complex task: instance segmentation. We examined if instance\nsegmentation models trained on European driving scenes (Eurocentric models) are\ngeo-biased. Consistent with previous work, we found that Eurocentric models\nwere geo-biased. Interestingly, we found that geo-biases came from\nclassification errors rather than localization errors, with classification\nerrors alone contributing 10-90% of the geo-biases in segmentation and 19-88%\nof the geo-biases in detection. This showed that while classification is\ngeo-biased, localization (including detection and segmentation) is\ngeographically robust. Our findings show that in region-specific models (e.g.,\nEurocentric models), geo-biases from classification errors can be significantly\nmitigated by using coarser classes (e.g., grouping car, bus, and truck as\n4-wheeler).",
    "pdf_url": "http://arxiv.org/pdf/2412.11061v1",
    "published": "2024-12-15T05:33:10+00:00",
    "categories": [
      "cs.CV",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11060v1",
    "title": "Making Bias Amplification in Balanced Datasets Directional and Interpretable",
    "authors": [
      "Bhanu Tokas",
      "Rahul Nair",
      "Hannah Kerner"
    ],
    "abstract": "Most of the ML datasets we use today are biased. When we train models on\nthese biased datasets, they often not only learn dataset biases but can also\namplify them -- a phenomenon known as bias amplification. Several\nco-occurrence-based metrics have been proposed to measure bias amplification\nbetween a protected attribute A (e.g., gender) and a task T (e.g., cooking).\nHowever, these metrics fail to measure biases when A is balanced with T. To\nmeasure bias amplification in balanced datasets, recent work proposed a\npredictability-based metric called leakage amplification. However, leakage\namplification cannot identify the direction in which biases are amplified. In\nthis work, we propose a new predictability-based metric called directional\npredictability amplification (DPA). DPA measures directional bias\namplification, even for balanced datasets. Unlike leakage amplification, DPA is\neasier to interpret and less sensitive to attacker models (a hyperparameter in\npredictability-based metrics). Our experiments on tabular and image datasets\nshow that DPA is an effective metric for measuring directional bias\namplification. The code will be available soon.",
    "pdf_url": "http://arxiv.org/pdf/2412.11060v1",
    "published": "2024-12-15T05:32:54+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11059v2",
    "title": "On the specific solutions of reduced biquaternion equality constrained least squares problem and their relative forward error bound",
    "authors": [
      "Sk. Safique Ahmad",
      "Neha Bhadala"
    ],
    "abstract": "This study focuses on addressing the challenge of solving the reduced\nbiquaternion equality constrained least squares (RBLSE) problem. We develop\nalgebraic techniques to derive real and complex solutions for the RBLSE problem\nby utilizing the real and complex forms of reduced biquaternion matrices.\nFurthermore, we propose algorithms and provide a detailed analysis of their\ncomputational complexity for finding special solutions to the RBLSE problem. A\nperturbation analysis is conducted, establishing an upper bound for the\nrelative forward error of these solutions. This analysis ensures the accuracy\nand stability of the solutions in the presence of data perturbations, which is\ncrucial for practical applications where errors arising from input inaccuracies\ncan cause deviations between computed and true solutions. Numerical examples\nare presented to validate the proposed algorithms, demonstrate their\neffectiveness, and verify the accuracy of the established upper bound for the\nrelative forward errors. These findings lay the groundwork for exploring\napplications in 3D and 4D algebra such as robotics, signal, and image\nprocessing, expanding their impact on practical and emerging domains.",
    "pdf_url": "http://arxiv.org/pdf/2412.11059v2",
    "published": "2024-12-15T05:32:39+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11058v1",
    "title": "SHMT: Self-supervised Hierarchical Makeup Transfer via Latent Diffusion Models",
    "authors": [
      "Zhaoyang Sun",
      "Shengwu Xiong",
      "Yaxiong Chen",
      "Fei Du",
      "Weihua Chen",
      "Fan Wang",
      "Yi Rong"
    ],
    "abstract": "This paper studies the challenging task of makeup transfer, which aims to\napply diverse makeup styles precisely and naturally to a given facial image.\nDue to the absence of paired data, current methods typically synthesize\nsub-optimal pseudo ground truths to guide the model training, resulting in low\nmakeup fidelity. Additionally, different makeup styles generally have varying\neffects on the person face, but existing methods struggle to deal with this\ndiversity. To address these issues, we propose a novel Self-supervised\nHierarchical Makeup Transfer (SHMT) method via latent diffusion models.\nFollowing a \"decoupling-and-reconstruction\" paradigm, SHMT works in a\nself-supervised manner, freeing itself from the misguidance of imprecise\npseudo-paired data. Furthermore, to accommodate a variety of makeup styles,\nhierarchical texture details are decomposed via a Laplacian pyramid and\nselectively introduced to the content representation. Finally, we design a\nnovel Iterative Dual Alignment (IDA) module that dynamically adjusts the\ninjection condition of the diffusion model, allowing the alignment errors\ncaused by the domain gap between content and makeup representations to be\ncorrected. Extensive quantitative and qualitative analyses demonstrate the\neffectiveness of our method. Our code is available at\n\\url{https://github.com/Snowfallingplum/SHMT}.",
    "pdf_url": "http://arxiv.org/pdf/2412.11058v1",
    "published": "2024-12-15T05:29:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11057v1",
    "title": "Set-Valued Sensitivity Analysis of Deep Neural Networks",
    "authors": [
      "Xin Wang",
      "Feilong Wang",
      "Xuegang Ban"
    ],
    "abstract": "This paper proposes a sensitivity analysis framework based on set valued\nmapping for deep neural networks (DNN) to understand and compute how the\nsolutions (model weights) of DNN respond to perturbations in the training data.\nAs a DNN may not exhibit a unique solution (minima) and the algorithm of\nsolving a DNN may lead to different solutions with minor perturbations to input\ndata, we focus on the sensitivity of the solution set of DNN, instead of\nstudying a single solution. In particular, we are interested in the expansion\nand contraction of the set in response to data perturbations. If the change of\nsolution set can be bounded by the extent of the data perturbation, the model\nis said to exhibit the Lipschitz like property. This \"set-to-set\" analysis\napproach provides a deeper understanding of the robustness and reliability of\nDNNs during training. Our framework incorporates both isolated and non-isolated\nminima, and critically, does not require the assumption that the Hessian of\nloss function is non-singular. By developing set-level metrics such as distance\nbetween sets, convergence of sets, derivatives of set-valued mapping, and\nstability across the solution set, we prove that the solution set of the Fully\nConnected Neural Network holds Lipschitz-like properties. For general neural\nnetworks (e.g., Resnet), we introduce a graphical-derivative-based method to\nestimate the new solution set following data perturbation without retraining.",
    "pdf_url": "http://arxiv.org/pdf/2412.11057v1",
    "published": "2024-12-15T05:22:38+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11056v1",
    "title": "Overview of TREC 2024 Medical Video Question Answering (MedVidQA) Track",
    "authors": [
      "Deepak Gupta",
      "Dina Demner-Fushman"
    ],
    "abstract": "One of the key goals of artificial intelligence (AI) is the development of a\nmultimodal system that facilitates communication with the visual world (image\nand video) using a natural language query. Earlier works on medical question\nanswering primarily focused on textual and visual (image) modalities, which may\nbe inefficient in answering questions requiring demonstration. In recent years,\nsignificant progress has been achieved due to the introduction of large-scale\nlanguage-vision datasets and the development of efficient deep neural\ntechniques that bridge the gap between language and visual understanding.\nImprovements have been made in numerous vision-and-language tasks, such as\nvisual captioning visual question answering, and natural language video\nlocalization. Most of the existing work on language vision focused on creating\ndatasets and developing solutions for open-domain applications. We believe\nmedical videos may provide the best possible answers to many first aid, medical\nemergency, and medical education questions. With increasing interest in AI to\nsupport clinical decision-making and improve patient engagement, there is a\nneed to explore such challenges and develop efficient algorithms for medical\nlanguage-video understanding and generation. Toward this, we introduced new\ntasks to foster research toward designing systems that can understand medical\nvideos to provide visual answers to natural language questions, and are\nequipped with multimodal capability to generate instruction steps from the\nmedical video. These tasks have the potential to support the development of\nsophisticated downstream applications that can benefit the public and medical\nprofessionals.",
    "pdf_url": "http://arxiv.org/pdf/2412.11056v1",
    "published": "2024-12-15T05:18:01+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11055v1",
    "title": "Constructing Psuedo-$τ$-fine Precompact Groups",
    "authors": [
      "Dekui Peng",
      "Gao Zhang"
    ],
    "abstract": "Let $\\tau$ be an uncountable cardinal. The notion of a \\emph{$\\tau$-fine}\ntopological group was introduced in 2021. More recently, H. Zhang et al.\ngeneralized this concept by defining pseudo-$\\tau$-fine topological groups to\nstudy certain factorization properties of continuous functions on topological\ngroups. It is known that $\\tau$-fineness cannot coexist with precompactness in\ntopological groups with uncountable character. In this paper, we investigate\nthis problem further. We prove that, in topological groups with uncountable\npseudocharacter, precompactness can coexist with pseudo-$\\tau$-fineness for\nsome bounded $\\tau$ but pseudocompactness can never.",
    "pdf_url": "http://arxiv.org/pdf/2412.11055v1",
    "published": "2024-12-15T05:17:19+00:00",
    "categories": [
      "math.GN",
      "math.GR"
    ],
    "primary_category": "math.GN"
  },
  {
    "id": "http://arxiv.org/abs/2412.11054v2",
    "title": "The $N_2V$ color center: a ubiquitous visible and near-infrared-II quantum emitter in nitrogen-doped diamond",
    "authors": [
      "Brett C. Johnson",
      "Mitchell O. de Vries",
      "Alexander J. Healey",
      "Marco Capelli",
      "Anjay Manian",
      "Giannis Thalassinos",
      "Amanda N. Abraham",
      "Harini Hapuarachchi",
      "Tingpeng Luo",
      "Vadym Mochalin",
      "Jan Jeske",
      "Jared H. Cole",
      "Salvy Russo",
      "Brant C. Gibson",
      "Alastair Stacey",
      "Philipp Reineck"
    ],
    "abstract": "Photoluminescent defects in diamond, like the nitrogen-vacancy (NV) color\ncenter, are at the forefront of emerging optical quantum technologies. Most\nemit in the visible and near-infrared spectral region below 1000 nm (NIR-I),\nlimiting their applications in photonics, fiber communications, and biology.\nHere, we show that the nitrogen-vacancy-nitrogen ($N_2V$) center, which emits\nin the visible and near-infrared-II (NIR-II, 1000-1700 nm), is ubiquitous in\nas-synthesized and processed nitrogen-doped diamond from bulk samples to\nnanoparticles. We demonstrate that $N_2V$ is also present in commercially\navailable state-of-the-art NV diamond sensing chips made via chemical vapor\ndeposition (CVD). In high-pressure high-temperature (HPHT) diamonds, the\nphotoluminescence (PL) intensity of both $N_2V$ charge states, $N_2V^0$ in the\nvisible and $N_2V^-$ in the NIR-II, increases with increasing substitutional\nnitrogen concentration. We determine the PL lifetime of $N_2V^-$ to be 0.3 ns\nand compare a quantum optical and density functional theory model of the\n$N_2V^-$ with experimental PL spectra. Finally, we show that detonation\nnanodiamonds (DND) show stable PL in the NIR-II, which we attribute to the\n$N_2V$ color center, and use this NIR-II PL to image DNDs inside skin cells.\nOur results will contribute to the scientific and technological exploration and\ndevelopment of the $N_2V$ color center and inspire more research into its\neffect on other color centers in diamond.",
    "pdf_url": "http://arxiv.org/pdf/2412.11054v2",
    "published": "2024-12-15T05:17:02+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2412.11053v1",
    "title": "NITRO: LLM Inference on Intel Laptop NPUs",
    "authors": [
      "Anthony Fei",
      "Mohamed S. Abdelfattah"
    ],
    "abstract": "Large Language Models (LLMs) have become essential tools in natural language\nprocessing, finding large usage in chatbots such as ChatGPT and Gemini, and are\na central area of research. A particular area of interest includes designing\nhardware specialized for these AI applications, with one such example being the\nneural processing unit (NPU). In 2023, Intel released the Intel Core Ultra\nprocessor with codename Meteor Lake, featuring a CPU, GPU, and NPU\nsystem-on-chip. However, official software support for the NPU through Intel's\nOpenVINO framework is limited to static model inference. The dynamic nature of\nautoregressive token generation in LLMs is therefore not supported out of the\nbox. To address this shortcoming, we present NITRO (NPU Inference for\nTransformers Optimization), a Python-based framework built on top of OpenVINO\nto support text and chat generation on NPUs. In this paper, we discuss in\ndetail the key modifications made to the transformer architecture to enable\ninference, some performance benchmarks, and future steps towards improving the\npackage. The code repository for NITRO can be found here:\nhttps://github.com/abdelfattah-lab/nitro.",
    "pdf_url": "http://arxiv.org/pdf/2412.11053v1",
    "published": "2024-12-15T05:15:54+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11052v1",
    "title": "Electromagnetic Interactions of Massive Higher-Spin Fields in 3D via Chiral Theory",
    "authors": [
      "Alexey Sharapov",
      "David Shcherbatov",
      "Evgeny Skvortsov"
    ],
    "abstract": "We address the issue of electromagnetic interaction for massive higher-spin\nfields in $3d$ Minkowski space. We show that consistent field equations can be\nobtained through the dimensional reduction of the higher-spin extension of\nself-dual Yang-Mills theory, which itself is a truncation of chiral higher-spin\ngravity in four dimensions. The resulting electromagnetic field satisfies the\nBogomolny equation, and the interaction is non-minimal with the gyromagnetic\nratio given by $g=1/s$, where $s$ is the spin. As a by-product, we obtain a new\nLagrangian for free massive higher-spin fields in $3d$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11052v1",
    "published": "2024-12-15T05:13:07+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2412.15251v2",
    "title": "AgentPS: Agentic Process Supervision for Content Moderation with Multimodal LLMs",
    "authors": [
      "Mingchao Liu",
      "Yu Sun",
      "Ruixiao Sun",
      "Xin Dong",
      "Xiang Shen",
      "Hongyu Xiong"
    ],
    "abstract": "The advanced processing and reasoning capabilities of multimodal large\nlanguage models (MLLMs) have driven substantial progress in vision-language\n(VL) understanding tasks. However, while effective for tasks governed by\nstraightforward logic, MLLMs often struggle with reasoning complex,\ndetail-intensive logical structures. To address this limitation, we introduce\nAgentPS, a novel framework that integrates Agentic Process Supervision into\nMLLMs by sequentially reasoning over ancillary questions during fine-tuning.\nAgentPS achieves substantial improvements over baseline MLLMs on both public\nbenchmarks and proprietary datasets. Notably, we show that using MLLM-generated\nancillary labels in place of human annotations yields only minimal performance\ndegradation, highlighting the method's scalability. These results establish\nAgentPS as a scalable and effective solution for complex multimodal\nclassification in large-scale industrial applications.",
    "pdf_url": "http://arxiv.org/pdf/2412.15251v2",
    "published": "2024-12-15T04:58:00+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11051v1",
    "title": "DisCo-DSO: Coupling Discrete and Continuous Optimization for Efficient Generative Design in Hybrid Spaces",
    "authors": [
      "Jacob F. Pettit",
      "Chak Shing Lee",
      "Jiachen Yang",
      "Alex Ho",
      "Daniel Faissol",
      "Brenden Petersen",
      "Mikel Landajuela"
    ],
    "abstract": "We consider the challenge of black-box optimization within hybrid\ndiscrete-continuous and variable-length spaces, a problem that arises in\nvarious applications, such as decision tree learning and symbolic regression.\nWe propose DisCo-DSO (Discrete-Continuous Deep Symbolic Optimization), a novel\napproach that uses a generative model to learn a joint distribution over\ndiscrete and continuous design variables to sample new hybrid designs. In\ncontrast to standard decoupled approaches, in which the discrete and continuous\nvariables are optimized separately, our joint optimization approach uses fewer\nobjective function evaluations, is robust against non-differentiable\nobjectives, and learns from prior samples to guide the search, leading to\nsignificant improvement in performance and sample efficiency. Our experiments\non a diverse set of optimization tasks demonstrate that the advantages of\nDisCo-DSO become increasingly evident as the complexity of the problem\nincreases. In particular, we illustrate DisCo-DSO's superiority over the\nstate-of-the-art methods for interpretable reinforcement learning with decision\ntrees.",
    "pdf_url": "http://arxiv.org/pdf/2412.11051v1",
    "published": "2024-12-15T04:51:54+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11050v3",
    "title": "RAC3: Retrieval-Augmented Corner Case Comprehension for Autonomous Driving with Vision-Language Models",
    "authors": [
      "Yujin Wang",
      "Quanfeng Liu",
      "Jiaqi Fan",
      "Jinlong Hong",
      "Hongqing Chu",
      "Mengjian Tian",
      "Bingzhao Gao",
      "Hong Chen"
    ],
    "abstract": "Understanding and addressing corner cases is essential for ensuring the\nsafety and reliability of autonomous driving systems. Vision-language models\n(VLMs) play a crucial role in enhancing scenario comprehension, yet they face\nsignificant challenges, such as hallucination and insufficient real-world\ngrounding, which compromise their performance in critical driving scenarios. In\nthis work, RAC3, a novel framework designed to enhance the performance of VLMs\nin corner case comprehension, is proposed. RAC3 integrates a frequency-spatial\nfusion (FSF) image encoder, a cross-modal alignment training method for\nembedding models with hard and semi-hard negative mining, and a fast querying\nand retrieval pipeline based on K-Means clustering and hierarchical navigable\nsmall world (HNSW) indexing. A multimodal chain-of-thought (CoT) prompting\nstrategy to guide analogical reasoning and reduce hallucinations during\ninference is introduced. Moreover, an update mechanism is integrated into RAC3\nto ensure continual learning within the framework. Extensive experiments on the\nCODA and nuScenes datasets demonstrate that RAC3 significantly improves corner\ncase comprehension across multiple downstream tasks. Compared to prior\nstate-of-the-art methods, RAC3 achieves the highest final score of 74.46 on the\nCODA-LM benchmark and shows consistent performance gains when integrated with\nend-to-end frameworks like DriveLM. These results demonstrate the effectiveness\nof retrieval-augmented strategies and cross-modal alignment for safer and more\ninterpretable autonomous driving.",
    "pdf_url": "http://arxiv.org/pdf/2412.11050v3",
    "published": "2024-12-15T04:51:30+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11049v2",
    "title": "Distributed Facility Location Games with Candidate Locations",
    "authors": [
      "Feiyue Sun"
    ],
    "abstract": "We study the distributed facility location games with candidate locations,\nwhere agents on a line are partitioned into groups. Both desirable and\nobnoxious facility location settings are discussed. In distributed location\nproblems, distortion can serve as a standard for quantifying performance,\nmeasuring the degree of difference between the actual location plan and the\nideal location plan. For the desirable setting, under the max of sum cost\nobjective, we give a strategyproof distributed mechanism with $5$-distortion,\nand prove that no strategyproof mechanism can have a distortion better than\n$\\sqrt{2}+1$. Under the sum of max cost objective, we give a strategyproof\ndistributed mechanism with $5$-distortion, and prove that no strategyproof\nmechanism can have a distortion better than $\\frac{\\sqrt{5}+1}{2}$. Under the\nmax of max cost, we get a strategyproof distributed mechanism with\n$3$-distortion, and prove that no strategyproof mechanism can have a distortion\nbetter than $\\frac{\\sqrt{5}+1}{2}$. For the obnoxious setting, under three\nsocial objectives, we present that there is no strategyproof mechanism with\nbounded distortion in the case of discrete candidate locations, and no group\nstrategyproof mechanism with bounded distortion in the case of continuous\ncandidate locations.",
    "pdf_url": "http://arxiv.org/pdf/2412.11049v2",
    "published": "2024-12-15T04:34:38+00:00",
    "categories": [
      "cs.GT",
      "math.OC"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11048v3",
    "title": "Non-simple abelian varieties in a family: arithmetic approaches",
    "authors": [
      "Yu Fu"
    ],
    "abstract": "Inspired by the work of Ellenberg, Elsholtz, Hall, and Kowalski, we\ninvestigate how the property of the generic fiber of a one-parameter family of\nabelian varieties being geometrically simple extends to other fibers. In\n\\cite{EEHK09}, the authors studied a special case involving specific\none-parameter families of Jacobians of curves using analytic methods. We\ngeneralize their results, particularly Theorem B, to all families of abelian\nvarieties with big geometric monodromy, employing an arithmetic approach. Our\nmethod applies Heath-Brown-type bounds on certain covers with level structures\nand optimizes the covers to derive the desired results.",
    "pdf_url": "http://arxiv.org/pdf/2412.11048v3",
    "published": "2024-12-15T04:27:38+00:00",
    "categories": [
      "math.NT",
      "14G05, 11G05, 11G50"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2412.19819v2",
    "title": "ChipAlign: Instruction Alignment in Large Language Models for Chip Design via Geodesic Interpolation",
    "authors": [
      "Chenhui Deng",
      "Yunsheng Bai",
      "Haoxing Ren"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have expanded their\napplication across various domains, including chip design, where domain-adapted\nchip models like ChipNeMo have emerged. However, these models often struggle\nwith instruction alignment, a crucial capability for LLMs that involves\nfollowing explicit human directives. This limitation impedes the practical\napplication of chip LLMs, including serving as assistant chatbots for hardware\ndesign engineers. In this work, we introduce ChipAlign, a novel approach that\nutilizes a training-free model merging strategy, combining the strengths of a\ngeneral instruction-aligned LLM with a chip-specific LLM. By considering the\nunderlying manifold in the weight space, ChipAlign employs geodesic\ninterpolation to effectively fuse the weights of input LLMs, producing a merged\nmodel that inherits strong instruction alignment and chip expertise from the\nrespective instruction and chip LLMs. Our results demonstrate that ChipAlign\nsignificantly enhances instruction-following capabilities of existing chip\nLLMs, achieving up to a 26.6% improvement on the IFEval benchmark, while\nmaintaining comparable expertise in the chip domain. This improvement in\ninstruction alignment also translates to notable gains in instruction-involved\nQA tasks, delivering performance enhancements of 3.9% on the OpenROAD QA\nbenchmark and 8.25% on production-level chip QA benchmarks, surpassing\nstate-of-the-art baselines.",
    "pdf_url": "http://arxiv.org/pdf/2412.19819v2",
    "published": "2024-12-15T04:21:24+00:00",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11047v1",
    "title": "Deployment Pipeline from Rockpool to Xylo for Edge Computing",
    "authors": [
      "Peng Zhou",
      "Dylan R. Muir"
    ],
    "abstract": "Deploying Spiking Neural Networks (SNNs) on the Xylo neuromorphic chip via\nthe Rockpool framework represents a significant advancement in achieving\nultra-low-power consumption and high computational efficiency for edge\napplications. This paper details a novel deployment pipeline, emphasizing the\nintegration of Rockpool's capabilities with Xylo's architecture, and evaluates\nthe system's performance in terms of energy efficiency and accuracy. The unique\nadvantages of the Xylo chip, including its digital spiking architecture and\nevent-driven processing model, are highlighted to demonstrate its suitability\nfor real-time, power-sensitive applications.",
    "pdf_url": "http://arxiv.org/pdf/2412.11047v1",
    "published": "2024-12-15T04:19:10+00:00",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2412.11046v1",
    "title": "Managing Project Teams in an Online Class of 1000+ Students",
    "authors": [
      "Nazanin Tabatabaei Anaraki",
      "Taneisha Ng",
      "Gaurav Verma",
      "Yu Fu",
      "Martin O'Connell",
      "Matthew Hull",
      "Susanta Routray",
      "Max Mahdi Roozbahani",
      "Duen Horng Chau"
    ],
    "abstract": "Team projects in Computer Science (CS) help students build collaboration\nskills, apply theory, and prepare for real-world software development. Online\nclasses present unique opportunities to transform the accessibility of CS\neducation at scale. Still, the geographical distribution of students and staff\nadds complexity to forming effective teams, providing consistent feedback, and\nfacilitating peer interactions. We discuss our approach of managing,\nevaluating, and providing constructive feedback to over 200 project teams,\ncomprising 1000+ graduate students distributed globally, two professors, and\n25+ teaching assistants. We deployed and iteratively refined this approach over\n10 years while offering the Data and Visual Analytics course (CSE 6242) at\nGeorgia Institute of Technology. Our approach and insights can help others\nstriving to make CS education accessible, especially in online and large-scale\nsettings.",
    "pdf_url": "http://arxiv.org/pdf/2412.11046v1",
    "published": "2024-12-15T04:16:32+00:00",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2412.11045v2",
    "title": "Facial Surgery Preview Based on the Orthognathic Treatment Prediction",
    "authors": [
      "Huijun Han",
      "Congyi Zhang",
      "Lifeng Zhu",
      "Pradeep Singh",
      "Richard Tai Chiu Hsung",
      "Yiu Yan Leung",
      "Taku Komura",
      "Wenping Wang",
      "Min Gu"
    ],
    "abstract": "Orthognathic surgery consultation is essential to help patients understand\nthe changes to their facial appearance after surgery. However, current\nvisualization methods are often inefficient and inaccurate due to limited pre-\nand post-treatment data and the complexity of the treatment. To overcome these\nchallenges, this study aims to develop a fully automated pipeline that\ngenerates accurate and efficient 3D previews of postsurgical facial appearances\nfor patients with orthognathic treatment without requiring additional medical\nimages. The study introduces novel aesthetic losses, such as mouth-convexity\nand asymmetry losses, to improve the accuracy of facial surgery prediction.\nAdditionally, it proposes a specialized parametric model for 3D reconstruction\nof the patient, medical-related losses to guide latent code prediction network\noptimization, and a data augmentation scheme to address insufficient data. The\nstudy additionally employs FLAME, a parametric model, to enhance the quality of\nfacial appearance previews by extracting facial latent codes and establishing\ndense correspondences between pre- and post-surgery geometries. Quantitative\ncomparisons showed the algorithm's effectiveness, and qualitative results\nhighlighted accurate facial contour and detail predictions. A user study\nconfirmed that doctors and the public could not distinguish between machine\nlearning predictions and actual postoperative results. This study aims to offer\na practical, effective solution for orthognathic surgery consultations,\nbenefiting doctors and patients.",
    "pdf_url": "http://arxiv.org/pdf/2412.11045v2",
    "published": "2024-12-15T04:06:39+00:00",
    "categories": [
      "cs.CV",
      "cs.HC",
      "68U99"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11044v1",
    "title": "Understanding and Mitigating Memorization in Diffusion Models for Tabular Data",
    "authors": [
      "Zhengyu Fang",
      "Zhimeng Jiang",
      "Huiyuan Chen",
      "Xiao Li",
      "Jing Li"
    ],
    "abstract": "Tabular data generation has attracted significant research interest in recent\nyears, with the tabular diffusion models greatly improving the quality of\nsynthetic data. However, while memorization, where models inadvertently\nreplicate exact or near-identical training data, has been thoroughly\ninvestigated in image and text generation, its effects on tabular data remain\nlargely unexplored. In this paper, we conduct the first comprehensive\ninvestigation of memorization phenomena in diffusion models for tabular data.\nOur empirical analysis reveals that memorization appears in tabular diffusion\nmodels and increases with larger training epochs. We further examine the\ninfluence of factors such as dataset sizes, feature dimensions, and different\ndiffusion models on memorization. Additionally, we provide a theoretical\nexplanation for why memorization occurs in tabular diffusion models. To address\nthis issue, we propose TabCutMix, a simple yet effective data augmentation\ntechnique that exchanges randomly selected feature segments between random\nsame-class training sample pairs. Building upon this, we introduce\nTabCutMixPlus, an enhanced method that clusters features based on feature\ncorrelations and ensures that features within the same cluster are exchanged\ntogether during augmentation. This clustering mechanism mitigates\nout-of-distribution (OOD) generation issues by maintaining feature coherence.\nExperimental results across various datasets and diffusion models demonstrate\nthat TabCutMix effectively mitigates memorization while maintaining\nhigh-quality data generation.",
    "pdf_url": "http://arxiv.org/pdf/2412.11044v1",
    "published": "2024-12-15T04:04:37+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11043v1",
    "title": "Semantic Steganography: A Framework for Robust and High-Capacity Information Hiding using Large Language Models",
    "authors": [
      "Minhao Bai",
      "Jinshuai Yang",
      "Kaiyi Pang",
      "Yongfeng Huang",
      "Yue Gao"
    ],
    "abstract": "In the era of Large Language Models (LLMs), generative linguistic\nsteganography has become a prevalent technique for hiding information within\nmodel-generated texts. However, traditional steganography methods struggle to\neffectively align steganographic texts with original model-generated texts due\nto the lower entropy of the predicted probability distribution of LLMs. This\nresults in a decrease in embedding capacity and poses challenges for decoding\nstegos in real-world communication channels. To address these challenges, we\npropose a semantic steganography framework based on LLMs, which construct a\nsemantic space and map secret messages onto this space using ontology-entity\ntrees. This framework offers robustness and reliability for transmission in\ncomplex channels, as well as resistance to text rendering and word blocking.\nAdditionally, the stegos generated by our framework are indistinguishable from\nthe covers and achieve a higher embedding capacity compared to state-of-the-art\nsteganography methods, while producing higher quality stegos.",
    "pdf_url": "http://arxiv.org/pdf/2412.11043v1",
    "published": "2024-12-15T04:04:23+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2412.11042v1",
    "title": "A Closed-Form Nonlinear Data Assimilation Algorithm for Multi-Layer Flow Fields",
    "authors": [
      "Zhongrui Wang",
      "Nan Chen",
      "Di Qi"
    ],
    "abstract": "State estimation in multi-layer turbulent flow fields with only a single\nlayer of partial observation remains a challenging yet practically important\ntask. Applications include inferring the state of the deep ocean by exploiting\nsurface observations. Directly implementing an ensemble Kalman filter based on\nthe full forecast model is usually expensive. One widely used method in\npractice projects the information of the observed layer to other layers via\nlinear regression. However, when nonlinearity in the highly turbulent flow\nfield becomes dominant, the regression solution will suffer from large\nuncertainty errors. In this paper, we develop a multi-step nonlinear data\nassimilation method. A sequence of nonlinear assimilation steps is applied from\nlayer to layer recurrently. Fundamentally different from the traditional linear\nregression approaches, a conditional Gaussian nonlinear system is adopted as\nthe approximate forecast model to characterize the nonlinear dependence between\nadjacent layers. The estimated posterior is a Gaussian mixture, which can be\nhighly non-Gaussian. Therefore, the multi-step nonlinear data assimilation\nmethod can capture strongly turbulent features, especially intermittency and\nextreme events, and better quantify the inherent uncertainty. Another notable\nadvantage of the multi-step data assimilation method is that the posterior\ndistribution can be solved using closed-form formulae under the conditional\nGaussian framework. Applications to the two-layer quasi-geostrophic system with\nLagrangian data assimilation show that the multi-step method outperforms the\none-step method with linear stochastic flow models, especially as the tracer\nnumber and ensemble size increase.",
    "pdf_url": "http://arxiv.org/pdf/2412.11042v1",
    "published": "2024-12-15T04:01:06+00:00",
    "categories": [
      "physics.flu-dyn",
      "math.DS"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2412.11041v3",
    "title": "Separate the Wheat from the Chaff: A Post-Hoc Approach to Safety Re-Alignment for Fine-Tuned Language Models",
    "authors": [
      "Di Wu",
      "Xin Lu",
      "Yanyan Zhao",
      "Bing Qin"
    ],
    "abstract": "Although large language models (LLMs) achieve effective safety alignment at\nthe time of release, they still face various safety challenges. A key issue is\nthat fine-tuning often compromises the safety alignment of LLMs. To address\nthis issue, we propose a method named IRR (Identify, Remove, and Recalibrate\nfor Safety Realignment) that performs safety realignment for LLMs. The core of\nIRR is to identify and remove unsafe delta parameters from the fine-tuned\nmodels, while recalibrating the retained ones. We evaluate the effectiveness of\nIRR across various datasets, including both full fine-tuning and LoRA methods.\nOur results demonstrate that IRR significantly enhances the safety performance\nof fine-tuned models on safety benchmarks, such as harmful queries and\njailbreak attacks, while maintaining their performance on downstream tasks. The\nsource code is available at: https://anonymous.4open.science/r/IRR-BD4F.",
    "pdf_url": "http://arxiv.org/pdf/2412.11041v3",
    "published": "2024-12-15T03:58:38+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11040v1",
    "title": "Amplitude analysis and branching fraction measurement of the Cabibbo-favored decay $D^+ \\to K^-π^+π^+π^0$",
    "authors": [
      "BESIII Collaboration",
      "M. Ablikim",
      "M. N. Achasov",
      "P. Adlarson",
      "O. Afedulidis",
      "X. C. Ai",
      "R. Aliberti",
      "A. Amoroso",
      "Y. Bai",
      "O. Bakina",
      "I. Balossino",
      "Y. Ban",
      "H. -R. Bao",
      "V. Batozskaya",
      "K. Begzsuren",
      "N. Berger",
      "M. Berlowski",
      "M. Bertani",
      "D. Bettoni",
      "F. Bianchi",
      "E. Bianco",
      "A. Bortone",
      "I. Boyko",
      "R. A. Briere",
      "A. Brueggemann",
      "H. Cai",
      "X. Cai",
      "A. Calcaterra",
      "G. F. Cao",
      "N. Cao",
      "S. A. Cetin",
      "X. Y. Chai",
      "J. F. Chang",
      "G. R. Che",
      "Y. Z. Che",
      "G. Chelkov",
      "C. Chen",
      "C. H. Chen",
      "Chao Chen",
      "G. Chen",
      "H. S. Chen",
      "H. Y. Chen",
      "M. L. Chen",
      "S. J. Chen",
      "S. L. Chen",
      "S. M. Chen",
      "T. Chen",
      "X. R. Chen",
      "X. T. Chen",
      "Y. B. Chen",
      "Y. Q. Chen",
      "Z. J. Chen",
      "S. K. Choi",
      "G. Cibinetto",
      "F. Cossio",
      "J. J. Cui",
      "H. L. Dai",
      "J. P. Dai",
      "A. Dbeyssi",
      "R. E. de Boer",
      "D. Dedovich",
      "C. Q. Deng",
      "Z. Y. Deng",
      "A. Denig",
      "I. Denysenko",
      "M. Destefanis",
      "F. De Mori",
      "B. Ding",
      "X. X. Ding",
      "Y. Ding",
      "Y. Ding",
      "J. Dong",
      "L. Y. Dong",
      "M. Y. Dong",
      "X. Dong",
      "M. C. Du",
      "S. X. Du",
      "Y. Y. Duan",
      "Z. H. Duan",
      "P. Egorov",
      "G. F. Fan",
      "J. J. Fan",
      "Y. H. Fan",
      "J. Fang",
      "J. Fang",
      "S. S. Fang",
      "W. X. Fang",
      "Y. Fang",
      "Y. Q. Fang",
      "R. Farinelli",
      "L. Fava",
      "F. Feldbauer",
      "G. Felici",
      "C. Q. Feng",
      "J. H. Feng",
      "Y. T. Feng",
      "M. Fritsch",
      "C. D. Fu",
      "J. L. Fu",
      "Y. W. Fu",
      "H. Gao",
      "X. B. Gao",
      "Y. N. Gao",
      "Y. N. Gao",
      "Yang Gao",
      "S. Garbolino",
      "I. Garzia",
      "P. T. Ge",
      "Z. W. Ge",
      "C. Geng",
      "E. M. Gersabeck",
      "A. Gilman",
      "K. Goetzen",
      "L. Gong",
      "W. X. Gong",
      "W. Gradl",
      "S. Gramigna",
      "M. Greco",
      "M. H. Gu",
      "Y. T. Gu",
      "C. Y. Guan",
      "A. Q. Guo",
      "L. B. Guo",
      "M. J. Guo",
      "R. P. Guo",
      "Y. P. Guo",
      "A. Guskov",
      "J. Gutierrez",
      "K. L. Han",
      "T. T. Han",
      "F. Hanisch",
      "X. Q. Hao",
      "F. A. Harris",
      "K. K. He",
      "K. L. He",
      "F. H. Heinsius",
      "C. H. Heinz",
      "Y. K. Heng",
      "C. Herold",
      "T. Holtmann",
      "P. C. Hong",
      "G. Y. Hou",
      "X. T. Hou",
      "Y. R. Hou",
      "Z. L. Hou",
      "B. Y. Hu",
      "H. M. Hu",
      "J. F. Hu",
      "Q. P. Hu",
      "S. L. Hu",
      "T. Hu",
      "Y. Hu",
      "G. S. Huang",
      "K. X. Huang",
      "L. Q. Huang",
      "P. Huang",
      "X. T. Huang",
      "Y. P. Huang",
      "Y. S. Huang",
      "T. Hussain",
      "F. Hölzken",
      "N. Hüsken",
      "N. in der Wiesche",
      "J. Jackson",
      "S. Janchiv",
      "Q. Ji",
      "Q. P. Ji",
      "W. Ji",
      "X. B. Ji",
      "X. L. Ji",
      "Y. Y. Ji",
      "X. Q. Jia",
      "Z. K. Jia",
      "D. Jiang",
      "H. B. Jiang",
      "P. C. Jiang",
      "S. S. Jiang",
      "T. J. Jiang",
      "X. S. Jiang",
      "Y. Jiang",
      "J. B. Jiao",
      "J. K. Jiao",
      "Z. Jiao",
      "S. Jin",
      "Y. Jin",
      "M. Q. Jing",
      "X. M. Jing",
      "T. Johansson",
      "S. Kabana",
      "N. Kalantar-Nayestanaki",
      "X. L. Kang",
      "X. S. Kang",
      "M. Kavatsyuk",
      "B. C. Ke",
      "V. Khachatryan",
      "A. Khoukaz",
      "R. Kiuchi",
      "O. B. Kolcu",
      "B. Kopf",
      "M. Kuessner",
      "X. Kui",
      "N. Kumar",
      "A. Kupsc",
      "W. Kühn",
      "W. N. Lan",
      "T. T. Lei",
      "Z. H. Lei",
      "M. Lellmann",
      "T. Lenz",
      "C. Li",
      "C. Li",
      "C. H. Li",
      "Cheng Li",
      "D. M. Li",
      "F. Li",
      "G. Li",
      "H. B. Li",
      "H. J. Li",
      "H. N. Li",
      "Hui Li",
      "J. R. Li",
      "J. S. Li",
      "K. Li",
      "K. L. Li",
      "L. J. Li",
      "L. K. Li",
      "Lei Li",
      "M. H. Li",
      "P. L. Li",
      "P. R. Li",
      "Q. M. Li",
      "Q. X. Li",
      "R. Li",
      "T. Li",
      "T. Y. Li",
      "W. D. Li",
      "W. G. Li",
      "X. Li",
      "X. H. Li",
      "X. L. Li",
      "X. Y. Li",
      "X. Z. Li",
      "Y. Li",
      "Y. G. Li",
      "Z. J. Li",
      "Z. Y. Li",
      "C. Liang",
      "H. Liang",
      "H. Liang",
      "Y. F. Liang",
      "Y. T. Liang",
      "G. R. Liao",
      "Y. P. Liao",
      "J. Libby",
      "A. Limphirat",
      "C. C. Lin",
      "C. X. Lin",
      "D. X. Lin",
      "T. Lin",
      "B. J. Liu",
      "B. X. Liu",
      "C. Liu",
      "C. X. Liu",
      "F. Liu",
      "F. H. Liu",
      "Feng Liu",
      "G. M. Liu",
      "H. Liu",
      "H. B. Liu",
      "H. H. Liu",
      "H. M. Liu",
      "Huihui Liu",
      "J. B. Liu",
      "J. Y. Liu",
      "K. Liu",
      "K. Y. Liu",
      "Ke Liu",
      "L. Liu",
      "L. C. Liu",
      "Lu Liu",
      "M. H. Liu",
      "P. L. Liu",
      "Q. Liu",
      "S. B. Liu",
      "T. Liu",
      "W. K. Liu",
      "W. M. Liu",
      "X. Liu",
      "X. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. B. Liu",
      "Z. A. Liu",
      "Z. D. Liu",
      "Z. Q. Liu",
      "X. C. Lou",
      "F. X. Lu",
      "H. J. Lu",
      "J. G. Lu",
      "Y. Lu",
      "Y. P. Lu",
      "Z. H. Lu",
      "C. L. Luo",
      "J. R. Luo",
      "M. X. Luo",
      "T. Luo",
      "X. L. Luo",
      "X. R. Lyu",
      "Y. F. Lyu",
      "F. C. Ma",
      "H. Ma",
      "H. L. Ma",
      "J. L. Ma",
      "L. L. Ma",
      "L. R. Ma",
      "M. M. Ma",
      "Q. M. Ma",
      "R. Q. Ma",
      "R. Y. Ma",
      "T. Ma",
      "X. T. Ma",
      "X. Y. Ma",
      "Y. M. Ma",
      "F. E. Maas",
      "I. MacKay",
      "M. Maggiora",
      "S. Malde",
      "Y. J. Mao",
      "Z. P. Mao",
      "S. Marcello",
      "Y. H. Meng",
      "Z. X. Meng",
      "J. G. Messchendorp",
      "G. Mezzadri",
      "H. Miao",
      "T. J. Min",
      "R. E. Mitchell",
      "X. H. Mo",
      "B. Moses",
      "N. Yu. Muchnoi",
      "J. Muskalla",
      "Y. Nefedov",
      "F. Nerling",
      "L. S. Nie",
      "I. B. Nikolaev",
      "Z. Ning",
      "S. Nisar",
      "Q. L. Niu",
      "W. D. Niu",
      "Y. Niu",
      "S. L. Olsen",
      "Q. Ouyang",
      "S. Pacetti",
      "X. Pan",
      "Y. Pan",
      "A. Pathak",
      "Y. P. Pei",
      "M. Pelizaeus",
      "H. P. Peng",
      "Y. Y. Peng",
      "K. Peters",
      "J. L. Ping",
      "R. G. Ping",
      "S. Plura",
      "V. Prasad",
      "F. Z. Qi",
      "H. Qi",
      "H. R. Qi",
      "M. Qi",
      "S. Qian",
      "W. B. Qian",
      "C. F. Qiao",
      "J. H. Qiao",
      "J. J. Qin",
      "L. Q. Qin",
      "L. Y. Qin",
      "X. P. Qin",
      "X. S. Qin",
      "Z. H. Qin",
      "J. F. Qiu",
      "Z. H. Qu",
      "C. F. Redmer",
      "K. J. Ren",
      "A. Rivetti",
      "M. Rolo",
      "G. Rong",
      "Ch. Rosner",
      "M. Q. Ruan",
      "S. N. Ruan",
      "N. Salone",
      "A. Sarantsev",
      "Y. Schelhaas",
      "K. Schoenning",
      "M. Scodeggio",
      "K. Y. Shan",
      "W. Shan",
      "X. Y. Shan",
      "Z. J. Shang",
      "J. F. Shangguan",
      "L. G. Shao",
      "M. Shao",
      "C. P. Shen",
      "H. F. Shen",
      "W. H. Shen",
      "X. Y. Shen",
      "B. A. Shi",
      "H. Shi",
      "J. L. Shi",
      "J. Y. Shi",
      "S. Y. Shi",
      "X. Shi",
      "J. J. Song",
      "T. Z. Song",
      "W. M. Song",
      "Y. J. Song",
      "Y. X. Song",
      "S. Sosio",
      "S. Spataro",
      "F. Stieler",
      "S. S Su",
      "Y. J. Su",
      "G. B. Sun",
      "G. X. Sun",
      "H. Sun",
      "H. K. Sun",
      "J. F. Sun",
      "K. Sun",
      "L. Sun",
      "S. S. Sun",
      "T. Sun",
      "Y. J. Sun",
      "Y. Z. Sun",
      "Z. Q. Sun",
      "Z. T. Sun",
      "C. J. Tang",
      "G. Y. Tang",
      "J. Tang",
      "M. Tang",
      "Y. A. Tang",
      "L. Y. Tao",
      "Q. T. Tao",
      "M. Tat",
      "J. X. Teng",
      "V. Thoren",
      "W. H. Tian",
      "Y. Tian",
      "Z. F. Tian",
      "I. Uman",
      "Y. Wan",
      "S. J. Wang",
      "B. Wang",
      "Bo Wang",
      "C. Wang",
      "D. Y. Wang",
      "H. J. Wang",
      "J. J. Wang",
      "J. P. Wang",
      "K. Wang",
      "L. L. Wang",
      "L. W. Wang",
      "M. Wang",
      "N. Y. Wang",
      "S. Wang",
      "S. Wang",
      "T. Wang",
      "T. J. Wang",
      "W. Wang",
      "W. Wang",
      "W. P. Wang",
      "X. Wang",
      "X. F. Wang",
      "X. J. Wang",
      "X. L. Wang",
      "X. N. Wang",
      "Y. Wang",
      "Y. D. Wang",
      "Y. F. Wang",
      "Y. H. Wang",
      "Y. L. Wang",
      "Y. N. Wang",
      "Y. Q. Wang",
      "Yaqian Wang",
      "Yi Wang",
      "Z. Wang",
      "Z. L. Wang",
      "Z. Y. Wang",
      "D. H. Wei",
      "F. Weidner",
      "S. P. Wen",
      "Y. R. Wen",
      "U. Wiedner",
      "G. Wilkinson",
      "M. Wolke",
      "L. Wollenberg",
      "C. Wu",
      "J. F. Wu",
      "L. H. Wu",
      "L. J. Wu",
      "Lianjie Wu",
      "X. Wu",
      "X. H. Wu",
      "Y. H. Wu",
      "Y. J. Wu",
      "Z. Wu",
      "L. Xia",
      "X. M. Xian",
      "B. H. Xiang",
      "T. Xiang",
      "D. Xiao",
      "G. Y. Xiao",
      "H. Xiao",
      "S. Y. Xiao",
      "Y. L. Xiao",
      "Z. J. Xiao",
      "C. Xie",
      "X. H. Xie",
      "Y. Xie",
      "Y. G. Xie",
      "Y. H. Xie",
      "Z. P. Xie",
      "T. Y. Xing",
      "C. F. Xu",
      "C. J. Xu",
      "G. F. Xu",
      "M. Xu",
      "Q. J. Xu",
      "Q. N. Xu",
      "W. L. Xu",
      "X. P. Xu",
      "Y. Xu",
      "Y. C. Xu",
      "Z. S. Xu",
      "F. Yan",
      "L. Yan",
      "W. B. Yan",
      "W. C. Yan",
      "W. P. Yan",
      "X. Q. Yan",
      "H. J. Yang",
      "H. L. Yang",
      "H. X. Yang",
      "J. H. Yang",
      "R. J. Yang",
      "T. Yang",
      "Y. Yang",
      "Y. F. Yang",
      "Y. F. Yang",
      "Y. X. Yang",
      "Y. Z. Yang",
      "Z. W. Yang",
      "Z. P. Yao",
      "M. Ye",
      "M. H. Ye",
      "J. H. Yin",
      "Junhao Yin",
      "Z. Y. You",
      "B. X. Yu",
      "C. X. Yu",
      "G. Yu",
      "J. S. Yu",
      "M. C. Yu",
      "T. Yu",
      "X. D. Yu",
      "C. Z. Yuan",
      "J. Yuan",
      "J. Yuan",
      "L. Yuan",
      "S. C. Yuan",
      "Y. Yuan",
      "Z. Y. Yuan",
      "C. X. Yue",
      "Ying Yue",
      "A. A. Zafar",
      "F. R. Zeng",
      "S. H. Zeng",
      "X. Zeng",
      "Y. Zeng",
      "Y. J. Zeng",
      "Y. J. Zeng",
      "X. Y. Zhai",
      "Y. C. Zhai",
      "Y. H. Zhan",
      "A. Q. Zhang",
      "B. L. Zhang",
      "B. X. Zhang",
      "D. H. Zhang",
      "G. Y. Zhang",
      "H. Zhang",
      "H. Zhang",
      "H. C. Zhang",
      "H. H. Zhang",
      "H. Q. Zhang",
      "H. R. Zhang",
      "H. Y. Zhang",
      "J. Zhang",
      "J. Zhang",
      "J. J. Zhang",
      "J. L. Zhang",
      "J. Q. Zhang",
      "J. S. Zhang",
      "J. W. Zhang",
      "J. X. Zhang",
      "J. Y. Zhang",
      "J. Z. Zhang",
      "Jianyu Zhang",
      "L. M. Zhang",
      "Lei Zhang",
      "P. Zhang",
      "Q. Zhang",
      "Q. Y. Zhang",
      "R. Y. Zhang",
      "S. H. Zhang",
      "Shulei Zhang",
      "X. M. Zhang",
      "X. Y Zhang",
      "X. Y. Zhang",
      "Y. Zhang",
      "Y. Zhang",
      "Y. T. Zhang",
      "Y. H. Zhang",
      "Y. M. Zhang",
      "Yan Zhang",
      "Z. D. Zhang",
      "Z. H. Zhang",
      "Z. L. Zhang",
      "Z. X. Zhang",
      "Z. Y. Zhang",
      "Z. Y. Zhang",
      "Z. Z. Zhang",
      "Zh. Zh. Zhang",
      "G. Zhao",
      "J. Y. Zhao",
      "J. Z. Zhao",
      "L. Zhao",
      "Lei Zhao",
      "M. G. Zhao",
      "N. Zhao",
      "R. P. Zhao",
      "S. J. Zhao",
      "Y. B. Zhao",
      "Y. X. Zhao",
      "Z. G. Zhao",
      "A. Zhemchugov",
      "B. Zheng",
      "B. M. Zheng",
      "J. P. Zheng",
      "W. J. Zheng",
      "X. R. Zheng",
      "Y. H. Zheng",
      "B. Zhong",
      "X. Zhong",
      "H. Zhou",
      "J. Y. Zhou",
      "L. P. Zhou",
      "S. Zhou",
      "X. Zhou",
      "X. K. Zhou",
      "X. R. Zhou",
      "X. Y. Zhou",
      "Y. Z. Zhou",
      "Z. C. Zhou",
      "A. N. Zhu",
      "J. Zhu",
      "K. Zhu",
      "K. J. Zhu",
      "K. S. Zhu",
      "L. Zhu",
      "L. X. Zhu",
      "S. H. Zhu",
      "T. J. Zhu",
      "W. D. Zhu",
      "W. Z. Zhu",
      "Y. C. Zhu",
      "Z. A. Zhu",
      "J. H. Zou",
      "J. Zu"
    ],
    "abstract": "An amplitude analysis of the Cabibbo-favored decay $D^+ \\to\nK^-\\pi^+\\pi^+\\pi^0$ is performed, using 7.93 $\\rm{fb}^{-1}$ of $e^+e^-$\ncollision data collected with the BESIII detector at the center-of-mass energy\nof 3.773 GeV. The branching fractions of the intermediate processes are\nmeasured, with the dominant contribution $D^+ \\to\n\\bar{K}^{*}(892)^0\\rho(770)^+$ observed to have a branching fraction of\n$(4.15\\pm0.07_{\\rm stat.}\\pm0.17_{\\rm syst.})\\%$. With the detection efficiency\nderived from the amplitude analysis, the absolute branching fraction of $D^+\n\\to K^-\\pi^+\\pi^+\\pi^0$ is measured to be $(6.06\\pm0.04_{\\rm stat.}\\pm0.07_{\\rm\nsyst.})\\%$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11040v1",
    "published": "2024-12-15T03:52:58+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2412.11039v2",
    "title": "AirMorph: Topology-Preserving Deep Learning for Pulmonary Airway Analysis",
    "authors": [
      "Minghui Zhang",
      "Chenyu Li",
      "Fangfang Xie",
      "Yaoyu Liu",
      "Hanxiao Zhang",
      "Junyang Wu",
      "Chunxi Zhang",
      "Jie Yang",
      "Jiayuan Sun",
      "Guang-Zhong Yang",
      "Yun Gu"
    ],
    "abstract": "Accurate anatomical labeling and analysis of the pulmonary structure and its\nsurrounding anatomy from thoracic CT is getting increasingly important for\nunderstanding the etilogy of abnormalities or supporting targetted therapy and\nearly interventions. Whilst lung and airway cell atlases have been attempted,\nthere is a lack of fine-grained morphological atlases that are clinically\ndeployable. In this work, we introduce AirMorph, a robust, end-to-end deep\nlearning pipeline enabling fully automatic and comprehensive airway anatomical\nlabeling at lobar, segmental, and subsegmental resolutions that can be used to\ncreate digital atlases of the lung. Evaluated across large-scale multi-center\ndatasets comprising diverse pulmonary conditions, the AirMorph consistently\noutperformed existing segmentation and labeling methods in terms of accuracy,\ntopological consistency, and completeness. To simplify clinical interpretation,\nwe further introduce a compact anatomical signature quantifying critical\nmorphological airway features, including stenosis, ectasia, tortuosity,\ndivergence, length, and complexity. When applied to various pulmonary diseases\nsuch as pulmonary fibrosis, emphysema, atelectasis, consolidation, and\nreticular opacities, it demonstrates strong discriminative power, revealing\ndisease-specific morphological patterns with high interpretability and\nexplainability. Additionally, AirMorph supports efficient automated branching\npattern analysis, potentially enhancing bronchoscopic navigation planning and\nprocedural safety, offering a valuable clinical tool for improved diagnosis,\ntargeted treatment, and personalized patient care.",
    "pdf_url": "http://arxiv.org/pdf/2412.11039v2",
    "published": "2024-12-15T03:35:00+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11038v2",
    "title": "Mass spectrum of the hidden-charm hybrid states via the QCD sum rules",
    "authors": [
      "Zhi-Gang Wang"
    ],
    "abstract": "In this work, we study the mass spectrum of the hidden-charm hybrid states\nwith the $J^{PC}=0^{-+}$, $0^{++}$, $0^{--}$, $1^{++}$, $1^{+-}$, $1^{-+}$,\n$1^{--}$, $2^{-+}$ and $2^{++}$ via the QCD sum rules in a consistent way. We\ncalculate the vacuum condensates up to dimensions-6 by taking account of both\nthe leading order and next-to-leading order contributions, and take the energy\nscale formula $\\mu=\\sqrt{M^2_{X/Y/Z}-(2{\\mathbb{M}}_c)^2}$ to choose the\nsuitable energy scales of the QCD spectral densities, it is the first time to\nexplore the energy scale dependence of the QCD sum rules for the hidden-charm\nhybrid states.",
    "pdf_url": "http://arxiv.org/pdf/2412.11038v2",
    "published": "2024-12-15T03:34:59+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11037v2",
    "title": "Heat kernel and local index theorem for open complex manifolds with $\\mathbb{C}^{\\ast }$-action",
    "authors": [
      "Jih-Hsin Cheng",
      "Chin-Yu Hsiao",
      "I-Hsun Tsai"
    ],
    "abstract": "For a complex manifold $\\Sigma $ with $\\mathbb{C}^{\\ast }$-action, we define\nthe $m$-th $\\mathbb{C}^{\\ast }$ Fourier-Dolbeault cohomology group and consider\nthe $m$-index on $\\Sigma $. By applying the method of transversal heat kernel\nasymptotics, we obtain a local index formula for the $m$-index. We can\nreinterpret Kawasaki's Hirzebruch-Riemann-Roch formula for a compact complex\norbifold with an orbifold holomorphic line bundle by our integral formulas over\na (smooth) complex manifold and finitely many complex submanifolds arising from\nsingular strata. We generalize $\\mathbb{C}^{\\ast }$-action to complex reductive\nLie group $G$-action on a compact or noncompact complex manifold. Among others,\nwe study the nonextendability of open group action and the space of all\n$G$-invariant holomorphic $p$-forms. Finally, in the case of two compatible\nholomorphic $\\mathbb{C}^{\\ast }$-actions, a mirror-type isomorphism is found\nbetween two linear spaces of holomorphic forms, and the Euler characteristic\nassociated with these spaces can be computed by our $\\mathbb{C}^{\\ast }$ local\nindex formula on the total space. In the perspective of the equivariant\nalgebraic cobordism theory $\\Omega _{\\ast }^{\\mathbb{C}^{\\ast }}(\\Sigma ),$ a\nspeculative connection is remarked. Possible relevance to the recent\ndevelopment in physics and number theory is briefly mentioned.",
    "pdf_url": "http://arxiv.org/pdf/2412.11037v2",
    "published": "2024-12-15T03:33:08+00:00",
    "categories": [
      "math.DG",
      "math.AP",
      "math.CV",
      "32Q55, 58E40, 58J20, 58J35"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11036v1",
    "title": "Stochastic Approximation and Brownian Repulsion based Evolutionary Search",
    "authors": [
      "Rajdeep Dutta",
      "T Venkatesh Varma",
      "Saikat Sarkar",
      "Mariya Mamajiwala",
      "Noor Awad",
      "Senthilnath Jayavelu",
      "Debasish Roy"
    ],
    "abstract": "Many global optimization algorithms of the memetic variety rely on some form\nof stochastic search, and yet they often lack a sound probabilistic basis.\nWithout a recourse to the powerful tools of stochastic calculus, treading the\nfine balance between exploration and exploitation could be tricky. In this\nwork, we propose an evolutionary algorithm (EA) comprising two types of\nadditive updates. The primary update utilizes stochastic approximation to guide\na population of randomly initialized particles towards an optimum. We\nincorporate derivative-free Robbins-Monro type gains in the first update so as\nto provide a directional guidance to the candidate solutions. The secondary\nupdate leverages stochastic conditioning to apply random perturbations for a\ncontrolled yet efficient exploration. Specifically, conceptualized on a change\nof measures, the perturbation strategy discourages two or more trajectories\nexploring the same region of the search space. Our optimization algorithm,\ndubbed as SABRES (Stochastic Approximation and Brownian Repulsion based\nEvolutionary Search), is applied to CEC-2022 benchmark functions on global\noptimization. Numerical results are indicative of the potentialities of SABRES\nin solving a variety of challenging multi-modal, non-separable, and\nasymmetrical benchmark functions.",
    "pdf_url": "http://arxiv.org/pdf/2412.11036v1",
    "published": "2024-12-15T03:28:13+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11035v1",
    "title": "Deep Learning Aided Multi-Objective Optimization and Multi-Criteria Decision Making in Thermal Cracking Process for Olefines Production",
    "authors": [
      "Seyed Reza Nabavi",
      "Mohammad Javad Jafari",
      "Zhiyuan Wang"
    ],
    "abstract": "Background: Multilayer perceptron (MLP) aided multi-objective particle swarm\noptimization algorithm (MOPSO) is employed in the present article to optimize\nthe liquefied petroleum gas (LPG) thermal cracking process. This new approach\nsignificantly accelerated the multi-objective optimization (MOO), which can now\nbe completed within one minute compared to the average of two days required by\nthe conventional approach. Methods: MOO generates a set of equally good\nPareto-optimal solutions, which are then ranked using a combination of a\nweighting method and five multi-criteria decision making (MCDM) methods. The\nfinal selection of a single solution for implementation is based on majority\nvoting and the similarity of the recommended solutions from the MCDM methods.\nSignificant Findings: The deep learning (DL) aided MOO and MCDM approach\nprovides valuable insights into the trade-offs between conflicting objectives\nand a more comprehensive understanding of the relationships between them.\nFurthermore, this approach also allows for a deeper understanding of the impact\nof decision variables on the objectives, enabling practitioners to make more\ninformed, data-driven decisions in the thermal cracking process.",
    "pdf_url": "http://arxiv.org/pdf/2412.11035v1",
    "published": "2024-12-15T03:18:10+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11034v1",
    "title": "SAM-IF: Leveraging SAM for Incremental Few-Shot Instance Segmentation",
    "authors": [
      "Xudong Zhou",
      "Wenhao He"
    ],
    "abstract": "We propose SAM-IF, a novel method for incremental few-shot instance\nsegmentation leveraging the Segment Anything Model (SAM). SAM-IF addresses the\nchallenges of class-agnostic instance segmentation by introducing a multi-class\nclassifier and fine-tuning SAM to focus on specific target objects. To enhance\nfew-shot learning capabilities, SAM-IF employs a cosine-similarity-based\nclassifier, enabling efficient adaptation to novel classes with minimal data.\nAdditionally, SAM-IF supports incremental learning by updating classifier\nweights without retraining the decoder. Our method achieves competitive but\nmore reasonable results compared to existing approaches, particularly in\nscenarios requiring specific object segmentation with limited labeled data.",
    "pdf_url": "http://arxiv.org/pdf/2412.11034v1",
    "published": "2024-12-15T03:11:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.12201v2",
    "title": "Embracing Large Language Models in Traffic Flow Forecasting",
    "authors": [
      "Yusheng Zhao",
      "Xiao Luo",
      "Haomin Wen",
      "Zhiping Xiao",
      "Wei Ju",
      "Ming Zhang"
    ],
    "abstract": "Traffic flow forecasting aims to predict future traffic flows based on the\nhistorical traffic conditions and the road network. It is an important problem\nin intelligent transportation systems, with a plethora of methods been\nproposed. Existing efforts mainly focus on capturing and utilizing\nspatio-temporal dependencies to predict future traffic flows. Though promising,\nthey fall short in adapting to test-time environmental changes of traffic\nconditions. To tackle this challenge, we propose to introduce large language\nmodels (LLMs) to help traffic flow forecasting and design a novel method named\nLarge Language Model Enhanced Traffic Flow Predictor (LEAF). LEAF adopts two\nbranches, capturing different spatio-temporal relations using graph and\nhypergraph structures respectively. The two branches are first pre-trained\nindividually, and during test-time, they yield different predictions. Based on\nthese predictions, a large language model is used to select the most likely\nresult. Then, a ranking loss is applied as the learning objective to enhance\nthe prediction ability of the two branches. Extensive experiments on several\ndatasets demonstrate the effectiveness of the proposed LEAF.",
    "pdf_url": "http://arxiv.org/pdf/2412.12201v2",
    "published": "2024-12-15T03:08:28+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11033v1",
    "title": "AURORA: Automated Unleash of 3D Room Outlines for VR Applications",
    "authors": [
      "Huijun Han",
      "Yongqing Liang",
      "Yuanlong Zhou",
      "Wenping Wang",
      "Edgar J. Rojas-Munoz",
      "Xin Li"
    ],
    "abstract": "Creating realistic VR experiences is challenging due to the labor-intensive\nprocess of accurately replicating real-world details into virtual scenes,\nhighlighting the need for automated methods that maintain spatial accuracy and\nprovide design flexibility. In this paper, we propose AURORA, a novel method\nthat leverages RGB-D images to automatically generate both purely virtual\nreality (VR) scenes and VR scenes combined with real-world elements. This\napproach can benefit designers by streamlining the process of converting\nreal-world details into virtual scenes. AURORA integrates advanced techniques\nin image processing, segmentation, and 3D reconstruction to efficiently create\nrealistic and detailed interior designs from real-world environments. The\ndesign of this integration ensures optimal performance and precision,\naddressing key challenges in automated indoor design generation by uniquely\ncombining and leveraging the strengths of foundation models. We demonstrate the\neffectiveness of our approach through experiments, both on self-captured data\nand public datasets, showcasing its potential to enhance virtual reality (VR)\napplications by providing interior designs that conform to real-world\npositioning.",
    "pdf_url": "http://arxiv.org/pdf/2412.11033v1",
    "published": "2024-12-15T03:06:22+00:00",
    "categories": [
      "cs.CV",
      "68U07",
      "J.6"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11032v1",
    "title": "AI-Driven Accelerated Discovery of Intercalation-type Cathode Materials for Magnesium Batteries",
    "authors": [
      "Wenjie Chen",
      "Zichang Lin",
      "Xinxin Zhang",
      "Hao Zhou",
      "Yuegang Zhang"
    ],
    "abstract": "Magnesium-ion batteries hold promise as future energy storage solution, yet\ncurrent Mg cathodes are challenged by low voltage and specific capacity.\nHerein, we present an AI-driven workflow for discovering high-performance Mg\ncathode materials. Utilizing the common characteristics of various ionic\nintercalation-type electrodes, we design and train a Crystal Graph\nConvolutional Neural Network model that can accurately predicts electrode\nvoltages for various ions with mean absolute errors (MAE) between 0.25 and 0.33\nV. By deploying the trained model to stable Mg compounds from Materials Project\nand GNoME AI dataset, we identify 160 high voltage structures out of 15,308\ncandidates with voltages above 3.0 V and volumetric capacity over 800 Ah/L. We\nfurther train a precise NequIP model to facilitate accurate and rapid\nsimulations of Mg ionic conductivity. From the 160 high voltage structures, the\nmachine learning molecular dynamics simulations have selected 23 cathode\nmaterials with both high energy density and high ionic conductivity. This\nAI-driven workflow dramatically boosts the efficiency and precision of material\ndiscovery for multivalent ion batteries, paving the way for advanced Mg battery\ndevelopment.",
    "pdf_url": "http://arxiv.org/pdf/2412.11032v1",
    "published": "2024-12-15T03:02:33+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2412.15250v1",
    "title": "An Enhanced Text Compression Approach Using Transformer-based Language Models",
    "authors": [
      "Chowdhury Mofizur Rahman",
      "Mahbub E Sobhani",
      "Anika Tasnim Rodela",
      "Swakkhar Shatabda"
    ],
    "abstract": "Text compression shrinks textual data while keeping crucial information,\neradicating constraints on storage, bandwidth, and computational efficacy. The\nintegration of lossless compression techniques with transformer-based text\ndecompression has received negligible attention, despite the increasing volume\nof English text data in communication. The primary barrier in advancing text\ncompression and restoration involves optimizing transformer-based approaches\nwith efficient pre-processing and integrating lossless compression algorithms,\nthat remained unresolved in the prior attempts. Here, we propose a\ntransformer-based method named RejuvenateForme for text decompression,\naddressing prior issues by harnessing a new pre-processing technique and a\nlossless compression method. Our meticulous pre-processing technique\nincorporating the Lempel-Ziv-Welch algorithm achieves compression ratios of\n12.57, 13.38, and 11.42 on the BookCorpus, EN-DE, and EN-FR corpora, thus\nshowing state-of-the-art compression ratios compared to other deep learning and\ntraditional approaches. Furthermore, the RejuvenateForme achieves a BLEU score\nof 27.31, 25.78, and 50.45 on the EN-DE, EN-FR, and BookCorpus corpora,\nshowcasing its comprehensive efficacy. In contrast, the pre-trained T5-Small\nexhibits better performance over prior state-of-the-art models.",
    "pdf_url": "http://arxiv.org/pdf/2412.15250v1",
    "published": "2024-12-15T03:01:17+00:00",
    "categories": [
      "cs.CL",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11031v1",
    "title": "The CMV bispectrality of the Jacobi polynomials on the unit circle",
    "authors": [
      "Luc Vinet",
      "Alexei Zhedanov"
    ],
    "abstract": "We show that the Jacobi polynomials that are orthogonal on the unit circle\n(the Jacobi OPUC) are CMV bispectral. This means that the corresponding Laurent\npolynomials in the CMV basis satisfy two dual ordinary eigenvalue problems: a\nrecurrence relation and a differential equation of Dunkl type. This is\npresumably the first nontrivial explicit example of CMV bispectral OPUC. We\nintroduce the circle Jacobi algebra which plays the role of hidden symmetry\nalgebra for the Jacobi OPUC. All fundamental properties of the Jacobi OPUC can\nbe derived from representations of this algebra.",
    "pdf_url": "http://arxiv.org/pdf/2412.11031v1",
    "published": "2024-12-15T03:01:03+00:00",
    "categories": [
      "math.CA",
      "33C45"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11030v1",
    "title": "How to Achieve Justice through Big Data: A Study Based on Credit Card Cases in Beijing",
    "authors": [
      "Cheng-To Lin",
      "Chung-Han Tsai",
      "Baowen Zhang",
      "Qingyue Deng",
      "Yunhui Zhao",
      "Zhijia Song"
    ],
    "abstract": "With the development of intelligence, the combination of big data and\njudicial practice has become a hot research topic. There are fewer studies on\ncredit card contract disputes related to big data, which makes it difficult to\nrespond to the trend of Big data era. This paper uses the data source of credit\ncard disputes related to the protection of personal information in Beijing from\n2022 to 2024, introduces a social network analysis methodology to analyse\nvalidated judgements and creates a database. Through the analysis of the\nrelationship network indicators of applicable laws and regulations, it can\nclearly show the laws and regulations applicable to this type of dispute in\nChina in terms of substantive and procedural matters. This paper provides a\nmethodology for combining big data with judicial trials and assisting judges in\ntrials. The effective use of social networks will help fill the gap in the\napplication of big data in judicial trials. The result and discussion of the\npaper is also of practical significance for improving the efficiency of\njudicial adjudication, constructing a database for searching classified cases,\nconstructing a holistic system for digital courts, and finally promoting\njustice.",
    "pdf_url": "http://arxiv.org/pdf/2412.11030v1",
    "published": "2024-12-15T02:53:39+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2501.00016v2",
    "title": "Predicting Crack Nucleation and Propagation in Brittle Materials Using Deep Operator Networks with Diverse Trunk Architectures",
    "authors": [
      "Elham Kiyani",
      "Manav Manav",
      "Nikhil Kadivar",
      "Laura De Lorenzis",
      "George Em Karniadakis"
    ],
    "abstract": "Phase-field modeling reformulates fracture problems as energy minimization\nproblems and enables a comprehensive characterization of the fracture process,\nincluding crack nucleation, propagation, merging, and branching, without\nrelying on ad-hoc assumptions. However, the numerical solution of phase-field\nfracture problems is characterized by a high computational cost. To address\nthis challenge, in this paper, we employ a deep neural operator (DeepONet)\nconsisting of a branch network and a trunk network to solve brittle fracture\nproblems. We explore three distinct approaches that vary in their trunk network\nconfigurations. In the first approach, we demonstrate the effectiveness of a\ntwo-step DeepONet, which results in a simplification of the learning task. In\nthe second approach, we employ a physics-informed DeepONet, whereby the\nmathematical expression of the energy is integrated into the trunk network's\nloss to enforce physical consistency. The integration of physics also results\nin a substantially smaller data size needed for training. In the third\napproach, we replace the neural network in the trunk with a Kolmogorov-Arnold\nNetwork and train it without the physics loss. Using these methods, we model\ncrack nucleation in a one-dimensional homogeneous bar under prescribed end\ndisplacements, as well as crack propagation and branching in single\nedge-notched specimens with varying notch lengths subjected to tensile and\nshear loading. We show that the networks predict the solution fields\naccurately, and the error in the predicted fields is localized near the crack.",
    "pdf_url": "http://arxiv.org/pdf/2501.00016v2",
    "published": "2024-12-15T02:50:30+00:00",
    "categories": [
      "physics.comp-ph",
      "cs.AI"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11029v1",
    "title": "General-order open-shell coupled-cluster method with partial-spin adaptation II: further formulations, simplifications, implementations, and numerical results",
    "authors": [
      "Cong Wang"
    ],
    "abstract": "This is a continuation of the previous work (arXiv:2403.10128). Additional\naspects such as linear combinations of projections and hash-table\ncanonicalizations are described. Implementations of the general-order\npartial-spin adaptation (PSA) coupled-cluster (CC) method are outlined.\nNumerical results are reported.",
    "pdf_url": "http://arxiv.org/pdf/2412.11029v1",
    "published": "2024-12-15T02:48:42+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11028v1",
    "title": "On the K-stability of blow-ups of projective bundles",
    "authors": [
      "Daniel Mallory"
    ],
    "abstract": "We investigate the K-stability of certain blow-ups of $\\mathbb{P}^1$-bundles\nover a Fano variety $V$, where the $\\mathbb{P}^1$-bundle is the projective\ncompactification of a line bundle $L$ proportional to $-K_V$ and the center of\nthe blow-up is the image along a positive section of a divisor $B$ also\nproportional to $L$. When $V$ and $B$ are smooth, we show that, for $B\n\\sim_{\\mathbb{Q}} 2L$, the K-semistability and K-polystability of the blow-up\nis equivalent to the K-semistability and K-polystability of the log Fano pair\n$(V,aB)$ for some coefficient $a$ explicitly computed. We also show that, for\n$B \\sim_{\\mathbb{Q}} l L$, $l \\neq 2$, the blow-up is K-unstable.",
    "pdf_url": "http://arxiv.org/pdf/2412.11028v1",
    "published": "2024-12-15T02:48:21+00:00",
    "categories": [
      "math.AG",
      "14J45 (Primary) 32Q26 (Secondary)"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11027v3",
    "title": "Symmetric instability in a Boussinesq fluid on a rotating planet",
    "authors": [
      "Yaoxuan Zeng",
      "Malte F. Jansen"
    ],
    "abstract": "Symmetric instability has broad applications in geophysical and planetary\nfluid dynamics. It plays a crucial role in the formation of mesoscale rainbands\nat mid-latitudes on Earth, instability in the ocean's mixed layer, and\nslantwise convection on gas giants and icy moon oceans. Here, we apply linear\ninstability analysis to an arbitrary zonally symmetric Boussinesq flow on a\nrotating spherical planet, with applicability to icy moon oceans. We divide the\ninstabilities into three types: (1) gravitational instability, occurring when\nstratification is unstable along angular momentum surfaces, (2) inertial\ninstability, occurring when angular momentum shear is unstable along buoyancy\nsurfaces, and (3) a mixed symmetric instability, occurring when neither of the\nprevious conditions are fulfilled, but the potential vorticity has the opposite\nsign to planetary rotation. We note that $N^2<0$ where $N$ is the\nBrunt--V\\\"ais\\\"al\\\"a frequency -- a typical criterion used to trigger\nconvective adjustment in global ocean models -- is neither necessary nor\nsufficient for instability. Instead, $b_z \\sin{\\theta_0}<0$, where $b_z$ is the\nstratification along the planetary rotation axis and $\\theta_0$ is the local\nlatitude, is always sufficient for instability and also necessary in the low\nRossby number limit. In this limit, relevant for deep convection in icy moon\noceans, the most unstable mode is slantwise convection parallel to the\nplanetary rotation axis. This slantwise convection differs from the\nparameterized convection in existing general circulation models, whose\nconvection schemes parameterize convection in the direction of gravity. Our\nresults suggest that convection schemes in global ocean models must be revised\nbefore being applied to icy moon oceans.",
    "pdf_url": "http://arxiv.org/pdf/2412.11027v3",
    "published": "2024-12-15T02:42:36+00:00",
    "categories": [
      "physics.flu-dyn",
      "astro-ph.EP"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2412.11026v2",
    "title": "SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation",
    "authors": [
      "Hang Zhang",
      "Zhuoling Li",
      "Jun Liu"
    ],
    "abstract": "Dynamic scenes contain intricate spatio-temporal information, crucial for\nmobile robots, UAVs, and autonomous driving systems to make informed decisions.\nParsing these scenes into semantic triplets <Subject-Predicate-Object> for\naccurate Scene Graph Generation (SGG) is highly challenging due to the\nfluctuating spatio-temporal complexity. Inspired by the reasoning capabilities\nof Large Language Models (LLMs), we propose SceneLLM, a novel framework that\nleverages LLMs as powerful scene analyzers for dynamic SGG. Our framework\nintroduces a Video-to-Language (V2L) mapping module that transforms video\nframes into linguistic signals (scene tokens), making the input more\ncomprehensible for LLMs. To better encode spatial information, we devise a\nSpatial Information Aggregation (SIA) scheme, inspired by the structure of\nChinese characters, which encodes spatial data into tokens. Using Optimal\nTransport (OT), we generate an implicit language signal from the frame-level\ntoken sequence that captures the video's spatio-temporal information. To\nfurther improve the LLM's ability to process this implicit linguistic input, we\napply Low-Rank Adaptation (LoRA) to fine-tune the model. Finally, we use a\ntransformer-based SGG predictor to decode the LLM's reasoning and predict\nsemantic triplets. Our method achieves state-of-the-art results on the Action\nGenome (AG) benchmark, and extensive experiments show the effectiveness of\nSceneLLM in understanding and generating accurate dynamic scene graphs.",
    "pdf_url": "http://arxiv.org/pdf/2412.11026v2",
    "published": "2024-12-15T02:41:31+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11025v1",
    "title": "From Simple to Professional: A Combinatorial Controllable Image Captioning Agent",
    "authors": [
      "Xinran Wang",
      "Muxi Diao",
      "Baoteng Li",
      "Haiwen Zhang",
      "Kongming Liang",
      "Zhanyu Ma"
    ],
    "abstract": "The Controllable Image Captioning Agent (CapAgent) is an innovative system\ndesigned to bridge the gap between user simplicity and professional-level\noutputs in image captioning tasks. CapAgent automatically transforms\nuser-provided simple instructions into detailed, professional instructions,\nenabling precise and context-aware caption generation. By leveraging multimodal\nlarge language models (MLLMs) and external tools such as object detection tool\nand search engines, the system ensures that captions adhere to specified\nguidelines, including sentiment, keywords, focus, and formatting. CapAgent\ntransparently controls each step of the captioning process, and showcases its\nreasoning and tool usage at every step, fostering user trust and engagement.\nThe project code is available at https://github.com/xin-ran-w/CapAgent.",
    "pdf_url": "http://arxiv.org/pdf/2412.11025v1",
    "published": "2024-12-15T02:37:20+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11024v2",
    "title": "Exploring Diffusion and Flow Matching Under Generator Matching",
    "authors": [
      "Zeeshan Patel",
      "James DeLoye",
      "Lance Mathias"
    ],
    "abstract": "In this paper, we present a comprehensive theoretical comparison of diffusion\nand flow matching under the Generator Matching framework. Despite their\napparent differences, both diffusion and flow matching can be viewed under the\nunified framework of Generator Matching. By recasting both diffusion and flow\nmatching under the same generative Markov framework, we provide theoretical\ninsights into why flow matching models can be more robust empirically and how\nnovel model classes can be constructed by mixing deterministic and stochastic\ncomponents. Our analysis offers a fresh perspective on the relationships\nbetween state-of-the-art generative modeling paradigms.",
    "pdf_url": "http://arxiv.org/pdf/2412.11024v2",
    "published": "2024-12-15T02:35:31+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11023v1",
    "title": "Exploring Enhanced Contextual Information for Video-Level Object Tracking",
    "authors": [
      "Ben Kang",
      "Xin Chen",
      "Simiao Lai",
      "Yang Liu",
      "Yi Liu",
      "Dong Wang"
    ],
    "abstract": "Contextual information at the video level has become increasingly crucial for\nvisual object tracking. However, existing methods typically use only a few\ntokens to convey this information, which can lead to information loss and limit\ntheir ability to fully capture the context. To address this issue, we propose a\nnew video-level visual object tracking framework called MCITrack. It leverages\nMamba's hidden states to continuously record and transmit extensive contextual\ninformation throughout the video stream, resulting in more robust object\ntracking. The core component of MCITrack is the Contextual Information Fusion\nmodule, which consists of the mamba layer and the cross-attention layer. The\nmamba layer stores historical contextual information, while the cross-attention\nlayer integrates this information into the current visual features of each\nbackbone block. This module enhances the model's ability to capture and utilize\ncontextual information at multiple levels through deep integration with the\nbackbone. Experiments demonstrate that MCITrack achieves competitive\nperformance across numerous benchmarks. For instance, it gets 76.6% AUC on\nLaSOT and 80.0% AO on GOT-10k, establishing a new state-of-the-art performance.\nCode and models are available at https://github.com/kangben258/MCITrack.",
    "pdf_url": "http://arxiv.org/pdf/2412.11023v1",
    "published": "2024-12-15T02:33:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11022v1",
    "title": "Resumming Photon Loops for Inflationary Gravity",
    "authors": [
      "A. J. Foraci",
      "R. P. Woodard"
    ],
    "abstract": "A previous calculation of the 1-loop photon contribution to the graviton\nself-energy on de Sitter background is considered. We first show that there is\nno local obstacle to conservation, unlike the contribution from a loop of\nmassless, minimally coupled scalars. This is correlated to the absence of an\nEddington ($R^2$) counterterm and to the vanishing of the stress tensor when\nthe photon in integrated out in the presence of a constant graviton field. We\nalso show that there is a secularly growing 1-loop contribution to the electric\ncomponents of the Weyl tensor for plane wave gravitons. Its coefficient agrees\nwith that of the secular 1-loop correction to the Newtonian potential, and both\ncan be resummed using a variant of the renormalization group.",
    "pdf_url": "http://arxiv.org/pdf/2412.11022v1",
    "published": "2024-12-15T02:32:19+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2412.11021v1",
    "title": "SparseMap: Loop Mapping for Sparse CNNs on Streaming Coarse-grained Reconfigurable Array",
    "authors": [
      "Xiaobing Ni",
      "Mengke Ge",
      "Jiaheng Ruan",
      "Song Chen",
      "Yi Kang"
    ],
    "abstract": "Streaming coarse-grained reconfgurable array (CGRA) is a promising\narchitecture for data/computing-intensive applications because of its\nfexibility, high throughput and efcient memory system. However,when\naccelerating sparse CNNs, the irregular input data demands inside sparse CNNs\nwould cause excessive caching operations (COPs) and multi-cycle internal\ndependencies (MCIDs) between operations, declining the throughput of the\nstreaming CGRA. We propose a mapping method for sparse CNNs onto streaming\nCGRA, SparseMap, which incorporates an efcient I/O data management along with\noperation scheduling and binding, to reduce the COPs and MCIDs, thereby\nensuring the optimal throughput of streaming CGRA.The experimental results show\nSparseMap reduces 92.5% COPs and 46.0 % MCIDs while achieves the same or even\nsmaller initiation interval (II) compared to previous works.",
    "pdf_url": "http://arxiv.org/pdf/2412.11021v1",
    "published": "2024-12-15T02:30:09+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11020v1",
    "title": "Reconfigurable Intelligent Surface-Aided Secure Integrated Radar and Communication Systems",
    "authors": [
      "Tong-Xing Zheng",
      "Xin Chen",
      "Lan Lan",
      "Ying Ju",
      "Xiaoyan Hu",
      "Rongke Liu",
      "Derrick Wing Kwan Ng",
      "Tiejun Cui"
    ],
    "abstract": "Despite the enhanced spectral efficiency brought by the integrated radar and\ncommunication technique, it poses significant risks to communication security\nwhen confronted with malicious radar targets. To address this issue, a\nreconfigurable intelligent surface (RIS)-aided transmission scheme is proposed\nto improve secure communication in two systems, i.e., the radar and\ncommunication co-existing (RCCE) system, where a single transmitter is utilized\nfor both radar sensing and communication, and the dual-functional radar and\ncommunication (DFRC) system. At the design stage, optimization problems are\nformulated to maximize the secrecy rate while satisfying the radar detection\nconstraint via joint active beamforming at the base station and passive\nbeamforming of RIS in both systems. Particularly, a zero-forcing-based block\ncoordinate descent (BCD) algorithm is developed for the RCCE system. Besides,\nthe Dinkelbach method combined with semidefinite relaxation is employed for the\nDFRC system, and to further reduce the computational complexity, a Riemannian\nconjugate gradient-based alternating optimization algorithm is proposed.\nMoreover, the RIS-aided robust secure communication in the DFRC system is\ninvestigated by considering the eavesdropper's imperfect channel state\ninformation (CSI), where a bounded uncertainty model is adopted to capture the\nangle error and fading channel error of the eavesdropper, and a tractable bound\nfor their joint uncertainty is derived. Simulation results confirm the\neffectiveness of the developed RIS-aided transmission scheme to improve the\nsecrecy rate even with the eavesdropper's imperfect CSI, and comparisons\nbetween both systems reveal that the RCCE system can provide a higher secrecy\nrate than the DFRC system.",
    "pdf_url": "http://arxiv.org/pdf/2412.11020v1",
    "published": "2024-12-15T02:27:51+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11019v1",
    "title": "PolyModel for Hedge Funds' Portfolio Construction Using Machine Learning",
    "authors": [
      "Siqiao Zhao",
      "Dan Wang",
      "Raphael Douady"
    ],
    "abstract": "The domain of hedge fund investments is undergoing significant\ntransformation, influenced by the rapid expansion of data availability and the\nadvancement of analytical technologies. This study explores the enhancement of\nhedge fund investment performance through the integration of machine learning\ntechniques, the application of PolyModel feature selection, and the analysis of\nfund size. We address three critical questions: (1) the effect of machine\nlearning on trading performance, (2) the role of PolyModel feature selection in\nfund selection and performance, and (3) the comparative reliability of larger\nversus smaller funds.\n  Our findings offer compelling insights. We observe that while machine\nlearning techniques enhance cumulative returns, they also increase annual\nvolatility, indicating variability in performance. PolyModel feature selection\nproves to be a robust strategy, with approaches that utilize a comprehensive\nset of features for fund selection outperforming more selective methodologies.\nNotably, Long-Term Stability (LTS) effectively manages portfolio volatility\nwhile delivering favorable returns. Contrary to popular belief, our results\nsuggest that larger funds do not consistently yield better investment outcomes,\nchallenging the assumption of their inherent reliability.\n  This research highlights the transformative impact of data-driven approaches\nin the hedge fund investment arena and provides valuable implications for\ninvestors and asset managers. By leveraging machine learning and PolyModel\nfeature selection, investors can enhance portfolio optimization and reassess\nthe dependability of larger funds, leading to more informed investment\nstrategies.",
    "pdf_url": "http://arxiv.org/pdf/2412.11019v1",
    "published": "2024-12-15T02:22:27+00:00",
    "categories": [
      "q-fin.ST",
      "q-fin.PM"
    ],
    "primary_category": "q-fin.ST"
  },
  {
    "id": "http://arxiv.org/abs/2412.11018v1",
    "title": "A characterization of the Grassmann graphs: one missing case",
    "authors": [
      "Jack H. Koolen",
      "Chenhui Lv",
      "Alexander L. Gavrilyuk"
    ],
    "abstract": "We prove that the Grassmann graphs $J_2(2D+3,D)$, $D\\geq 3$, are\ncharacterized by their intersection numbers, which settles one of the few\nremaining cases.",
    "pdf_url": "http://arxiv.org/pdf/2412.11018v1",
    "published": "2024-12-15T02:11:57+00:00",
    "categories": [
      "math.CO",
      "05E30"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11017v2",
    "title": "On Distilling the Displacement Knowledge for Few-Shot Class-Incremental Learning",
    "authors": [
      "Pengfei Fang",
      "Yongchun Qin",
      "Hui Xue"
    ],
    "abstract": "Few-shot Class-Incremental Learning (FSCIL) addresses the challenges of\nevolving data distributions and the difficulty of data acquisition in\nreal-world scenarios. To counteract the catastrophic forgetting typically\nencountered in FSCIL, knowledge distillation is employed as a way to maintain\nthe knowledge from learned data distribution. Recognizing the limitations of\ngenerating discriminative feature representations in a few-shot context, our\napproach incorporates structural information between samples into knowledge\ndistillation. This structural information serves as a remedy for the low\nquality of features. Diverging from traditional structured distillation methods\nthat compute sample similarity, we introduce the Displacement Knowledge\nDistillation (DKD) method. DKD utilizes displacement rather than similarity\nbetween samples, incorporating both distance and angular information to\nsignificantly enhance the information density retained through knowledge\ndistillation. Observing performance disparities in feature distribution between\nbase and novel classes, we propose the Dual Distillation Network (DDNet). This\nnetwork applies traditional knowledge distillation to base classes and DKD to\nnovel classes, challenging the conventional integration of novel classes with\nbase classes. Additionally, we implement an instance-aware sample selector\nduring inference to dynamically adjust dual branch weights, thereby leveraging\nthe complementary strengths of each approach. Extensive testing on three\nbenchmarks demonstrates that DDNet achieves state-of-the-art results. Moreover,\nthrough rigorous experimentation and comparison, we establish the robustness\nand general applicability of our proposed DKD method.",
    "pdf_url": "http://arxiv.org/pdf/2412.11017v2",
    "published": "2024-12-15T02:10:18+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11016v1",
    "title": "A Contextualized BERT model for Knowledge Graph Completion",
    "authors": [
      "Haji Gul",
      "Abdul Ghani Naim",
      "Ajaz A. Bhat"
    ],
    "abstract": "Knowledge graphs (KGs) are valuable for representing structured,\ninterconnected information across domains, enabling tasks like semantic search,\nrecommendation systems and inference. A pertinent challenge with KGs, however,\nis that many entities (i.e., heads, tails) or relationships are unknown.\nKnowledge Graph Completion (KGC) addresses this by predicting these missing\nnodes or links, enhancing the graph's informational depth and utility.\nTraditional methods like TransE and ComplEx predict tail entities but struggle\nwith unseen entities. Textual-based models leverage additional semantics but\ncome with high computational costs, semantic inconsistencies, and data\nimbalance issues. Recent LLM-based models show improvement but overlook\ncontextual information and rely heavily on entity descriptions. In this study,\nwe introduce a contextualized BERT model for KGC that overcomes these\nlimitations by utilizing the contextual information from neighbouring entities\nand relationships to predict tail entities. Our model eliminates the need for\nentity descriptions and negative triplet sampling, reducing computational\ndemands while improving performance. Our model outperforms state-of-the-art\nmethods on standard datasets, improving Hit@1 by 5.3% and 4.88% on FB15k-237\nand WN18RR respectively, setting a new benchmark in KGC.",
    "pdf_url": "http://arxiv.org/pdf/2412.11016v1",
    "published": "2024-12-15T02:03:16+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11015v2",
    "title": "Experimental demonstration of enhanced quantum tomography via quantum reservoir processing",
    "authors": [
      "Tanjung Krisnanda",
      "Pengtao Song",
      "Adrian Copetudo",
      "Clara Yun Fontaine",
      "Tomasz Paterek",
      "Timothy C. H. Liew",
      "Yvonne Y. Gao"
    ],
    "abstract": "Quantum machine learning is a rapidly advancing discipline that leverages the\nfeatures of quantum mechanics to enhance the performance of computational\ntasks. Quantum reservoir processing, which allows efficient optimization of a\nsingle output layer without precise control over the quantum system, stands out\nas one of the most versatile and practical quantum machine learning techniques.\nHere we experimentally demonstrate a quantum reservoir processing approach for\ncontinuous-variable state reconstruction on a bosonic circuit quantum\nelectrodynamics platform. The scheme learns the true dynamical process through\na minimum set of measurement outcomes of a known set of initial states. We show\nthat the map learnt this way achieves high reconstruction fidelity for several\ntest states, offering significantly enhanced performance over using a map\ncalculated based on an idealised model of the system. This is due to a key\nfeature of reservoir processing which accurately accounts for physical\nnon-idealities such as decoherence, spurious dynamics, and systematic errors.\nOur results present a valuable tool for robust bosonic state and process\nreconstruction, concretely demonstrating the power of quantum reservoir\nprocessing in enhancing real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2412.11015v2",
    "published": "2024-12-15T02:02:43+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2412.11014v2",
    "title": "CoopetitiveV: Leveraging LLM-powered Coopetitive Multi-Agent Prompting for High-quality Verilog Generation",
    "authors": [
      "Zhendong Mi",
      "Renming Zheng",
      "Haowen Zhong",
      "Yue Sun",
      "Seth Kneeland",
      "Sayan Moitra",
      "Ken Kutzer",
      "Zhaozhuo Xu Shaoyi Huang"
    ],
    "abstract": "Recent advances in agentic LLMs have demonstrated great capabilities in\nVerilog code generation. However, existing approaches either use LLM-assisted\nsingle-agent prompting or cooperation-only multi-agent learning, which will\nlead to: (i) Degeneration issue for single-agent learning: characterized by\ndiminished error detection and correction capabilities; (ii) Error propagation\nin cooperation-only multi-agent learning: erroneous information from the former\nagent will be propagated to the latter through prompts, which can make the\nlatter agents generate buggy code. In this paper, we propose an LLM-based\ncoopetitive multi-agent prompting framework, in which the agents cannot\ncollaborate with each other to form the generation pipeline, but also create a\nhealthy competitive mechanism to improve the generating quality. Our\nexperimental results show that the coopetitive multi-agent framework can\neffectively mitigate the degeneration risk and reduce the error propagation\nwhile improving code error correction capabilities, resulting in higher quality\nVerilog code generation. The effectiveness of our approach is validated through\nextensive experiments. On VerilogEval Machine and Human dataset,\nCoopetitiveV+GPT-4 achieves 99.2% and 99.1% pass@10 scores, respectively. While\non RTLLM, CoopetitiveV+GPT-4 obtains 100% syntax and 99.9% functionality pass@5\nscores.",
    "pdf_url": "http://arxiv.org/pdf/2412.11014v2",
    "published": "2024-12-15T01:58:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11013v1",
    "title": "A Hopf algebra generalization of the symmetric functions in partially commutative variables",
    "authors": [
      "Spencer Daugherty"
    ],
    "abstract": "The quasisymmetric functions, $QSym$, are generalized for a finite alphabet\n$A$ by the colored quasisymmetric functions, $QSym_A$, in partially commutative\nvariables. Their dual, $NSym_A$, generalizes the noncommutative symmetric\nfunctions, $NSym$, through a relationship with a Hopf algebra of trees. We\ndefine an algebra $Sym_A$, contained within $QSym_A$, that is isomorphic to the\nsymmetric functions, $Sym$, when $A$ is an alphabet of size one. We show that\n$Sym_A$ is a Hopf algebra and define its graded dual, $PSym_A$, which is the\ncommutative image of $NSym_A$ and also generalizes $Sym$. The seven algebras\nlisted here can be placed in a commutative diagram connected by Hopf morphisms.\nIn addition to defining generalizations of the classic bases of the symmetric\nfunctions to $Sym_A$ and $PSym_A$, we describe multiplication,\ncomultiplication, and the antipode in terms of a basis for both algebras. We\nconclude by defining a pair of dual bases that generalize the Schur functions\nand listing open questions.",
    "pdf_url": "http://arxiv.org/pdf/2412.11013v1",
    "published": "2024-12-15T01:49:15+00:00",
    "categories": [
      "math.CO",
      "05E05, 16T30"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2412.11012v2",
    "title": "Comments on firewalls in JT gravity with matter",
    "authors": [
      "Chuanxin Cui",
      "Moshe Rozali"
    ],
    "abstract": "We present two discussions of firewalls in JT gravity. First we present an\nalternative, arguably simpler, derivation of the gray hole conjecture, applying\nuniformly to all probes of the firewall probability previously discussed. This\nderivation is based on the wormhole shortening picture using the handle-disk\ngeometry. However we modifies Saad's story utilizing a \"Wilsonian\" effective\ngravitational description, adapted to the time scale probed, in which high\nfrequency modes are integrated out generating the gravitational bulk geometries\n(dual to the genus expansion in the matrix integral side) whereas low frequency\nmodes are more precisely resolved by being represented as eigenvalue D-branes\nwhere JT universes can end. This treatment results in an effective \"twist\nfactor cutoff\" prescription which simplifies the discussion of long time\nquantities including the firewall probability. In the second part we discuss\neffects of matter loops on the firewall probability. While such effects lead to\nnew firewall sources, we argue that these matter loop contributions are\nsub-dominant at late times.",
    "pdf_url": "http://arxiv.org/pdf/2412.11012v2",
    "published": "2024-12-15T01:47:55+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2412.11011v2",
    "title": "Algebraic Topology Without Open Sets: A Net Approach to Homotopy Theory in Limit Spaces",
    "authors": [
      "Rodrigo Santos Monteiro"
    ],
    "abstract": "Convergence spaces are a generalization of topological spaces. The category\nof convergence spaces is well-suited for Algebraic Topology, one of the reasons\nis the existence of exponential objects provided by continuous convergence. In\nthis work, we use a net-theoretic approach to convergence spaces. The goal is\nto simplify the description of continuous convergence and apply it to problems\nrelated to homotopy theory. We present methods to develop the basis of homotopy\ntheory in limit spaces, define the fundamental groupoid, and prove the groupoid\nversion of the Seifert-van Kampen Theorem for limit spaces.",
    "pdf_url": "http://arxiv.org/pdf/2412.11011v2",
    "published": "2024-12-15T01:40:57+00:00",
    "categories": [
      "math.AT",
      "math.GN"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2412.11010v1",
    "title": "FBSJNN: A Theoretically Interpretable and Efficiently Deep Learning method for Solving Partial Integro-Differential Equations",
    "authors": [
      "Zaijun Ye",
      "Wansheng Wang"
    ],
    "abstract": "We propose a novel framework for solving a class of Partial\nIntegro-Differential Equations (PIDEs) and Forward-Backward Stochastic\nDifferential Equations with Jumps (FBSDEJs) through a deep learning-based\napproach. This method, termed the Forward-Backward Stochastic Jump Neural\nNetwork (FBSJNN), is both theoretically interpretable and numerically\neffective. Theoretical analysis establishes the convergence of the numerical\nscheme and provides error estimates grounded in the universal approximation\nproperties of neural networks. In comparison to existing methods, the key\ninnovation of the FBSJNN framework is that it uses a single neural network to\napproximate both the solution of the PIDEs and the non-local integral,\nleveraging Taylor expansion for the latter. This enables the method to reduce\nthe total number of parameters in FBSJNN, which enhances optimization\nefficiency. Numerical experiments indicate that the FBSJNN scheme can obtain\nnumerical solutions with a relative error on the scale of $10^{-3}$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11010v1",
    "published": "2024-12-15T01:37:48+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "stat.ML"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2412.11009v1",
    "title": "Dual Traits in Probabilistic Reasoning of Large Language Models",
    "authors": [
      "Shenxiong Li",
      "Huaxia Rui"
    ],
    "abstract": "We conducted three experiments to investigate how large language models\n(LLMs) evaluate posterior probabilities. Our results reveal the coexistence of\ntwo modes in posterior judgment among state-of-the-art models: a normative\nmode, which adheres to Bayes' rule, and a representative-based mode, which\nrelies on similarity -- paralleling human System 1 and System 2 thinking.\nAdditionally, we observed that LLMs struggle to recall base rate information\nfrom their memory, and developing prompt engineering strategies to mitigate\nrepresentative-based judgment may be challenging. We further conjecture that\nthe dual modes of judgment may be a result of the contrastive loss function\nemployed in reinforcement learning from human feedback. Our findings underscore\nthe potential direction for reducing cognitive biases in LLMs and the necessity\nfor cautious deployment of LLMs in critical areas.",
    "pdf_url": "http://arxiv.org/pdf/2412.11009v1",
    "published": "2024-12-15T01:33:45+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2412.11008v1",
    "title": "Towards Context-aware Convolutional Network for Image Restoration",
    "authors": [
      "Fangwei Hao",
      "Ji Du",
      "Weiyun Liang",
      "Jing Xu",
      "Xiaoxuan Xu"
    ],
    "abstract": "Image restoration (IR) is a long-standing task to recover a high-quality\nimage from its corrupted observation. Recently, transformer-based algorithms\nand some attention-based convolutional neural networks (CNNs) have presented\npromising results on several IR tasks. However, existing convolutional residual\nbuilding modules for IR encounter limited ability to map inputs into\nhigh-dimensional and non-linear feature spaces, and their local receptive\nfields have difficulty in capturing long-range context information like\nTransformer. Besides, CNN-based attention modules for IR either face static\nabundant parameters or have limited receptive fields. To address the first\nissue, we propose an efficient residual star module (ERSM) that includes\ncontext-aware \"star operation\" (element-wise multiplication) to contextually\nmap features into exceedingly high-dimensional and non-linear feature spaces,\nwhich greatly enhances representation learning. To further boost the extraction\nof contextual information, as for the second issue, we propose a large dynamic\nintegration module (LDIM) which possesses an extremely large receptive field.\nThus, LDIM can dynamically and efficiently integrate more contextual\ninformation that helps to further significantly improve the reconstruction\nperformance. Integrating ERSM and LDIM into an U-shaped backbone, we propose a\ncontext-aware convolutional network (CCNet) with powerful learning ability for\ncontextual high-dimensional mapping and abundant contextual information.\nExtensive experiments show that our CCNet with low model complexity achieves\nsuperior performance compared to other state-of-the-art IR methods on several\nIR tasks, including image dehazing, image motion deblurring, and image\ndesnowing.",
    "pdf_url": "http://arxiv.org/pdf/2412.11008v1",
    "published": "2024-12-15T01:29:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2412.11007v1",
    "title": "FlashSparse: Minimizing Computation Redundancy for Fast Sparse Matrix Multiplications on Tensor Cores",
    "authors": [
      "Jinliang Shi",
      "Shigang Li",
      "Youxuan Xu",
      "Rongtian Fu",
      "Xueying Wang",
      "Tong Wu"
    ],
    "abstract": "Sparse Matrix-matrix Multiplication (SpMM) and Sampled Dense-dense Matrix\nMultiplication (SDDMM) are important sparse operators in scientific computing\nand deep learning. Tensor Core Units (TCUs) enhance modern accelerators with\nsuperior computing power, which is promising to boost the performance of matrix\noperators to a higher level. However, due to the irregularity of unstructured\nsparse data, it is difficult to deliver practical speedups on TCUs. To this\nend, we propose FlashSparse, a novel approach to bridge the gap between sparse\nworkloads and the TCU architecture. Specifically, FlashSparse minimizes the\nsparse granularity for SpMM and SDDMM on TCUs through a novel\nswap-and-transpose matrix multiplication strategy. Benefiting from the minimum\nsparse granularity, the computation redundancy is remarkably reduced while the\ncomputing power of TCUs is fully utilized. Besides, FlashSparse is equipped\nwith a memory-efficient thread mapping strategy for coalesced data access and a\nsparse matrix storage format to save memory footprint. Extensive experimental\nresults on H100 and RTX 4090 GPUs show that FlashSparse sets a new\nstate-of-the-art for sparse matrix multiplications (geometric mean 5.5x speedup\nover DTC-SpMM and 3.22x speedup over RoDe).",
    "pdf_url": "http://arxiv.org/pdf/2412.11007v1",
    "published": "2024-12-15T01:12:33+00:00",
    "categories": [
      "cs.DC",
      "cs.LG",
      "C.1.4; I.2.11"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2412.15249v2",
    "title": "LitLLMs, LLMs for Literature Review: Are we there yet?",
    "authors": [
      "Shubham Agarwal",
      "Gaurav Sahu",
      "Abhay Puri",
      "Issam H. Laradji",
      "Krishnamurthy DJ Dvijotham",
      "Jason Stanley",
      "Laurent Charlin",
      "Christopher Pal"
    ],
    "abstract": "Literature reviews are an essential component of scientific research, but\nthey remain time-intensive and challenging to write, especially due to the\nrecent influx of research papers. This paper explores the zero-shot abilities\nof recent Large Language Models (LLMs) in assisting with the writing of\nliterature reviews based on an abstract. We decompose the task into two\ncomponents: 1. Retrieving related works given a query abstract, and 2. Writing\na literature review based on the retrieved results. We analyze how effective\nLLMs are for both components. For retrieval, we introduce a novel two-step\nsearch strategy that first uses an LLM to extract meaningful keywords from the\nabstract of a paper and then retrieves potentially relevant papers by querying\nan external knowledge base. Additionally, we study a prompting-based re-ranking\nmechanism with attribution and show that re-ranking doubles the normalized\nrecall compared to naive search methods, while providing insights into the\nLLM's decision-making process. In the generation phase, we propose a two-step\napproach that first outlines a plan for the review and then executes steps in\nthe plan to generate the actual review. To evaluate different LLM-based\nliterature review methods, we create test sets from arXiv papers using a\nprotocol designed for rolling use with newly released LLMs to avoid test set\ncontamination in zero-shot evaluations. We release this evaluation protocol to\npromote additional research and development in this regard. Our empirical\nresults suggest that LLMs show promising potential for writing literature\nreviews when the task is decomposed into smaller components of retrieval and\nplanning. Our project page including a demonstration system and toolkit can be\naccessed here: https://litllm.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2412.15249v2",
    "published": "2024-12-15T01:12:26+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2412.11006v1",
    "title": "Entropy-Regularized Process Reward Model",
    "authors": [
      "Hanning Zhang",
      "Pengcheng Wang",
      "Shizhe Diao",
      "Yong Lin",
      "Rui Pan",
      "Hanze Dong",
      "Dylan Zhang",
      "Pavlo Molchanov",
      "Tong Zhang"
    ],
    "abstract": "Large language models (LLMs) have shown promise in performing complex\nmulti-step reasoning, yet they continue to struggle with mathematical\nreasoning, often making systematic errors. A promising solution is\nreinforcement learning (RL) guided by reward models, particularly those\nfocusing on process rewards, which score each intermediate step rather than\nsolely evaluating the final outcome. This approach is more effective at guiding\npolicy models towards correct reasoning trajectories. In this work, we propose\nan entropy-regularized process reward model (ER-PRM) that integrates\nKL-regularized Markov Decision Processes (MDP) to balance policy optimization\nwith the need to prevent the policy from shifting too far from its initial\ndistribution. We derive a novel reward construction method based on the\ntheoretical results. Our theoretical analysis shows that we could derive the\noptimal reward model from the initial policy sampling. Our empirical\nexperiments on the MATH and GSM8K benchmarks demonstrate that ER-PRM\nconsistently outperforms existing process reward models, achieving 1%\nimprovement on GSM8K and 2-3% improvement on MATH under best-of-N evaluation,\nand more than 1% improvement under RLHF. These results highlight the efficacy\nof entropy-regularization in enhancing LLMs' reasoning capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2412.11006v1",
    "published": "2024-12-15T01:09:23+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11005v1",
    "title": "Stability of the Couette flow for 3D Navier-Stokes equations with rotation",
    "authors": [
      "Wenting Huang",
      "Ying Sun",
      "Xiaojing Xu"
    ],
    "abstract": "Rotation significantly influences the stability characteristics of both\nlaminar and turbulent shear flows. This study examines the stability threshold\nof the three-dimensional Navier-Stokes equations with rotation, in the vicinity\nof the Couette flow at high Reynolds numbers ($\\mathbf{Re}$) in the periodical\ndomain $\\mathbb{T} \\times \\mathbb{R} \\times \\mathbb{T}$, where the rotational\nstrength is equivalent to the Couette flow. Compared to the classical\nNavier-Stokes equations, rotation term brings us more two primary difficulties:\nthe linear coupling term involving in the equation of $u^2$ and the lift-up\neffect in two directions. To address these difficulties, we introduce two new\ngood unknowns that effectively capture the phenomena of enhanced dissipation\nand inviscid damping to suppress the lift-up effect. Moreover, we establish the\nstability threshold for initial perturbation\n$\\left\\|u_{\\mathrm{in}}\\right\\|_{H^{\\sigma}} < \\delta \\mathbf{Re}^{-2}$ for any\n$\\sigma > \\frac{9}{2}$ and some $\\delta=\\delta(\\sigma)>0$ depending only on\n$\\sigma$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11005v1",
    "published": "2024-12-15T00:58:00+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11004v1",
    "title": "SightGlow: A Web Extension to Enhance Color Perception and Interaction for Vision Deficiency",
    "authors": [
      "Sansrit Paudel"
    ],
    "abstract": "SightGlow is a web extension tailored to improve color perception accuracy\nfor individuals with red-green color blindness. The research was focused on\nevaluating whether personalized color adjustment and selective zoom enhance\nuser interaction and satisfaction for individuals with low vision and color\nvision impairment. The system was developed as an iterative process by\nconducting a pilot user survey. Existing web extensions were limited in\naddressing challenges faced by low vision and color blindness; hence this\napplication provides additional features, including selective zoom and color\ncontrols, which make it unique. Most participants responded that the\napplication's flexibility to adjust the color balance for any images or video\ngraphic content enhanced their user experience, hence resulting in the\neffectiveness of the system.",
    "pdf_url": "http://arxiv.org/pdf/2412.11004v1",
    "published": "2024-12-15T00:55:27+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2412.11003v3",
    "title": "Optimal Rates for Robust Stochastic Convex Optimization",
    "authors": [
      "Changyu Gao",
      "Andrew Lowy",
      "Xingyu Zhou",
      "Stephen J. Wright"
    ],
    "abstract": "Machine learning algorithms in high-dimensional settings are highly\nsusceptible to the influence of even a small fraction of structured outliers,\nmaking robust optimization techniques essential. In particular, within the\n$\\epsilon$-contamination model, where an adversary can inspect and replace up\nto an $\\epsilon$-fraction of the samples, a fundamental open problem is\ndetermining the optimal rates for robust stochastic convex optimization (SCO)\nunder such contamination. We develop novel algorithms that achieve\nminimax-optimal excess risk (up to logarithmic factors) under the\n$\\epsilon$-contamination model. Our approach improves over existing algorithms,\nwhich are not only suboptimal but also require stringent assumptions, including\nLipschitz continuity and smoothness of individual sample functions. By\ncontrast, our optimal algorithms do not require these stringent assumptions,\nassuming only population-level smoothness of the loss. Moreover, our algorithms\ncan be adapted to handle the case in which the covariance parameter is unknown,\nand can be extended to nonsmooth population risks via convolutional smoothing.\nWe complement our algorithmic developments with a tight information-theoretic\nlower bound for robust SCO.",
    "pdf_url": "http://arxiv.org/pdf/2412.11003v3",
    "published": "2024-12-15T00:52:08+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2412.11002v1",
    "title": "Communications over Unlicensed sub-8 GHz Spectrum: Opportunities and Challenges",
    "authors": [
      "Karim Saifullin",
      "Hussein Al-Shatri",
      "Mohamed-Slim Alouini"
    ],
    "abstract": "The utilization of unlicensed spectrum presents a promising solution to the\nissue of spectrum scarcity in densely populated areas, while also offering a\ncost-effective means to connect underserved regions. In response to this\npotential, both academia and industry are actively exploring innovative\napplications of unlicensed spectrum. This work offers a thorough overview of\nunlicensed spectrum bands below 8 GHz, including TV White Spaces, Civil\nBroadband Radio Services, Industrial Scientific Medical bands, and the\nUnlicensed National Information Infrastructure. The paper focuses on three key\naspects: regulations, existing technologies, and applications. It is essential\nto recognize that \"unlicensed\" does not equate to \"unregulated\"; therefore, a\nclear understanding of permissible and prohibited activities is crucial. From a\ntechnological perspective, we examine the current technologies, their\ncapabilities, and relevant applications. Additionally, the shared nature of\nthis spectrum introduces challenges related to interference among users. These\ncollisions can be managed through two primary strategies, that we described: a\ndatabase-driven approach and coexistence mechanisms at the MAC and PHY layers.\nThis work may serve as a starting point for those who are interested in the\nunlicensed spectrum, both in academia and industry.",
    "pdf_url": "http://arxiv.org/pdf/2412.11002v1",
    "published": "2024-12-15T00:34:28+00:00",
    "categories": [
      "eess.SP",
      "cs.NI"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2412.11001v1",
    "title": "Two characteristic constants of the supercooled liquid transitions of amorphous substances",
    "authors": [
      "Wenlong Jiang"
    ],
    "abstract": "Supercooled liquid state is a particularly interesting state in that it\nexhibits several unusual physical properties. To illustrate, the liquid\ndisplays a single peak relaxation frequency at high temperatures, which splits\ninto $\\alpha$ relaxation and $\\beta$ relaxation in the moderately supercooled\nregime, with relaxation a disappearing at the glass transition temperature. The\nmechanism underlying these unusual physical properties of liquids has always\nbeen one of the important research topics in condensed matter. Here, a new\nmechanism is proposed. A distinctive physical state is built, and its most\nsalient feature is that its independent variables are difficult or impossible\nto measure. Theoretical calculations indicate that there exist two sets of\nmeasurable variables in this physical state that cannot be measure exactly\nsimultaneously. Moreover, it is easy to reach an erroneous conclusion, namely\nthat ``a system in this physical state is in a superposition of some real\nstates, until it is measured''. Further theoretical calculations demonstrate\nthat there are two new transitions and that $\\mathrm{e}^{3}$ and\n$2\\mathrm{e}^{3}$ are characteristic values of these two transitions,\nrespectively, where $\\mathrm{e}$ is Euler's number. Considerable experimental\ndata shows that the characteristic value of glass transition appears to be\nconcentrated near $2\\mathrm{e}^{3}$ and the characteristic value of another\ntransition (for example, the splitting of relaxation peak) appears to be\nconcentrated near $\\mathrm{e}^{3}$.",
    "pdf_url": "http://arxiv.org/pdf/2412.11001v1",
    "published": "2024-12-15T00:34:18+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2412.11000v2",
    "title": "Upper limit of spin relaxation in suspended graphene",
    "authors": [
      "Aron W. Cummings",
      "Simon M. -M. Dubois",
      "Pedro Alcázar Guerrero",
      "Jean-Christophe Charlier",
      "Stephan Roche"
    ],
    "abstract": "We use a combination of molecular dynamics and quantum transport simulations\nto investigate the upper limit of spin transport in suspended graphene. We find\nthat thermally-induced atomic-scale corrugations are the dominant factor,\nlimiting spin lifetimes to ~10 ns by inducing a strongly-varying local\nspin-orbit coupling. These extremely short-range corrugations appear even when\nthe height profile appears to be smooth, suggesting they may be present in any\ngraphene device. We discuss our results in the context of experiments, and\nbriefly consider approaches to suppress these short-range corrugations and\nfurther enhance spin lifetimes in graphene-based spin devices.",
    "pdf_url": "http://arxiv.org/pdf/2412.11000v2",
    "published": "2024-12-15T00:19:30+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  }
]