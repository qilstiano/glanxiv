[
  {
    "id": "http://arxiv.org/abs/2502.12390v1",
    "title": "Faster search for tensor decomposition over finite fields",
    "authors": [
      "Jason Yang"
    ],
    "abstract": "We present an $O^*(|\\mathbb{F}|^{\\min\\left\\{R,\\ \\sum_{d\\ge 2} n_d\\right\\} +\n(R-n_0)(\\sum_{d\\ne 0} n_d)})$-time algorithm for determining whether the rank\nof a concise tensor $T\\in\\mathbb{F}^{n_0\\times\\dots\\times n_{D-1}}$ is $\\le R$,\nassuming $n_0\\ge\\dots\\ge n_{D-1}$ and $R\\ge n_0$. For 3-dimensional tensors, we\nhave a second algorithm running in $O^*(|\\mathbb{F}|^{n_0+n_2 +\n(R-n_0+1-r_*)(n_1+n_2)+r_*^2})$ time, where\n$r_*:=\\left\\lfloor\\frac{R}{n_0}\\right\\rfloor+1$. Both algorithms use polynomial\nspace and improve on our previous work, which achieved running time\n$O^*(|\\mathbb{F}|^{n_0+(R-n_0)(\\sum_d n_d)})$.",
    "pdf_url": "http://arxiv.org/pdf/2502.12390v1",
    "published": "2025-02-17T23:59:24+00:00",
    "categories": [
      "cs.CC"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12389v1",
    "title": "Homogenization and Mean-Field Approximation for Multi-Player Games",
    "authors": [
      "Rama Cont",
      "Anran Hu"
    ],
    "abstract": "We investigate how the framework of mean-field games may be used to\ninvestigate strategic interactions in large heterogeneous populations. We\nconsider strategic interactions in a population of players which may be\npartitioned into near-homogeneous sub-populations subject to peer group effects\nand interactions across groups. We prove a quantitative homogenization result\nfor multi-player games in this setting: we show that $\\epsilon$-Nash equilibria\nof a general multi-player game with heterogeneity may be computed in terms of\nthe Nash equilibria of an auxiliary multi-population mean-field game. We\nprovide explicit and non-asymptotic bounds for the distance from optimality in\nterms of the number of players and the deviations from homogeneity in\nsub-populations. The best mean-field approximation corresponds to an optimal\npartition into sub-populations, which may be formulated as the solution of a\nmixed-integer program.",
    "pdf_url": "http://arxiv.org/pdf/2502.12389v1",
    "published": "2025-02-17T23:54:50+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12388v2",
    "title": "Achieving Upper Bound Accuracy of Joint Training in Continual Learning",
    "authors": [
      "Saleh Momeni",
      "Bing Liu"
    ],
    "abstract": "Continual learning has been an active research area in machine learning,\nfocusing on incrementally learning a sequence of tasks. A key challenge is\ncatastrophic forgetting (CF), and most research efforts have been directed\ntoward mitigating this issue. However, a significant gap remains between the\naccuracy achieved by state-of-the-art continual learning algorithms and the\nideal or upper-bound accuracy achieved by training all tasks together jointly.\nThis gap has hindered or even prevented the adoption of continual learning in\napplications, as accuracy is often of paramount importance. Recently, another\nchallenge, termed inter-task class separation (ICS), was also identified, which\nspurred a theoretical study into principled approaches for solving continual\nlearning. Further research has shown that by leveraging the theory and the\npower of large foundation models, it is now possible to achieve upper-bound\naccuracy, which has been empirically validated using both text and image\nclassification datasets. Continual learning is now ready for real-life\napplications. This paper surveys the main research leading to this achievement,\njustifies the approach both intuitively and from neuroscience research, and\ndiscusses insights gained.",
    "pdf_url": "http://arxiv.org/pdf/2502.12388v2",
    "published": "2025-02-17T23:54:43+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12387v1",
    "title": "Angular Resolution of Electrons in Gaseous Targets",
    "authors": [
      "Majd Ghrear",
      "Sven E. Vahsen"
    ],
    "abstract": "Low-energy electron recoils are of interest in several planned and proposed\nfuture nuclear and particle physics experiments. The topology and directions of\nsuch recoils provide important particle identification and kinematical\nconstraints, and are experimentally accessible in gaseous targets. Electron\nrecoils have complex trajectories, and the angular resolution that can be\nachieved has not been well understood. We have developed a method for\nestimating and optimizing this angular resolution, considering contributions\nfrom both multiple scattering and detection. First, we clarify that the formula\ncommonly used for multiple scattering through small angles is actually a fit to\nMoliere theory for heavy particles. We revise this formula so that it is\napplicable to electrons in gas. Next, we combine this with an effective point\nresolution contribution, which accounts for diffusion and detector effects, to\nobtain an approximation for the angular resolution. We identify the optimal fit\nlength and the corresponding optimal angular resolution. The result is a simple\nformula to estimate the best achievable angular resolution for electrons in\ngaseous detectors, given the electron energy and basic gas and detector\nproperties. Our model's predictions show good agreement with simulations. This\napproach can assist in the design of future experiments and the development of\nanalysis techniques. Given the widespread use of gaseous detectors, this work\nis relevant to many scientific communities.",
    "pdf_url": "http://arxiv.org/pdf/2502.12387v1",
    "published": "2025-02-17T23:54:36+00:00",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2502.12386v1",
    "title": "Bridging the Data Gap in AI Reliability Research and Establishing DR-AIR, a Comprehensive Data Repository for AI Reliability",
    "authors": [
      "Simin Zheng",
      "Jared M. Clark",
      "Fatemeh Salboukh",
      "Priscila Silva",
      "Karen da Mata",
      "Fenglian Pan",
      "Jie Min",
      "Jiayi Lian",
      "Caleb B. King",
      "Lance Fiondella",
      "Jian Liu",
      "Xinwei Deng",
      "Yili Hong"
    ],
    "abstract": "Artificial intelligence (AI) technology and systems have been advancing\nrapidly. However, ensuring the reliability of these systems is crucial for\nfostering public confidence in their use. This necessitates the modeling and\nanalysis of reliability data specific to AI systems. A major challenge in AI\nreliability research, particularly for those in academia, is the lack of\nreadily available AI reliability data. To address this gap, this paper focuses\non conducting a comprehensive review of available AI reliability data and\nestablishing DR-AIR: a data repository for AI reliability. Specifically, we\nintroduce key measurements and data types for assessing AI reliability, along\nwith the methodologies used to collect these data. We also provide a detailed\ndescription of the currently available datasets with illustrative examples.\nFurthermore, we outline the setup of the DR-AIR repository and demonstrate its\npractical applications. This repository provides easy access to datasets\nspecifically curated for AI reliability research. We believe these efforts will\nsignificantly benefit the AI research community by facilitating access to\nvaluable reliability data and promoting collaboration across various academic\ndomains within AI. We conclude our paper with a call to action, encouraging the\nresearch community to contribute and share AI reliability data to further\nadvance this critical field of study.",
    "pdf_url": "http://arxiv.org/pdf/2502.12386v1",
    "published": "2025-02-17T23:50:36+00:00",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12385v2",
    "title": "Programmable photonic waveguide arrays: opportunities and challenges",
    "authors": [
      "Yang Yang",
      "Akram Youssry",
      "Alberto Peruzzo"
    ],
    "abstract": "The field of programmable photonics has advanced significantly in recent\ndecades, driven by the rising demand for complex applications, such as optical\nquantum computing and photonic neural networks. However, as the complexity of\nthese applications increases, there is an increasing need for novel designs\nthat enhance circuit transmission and enable further miniaturization. Photonic\nwaveguide arrays (WAs) hold a unique position in integrated photonics, as they\nimplement ``always-on'' Hamiltonians and have no direct analogs in free-space\noptics. They find applications in various fields, including light propagation\nstudies, quantum walks, and topological photonics. Despite their versatility,\nthe lack of reconfigurability has limited their utility and hindered further\nadvancements for a long time. Recently, programmable waveguide arrays (PWAs)\nhave emerged as a promising solution for overcoming the limitations of static\nWAs and PWA-based architectures have been proven to be universal. This\nperspective proposes a vision for photonic circuits based on PWAs as a new,\ninterdisciplinary field. We review the history of the development of PWAs and\noutline their potential in areas such as simulation, communication, sensing,\nand classical and quantum information processing. This technology is expected\nto become increasingly feasible with advancements in programmable photonics,\nnanofabrication, and quantum control.",
    "pdf_url": "http://arxiv.org/pdf/2502.12385v2",
    "published": "2025-02-17T23:46:24+00:00",
    "categories": [
      "physics.optics",
      "quant-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.12384v1",
    "title": "Scalable Back-Propagation-Free Training of Optical Physics-Informed Neural Networks",
    "authors": [
      "Yequan Zhao",
      "Xinling Yu",
      "Xian Xiao",
      "Zhixiong Chen",
      "Ziyue Liu",
      "Geza Kurczveil",
      "Raymond G. Beausoleil",
      "Sijia Liu",
      "Zheng Zhang"
    ],
    "abstract": "Physics-informed neural networks (PINNs) have shown promise in solving\npartial differential equations (PDEs), with growing interest in their\nenergy-efficient, real-time training on edge devices. Photonic computing offers\na potential solution to achieve this goal because of its ultra-high operation\nspeed. However, the lack of photonic memory and the large device sizes prevent\ntraining real-size PINNs on photonic chips. This paper proposes a completely\nback-propagation-free (BP-free) and highly salable framework for training\nreal-size PINNs on silicon photonic platforms. Our approach involves three key\ninnovations: (1) a sparse-grid Stein derivative estimator to avoid the BP in\nthe loss evaluation of a PINN, (2) a dimension-reduced zeroth-order\noptimization via tensor-train decomposition to achieve better scalability and\nconvergence in BP-free training, and (3) a scalable on-chip photonic PINN\ntraining accelerator design using photonic tensor cores. We validate our\nnumerical methods on both low- and high-dimensional PDE benchmarks. Through\ncircuit simulation based on real device parameters, we further demonstrate the\nsignificant performance benefit (e.g., real-time training, huge chip area\nreduction) of our photonic accelerator.",
    "pdf_url": "http://arxiv.org/pdf/2502.12384v1",
    "published": "2025-02-17T23:45:23+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12383v1",
    "title": "Locally-Deployed Chain-of-Thought (CoT) Reasoning Model in Chemical Engineering: Starting from 30 Experimental Data",
    "authors": [
      "Tianhang Zhou",
      "Yingchun Niu",
      "Xingying Lan",
      "Chunming Xu"
    ],
    "abstract": "In the field of chemical engineering, traditional data-processing and\nprediction methods face significant challenges. Machine-learning and\nlarge-language models (LLMs) also have their respective limitations. This paper\nexplores the application of the Chain-of-Thought (CoT) reasoning model in\nchemical engineering, starting from 30 experimental data points. By integrating\ntraditional surrogate models like Gaussian processes and random forests with\npowerful LLMs such as DeepSeek-R1, a hierarchical architecture is proposed. Two\nCoT-building methods, Large Language Model-Chain of Thought (LLM-CoT) and\nMachine Learning-Large Language Model-Chain of Thought (ML-LLM-CoT), are\nstudied. The LLM-CoT combines local models DeepSeek-r1:14b and Qwen2:7b with\nOllama. The ML-LLM-CoT integrates a pre-trained Gaussian ML model with the\nLLM-based CoT framework. Our results show that during construction, ML-LLM-CoT\nis more efficient. It only has 2 points that require rethink and a total of 4\nrethink times, while LLM-CoT has 5 points that need to be re-thought and 34\ntotal rethink times. In predicting the solubility of 20 molecules with\ndissimilar structures, the number of molecules with a prediction deviation\nhigher than 100\\% for the Gaussian model, LLM-CoT, and ML-LLM-CoT is 7, 6, and\n4 respectively. These results indicate that ML-LLM-CoT performs better in\ncontrolling the number of high-deviation molecules, optimizing the average\ndeviation, and achieving a higher success rate in solubility judgment,\nproviding a more reliable method for chemical engineering and molecular\nproperty prediction. This study breaks through the limitations of traditional\nmethods and offers new solutions for rapid property prediction and process\noptimization in chemical engineering.",
    "pdf_url": "http://arxiv.org/pdf/2502.12383v1",
    "published": "2025-02-17T23:43:48+00:00",
    "categories": [
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12382v1",
    "title": "Hybrid Machine Learning Models for Intrusion Detection in IoT: Leveraging a Real-World IoT Dataset",
    "authors": [
      "Md Ahnaf Akif",
      "Ismail Butun",
      "Andre Williams",
      "Imadeldin Mahgoub"
    ],
    "abstract": "The rapid growth of the Internet of Things (IoT) has revolutionized\nindustries, enabling unprecedented connectivity and functionality. However,\nthis expansion also increases vulnerabilities, exposing IoT networks to\nincreasingly sophisticated cyberattacks. Intrusion Detection Systems (IDS) are\ncrucial for mitigating these threats, and recent advancements in Machine\nLearning (ML) offer promising avenues for improvement. This research explores a\nhybrid approach, combining several standalone ML models such as Random Forest\n(RF), XGBoost, K-Nearest Neighbors (KNN), and AdaBoost, in a voting-based\nhybrid classifier for effective IoT intrusion detection. This ensemble method\nleverages the strengths of individual algorithms to enhance accuracy and\naddress challenges related to data complexity and scalability. Using the\nwidely-cited IoT-23 dataset, a prominent benchmark in IoT cybersecurity\nresearch, we evaluate our hybrid classifiers for both binary and multi-class\nintrusion detection problems, ensuring a fair comparison with existing\nliterature. Results demonstrate that our proposed hybrid models, designed for\nrobustness and scalability, outperform standalone approaches in IoT\nenvironments. This work contributes to the development of advanced, intelligent\nIDS frameworks capable of addressing evolving cyber threats.",
    "pdf_url": "http://arxiv.org/pdf/2502.12382v1",
    "published": "2025-02-17T23:41:10+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12381v4",
    "title": "Linear Diffusion Networks",
    "authors": [
      "Jacob Fein-Ashley"
    ],
    "abstract": "We present Linear Diffusion Networks (LDNs), a novel architecture that\nreinterprets sequential data processing as a unified diffusion process. Our\nmodel integrates adaptive diffusion modules with localized nonlinear updates\nand a diffusion-inspired attention mechanism. This design enables efficient\nglobal information propagation while preserving fine-grained temporal details.\nLDN overcomes the limitations of conventional recurrent and transformer models\nby allowing full parallelization across time steps and supporting robust\nmulti-scale temporal representations. Experiments on benchmark sequence\nmodeling tasks demonstrate that LDN delivers competitive performance across\nImageNet and LRA tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.12381v4",
    "published": "2025-02-17T23:40:27+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12380v3",
    "title": "Nexus Machine: An Active Message Inspired Reconfigurable Architecture for Irregular Workloads",
    "authors": [
      "Rohan Juneja",
      "Pranav Dangi",
      "Thilini Kaushalya Bandara",
      "Tulika Mitra",
      "Li-shiuan Peh"
    ],
    "abstract": "Modern reconfigurable architectures are increasingly favored for\nresource-constrained edge devices as they balance high performance, energy\nefficiency, and programmability well. However, their proficiency in handling\nregular compute patterns constrains their effectiveness in executing irregular\nworkloads, such as sparse linear algebra and graph analytics with unpredictable\naccess patterns and control flow. To address this limitation, we introduce the\nNexus Machine, a novel reconfigurable architecture consisting of a PE array\ndesigned to efficiently handle irregularity by distributing sparse tensors\nacross the fabric and employing active messages that morph instructions based\non dynamic control flow. As the inherent irregularity in workloads can lead to\nhigh load imbalance among different Processing Elements (PEs), Nexus Machine\ndeploys and executes instructions en-route on idle PEs at run-time. Thus,\nunlike traditional reconfigurable architectures with only static instructions\nwithin each PE, Nexus Machine brings dynamic control to the idle compute units,\nmitigating load imbalance and enhancing overall performance. Our experiments\ndemonstrate that Nexus Machine achieves 90% better performance compared to\nstate-of-the-art (SOTA) reconfigurable architectures, within the same power\nbudget and area. Nexus Machine also achieves 70% higher fabric utilization, in\ncontrast to SOTA architectures.",
    "pdf_url": "http://arxiv.org/pdf/2502.12380v3",
    "published": "2025-02-17T23:34:41+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12379v1",
    "title": "OCT Data is All You Need: How Vision Transformers with and without Pre-training Benefit Imaging",
    "authors": [
      "Zihao Han",
      "Philippe De Wilde"
    ],
    "abstract": "Optical Coherence Tomography (OCT) provides high-resolution cross-sectional\nimages useful for diagnosing various diseases, but their distinct\ncharacteristics from natural images raise questions about whether large-scale\npre-training on datasets like ImageNet is always beneficial. In this paper, we\ninvestigate the impact of ImageNet-based pre-training on Vision Transformer\n(ViT) performance for OCT image classification across different dataset sizes.\nOur experiments cover four-category retinal pathologies (CNV, DME, Drusen,\nNormal). Results suggest that while pre-training can accelerate convergence and\npotentially offer better performance in smaller datasets, training from scratch\nmay achieve comparable or even superior accuracy when sufficient OCT data is\navailable. Our findings highlight the importance of matching domain\ncharacteristics in pre-training and call for further study on large-scale\nOCT-specific pre-training.",
    "pdf_url": "http://arxiv.org/pdf/2502.12379v1",
    "published": "2025-02-17T23:31:57+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12378v3",
    "title": "Pragmatics in the Era of Large Language Models: A Survey on Datasets, Evaluation, Opportunities and Challenges",
    "authors": [
      "Bolei Ma",
      "Yuting Li",
      "Wei Zhou",
      "Ziwei Gong",
      "Yang Janet Liu",
      "Katja Jasinskaja",
      "Annemarie Friedrich",
      "Julia Hirschberg",
      "Frauke Kreuter",
      "Barbara Plank"
    ],
    "abstract": "Understanding pragmatics-the use of language in context-is crucial for\ndeveloping NLP systems capable of interpreting nuanced language use. Despite\nrecent advances in language technologies, including large language models,\nevaluating their ability to handle pragmatic phenomena such as implicatures and\nreferences remains challenging. To advance pragmatic abilities in models, it is\nessential to understand current evaluation trends and identify existing\nlimitations. In this survey, we provide a comprehensive review of resources\ndesigned for evaluating pragmatic capabilities in NLP, categorizing datasets by\nthe pragmatic phenomena they address. We analyze task designs, data collection\nmethods, evaluation approaches, and their relevance to real-world applications.\nBy examining these resources in the context of modern language models, we\nhighlight emerging trends, challenges, and gaps in existing benchmarks. Our\nsurvey aims to clarify the landscape of pragmatic evaluation and guide the\ndevelopment of more comprehensive and targeted benchmarks, ultimately\ncontributing to more nuanced and context-aware NLP models.",
    "pdf_url": "http://arxiv.org/pdf/2502.12378v3",
    "published": "2025-02-17T23:31:38+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12377v2",
    "title": "Alignment and Adversarial Robustness: Are More Human-Like Models More Secure?",
    "authors": [
      "Blaine Hoak",
      "Kunyang Li",
      "Patrick McDaniel"
    ],
    "abstract": "A small but growing body of work has shown that machine learning models which\nbetter align with human vision have also exhibited higher robustness to\nadversarial examples, raising the question: can human-like perception make\nmodels more secure? If true generally, such mechanisms would offer new avenues\ntoward robustness. In this work, we conduct a large-scale empirical analysis to\nsystematically investigate the relationship between representational alignment\nand adversarial robustness. We evaluate 114 models spanning diverse\narchitectures and training paradigms, measuring their neural and behavioral\nalignment and engineering task performance across 105 benchmarks as well as\ntheir adversarial robustness via AutoAttack. Our findings reveal that while\naverage alignment and robustness exhibit a weak overall correlation, specific\nalignment benchmarks serve as strong predictors of adversarial robustness,\nparticularly those that measure selectivity toward texture or shape. These\nresults suggest that different forms of alignment play distinct roles in model\nrobustness, motivating further investigation into how alignment-driven\napproaches can be leveraged to build more secure and perceptually-grounded\nvision models.",
    "pdf_url": "http://arxiv.org/pdf/2502.12377v2",
    "published": "2025-02-17T23:30:50+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12376v1",
    "title": "The impact of job stability on monetary poverty in Italy: causal small area estimation",
    "authors": [
      "Katarzyna Reluga",
      "Dehan Kong",
      "Setareh Ranjbar",
      "Nicola Salvati",
      "Mark van der Laan"
    ],
    "abstract": "Job stability - encompassing secure contracts, adequate wages, social\nbenefits, and career opportunities - is a critical determinant in reducing\nmonetary poverty, as it provides households with reliable income and enhances\neconomic well-being. This study leverages EU-SILC survey and census data to\nestimate the causal effect of job stability on monetary poverty across Italian\nprovinces, quantifying its influence and analyzing regional disparities. We\nintroduce a novel causal small area estimation (CSAE) framework that integrates\nglobal and local estimation strategies for heterogeneous treatment effect\nestimation, effectively addressing data sparsity at the provincial level.\nFurthermore, we develop a general bootstrap scheme to construct reliable\nconfidence intervals, applicable regardless of the method used for estimating\nnuisance parameters. Extensive simulation studies demonstrate that our proposed\nestimators outperform classical causal inference methods in terms of stability\nwhile maintaining computational scalability for large datasets. Applying this\nmethodology to real-world data, we uncover significant relationships between\njob stability and poverty across six Italian regions, offering critical\ninsights into regional disparities and their implications for evidence-based\npolicy design.",
    "pdf_url": "http://arxiv.org/pdf/2502.12376v1",
    "published": "2025-02-17T23:30:27+00:00",
    "categories": [
      "stat.AP",
      "62P20, 62F40, 62D20, 62D05"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12375v1",
    "title": "UltraGen: Extremely Fine-grained Controllable Generation via Attribute Reconstruction and Global Preference Optimization",
    "authors": [
      "Longfei Yun",
      "Letian Peng",
      "Jingbo Shang"
    ],
    "abstract": "Fine granularity is an essential requirement for controllable text\ngeneration, which has seen rapid growth with the ability of LLMs. However,\nexisting methods focus mainly on a small set of attributes like 3 to 5, and\ntheir performance degrades significantly when the number of attributes\nincreases to the next order of magnitude. To address this challenge, we propose\na novel zero-shot approach for extremely fine-grained controllable generation\n(EFCG), proposing auto-reconstruction (AR) and global preference optimization\n(GPO). In the AR phase, we leverage LLMs to extract soft attributes (e.g.,\nEmphasis on simplicity and minimalism in design) from raw texts, and combine\nthem with programmatically derived hard attributes (e.g., The text should be\nbetween 300 and 400 words) to construct massive (around 45) multi-attribute\nrequirements, which guide the fine-grained text reconstruction process under\nweak supervision. In the GPO phase, we apply direct preference optimization\n(DPO) to refine text generation under diverse attribute combinations, enabling\nefficient exploration of the global combination space. Additionally, we\nintroduce an efficient attribute sampling strategy to identify and correct\npotentially erroneous attributes, further improving global optimization. Our\nframework significantly improves the constraint satisfaction rate (CSR) and\ntext quality for EFCG by mitigating position bias and alleviating attention\ndilution.",
    "pdf_url": "http://arxiv.org/pdf/2502.12375v1",
    "published": "2025-02-17T23:28:58+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12374v1",
    "title": "Eigenvalue distribution of the Hadamard product of sample covariance matrices in a quadratic regime",
    "authors": [
      "Sebastien Abou Assaly",
      "Lucas Benigni"
    ],
    "abstract": "In this note, we prove that if $X\\in\\mathbb{R}^{n\\times d}$ and\n$Y\\in\\mathbb{R}^{n\\times p}$ are two independent matrices with i.i.d entries\nthen the empirical spectral distribution of $\\frac{1}{d}XX^\\top \\odot\n\\frac{1}{p}YY^\\top$, where $\\odot$ denotes the Hadamard product, converges to\nthe Marchenko--Pastur distribution of shape $\\gamma$ in the quadratic regime of\ndimension $\\frac{n}{dp}\\to \\gamma$ and $\\frac{p}{d}\\to a$.",
    "pdf_url": "http://arxiv.org/pdf/2502.12374v1",
    "published": "2025-02-17T23:25:01+00:00",
    "categories": [
      "math.PR",
      "60B20, 15B52"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12373v1",
    "title": "Soft Robotics for Search and Rescue: Advancements, Challenges, and Future Directions",
    "authors": [
      "Abhishek Sebastian"
    ],
    "abstract": "Soft robotics has emerged as a transformative technology in Search and Rescue\n(SAR) operations, addressing challenges in navigating complex, hazardous\nenvironments that often limit traditional rigid robots. This paper critically\nexamines advancements in soft robotic technologies tailored for SAR\napplications, focusing on their unique capabilities in adaptability, safety,\nand efficiency. By leveraging bio-inspired designs, flexible materials, and\nadvanced locomotion mechanisms, such as crawling, rolling, and shape morphing,\nsoft robots demonstrate exceptional potential in disaster scenarios. However,\nsignificant barriers persist, including material durability, power\ninefficiency, sensor integration, and control complexity. This comprehensive\nreview highlights the current state of soft robotics in SAR, discusses\nsimulation methodologies and hardware validations, and introduces performance\nmetrics essential for their evaluation. By bridging the gap between theoretical\nadvancements and practical deployment, this study underscores the potential of\nsoft robotic systems to revolutionize SAR missions and advocates for continued\ninterdisciplinary innovation to overcome existing limitations.",
    "pdf_url": "http://arxiv.org/pdf/2502.12373v1",
    "published": "2025-02-17T23:24:18+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12372v1",
    "title": "Factual Inconsistency in Data-to-Text Generation Scales Exponentially with LLM Size: A Statistical Validation",
    "authors": [
      "Joy Mahapatra",
      "Soumyajit Roy",
      "Utpal Garain"
    ],
    "abstract": "Monitoring factual inconsistency is essential for ensuring trustworthiness in\ndata-to-text generation (D2T). While large language models (LLMs) have\ndemonstrated exceptional performance across various D2T tasks, previous studies\non scaling laws have primarily focused on generalization error through power\nlaw scaling to LLM size (i.e., the number of model parameters). However, no\nresearch has examined the impact of LLM size on factual inconsistency in D2T.\nIn this paper, we investigate how factual inconsistency in D2T scales with LLM\nsize by exploring two scaling laws: power law and exponential scaling. To\nrigorously evaluate and compare these scaling laws, we employ a statistical\nvalidation framework consisting of three key stages: predictive performance\nestimation, goodness-of-fit assessment, and comparative analysis. For a\ncomprehensive empirical study, we analyze three popular LLM families across\nfive D2T datasets, measuring factual inconsistency inversely using four\nstate-of-the-art consistency metrics. Our findings, based on exhaustive\nempirical results and validated through our framework, reveal that, contrary to\nthe widely assumed power law scaling, factual inconsistency in D2T follows an\nexponential scaling with LLM size.",
    "pdf_url": "http://arxiv.org/pdf/2502.12372v1",
    "published": "2025-02-17T23:24:00+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12371v2",
    "title": "IMLE Policy: Fast and Sample Efficient Visuomotor Policy Learning via Implicit Maximum Likelihood Estimation",
    "authors": [
      "Krishan Rana",
      "Robert Lee",
      "David Pershouse",
      "Niko Suenderhauf"
    ],
    "abstract": "Recent advances in imitation learning, particularly using generative\nmodelling techniques like diffusion, have enabled policies to capture complex\nmulti-modal action distributions. However, these methods often require large\ndatasets and multiple inference steps for action generation, posing challenges\nin robotics where the cost for data collection is high and computation\nresources are limited. To address this, we introduce IMLE Policy, a novel\nbehaviour cloning approach based on Implicit Maximum Likelihood Estimation\n(IMLE). IMLE Policy excels in low-data regimes, effectively learning from\nminimal demonstrations and requiring 38\\% less data on average to match the\nperformance of baseline methods in learning complex multi-modal behaviours. Its\nsimple generator-based architecture enables single-step action generation,\nimproving inference speed by 97.3\\% compared to Diffusion Policy, while\noutperforming single-step Flow Matching. We validate our approach across\ndiverse manipulation tasks in simulated and real-world environments, showcasing\nits ability to capture complex behaviours under data constraints. Videos and\ncode are provided on our project page: https://imle-policy.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2502.12371v2",
    "published": "2025-02-17T23:22:49+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12370v1",
    "title": "Positional Encoding in Transformer-Based Time Series Models: A Survey",
    "authors": [
      "Habib Irani",
      "Vangelis Metsis"
    ],
    "abstract": "Recent advancements in transformer-based models have greatly improved time\nseries analysis, providing robust solutions for tasks such as forecasting,\nanomaly detection, and classification. A crucial element of these models is\npositional encoding, which allows transformers to capture the intrinsic\nsequential nature of time series data. This survey systematically examines\nexisting techniques for positional encoding in transformer-based time series\nmodels. We investigate a variety of methods, including fixed, learnable,\nrelative, and hybrid approaches, and evaluate their effectiveness in different\ntime series classification tasks. Furthermore, we outline key challenges and\nsuggest potential research directions to enhance positional encoding\nstrategies. By delivering a comprehensive overview and quantitative\nbenchmarking, this survey intends to assist researchers and practitioners in\nselecting and designing effective positional encoding methods for\ntransformer-based time series models.",
    "pdf_url": "http://arxiv.org/pdf/2502.12370v1",
    "published": "2025-02-17T23:21:42+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12369v2",
    "title": "An a posteriori data-driven method for phase-averaged optical measurements",
    "authors": [
      "Enrico Amico",
      "Sara Montagner",
      "Jacopo Serpieri",
      "Gioacchino Cafiero"
    ],
    "abstract": "Phase-averaging is a fundamental approach for investigating periodic and\nnon-stationary phenomena. In fluid dynamics, these can be generated by rotating\nblades such as propellers/turbines or by pulsed jets. Traditional\nphase-averaging approaches often rely on synchronized data acquisition systems,\nwhich might require high-speed cameras, light sources, and precise delay\ngenerators and encoders, making them expensive and sometimes unfeasible. This\nwork proposes an a posteriori data-driven approach that reconstructs phase\ninformation from randomly acquired uncorrelated photographic frames (snapshots)\nusing the ISOMAP algorithm. The technique enables accurate reordering of\nsnapshots in the phase space and subsequent computation of the phase-averaged\nflow field without the need for synchronization. The framework was validated\nthrough numerical simulations and experimental fluid dynamics datasets from an\noptical setup featuring single- and multi-propeller configurations. The results\ndemonstrate that the proposed method effectively captures the periodic flow\ncharacteristics while addressing the challenges related to synchronization and\nhardware limitations. Furthermore, the ability to apply this technique to\narchival datasets extends its applicability to a wide range of experimental\nfluid dynamics studies. This approach provides a scalable and cost-effective\nalternative to traditional methods for the analysis of periodic phenomena.",
    "pdf_url": "http://arxiv.org/pdf/2502.12369v2",
    "published": "2025-02-17T23:19:45+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.data-an"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.12368v1",
    "title": "Recovery of the rod cross section shape",
    "authors": [
      "Vladislav V. Kravchenko",
      "Sergii M. Torba",
      "Alexander O. Vatulyan"
    ],
    "abstract": "A direct method for solving the inverse problem of determining the shape of\nthe cross section of a rod is proposed. The method is based on Neumann series\nof Bessel functions representations for solutions of Sturm-Liouville equations.\nThe first coefficient of the representation is sufficient for the recovery of\nthe unknown function. A system of linear algebraic equations for finding this\ncoefficient is obtained. The proposed method leads to an efficient numerical\nalgorithm.",
    "pdf_url": "http://arxiv.org/pdf/2502.12368v1",
    "published": "2025-02-17T23:18:58+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math-ph",
      "math.CA",
      "math.MP",
      "34A55, 34B05, 34B24, 34B60, 34L40, 35L05, 35R30, 65L09, 65N21"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12367v1",
    "title": "An edge crack and a crack close to the vertex of a wedge",
    "authors": [
      "Y. A. Antipov"
    ],
    "abstract": "Two model problems of an elastic wedge with an internal and edge crack are\nanalyzed. The problem of an internal crack reduces to an order-4 vector\nRiemann-Hilbert problem whose matrix kernel entries are meromorphic functions\nand have exponential factors. When the internal crack is located along one of\nthe wedge sides, an efficient method of solution is proposed. It requires a\nfactorization of the order-2 matrix coefficient associated with the\ncorresponding problem of an edge crack and the solution of an infinite system\nof linear algebraic system with an exponential rate of convergence of an\napproximate solution to the exact one. The order-2 Khrapkov's factorization is\nmodified by splitting the matrix kernel into a scalar dominant function and a\n``regular\" matrix whose factorization is more convenient for numerical\npurposes. Expressions for the stress intensity coefficients and the potential\nenergy released when the crack advances are derived. Asymptotic relations for\nthe stress intensity coefficients and the potential energy when one of the\ncrack tips is close the wedge vertex are obtained.",
    "pdf_url": "http://arxiv.org/pdf/2502.12367v1",
    "published": "2025-02-17T23:14:45+00:00",
    "categories": [
      "math.AP",
      "39Q15"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12366v1",
    "title": "ScriptoriumWS: A Code Generation Assistant for Weak Supervision",
    "authors": [
      "Tzu-Heng Huang",
      "Catherine Cao",
      "Spencer Schoenberg",
      "Harit Vishwakarma",
      "Nicholas Roberts",
      "Frederic Sala"
    ],
    "abstract": "Weak supervision is a popular framework for overcoming the labeled data\nbottleneck: the need to obtain labels for training data. In weak supervision,\nmultiple noisy-but-cheap sources are used to provide guesses of the label and\nare aggregated to produce high-quality pseudolabels. These sources are often\nexpressed as small programs written by domain experts -- and so are expensive\nto obtain. Instead, we argue for using code-generation models to act as coding\nassistants for crafting weak supervision sources. We study prompting strategies\nto maximize the quality of the generated sources, settling on a multi-tier\nstrategy that incorporates multiple types of information. We explore how to\nbest combine hand-written and generated sources. Using these insights, we\nintroduce ScriptoriumWS, a weak supervision system that, when compared to\nhand-crafted sources, maintains accuracy and greatly improves coverage.",
    "pdf_url": "http://arxiv.org/pdf/2502.12366v1",
    "published": "2025-02-17T23:07:14+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12365v1",
    "title": "On the Performance of Uplink Pinching Antenna Systems (PASS)",
    "authors": [
      "Tianwei Hou",
      "Yuanwei Liu",
      "Arumugam Nallanathan"
    ],
    "abstract": "Pinching antenna (PA) is a flexible antenna composed of a waveguide and\nmultiple dielectric particles, which is capable of reconfiguring wireless\nchannels intelligently in line-of-sight links. By leveraging the unique\nfeatures of PAs, we exploit the uplink (UL) transmission in pinching antenna\nsystems (PASS). To comprehensively evaluate the performance gains of PASS in UL\ntransmissions, three scenarios, multiple PAs for a single user (MPSU), a single\nPA for a single user (SPSU), and a single PA for multiple users (SPMU) are\nconsidered. The positions of PAs are optimized to obtain the maximal channel\ngains in the considered scenarios. For the MPSU and SPSU scenarios, by applying\nthe optimized position of PAs, closed-form expressions for analytical,\nasymptotic and approximated ergodic rate are derived. As the further advance,\nclosed-form expressions of approximated ergodic rate is derived when a single\nPA is fixed in the SPMU scenario. Our results demonstrate the following key\ninsights: i) The proposed PASS significantly outperforms conventional\nMultiple-input Single-output networks by exploiting the flexibility of PAs; ii)\nThe PA distribution follows an asymmetric non-uniform distribution in the MPSU\nscenario; iii) Optimizing PA positions significantly enhances the ergodic sum\nrate performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.12365v1",
    "published": "2025-02-17T23:06:35+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12364v1",
    "title": "Many-body theory and Gaussian-basis implementation of positron annihilation $Î³$-ray spectra on polyatomic molecules",
    "authors": [
      "S. K. Gregg",
      "J. P. Cassidy",
      "A. R. Swann",
      "J. Hofierka",
      "B. Cunningham",
      "D. G. Green"
    ],
    "abstract": "Doppler-broadened $\\gamma$-ray spectra for positron annihilation on molecules\nare calculated using many-body theory. By employing Gaussian bases for the\nelectron and positron wavefunctions, a computable expression that involves a\nfour-centre integral over the two-annihilation-photon momenta is derived for\nthe $\\gamma$ spectra in the independent particle model approximation to the\nannihilation vertex, and implemented in the open-source {\\tt EXCITON+} code.\nThe influence of electron-positron correlations on the $\\gamma$ spectra is\nexamined through \\textit{ab initio} treatment of the positron wavefunction,\nwhilst corrections to the annihilation vertex are treated approximately via\nenhancement factors previously calculated [D. G. Green and G. F. Gribakin,\nPhys.~Rev.~Lett.~{\\bf 114}, 093201 (2015)] exactly for atoms. Calculated\n$\\gamma$ spectra for furan and acetonitrile are presented for annihilation from\nthe positron bound state with electrons of individual molecular orbitals. For\nsuch annihilation from the positron-molecule bound state, it is found that the\nmagnitude of the partial contribution to the $\\gamma$ spectra from individual\nmolecular orbitals depends not just on the orbital energies, but also on the\nmolecular symmetry, more precisely the relative localisation of the positron\nand electron densities.",
    "pdf_url": "http://arxiv.org/pdf/2502.12364v1",
    "published": "2025-02-17T22:58:31+00:00",
    "categories": [
      "physics.atom-ph",
      "physics.atm-clus",
      "physics.chem-ph",
      "physics.comp-ph",
      "quant-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12363v1",
    "title": "A Pathwise Coordinate Descent Algorithm for LASSO Penalized Quantile Regression",
    "authors": [
      "Sanghee Kim",
      "Sumanta Basu"
    ],
    "abstract": "$\\ell_1$ penalized quantile regression is used in many fields as an\nalternative to penalized least squares regressions for high-dimensional data\nanalysis. Existing algorithms for penalized quantile regression either use\nlinear programming, which does not scale well in high dimension, or an\napproximate coordinate descent (CD) which does not solve for exact\ncoordinatewise minimum of the nonsmooth loss function. Further, neither\napproaches build fast, pathwise algorithms commonly used in high-dimensional\nstatistics to leverage sparsity structure of the problem in large-scale data\nsets. To avoid the computational challenges associated with the nonsmooth\nquantile loss, some recent works have even advocated using smooth\napproximations to the exact problem. In this work, we develop a fast, pathwise\ncoordinate descent algorithm to compute exact $\\ell_1$ penalized quantile\nregression estimates for high-dimensional data. We derive an easy-to-compute\nexact solution for the coordinatewise nonsmooth loss minimization, which, to\nthe best of our knowledge, has not been reported in the literature. We also\nemploy a random perturbation strategy to help the algorithm avoid getting stuck\nalong the regularization path. In simulated data sets, we show that our\nalgorithm runs substantially faster than existing alternatives based on\napproximate CD and linear program, while retaining the same level of estimation\naccuracy.",
    "pdf_url": "http://arxiv.org/pdf/2502.12363v1",
    "published": "2025-02-17T22:57:41+00:00",
    "categories": [
      "stat.CO",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12362v1",
    "title": "Classifiers of Data Sharing Statements in Clinical Trial Records",
    "authors": [
      "Saber Jelodari Mamaghani",
      "Cosima Strantz",
      "Dennis Toddenroth"
    ],
    "abstract": "Digital individual participant data (IPD) from clinical trials are\nincreasingly distributed for potential scientific reuse. The identification of\navailable IPD, however, requires interpretations of textual data-sharing\nstatements (DSS) in large databases. Recent advancements in computational\nlinguistics include pre-trained language models that promise to simplify the\nimplementation of effective classifiers based on textual inputs. In a subset of\n5,000 textual DSS from ClinicalTrials.gov, we evaluate how well classifiers\nbased on domain-specific pre-trained language models reproduce original\navailability categories as well as manually annotated labels. Typical metrics\nindicate that classifiers that predicted manual annotations outperformed those\nthat learned to output the original availability categories. This suggests that\nthe textual DSS descriptions contain applicable information that the\navailability categories do not, and that such classifiers could thus aid the\nautomatic identification of available IPD in large trial databases.",
    "pdf_url": "http://arxiv.org/pdf/2502.12362v1",
    "published": "2025-02-17T22:56:56+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7; J.3"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12361v3",
    "title": "ConFit v2: Improving Resume-Job Matching using Hypothetical Resume Embedding and Runner-Up Hard-Negative Mining",
    "authors": [
      "Xiao Yu",
      "Ruize Xu",
      "Chengyuan Xue",
      "Jinzhong Zhang",
      "Xu Ma",
      "Zhou Yu"
    ],
    "abstract": "A reliable resume-job matching system helps a company recommend suitable\ncandidates from a pool of resumes and helps a job seeker find relevant jobs\nfrom a list of job posts. However, since job seekers apply only to a few jobs,\ninteraction labels in resume-job datasets are sparse. We introduce ConFit v2,\nan improvement over ConFit to tackle this sparsity problem. We propose two\ntechniques to enhance the encoder's contrastive training process: augmenting\njob data with hypothetical reference resume generated by a large language\nmodel; and creating high-quality hard negatives from unlabeled resume/job pairs\nusing a novel hard-negative mining strategy. We evaluate ConFit v2 on two\nreal-world datasets and demonstrate that it outperforms ConFit and prior\nmethods (including BM25 and OpenAI text-embedding-003), achieving an average\nabsolute improvement of 13.8% in recall and 17.5% in nDCG across job-ranking\nand resume-ranking tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.12361v3",
    "published": "2025-02-17T22:56:42+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12360v2",
    "title": "Detecting Systematic Weaknesses in Vision Models along Predefined Human-Understandable Dimensions",
    "authors": [
      "Sujan Sai Gannamaneni",
      "Rohil Prakash Rao",
      "Michael Mock",
      "Maram Akila",
      "Stefan Wrobel"
    ],
    "abstract": "Slice discovery methods (SDMs) are prominent algorithms for finding\nsystematic weaknesses in DNNs. They identify top-k semantically coherent\nslices/subsets of data where a DNN-under-test has low performance. For being\ndirectly useful, slices should be aligned with human-understandable and\nrelevant dimensions, which, for example, are defined by safety and domain\nexperts as part of the operational design domain (ODD). While SDMs can be\napplied effectively on structured data, their application on image data is\ncomplicated by the lack of semantic metadata. To address these issues, we\npresent an algorithm that combines foundation models for zero-shot image\nclassification to generate semantic metadata with methods for combinatorial\nsearch to find systematic weaknesses in images. In contrast to existing\napproaches, ours identifies weak slices that are in line with pre-defined\nhuman-understandable dimensions. As the algorithm includes foundation models,\nits intermediate and final results may not always be exact. Therefore, we\ninclude an approach to address the impact of noisy metadata. We validate our\nalgorithm on both synthetic and real-world datasets, demonstrating its ability\nto recover human-understandable systematic weaknesses. Furthermore, using our\napproach, we identify systematic weaknesses of multiple pre-trained and\npublicly available state-of-the-art computer vision DNNs.",
    "pdf_url": "http://arxiv.org/pdf/2502.12360v2",
    "published": "2025-02-17T22:50:45+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12359v1",
    "title": "LanP: Rethinking the Impact of Language Priors in Large Vision-Language Models",
    "authors": [
      "Zongyu Wu",
      "Yuwei Niu",
      "Hongcheng Gao",
      "Minhua Lin",
      "Zhiwei Zhang",
      "Zhifang Zhang",
      "Qi Shi",
      "Yilong Wang",
      "Sike Fu",
      "Junjie Xu",
      "Junjie Ao",
      "Enyan Dai",
      "Lei Feng",
      "Xiang Zhang",
      "Suhang Wang"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have shown impressive performance in\nvarious tasks. However, LVLMs suffer from hallucination, which hinders their\nadoption in the real world. Existing studies emphasized that the strong\nlanguage priors of LVLMs can overpower visual information, causing\nhallucinations. However, the positive role of language priors is the key to a\npowerful LVLM. If the language priors are too weak, LVLMs will struggle to\nleverage rich parameter knowledge and instruction understanding abilities to\ncomplete tasks in challenging visual scenarios where visual information alone\nis insufficient. Therefore, we propose a benchmark called LanP to rethink the\nimpact of Language Priors in LVLMs. It is designed to investigate how strong\nlanguage priors are in current LVLMs. LanP consists of 170 images and 340\ncorresponding well-designed questions. Extensive experiments on 25 popular\nLVLMs reveal that many LVLMs' language priors are not strong enough to\neffectively aid question answering when objects are partially hidden. Many\nmodels, including GPT-4 Turbo, exhibit an accuracy below 0.5 in such a\nscenario.",
    "pdf_url": "http://arxiv.org/pdf/2502.12359v1",
    "published": "2025-02-17T22:48:34+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12358v2",
    "title": "Wavefront shaping enhanced nano-optomechanics down to the quantum precision limit",
    "authors": [
      "Alexandros G. Tavernarakis",
      "Rodrigo GutiÃ©rrez-Cuevas",
      "LoÃ¯c Rondin",
      "Thomas Antoni",
      "SÃ©bastien M. Popoff",
      "Pierre Verlot"
    ],
    "abstract": "We introduce wavefront shaping as a tool for optimizing the sensitivity in\nnano-optomechanical measurement schemes. We perform multimode output analysis\nof an optomechanical system consisting of a focused laser beam coupled to the\ntransverse motion of a tapered cantilever, and demonstrate that wavefront\nshaping enables a 350-fold enhancement of the measurement signal-to-noise\n(+25.5 dB) compared to standard split-detection, close to the quantum precision\nlimit. Our results open new perspectives in terms of sensitivity and control of\nthe optomechanical interaction.",
    "pdf_url": "http://arxiv.org/pdf/2502.12358v2",
    "published": "2025-02-17T22:47:40+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12357v2",
    "title": "The (universally) Japanese property for valuation rings and PrÃ¼fer domains",
    "authors": [
      "Shiji Lyu"
    ],
    "abstract": "We discuss the Japanese and universally Japanese properties for valuation\nrings and Pr\\\"ufer domains. These properties, regarding finiteness of integral\nclosure, have been studied extensively for Noetherian rings, but very rarely,\nif ever, for non-Noetherian rings. Among other results, we show that for\nvaluation rings and Pr\\\"ufer domains, the Japanese and universally Japanese\nproperties are equivalent. This result can be seen as a counterpart of Nagata's\nclassical result for Noetherian rings. This result also tells us many\nnon-Noetherian rings, including all absolutely integrally closed valuation\nrings and Pr\\\"ufer domains, are universally Japanese.",
    "pdf_url": "http://arxiv.org/pdf/2502.12357v2",
    "published": "2025-02-17T22:46:28+00:00",
    "categories": [
      "math.AC"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12356v1",
    "title": "Edge non-collinear magnetism in nanoribbons of Fe3GeTe2 and Fe3GaTe2",
    "authors": [
      "R. Cardias",
      "Anders Bergman",
      "Hugo U. R. Strand",
      "R. B. Muniz",
      "Marcio Costa"
    ],
    "abstract": "Fe3GeTe2 and Fe3GaTe2 are ferromagnetic conducting materials of van der\nWaals-type with unique magnetic properties that are highly promising for the\ndevelopment of new spintronic, orbitronic and magnonic devices. Even in the\nform of two-dimensional-like ultrathin films, they exhibit relatively high\nCurie temperature, magnetic anisotropy perpendicular to the atomic planes and\nmultiple types of Hall effects. We explore nanoribbons made from single layers\nof these materials and show that they display non-collinear magnetic ordering\nat their edges. This magnetic inhomogeneity allows angular momentum currents to\ngenerate magnetic torques at the sample edges, regardless of their polarization\ndirection, significantly enhancing the effectiveness of magnetization\nmanipulation in these systems. We also demonstrate that it is possible to\nrapidly reverse the magnetization direction of these nanostructures by means of\nspin-orbit and spin-transfer torques with rather low current densities, making\nthem quite propitious for non-volatile magnetic memory units.",
    "pdf_url": "http://arxiv.org/pdf/2502.12356v1",
    "published": "2025-02-17T22:46:00+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.12355v1",
    "title": "Hovering Flight of Soft-Actuated Insect-Scale Micro Aerial Vehicles using Deep Reinforcement Learning",
    "authors": [
      "Yi-Hsuan Hsiao",
      "Wei-Tung Chen",
      "Yun-Sheng Chang",
      "Pulkit Agrawal",
      "YuFeng Chen"
    ],
    "abstract": "Soft-actuated insect-scale micro aerial vehicles (IMAVs) pose unique\nchallenges for designing robust and computationally efficient controllers. At\nthe millimeter scale, fast robot dynamics ($\\sim$ms), together with system\ndelay, model uncertainty, and external disturbances significantly affect flight\nperformances. Here, we design a deep reinforcement learning (RL) controller\nthat addresses system delay and uncertainties. To initialize this neural\nnetwork (NN) controller, we propose a modified behavior cloning (BC) approach\nwith state-action re-matching to account for delay and domain-randomized expert\ndemonstration to tackle uncertainty. Then we apply proximal policy optimization\n(PPO) to fine-tune the policy during RL, enhancing performance and smoothing\ncommands. In simulations, our modified BC substantially increases the mean\nreward compared to baseline BC; and RL with PPO improves flight quality and\nreduces command fluctuations. We deploy this controller on two different\ninsect-scale aerial robots that weigh 720 mg and 850 mg, respectively. The\nrobots demonstrate multiple successful zero-shot hovering flights, with the\nlongest lasting 50 seconds and root-mean-square errors of 1.34 cm in lateral\ndirection and 0.05 cm in altitude, marking the first end-to-end deep RL-based\nflight on soft-driven IMAVs.",
    "pdf_url": "http://arxiv.org/pdf/2502.12355v1",
    "published": "2025-02-17T22:45:59+00:00",
    "categories": [
      "cs.RO",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12354v2",
    "title": "Human-centered explanation does not fit all: The interplay of sociotechnical, cognitive, and individual factors in the effect AI explanations in algorithmic decision-making",
    "authors": [
      "Yongsu Ahn",
      "Yu-Ru Lin",
      "Malihe Alikhani",
      "Eunjeong Cheon"
    ],
    "abstract": "Recent XAI studies have investigated what constitutes a \\textit{good}\nexplanation in AI-assisted decision-making. Despite the widely accepted\nhuman-friendly properties of explanations, such as contrastive and selective,\nexisting studies have yielded inconsistent findings. To address these gaps, our\nstudy focuses on the cognitive dimensions of explanation evaluation, by\nevaluating six explanations with different contrastive strategies and\ninformation selectivity and scrutinizing factors behind their valuation\nprocess. Our analysis results find that contrastive explanations are not the\nmost preferable or understandable in general; Rather, different contrastive and\nselective explanations were appreciated to a different extent based on who they\nare, when, how, and what to explain -- with different level of cognitive load\nand engagement and sociotechnical contexts. Given these findings, we call for a\nnuanced view of explanation strategies, with implications for designing AI\ninterfaces to accommodate individual and contextual differences in AI-assisted\ndecision-making.",
    "pdf_url": "http://arxiv.org/pdf/2502.12354v2",
    "published": "2025-02-17T22:42:53+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.12353v1",
    "title": "Stability-based Generalization Bounds for Variational Inference",
    "authors": [
      "Yadi Wei",
      "Roni Khardon"
    ],
    "abstract": "Variational inference (VI) is widely used for approximate inference in\nBayesian machine learning. In addition to this practical success,\ngeneralization bounds for variational inference and related algorithms have\nbeen developed, mostly through the connection to PAC-Bayes analysis. A second\nline of work has provided algorithm-specific generalization bounds through\nstability arguments or using mutual information bounds, and has shown that the\nbounds are tight in practice, but unfortunately these bounds do not directly\napply to approximate Bayesian algorithms. This paper fills this gap by\ndeveloping algorithm-specific stability based generalization bounds for a class\nof approximate Bayesian algorithms that includes VI, specifically when using\nstochastic gradient descent to optimize their objective. As in the non-Bayesian\ncase, the generalization error is bounded by by expected parameter differences\non a perturbed dataset. The new approach complements PAC-Bayes analysis and can\nprovide tighter bounds in some cases. An experimental illustration shows that\nthe new approach yields non-vacuous bounds on modern neural network\narchitectures and datasets and that it can shed light on performance\ndifferences between variant approximate Bayesian algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2502.12353v1",
    "published": "2025-02-17T22:40:26+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12352v2",
    "title": "Towards Mechanistic Interpretability of Graph Transformers via Attention Graphs",
    "authors": [
      "Batu El",
      "Deepro Choudhury",
      "Pietro LiÃ²",
      "Chaitanya K. Joshi"
    ],
    "abstract": "We introduce Attention Graphs, a new tool for mechanistic interpretability of\nGraph Neural Networks (GNNs) and Graph Transformers based on the mathematical\nequivalence between message passing in GNNs and the self-attention mechanism in\nTransformers. Attention Graphs aggregate attention matrices across Transformer\nlayers and heads to describe how information flows among input nodes. Through\nexperiments on homophilous and heterophilous node classification tasks, we\nanalyze Attention Graphs from a network science perspective and find that: (1)\nWhen Graph Transformers are allowed to learn the optimal graph structure using\nall-to-all attention among input nodes, the Attention Graphs learned by the\nmodel do not tend to correlate with the input/original graph structure; and (2)\nFor heterophilous graphs, different Graph Transformer variants can achieve\nsimilar performance while utilising distinct information flow patterns. Open\nsource code: https://github.com/batu-el/understanding-inductive-biases-of-gnns",
    "pdf_url": "http://arxiv.org/pdf/2502.12352v2",
    "published": "2025-02-17T22:35:16+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2503.03756v1",
    "title": "Efficient Finetuning for Dimensional Speech Emotion Recognition in the Age of Transformers",
    "authors": [
      "Aneesha Sampath",
      "James Tavernor",
      "Emily Mower Provost"
    ],
    "abstract": "Accurate speech emotion recognition is essential for developing human-facing\nsystems. Recent advancements have included finetuning large, pretrained\ntransformer models like Wav2Vec 2.0. However, the finetuning process requires\nsubstantial computational resources, including high-memory GPUs and significant\nprocessing time. As the demand for accurate emotion recognition continues to\ngrow, efficient finetuning approaches are needed to reduce the computational\nburden. Our study focuses on dimensional emotion recognition, predicting\nattributes such as activation (calm to excited) and valence (negative to\npositive). We present various finetuning techniques, including full finetuning,\npartial finetuning of transformer layers, finetuning with mixed precision,\npartial finetuning with caching, and low-rank adaptation (LoRA) on the Wav2Vec\n2.0 base model. We find that partial finetuning with mixed precision achieves\nperformance comparable to full finetuning while increasing training speed by\n67%. Caching intermediate representations further boosts efficiency, yielding\nan 88% speedup and a 71% reduction in learnable parameters. We recommend\nfinetuning the final three transformer layers in mixed precision to balance\nperformance and training efficiency, and adding intermediate representation\ncaching for optimal speed with minimal performance trade-offs. These findings\nlower the barriers to finetuning speech emotion recognition systems, making\naccurate emotion recognition more accessible to a broader range of researchers\nand practitioners.",
    "pdf_url": "http://arxiv.org/pdf/2503.03756v1",
    "published": "2025-02-17T22:34:08+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2502.12351v1",
    "title": "Modelling the impact of Multi Cancer Early Detection tests: a review of natural history of disease models",
    "authors": [
      "O Mandrik",
      "S Whyte",
      "N Kunst",
      "A Rayner",
      "M Harden",
      "S Dias",
      "K Payne",
      "S Palmer",
      "MO Soares"
    ],
    "abstract": "Introduction: The potential for multi-cancer early detection (MCED) tests to\ndetect cancer at earlier stages is currently being evaluated in screening\nclinical trials. Once trial evidence becomes available, modelling will be\nnecessary to predict impacts on final outcomes (benefits and harms), account\nfor heterogeneity in determining clinical and cost-effectiveness, and explore\nalternative screening programme specifications. The natural history of disease\n(NHD) component of a MCED model will use statistical, mathematical or\ncalibration methods. Methods: Modelling approaches for MCED screening that\ninclude an NHD component were identified from the literature, reviewed and\ncritically appraised. Purposively selected (non-MCED) cancer screening models\nwere also reviewed. The appraisal focussed on the scope, data sources,\nevaluation approaches and the structure and parameterisation of the models.\nResults: Five different MCED NHD models were identified and reviewed, alongside\nfour additional (non-MCED) models. The critical appraisal highlighted several\nfeatures of this literature. In the absence of trial evidence, MCED effects are\nbased on predictions derived from test accuracy. These predictions rely on\nsimplifying assumptions with unknown impacts, such as the stage-shift\nassumption used to estimate mortality impacts from predicted stage-shifts. None\nof the MCED models fully characterised uncertainty in the NHD or examined\nuncertainty in the stage-shift assumption. Conclusion: MCED technologies are\ndeveloping rapidly, and large and costly clinical studies are being designed\nand implemented across the globe. Currently there is no modelling approach that\ncan integrate clinical study evidence and therefore, in support of policy, it\nis important that similar efforts are made in the development of MCED models\nthat make best use of the available data on benefits and harms.",
    "pdf_url": "http://arxiv.org/pdf/2502.12351v1",
    "published": "2025-02-17T22:32:35+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.12350v1",
    "title": "Mamute: high-performance computing for geophysical methods",
    "authors": [
      "JoÃ£o B. Fernandes",
      "AntÃ´nio D. S. Oliveira",
      "Mateus C. A. T. Silva",
      "Felipe H. Santos-da-Silva",
      "Vitor H. M. Rodrigues",
      "Kleiton A. Schneider",
      "Calebe P. Bianchini",
      "JoÃ£o M. de Araujo",
      "Tiago Barros",
      "Ãtalo A. S. Assis",
      "Samuel Xavier-de-Souza"
    ],
    "abstract": "Due to their high computational cost, geophysical applications are typically\ndesigned to run in large computing systems. Because of that, such applications\nmust implement several high-performance techniques to use the computational\nresources better. In this paper, we present Mamute, a software that delivers\nwave equation-based geophysical methods. Mamute implements two geophysical\nmethods: seismic modeling and full waveform inversion (FWI). It also supports\nhigh-performance strategies such as fault tolerance, automatic parallel looping\nscheduling, and distributed systems workload balancing. We demonstrate Mamute's\noperation using both seismic modeling and FWI. Mamute is a C++ software readily\navailable under the MIT license.",
    "pdf_url": "http://arxiv.org/pdf/2502.12350v1",
    "published": "2025-02-17T22:31:59+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12349v1",
    "title": "Quantitative diagnosis of amyloid without Congo red staining using polarized light microscopy",
    "authors": [
      "Owen Lailey",
      "Maria Agustina Alais",
      "Liuhe Wang",
      "Pinki Chahal",
      "David G. Cory",
      "Timothy Khoo",
      "Ekaterina Olkhov-Mitsel",
      "Dusan Sarenac",
      "Dmitry A. Pushin",
      "Jelena Mirkovic"
    ],
    "abstract": "Amyloidosis is a protein misfolding disease caused by the deposition of\nlarge, insoluble aggregates (amyloid fibrils) of protein in a tissue, which has\nbeen associated with various conditions, such as lymphoid disorders,\nAlzheimer's disease, diabetes mellitus type 2, chronic inflammatory processes,\nand cancers. Amyloid fibrils are commonly diagnosed by qualitative observation\nof green birefringence from Congo red stained biopsy tissue samples under\npolarized light, a technique that is limited by lack of specificity, dependence\non subjective interpretation, and technical constraints. Studies emphasize the\nutility of quantitative polarized light microscopy (PLM) methodology to\ndiagnose amyloid fibrils in Congo red stained tissues. However, while Congo red\nenhances the intrinsic birefringence of amyloid fibrillar structures, there are\nsignificant disadvantages such as the appearance of multiple non-green colors\nunder polarized light and binding to other structures, which may result in\nmisdiagnoses with Congo red dye and inconclusive explanations. In this work, we\npresent an improved PLM methodology for quantitative detection of amyloid\nfibrils without requiring Congo red staining. We perform PLM measurements on\nfour tissues: abdominal subcutaneous tissue biopsy, duodenal biopsy, thyroid\nbiopsy, and breast biopsy, both with Congo red stain and H\\&E stain, and\nthrough Fourier analysis quantify birefringence, birefringent axis orientation,\ndichroism, optical activity, and relative amyloid density. These results\nemphasize a quantitative analysis for amyloid diagnosis rooted in Fourier\nsignal harmonics that does not require Congo red dye and paves the way for\nrapid, simple, and accurate diagnosis of amyloid fibrils.",
    "pdf_url": "http://arxiv.org/pdf/2502.12349v1",
    "published": "2025-02-17T22:31:02+00:00",
    "categories": [
      "physics.med-ph"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12348v1",
    "title": "Robust Steady-State-Aware Model Predictive Control for Systems with Limited Computational Resources and External Disturbances",
    "authors": [
      "Hassan Jafari Ozoumchelooei",
      "Mehdi Hosseinzadeh"
    ],
    "abstract": "Model Predictive Control (MPC) is a powerful control strategy; however, its\nreliance on online optimization poses significant challenges for implementation\non systems with limited computational resources. One possible approach to\naddress this issue is to shorten the prediction horizon and adjust the\nconventional MPC formulation to enlarge the region of attraction. However,\nthese methods typically introduce additional computational load. Recently,\nsteady-state-aware MPC has been introduced to ensure output tracking and\nconvergence to a given desired steady-state configuration while maintaining\nconstraint satisfaction at all times without adding extra computational load.\nDespite its promising performance, steady-state-aware MPC does not account for\nexternal disturbances, which can significantly limit its applicability to\nreal-world systems. This paper aims to advance the method further by enhancing\nits robustness against external disturbances. To achieve this, we adopt the\ntube-based design framework, which decouples nominal trajectory optimization\nfrom robust control synthesis, thereby requiring no additional online\ncomputational resources. Theoretical guarantees of the proposed methodology are\nshown analytically, and its effectiveness is assessed through simulations and\nexperimental studies on a Parrot Bebop 2 drone.",
    "pdf_url": "http://arxiv.org/pdf/2502.12348v1",
    "published": "2025-02-17T22:23:57+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12347v2",
    "title": "Improving Grip Stability Using Passive Compliant Microspine Arrays for Soft Robots in Unstructured Terrain",
    "authors": [
      "Lauren Ervin",
      "Harish Bezawada",
      "Vishesh Vikas"
    ],
    "abstract": "Microspine grippers are small spines commonly found on insect legs that\nreinforce surface interaction by engaging with asperities to increase shear\nforce and traction. An array of such microspines, when integrated into the\nlimbs or undercarriage of a robot, can provide the ability to maneuver uneven\nterrains, traverse inclines, and even climb walls. Conformability and\nadaptability of soft robots makes them ideal candidates for these applications\ninvolving traversal of complex, unstructured terrains. However, there remains a\nreal-life realization gap for soft locomotors pertaining to their transition\nfrom controlled lab environment to the field by improving grip stability\nthrough effective integration of microspines. We propose a passive, compliant\nmicrospine stacked array design to enhance the locomotion capabilities of\nmobile soft robots, in our case, ones that are motor tendon actuated. We offer\na standardized microspine array integration method with effective\nsoft-compliant stiffness integration, and reduced complexity resulting from a\nsingle actuator passively controlling them. The presented design utilizes a\ntwo-row, stacked microspine array configuration that offers additional gripping\ncapabilities on extremely steep/irregular surfaces from the top row while not\nhindering the effectiveness of the more frequently active bottom row. We\nexplore different configurations of the microspine array to account for\nchanging surface topologies and enable independent, adaptable gripping of\nasperities per microspine. Field test experiments are conducted on various\nrough surfaces including concrete, brick, compact sand, and tree roots with\nthree robots consisting of a baseline without microspines compared against two\nrobots with different combinations of microspine arrays. Tracking results\nindicate that the inclusion of microspine arrays increases planar displacement\non average by 15 and 8 times.",
    "pdf_url": "http://arxiv.org/pdf/2502.12347v2",
    "published": "2025-02-17T22:23:39+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12346v1",
    "title": "QuZO: Quantized Zeroth-Order Fine-Tuning for Large Language Models",
    "authors": [
      "Jiajun Zhou",
      "Yifan Yang",
      "Kai Zhen",
      "Ziyue Liu",
      "Yequan Zhao",
      "Ershad Banijamali",
      "Athanasios Mouchtaris",
      "Ngai Wong",
      "Zheng Zhang"
    ],
    "abstract": "Language Models (LLMs) are often quantized to lower precision to reduce the\nmemory cost and latency in inference. However, quantization often degrades\nmodel performance, thus fine-tuning is required for various down-stream tasks.\nTraditional fine-tuning methods such as stochastic gradient descent and Adam\noptimization require backpropagation, which are error-prone in the\nlow-precision settings. To overcome these limitations, we propose the Quantized\nZeroth-Order (QuZO) framework, specifically designed for fine-tuning LLMs\nthrough low-precision (e.g., 4- or 8-bit) forward passes. Our method can avoid\nthe error-prone low-precision straight-through estimator, and utilizes\noptimized stochastic rounding to mitigate the increased bias. QuZO simplifies\nthe training process, while achieving results comparable to first-order methods\nin ${\\rm FP}8$ and superior accuracy in ${\\rm INT}8$ and ${\\rm INT}4$ training.\nExperiments demonstrate that low-bit training QuZO achieves performance\ncomparable to MeZO optimization on GLUE, Multi-Choice, and Generation tasks,\nwhile reducing memory cost by $2.94 \\times$ in LLaMA2-7B fine-tuning compared\nto quantized first-order methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.12346v1",
    "published": "2025-02-17T22:20:31+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12345v1",
    "title": "Uncertainty quantification for stationary and time-dependent PDEs subject to Gevrey regular random domain deformations",
    "authors": [
      "Ana Djurdjevac",
      "Vesa Kaarnioja",
      "Claudia Schillings",
      "AndrÃ©-Alexander Zepernick"
    ],
    "abstract": "We study uncertainty quantification for partial differential equations\nsubject to domain uncertainty. We parameterize the random domain using the\nmodel recently considered by Chernov and Le (2024) as well as Harbrecht,\nSchmidlin, and Schwab (2024) in which the input random field is assumed to\nbelong to a Gevrey smoothness class. This approach has the advantage of being\nsubstantially more general than models which assume a particular parametric\nrepresentation of the input random field such as a Karhunen-Loeve series\nexpansion. We consider both the Poisson equation as well as the heat equation\nand design randomly shifted lattice quasi-Monte Carlo (QMC) cubature rules for\nthe computation of the expected solution under domain uncertainty. We show that\nthese QMC rules exhibit dimension-independent, essentially linear cubature\nconvergence rates in this framework. In addition, we complete the error\nanalysis by taking into account the approximation errors incurred by dimension\ntruncation of the random input field and finite element discretization.\nNumerical experiments are presented to confirm the theoretical rates.",
    "pdf_url": "http://arxiv.org/pdf/2502.12345v1",
    "published": "2025-02-17T22:18:50+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65D30, 65D32, 35R60"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12344v1",
    "title": "Hardware-Software Co-Design for Accelerating Transformer Inference Leveraging Compute-in-Memory",
    "authors": [
      "Dong Eun Kim",
      "Tanvi Sharma",
      "Kaushik Roy"
    ],
    "abstract": "Transformers have become the backbone of neural network architecture for most\nmachine learning applications. Their widespread use has resulted in multiple\nefforts on accelerating attention, the basic building block of transformers.\nThis paper tackles the challenges associated with accelerating attention\nthrough a hardware-software co-design approach while leveraging\ncompute-in-memory(CIM) architecture. In particular, our energy- and\narea-efficient CIM based accelerator, named HASTILY, aims to accelerate softmax\ncomputation, an integral operation in attention, and minimize their high\non-chip memory requirements that grows quadratically with input sequence\nlength. Our architecture consists of novel CIM units called unified compute and\nlookup modules(UCLMs) that integrate both lookup and multiply-accumulate\nfunctionality within the same SRAM array, incurring minimal area overhead over\nstandard CIM arrays. Designed in TSMC 65nm, UCLMs can be used to concurrently\nperform exponential and matrix-vector multiplication operations. Complementing\nthe proposed architecture, HASTILY features a fine-grained pipelining strategy\nfor scheduling both attention and feed-forward layers, to reduce the quadratic\ndependence on sequence length to linear dependence. Further, for fast softmax\ncomputation which involves computing the maxima and sum of exponential values,\nsuch operations are parallelized across multiple cores using reduce and gather\nstrategy. We evaluate our proposed architecture using a compiler tailored\ntowards attention computation and a standard cycle-level CIM simulator. Our\nevaluation shows end-to-end throughput(TOPS) improvement of 4.4x-9.8x and\n1.7x-5.9x over Nvidia A40 GPU and baseline CIM hardware, respectively, for BERT\nmodels with INT-8 precision. Additionally, it shows gains of 16x-36x in\nenergy-efficiency(TOPS/W) over A40 GPU and similar energy-efficiency as\nbaseline CIM hardware.",
    "pdf_url": "http://arxiv.org/pdf/2502.12344v1",
    "published": "2025-02-17T22:16:34+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12343v1",
    "title": "Energy-Efficient Flat Precoding for MIMO Systems",
    "authors": [
      "Foad Sohrabi",
      "Carl Nuzman",
      "Jinfeng Du",
      "Hong Yang",
      "Harish Viswanathan"
    ],
    "abstract": "This paper addresses the suboptimal energy efficiency of conventional digital\nprecoding schemes in multiple-input multiple-output (MIMO) systems. Through an\nanalysis of the power amplifier (PA) output power distribution associated with\nconventional precoders, it is observed that these power distributions can be\nquite uneven, resulting in large PA backoff (thus low efficiency) and high\npower consumption. To tackle this issue, we propose a novel approach called\nflat precoding, which aims to control the flatness of the power distribution\nwithin a desired interval. In addition to reducing PA power consumption, flat\nprecoding offers the advantage of requiring smaller saturation levels for PAs,\nwhich reduces the size of PAs and lowers the cost. To incorporate the concept\nof flat power distribution into precoding design, we introduce a new\nlower-bound per-antenna power constraint alongside the conventional sum power\nconstraint and the upper-bound per-antenna power constraint. By adjusting the\nlower-bound and upper-bound values, we can effectively control the level of\nflatness in the power distribution. We then seek to find a flat precoder that\nsatisfies these three sets of constraints while maximizing the weighted sum\nrate (WSR). In particular, we develop efficient algorithms to design weighted\nminimum mean squared error (WMMSE) and zero-forcing (ZF)-type precoders with\ncontrollable flatness features that maximize WSR. Numerical results demonstrate\nthat complete flat precoding approaches, where the power distribution is a\nstraight line, achieve the best trade-off between spectral efficiency and\nenergy efficiency for existing PA technologies. We also show that the proposed\nZF and WMMSE precoding methods can approach the performance of their\nconventional counterparts with only the sum power constraint, while\nsignificantly reducing PA size and power consumption.",
    "pdf_url": "http://arxiv.org/pdf/2502.12343v1",
    "published": "2025-02-17T22:12:48+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12342v1",
    "title": "REAL-MM-RAG: A Real-World Multi-Modal Retrieval Benchmark",
    "authors": [
      "Navve Wasserman",
      "Roi Pony",
      "Oshri Naparstek",
      "Adi Raz Goldfarb",
      "Eli Schwartz",
      "Udi Barzelay",
      "Leonid Karlinsky"
    ],
    "abstract": "Accurate multi-modal document retrieval is crucial for Retrieval-Augmented\nGeneration (RAG), yet existing benchmarks do not fully capture real-world\nchallenges with their current design. We introduce REAL-MM-RAG, an\nautomatically generated benchmark designed to address four key properties\nessential for real-world retrieval: (i) multi-modal documents, (ii) enhanced\ndifficulty, (iii) Realistic-RAG queries and (iv) accurate labeling.\nAdditionally, we propose a multi-difficulty-level scheme based on query\nrephrasing to evaluate models' semantic understanding beyond keyword matching.\nOur benchmark reveals significant model weaknesses, particularly in handling\ntable-heavy documents and robustness to query rephrasing. To mitigate these\nshortcomings, we curate a rephrased training set and introduce a new\nfinance-focused, table-heavy dataset. Fine-tuning on these datasets enables\nmodels to achieve state-of-the-art retrieval performance on REAL-MM-RAG\nbenchmark. Our work offers a better way to evaluate and improve retrieval in\nmulti-modal RAG systems while also providing training data and models that\naddress current limitations.",
    "pdf_url": "http://arxiv.org/pdf/2502.12342v1",
    "published": "2025-02-17T22:10:47+00:00",
    "categories": [
      "cs.IR",
      "cs.CV"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12341v1",
    "title": "Multivariable $p$-adic Hodge theory for products of Galois groups",
    "authors": [
      "LÃ©o Poyeton",
      "Pietro Vanni"
    ],
    "abstract": "In this paper we explain how to attach to a family of $p$-adic\nrepresentations of a product of Galois groups an overconvergent family of\nmultivariable $(\\varphi,\\Gamma)$-modules, generalizing results from Pal-Zabradi\nand Carter-Kedlaya-Zabradi, using Colmez-Sen-Tate descent. We also define rings\nof multivariable crystalline and semistable periods, and explain how to recover\nthis multivariable $p$-adic theory attached to a family of representations from\nits multivariable $(\\varphi,\\Gamma)$-module. We also explain how our framework\nallows us to recover the main results of Brinon-Chiarellotto-Mazzari on\nmultivariable $p$-adic Galois representations.",
    "pdf_url": "http://arxiv.org/pdf/2502.12341v1",
    "published": "2025-02-17T22:08:29+00:00",
    "categories": [
      "math.NT",
      "11S20, 11F85, 13J10, 46S10"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12340v1",
    "title": "Understanding Silent Data Corruption in LLM Training",
    "authors": [
      "Jeffrey Ma",
      "Hengzhi Pei",
      "Leonard Lausen",
      "George Karypis"
    ],
    "abstract": "As the scale of training large language models (LLMs) increases, one emergent\nfailure is silent data corruption (SDC), where hardware produces incorrect\ncomputations without explicit failure signals. In this work, we are the first\nto investigate the impact of real-world SDCs on LLM training by comparing model\ntraining between healthy production nodes and unhealthy nodes exhibiting SDCs.\nWith the help from a cloud computing platform, we access the unhealthy nodes\nthat were swept out from production by automated fleet management. Using\ndeterministic execution via XLA compiler and our proposed synchronization\nmechanisms, we isolate and analyze the impact of SDC errors on these nodes at\nthree levels: at each submodule computation, at a single optimizer step, and at\na training period. Our results reveal that the impact of SDCs on computation\nvaries on different unhealthy nodes. Although in most cases the perturbations\nfrom SDCs on submodule computation and gradients are relatively small, SDCs can\nlead models to converge to different optima with different weights and even\ncause spikes in the training loss. Our analysis sheds light on further\nunderstanding and mitigating the impact of SDCs.",
    "pdf_url": "http://arxiv.org/pdf/2502.12340v1",
    "published": "2025-02-17T22:07:49+00:00",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12339v2",
    "title": "Orbitronics in Two-dimensional Materials",
    "authors": [
      "Tarik P. Cysne",
      "Luis M. Canonico",
      "Marcio Costa",
      "R. B. Muniz",
      "Tatiana G. Rappoport"
    ],
    "abstract": "Orbitronics explores the control and manipulation of electronic orbital\nangular momentum in solid-state systems, opening new pathways for information\nprocessing and storage. One significant advantage of orbitronics over\nspintronics is that it does not rely on spin-orbit coupling, thereby broadening\nthe range of non-magnetic materials that can be utilized for these\napplications. It also introduces new topological features related to electronic\norbital angular momentum, and clarifies some long-standing challenges in\nunderstanding experiments that rely on the conventional concept of valley\ntransport. This review highlights recent advances in orbitronics, particularly\nin relation to two-dimensional materials. We examine the fundamental principles\nunderlying the generation, transport, and dynamics of orbital angular momentum\nto illustrate how the unique properties of two-dimensional materials can\npromote orbitronic phenomena. We also outline potential future research\ndirections and address some outstanding questions in this field.",
    "pdf_url": "http://arxiv.org/pdf/2502.12339v2",
    "published": "2025-02-17T22:02:47+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.12338v2",
    "title": "Strong coupling of polaritons at room temperature in a GaAs/AlGaAs structure",
    "authors": [
      "Hassan Alnatah",
      "Shuang Liang",
      "Qiaochu Wan",
      "Jonathan Beaumariage",
      "Ken West",
      "Kirk Baldwin",
      "Loren N. Pfeiffer",
      "Man Chun Alan Tam",
      "Zbigniew R. Wasilewski",
      "David W. Snoke"
    ],
    "abstract": "We report direct measurement of the dispersion relation of polaritons in\nGaAs/AlGaAs microcavity structures at room temperature, which clearly shows\nthat the polaritons are in the strong coupling limit. The Rabi splitting of the\npolariton states decreases as the polariton gas increases in density, but even\nwhen the polariton gas becomes a coherent, Bose-condensate-like state, the\npolaritons retain a strong exciton component, as seen in the nonlinear energy\nshift of the light emission. This opens up the possibility of polaritonic\ndevices at room temperature in a material system which can be grown with very\nhigh quality and uniformity.",
    "pdf_url": "http://arxiv.org/pdf/2502.12338v2",
    "published": "2025-02-17T21:56:13+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.15784v2",
    "title": "Rotating black holes: The most fantastic source of energy in the universe",
    "authors": [
      "Jorge Pinochet"
    ],
    "abstract": "Rotating black holes are the most powerful source of energy in the known\nuniverse, and are the cause of some of the most spectacular and extreme\nastronomical phenomena. The goal of this article is to analyze in simple terms\nthe physics of energy extraction in rotating black holes. Specifically, the\nsource of said energy, the efficiency of the energy extraction process, and\nsome specific mechanisms that allow said extraction are analyzed. The article\nis intended primarily for undergraduate students of physics, astronomy and\nrelated fields.",
    "pdf_url": "http://arxiv.org/pdf/2502.15784v2",
    "published": "2025-02-17T21:54:36+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2502.12337v2",
    "title": "Stochastic Real-Time Deception in Nash Equilibrium Seeking for Games with Quadratic Payoffs",
    "authors": [
      "Michael Tang",
      "Miroslav Krstic",
      "Jorge Poveda"
    ],
    "abstract": "In multi-agent autonomous systems, deception is a fundamental concept which\ncharacterizes the exploitation of unbalanced information to mislead victims\ninto choosing oblivious actions. This effectively alters the system's long term\nbehavior, leading to outcomes that may be beneficial to the deceiver but\ndetrimental to victim. We study this phenomenon for a class of model-free Nash\nequilibrium seeking (NES) where players implement independent stochastic\nexploration signals to learn the pseudogradient flow. In particular, we show\nthat deceptive players who obtain real-time measurements of other players'\nstochastic perturbation can incorporate this information into their own NES\naction update, consequentially steering the overall dynamics to a new operating\npoint that could potentially improve the payoffs of the deceptive players. We\nconsider games with quadratic payoff functions, as this restriction allows us\nto derive a more explicit formulation of the capabilities of the deceptive\nplayers. By leveraging results on multi-input stochastic averaging for\ndynamical systems, we establish local exponential (in probability) convergence\nfor the proposed deceptive NES dynamics. To illustrate our results, we apply\nthem to a two player quadratic game.",
    "pdf_url": "http://arxiv.org/pdf/2502.12337v2",
    "published": "2025-02-17T21:51:25+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.12336v2",
    "title": "Controlling complex dynamics with synthetic magnetism in optomechanical systems: A route to enhanced sensor performance",
    "authors": [
      "Deivasundari Muthukumar",
      "Stella Rolande Mbokop Tchounda",
      "Sifeu Takougang Kingni",
      "Karthikeyan Rajagopal",
      "Serge Guy Nana Engo"
    ],
    "abstract": "This paper investigates the complex nonlinear dynamics of an optomechanical\nsystem featuring an optical cavity coupled to two mechanical resonators\ninterconnected by a phase-dependent interaction. We specifically explore the\nrole of this phase-dependent phonon hopping as a mechanism for generating\nsynthetic gauge fields without relying on gain-loss or PT-symmetric elements,\noffering a potentially more robust approach to manipulate mechanical energy\ntransfer. By deriving the semiclassical dynamical equations, we map out the\nsystem's behavior across different parameter regimes. Our findings reveal a\nrich spectrum of dynamics, including bistability (coexistence of two steady\nstates) and the emergence of complex attractors such as self-excited\noscillations, hidden attractors, and chaos. We demonstrate how controlling\nsystem parameters, particularly the mechanical coupling phase and optical\ndrive, allows for tunability between these distinct dynamical states. The\npresence of tunable bistability and sensitive chaotic regimes offers\nsignificant potential for practical applications. Specifically, we discuss how\nthese controlled dynamics could be leveraged for state-switching in optical\ninformation processing and for enhancing sensitivity in advanced sensor\ntechnologies through chaos-based mechanisms. This work deepens our\nunderstanding of how synthetic gauge fields, generated via phase-dependent\ninteractions, can sculpt the nonlinear dynamics of optomechanical systems,\nproviding a pathway toward designing robust and tunable devices for signal\nprocessing, communication, and sensing.",
    "pdf_url": "http://arxiv.org/pdf/2502.12336v2",
    "published": "2025-02-17T21:45:44+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12335v2",
    "title": "Robust Super-MoirÃ© in Large Angle Single-Twist Bilayers",
    "authors": [
      "Yanxing Li",
      "Chuqiao Shi",
      "Fan Zhang",
      "Xiaohui Liu",
      "Yuan Xue",
      "Viet-Anh Ha",
      "Qiang Gao",
      "Chengye Dong",
      "Yu-chuan Lin",
      "Luke N Holtzman",
      "Nicolas Morales-DurÃ¡n",
      "Hyunsue Kim",
      "Yi Jiang",
      "Madisen Holbrook",
      "James Hone",
      "Katayun Barmak",
      "Joshua Robinson",
      "Xiaoqin Li",
      "Feliciano Giustino",
      "Eslam Khalaf",
      "Yimo Han",
      "Chih-Kang Shih"
    ],
    "abstract": "Forming long wavelength moir\\'e superlattices (MSL) at small-angle twist van\nder Waals (vdW) bilayers has been a key approach to creating moir\\'e flat\nbands. The small-angle twist, however, leads to strong lattice reconstruction,\ncausing domain walls and moir\\'e disorders, which pose considerable challenges\nin engineering such platforms. At large twist angles, the rigid lattices render\na more robust, but shorter wavelength MSL, making it difficult to engineer flat\nbands. Here, we depict a novel approach to tailoring robust super-moir\\'e (SM)\nstructures that combines the advantages of both small-twist and large-twist\ntransition metal dichalcogenides (TMDs) bilayers using only a single twist\nangle near a commensurate angle. Structurally, we unveil the spontaneous\nformation of a periodic arrangement of three inequivalent commensurate moir\\'e\n(CM) stacking, where the angle deviation from the commensurate angle can tune\nthe periodicity. Electronically, we reveal a large set of van Hove\nsingularities (VHSs) that indicate strong band hybridization, leading to flat\nbands near the valence band maximum. Our study paves the way for a new platform\nof robust SM bilayers with structural rigidity and controllable wavelength,\nextending the investigation of the interplay among band topology, quantum\ngeometry, and moir\\'e superconductivity to the large twist angle regime.",
    "pdf_url": "http://arxiv.org/pdf/2502.12335v2",
    "published": "2025-02-17T21:45:39+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.12334v2",
    "title": "Inference for Log-Gaussian Cox Point Processes using Bayesian Deep Learning: Application to Human Oral Microbiome Image Data",
    "authors": [
      "Shuwan Wang",
      "Christopher K. Wikle",
      "Athanasios C. Micheas",
      "Jessica L. Mark Welch",
      "Jacqueline R. Starr",
      "Kyu Ha Lee"
    ],
    "abstract": "It is common in nature to see aggregation of objects in space. Exploring the\nmechanism associated with the locations of such clustered observations can be\nessential to understanding the phenomenon, such as the source of spatial\nheterogeneity, or comparison to other event generating processes in the same\ndomain. Log-Gaussian Cox processes (LGCPs) represent an important class of\nmodels for quantifying aggregation in a spatial point pattern. However,\nimplementing likelihood-based Bayesian inference for such models presents many\ncomputational challenges, particularly in high dimensions. In this paper, we\npropose a novel likelihood-free inference approach for LGCPs using the recently\ndeveloped BayesFlow approach, where invertible neural networks are employed to\napproximate the posterior distribution of the parameters of interest. BayesFlow\nis a neural simulation-based method based on \"amortized\" posterior estimation.\nThat is, after an initial training procedure, fast feed-forward operations\nallow rapid posterior inference for any data within the same model family.\nComprehensive numerical studies validate the reliability of the framework and\nshow that BayesFlow achieves substantial computational gain in repeated\napplication, especially for two-dimensional LGCPs. We demonstrate the utility\nand robustness of the method by applying it to two distinct oral microbial\nbiofilm images.",
    "pdf_url": "http://arxiv.org/pdf/2502.12334v2",
    "published": "2025-02-17T21:44:19+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.12333v2",
    "title": "Impact of momentum-dependent drag coefficient on energy loss of charm and bottom quarks in QGP",
    "authors": [
      "Marjan Rahimi Nezhad",
      "Fatemeh Taghavi-Shahri",
      "Kurosh Javidan"
    ],
    "abstract": "This paper investigates how the momentum of heavy particles affects their\ninteraction rate, and consequently their energy loss, in a quark-gluon plasma.\nTo account for this momentum dependence, the drag coefficient is derived by\nexpressing the energy loss coefficients as polynomial expansions of momentum\n($p$). This approach allows for a more precise investigation of momentum\ndependence of drag coefficient by incorporating the linear terms of these\nexpansions. Additionally, the influence of particle's momentum on radiative and\ncollisional energy loss is more clearly determined. The study focuses on\ncalculation of the nuclear modification factor ($R_{AA}$) of charm and bottom\nquarks in Pb-Pb collisions at $\\sqrt{S_{NN}} = 5.02 \\: TeV$. The initial\ndistribution functions have been evolved numerically based on the Fokker-Planck\nequation. The results are compared with the latest data from ALICE and ATLAS\nexperiments, conducted in 2021 and 2022.",
    "pdf_url": "http://arxiv.org/pdf/2502.12333v2",
    "published": "2025-02-17T21:40:11+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12332v1",
    "title": "The elliptic lattice KdV system revisited",
    "authors": [
      "Frank Nijhoff",
      "Cheng Zhang",
      "Da-jun Zhang"
    ],
    "abstract": "In a previous paper [Nijhoff,Puttock,2003], a 2-parameter extension of the\nlattice potential KdV equation was derived, associated with an elliptic curve.\nThis comprises a rather complicated 3-component system on the quad lattice\nwhich contains the moduli of the elliptic curve as parameters. In the present\npaper, we investigate this system further and, among other results, we derive a\n2-component multiquartic form of the system on the quad lattice. Furthermore,\nwe construct an elliptic Yang-Baxter map, and study the associated continuous\nand semi-discrete systems. In particular, we derive the so-called ``generating\nPDE'' for this system, comprising a 6-component system of second order PDEs\nwhich could be considered to constitute an elliptic extension of the Ernst\nequations of General Relativity.",
    "pdf_url": "http://arxiv.org/pdf/2502.12332v1",
    "published": "2025-02-17T21:37:11+00:00",
    "categories": [
      "nlin.SI",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "nlin.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12331v1",
    "title": "Simple systems of nonlinear recursions whose evolution is rather easily ascertained",
    "authors": [
      "Francesco Calogero"
    ],
    "abstract": "It is shown that the solutions of certain systems of nonlinear \\\"Orst-order\nrecursions with polynomial right-hand sides may be rather easily ascertained,\nand display interesting evolutions in their ticking time variable (taking\ninteger values): for instance a remarkable kind of asymptotic periodicity.",
    "pdf_url": "http://arxiv.org/pdf/2502.12331v1",
    "published": "2025-02-17T21:37:01+00:00",
    "categories": [
      "nlin.SI"
    ],
    "primary_category": "nlin.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.14897v2",
    "title": "Market-Derived Financial Sentiment Analysis: Context-Aware Language Models for Crypto Forecasting",
    "authors": [
      "Hamid Moradi-Kamali",
      "Mohammad-Hossein Rajabi-Ghozlou",
      "Mahdi Ghazavi",
      "Ali Soltani",
      "Amirreza Sattarzadeh",
      "Reza Entezari-Maleki"
    ],
    "abstract": "Financial Sentiment Analysis (FSA) traditionally relies on human-annotated\nsentiment labels to infer investor sentiment and forecast market movements.\nHowever, inferring the potential market impact of words based on their\nhuman-perceived intentions is inherently challenging. We hypothesize that the\nhistorical market reactions to words, offer a more reliable indicator of their\npotential impact on markets than subjective sentiment interpretations by human\nannotators. To test this hypothesis, a market-derived labeling approach is\nproposed to assign tweet labels based on ensuing short-term price trends,\nenabling the language model to capture the relationship between textual signals\nand market dynamics directly. A domain-specific language model was fine-tuned\non these labels, achieving up to an 11% improvement in short-term trend\nprediction accuracy over traditional sentiment-based benchmarks. Moreover, by\nincorporating market and temporal context through prompt-tuning, the proposed\ncontext-aware language model demonstrated an accuracy of 89.6% on a curated\ndataset of 227 impactful Bitcoin-related news events with significant market\nimpacts. Aggregating daily tweet predictions into trading signals, our method\noutperformed traditional fusion models (which combine sentiment-based and\nprice-based predictions). It challenged the assumption that sentiment-based\nsignals are inferior to price-based predictions in forecasting market\nmovements. Backtesting these signals across three distinct market regimes\nyielded robust Sharpe ratios of up to 5.07 in trending markets and 3.73 in\nneutral markets. Our findings demonstrate that language models can serve as\neffective short-term market predictors. This paradigm shift underscores the\nuntapped capabilities of language models in financial decision-making and opens\nnew avenues for market prediction applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.14897v2",
    "published": "2025-02-17T21:35:18+00:00",
    "categories": [
      "cs.CE",
      "cs.CL",
      "cs.LG",
      "q-fin.ST",
      "68T50",
      "H.3.1; I.2.7; J.1"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12330v2",
    "title": "X-IL: Exploring the Design Space of Imitation Learning Policies",
    "authors": [
      "Xiaogang Jia",
      "Atalay Donat",
      "Xi Huang",
      "Xuan Zhao",
      "Denis Blessing",
      "Hongyi Zhou",
      "Han A. Wang",
      "Hanyi Zhang",
      "Qian Wang",
      "Rudolf Lioutikov",
      "Gerhard Neumann"
    ],
    "abstract": "Designing modern imitation learning (IL) policies requires making numerous\ndecisions, including the selection of feature encoding, architecture, policy\nrepresentation, and more. As the field rapidly advances, the range of available\noptions continues to grow, creating a vast and largely unexplored design space\nfor IL policies. In this work, we present X-IL, an accessible open-source\nframework designed to systematically explore this design space. The framework's\nmodular design enables seamless swapping of policy components, such as\nbackbones (e.g., Transformer, Mamba, xLSTM) and policy optimization techniques\n(e.g., Score-matching, Flow-matching). This flexibility facilitates\ncomprehensive experimentation and has led to the discovery of novel policy\nconfigurations that outperform existing methods on recent robot learning\nbenchmarks. Our experiments demonstrate not only significant performance gains\nbut also provide valuable insights into the strengths and weaknesses of various\ndesign choices. This study serves as both a practical reference for\npractitioners and a foundation for guiding future research in imitation\nlearning.",
    "pdf_url": "http://arxiv.org/pdf/2502.12330v2",
    "published": "2025-02-17T21:33:56+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12329v1",
    "title": "A Novel Unified Parametric Assumption for Nonconvex Optimization",
    "authors": [
      "Artem Riabinin",
      "Ahmed Khaled",
      "Peter RichtÃ¡rik"
    ],
    "abstract": "Nonconvex optimization is central to modern machine learning, but the general\nframework of nonconvex optimization yields weak convergence guarantees that are\ntoo pessimistic compared to practice. On the other hand, while convexity\nenables efficient optimization, it is of limited applicability to many\npractical problems. To bridge this gap and better understand the practical\nsuccess of optimization algorithms in nonconvex settings, we introduce a novel\nunified parametric assumption. Our assumption is general enough to encompass a\nbroad class of nonconvex functions while also being specific enough to enable\nthe derivation of a unified convergence theorem for gradient-based methods.\nNotably, by tuning the parameters of our assumption, we demonstrate its\nversatility in recovering several existing function classes as special cases\nand in identifying functions amenable to efficient optimization. We derive our\nconvergence theorem for both deterministic and stochastic optimization, and\nconduct experiments to verify that our assumption can hold practically over\noptimization trajectories.",
    "pdf_url": "http://arxiv.org/pdf/2502.12329v1",
    "published": "2025-02-17T21:25:31+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.13174v2",
    "title": "Diverse Topology Optimization using Modulated Neural Fields",
    "authors": [
      "Andreas Radler",
      "Eric Volkmann",
      "Johannes Brandstetter",
      "Arturs Berzins"
    ],
    "abstract": "Topology optimization (TO) is a family of computational methods that derive\nnear-optimal geometries from formal problem descriptions. Despite their\nsuccess, established TO methods are limited to generating single solutions,\nrestricting the exploration of alternative designs. To address this limitation,\nwe introduce Topology Optimization using Modulated Neural Fields (TOM) - a\ndata-free method that trains a neural network to generate structurally\ncompliant shapes and explores diverse solutions through an explicit diversity\nconstraint. The network is trained with a solver-in-the-loop, optimizing the\nmaterial distribution in each iteration. The trained model produces diverse\nshapes that closely adhere to the design requirements. We validate TOM on 2D\nand 3D TO problems. Our results show that TOM generates more diverse solutions\nthan any previous method, all while maintaining near-optimality and without\nrelying on a dataset. These findings open new avenues for engineering and\ndesign, offering enhanced flexibility and innovation in structural\noptimization.",
    "pdf_url": "http://arxiv.org/pdf/2502.13174v2",
    "published": "2025-02-17T21:24:18+00:00",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12328v1",
    "title": "LM Agents for Coordinating Multi-User Information Gathering",
    "authors": [
      "Harsh Jhamtani",
      "Jacob Andreas",
      "Benjamin Van Durme"
    ],
    "abstract": "This paper introduces PeopleJoin, a benchmark for evaluating LM-mediated\ncollaborative problem solving. Given a user request, PeopleJoin agents must\nidentify teammates who might be able to assist, converse with these teammates\nto gather information, and finally compile a useful answer or summary for the\noriginal user. PeopleJoin comprises two evaluation domains: PeopleJoin-QA,\nfocused on questions about tabular data, and PeopleJoin-DocCreation, focused on\ndocument creation tasks. The two domains are adapted from existing NLP\nbenchmarks for database question answering and multi-document summarization;\nhere, however, the information needed to complete these tasks is distributed\nacross synthetic ``organizations'' of 2--20 users, simulating natural\nmulti-user collaboration scenarios. We implemented several popular LM agent\narchitectures, evaluating their accuracy and efficiency at completing tasks,\nand highlight new research questions that can be studied using PeopleJoin.",
    "pdf_url": "http://arxiv.org/pdf/2502.12328v1",
    "published": "2025-02-17T21:19:45+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12327v2",
    "title": "Learning Plasma Dynamics and Robust Rampdown Trajectories with Predict-First Experiments at TCV",
    "authors": [
      "Allen M. Wang",
      "Alessandro Pau",
      "Cristina Rea",
      "Oswin So",
      "Charles Dawson",
      "Olivier Sauter",
      "Mark D. Boyer",
      "Anna Vu",
      "Cristian Galperti",
      "Chuchu Fan",
      "Antoine Merle",
      "Yoeri Poels",
      "Cristina Venturini",
      "Stefano Marchioni",
      "the TCV Team"
    ],
    "abstract": "The rampdown phase of a tokamak pulse is difficult to simulate and often\nexacerbates multiple plasma instabilities. To reduce the risk of disrupting\noperations, we leverage advances in Scientific Machine Learning (SciML) to\ncombine physics with data-driven models, developing a neural state-space model\n(NSSM) that predicts plasma dynamics during Tokamak \\`a Configuration Variable\n(TCV) rampdowns. The NSSM efficiently learns dynamics from a modest dataset of\n311 pulses with only five pulses in a reactor-relevant high-performance regime.\nThe NSSM is parallelized across uncertainties, and reinforcement learning (RL)\nis applied to design trajectories that avoid instability limits.\nHigh-performance experiments at TCV show statistically significant improvements\nin relevant metrics. A predict-first experiment, increasing plasma current by\n20% from baseline, demonstrates the NSSM's ability to make small\nextrapolations. The developed approach paves the way for designing tokamak\ncontrols with robustness to considerable uncertainty and demonstrates the\nrelevance of SciML for fusion experiments.",
    "pdf_url": "http://arxiv.org/pdf/2502.12327v2",
    "published": "2025-02-17T21:19:15+00:00",
    "categories": [
      "physics.plasm-ph",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12326v1",
    "title": "Stability Bounds for Smooth Optimal Transport Maps and their Statistical Implications",
    "authors": [
      "Sivaraman Balakrishnan",
      "Tudor Manole"
    ],
    "abstract": "We study estimators of the optimal transport (OT) map between two probability\ndistributions. We focus on plugin estimators derived from the OT map between\nestimates of the underlying distributions. We develop novel stability bounds\nfor OT maps which generalize those in past work, and allow us to reduce the\nproblem of optimally estimating the transport map to that of optimally\nestimating densities in the Wasserstein distance. In contrast, past work\nprovided a partial connection between these problems and relied on regularity\ntheory for the Monge-Ampere equation to bridge the gap, a step which required\nunnatural assumptions to obtain sharp guarantees. We also provide some new\ninsights into the connections between stability bounds which arise in the\nanalysis of plugin estimators and growth bounds for the semi-dual functional\nwhich arise in the analysis of Brenier potential-based estimators of the\ntransport map. We illustrate the applicability of our new stability bounds by\nrevisiting the smooth setting studied by Manole et al., analyzing two of their\nestimators under more general conditions. Critically, our bounds do not require\nsmoothness or boundedness assumptions on the underlying measures. As an\nillustrative application, we develop and analyze a novel tuning parameter-free\nestimator for the OT map between two strongly log-concave distributions.",
    "pdf_url": "http://arxiv.org/pdf/2502.12326v1",
    "published": "2025-02-17T21:17:03+00:00",
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.ME",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2502.12325v1",
    "title": "From Dense to Dynamic: Token-Difficulty Driven MoEfication of Pre-Trained LLMs",
    "authors": [
      "Kumari Nishu",
      "Sachin Mehta",
      "Samira Abnar",
      "Mehrdad Farajtabar",
      "Maxwell Horton",
      "Mahyar Najibi",
      "Moin Nabi",
      "Minsik Cho",
      "Devang Naik"
    ],
    "abstract": "Training large language models (LLMs) for different inference constraints is\ncomputationally expensive, limiting control over efficiency-accuracy\ntrade-offs. Moreover, once trained, these models typically process tokens\nuniformly, regardless of their complexity, leading to static and inflexible\nbehavior. In this paper, we introduce a post-training optimization framework,\nDynaMoE, that adapts a pre-trained dense LLM to a token-difficulty-driven\nMixture-of-Experts model with minimal fine-tuning cost. This adaptation makes\nthe model dynamic, with sensitivity control to customize the balance between\nefficiency and accuracy. DynaMoE features a token-difficulty-aware router that\npredicts the difficulty of tokens and directs them to the appropriate\nsub-networks or experts, enabling larger experts to handle more complex tokens\nand smaller experts to process simpler ones. Our experiments demonstrate that\nDynaMoE can generate a range of adaptive model variants of the existing trained\nLLM with a single fine-tuning step, utilizing only $10B$ tokens, a minimal cost\ncompared to the base model's training. Each variant offers distinct trade-offs\nbetween accuracy and performance. Compared to the baseline post-training\noptimization framework, Flextron, our method achieves similar aggregated\naccuracy across downstream tasks, despite using only $\\frac{1}{9}\\text{th}$ of\ntheir fine-tuning cost.",
    "pdf_url": "http://arxiv.org/pdf/2502.12325v1",
    "published": "2025-02-17T21:12:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.17579v2",
    "title": "VANPY: Voice Analysis Framework",
    "authors": [
      "Gregory Koushnir",
      "Michael Fire",
      "Galit Fuhrmann Alpert",
      "Dima Kagan"
    ],
    "abstract": "Voice data is increasingly being used in modern digital communications, yet\nthere is still a lack of comprehensive tools for automated voice analysis and\ncharacterization. To this end, we developed the VANPY (Voice Analysis in\nPython) framework for automated pre-processing, feature extraction, and\nclassification of voice data. The VANPY is an open-source end-to-end\ncomprehensive framework that was developed for the purpose of speaker\ncharacterization from voice data. The framework is designed with extensibility\nin mind, allowing for easy integration of new components and adaptation to\nvarious voice analysis applications. It currently incorporates over fifteen\nvoice analysis components - including music/speech separation, voice activity\ndetection, speaker embedding, vocal feature extraction, and various\nclassification models.\n  Four of the VANPY's components were developed in-house and integrated into\nthe framework to extend its speaker characterization capabilities: gender\nclassification, emotion classification, age regression, and height regression.\nThe models demonstrate robust performance across various datasets, although not\nsurpassing state-of-the-art performance.\n  As a proof of concept, we demonstrate the framework's ability to extract\nspeaker characteristics on a use-case challenge of analyzing character voices\nfrom the movie \"Pulp Fiction.\" The results illustrate the framework's\ncapability to extract multiple speaker characteristics, including gender, age,\nheight, emotion type, and emotion intensity measured across three dimensions:\narousal, dominance, and valence.",
    "pdf_url": "http://arxiv.org/pdf/2502.17579v2",
    "published": "2025-02-17T21:12:57+00:00",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2502.12324v1",
    "title": "A comprehensive survey of the GEO-belt using simultaneous four-colour observations with STING",
    "authors": [
      "Robert J. S. Airey",
      "Paul Chote",
      "James A. Blake",
      "Benjamin F. Cooke",
      "James McCormac",
      "Phineas Allen",
      "Alex MacManus",
      "Don Pollacco",
      "Billy Shrive",
      "Richard West"
    ],
    "abstract": "Colour light curves of resident space objects (RSOs) encapsulate distinctive\nfeatures that can offer insights into an object's structure and design, making\nthem an invaluable tool for classification and characterisation. We present the\nresults of the first large systematic colour survey of the GEO belt in which we\nobtain full-night multi-colour light curves for 112 active geostationary\nobjects between April and May 2023. Colour light curve maps were created to\ncompare and contrast the colours between different satellites and bus\nconfigurations. We find that satellites with BSS-702 and STAR-2 buses can be\neffectively distinguished from the colour measurements on these maps, but\ncomparing the average colour of individual satellites within given solar\nequatorial phase angle ranges shows that it is difficult to distinguish between\nbus configurations based on colour alone. We also find tentative evidence to\nsuggest that there is a relationship between colour and time spent on orbit for\nthe Eurostar-3000 class satellites, which is unseen behaviour within other bus\nconfiguration classes. The satellites in our sample exhibit `redder' colours\nthan the Sun, which is in agreement with previous findings. We found common\nlight curve features such as symmetrical colour changes as well as unique\nregions of short timescale glinting which are `bluer' than other regimes within\nthe colour light curves. If these features are indeed seasonal, this would be a\npowerful characterisation tool. We are able to detect and resolve features in\nthe light curve of the LDPE-3A satellite related to manoeuvres being performed.\nFinally, we measured the solar panel offsets of 54 satellites in our sample and\nfound variation in the type of colour response. The majority of which did not\nexhibit any colour change across the solar panel glints compared to them\nshifting towards 'redder' or 'bluer' colours.",
    "pdf_url": "http://arxiv.org/pdf/2502.12324v1",
    "published": "2025-02-17T21:01:54+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2502.12322v2",
    "title": "VIC: Evasive Video Game Cheating via Virtual Machine Introspection",
    "authors": [
      "Panicos Karkallis",
      "Jorge Blasco"
    ],
    "abstract": "Video game cheats modify a video game behaviour to give unfair advantages to\nsome players while bypassing the methods game developers use to detect them.\nThis destroys the experience of online gaming and can result in financial\nlosses for game developers. In this work, we present a new type of game cheat,\nVirtual machine Introspection Cheat (VIC), that takes advantage of virtual\nmachines to stealthy execute game cheats. VIC employees a hypervisor with\nintrospection enabled to lower the bar of cheating against legacy and modern\nanti-cheat systems. We demonstrate the feasibility and stealthiness of VIC\nagainst three popular games (Fortnite, BlackSquad and Team Fortress 2) that\ninclude five different anti-cheats. In particular, we use VIC to implement a\ncheat radar, a wall-hack cheat and a trigger-bot. To support our claim that\nthis type of cheats can be effectively used, we present the performance impact\nVICs have on gameplay by monitoring the frames per second (fps) while the\ncheats are activated. Our experimentation also shows how these cheats are\ncurrently undetected by the most popular anti-cheat systems, enabling a new\nparadigm that can take advantage of cloud infrastructure to offer\ncheating-as-a-service.",
    "pdf_url": "http://arxiv.org/pdf/2502.12322v2",
    "published": "2025-02-17T20:54:56+00:00",
    "categories": [
      "cs.CR",
      "D.4.6"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12323v1",
    "title": "Adversarial Debiasing for Unbiased Parameter Recovery",
    "authors": [
      "Luke C Sanford",
      "Megan Ayers",
      "Matthew Gordon",
      "Eliana Stone"
    ],
    "abstract": "Advances in machine learning and the increasing availability of\nhigh-dimensional data have led to the proliferation of social science research\nthat uses the predictions of machine learning models as proxies for measures of\nhuman activity or environmental outcomes. However, prediction errors from\nmachine learning models can lead to bias in the estimates of regression\ncoefficients. In this paper, we show how this bias can arise, propose a test\nfor detecting bias, and demonstrate the use of an adversarial machine learning\nalgorithm in order to de-bias predictions. These methods are applicable to any\nsetting where machine-learned predictions are the dependent variable in a\nregression. We conduct simulations and empirical exercises using ground truth\nand satellite data on forest cover in Africa. Using the predictions from a\nnaive machine learning model leads to biased parameter estimates, while the\npredictions from the adversarial model recover the true coefficients.",
    "pdf_url": "http://arxiv.org/pdf/2502.12323v1",
    "published": "2025-02-17T20:54:56+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12321v2",
    "title": "Bubble wall velocity for first-order QCD phase transition",
    "authors": [
      "James M. Cline",
      "Benoit Laurent"
    ],
    "abstract": "Although the QCD phase transition is a crossover in the standard model,\nnonstandard effects such as a large lepton asymmetry are known to make it first\norder, with possible applications to gravitational wave production. This\nprocess is sensitive to the speed of the bubble walls during the phase\ntransition, which is difficult to compute from first principles. We take\nadvantage of recent progress on wall speed determinations to provide a simple\nestimate valid in the small supercooling regime which constrains the wall speed\nto be significantly lower than what has been used in previous literature. This\nin turn strongly suppresses the production of gravitational waves, to a level\nthat is just out of reach of the most sensitive projected experiment for this\nsignal, $\\mu$Ares. While our analysis approximates the equation of state using\nthe template model, we demonstrate that our conclusions remain robust when\nincorporating state-of-the-art QCD equation of state data.",
    "pdf_url": "http://arxiv.org/pdf/2502.12321v2",
    "published": "2025-02-17T20:52:45+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.14896v2",
    "title": "A Comprehensive Survey on Concept Erasure in Text-to-Image Diffusion Models",
    "authors": [
      "Changhoon Kim",
      "Yanjun Qi"
    ],
    "abstract": "Text-to-Image (T2I) models have made remarkable progress in generating\nhigh-quality, diverse visual content from natural language prompts. However,\ntheir ability to reproduce copyrighted styles, sensitive imagery, and harmful\ncontent raises significant ethical and legal concerns. Concept erasure offers a\nproactive alternative to external filtering by modifying T2I models to prevent\nthe generation of undesired content. In this survey, we provide a structured\noverview of concept erasure, categorizing existing methods based on their\noptimization strategies and the architectural components they modify. We\ncategorize concept erasure methods into fine-tuning for parameter updates,\nclosed-form solutions for efficient edits, and inference-time interventions for\ncontent restriction without weight modification. Additionally, we explore\nadversarial attacks that bypass erasure techniques and discuss emerging\ndefenses. To support further research, we consolidate key datasets, evaluation\nmetrics, and benchmarks for assessing erasure effectiveness and model\nrobustness. This survey serves as a comprehensive resource, offering insights\ninto the evolving landscape of concept erasure, its challenges, and future\ndirections.",
    "pdf_url": "http://arxiv.org/pdf/2502.14896v2",
    "published": "2025-02-17T20:51:20+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12320v2",
    "title": "Towards Fusing Point Cloud and Visual Representations for Imitation Learning",
    "authors": [
      "Atalay Donat",
      "Xiaogang Jia",
      "Xi Huang",
      "Aleksandar Taranovic",
      "Denis Blessing",
      "Ge Li",
      "Hongyi Zhou",
      "Hanyi Zhang",
      "Rudolf Lioutikov",
      "Gerhard Neumann"
    ],
    "abstract": "Learning for manipulation requires using policies that have access to rich\nsensory information such as point clouds or RGB images. Point clouds\nefficiently capture geometric structures, making them essential for\nmanipulation tasks in imitation learning. In contrast, RGB images provide rich\ntexture and semantic information that can be crucial for certain tasks.\nExisting approaches for fusing both modalities assign 2D image features to\npoint clouds. However, such approaches often lose global contextual information\nfrom the original images. In this work, we propose FPV-Net, a novel imitation\nlearning method that effectively combines the strengths of both point cloud and\nRGB modalities. Our method conditions the point-cloud encoder on global and\nlocal image tokens using adaptive layer norm conditioning, leveraging the\nbeneficial properties of both modalities. Through extensive experiments on the\nchallenging RoboCasa benchmark, we demonstrate the limitations of relying on\neither modality alone and show that our method achieves state-of-the-art\nperformance across all tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.12320v2",
    "published": "2025-02-17T20:46:54+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12319v1",
    "title": "Enhancing Stellarator Accessibility through Port Size Optimization",
    "authors": [
      "A. Baillod",
      "E. J. Paul",
      "T. Elder",
      "J. M. Halpern"
    ],
    "abstract": "Access to the plasma chamber in a stellarator reactor is essential for\nmaintenance and diagnostics. However, the complex geometry of stellarator\ncoils, often characterized by their strong twisting, can severely limit the\nspace available for access ports. This study introduces a novel optimization\napproach in which access ports are represented as closed curves on the plasma\nboundary. By carefully selecting a set of objectives and penalties related to\nthe access port, we demonstrate the first stellarator coil optimization\nexplicitly targeting improved access port size. The trade-off between magnetic\nfield quality and port size is analyzed through the Pareto front of their\nrespective objectives. The optimal location of a port is explained using a\ncurrent potential approach. Finally, we show that additional shaping coils,\nsuch as windowpane coils, can enable the crossing of the Pareto front to\nachieve superior configurations.",
    "pdf_url": "http://arxiv.org/pdf/2502.12319v1",
    "published": "2025-02-17T20:45:40+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12318v2",
    "title": "Open-System Virus Particle Physics: A Path-Integral Viral Lattice Theory Using Non-Self Adjoint Stochastic PDEs and Fock-Space Formalism",
    "authors": [
      "Lillian St. Kleess"
    ],
    "abstract": "We develop a comprehensive theoretical biophysics model grounded in a path\nintegral perspective and an m-sectorial open-system framework, to describe\ncomplex, damped viral phonon dynamics in resource limited and noise driven\nenvironments. By unifying wave mechanics (via PDEs with multiplicative noise),\nMarkov jumps for occupant or arrangement transitions, and second quantized\n(Fock-space) expansions, our construction accommodates an unbounded number of\nviral lattices in a single global wavefunction. In doing so, we capture how an\nentire population potentially numbering in the millions may be represented by a\nsingle operator theoretic state, or orbit, whose evolution is governed by\nnon-unitary semigroups with potential equilibrium or non equilibrium steady\nstates. This approach admits action functionals over the space of system\ntrajectories, enabling large deviation and flux analyses whenever detailed\nbalance is broken by sustained resource inputs, as often happens in real\ninfections.\n  Such a global wavefunction thus synthesizes PDE wavefront modes, occupant\ntransitions, and stochastically induced rearrangements into a single evolution\nequation, capturing how local capsid vibrations might catalyze large scale\nreplication bursts, and vice versa. Our proofs show that, despite unbounded\noccupant expansions or morphological continuums, solutions remain finite norm\nover finite times. The well posedness extends to non-self-adjoint operators\nwith complex damping, irreversibility, and operator-valued-noise, thus\nmirroring host constraints and immune factors that restrict virus\nproliferation. Our formalism invites direct experimental cross validation, from\nsingle virion tracking to population assays, and offers predictive insights for\nresource limited replication, capsid reorganizations, and potential\nintervention strategies in modern virology.",
    "pdf_url": "http://arxiv.org/pdf/2502.12318v2",
    "published": "2025-02-17T20:44:18+00:00",
    "categories": [
      "physics.bio-ph"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12317v1",
    "title": "Can Language Models Learn Typologically Implausible Languages?",
    "authors": [
      "Tianyang Xu",
      "Tatsuki Kuribayashi",
      "Yohei Oseki",
      "Ryan Cotterell",
      "Alex Warstadt"
    ],
    "abstract": "Grammatical features across human languages show intriguing correlations\noften attributed to learning biases in humans. However, empirical evidence has\nbeen limited to experiments with highly simplified artificial languages, and\nwhether these correlations arise from domain-general or language-specific\nbiases remains a matter of debate. Language models (LMs) provide an opportunity\nto study artificial language learning at a large scale and with a high degree\nof naturalism. In this paper, we begin with an in-depth discussion of how LMs\nallow us to better determine the role of domain-general learning biases in\nlanguage universals. We then assess learnability differences for LMs resulting\nfrom typologically plausible and implausible languages closely following the\nword-order universals identified by linguistic typologists. We conduct a\nsymmetrical cross-lingual study training and testing LMs on an array of highly\nnaturalistic but counterfactual versions of the English (head-initial) and\nJapanese (head-final) languages. Compared to similar work, our datasets are\nmore naturalistic and fall closer to the boundary of plausibility. Our\nexperiments show that these LMs are often slower to learn these subtly\nimplausible languages, while ultimately achieving similar performance on some\nmetrics regardless of typological plausibility. These findings lend credence to\nthe conclusion that LMs do show some typologically-aligned learning\npreferences, and that the typological patterns may result from, at least to\nsome degree, domain-general learning biases.",
    "pdf_url": "http://arxiv.org/pdf/2502.12317v1",
    "published": "2025-02-17T20:40:01+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12316v3",
    "title": "Large-scale clustering of inertial particles in a rotating, stratified and inhomogeneous turbulence",
    "authors": [
      "Nathan Kleeorin",
      "Igor Rogachevskii"
    ],
    "abstract": "We develop a theory of various kinds of large-scale clustering of inertial\nparticles in a rotating density stratified or inhomogeneous turbulent fluid\nflows. The large-scale particle clustering occurs in scales which are much\nlarger than the integral scale of turbulence, and it is described in terms of\nthe effective pumping velocity in a turbulent flux of particles. We show that\nfor a fast rotating strongly anisotropic turbulence, the large-scale clustering\noccurs in the plane perpendicular to rotation axis in the direction of the\nfluid density stratification. We apply the theory of the large-scale particle\nclustering for explanation of the formation of planetesimals (progenitors of\nplanets) in accretion protoplanetary discs. We determine the radial profiles of\nthe radial and azimuthal components of the effective pumping velocity of\nparticles which have two maxima corresponding to different regimes of the\nparticle--fluid interactions: at the small radius it is the Stokes regime,\nwhile at the larger radius it is the Epstein regime. With the decrease the\nparticle radius, the distance between the maxima increases. This implies that\nsmaller-size particles are concentrated nearby the central body of the\naccretion disk, while larger-size particles are accumulated far from the\ncentral body. The dynamic time of the particle clustering is about $\\tau_{\\rm\ndyn} \\sim 10^5$--$10^6$ years, while the turbulent diffusion time is about\n$10^7$ years, that is much larger than the characteristic formation time of\nlarge-scale particle clusters ($\\sim \\tau_{\\rm dyn}$).",
    "pdf_url": "http://arxiv.org/pdf/2502.12316v3",
    "published": "2025-02-17T20:34:55+00:00",
    "categories": [
      "physics.flu-dyn",
      "astro-ph.EP",
      "astro-ph.SR",
      "physics.geo-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.12315v1",
    "title": "Mean-Field Bayesian Optimisation",
    "authors": [
      "Petar Steinberg",
      "Juliusz Ziomek",
      "Matej Jusup",
      "Ilija Bogunovic"
    ],
    "abstract": "We address the problem of optimising the average payoff for a large number of\ncooperating agents, where the payoff function is unknown and treated as a black\nbox. While standard Bayesian Optimisation (BO) methods struggle with the\nscalability required for high-dimensional input spaces, we demonstrate how\nleveraging the mean-field assumption on the black-box function can transform BO\ninto an efficient and scalable solution. Specifically, we introduce MF-GP-UCB,\na novel efficient algorithm designed to optimise agent payoffs in this setting.\nOur theoretical analysis establishes a regret bound for MF-GP-UCB that is\nindependent of the number of agents, contrasting sharply with the exponential\ndependence observed when naive BO methods are applied. We evaluate our\nalgorithm on a diverse set of tasks, including real-world problems, such as\noptimising the location of public bikes for a bike-sharing programme,\ndistributing taxi fleets, and selecting refuelling ports for maritime vessels.\nEmpirical results demonstrate that MF-GP-UCB significantly outperforms existing\nbenchmarks, offering substantial improvements in performance and scalability,\nconstituting a promising solution for mean-field, black-box optimisation. The\ncode is available at https://github.com/petarsteinberg/MF-BO.",
    "pdf_url": "http://arxiv.org/pdf/2502.12315v1",
    "published": "2025-02-17T20:34:29+00:00",
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12314v1",
    "title": "Searching for exotic scalars at fusion reactors",
    "authors": [
      "Chaja Baruch",
      "Patrick J. Fitzpatrick",
      "Tony Menzo",
      "Yotam Soreq",
      "Sokratis Trifinopoulos",
      "Jure Zupan"
    ],
    "abstract": "The energy created in deuterium-tritium fusion reactors originates from a\nhigh-intensity neutron flux interacting with the reactor's inner walls. The\nneutron flux can also be used to produce a self-sustaining reaction by lining\nthe walls with lithium-rich `breeding blankets', in which a fraction of\nneutrons interacts with lithium, creating the tritium fuel. The high-intensity\nneutron flux can also result in the production of dark sector particles, feebly\ninteracting light scalars or pseudoscalars, via nuclear transitions within the\nbreeding blanket. We estimate the potential size of such dark sector flux\noutside the reactor, taking into account all current constraints, and consider\npossible detection methods at current and future thermonuclear fusion reactors.\nAs a by-product, we also recast the SNO axion bound for a CP even scalar. We\nfind that year-long searches at current and future reactors can set leading\nconstraints on dark scalar -- and dark pseudoscalar -- nucleon couplings.",
    "pdf_url": "http://arxiv.org/pdf/2502.12314v1",
    "published": "2025-02-17T20:33:06+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12313v2",
    "title": "Selling an Item Among a Strategic Bidder and a Profiled Agent",
    "authors": [
      "Ioannis Caragiannis",
      "Georgios Kalantzis"
    ],
    "abstract": "We consider the fundamental scenario where a single item is to be sold to one\nof two agents. Both agents draw their valuation for the item from the same\nprobability distribution. However, only one of them submits a bid to the\nmechanism. The other agent is profiled, i.e., the mechanism receives a\nprediction for her valuation, which can be true or false. Our goal is to design\nmechanisms for selling the item that make as much revenue as possible in cases\nof a correct or incorrect prediction. As a benchmark for proving our\nrevenue-approximation guarantees, we use the maximum expected revenue that can\nbe obtained by a strategic and an honest bidder. We study two mechanisms. The\nfirst one yields optimal revenue when the prediction is guaranteed to be\ncorrect and a constant revenue approximation when the prediction is incorrect,\nassuming that the agent valuations are drawn from a monotone hazard rate (MHR)\ndistribution. The second mechanism ignores the prediction for the second agent\nand simulates the revenue-optimal mechanism when no bid information for the\nbidders is available. We prove, again assuming that valuations are drawn from\nMHR distributions, that this mechanism achieves a constant revenue\napproximation guarantee compared to our revenue benchmark. The MHR assumption\nis necessary; we show that there are non-MHR but regular probability\ndistributions for which no constant approximation of our revenue benchmark is\npossible.",
    "pdf_url": "http://arxiv.org/pdf/2502.12313v2",
    "published": "2025-02-17T20:32:43+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12312v1",
    "title": "Nature of the ferromagnet-paramagnet transition in Y$_{1-x}$Ca$_{x}$TiO$_{3}$",
    "authors": [
      "S. Hameed",
      "I. Khayr",
      "J. Joe",
      "G. Q. Zhao",
      "Y. Cai",
      "K. M. Kojima",
      "S. Chi",
      "T. J. Williams",
      "M. Matsuda",
      "Y. J. Uemura",
      "M. Greven"
    ],
    "abstract": "Neutron scattering, magnetometry, and muon spin rotation ($\\mu$SR)\nmeasurements were performed to investigate the magnetic order and spin dynamics\nacross the ferromagnet-to-paramagnet transition in the hole-doped Mott\ninsulator Y$_{1-x}$Ca$_x$TiO$_3$. We find that the transition proceeds through\na volume-wise phase separation into ferromagnetic and paramagnetic regions.\nSpin fluctuations with a characteristic timescale of $\\sim$ 0.1 $\\mu$s, as\ndetected via $\\mu$SR, are observed to appear at Ca concentrations $x \\geq\n0.10$. The magnetic phase separation, accompanied by a modest dynamic response,\nrepresents a novel behavior in Mott systems near the loss of magnetic order. It\nis linked to a previously observed insulator-metal transition and the\nassociated electronic phase separation into hole-poor Mott insulating and\nhole-rich metallic phases for $0 < x < 0.50$. In particular, the $x$-dependence\nof the paramagnetic volume fraction strongly correlates with that of the volume\nfraction of the hole-rich metallic phase. The spin-wave spectra reveal a\ndoping-induced crossover from isotropic to two-dimensional anisotropic exchange\ninteractions, reflecting substantial changes in the orbital state with\nincreasing Ca content.",
    "pdf_url": "http://arxiv.org/pdf/2502.12312v1",
    "published": "2025-02-17T20:32:17+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.12311v2",
    "title": "Implicit Geometric Descriptor-Enabled ANN Framework for a Unified Structure-Property Relationship in Architected Nanofibrous Materials",
    "authors": [
      "Bhanugoban Maheswaran",
      "Komal Chawla",
      "Abhishek Gupta",
      "Ramathasan Thevamaran"
    ],
    "abstract": "Hierarchically architected nanofibrous materials, such as the vertically\naligned carbon nanotube (VACNT) foams, draw their exceptional mechanical\nproperties from the interplay of nanoscale size effects and inter-nanotube\ninteractions within and across architectures. However, the distinct effects of\nthese mechanisms, amplified by the architecture, on different mechanical\nproperties remain elusive, limiting their independent tunability for targeted\nproperty combinations. Reliance on architecture-specific explicit design\nparameters further inhibits the development of a unified structure-property\nrelationship rooted in those nanoscale mechanisms. Here, we introduce two\nimplicit geometric descriptors -- multi-component shape invariants (MCSI) -- in\nan artificial neural network (ANN) framework to establish a unified\nstructure-property relationship that governs diverse architectures. The MCSIs\neffectively capture the key nanoscale mechanisms that give rise to the bulk\nmechanical properties such as specific-energy absorption, peak stress, and\naverage modulus. Exploiting their ability to predict mechanical properties for\ndesigns that are even outside of the training data, we propose generalized\ndesign strategies to achieve desired mechanical property combinations in\narchitected VACNT foams. Such implicit descriptor-enabled ANN frameworks can\nguide the accelerated and tractable design of complex hierarchical materials\nfor applications ranging from shock-absorbing layers in extreme environments to\nfunctional components in soft robotics.",
    "pdf_url": "http://arxiv.org/pdf/2502.12311v2",
    "published": "2025-02-17T20:31:59+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.12310v1",
    "title": "Domain Randomization is Sample Efficient for Linear Quadratic Control",
    "authors": [
      "Tesshu Fujinami",
      "Bruce D. Lee",
      "Nikolai Matni",
      "George J. Pappas"
    ],
    "abstract": "We study the sample efficiency of domain randomization and robust control for\nthe benchmark problem of learning the linear quadratic regulator (LQR). Domain\nrandomization, which synthesizes controllers by minimizing average performance\nover a distribution of model parameters, has achieved empirical success in\nrobotics, but its theoretical properties remain poorly understood. We establish\nthat with an appropriately chosen sampling distribution, domain randomization\nachieves the optimal asymptotic rate of decay in the excess cost, matching\ncertainty equivalence. We further demonstrate that robust control, while\npotentially overly conservative, exhibits superior performance in the low-data\nregime due to its ability to stabilize uncertain systems with coarse parameter\nestimates. We propose a gradient-based algorithm for domain randomization that\nperforms well in numerical experiments, which enables us to validate the trends\npredicted by our analysis. These results provide insights into the use of\ndomain randomization in learning-enabled control, and highlight several open\nquestions about its application to broader classes of systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.12310v1",
    "published": "2025-02-17T20:31:52+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.12309v1",
    "title": "Eigenvalues in microeconomics",
    "authors": [
      "Benjamin Golub"
    ],
    "abstract": "Square matrices often arise in microeconomics, particularly in network models\naddressing applications from opinion dynamics to platform regulation. Spectral\ntheory provides powerful tools for analyzing their properties. We present an\naccessible overview of several fundamental applications of spectral methods in\nmicroeconomics, focusing especially on the Perron-Frobenius Theorem's role and\nits connection to centrality measures. Applications include social learning,\nnetwork games, public goods provision, and market intervention under\nuncertainty. The exposition assumes minimal social science background, using\nspectral theory as a unifying mathematical thread to introduce interested\nreaders to some exciting current topics in microeconomic theory.",
    "pdf_url": "http://arxiv.org/pdf/2502.12309v1",
    "published": "2025-02-17T20:30:52+00:00",
    "categories": [
      "econ.TH",
      "cs.SI",
      "math.HO"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2502.12308v2",
    "title": "New Physics versus Quenching Factors in Coherent Neutrino Scattering",
    "authors": [
      "Yulun Li",
      "Gonzalo Herrera",
      "Patrick Huber"
    ],
    "abstract": "Recent results on the Coherent Elastic Neutrino-Nucleus Scattering\n(CE$\\nu$NS) on germanium present significant discrepancies among experiments.\nWe perform a combined analysis of the Dresden-II, CONUS+ and COHERENT data,\nquantifying the impact of quenching factor uncertainties on their CE$\\nu$NS\ncross section measurement. No choice of quenching factor can bring these three\ndata sets into mutual agreement, whereas the combination of COHERENT with\neither Dresden-II or CONUS+ agrees well albeit for very different quenching\nfactors. We further study the quenching factor dependence on the sensitivity of\nthese experiments to a large neutrino magnetic moment, finding that the\nconstraints can vary by up to an order of magnitude. Our work highlights the\nimportance of reducing this uncertainty on quenching factors in order to probe\nnew physics from neutrinos at the low-energy frontier.",
    "pdf_url": "http://arxiv.org/pdf/2502.12308v2",
    "published": "2025-02-17T20:28:55+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2503.05725v2",
    "title": "A new framework for prognostics in decentralized industries: Enhancing fairness, security, and transparency through Blockchain and Federated Learning",
    "authors": [
      "T. Q. D. Pham",
      "K. D. Tran",
      "Khanh T. P. Nguyen",
      "X. V. Tran",
      "L. KÃ¶ehl",
      "K. P. Tran"
    ],
    "abstract": "As global industries transition towards Industry 5.0 predictive maintenance\nPM remains crucial for cost effective operations resilience and minimizing\ndowntime in increasingly smart manufacturing environments In this chapter we\nexplore how the integration of Federated Learning FL and blockchain BC\ntechnologies enhances the prediction of machinerys Remaining Useful Life RUL\nwithin decentralized and human centric industrial ecosystems Traditional\ncentralized data approaches raise concerns over privacy security and\nscalability especially as Artificial intelligence AI driven smart manufacturing\nbecomes more prevalent This chapter leverages FL to enable localized model\ntraining across multiple sites while utilizing BC to ensure trust transparency\nand data integrity across the network This BC integrated FL framework optimizes\nRUL predictions enhances data privacy and security establishes transparency and\npromotes collaboration in decentralized manufacturing It addresses key\nchallenges such as maintaining privacy and security ensuring transparency and\nfairness and incentivizing participation in decentralized networks Experimental\nvalidation using the NASA CMAPSS dataset demonstrates the model effectiveness\nin real world scenarios and we extend our findings to the broader research\ncommunity through open source code on GitHub inviting collaborative development\nto drive innovation in Industry 5.0",
    "pdf_url": "http://arxiv.org/pdf/2503.05725v2",
    "published": "2025-02-17T20:28:40+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.12307v1",
    "title": "The Agafonov and Schnorr-Stimm theorems for probabilistic automata",
    "authors": [
      "Laurent Bienvenu",
      "Hugo Gimbert",
      "Subin Pulari"
    ],
    "abstract": "For a fixed alphabet $A$, an infinite sequence $X$ is said to be normal if\nevery word $w$ over $A$ appears in $X$ with the same frequency as any other\nword of the same length. A classical result of Agafonov (1966) relates\nnormality to finite automata as follows: a sequence $X$ is normal if and only\nif any subsequence of $X$ selected by a finite automaton is itself normal.\nAnother theorem of Schnorr and Stimm (1972) gives an alternative\ncharacterization: a sequence $X$ is normal if and only if no gambler can win\nlarge amounts of money by betting on the sequence $X$ using a strategy that can\nbe described by a finite automaton. Both of these theorems are established in\nthe setting of deterministic finite automata. This raises the question as to\nwhether they can be extended to the setting of probabilistic finite automata.\nIn the case of the Agafonov theorem, this question was positively answered by\nL\\'echine et al.\\ (2024) in a restricted case of probabilistic automata with\nrational transition probabilities.\n  In this paper, we settle the full conjecture by proving that both the\nAgafonov and the Schnorr-Stimm theorems hold true for arbitrary probabilistic\nautomata. Specifically, we show that a sequence $X$ is normal if and only if\nany probabilistic automaton selects a normal subsequence of $X$ with\nprobability $1$. We also show that a sequence $X$ is normal if and only if a\nprobabilistic finite-state gambler fails to win on $X$ with probability $1$.",
    "pdf_url": "http://arxiv.org/pdf/2502.12307v1",
    "published": "2025-02-17T20:26:55+00:00",
    "categories": [
      "cs.FL",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.FL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12306v1",
    "title": "The Effectiveness of Golden Tickets and Wooden Spoons for Budget-Feasible Mechanisms",
    "authors": [
      "Bart de Keijzer",
      "Guido SchÃ¤fer",
      "Artem Tsikiridis",
      "Carmine Ventre"
    ],
    "abstract": "One of the main challenges in mechanism design is to carefully engineer\nincentives ensuring truthfulness while maintaining strong social welfare\napproximation guarantees. But these objectives are often in conflict, making it\nimpossible to design effective mechanisms. An important class of mechanism\ndesign problems that belong to this category are budget-feasible mechanisms.\nHere, the designer needs to procure services of maximum value from a set of\nagents while being on a budget, i.e., having a limited budget to enforce\ntruthfulness. However, as empirical studies suggest, factors like limited\ninformation and bounded rationality question the idealized assumption that the\nagents behave perfectly rationally. Motivated by this, Troyan and Morill in\n2022 introduced non-obvious manipulability (NOM) as a more lenient incentive\ncompatibility notion. In this paper, we investigate whether resorting to NOM\nenables us to derive improved mechanisms in budget-feasible domains. We\nestablish a tight bound of 2 on the approximation guarantee of budget-feasible\nmechanisms satisfying NOM for the general class of monotone subadditive\nvaluation functions. Our result thus establishes a clear separation between the\nachievable guarantees for DSIC (perfectly rational agents) and NOM (imperfectly\nrational agents) as no truthful mechanism can achieve a guarantee better than\n2.41. Along the way, we fully characterize BNOM and WNOM (which together form\nNOM) and derive matching upper and lower bounds, respectively. Conceptually,\nour characterization results suggest \"Golden Tickets\" and \"Wooden Spoons\" as\nnatural means to realize BNOM and WNOM, respectively. Additionally, we show\nthat randomized budget-feasible mechanisms satisfying BNOM can achieve an\nexpected approximation ratio arbitrarily close to 1.",
    "pdf_url": "http://arxiv.org/pdf/2502.12306v1",
    "published": "2025-02-17T20:26:46+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12305v2",
    "title": "Stochastic SchrÃ¶dinger equation for a homodyne measurement setup of strongly correlated systems",
    "authors": [
      "Aniket Patra",
      "Felix Motzoi",
      "Klaus MÃ¸lmer"
    ],
    "abstract": "Starting from an experimentally feasible atomic setup, we derive a stochastic\nSchr\\\"{o}dinger equation that captures the homodyne detection record of a\nstrongly interacting system. Applying the rotating wave approximation to the\nlinear atom-light coupling, we arrive at a reduced equation formulated solely\nin terms of atomic operators. In the appropriate limit, this equation converges\nto that of Gaussian continuous quantum measurement -- revealing that the\ncomplexities of real-world detection can, under certain conditions, echo the\nelegance of idealized theory. To illustrate the utility of this framework, we\nnumerically study the Bose-Hubbard model under continuous observation, showing\nthat time-domain analysis of the measurement signal uncovers rich dynamical\nfeatures, including quantum jumps, that are obscured in ensemble-averaged\nspectral data.",
    "pdf_url": "http://arxiv.org/pdf/2502.12305v2",
    "published": "2025-02-17T20:26:39+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12304v1",
    "title": "Warmup Generations: A Task-Agnostic Approach for Guiding Sequence-to-Sequence Learning with Unsupervised Initial State Generation",
    "authors": [
      "Senyu Li",
      "Zipeng Sun",
      "Jiayi Wang",
      "Xue Liu",
      "Pontus Stenetorp",
      "Siva Reddy",
      "David Ifeoluwa Adelani"
    ],
    "abstract": "Traditional supervised fine-tuning (SFT) strategies for sequence-to-sequence\ntasks often train models to directly generate the target output. Recent work\nhas shown that guiding models with intermediate steps, such as keywords,\noutlines, or reasoning chains, can significantly improve performance,\ncoherence, and interpretability. However, these methods often depend on\npredefined intermediate formats and annotated data, limiting their scalability\nand generalizability. In this work, we introduce a task-agnostic framework that\nenables models to generate intermediate \"warmup\" sequences. These warmup\nsequences, serving as an initial state for subsequent generation, are optimized\nto enhance the probability of generating the target sequence without relying on\nexternal supervision or human-designed structures. Drawing inspiration from\nreinforcement learning principles, our method iteratively refines these\nintermediate steps to maximize their contribution to the final output, similar\nto reward-driven optimization in reinforcement learning with human feedback.\nExperimental results across tasks such as translation, summarization, and\nmulti-choice question answering for logical reasoning show that our approach\noutperforms traditional SFT methods, and offers a scalable and flexible\nsolution for sequence-to-sequence tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.12304v1",
    "published": "2025-02-17T20:23:42+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12303v1",
    "title": "From Gaming to Research: GTA V for Synthetic Data Generation for Robotics and Navigations",
    "authors": [
      "Matteo Scucchia",
      "Matteo Ferrara",
      "Davide Maltoni"
    ],
    "abstract": "In computer vision, the development of robust algorithms capable of\ngeneralizing effectively in real-world scenarios more and more often requires\nlarge-scale datasets collected under diverse environmental conditions. However,\nacquiring such datasets is time-consuming, costly, and sometimes unfeasible. To\naddress these limitations, the use of synthetic data has gained attention as a\nviable alternative, allowing researchers to generate vast amounts of data while\nsimulating various environmental contexts in a controlled setting. In this\nstudy, we investigate the use of synthetic data in robotics and navigation,\nspecifically focusing on Simultaneous Localization and Mapping (SLAM) and\nVisual Place Recognition (VPR). In particular, we introduce a synthetic dataset\ncreated using the virtual environment of the video game Grand Theft Auto V (GTA\nV), along with an algorithm designed to generate a VPR dataset, without human\nsupervision. Through a series of experiments centered on SLAM and VPR, we\ndemonstrate that synthetic data derived from GTA V are qualitatively comparable\nto real-world data. Furthermore, these synthetic data can complement or even\nsubstitute real-world data in these applications. This study sets the stage for\nthe creation of large-scale synthetic datasets, offering a cost-effective and\nscalable solution for future research and development.",
    "pdf_url": "http://arxiv.org/pdf/2502.12303v1",
    "published": "2025-02-17T20:22:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12302v1",
    "title": "Chaotic Map based Compression Approach to Classification",
    "authors": [
      "Harikrishnan N B",
      "Anuja Vats",
      "Nithin Nagaraj",
      "Marius Pedersen"
    ],
    "abstract": "Modern machine learning approaches often prioritize performance at the cost\nof increased complexity, computational demands, and reduced interpretability.\nThis paper introduces a novel framework that challenges this trend by\nreinterpreting learning from an information-theoretic perspective, viewing it\nas a search for encoding schemes that capture intrinsic data structures through\ncompact representations. Rather than following the conventional approach of\nfitting data to complex models, we propose a fundamentally different method\nthat maps data to intervals of initial conditions in a dynamical system. Our\nGLS (Generalized L\\\"uroth Series) coding compression classifier employs skew\ntent maps - a class of chaotic maps - both for encoding data into initial\nconditions and for subsequent recovery. The effectiveness of this simple\nframework is noteworthy, with performance closely approaching that of\nwell-established machine learning methods. On the breast cancer dataset, our\napproach achieves 92.98\\% accuracy, comparable to Naive Bayes at 94.74\\%. While\nthese results do not exceed state-of-the-art performance, the significance of\nour contribution lies not in outperforming existing methods but in\ndemonstrating that a fundamentally simpler, more interpretable approach can\nachieve competitive results.",
    "pdf_url": "http://arxiv.org/pdf/2502.12302v1",
    "published": "2025-02-17T20:22:49+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12301v1",
    "title": "SMOL: Professionally translated parallel data for 115 under-represented languages",
    "authors": [
      "Isaac Caswell",
      "Elizabeth Nielsen",
      "Jiaming Luo",
      "Colin Cherry",
      "Geza Kovacs",
      "Hadar Shemtov",
      "Partha Talukdar",
      "Dinesh Tewari",
      "Baba Mamadi Diane",
      "Koulako Moussa Doumbouya",
      "Djibrila Diane",
      "Solo Farabado CissÃ©"
    ],
    "abstract": "We open-source SMOL (Set of Maximal Overall Leverage), a suite of training\ndata to unlock translation for low-resource languages (LRLs). SMOL has been\ntranslated into 115 under-resourced languages, including many for which there\nexist no previous public resources, for a total of 6.1M translated tokens. SMOL\ncomprises two sub-datasets, each carefully chosen for maximum impact given its\nsize: SMOL-Sent, a set of sentences chosen for broad unique token coverage, and\nSMOL-Doc, a document-level source focusing on a broad topic coverage. They join\nthe already released GATITOS for a trifecta of paragraph, sentence, and\ntoken-level content. We demonstrate that using SMOL to prompt or fine-tune\nLarge Language Models yields robust ChrF improvements. In addition to\ntranslation, we provide factuality ratings and rationales for all documents in\nSMOL-Doc, yielding the first factuality datasets for most of these languages.",
    "pdf_url": "http://arxiv.org/pdf/2502.12301v1",
    "published": "2025-02-17T20:22:08+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12300v1",
    "title": "Per-channel autoregressive linear prediction padding in tiled CNN processing of 2D spatial data",
    "authors": [
      "Olli Niemitalo",
      "Otto Rosenberg",
      "Nathaniel Narra",
      "Olli Koskela",
      "Iivari Kunttu"
    ],
    "abstract": "We present linear prediction as a differentiable padding method. For each\nchannel, a stochastic autoregressive linear model is fitted to the padding\ninput by minimizing its noise terms in the least-squares sense. The padding is\nformed from the expected values of the autoregressive model given the known\npixels. We trained the convolutional RVSR super-resolution model from scratch\non satellite image data, using different padding methods. Linear prediction\npadding slightly reduced the mean square super-resolution error compared to\nzero and replication padding, with a moderate increase in time cost. Linear\nprediction padding better approximated satellite image data and RVSR feature\nmap data. With zero padding, RVSR appeared to use more of its capacity to\ncompensate for the high approximation error. Cropping the network output by a\nfew pixels reduced the super-resolution error and the effect of the choice of\npadding method on the error, favoring output cropping with the faster\nreplication and zero padding methods, for the studied workload.",
    "pdf_url": "http://arxiv.org/pdf/2502.12300v1",
    "published": "2025-02-17T20:21:33+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12299v1",
    "title": "Vibrational properties of photochromic yttrium oxyhydride and oxydeuteride thin films",
    "authors": [
      "Martins Zubkins",
      "Jevgenijs Gabrusenoks",
      "Rihards Aleksis",
      "George Chikvaidze",
      "Edvards Strods",
      "Viktors Vibornijs",
      "Alons Lends",
      "Karlis Kundzins",
      "Juris Purans"
    ],
    "abstract": "A comprehensive study of the vibrational properties of photochromic yttrium\noxyhydride (YHO) and oxydeuteride (YDO) thin films is presented. These films\nare deposited using reactive magnetron sputtering, followed by post-oxidation.\nOur investigation employs vibrational Fourier-transform infrared (FTIR)\nspectroscopy, in conjunction with first-principles Density Functional Theory\n(DFT) calculations. The FTIR spectra of the films reveal broad vibrational\nbands, primarily attributed to the disordered structure containing small\ncrystallites (<10 nm), as confirmed by solid-state nuclear magnetic resonance\nand X-ray diffraction measurements. An isotopic shift from approximately 900 to\n745 cm-1 is observed in the hydrogen/deuterium-related vibration band, while\nthe lower frequency bands (< 600 cm-1) remain unaffected upon replacement of\nhydrogen with deuterium. These experimental observations are consistent with\nthe DFT theoretical calculations for various stable YHO lattices reported in\nthe literature. Illumination of the films with ultraviolet light at 3.3 eV\nleads to additional absorption not only in the visible light range but also up\nto approximately 2000 cm-1 in the mid-infrared region. However, no phase\ntransformation change or formation of hydroxyl (OH) groups are observed\nfollowing illumination. Our findings provide valuable insight into the\nvibrational and photochromic properties of YH(D)O thin films.",
    "pdf_url": "http://arxiv.org/pdf/2502.12299v1",
    "published": "2025-02-17T20:20:21+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.12298v1",
    "title": "Symmetric Rank-One Quasi-Newton Methods for Deep Learning Using Cubic Regularization",
    "authors": [
      "Aditya Ranganath",
      "Mukesh Singhal",
      "Roummel Marcia"
    ],
    "abstract": "Stochastic gradient descent and other first-order variants, such as Adam and\nAdaGrad, are commonly used in the field of deep learning due to their\ncomputational efficiency and low-storage memory requirements. However, these\nmethods do not exploit curvature information. Consequently, iterates can\nconverge to saddle points or poor local minima. On the other hand, Quasi-Newton\nmethods compute Hessian approximations which exploit this information with a\ncomparable computational budget. Quasi-Newton methods re-use previously\ncomputed iterates and gradients to compute a low-rank structured update. The\nmost widely used quasi-Newton update is the L-BFGS, which guarantees a positive\nsemi-definite Hessian approximation, making it suitable in a line search\nsetting. However, the loss functions in DNNs are non-convex, where the Hessian\nis potentially non-positive definite. In this paper, we propose using a\nlimited-memory symmetric rank-one quasi-Newton approach which allows for\nindefinite Hessian approximations, enabling directions of negative curvature to\nbe exploited. Furthermore, we use a modified adaptive regularized cubics\napproach, which generates a sequence of cubic subproblems that have closed-form\nsolutions with suitable regularization choices. We investigate the performance\nof our proposed method on autoencoders and feed-forward neural network models\nand compare our approach to state-of-the-art first-order adaptive stochastic\nmethods as well as other quasi-Newton methods.x",
    "pdf_url": "http://arxiv.org/pdf/2502.12298v1",
    "published": "2025-02-17T20:20:11+00:00",
    "categories": [
      "math.OC",
      "cs.IT",
      "cs.LG",
      "cs.NA",
      "math.IT",
      "math.NA",
      "stat.ML"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12297v2",
    "title": "Duo Streamers: A Streaming Gesture Recognition Framework",
    "authors": [
      "Boxuan Zhu",
      "Sicheng Yang",
      "Zhuo Wang",
      "Haining Liang",
      "Junxiao Shen"
    ],
    "abstract": "Gesture recognition in resource-constrained scenarios faces significant\nchallenges in achieving high accuracy and low latency. The streaming gesture\nrecognition framework, Duo Streamers, proposed in this paper, addresses these\nchallenges through a three-stage sparse recognition mechanism, an RNN-lite\nmodel with an external hidden state, and specialized training and\npost-processing pipelines, thereby making innovative progress in real-time\nperformance and lightweight design. Experimental results show that Duo\nStreamers matches mainstream methods in accuracy metrics, while reducing the\nreal-time factor by approximately 92.3%, i.e., delivering a nearly 13-fold\nspeedup. In addition, the framework shrinks parameter counts to 1/38 (idle\nstate) and 1/9 (busy state) compared to mainstream models. In summary, Duo\nStreamers not only offers an efficient and practical solution for streaming\ngesture recognition in resource-constrained devices but also lays a solid\nfoundation for extended applications in multimodal and diverse scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.12297v2",
    "published": "2025-02-17T20:13:43+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12296v1",
    "title": "Temporal Coarse Graining for Classical Stochastic Noise in Quantum Systems",
    "authors": [
      "Tameem Albash",
      "Steve Young",
      "N. Tobias Jacobson"
    ],
    "abstract": "Simulations of quantum systems with Hamiltonian classical stochastic noise\ncan be challenging when the noise exhibits temporal correlations over a\nmultitude of time scales, such as for $1/f$ noise in solid-state quantum\ninformation processors. Here we present an approach for simulating Hamiltonian\nclassical stochastic noise that performs temporal coarse-graining by\neffectively integrating out the high-frequency components of the noise. We\nfocus on the case where the stochastic noise can be expressed as a sum of\nOrnstein-Uhlenbeck processes. Temporal coarse-graining is then achieved by\nconditioning the stochastic process on a coarse realization of the noise,\nexpressing the conditioned stochastic process in terms of a sum of smooth,\ndeterministic functions and bridge processes with boundaries fixed at zero, and\nperforming the ensemble average over the bridge processes. For\nOrnstein-Uhlenbeck processes, the deterministic components capture all\ndependence on the coarse realization, and the stochastic bridge processes are\nnot only independent but taken from the same distribution with correlators that\ncan be expressed analytically, allowing the associated noise propagators to be\nprecomputed once for all simulations. This combination of noise trajectories on\na coarse time grid and ensemble averaging over bridge processes has practical\nadvantages, such as a simple concatenation rule, that we highlight with\nnumerical examples.",
    "pdf_url": "http://arxiv.org/pdf/2502.12296v1",
    "published": "2025-02-17T20:09:18+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12295v1",
    "title": "On the Computational Tractability of the (Many) Shapley Values",
    "authors": [
      "Reda Marzouk",
      "Shahaf Bassan",
      "Guy Katz",
      "Colin de la Higuera"
    ],
    "abstract": "Recent studies have examined the computational complexity of computing\nShapley additive explanations (also known as SHAP) across various models and\ndistributions, revealing their tractability or intractability in different\nsettings. However, these studies primarily focused on a specific variant called\nConditional SHAP, though many other variants exist and address different\nlimitations. In this work, we analyze the complexity of computing a much\nbroader range of such variants, including Conditional, Interventional, and\nBaseline SHAP, while exploring both local and global computations. We show that\nboth local and global Interventional and Baseline SHAP can be computed in\npolynomial time for various ML models under Hidden Markov Model distributions,\nextending popular algorithms such as TreeSHAP beyond empirical distributions.\nOn the downside, we prove intractability results for these variants over a wide\nrange of neural networks and tree ensembles. We believe that our results\nemphasize the intricate diversity of computing Shapley values, demonstrating\nhow their complexity is substantially shaped by both the specific SHAP variant,\nthe model type, and the distribution.",
    "pdf_url": "http://arxiv.org/pdf/2502.12295v1",
    "published": "2025-02-17T20:08:03+00:00",
    "categories": [
      "cs.LG",
      "cs.CC",
      "cs.LO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12294v1",
    "title": "Connections between $\\mathcal{S}$-operators and restriction estimates for spheres over finite fields",
    "authors": [
      "Hunseok Kang",
      "Doowon Koh"
    ],
    "abstract": "In this paper, we introduce a new operator, $\\mathcal{S}$, which is closely\nrelated to the restriction problem for spheres in $\\mathbb{F}_q^d$, the\n$d$-dimensional vector space over the finite field $\\mathbb{F}_q$ with $q$\nelements. The $\\mathcal{S}$ operator is considered as a specific operator that\nmaps functions on $\\mathbb{F}_q^d$ to functions on $\\mathbb{F}_q^{d+1}$. We\nexplore a relationship between the boundedness of the $\\mathcal{S}$ operator\nand the restriction estimate for spheres in $\\mathbb{F}_q^d$. Consequently,\nusing this relationship, we prove that the $L^2$ restriction conjectures for\nspheres hold in all dimensions when the test functions are restricted to\nhomogeneous functions of degree zero.",
    "pdf_url": "http://arxiv.org/pdf/2502.12294v1",
    "published": "2025-02-17T20:01:20+00:00",
    "categories": [
      "math.CA",
      "math.AP",
      "42B05, 43A32, 43A15"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12292v2",
    "title": "Independence Tests for Language Models",
    "authors": [
      "Sally Zhu",
      "Ahmed Ahmed",
      "Rohith Kuditipudi",
      "Percy Liang"
    ],
    "abstract": "We consider the following problem: given the weights of two models, can we\ntest whether they were trained independently -- i.e., from independent random\ninitializations? We consider two settings: constrained and unconstrained. In\nthe constrained setting, we make assumptions about model architecture and\ntraining and propose a family of statistical tests that yield exact p-values\nwith respect to the null hypothesis that the models are trained from\nindependent random initializations. These p-values are valid regardless of the\ncomposition of either model's training data; we compute them by simulating\nexchangeable copies of each model under our assumptions and comparing various\nsimilarity measures of weights and activations between the original two models\nversus these copies. We report the p-values from these tests on pairs of 21\nopen-weight models (210 total pairs) and correctly identify all pairs of\nnon-independent models. Our tests remain effective even if one model was\nfine-tuned for many tokens. In the unconstrained setting, where we make no\nassumptions about training procedures, can change model architecture, and allow\nfor adversarial evasion attacks, the previous tests no longer work. Instead, we\npropose a new test which matches hidden activations between two models, and\nwhich is robust to adversarial transformations and to changes in model\narchitecture. The test can also do localized testing: identifying specific\nnon-independent components of models. Though we no longer obtain exact p-values\nfrom this, empirically we find it behaves as one and reliably identifies\nnon-independent models. Notably, we can use the test to identify specific parts\nof one model that are derived from another (e.g., how Llama 3.1-8B was pruned\nto initialize Llama 3.2-3B, or shared layers between Mistral-7B and\nStripedHyena-7B), and it is even robust to retraining individual layers of\neither model from scratch.",
    "pdf_url": "http://arxiv.org/pdf/2502.12292v2",
    "published": "2025-02-17T20:01:08+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12293v2",
    "title": "Data-Efficient Limited-Angle CT Using Deep Priors and Regularization",
    "authors": [
      "Ilmari Vahteristo",
      "Zhi-Song Liu",
      "Andreas Rupp"
    ],
    "abstract": "Reconstructing an image from its Radon transform is a fundamental computed\ntomography (CT) task arising in applications such as X-ray scans. In many\npractical scenarios, a full 180-degree scan is not feasible, or there is a\ndesire to reduce radiation exposure. In these limited-angle settings, the\nproblem becomes ill-posed, and methods designed for full-view data often leave\nsignificant artifacts. We propose a very low-data approach to reconstruct the\noriginal image from its Radon transform under severe angle limitations. Because\nthe inverse problem is ill-posed, we combine multiple regularization methods,\nincluding Total Variation, a sinogram filter, Deep Image Prior, and a\npatch-level autoencoder. We use a differentiable implementation of the Radon\ntransform, which allows us to use gradient-based techniques to solve the\ninverse problem. Our method is evaluated on a dataset from the Helsinki\nTomography Challenge 2022, where the goal is to reconstruct a binary disk from\nits limited-angle sinogram. We only use a total of 12 data points--eight for\nlearning a prior and four for hyperparameter selection--and achieve results\ncomparable to the best synthetic data-driven approaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.12293v2",
    "published": "2025-02-17T20:01:08+00:00",
    "categories": [
      "cs.CV",
      "I.4.5"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12291v1",
    "title": "A framework for the generalised ErdÅs-Rothschild problem and a resolution of the dichromatic triangle case",
    "authors": [
      "Pranshu Gupta",
      "Yani Pehova",
      "Emil Powierski",
      "Katherine Staden"
    ],
    "abstract": "The Erd\\H{o}s-Rothschild problem from 1974 asks for the maximum number of\n$s$-edge colourings in an $n$-vertex graph which avoid a monochromatic copy of\n$K_k$, given positive integers $n,s,k$. In this paper, we systematically study\nthe generalisation of this problem to a given forbidden family of colourings of\n$K_k$. This problem typically exhibits a dichotomy whereby for some values of\n$s$, the extremal graph is the `trivial' one, namely the Tur\\'an graph on $k-1$\nparts, with no copies of $K_k$; while for others, this graph is no longer\nextremal and determining the extremal graph becomes much harder.\n  We generalise a framework developed for the monochromatic\nErd\\H{o}s-Rothschild problem to the general setting and work in this framework\nto obtain our main results, which concern two specific forbidden families:\ntriangles with exactly two colours, and improperly coloured cliques. We\nessentially solve these problems fully for all integers $s \\geq 2$ and large\n$n$. In both cases we obtain an infinite family of structures which are\nextremal for some $s$, which are the first results of this kind.\n  A consequence of our results is that for every non-monochromatic colour\npattern, every extremal graph is complete partite. Our work extends work of\nHoppen, Lefmann and Schmidt and of Benevides, Hoppen and Sampaio.",
    "pdf_url": "http://arxiv.org/pdf/2502.12291v1",
    "published": "2025-02-17T20:00:21+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12290v2",
    "title": "Asymptotic safety, quantum gravity, and the swampland: a conceptual assessment",
    "authors": [
      "Ivano Basile",
      "Benjamin Knorr",
      "Alessia Platania",
      "Marc Schiffer"
    ],
    "abstract": "We provide a conceptual assessment of some aspects of fundamental quantum\nfield theories of gravity in light of foundational aspects of the swampland\nprogram. On the one hand, asymptotically safe quantum gravity may provide a\nsimple and predictive framework, thanks to a finite number of relevant\nparameters. On the other hand, a (sub-)set of intertwined swampland conjectures\non the consistency of quantum gravity can be argued to be universal via\neffective field theory considerations. We answer whether some foundational\nfeatures of these frameworks are compatible. This involves revisiting and\nrefining several arguments (and loopholes) concerning the relation between\nfield-theoretic descriptions of gravity and general swampland ideas. We\nidentify the thermodynamics of black holes, spacetime topology change, and\nholography as the core aspects of this relation. We draw lessons on the\nfeatures that a field theoretic description of gravity must (not) have to be\nconsistent with fundamental principles underlying the swampland program, and on\nthe universality of the latter.",
    "pdf_url": "http://arxiv.org/pdf/2502.12290v2",
    "published": "2025-02-17T20:00:06+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.12289v2",
    "title": "Evaluating Step-by-step Reasoning Traces: A Survey",
    "authors": [
      "Jinu Lee",
      "Julia Hockenmaier"
    ],
    "abstract": "Step-by-step reasoning is widely used to enhance the reasoning ability of\nlarge language models (LLMs) in complex problems. Evaluating the quality of\nreasoning traces is crucial for understanding and improving LLM reasoning.\nHowever, existing evaluation practices are highly inconsistent, resulting in\nfragmented progress across evaluator design and benchmark development. To\naddress this gap, this survey provides a comprehensive overview of step-by-step\nreasoning evaluation, proposing a taxonomy of evaluation criteria with four\ntop-level categories (factuality, validity, coherence, and utility). Based on\nthe taxonomy, we review different evaluator implementations and recent\nfindings, leading to promising directions for future research.",
    "pdf_url": "http://arxiv.org/pdf/2502.12289v2",
    "published": "2025-02-17T19:58:31+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.13173v1",
    "title": "Thinking Preference Optimization",
    "authors": [
      "Wang Yang",
      "Hongye Jin",
      "Jingfeng Yang",
      "Vipin Chaudhary",
      "Xiaotian Han"
    ],
    "abstract": "Supervised Fine-Tuning (SFT) has been a go-to and effective method for\nenhancing long chain-of-thought (CoT) reasoning in relatively small LLMs by\nfine-tuning them with long CoT responses from larger LLMs. To continually\nimprove reasoning abilities, we can either collect new high-quality long CoT\nreasoning SFT data or repeatedly train on existing SFT datasets. However,\nacquiring new long CoT SFT data is costly and limited, while repeated training\noften results in a performance plateau or decline. To further boost the\nperformance with the SFT data, we propose Thinking Preference Optimization\n(ThinkPO), a simple yet effective post-SFT method that enhances long CoT\nreasoning without requiring new long CoT responses. Instead, ThinkPO utilizes\nreadily available or easily obtainable short CoT reasoning responses as\nrejected answers and long CoT responses as chosen answers for the same\nquestion. It then applies direct preference optimization to encourage the model\nto favor longer reasoning outputs. Experiments show that ThinkPO further\nimproves the reasoning performance of SFT-ed models, e.g. it increases math\nreasoning accuracy of SFT-ed models by 8.6% and output length by 25.9%.\nNotably, ThinkPO is capable of continually boosting the performance of the\npublicly distilled SFT model, e.g., increasing the official\nDeepSeek-R1-Distill-Qwen-7B's performance on MATH500 from 87.4% to 91.2%.",
    "pdf_url": "http://arxiv.org/pdf/2502.13173v1",
    "published": "2025-02-17T19:56:21+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.13172v2",
    "title": "Unveiling Privacy Risks in LLM Agent Memory",
    "authors": [
      "Bo Wang",
      "Weiyi He",
      "Shenglai Zeng",
      "Zhen Xiang",
      "Yue Xing",
      "Jiliang Tang",
      "Pengfei He"
    ],
    "abstract": "Large Language Model (LLM) agents have become increasingly prevalent across\nvarious real-world applications. They enhance decision-making by storing\nprivate user-agent interactions in the memory module for demonstrations,\nintroducing new privacy risks for LLM agents. In this work, we systematically\ninvestigate the vulnerability of LLM agents to our proposed Memory EXTRaction\nAttack (MEXTRA) under a black-box setting. To extract private information from\nmemory, we propose an effective attacking prompt design and an automated prompt\ngeneration method based on different levels of knowledge about the LLM agent.\nExperiments on two representative agents demonstrate the effectiveness of\nMEXTRA. Moreover, we explore key factors influencing memory leakage from both\nthe agent designer's and the attacker's perspectives. Our findings highlight\nthe urgent need for effective memory safeguards in LLM agent design and\ndeployment.",
    "pdf_url": "http://arxiv.org/pdf/2502.13172v2",
    "published": "2025-02-17T19:55:53+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12288v1",
    "title": "Analysis of Dry Friction Dynamics in a Vibro-Impact Energy Harvester",
    "authors": [
      "Christina Athanasouli",
      "Daniil Yurchenko",
      "Rachel Kuske"
    ],
    "abstract": "Vibro-impact (VI) systems provide a promising nonlinear mechanism for energy\nharvesting (EH) in many engineering applications. Here, we consider a VI-EH\nsystem that consists of an inclined cylindrical capsule that is externally\nforced and a bullet that is allowed to move inside the capsule, and analyze its\ndynamics under the presence of dry friction. Dry friction introduces a\nswitching manifold corresponding to zero relative velocity where the bullet\nsticks to the capsule, appearing as sliding in the model. We identify\nanalytical conditions for the occurrence of non-stick and sliding motions, and\nconstruct a series of nonlinear maps that capture model solutions and their\ndynamics on the switching and impacting manifolds. An interplay of smooth\n(period-doubling) and non-smooth (grazing) bifurcations characterizes the\ntransition from periodic solutions with alternating impacts to solutions with\nan additional impact on one end of the capsule per period. This transition is\npreceded by a sequence of grazing-sliding, switching-sliding and\ncrossing-sliding bifurcations on the switching manifold that may reverse period\ndoubling bifurcations for larger values of the dry friction coefficient. In\ngeneral, a larger dry friction coefficient also results in larger sliding\nintervals, lower impact velocities yielding lower average energy outputs, and a\nshift in the location of some bifurcations. Surprisingly, we identify parameter\nregimes in which higher dry friction maintains higher energy output levels, as\nit shifts the location of grazing bifurcations.",
    "pdf_url": "http://arxiv.org/pdf/2502.12288v1",
    "published": "2025-02-17T19:52:48+00:00",
    "categories": [
      "math.DS",
      "37G15, 74H60, 74H45, 74M20, 70K50, 34A36"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.12287v1",
    "title": "Boundary Reconstruction for the Anisotropic Fractional CalderÃ³n Problem",
    "authors": [
      "Xiaopeng Cheng",
      "Angkana RÃ¼land"
    ],
    "abstract": "In this article, we provide a boundary reconstruction result for the\nanisotropic fractional Calder\\'on problem and its associated degenerate\nelliptic extension into the upper half plane. More precisely, considering the\nsetting from \\cite{FGKU21}, we show that the metric on the measurement set can\nbe reconstructed from the source-to-solution data. To this end, we rely on the\napproach by Brown \\cite{B01} in the framework developed in \\cite{NT01} (see\nalso \\cite{KY02}) after localizing the problem by considering it through an\nextension perspective.",
    "pdf_url": "http://arxiv.org/pdf/2502.12287v1",
    "published": "2025-02-17T19:48:25+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12286v1",
    "title": "Rational Capability in Concurrent Games",
    "authors": [
      "Yinfeng Li",
      "Emiliano Lorini",
      "Munyque Mittelmann"
    ],
    "abstract": "We extend concurrent game structures (CGSs) with a simple notion of\npreference over computations and define a minimal notion of rationality for\nagents based on the concept of dominance. We use this notion to interpret a CL\nand an ATL languages that extend the basic CL and ATL languages with modalities\nfor rational capability, namely, a coalition's capability to rationally enforce\na given property. For each of these languages, we provide results about the\ncomplexity of satisfiability checking and model checking as well as about\naxiomatization.",
    "pdf_url": "http://arxiv.org/pdf/2502.12286v1",
    "published": "2025-02-17T19:47:36+00:00",
    "categories": [
      "cs.LO",
      "cs.MA"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12285v1",
    "title": "Cyclic Relaxed Douglas-Rachford Splitting for Inconsistent Nonconvex Feasibility",
    "authors": [
      "Thi Lan Dinh",
      "G. S. Matthijs Jansen",
      "D. Russell Luke"
    ],
    "abstract": "We study the cyclic relaxed Douglas-Rachford algorithm for possibly\nnonconvex, and inconsistent feasibility problems. This algorithm can be viewed\nas a convex relaxation between the cyclic Douglas-Rachford algorithm first\nintroduced by Borwein and Tam [2014] and the classical cyclic projections\nalgorithm. We characterize the fixed points of the cyclic relaxed\nDouglas-Rachford algorithm and show the relation of the {\\em shadows} of these\nfixed points to the fixed points of the cyclic projections algorithm. Finally,\nwe provide conditions that guarantee local quantitative convergence estimates\nin the nonconvex, inconsistent setting.",
    "pdf_url": "http://arxiv.org/pdf/2502.12285v1",
    "published": "2025-02-17T19:46:53+00:00",
    "categories": [
      "math.OC",
      "65K10, 49J53, 49K40, 49M05, 65K05, 90C26, 49M20"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12284v1",
    "title": "Entanglement theory with limited computational resources",
    "authors": [
      "Lorenzo Leone",
      "Jacopo Rizzo",
      "Jens Eisert",
      "Sofiene Jerbi"
    ],
    "abstract": "The precise quantification of the ultimate efficiency in manipulating quantum\nresources lies at the core of quantum information theory. However, purely\ninformation-theoretic measures fail to capture the actual computational\ncomplexity involved in performing certain tasks. In this work, we rigorously\naddress this issue within the realm of entanglement theory, a cornerstone of\nquantum information science. We consider two key figures of merit: the\ncomputational distillable entanglement and the computational entanglement cost,\nquantifying the optimal rate of entangled bits (ebits) that can be extracted\nfrom or used to dilute many identical copies of $n$-qubit bipartite pure\nstates, using computationally efficient local operations and classical\ncommunication (LOCC). We demonstrate that computational entanglement measures\ndiverge significantly from their information-theoretic counterparts. While the\nvon Neumann entropy captures information-theoretic rates for pure-state\ntransformations, we show that under computational constraints, the min-entropy\ninstead governs optimal entanglement distillation. Meanwhile, efficient\nentanglement dilution incurs in a major cost, requiring maximal\n$(\\tilde{\\Omega}(n))$ ebits even for nearly unentangled states. Surprisingly,\nin the worst-case scenario, even if an efficient description of the state\nexists and is fully known, one gains no advantage over state-agnostic\nprotocols. Our results establish a stark, maximal separation of\n$\\tilde{\\Omega}(n)$ vs. $o(1)$ between computational and information-theoretic\nentanglement measures. Finally, our findings yield new sample-complexity bounds\nfor measuring and testing the von Neumann entropy, fundamental limits on\nefficient state compression, and efficient LOCC tomography protocols.",
    "pdf_url": "http://arxiv.org/pdf/2502.12284v1",
    "published": "2025-02-17T19:43:59+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12283v1",
    "title": "The nature of an imaginary quasi-periodic oscillation in the soft-to-hard transition of MAXI J1820+070",
    "authors": [
      "Candela Bellavita",
      "Mariano MÃ©ndez",
      "Federico GarcÃ­a",
      "Ruican Ma",
      "Ole KÃ¶nig"
    ],
    "abstract": "A recent study shows that if the power spectra (PS) of accreting compact\nobjects consist of a combination of Lorentzian functions that are coherent in\ndifferent energy bands but incoherent with each other, the same is true for the\nReal and Imaginary parts of the cross spectrum (CS). Using this idea, we\ndiscovered imaginary quasi-periodic oscillations (QPOs) in NICER observations\nof the black hole candidate MAXI J1820+070. The imaginary QPOs appear as narrow\nfeatures with a small Real and large Imaginary part in the CS but are not\nsignificantly detected in the PS when they overlap in frequency with other\nvariability components. The coherence function drops and the phase lags\nincrease abruptly at the frequency of the imaginary QPO. We show that the\nmulti-Lorentzian model that fits the PS and CS of the source in two energy\nbands correctly reproduces the lags and the coherence, and that the narrow drop\nof the coherence is caused by the interaction of the imaginary QPO with other\nvariability components. The imaginary QPO appears only in the decay of the\noutburst, during the transition from the high-soft to the low-hard state of\nMAXI J1820+070, and its frequency decreases from approximately 5 Hz to around 1\nHz as the source spectrum hardens. We also analysed the earlier observations of\nthe transition, where no narrow features were seen, and we identified a QPO in\nthe PS that appears to evolve into the imaginary QPO as the source hardens. As\nfor the type-B and C QPOs in this source, the rms spectrum of the imaginary QPO\nincreases with energy. The lags of the imaginary QPO are similar to those of\nthe type-B and C QPOs above 2 keV but differ from the lags of those other QPOs\nbelow that energy. While the properties of this imaginary QPO resemble those of\ntype-C QPOs, we cannot rule out that it is a new type of QPO.",
    "pdf_url": "http://arxiv.org/pdf/2502.12283v1",
    "published": "2025-02-17T19:39:34+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12282v1",
    "title": "ULX collimation by outflows in moderately magnetized neutron stars",
    "authors": [
      "Fatemeh Kayanikhoo",
      "WÅodek KluÅºniak",
      "Miljenko ÄemeljiÄ"
    ],
    "abstract": "We perform radiative magnetohydrodynamics simulations in general relativity\n(GRRMHD) of super-Eddington disk accretion onto neutron stars endowed with a\nmagnetic dipole corresponding to surface strengths not exceeding 100 GigaGauss.\nAccretion is found to power strong outflows which collimate the emergent\nradiation of the accretion columns, leading to apparent radiative luminosities\nof $\\sim 100$ Eddington, when the true luminosity is a few Eddington units.\nSurprisingly, the collimation cone/angle widens with increasing magnetic field.\nThus, in our simulations the apparent luminosity of the neutron star is\nsubstantially larger for the weaker magnetic fields ($10^{10}\\,$G) than for the\nstronger ones ($10^{11}\\,$G). We conclude that a super-Eddington accreting\nneutron star with the dipole magnetic field $10^{10}\\,$G is the most likely\nsource of ultraluminous X-rays.",
    "pdf_url": "http://arxiv.org/pdf/2502.12282v1",
    "published": "2025-02-17T19:38:31+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12281v2",
    "title": "Euler characteristics of higher rank double ramification loci in genus one",
    "authors": [
      "Luca Battistella",
      "Navid Nabijou"
    ],
    "abstract": "Double ramification loci parametrise marked curves where a weighted sum of\nthe markings is linearly trivial; higher rank loci are obtained by imposing\nseveral such conditions simultaneously. We obtain closed formulae for the\norbifold Euler characteristics of double ramification loci, and their higher\nrank generalisations, in genus one. The rank one formula is a polynomial, while\nthe higher rank formula involves greatest common divisors of matrix minors. The\nproof is based on a recurrence relation, which allows for induction on the rank\nand number of markings.",
    "pdf_url": "http://arxiv.org/pdf/2502.12281v2",
    "published": "2025-02-17T19:33:31+00:00",
    "categories": [
      "math.AG",
      "math.CO",
      "14H10, 14H40, 14H52, 14N10"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12280v1",
    "title": "Connecting Large Language Model Agent to High Performance Computing Resource",
    "authors": [
      "Heng Ma",
      "Alexander Brace",
      "Carlo Siebenschuh",
      "Greg Pauloski",
      "Ian Foster",
      "Arvind Ramanathan"
    ],
    "abstract": "The Large Language Model agent workflow enables the LLM to invoke tool\nfunctions to increase the performance on specific scientific domain questions.\nTo tackle large scale of scientific research, it requires access to computing\nresource and parallel computing setup. In this work, we implemented Parsl to\nthe LangChain/LangGraph tool call setup, to bridge the gap between the LLM\nagent to the computing resource. Two tool call implementations were set up and\ntested on both local workstation and HPC environment on Polaris/ALCF. The first\nimplementation with Parsl-enabled LangChain tool node queues the tool functions\nconcurrently to the Parsl workers for parallel execution. The second\nconfiguration is implemented by converting the tool functions into Parsl\nensemble functions, and is more suitable for large task on super computer\nenvironment. The LLM agent workflow was prompted to run molecular dynamics\nsimulations, with different protein structure and simulation conditions. These\nresults showed the LLM agent tools were managed and executed concurrently by\nParsl on the available computing resource.",
    "pdf_url": "http://arxiv.org/pdf/2502.12280v1",
    "published": "2025-02-17T19:32:30+00:00",
    "categories": [
      "cs.DC",
      "cs.AI",
      "I.2.11"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12279v1",
    "title": "Bayesian inference from time series of allele frequency data using exact simulation techniques",
    "authors": [
      "Jaromir Sant",
      "Paul A. Jenkins",
      "Jere Koskela",
      "Dario Spano"
    ],
    "abstract": "A central statistical problem in population genetics is to infer evolutionary\nand biological parameters such as the strength of natural selection and allele\nage from DNA samples extracted from a contemporary population. That all samples\ncome only from the present-day has long been known to limit statistical\ninference; there is potentially more information available if one also has\naccess to ancient DNA so that inference is based on a time-series of historical\nchanges in allele frequencies. We introduce a Markov Chain Monte Carlo (MCMC)\nmethod for Bayesian inference from allele frequency time-series data based on\nan underlying Wright--Fisher diffusion model of evolution, through which one\ncan infer the parameters of essentially any selection model including those\nwith frequency-dependent effects. The chief novelty is that we show this method\nto be exact in the sense that it is possible to augment the state space\nexplored by MCMC with the unobserved diffusion trajectory, even though the\ntransition function of this diffusion is intractable. Through careful design of\na proposal distribution, we describe an efficient method in which updates to\nthe trajectory and accept/reject decisions are calculated without error. We\nillustrate the method on data capturing changes in coat colour over the past\n20,000 years, and find evidence to support previous findings that the mutant\nalleles ASIP and MC1R responsible for changes in coat color have experienced\nvery strong, possibly overdominant, selection and further provide estimates for\nthe ages of these genes.",
    "pdf_url": "http://arxiv.org/pdf/2502.12279v1",
    "published": "2025-02-17T19:28:15+00:00",
    "categories": [
      "q-bio.PE",
      "math.PR",
      "q-bio.QM",
      "stat.AP",
      "stat.CO",
      "92D25, 60J70, 65C40, 60J60, 62F15"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12278v2",
    "title": "Towards Practical First-Order Model Counting",
    "authors": [
      "Ananth K. Kidambi",
      "Guramrit Singh",
      "Paulius Dilkas",
      "Kuldeep S. Meel"
    ],
    "abstract": "First-order model counting (FOMC) is the problem of counting the number of\nmodels of a sentence in first-order logic. Since lifted inference techniques\nrely on reductions to variants of FOMC, the design of scalable methods for FOMC\nhas attracted attention from both theoreticians and practitioners over the past\ndecade. Recently, a new approach based on first-order knowledge compilation was\nproposed. This approach, called Crane, instead of simply providing the final\ncount, generates definitions of (possibly recursive) functions that can be\nevaluated with different arguments to compute the model count for any domain\nsize. However, this approach is not fully automated, as it requires manual\nevaluation of the constructed functions. The primary contribution of this work\nis a fully automated compilation algorithm, called Crane2, which transforms the\nfunction definitions into C++ code equipped with arbitrary-precision\narithmetic. These additions allow the new FOMC algorithm to scale to domain\nsizes over 500,000 times larger than the current state of the art, as\ndemonstrated through experimental results.",
    "pdf_url": "http://arxiv.org/pdf/2502.12278v2",
    "published": "2025-02-17T19:28:06+00:00",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12277v1",
    "title": "Healthcare cost prediction for heterogeneous patient profiles using deep learning models with administrative claims data",
    "authors": [
      "Mohammad Amin Morid",
      "Olivia R. Liu Sheng"
    ],
    "abstract": "Problem: How can we design patient cost prediction models that effectively\naddress the challenges of heterogeneity in administrative claims (AC) data to\nensure accurate, fair, and generalizable predictions, especially for high-need\n(HN) patients with complex chronic conditions?\n  Relevance: Accurate and equitable patient cost predictions are vital for\ndeveloping health management policies and optimizing resource allocation, which\ncan lead to significant cost savings for healthcare payers, including\ngovernment agencies and private insurers. Addressing disparities in prediction\noutcomes for HN patients ensures better economic and clinical decision-making,\nbenefiting both patients and payers.\n  Methodology: This study is grounded in socio-technical considerations that\nemphasize the interplay between technical systems (e.g., deep learning models)\nand humanistic outcomes (e.g., fairness in healthcare decisions). It\nincorporates representation learning and entropy measurement to address\nheterogeneity and complexity in data and patient profiles, particularly for HN\npatients. We propose a channel-wise deep learning framework that mitigates data\nheterogeneity by segmenting AC data into separate channels based on types of\ncodes (e.g., diagnosis, procedures) and costs. This approach is paired with a\nflexible evaluation design that uses multi-channel entropy measurement to\nassess patient heterogeneity.\n  Results: The proposed channel-wise models reduce prediction errors by 23%\ncompared to single-channel models, leading to 16.4% and 19.3% reductions in\noverpayments and underpayments, respectively. Notably, the reduction in\nprediction bias is significantly higher for HN patients, demonstrating\neffectiveness in handling heterogeneity and complexity in data and patient\nprofiles. This demonstrates the potential for applying channel-wise modeling to\ndomains with similar heterogeneity challenges.",
    "pdf_url": "http://arxiv.org/pdf/2502.12277v1",
    "published": "2025-02-17T19:20:41+00:00",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12276v1",
    "title": "Story Grammar Semantic Matching for Literary Study",
    "authors": [
      "Abigail Swenor",
      "Neil Coffee",
      "Walter Scheirer"
    ],
    "abstract": "In Natural Language Processing (NLP), semantic matching algorithms have\ntraditionally relied on the feature of word co-occurrence to measure semantic\nsimilarity. While this feature approach has proven valuable in many contexts,\nits simplistic nature limits its analytical and explanatory power when used to\nunderstand literary texts. To address these limitations, we propose a more\ntransparent approach that makes use of story structure and related elements.\nUsing a BERT language model pipeline, we label prose and epic poetry with story\nelement labels and perform semantic matching by only considering these labels\nas features. This new method, Story Grammar Semantic Matching, guides literary\nscholars to allusions and other semantic similarities across texts in a way\nthat allows for characterizing patterns and literary technique.",
    "pdf_url": "http://arxiv.org/pdf/2502.12276v1",
    "published": "2025-02-17T19:20:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12275v2",
    "title": "Integrating Expert Knowledge into Logical Programs via LLMs",
    "authors": [
      "Franciszek GÃ³rski",
      "Oskar Wysocki",
      "Marco Valentino",
      "Andre Freitas"
    ],
    "abstract": "This paper introduces ExKLoP, a novel framework designed to evaluate how\neffectively Large Language Models (LLMs) integrate expert knowledge into\nlogical reasoning systems. This capability is especially valuable in\nengineering, where expert knowledge-such as manufacturer-recommended\noperational ranges-can be directly embedded into automated monitoring systems.\nBy mirroring expert verification steps, tasks like range checking and\nconstraint validation help ensure system safety and reliability. Our approach\nsystematically evaluates LLM-generated logical rules, assessing both syntactic\nfluency and logical correctness in these critical validation tasks. We also\nexplore the models' capacity for self-correction via an iterative feedback loop\nbased on code execution outcomes. ExKLoP presents an extensible dataset\ncomprising 130 engineering premises, 950 prompts, and corresponding validation\npoints. It enables comprehensive benchmarking while allowing control over task\ncomplexity and scalability of experiments. We leverage the synthetic data\ncreation methodology to conduct extensive empirical evaluation on a diverse set\nof LLMs including Llama3, Gemma3, Codestral and QwenCoder. The results reveal\nthat most models generate nearly perfect syntactically correct code and exhibit\nstrong performance in translating expert knowledge into correct code. At the\nsame time, while most LLMs produce nearly flawless syntactic output, their\nability to correctly implement logical rules varies, as does their capacity for\nself-improvement. Overall, ExKLoP serves as a robust evaluation platform that\nstreamlines the selection of effective models for self-correcting systems while\nclearly delineating the types of errors encountered.",
    "pdf_url": "http://arxiv.org/pdf/2502.12275v2",
    "published": "2025-02-17T19:18:23+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12274v1",
    "title": "Transformations induced by hydrostatic pressure on lead metasilicate phases",
    "authors": [
      "Ariano D. Rodrigues",
      "Thiago R. Cunha",
      "Rafaella B. Pena",
      "Ulisses F. Kaneko",
      "Lucas M. E. Pinho",
      "Benjamim J. A. Moulton",
      "Paulo S. Pizani"
    ],
    "abstract": "For most silicates, controlling the crystallization - through the nucleation,\ngrowth, and stabilization of distinct crystalline phase - is critical to\nachieving the desired physical properties in the final glass-ceramic product.\nIn this context, lead metasilicate PbSiO3 (PS) represents an ideal model system\nfor investigating structural evolution under varying pressure and temperature\nconditions. This is primarily due to its distinct Raman signatures and the\ncapability of resolving its structure with high precision through diffraction\nmeasurements. These attributes enable a comprehensive evaluation of the\nthermodynamic quantities involved in this complex process, which are essential\nfor the physical description of the crystallization of glasses undergoing\nheterogeneous nucleation. We report on high-pressure in situ analyses of three\ncrystalline phases of PS: a stable monoclinic structure, a metastable hexagonal\nstructure, and a lower symmetry metastable phase. Combined high-pressure Raman\nand synchrotron X-ray diffraction indicate that the structures are highly\nsensitive to the application of hydrostatic pressure and that significant\nstructural rearrangements can be achieved in moderate pressure regimes. Such\nanalyses also enabled determining important thermodynamic variables of those\nsystems, such as compressibility. From an applied perspective, our findings\ndemonstrate that the application of pressure achievable using large-volume\npresses and capable of altering the energy states of such phases, can be\nregarded as a promising strategy to influence the stages of the overall\ncrystallization process. This approach opens new avenues for the development of\nnovel structures and properties in the resulting glass-ceramic materials",
    "pdf_url": "http://arxiv.org/pdf/2502.12274v1",
    "published": "2025-02-17T19:17:48+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.12273v2",
    "title": "Gem5-AcceSys: Enabling System-Level Exploration of Standard Interconnects for Novel Accelerators",
    "authors": [
      "Qunyou Liu",
      "Marina Zapater",
      "David Atienza"
    ],
    "abstract": "The growing demand for efficient, high-performance processing in machine\nlearning (ML) and image processing has made hardware accelerators, such as GPUs\nand Data Streaming Accelerators (DSAs), increasingly essential. These\naccelerators enhance ML and image processing tasks by offloading computation\nfrom the CPU to dedicated hardware. These accelerators rely on interconnects\nfor efficient data transfer, making interconnect design crucial for\nsystem-level performance. This paper introduces Gem5-AcceSys, an innovative\nframework for system-level exploration of standard interconnects and\nconfigurable memory hierarchies. Using a matrix multiplication accelerator\ntailored for transformer workloads as a case study, we evaluate PCIe\nperformance across diverse memory types (DDR4, DDR5, GDDR6, HBM2) and\nconfigurations, including host-side and device-side memory. Our findings\ndemonstrate that optimized interconnects can achieve up to 80% of device-side\nmemory performance and, in some scenarios, even surpass it. These results offer\nactionable insights for system architects, enabling a balanced approach to\nperformance and cost in next-generation accelerator design.",
    "pdf_url": "http://arxiv.org/pdf/2502.12273v2",
    "published": "2025-02-17T19:16:46+00:00",
    "categories": [
      "cs.AR",
      "cs.PF"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12272v5",
    "title": "Learning to Reason at the Frontier of Learnability",
    "authors": [
      "Thomas Foster",
      "Anya Sims",
      "Johannes Forkel",
      "Mattie Fellows",
      "Jakob Foerster"
    ],
    "abstract": "Reinforcement learning is now widely adopted as the final stage of large\nlanguage model training, especially for reasoning-style tasks such as maths\nproblems. Typically, models attempt each question many times during a single\ntraining step and attempt to learn from their successes and failures. However,\nwe demonstrate that throughout training with two popular algorithms (PPO and\nVinePPO) on two widely used datasets, many questions are either solved by all\nattempts - meaning they are already learned - or by none - providing no\nmeaningful training signal. To address this, we adapt a method from the\nreinforcement learning literature - sampling for learnability - and apply it to\nthe reinforcement learning stage of LLM training. Our curriculum prioritises\nquestions with high variance of success, i.e. those where the agent sometimes\nsucceeds, but not always. Our findings demonstrate that this curriculum\nconsistently boosts training performance across multiple algorithms and\ndatasets, paving the way for more efficient and effective reinforcement\nlearning with LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.12272v5",
    "published": "2025-02-17T19:16:37+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12271v1",
    "title": "Energy spectrum of the long-range Lennard-Jones potential",
    "authors": [
      "Shahar Hod"
    ],
    "abstract": "The discrete energy spectra of composite inverse power-law binding potentials\nof the form $V(r;\\alpha,\\beta,n)=-\\alpha/r^2+\\beta/r^n$ with $n>2$ are studied\n{\\it analytically}. In particular, using a functional matching procedure for\nthe eigenfunctions of the radial Schr\\\"odinger equation, we derive a remarkably\ncompact analytical formula for the discrete spectra of binding energies\n$\\{E(\\alpha,\\beta,n;k)\\}^{k=\\infty}_{k=1}$ which characterize the\nhighly-excited bound-state resonances of these long-range binding potentials.\nOur results are of practical importance for the physics of polarized molecules,\nthe physics of composite polymers, and also for physical models describing the\nquantum interactions of bosonic particles.",
    "pdf_url": "http://arxiv.org/pdf/2502.12271v1",
    "published": "2025-02-17T19:15:56+00:00",
    "categories": [
      "quant-ph",
      "physics.atom-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12270v1",
    "title": "Multiple realizations of modular flavor symmetries and their phenomenology",
    "authors": [
      "Carlos Arriaga-Osante",
      "Mu-Chun Chen",
      "Ramon Diaz-Castro",
      "Xueqi Li",
      "Xiang-Gan Liu",
      "Saul Ramos-Sanchez",
      "Michael Ratz"
    ],
    "abstract": "We point out that specifying the finite modular group does not uniquely fix a\nmodular flavor symmetry. We illustrate this using the finite modular group\n$T'$. Otherwise equivalent models based on different $T'$ lead to modular forms\nwith different properties and, hence, produce different phenomenological\nfeatures. We exemplify this in various scenarios, and show that the ability of\na given model to accommodate mass and other observed hierarchies depends\nsensitively on the way the $T'$ is implemented.",
    "pdf_url": "http://arxiv.org/pdf/2502.12270v1",
    "published": "2025-02-17T19:11:03+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12269v1",
    "title": "Ergodic optimization for beta-transformations",
    "authors": [
      "Zelai Hao",
      "Yinying Huang",
      "Oliver Jenkinson",
      "Zhiqiang Li"
    ],
    "abstract": "Ergodic optimization for beta-transformations $T_\\beta(x)= \\beta x \\pmod 1$\nis developed. If $\\beta>1$ is a beta-number, or such that the orbit-closure of\n$1$ is not minimal, we show that the Typically Periodic Optimization Conjecture\nholds, establishing that there exists an open dense set of H\\\"{o}lder\ncontinuous functions such that for each function in this set, there exists a\nunique maximizing measure, this measure is supported on a periodic orbit, and\nthe periodic locking property holds. It follows that typical periodic\noptimization is typical among the class of beta-transformations: it holds for a\nset of parameters $\\beta>1$ that is residual, and has full Lebesgue measure.",
    "pdf_url": "http://arxiv.org/pdf/2502.12269v1",
    "published": "2025-02-17T19:10:15+00:00",
    "categories": [
      "math.DS",
      "Primary: 37A99, Secondary: 37A05, 37D20, 37D35, 37E05, 37A44"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.12268v2",
    "title": "Friedman-Ramanujan functions in random hyperbolic geometry and application to spectral gaps II",
    "authors": [
      "Nalini Anantharaman",
      "Laura Monk"
    ],
    "abstract": "The core focus of this series of two articles is the study of the\ndistribution of the length spectrum of closed hyperbolic surfaces of genus $g$,\nsampled randomly with respect to the Weil-Petersson probability measure. In the\nfirst article, we introduced a notion of local topological type $T$, and\nestablished the existence of a density function $V_g^T(l)$ describing the\ndistribution of the lengths of all closed geodesics of type $T$ in a genus $g$\nhyperbolic surface. We proved that $V_g^{T}(l)$ admits an asymptotic expansion\nin powers of $1/g$. We introduced a new class of functions, called\nFriedman-Ramanujan functions, and related it to the study of the spectral gap\n$\\lambda_1$ of the Laplacian.\n  In this second part, we provide a variety of new tools allowing to compute\nand estimate the volume functions $V_g^{T}(l)$. Notably, we construct new sets\nof coordinates on Teichm\\\"uller spaces, distinct from Fenchel-Nielsen\ncoordinates, in which the Weil-Petersson volume has a simple form. These\ncoordinates are tailored to the geodesics we study, and we can therefore prove\nnice formulae for their lengths. We use these new ideas, together with a notion\nof pseudo-convolutions, to prove that the coefficients of the expansion of\n$V_g^{T}(l)$ in powers of $1/g$ are Friedman-Ramanujan functions, for any local\ntopological type $T$. We then exploit this result to prove that, for any\n$\\epsilon>0$, $\\lambda_1 \\geq \\frac14 - \\epsilon$ with probability going to one\nas $g \\rightarrow + \\infty$, or, in other words, typical hyperbolic surfaces\nhave an asymptotically optimal spectral gap.",
    "pdf_url": "http://arxiv.org/pdf/2502.12268v2",
    "published": "2025-02-17T19:08:30+00:00",
    "categories": [
      "math.MG",
      "math.SP",
      "Primary 58J50, 32G15, Secondary 05C80, 11F72"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12267v2",
    "title": "NeuroStrata: Harnessing Neurosymbolic Paradigms for Improved Design, Testability, and Verifiability of Autonomous CPS",
    "authors": [
      "Xi Zheng",
      "Ziyang Li",
      "Ivan Ruchkin",
      "Ruzica Piskac",
      "Miroslav Pajic"
    ],
    "abstract": "Autonomous cyber-physical systems (CPSs) leverage AI for perception,\nplanning, and control but face trust and safety certification challenges due to\ninherent uncertainties. The neurosymbolic paradigm replaces stochastic layers\nwith interpretable symbolic AI, enabling determinism. While promising,\nchallenges like multisensor fusion, adaptability, and verification remain. This\npaper introduces NeuroStrata, a neurosymbolic framework to enhance the testing\nand verification of autonomous CPS. We outline its key components, present\nearly results, and detail future plans.",
    "pdf_url": "http://arxiv.org/pdf/2502.12267v2",
    "published": "2025-02-17T19:07:41+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12266v3",
    "title": "Non-perturbative Overlaps in JT Gravity: From Spectral Form Factor to Generating Functions of Complexity",
    "authors": [
      "Masamichi Miyaji",
      "Shan-Ming Ruan",
      "Shono Shibuya",
      "Kazuyoshi Yano"
    ],
    "abstract": "The interplay between black hole interior dynamics and quantum chaos provides\na crucial framework for probing quantum effects in quantum gravity. In this\nwork, we investigate non-perturbative overlaps in Jackiw-Teitelboim (JT)\ngravity to uncover universal signatures of quantum chaos and quantum\ncomplexity. Taking advantage of universal spectral correlators from random\nmatrix theory, we compute the overlaps between the thermofield double (TFD)\nstate and two distinct classes of states: fixed-length states, which encode\nmaximal volume slices, and time-shifted TFD states. The squared overlaps\nnaturally define probability distributions that quantify the expectation values\nof gravitational observables. Central to our results is the introduction of\ngenerating functions for quantum complexity measures, such as $\\langle\ne^{-\\alpha \\ell} \\rangle$. The time evolution of these generating functions\nexhibits the universal slope-ramp-plateau structure, mirroring the behavior of\nthe spectral form factor (SFF). Using generating functions, we further\ndemonstrate that the universal time evolution of complexity for chaotic\nsystems, which is characterized by a linear growth followed by a late-time\nplateau, arises from the disappearance of the linear ramp as the regularization\nparameter $\\alpha$ decreases. With regard to the time-shifted TFD state, we\nderive a surprising result: the expectation value of the time shift, which\nclassically grows linearly, vanishes when non-perturbative quantum corrections\nare incorporated. This cancellation highlights a fundamental distinction\nbetween semiclassical and quantum gravitational descriptions of the black hole\ninterior. All our findings establish generating functions as powerful probes of\nquantum complexity and chaos in gravitational and quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.12266v3",
    "published": "2025-02-17T19:06:30+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2503.05724v1",
    "title": "Addressing Moral Uncertainty using Large Language Models for Ethical Decision-Making",
    "authors": [
      "Rohit K. Dubey",
      "Damian Dailisan",
      "Sachit Mahajan"
    ],
    "abstract": "We present an ethical decision-making framework that refines a pre-trained\nreinforcement learning (RL) model using a task-agnostic ethical layer.\nFollowing initial training, the RL model undergoes ethical fine-tuning, where\nhuman feedback is replaced by feedback generated from a large language model\n(LLM). The LLM embodies consequentialist, deontological, virtue, social\njustice, and care ethics as moral principles to assign belief values to\nrecommended actions during ethical decision-making. An ethical layer aggregates\nbelief scores from multiple LLM-derived moral perspectives using Belief\nJensen-Shannon Divergence and Dempster-Shafer Theory into probability scores\nthat also serve as the shaping reward, steering the agent toward choices that\nalign with a balanced ethical framework. This integrated learning framework\nhelps the RL agent navigate moral uncertainty in complex environments and\nenables it to make morally sound decisions across diverse tasks. Our approach,\ntested across different LLM variants and compared with other belief aggregation\ntechniques, demonstrates improved consistency, adaptability, and reduced\nreliance on handcrafted ethical rewards. This method is especially effective in\ndynamic scenarios where ethical challenges arise unexpectedly, making it\nwell-suited for real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2503.05724v1",
    "published": "2025-02-17T19:05:55+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.12265v1",
    "title": "Quantum geometric photocurrents of quasiparticles in superconductors",
    "authors": [
      "Daniel Kaplan",
      "Kevin P. Lucht",
      "Pavel A. Volkov",
      "J. H. Pixley"
    ],
    "abstract": "Nonlinear optical response is a sensitive probe of the geometry and symmetry\nof electronic Bloch states in solids. Here, we extend this notion to the\nBogoliubiov-de-Gennes (BdG) quasiparticles in superconductors. We present a\ntheory of photocurrents in superconductors and show that they sensitively\ndepend on the quantum geometry of the BdG excitation spectrum. For all light\npolarizations, the photocurrent is proportional to the quantum geometric\ntensor: for linear polarized light it is related to the quantum metric and for\ncircular polarization -- the Berry curvature dipole of the associated BdG\nbands. We further relate the photocurrent to the ground state symmetries,\nproviding a symmetry dictionary for the allowed photocurrent responses. For\nlight not at normal incidence to the sample, photocurrent probes time-reversal\nsymmetry breaking in systems with chiral point groups (such as twisted\nbilayers). We demonstrate that photocurrents allow to probe topology and TRS\nbreaking in twisted $d$-wave superconductors and test the nature of\nsuperconductivity in twisted WSe$_2$ and multilayer stacks of rhombohedral\ngraphene. Our results pave the way to contactless measurement of the quantum\ngeometric properties and symmetry of superconductivity in materials and\nheterostructures.",
    "pdf_url": "http://arxiv.org/pdf/2502.12265v1",
    "published": "2025-02-17T19:05:32+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mes-hall",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2502.12264v1",
    "title": "Multi-dimensional Test Design",
    "authors": [
      "Xiaoyun Qiu",
      "Liren Shan"
    ],
    "abstract": "How should one jointly design tests and the arrangement of agencies to\nadminister these tests (testing procedure)? To answer this question, we analyze\na model where a principal must use multiple tests to screen an agent with a\nmulti-dimensional type, knowing that the agent can change his type at a cost.\nWe identify a new tradeoff between setting difficult tests and using a\ndifficult testing procedure. We compare two settings: (1) the agent only\nmisrepresents his type (manipulation) and (2) the agent improves his actual\ntype (investment). Examples include interviews, regulations, and data\nclassification. We show that in the manipulation setting, stringent tests\ncombined with an easy procedure, i.e., offering tests sequentially in a fixed\norder, is optimal. In contrast, in the investment setting, non-stringent tests\nwith a difficult procedure, i.e., offering tests simultaneously, is optimal;\nhowever, under mild conditions offering them sequentially in a random order may\nbe as good. Our results suggest that whether the agent manipulates or invests\nin his type determines which arrangement of agencies is optimal.",
    "pdf_url": "http://arxiv.org/pdf/2502.12264v1",
    "published": "2025-02-17T19:03:39+00:00",
    "categories": [
      "econ.TH",
      "cs.CY",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2502.12263v1",
    "title": "Improved constraints on the Faraday rotation towards eight fast radio bursts using dense grids of polarized radio galaxies",
    "authors": [
      "Ayush Pandhi",
      "Bryan M. Gaensler",
      "Ziggy Pleunis",
      "Sebastian Hutschenreuter",
      "Casey Law",
      "Ryan Mckinven",
      "Shane P. O'Sullivan",
      "Emily B. Petroff",
      "Tessa Vernstrom"
    ],
    "abstract": "We present 2-4 GHz observations of polarized radio galaxies towards eight\nfast radio bursts (FRBs), producing grids of Faraday rotation measure (RM)\nsources with sky densities of 9-28 polarized sources per square degree. Using a\nBayesian interpolation framework, we constrain Galactic RM fluctuations below ~\n1 degree squared angular scales around the FRB positions. Despite the positions\nof all eight FRBs far from the Galactic plane, we constrain previously\nunresolved small-scale Galactic RM structures around six of the eight FRBs. In\ntwo of these fields, we find potential changes in the sign of the Galactic RM\nthat are not captured by previous, sparsely sampled RM grid observations. Our\nGalactic RM estimate towards the FRBs differs between a few rad m^-2 up to ~ 40\nrad m^-2 from the all-sky Galactic RM map of Hutschenreuter et al. (2022).\nExtrapolating our results to the known population of polarized FRB sources, we\nmay be incorrectly interpreting the host galaxy RM for ~ 30% of the FRB source\npopulation with current RM grid observations. Measuring small-scale Galactic RM\nvariations is crucial for identifying FRBs in low density and weakly magnetized\nenvironments, which in turn could serve as potent probes of cosmic magnetism.\nThis framework of reconstructing continuous Galactic RM structure from RM grid\nobservations can be readily applied to FRBs that fall in the sky coverage of\nupcoming large-sky radio polarization surveys of radio galaxies, such as the\nVery Large Array Sky Survey (VLASS) and the Polarization Sky Survey of the\nUniverse's Magnetism (POSSUM).",
    "pdf_url": "http://arxiv.org/pdf/2502.12263v1",
    "published": "2025-02-17T19:03:31+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12262v1",
    "title": "Titanium chemistry of WASP-121 b with ESPRESSO in 4-UT mode",
    "authors": [
      "B. Prinoth",
      "J. V. Seidel",
      "H. J. Hoeijmakers",
      "B. M. Morris",
      "M. Baratella",
      "N. W. Borsato",
      "Y. C. Damasceno",
      "V. Parmentier",
      "D. Kitzmann",
      "E. Sedaghati",
      "L. Pino",
      "F. Borsa",
      "R. Allart",
      "N. Santos",
      "M. Steiner",
      "A. SuÃ¡rez MascareÃ±o",
      "H. Tabernero",
      "M. R. Zapatero Osorio"
    ],
    "abstract": "Transit spectroscopy usually relies on the integration of one or several\ntransits to achieve the S/N necessary to resolve spectral features.\nConsequently, high-S/N observations of exoplanet atmospheres are essential for\ndisentangling the complex chemistry and dynamics beyond global trends. In this\nstudy, we combined two partial 4-UT transits of the ultrahot Jupiter WASP-121\nb, observed with the ESPRESSO at the VLT in order to revisit its titanium\nchemistry. Through cross-correlation analysis, we achieved detections of H I,\nLi I, Na I, K I, Mg I, Ca I, Ti I, V I, Cr I, Mn I, Fe I, Fe II, Co I, Ni I, Ba\nII, Sr I, and Sr II. Additionally, narrow-band spectroscopy allowed us to\nresolve strong single lines, resulting in significant detections of H$\\alpha$,\nH$\\beta$, H$\\gamma$, Li I, Na I, K I, Mg I, Ca II, Sr I, Sr II, and Mn I. Our\nmost notable finding is the high-significance detection of Ti I ($\\sim$\n5$\\sigma$ per spectrum, and $\\sim$ 19$\\sigma$ stacked in the planetary rest\nframe). Comparison with atmospheric models reveals that Ti I is indeed depleted\ncompared to V I. We also resolve the planetary velocity traces of both Ti I and\nV I, with Ti I exhibiting a significant blueshift toward the end of the\ntransit. This suggests that Ti I primarily originates from low-latitude regions\nwithin the super-rotating jet observed in WASP-121 b. Our observations suggest\nlimited mixing between the equatorial jet and the mid-latitudes, in contrast\nwith model predictions from GCMs. We also report the non-detection of TiO,\nwhich we attribute to inaccuracies in the line list that could hinder its\ndetection, even if present. Thus, the final determination of the presence of\nTiO must await space-based observations. We conclude that the 4-UT mode of\nESPRESSO is an excellent testbed for achieving high S/N on relatively faint\ntargets, paving the way for future observations with the ELT.",
    "pdf_url": "http://arxiv.org/pdf/2502.12262v1",
    "published": "2025-02-17T19:03:23+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12261v1",
    "title": "Vertical structure of an exoplanet's atmospheric jet stream",
    "authors": [
      "Julia V. Seidel",
      "Bibiana Prinoth",
      "Lorenzo Pino",
      "Leonardo A. dos Santos",
      "Hritam Chakraborty",
      "Vivien Parmentier",
      "Elyar Sedaghati",
      "Joost P. Wardenier",
      "Casper Farret Jentink",
      "Maria Rosa Zapatero Osorio",
      "Romain Allart",
      "David Ehrenreich",
      "Monika Lendl",
      "Giulia Roccetti",
      "Yuri Damasceno",
      "Vincent Bourrier",
      "Jorge Lillo-Box",
      "H. Jens Hoeijmakers",
      "Enric PallÃ©",
      "Nuno Santos",
      "Alejandro SuÃ¡rez MascareÃ±o",
      "Sergio G. Sousa",
      "Hugo M. Tabernero",
      "Francesco A. Pepe"
    ],
    "abstract": "Ultra-hot Jupiters, an extreme class of planets not found in our solar\nsystem, provide a unique window into atmospheric processes. The extreme\ntemperature contrasts between their day- and night-sides pose a fundamental\nclimate puzzle: how is energy distributed? To address this, we must observe the\n3D structure of these atmospheres, particularly their vertical circulation\npatterns, which can serve as a testbed for advanced Global Circulation Models\n(GCM) [e.g. 1]. Here, we show a dramatic shift in atmospheric circulation in an\nultra-hot Jupiter: a unilateral flow from the hot star-facing side to the\ncooler space-facing side of the planet sits below an equatorial\nsuper-rotational jet stream. By resolving the vertical structure of atmospheric\ndynamics, we move beyond integrated global snapshots of the atmosphere,\nenabling more accurate identification of flow patterns and allowing for a more\nnuanced comparison to models. Global circulation models based on first\nprinciples struggle to replicate the observed circulation pattern [3],\nunderscoring a critical gap between theoretical understanding of atmospheric\nflows and observational evidence. This work serves as a testbed to develop more\ncomprehensive models applicable beyond our Solar System as we prepare for the\nnext generation of giant telescopes.",
    "pdf_url": "http://arxiv.org/pdf/2502.12261v1",
    "published": "2025-02-17T19:03:21+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12260v1",
    "title": "Homoclinic classes for flows: ergodicity and SRB measures",
    "authors": [
      "Ygor de Jesus",
      "Marcielis Espitia",
      "Gabriel Ponce"
    ],
    "abstract": "In this work we intend to study homoclinic classes for some classes of flows.\nTo this end we obtain analogous results those obtained by\nHertz-Hertz-Tahzibi-Ures in the flow setting. Namely we prove that if the\nLesbegue measure gives positive measure to both stable and unstable homoclinic\nclasses of a periodic hyperbolic orbit, then their intersection constitute an\nergodic component. Futhermore, with similar techiniques we state several\nresults concerning regular SRB measures.",
    "pdf_url": "http://arxiv.org/pdf/2502.12260v1",
    "published": "2025-02-17T19:03:13+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.12259v2",
    "title": "Extracting topological spins from bulk multipartite entanglement",
    "authors": [
      "Yarden Sheffer",
      "Ady Stern",
      "Erez Berg"
    ],
    "abstract": "We address the problem of identifying a 2+1d topologically ordered phase\nusing measurements on the ground-state wavefunction. For non-chiral topological\norder, we describe a series of bulk multipartite entanglement measures that\nextract the invariants $\\sum_a d_a^2 \\theta_a^r$ for any $r \\geq 2$, where\n$d_a$ and $\\theta_a$ are the quantum dimension and topological spin of an anyon\n$a$, respectively. These invariants are obtained as expectation values of\npermutation operators between $2r$ replicas of the wavefunction, applying\ndifferent permutations on four distinct regions of the plane. Our proposed\nmeasures provide a refined tool for distinguishing topological phases,\ncapturing information beyond conventional entanglement measures such as the\ntopological entanglement entropy. We argue that any operator capable of\nextracting the above invariants must act on at least $2r$ replicas, making our\nprocedure optimal in terms of the required number of replicas. We discuss the\ngeneralization of our results to chiral states.",
    "pdf_url": "http://arxiv.org/pdf/2502.12259v2",
    "published": "2025-02-17T19:02:19+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.str-el"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2503.05723v1",
    "title": "AI Mimicry and Human Dignity: Chatbot Use as a Violation of Self-Respect",
    "authors": [
      "Jan-Willem van der Rijt",
      "Dimitri Coelho Mollo",
      "Bram Vaassen"
    ],
    "abstract": "This paper investigates how human interactions with AI-powered chatbots may\noffend human dignity. Current chatbots, driven by large language models (LLMs),\nmimic human linguistic behaviour but lack the moral and rational capacities\nessential for genuine interpersonal respect. Human beings are prone to\nanthropomorphise chatbots. Indeed, chatbots appear to be deliberately designed\nto elicit that response. As a result, human beings' behaviour toward chatbots\noften resembles behaviours typical of interaction between moral agents. Drawing\non a second-personal, relational account of dignity, we argue that interacting\nwith chatbots in this way is incompatible with the dignity of users. We show\nthat, since second-personal respect is premised on reciprocal recognition of\nsecond-personal authority, behaving towards chatbots in ways that convey\nsecond-personal respect is bound to misfire in morally problematic ways, given\nthe lack of reciprocity. Consequently, such chatbot interactions amount to\nsubtle but significant violations of self-respect: the respect we are dutybound\nto show for our own dignity. We illustrate this by discussing four actual\nchatbot use cases (information retrieval, customer service, advising, and\ncompanionship), and propound that the increasing societal pressure to engage in\nsuch interactions with chatbots poses a hitherto underappreciated threat to\nhuman dignity.",
    "pdf_url": "http://arxiv.org/pdf/2503.05723v1",
    "published": "2025-02-17T19:02:12+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.12258v1",
    "title": "SmokeNet: Efficient Smoke Segmentation Leveraging Multiscale Convolutions and Multiview Attention Mechanisms",
    "authors": [
      "Xuesong Liu",
      "Emmett J. Ientilucci"
    ],
    "abstract": "Efficient segmentation of smoke plumes is crucial for environmental\nmonitoring and industrial safety, enabling the detection and mitigation of\nharmful emissions from activities like quarry blasts and wildfires. Accurate\nsegmentation facilitates environmental impact assessments, timely\ninterventions, and compliance with safety standards. However, existing models\noften face high computational demands and limited adaptability to diverse smoke\nappearances, restricting their deployment in resource-constrained environments.\nTo address these issues, we introduce SmokeNet, a novel deep learning\narchitecture that leverages multiscale convolutions and multiview linear\nattention mechanisms combined with layer-specific loss functions to handle the\ncomplex dynamics of diverse smoke plumes, ensuring efficient and accurate\nsegmentation across varied environments. Additionally, we evaluate SmokeNet's\nperformance and versatility using four datasets, including our quarry blast\nsmoke dataset made available to the community. The results demonstrate that\nSmokeNet maintains a favorable balance between computational efficiency and\nsegmentation accuracy, making it suitable for deployment in environmental\nmonitoring and safety management systems. By contributing a new dataset and\noffering an efficient segmentation model, SmokeNet advances smoke segmentation\ncapabilities in diverse and challenging environments.",
    "pdf_url": "http://arxiv.org/pdf/2502.12258v1",
    "published": "2025-02-17T19:01:27+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12257v2",
    "title": "InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context",
    "authors": [
      "Bryan L. M. de Oliveira",
      "Luana G. B. Martins",
      "Bruno BrandÃ£o",
      "Luckeciano C. Melo"
    ],
    "abstract": "Large language models excel at following explicit instructions, but they\noften struggle with ambiguous or incomplete user requests, defaulting to\nverbose, generic responses instead of seeking clarification. We introduce\nInfoQuest, a multi-turn chat benchmark designed to evaluate how dialogue agents\nhandle hidden context in open-ended user requests. This benchmark presents\nintentionally ambiguous scenarios that require models to engage in\ninformation-seeking dialogue by asking clarifying questions before providing\nappropriate responses. Our evaluation of both open and closed models reveals\nthat, while proprietary models generally perform better, all current assistants\nstruggle to gather critical information effectively. They often require\nmultiple turns to infer user intent and frequently default to generic responses\nwithout proper clarification. We provide a systematic methodology for\ngenerating diverse scenarios and evaluating models' information-seeking\ncapabilities, which can be leveraged to automatically generate data for\nself-improvement. We also offer insights into the current limitations of\nlanguage models in handling ambiguous requests through multi-turn interactions.",
    "pdf_url": "http://arxiv.org/pdf/2502.12257v2",
    "published": "2025-02-17T19:01:10+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12256v2",
    "title": "The life cycle of giant molecular clouds in simulated Milky Way-mass galaxies",
    "authors": [
      "Yang Ni",
      "Hui Li",
      "Mark Vogelsberger",
      "Laura V. Sales",
      "Federico Marinacci",
      "Paul Torrey"
    ],
    "abstract": "In this work, we trace the complete life cycle of individual GMCs in\nhigh-resolution Milky Way-mass galaxy simulations to determine how different\nstellar feedback mechanisms and galactic-scale processes govern cloud\nlifetimes, mass evolution, and local star formation efficiency (SFE). We\nidentify GMCs in simulated galaxies and track their evolution using cloud\nevolution trees. Via cloud evolution trees, we quantify the lifetimes and SFE\nof GMCs. We further apply our diagnostics on a suite of simulations with\nvarying star formation and stellar feedback subgrid models and explore their\nimpact together with galactic environments to the GMC life cycles. Our analysis\nreveals that GMCs undergo dynamic evolution, characterized by continuous gas\naccretion, gravitational collapse, and star formation, followed by disruption\ndue to stellar feedback. The accretion process sustains the gas content\nthroughout most of the GMC life cycles, resulting in a positive correlation\nbetween GMC lifetimes and their maximum masses. The GMC lifetimes range from a\nfew to several tens of Myr, with two distinct dynamical modes: (1) GMCs near\nthe galactic center experience strong tidal disturbances, prolonging their\nlifetimes when they remain marginally unbound; (2) those in the outer regions\nare less affected by tides, remain gravitationally bound, and evolve more\nrapidly. In all model variations, we observe that GMC-scale SFE correlates with\nthe baryonic surface density of GMCs, consistent with previous studies of\nisolated GMCs. Additionally, we emphasize the critical role of galactic shear\nin regulating GMC-scale star formation and refine the correlation between local\nSFE and surface density by including its effects. These findings demonstrate\nhow stellar feedback and galactic-scale dynamics jointly shape GMC-scale star\nformation in realistic galactic environments.",
    "pdf_url": "http://arxiv.org/pdf/2502.12256v2",
    "published": "2025-02-17T19:01:04+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12255v3",
    "title": "The past, present and future of observations of externally irradiated disks",
    "authors": [
      "Planet formation environments collaboration",
      "Megan Allen",
      "Rossella Anania",
      "Morten Andersen",
      "Mari-Liis Aru",
      "Giulia Ballabio",
      "Nicholas P. Ballering",
      "Giacomo Beccari",
      "Olivier BernÃ©",
      "Arjan Bik",
      "Ryan Boyden",
      "Gavin Coleman",
      "Javiera DÃ­az-Berrios",
      "Joseph W. Eatson",
      "Jenny Frediani",
      "Jan Forbrich",
      "Katia Gkimisi",
      "Javier R. Goicoechea",
      "Saumya Gupta",
      "Mario G. Guarcello",
      "Thomas J. Haworth",
      "William J. Henney",
      "Andrea Isella",
      "Dominika Itrich",
      "Luke Keyte",
      "Jinyoung Serena Kim",
      "Michael Kuhn",
      "Franck Le Petit",
      "Lilian Luo",
      "Carlo Manara",
      "Karina MaucÃ³",
      "RaphaÃ«l Meshaka",
      "Samuel Millstone",
      "James E. Owen",
      "SÃ©bastien Paine",
      "Richard J. Parker",
      "Tyger Peake",
      "Megan Peatt",
      "Paola Pinilla",
      "Lin Qiao",
      "MarÃ­a Claudia RamÃ­rez-Tannus",
      "Suzanne Ramsay",
      "Megan Reiter",
      "CiarÃ¡n Rogers",
      "Giovanni Rosotti",
      "Ilane Schroetter",
      "Andrew Sellek",
      "Leonardo Testi",
      "Sierk van Terwisga",
      "Silvia Vicente",
      "Catherine Walsh",
      "Andrew Winter",
      "Nicholas J. Wright",
      "Peter Zeidler"
    ],
    "abstract": "Recent years have seen a surge of interest in the community studying the\neffect of ultraviolet radiation environment, predominantly set by OB stars, on\nprotoplanetary disc evolution and planet formation. This is important because a\nsignificant fraction of planetary systems, potentially including our own,\nformed in close proximity to OB stars. This is a rapidly developing field, with\na broad range of observations across many regions recently obtained or recently\nscheduled. In this paper, stimulated by a series of workshops on the topic, we\ntake stock of the current and upcoming observations. We discuss how the\ncommunity can build on this recent success with future observations to make\nprogress in answering the big questions of the field, with the broad goal of\ndisentangling how external photoevaporation contributes to shaping the observed\n(exo)planet population. Both existing and future instruments offer numerous\nopportunities to make progress towards this goal.",
    "pdf_url": "http://arxiv.org/pdf/2502.12255v3",
    "published": "2025-02-17T19:00:27+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12254v1",
    "title": "Many-body and QED effects in electron-atom inelastic scattering in EELS",
    "authors": [
      "Ioannis Iatrakis",
      "Valerii Brudanin"
    ],
    "abstract": "The elemental composition and electronic structure analysis of materials in\nElectron Energy Loss Spectroscopy (EELS) is probed by the inner shell\nionization of atoms. This is a localized process in the material which can be\nwell approximated by the scattering of a beam electron from a free atom. The\ninelastic differential cross section is calculated in the context of Quantum\nElectrodynamics (QED). The interaction of the incoming electron with the atom\nfactorizes and it is treated perturbatively in QED. The atomic transition\ncurrents are calculated in the context of the relaxed Dirac-Hartree-Fock\nmethod. Correlation effects, which are induced by the relaxation of the atomic\norbitals due to the created core-hole, are analyzed. Such effects are\nparticularly important for quantum many-body systems and they are shown to have\nimportant impact on the shape of the differential cross section near the\nionization threshold in Electron Energy Loss Spectra. In addition to the\nionization spectrum, we calculate the excitation spectrum of Sc and Dy oxides\nusing the crystal field multiplet theory. The calculation is compared to\nexperimental EELS data and shows good agreement.",
    "pdf_url": "http://arxiv.org/pdf/2502.12254v1",
    "published": "2025-02-17T19:00:24+00:00",
    "categories": [
      "physics.atom-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12253v1",
    "title": "A Precise Determination of $Î±_s$ from the Heavy Jet Mass Distribution",
    "authors": [
      "Miguel A. Benitez",
      "Arindam Bhattacharya",
      "Andre H. Hoang",
      "Vicent Mateu",
      "Matthew D. Schwartz",
      "Iain W. Stewart",
      "Xiaoyuan Zhang"
    ],
    "abstract": "A global fit for $\\alpha_s(m_Z)$ is performed on available $e^+e^-$ data for\nthe heavy jet mass distribution. The state-of-the-art theory prediction\nincludes $\\mathcal{O}(\\alpha_s^3)$ fixed-order results, N$^3$LL$^\\prime$ dijet\nresummation, N$^2$LL Sudakov shoulder resummation, and a first-principles\ntreatment of power corrections in the dijet region. Theoretical correlations\nare incorporated through a flat random-scan covariance matrix. The global fit\nresults in $0.1145^{+0.0021}_{-0.0019}$, compatible with similar determinations\nfrom thrust and $C$-parameter. Dijet resummation is essential for a robust fit,\nas it engenders insensitivity to the fit-range lower cutoff; without\nresummation the fit-range sensitivity is overwhelming. In addition, we find\nevidence for a negative power correction in the trijet region if and only if\nSudakov shoulder resummation is included.",
    "pdf_url": "http://arxiv.org/pdf/2502.12253v1",
    "published": "2025-02-17T19:00:13+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12252v3",
    "title": "Roadmap to fault tolerant quantum computation using topological qubit arrays",
    "authors": [
      "David Aasen",
      "Morteza Aghaee",
      "Zulfi Alam",
      "Mariusz Andrzejczuk",
      "Andrey Antipov",
      "Mikhail Astafev",
      "Lukas Avilovas",
      "Amin Barzegar",
      "Bela Bauer",
      "Jonathan Becker",
      "Juan M. Bello-Rivas",
      "Umesh Bhaskar",
      "Alex Bocharov",
      "Srini Boddapati",
      "David Bohn",
      "Jouri Bommer",
      "Parsa Bonderson",
      "Jan Borovsky",
      "Leo Bourdet",
      "Samuel Boutin",
      "Tom Brown",
      "Gary Campbell",
      "Lucas Casparis",
      "Srivatsa Chakravarthi",
      "Rui Chao",
      "Benjamin J. Chapman",
      "Sohail Chatoor",
      "Anna Wulff Christensen",
      "Patrick Codd",
      "William Cole",
      "Paul Cooper",
      "Fabiano Corsetti",
      "Ajuan Cui",
      "Wim van Dam",
      "Tareq El Dandachi",
      "Sahar Daraeizadeh",
      "Adrian Dumitrascu",
      "Andreas EkefjÃ¤rd",
      "Saeed Fallahi",
      "Luca Galletti",
      "Geoff Gardner",
      "Raghu Gatta",
      "Haris Gavranovic",
      "Michael Goulding",
      "Deshan Govender",
      "Flavio Griggio",
      "Ruben Grigoryan",
      "Sebastian Grijalva",
      "Sergei Gronin",
      "Jan Gukelberger",
      "Jeongwan Haah",
      "Marzie Hamdast",
      "Esben Bork Hansen",
      "Matthew Hastings",
      "Sebastian Heedt",
      "Samantha Ho",
      "Justin Hogaboam",
      "Laurens Holgaard",
      "Kevin Van Hoogdalem",
      "Jinnapat Indrapiromkul",
      "Henrik Ingerslev",
      "Lovro Ivancevic",
      "Sarah Jablonski",
      "Thomas Jensen",
      "Jaspreet Jhoja",
      "Jeffrey Jones",
      "Kostya Kalashnikov",
      "Ray Kallaher",
      "Rachpon Kalra",
      "Farhad Karimi",
      "Torsten Karzig",
      "Seth Kimes",
      "Vadym Kliuchnikov",
      "Maren Elisabeth Kloster",
      "Christina Knapp",
      "Derek Knee",
      "Jonne Koski",
      "Pasi Kostamo",
      "Jamie Kuesel",
      "Brad Lackey",
      "Tom Laeven",
      "Jeffrey Lai",
      "Gijs de Lange",
      "Thorvald Larsen",
      "Jason Lee",
      "Kyunghoon Lee",
      "Grant Leum",
      "Kongyi Li",
      "Tyler Lindemann",
      "Marijn Lucas",
      "Roman Lutchyn",
      "Morten Hannibal Madsen",
      "Nash Madulid",
      "Michael Manfra",
      "Signe Brynold Markussen",
      "Esteban Martinez",
      "Marco Mattila",
      "Jake Mattinson",
      "Robert McNeil",
      "Antonio Rodolph Mei",
      "Ryan V. Mishmash",
      "Gopakumar Mohandas",
      "Christian Mollgaard",
      "Michiel de Moor",
      "Trevor Morgan",
      "George Moussa",
      "Anirudh Narla",
      "Chetan Nayak",
      "Jens Hedegaard Nielsen",
      "William Hvidtfelt PadkÃ¦r Nielsen",
      "FrÃ©dÃ©ric Nolet",
      "Mike Nystrom",
      "Eoin O'Farrell",
      "Keita Otani",
      "Adam Paetznick",
      "Camille Papon",
      "Andres Paz",
      "Karl Petersson",
      "Luca Petit",
      "Dima Pikulin",
      "Diego Olivier Fernandez Pons",
      "Sam Quinn",
      "Mohana Rajpalke",
      "Alejandro Alcaraz Ramirez",
      "Katrine Rasmussen",
      "David Razmadze",
      "Ben Reichardt",
      "Yuan Ren",
      "Ken Reneris",
      "Roy Riccomini",
      "Ivan Sadovskyy",
      "Lauri Sainiemi",
      "Juan Carlos Estrada SaldaÃ±a",
      "Irene Sanlorenzo",
      "Simon Schaal",
      "Emma Schmidgall",
      "Cristina Sfiligoj",
      "Marcus P. da Silva",
      "Shilpi Singh",
      "Sarat Sinha",
      "Mathias Soeken",
      "Patrick Sohr",
      "Tomas Stankevic",
      "Lieuwe Stek",
      "Patrick StrÃ¸m-Hansen",
      "Eric Stuppard",
      "Aarthi Sundaram",
      "Henri Suominen",
      "Judith Suter",
      "Satoshi Suzuki",
      "Krysta Svore",
      "Sam Teicher",
      "Nivetha Thiyagarajah",
      "Raj Tholapi",
      "Mason Thomas",
      "Dennis Tom",
      "Emily Toomey",
      "Josh Tracy",
      "Matthias Troyer",
      "Michelle Turley",
      "Matthew D. Turner",
      "Shivendra Upadhyay",
      "Ivan Urban",
      "Alexander Vaschillo",
      "Dmitrii Viazmitinov",
      "Dominik Vogel",
      "Zhenghan Wang",
      "John Watson",
      "Alex Webster",
      "Joseph Weston",
      "Timothy Williamson",
      "Georg W. Winkler",
      "David J. van Woerkom",
      "Brian Paquelet WÃ¼tz",
      "Chung Kai Yang",
      "Richard Yu",
      "Emrah Yucelen",
      "JesÃºs Herranz Zamorano",
      "Roland Zeisel",
      "Guoji Zheng",
      "Justin Zilke",
      "Andrew Zimmerman"
    ],
    "abstract": "We describe a concrete device roadmap towards a fault-tolerant quantum\ncomputing architecture based on noise-resilient, topologically protected\nMajorana-based qubits. Our roadmap encompasses four generations of devices: a\nsingle-qubit device that enables a measurement-based qubit benchmarking\nprotocol; a two-qubit device that uses measurement-based braiding to perform\nsingle-qubit Clifford operations; an eight-qubit device that can be used to\nshow an improvement of a two-qubit operation when performed on logical qubits\nrather than directly on physical qubits; and a topological qubit array\nsupporting lattice surgery demonstrations on two logical qubits. Devices that\nenable this path require a superconductor-semiconductor heterostructure that\nsupports a topological phase, quantum dots and coupling between those quantum\ndots that can create the appropriate loops for interferometric measurements,\nand a microwave readout system that can perform fast, low-error single-shot\nmeasurements. We describe the key design components of these qubit devices,\nalong with the associated protocols for demonstrations of single-qubit\nbenchmarking, Clifford gate execution, quantum error detection, and quantum\nerror correction, which differ greatly from those in more conventional qubits.\nFinally, we comment on implications and advantages of this architecture for\nutility-scale quantum computation.",
    "pdf_url": "http://arxiv.org/pdf/2502.12252v3",
    "published": "2025-02-17T19:00:10+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.supr-con"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12250v2",
    "title": "Total Drell-Yan in the flavorful SMEFT",
    "authors": [
      "Gudrun Hiller",
      "Lara Nollen",
      "Daniel Wendler"
    ],
    "abstract": "We perform a global analysis of Drell-Yan production of charged leptons and\ndineutrinos, the latter in missing energy plus jet events, in proton-proton\ncollisions within the Standard Model Effective Field Theory (SMEFT). The\ncombination allows for the removal of flat directions, sharper limits and to\nprobe more couplings than the individual observables, which we show performing\na fit to LHC-data. We also find that limits have only mild dependence on lepton\nflavor patterns; hierarchies in quark flavors are driven by the parton\ndistribution functions. The strongest constraints are on couplings involving\nthe first and second generation quarks, exceeding 10 TeV. Combining flavor and\nhigh-$p_T$ data, the limits on electroweak and gluon dipole operators can be\nimproved, by up to a factor of three, highlighting once more that a more global\napproach increases sensitivities significantly. We also estimate the\nimprovements in reach over existing data for the high-luminosity LHC (HL-LHC)\nby $\\sim 1.5$, and future collider options such as the high-energy LHC (HE-LHC)\nby $\\sim 3$ and FCC-hh by $\\sim 8$. To maximize the new physics reach kinematic\ncuts and binning needs to be adjusted to each quark-flavor separately.",
    "pdf_url": "http://arxiv.org/pdf/2502.12250v2",
    "published": "2025-02-17T19:00:06+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12251v1",
    "title": "Evidence of Galactic Interaction in the Small Magellanic Cloud Probed by Gaia Selected Massive Star Candidates",
    "authors": [
      "Satoya Nakano",
      "Kengo Tachihara",
      "Mao Tamashiro"
    ],
    "abstract": "We present identifications and kinematic analysis of 7,426 massive\n($\\mathrm{\\geq}8M_{\\odot}$) stars in the Small Magellanic Cloud (SMC), using\nGaia DR3 data. We used Gaia ($G_\\mathrm{BP}-G_\\mathrm{RP}$, $G$)\ncolor-magnitude diagram to select the population of massive stars, and parallax\nto omit foreground objects. The spatial distribution of the 7,426 massive star\ncandidates is generally consistent with the spatial distribution of the\ninterstellar medium, such as H$\\alpha$ and H i emission. The identified massive\nstars show inhomogeneous distributions over the galaxy, showing several\nsuperstructures formed by massive stars with several hundred parsecs scale. The\nstellar superstructures defined by the surface density have opposite mean\nproper motions in the east and west, moving away from each other. Similarly,\nthe mean line-of-sight velocities of the superstructures are larger to the\nsoutheast and smaller to the northwest. The different east-west properties of\nthe superstructures' proper motion, line-of-sight velocity indicate that the\nSMC is being stretched by tidal forces and/or ram pressure from the Large\nMagellanic Cloud to the southeast, thereby rejecting the presence of galaxy\nrotation in the SMC.",
    "pdf_url": "http://arxiv.org/pdf/2502.12251v1",
    "published": "2025-02-17T19:00:06+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12248v3",
    "title": "Filtered cogenesis of PBH dark matter and baryons",
    "authors": [
      "Debasish Borah",
      "Indrajit Saha"
    ],
    "abstract": "We propose a novel cogenesis of baryon and dark matter (DM) in the Universe\nby utilising a first-order phase transition (FOPT) in the dark sector\ncontaining an asymmetric Dirac fermion $\\chi$. Due to the mass difference of\n$\\chi$ across the bubble walls, it is energetically favourable for $\\chi$ to\nget trapped in the false vacuum leading to the formation of Fermi-ball, which\ncan self-collapse to form primordial black hole (PBH) if $\\chi$ has a\nsufficiently large Yukawa interaction. While such PBH formed out of false\nvacuum collapse can give rise to the DM in the Universe, a tiny amount of\nasymmetric $\\chi$ leaking into the true vacuum through the bubble walls can\ntransfer the dark asymmetry into the visible sector via decay. The same mass\ndifference of $\\chi$ across the two minima which decides the amount of trapping\nor filtering of $\\chi$, also allows $\\chi$ decay into visible sector in the\ntrue minima while keeping it stable in the false vacuum. Our filtered cogenesis\nscenario can be probed via FOPT generated stochastic gravitational waves (GW)\nat near future detectors in addition to the well-known detection aspects of\nasteroid mass PBH constituting DM in the Universe.",
    "pdf_url": "http://arxiv.org/pdf/2502.12248v3",
    "published": "2025-02-17T19:00:03+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12249v2",
    "title": "Particle production from inhomogeneities: general metric perturbations",
    "authors": [
      "Raghuveer Garani",
      "Michele Redi",
      "Andrea Tesi"
    ],
    "abstract": "We present universal formulas for particle production from gravitational\ninhomogeneities. In the massless limit the result is strikingly simple and\ncompletely determined by the two-point function of the energy-momentum tensor\nthat is fixed up to a constant - the central charge - for conformally coupled\nscalars, massless fermions and gauge fields. This result can be applied to any\nconformally coupled theory, weakly or strongly interacting, unifying previous\nderivations for fields of different spin and for scalar and tensor\nperturbations. We derive the results using the Schwinger method of 1PI\neffective action and through Bogoliubov transformations that allows to compute\nexclusive information on the distribution of particles. We then apply these\nresults to stochastic backgrounds of scalar and tensor perturbations that can\nbe generated by various phenomena such us inflationary perturbations and first\norder phase transitions. Differently from particle production usually\nconsidered in cosmology this mechanism allows for the production of massless\nfields. In particular the abundance induced by inhomogeneities can easily\nreproduce the dark matter abundance if scalar perturbations produced from\ninflation are enhanced at short scales.",
    "pdf_url": "http://arxiv.org/pdf/2502.12249v2",
    "published": "2025-02-17T19:00:03+00:00",
    "categories": [
      "hep-th",
      "astro-ph.CO",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.12242v3",
    "title": "Weighing the curvature invariants",
    "authors": [
      "Jan DragaÅ¡eviÄ",
      "Ina Moslavac",
      "Ivica SmoliÄ"
    ],
    "abstract": "We prove several inequalities between the curvature invariants, which impose\nconstraints on curvature singularities. Some of the inequalities hold for a\nfamily of spacetimes which include static,\nFriedmann--Lema\\^itre--Robertson--Walker, and Bianchi type I metrics,\nindependently of whether they are solutions of some particular field equations.\nIn contrast, others hold for solutions of Einstein's gravitational field\nequation and a family of energy-momentum tensors (featuring ideal fluids,\nscalar fields and nonlinear electromagnetic fields), independently of the\nspecific form of the spacetime metric. We illustrate different behaviour of the\nbasic curvature invariants with numerous examples and discuss the consequences\nand limitations of the proven results.",
    "pdf_url": "http://arxiv.org/pdf/2502.12242v3",
    "published": "2025-02-17T19:00:02+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.12243v1",
    "title": "On the Learnability of Knot Invariants: Representation, Predictability, and Neural Similarity",
    "authors": [
      "Audrey Lindsay",
      "Fabian Ruehle"
    ],
    "abstract": "We analyze different aspects of neural network predictions of knot\ninvariants. First, we investigate the impact of different knot representations\non the prediction of invariants and find that braid representations work in\ngeneral the best. Second, we study which knot invariants are easy to learn,\nwith invariants derived from hyperbolic geometry and knot diagrams being very\neasy to learn, while invariants derived from topological or homological data\nare harder. Predicting the Arf invariant could not be learned for any\nrepresentation. Third, we propose a cosine similarity score based on gradient\nsaliency vectors, and a joint misclassification score to uncover similarities\nin neural networks trained to predict related topological invariants.",
    "pdf_url": "http://arxiv.org/pdf/2502.12243v1",
    "published": "2025-02-17T19:00:02+00:00",
    "categories": [
      "math.GT",
      "cs.LG"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12244v1",
    "title": "Lower bound on the radii of circular orbits in the extremal Kerr black-hole spacetime",
    "authors": [
      "Shahar Hod"
    ],
    "abstract": "It is often stated in the physics literature that maximally-spinning Kerr\nblack-hole spacetimes are characterized by near-horizon co-rotating circular\ngeodesics of radius $r_{\\text{circular}}$ with the property\n$r_{\\text{circular}}\\to r^+_{\\text{H}}$, where $r_{\\text{H}}$ is the horizon\nradius of the extremal black hole. Based on the famous Thorne hoop conjecture,\nin the present compact paper we provide evidence for the existence of a\nnon-trivial lower bound\n${{r_{\\text{circular}}-r_{\\text{H}}}\\over{r_{\\text{H}}}}\\gtrsim (\\mu/M)^{1/2}$\non the radii of circular orbits in the extremal Kerr black-hole spacetime,\nwhere $\\mu/M$ is the dimensionless mass ratio which characterizes the composed\nblack-hole-orbiting-particle system.",
    "pdf_url": "http://arxiv.org/pdf/2502.12244v1",
    "published": "2025-02-17T19:00:02+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.HE",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.12245v2",
    "title": "Non-Abelian phases from the condensation of Abelian anyons",
    "authors": [
      "Misha Yutushui",
      "Maria Hermanns",
      "David F. Mross"
    ],
    "abstract": "The observed fractional quantum Hall (FQH) plateaus follow a recurring\nhierarchical structure that allows an understanding of complex states based on\nsimpler ones. Condensing the elementary quasiparticles of an Abelian FQH state\nresults in a new Abelian phase at a different filling factor, and this process\ncan be iterated \\textit{ad infinitum}. We show that condensing clusters of the\nsame quasiparticles into an Abelian state can instead realize non-Abelian FQH\nstates. In particular, condensing quasiparticle pairs in the $\\nu=\\frac{2}{3}$\nLaughlin state yields the anti-Pfaffian phase at half-filling. We moreover show\nthat the successive condensation of Laughlin quasiparticles produces quantum\nHall states whose fillings coincide with the most prominent plateaus in the\nfirst excited Landau level of GaAs. More generally, such condensation can\nrealize any non-Abelian FQH state that admits a parton representation. This\nsurprising result is supported by an exact analysis of explicit wavefunctions,\nfield theory arguments, conformal-field theory constructions of trial states,\nand numerical simulations.",
    "pdf_url": "http://arxiv.org/pdf/2502.12245v2",
    "published": "2025-02-17T19:00:02+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.12246v1",
    "title": "Entropy Inequalities Constrain Holographic Erasure Correction",
    "authors": [
      "Bartlomiej Czech",
      "Sirui Shuai",
      "Yixu Wang"
    ],
    "abstract": "We interpret holographic entropy inequalities in terms of erasure correction.\nThe non-saturation of an inequality is a necessary condition for certain\nschemes of holographic erasure correction, manifested in the bulk as non-empty\noverlaps of corresponding entanglement wedges.",
    "pdf_url": "http://arxiv.org/pdf/2502.12246v1",
    "published": "2025-02-17T19:00:02+00:00",
    "categories": [
      "hep-th",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.12247v1",
    "title": "The bulge globular cluster Terzan 6 as seen from multi-conjugate adaptive optics and HST",
    "authors": [
      "Martina Loriga",
      "Cristina Pallanca",
      "Francesco R. Ferraro",
      "Emanuele Dalessandro",
      "Barbara Lanzoni",
      "Mario Cadelano",
      "Livia Origlia",
      "Cristiano Fanelli",
      "Douglas Geisler",
      "Sandro Villanova"
    ],
    "abstract": "This work consists of the first detailed photometric study of Terzan 6, one\nof the least known globular clusters in the Galactic bulge. Through the\nanalysis of high angular resolution and multi-wavelength data obtained from\nadaptive optics corrected and space observations, we built deep, optical and\nnear-infrared color-magnitude diagrams reaching $\\approx 4$ magnitudes below\nthe main-sequence turnoff. Taking advantage of 4 different epochs of\nobservations, we measured precise relative proper motions for a large sample of\nstars, from which cluster members have been solidly distinguished from Galactic\nfield interlopers. A non-canonical reddening law (with $R_V=2.85$) and\nhigh-resolution differential reddening map, with color excess variations up to\n$\\delta E(B-V) \\approx 0.8 $ mag, have been derived in the direction of the\nsystem. According to these findings, new values of the extinction and distance\nmodulus have been obtained: respectively, $E(B-V)=2.36\\pm0.05$ and\n$(m-M)_0=14.46 \\pm 0.10$ (corresponding to $d=7.8 \\pm 0.3$ kpc). We also\nprovide the first determinations of the cluster center and projected density\nprofile from resolved star counts. The center is offset by more than $7$ arcsec\nto the east from the literature value, and the structural parameters obtained\nfrom the King model fitting to the density profile indicate that Terzan 6 is in\nan advanced stage of its dynamical evolution. We also determined the absolute\nage of the system, finding $t=13\\pm 1 $ Gyr, in agreement with the old ages\nfound for the globular clusters in the Galactic bulge. From the\nre-determination of the absolute magnitude of the red giant branch bump and the\nrecent estimate of the cluster global metallicity, we find that Terzan 6 nicely\nmatches the tight relation between these two parameters drawn by the Galactic\nglobular cluster population.",
    "pdf_url": "http://arxiv.org/pdf/2502.12247v1",
    "published": "2025-02-17T19:00:02+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.14895v1",
    "title": "High-Dynamic Radar Sequence Prediction for Weather Nowcasting Using Spatiotemporal Coherent Gaussian Representation",
    "authors": [
      "Ziye Wang",
      "Yiran Qin",
      "Lin Zeng",
      "Ruimao Zhang"
    ],
    "abstract": "Weather nowcasting is an essential task that involves predicting future radar\necho sequences based on current observations, offering significant benefits for\ndisaster management, transportation, and urban planning. Current prediction\nmethods are limited by training and storage efficiency, mainly focusing on 2D\nspatial predictions at specific altitudes. Meanwhile, 3D volumetric predictions\nat each timestamp remain largely unexplored. To address such a challenge, we\nintroduce a comprehensive framework for 3D radar sequence prediction in weather\nnowcasting, using the newly proposed SpatioTemporal Coherent Gaussian Splatting\n(STC-GS) for dynamic radar representation and GauMamba for efficient and\naccurate forecasting. Specifically, rather than relying on a 4D Gaussian for\ndynamic scene reconstruction, STC-GS optimizes 3D scenes at each frame by\nemploying a group of Gaussians while effectively capturing their movements\nacross consecutive frames. It ensures consistent tracking of each Gaussian over\ntime, making it particularly effective for prediction tasks. With the\ntemporally correlated Gaussian groups established, we utilize them to train\nGauMamba, which integrates a memory mechanism into the Mamba framework. This\nallows the model to learn the temporal evolution of Gaussian groups while\nefficiently handling a large volume of Gaussian tokens. As a result, it\nachieves both efficiency and accuracy in forecasting a wide range of dynamic\nmeteorological radar signals. The experimental results demonstrate that our\nSTC-GS can efficiently represent 3D radar sequences with over $16\\times$ higher\nspatial resolution compared with the existing 3D representation methods, while\nGauMamba outperforms state-of-the-art methods in forecasting a broad spectrum\nof high-dynamic weather conditions.",
    "pdf_url": "http://arxiv.org/pdf/2502.14895v1",
    "published": "2025-02-17T19:00:02+00:00",
    "categories": [
      "cs.CV",
      "eess.SP"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12236v1",
    "title": "Increasing the distance of topological codes with time vortex defects",
    "authors": [
      "Gilad Kishony",
      "Erez Berg"
    ],
    "abstract": "We propose modifying topological quantum error correcting codes by\nincorporating space-time defects, termed ``time vortices,'' to reduce the\nnumber of physical qubits required to achieve a desired logical error rate. A\ntime vortex is inserted by adding a spatially varying delay to the periodic\nmeasurement sequence defining the code such that the delay accumulated on a\nhomologically non-trivial cycle is an integer multiple of the period. We\nanalyze this construction within the framework of the Floquet color code and\noptimize the embedding of the code on a torus along with the choice of the\nnumber of time vortices inserted in each direction. Asymptotically, the\nvortexed code requires less than half the number of qubits as the vortex-free\ncode to reach a given code distance. We benchmark the performance of the\nvortexed Floquet color code by Monte Carlo simulations with a circuit-level\nnoise model and demonstrate that the smallest vortexed code (with $30$ qubits)\noutperforms the vortex-free code with $42$ qubits.",
    "pdf_url": "http://arxiv.org/pdf/2502.12236v1",
    "published": "2025-02-17T19:00:01+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12237v1",
    "title": "Systematic biases from the exclusion of higher harmonics in parameter estimation on LISA binaries",
    "authors": [
      "Sophia Yi",
      "Francesco Iacovelli",
      "Sylvain Marsat",
      "Digvijay Wadekar",
      "Emanuele Berti"
    ],
    "abstract": "The remarkable sensitivity achieved by the planned Laser Interferometer Space\nAntenna (LISA) will allow us to observe gravitational-wave signals from the\nmergers of massive black hole binaries (MBHBs) with signal-to-noise ratio (SNR)\nin the hundreds, or even thousands. At such high SNR, our ability to precisely\ninfer the parameters of an MBHB from the detected signal will be limited by the\naccuracy of the waveform templates we use. In this paper, we explore the\nsystematic biases that arise in parameter estimation if we use waveform\ntemplates that do not model radiation in higher-order multipoles. This is an\nimportant consideration for the large fraction of high-mass events expected to\nbe observed with LISA. We examine how the biases change for MBHB events with\ndifferent total masses, mass ratios, and inclination angles. We find that\nsystematic biases due to insufficient mode content are severe for events with\ntotal redshifted mass $\\gtrsim10^6\\,M_\\odot$. We then compare several methods\nof predicting such systematic biases without performing a full Bayesian\nparameter estimation. In particular, we show that through direct likelihood\noptimization it is possible to predict systematic biases with remarkable\ncomputational efficiency and accuracy. Finally, we devise a method to construct\napproximate waveforms including angular multipoles with $\\ell\\geq5$ to better\nunderstand how many additional modes (beyond the ones available in current\napproximants) might be required to perform unbiased parameter estimation on the\nMBHB signals detected by LISA.",
    "pdf_url": "http://arxiv.org/pdf/2502.12237v1",
    "published": "2025-02-17T19:00:01+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.HE"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.12238v1",
    "title": "Searching For Superheavy Decaying Particles With Ultra-High-Energy Neutrino Observatories",
    "authors": [
      "Kim V. Berghaus",
      "Dan Hooper",
      "Emily R. Simon"
    ],
    "abstract": "If there exist unstable but long-lived relics of the early universe, their\ndecays could produce detectable fluxes of gamma rays and neutrinos. In this\npaper, we point out that the decays of superheavy particles, $m_{\\chi} \\gtrsim\n10^{10} \\, \\text{GeV}$,would produce an enhanced flux of ultra-high-energy\nneutrinos through the processes of muon and pion pair production in the\nresulting electromagnetic cascades. These processes transfer energy from\nelectromagnetic decay products into neutrinos, relaxing the constraints that\ncan be derived from gamma-ray observations, and increasing the sensitivity of\nhigh-energy neutrino telescopes to superheavy particle decays. Taking this into\naccount, we derive new constraints on long-lived superheavy relics from the\nIceCube Neutrino Observatory, and from the Fermi Gamma-Ray Space Telescope. We\nfind that IceCube-Gen2, and other next generation neutrino telescopes, will\nprovide unprecedented sensitivity to the decays of superheavy dark matter\nparticles and other long-lived relics.",
    "pdf_url": "http://arxiv.org/pdf/2502.12238v1",
    "published": "2025-02-17T19:00:01+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "astro-ph.HE"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12239v2",
    "title": "Binarity at LOw Metallicity (BLOeM): Multiplicity of early B-type supergiants in the Small Magellanic Cloud",
    "authors": [
      "N. Britavskiy",
      "L. Mahy",
      "D. J. Lennon",
      "L. R. Patrick",
      "H. Sana",
      "J. I. VillaseÃ±or",
      "T. Shenar",
      "J. Bodensteiner",
      "M. Bernini-Peron",
      "S. R. Berlanas",
      "D. M. Bowman",
      "P. A. Crowther",
      "S. E. de Mink",
      "C. J. Evans",
      "Y. GÃ¶tberg",
      "G. Holgado",
      "C. Johnston",
      "Z. Keszthelyi",
      "J. Klencki",
      "N. Langer",
      "I. Mandel",
      "A. Menon",
      "M. Moe",
      "L. M. Oskinova",
      "D. Pauli",
      "M. Pawlak",
      "V. Ramachandran",
      "M. Renzo",
      "A. A. C. Sander",
      "F. R. N. Schneider",
      "A. Schootemeijer",
      "K. Sen",
      "S. SimÃ³n-DÃ­az",
      "J. Th. van Loon",
      "J. S. Vink"
    ],
    "abstract": "The blue supergiant (BSG) domain contains a large variety of stars whose past\nand future evolutionary paths are still highly uncertain. Since binary\ninteraction plays a crucial role in the fate of massive stars, investigating\nthe multiplicity among BSGs helps shed light on the fate of such objects. We\naim to estimate the binary fraction of a large sample of BSGs in the Small\nMagellanic Cloud within the Binarity at LOw Metallicity (BLOeM) survey. In\ntotal, we selected 262 targets with spectral types B0-B3 and luminosity classes\nI-II. This work is based on spectroscopic data collected by the GIRAFFE\ninstrument, mounted on the Very Large Telescope, which gathered nine epochs\nover three months. Our spectroscopic analysis for each target includes the\nindividual and peak-to-peak radial velocity measurements, an investigation of\nthe line profile variability, and a periodogram analysis to search for possible\nshort- and long-period binaries. By applying a 20 km s$^{-1}$ threshold on the\npeak-to-peak radial velocities above which we would consider the star to be\nbinary, the resulting observed spectroscopic binary fraction for our BSG sample\nis 23 $\\pm$ 3$\\%$. In addition, we derived reliable orbital periods for 41\nspectroscopic binaries and potential binary candidates, among which there are\n17 eclipsing binaries, including 20 SB1 and SB2 systems with periods of less\nthan 10 days. We reported a significant drop in the binary fraction of BSGs\nwith spectral types later than B2 and effective temperatures less than 18 kK,\nwhich could indicate the end of the main sequence phase in this temperature\nregime. We found no metallicity dependence in the binary fraction of BSGs,\ncompared to existing spectroscopic surveys of the Galaxy and Large Magellanic\nCloud.",
    "pdf_url": "http://arxiv.org/pdf/2502.12239v2",
    "published": "2025-02-17T19:00:01+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12240v1",
    "title": "Observable and computable entanglement in time",
    "authors": [
      "Alexey Milekhin",
      "Zofia Adamska",
      "John Preskill"
    ],
    "abstract": "We propose a novel family of entanglement measures for time-separated\nsubsystems. Our definitions are applicable to any quantum system, continuous or\ndiscrete. To illustrate their utility, we derive upper and lower bounds on\ntime-separated correlation functions, akin to the bound on spatially separated\ncorrelators in terms of the mutual information. In certain cases our bounds are\ntight. For relativistic quantum field theories our definition agrees with the\nanalytic continuation from spacelike to timelike separated regions. We provide\nrelevant measurement protocols and execute them on the IBM quantum device\nibm_sherbrooke for a simple qubit system. Also we perform explicit computations\nfor an Ising spin chain, free fermions, (1+1)-dimensional conformal field\ntheories and holographic theories. Finally we explain how the proposed\nentanglement in time provides a microscopic definition for the recently\nintroduced timelike pseudoentropy.",
    "pdf_url": "http://arxiv.org/pdf/2502.12240v1",
    "published": "2025-02-17T19:00:01+00:00",
    "categories": [
      "quant-ph",
      "hep-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12241v2",
    "title": "Certification of quantum correlations and DIQKD at arbitrary distances through routed Bell tests",
    "authors": [
      "Pavel Sekatski",
      "Jef Pauwels",
      "Edwin Peter Lobo",
      "Stefano Pironio",
      "Nicolas Brunner"
    ],
    "abstract": "Transmission loss represents a major obstacle to the device-independent\ncertification of quantum correlations over long distances, limiting\napplications such as device-independent quantum key distribution (DIQKD). In\nthis work, we investigate the recently proposed concept of routed Bell\nexperiments, in which a particle sent to one side can be measured either near\nor far from the source. We prove that routed Bell tests involving only\nentangled qubits can certify quantum correlations even in the presence of\narbitrary loss on the channel to the distant device. This is achieved by\nadapting concepts from self-testing and quantum steering to the routed Bell\ntest framework. Finally, as a natural extension of our approach, we outline a\nDIQKD protocol that, in principle, is secure over arbitrary distances.",
    "pdf_url": "http://arxiv.org/pdf/2502.12241v2",
    "published": "2025-02-17T19:00:01+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12232v1",
    "title": "A shocking outcome: Jet dynamics and polarimetric signatures of the multi-band flare in blazar OJ 248",
    "authors": [
      "G. F. Paraschos"
    ],
    "abstract": "The connection between $\\gamma$-ray flares and blazars is a topic of active\nresearch, with few sources exhibiting distinct enough such outbursts to be able\nto conclusively connect them to features in their jet morphology. Here we\npresent an investigation of the sole $\\gamma$-ray flare of the blazar OJ 248\nthus far, in association with its jet structure, as revealed by very long\nbaseline interferometry (VLBI). We find that throughout the course of the\n$\\gamma$-ray flare, the fractional linear polarisation increases in the jet of\nOJ 248, and the VLBI electric vector position angles (EVPAs) turn perpendicular\nto the bulk jet flow. We interpret this behaviour as a moving shock, travelling\nthrough a recollimation shock and upscattering photons via the inverse Compton\nscattering process, producing a $\\gamma$-ray flare; we discuss possible\nmechanisms. Our hypothesised shock-shock interaction scenario is a viable\nmechanism to induce such EVPA rotations in both optical and radio bands.",
    "pdf_url": "http://arxiv.org/pdf/2502.12232v1",
    "published": "2025-02-17T19:00:00+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12233v1",
    "title": "Quantum Critical Dynamics Induced by Topological Zero Modes",
    "authors": [
      "Ilia Komissarov",
      "Tobias Holder",
      "Raquel Queiroz"
    ],
    "abstract": "We investigate the low-frequency ac transport in the Su-Schrieffer-Heeger\n(SSH) chain with chiral disorder near the topological delocalization\ntransition. Our key finding is that the formation of hybridized pairs of\ntopological domain wall zero modes leads to the anomalous logarithmic scaling\nof the ac conductivity $\\sigma(\\omega) \\sim \\log \\omega$ at criticality, and\n$\\sigma(\\omega) \\sim \\omega^{2 \\delta} \\log ^2 \\omega$ away from it. Using the\ncombination of real-space renormalization group analysis and qualitative\nhybridization arguments, we demonstrate that the form of the scaling of ac\nconductivity at criticality stems directly from the stretched-exponential\n($\\psi(x) \\sim e^{-s \\sqrt{x}}$) spatial decay of zero-mode wavefunctions at\nthe critical point.",
    "pdf_url": "http://arxiv.org/pdf/2502.12233v1",
    "published": "2025-02-17T19:00:00+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.dis-nn"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.12234v1",
    "title": "A new convection scheme for GCMs of temperate sub-Neptunes",
    "authors": [
      "Edouard F. L. Barrier",
      "Nikku Madhusudhan"
    ],
    "abstract": "Atmospheric characterisation of temperate sub-Neptunes is the new frontier of\nexoplanetary science with recent JWST observations of possible Hycean world\nK2-18b. Accurate modelling of atmospheric processes is essential to\ninterpreting high-precision spectroscopic data given the wide range of possible\nconditions in the sub-Neptune regime, including on potentially habitable\nplanets. Notably, convection is an important process which can operate in\ndifferent modes across sub-Neptune conditions. Convection can act very\ndifferently in atmospheres with a high condensible mass fraction (non-dilute\natmospheres) or with a lighter background gas, e.g. water convection in a\nH$_2$-rich atmosphere, and can be much weaker or even shut down entirely in the\nlatter case. We present a new mass-flux scheme which can capture these\nvariations and simulate convection over a wide range of parameter space for use\nin 3D general circulation models (GCMs). We validate our scheme for two\nrepresentative cases, a terrestrial-like atmosphere and a mini-Neptune\natmosphere. In the terrestrial case, considering TRAPPIST-1e with an Earth-like\natmosphere, the model performs near-identically to Earth-tuned models in an\nEarth-like convection case. In the mini-Neptune case, considering the bulk\nproperties of K2-18b and assuming a deep H$_2$-rich atmosphere, we demonstrate\nthe capability of the scheme to reproduce non-condensing convection. We find\nconvection occurring at pressures greater than 0.3 bar and the dynamical\nstructure shows high-latitude prograde jets. Our convection scheme will aid in\nthe 3D climate modelling of a wide range of exoplanet atmospheres, and enable\nfurther exploration of temperate sub-Neptune atmospheres.",
    "pdf_url": "http://arxiv.org/pdf/2502.12234v1",
    "published": "2025-02-17T19:00:00+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12235v1",
    "title": "Canted magnetism and $\\mathbb{Z}_2$ fractionalization in metallic states of the Lieb lattice Hubbard model near quarter filling",
    "authors": [
      "Alexander Nikolaenko",
      "Pietro M. Bonetti",
      "Anant Kale",
      "Martin Lebrat",
      "Markus Greiner",
      "Subir Sachdev"
    ],
    "abstract": "A recent experiment has examined ultracold, fermionic, spin-1/2 $^6$Li atoms\nin the Lieb lattice at different Hubbard repulsion $U$ and filling fractions\n$\\nu$ (Lebrat et al. arXiv:2404.17555). At $\\nu=1/2$ and small $U$, they\nobserve an enhanced compressibility on the $p_{x,y}$ sites, pointing to a flat\nband near the Fermi energy. At $\\nu=1/2$ and large $U$ they observe an\ninsulating ferrimagnet. Both small and large $U$ observations at $\\nu=1/2$ are\nconsistent with theoretical expectations. Surprisingly, near $\\nu=1/4$ and\nlarge $U$, they again observe a large $p_{x,y}$ compressibility, pointing to a\nflat $p_{x,y}$ band of fermions across the Fermi energy. Our Hartree-Fock\ncomputations near $\\nu=1/4$ find states with canted magnetism (and related\nspiral states) at large $U$, which possess nearly flat $p_{x,y}$ bands near the\nFermi level. We employ parton theories to describe quantum fluctuations of the\nmagnetic order found in Hartree-Fock. We find a metallic state with\n$\\mathbb{Z}_2$ fractionalization possessing gapless, fermionic, spinless\n`chargons' carrying $\\mathbb{Z}_2$ gauge charges which have a nearly flat\n$p_{x,y}$ band near their Fermi level: this fractionalized metal is also\nconsistent with observations. Our DMRG study does not indicate the presence of\nmagnetic order, and so supports a fractionalized ground state. Given the\nconventional ferrimagnetic insulator at $\\nu=1/2$, the $\\mathbb{Z}_2$\nfractionalized metal at $\\nu=1/4$ represents a remarkable realization of\ndoping-induced fractionalization.",
    "pdf_url": "http://arxiv.org/pdf/2502.12235v1",
    "published": "2025-02-17T19:00:00+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.12156v3",
    "title": "Sampling the full hierarchical population posterior distribution in gravitational-wave astronomy",
    "authors": [
      "Michele Mancarella",
      "Davide Gerosa"
    ],
    "abstract": "We present a full sampling of the hierarchical population posterior\ndistribution of merging black holes using current gravitational-wave data. We\ndirectly tackle the most relevant intrinsic parameter space made of the binary\nparameters (masses, spin magnitudes, spin directions, redshift) of all the\nevents entering the GWTC-3 LIGO/Virgo/KAGRA catalog, as well as the\nhyperparameters of the underlying population of sources. This results in a\nparameter space of about 500 dimensions, in contrast with current\ninvestigations where the targeted dimensionality is drastically reduced by\nmarginalizing over all single-event parameters. In particular, we have direct\naccess to (i) population parameters, (ii) population-informed single-event\nparameters, and (iii) correlations between these two sets of parameters. We\nquantify the fractional contribution of each event to the constraints on the\npopulation hyperparameters. Our implementation relies on modern probabilistic\nprogramming languages and Hamiltonian Monte Carlo, with a continuous\ninterpolation of single-event posterior probabilities. Sampling the full\nhierarchical problem is feasible, as demonstrated here, and advantageous as it\nremoves some (but not all) of the Monte Carlo integrations that enter the\nlikelihood together with the related variances.",
    "pdf_url": "http://arxiv.org/pdf/2502.12156v3",
    "published": "2025-02-17T18:59:55+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "astro-ph.HE",
      "astro-ph.IM",
      "physics.data-an"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.12155v2",
    "title": "Observation of a zero-energy excitation mode in the open Dicke model",
    "authors": [
      "Anton Bolian",
      "Phatthamon Kongkhambut",
      "Christoph Georges",
      "Roy D. Jara Jr.",
      "JosÃ© Vargas",
      "Jens Klinder",
      "Jayson G. Cosme",
      "Hans KeÃler",
      "Andreas Hemmerich"
    ],
    "abstract": "Approaching phase boundaries in many-body systems can give rise to intriguing\nsignatures in their excitation spectra. Here, we explore the excitation\nspectrum of a Bose-Einstein condensate strongly coupled to an optical cavity\nand pumped by an optical standing wave, which simulates the famous\nDicke-Hepp-Lieb phase transition of the open Dicke model with dissipation\narising due to photon leakage from the cavity. For weak dissipation, the\nexcitation spectrum displays two strongly polaritonic modes. Close to the phase\nboundary, we observe an intriguing regime where the lower-energetic of these\nmodes, instead of showing the expected roton-type mode softening, is found to\napproach and persist at zero energy, well before the critical pump strength for\nthe Dicke-Hepp-Lieb transition boundary is reached. Hence, a peculiar situation\narises, where an excitation is possible at zero energy cost, but nevertheless\nno instability of the system is created.",
    "pdf_url": "http://arxiv.org/pdf/2502.12155v2",
    "published": "2025-02-17T18:59:51+00:00",
    "categories": [
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2502.12154v1",
    "title": "Diffusion Models without Classifier-free Guidance",
    "authors": [
      "Zhicong Tang",
      "Jianmin Bao",
      "Dong Chen",
      "Baining Guo"
    ],
    "abstract": "This paper presents Model-guidance (MG), a novel objective for training\ndiffusion model that addresses and removes of the commonly used Classifier-free\nguidance (CFG). Our innovative approach transcends the standard modeling of\nsolely data distribution to incorporating the posterior probability of\nconditions. The proposed technique originates from the idea of CFG and is easy\nyet effective, making it a plug-and-play module for existing models. Our method\nsignificantly accelerates the training process, doubles the inference speed,\nand achieve exceptional quality that parallel and even surpass concurrent\ndiffusion models with CFG. Extensive experiments demonstrate the effectiveness,\nefficiency, scalability on different models and datasets. Finally, we establish\nstate-of-the-art performance on ImageNet 256 benchmarks with an FID of 1.34.\nOur code is available at https://github.com/tzco/Diffusion-wo-CFG.",
    "pdf_url": "http://arxiv.org/pdf/2502.12154v1",
    "published": "2025-02-17T18:59:50+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12231v2",
    "title": "PUGS: Zero-shot Physical Understanding with Gaussian Splatting",
    "authors": [
      "Yinghao Shuai",
      "Ran Yu",
      "Yuantao Chen",
      "Zijian Jiang",
      "Xiaowei Song",
      "Nan Wang",
      "Jv Zheng",
      "Jianzhu Ma",
      "Meng Yang",
      "Zhicheng Wang",
      "Wenbo Ding",
      "Hao Zhao"
    ],
    "abstract": "Current robotic systems can understand the categories and poses of objects\nwell. But understanding physical properties like mass, friction, and hardness,\nin the wild, remains challenging. We propose a new method that reconstructs 3D\nobjects using the Gaussian splatting representation and predicts various\nphysical properties in a zero-shot manner. We propose two techniques during the\nreconstruction phase: a geometry-aware regularization loss function to improve\nthe shape quality and a region-aware feature contrastive loss function to\npromote region affinity. Two other new techniques are designed during\ninference: a feature-based property propagation module and a volume integration\nmodule tailored for the Gaussian representation. Our framework is named as\nzero-shot physical understanding with Gaussian splatting, or PUGS. PUGS\nachieves new state-of-the-art results on the standard benchmark of ABO-500 mass\nprediction. We provide extensive quantitative ablations and qualitative\nvisualization to demonstrate the mechanism of our designs. We show the proposed\nmethodology can help address challenging real-world grasping tasks. Our codes,\ndata, and models are available at https://github.com/EverNorif/PUGS",
    "pdf_url": "http://arxiv.org/pdf/2502.12231v2",
    "published": "2025-02-17T18:59:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12153v1",
    "title": "Gravitational waves from the Axiverse",
    "authors": [
      "Saurav Das",
      "Francesc Ferrer"
    ],
    "abstract": "Models with axion like particles (ALPs) often predict the formation of a\nstring-domain wall network in the early universe. We study how such networks of\ndefects appear in the context of string theory, and discuss the conditions for\ntheir long-term stability. In a scenario with several axions, we show how a\nbias term in the potential arises naturally from the effects of multiple\ninstantons, leading to the eventual decay of the domain walls. We find that the\nannihilation of the network leads to the generation of a stochastic\ngravitational wave background (SGWB) with a spectrum that has characteristic\ncontributions from both walls and strings. The unique shape of the spectrum\nprovides an opportunity to probe string theory axions at existing and upcoming\nobservatories. The extinction of the network is also accompanied by the\nproduction of different axion mass eigenstates. In a region of the parameter\nspace, the lightest eigenstate can be long lived and make up the dark matter in\nthe universe.",
    "pdf_url": "http://arxiv.org/pdf/2502.12153v1",
    "published": "2025-02-17T18:59:30+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12152v2",
    "title": "Learning Getting-Up Policies for Real-World Humanoid Robots",
    "authors": [
      "Xialin He",
      "Runpei Dong",
      "Zixuan Chen",
      "Saurabh Gupta"
    ],
    "abstract": "Automatic fall recovery is a crucial prerequisite before humanoid robots can\nbe reliably deployed. Hand-designing controllers for getting up is difficult\nbecause of the varied configurations a humanoid can end up in after a fall and\nthe challenging terrains humanoid robots are expected to operate on. This paper\ndevelops a learning framework to produce controllers that enable humanoid\nrobots to get up from varying configurations on varying terrains. Unlike\nprevious successful applications of learning to humanoid locomotion, the\ngetting-up task involves complex contact patterns (which necessitates\naccurately modeling of the collision geometry) and sparser rewards. We address\nthese challenges through a two-phase approach that induces a curriculum. The\nfirst stage focuses on discovering a good getting-up trajectory under minimal\nconstraints on smoothness or speed / torque limits. The second stage then\nrefines the discovered motions into deployable (i.e. smooth and slow) motions\nthat are robust to variations in initial configuration and terrains. We find\nthese innovations enable a real-world G1 humanoid robot to get up from two main\nsituations that we considered: a) lying face up and b) lying face down, both\ntested on flat, deformable, slippery surfaces and slopes (e.g., sloppy grass\nand snowfield). This is one of the first successful demonstrations of learned\ngetting-up policies for human-sized humanoid robots in the real world.",
    "pdf_url": "http://arxiv.org/pdf/2502.12152v2",
    "published": "2025-02-17T18:59:06+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12151v1",
    "title": "VoLUT: Efficient Volumetric streaming enhanced by LUT-based super-resolution",
    "authors": [
      "Chendong Wang",
      "Anlan Zhang",
      "Yifan Yang",
      "Lili Qiu",
      "Yuqing Yang",
      "Xinyang Jiang",
      "Feng Qian",
      "Suman Banerjee"
    ],
    "abstract": "3D volumetric video provides immersive experience and is gaining traction in\ndigital media. Despite its rising popularity, the streaming of volumetric video\ncontent poses significant challenges due to the high data bandwidth\nrequirement. A natural approach to mitigate the bandwidth issue is to reduce\nthe volumetric video's data rate by downsampling the content prior to\ntransmission. The video can then be upsampled at the receiver's end using a\nsuper-resolution (SR) algorithm to reconstruct the high-resolution details.\nWhile super-resolution techniques have been extensively explored and advanced\nfor 2D video content, there is limited work on SR algorithms tailored for\nvolumetric videos.\n  To address this gap and the growing need for efficient volumetric video\nstreaming, we have developed VoLUT with a new SR algorithm specifically\ndesigned for volumetric content. Our algorithm uniquely harnesses the power of\nlookup tables (LUTs) to facilitate the efficient and accurate upscaling of\nlow-resolution volumetric data. The use of LUTs enables our algorithm to\nquickly reference precomputed high-resolution values, thereby significantly\nreducing the computational complexity and time required for upscaling. We\nfurther apply adaptive video bit rate algorithm (ABR) to dynamically determine\nthe downsampling rate according to the network condition and stream the\nselected video rate to the receiver. Compared to related work, VoLUT is the\nfirst to enable high-quality 3D SR on commodity mobile devices at line-rate.\nOur evaluation shows VoLUT can reduce bandwidth usage by 70% , boost QoE by\n36.7% for volumetric video streaming and achieve\n  3D SR speed-up with no quality compromise.",
    "pdf_url": "http://arxiv.org/pdf/2502.12151v1",
    "published": "2025-02-17T18:59:03+00:00",
    "categories": [
      "cs.CV",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12150v2",
    "title": "Idiosyncrasies in Large Language Models",
    "authors": [
      "Mingjie Sun",
      "Yida Yin",
      "Zhiqiu Xu",
      "J. Zico Kolter",
      "Zhuang Liu"
    ],
    "abstract": "In this work, we unveil and study idiosyncrasies in Large Language Models\n(LLMs) -- unique patterns in their outputs that can be used to distinguish the\nmodels. To do so, we consider a simple classification task: given a particular\ntext output, the objective is to predict the source LLM that generates the\ntext. We evaluate this synthetic task across various groups of LLMs and find\nthat simply fine-tuning text embedding models on LLM-generated texts yields\nexcellent classification accuracy. Notably, we achieve 97.1% accuracy on\nheld-out validation data in the five-way classification problem involving\nChatGPT, Claude, Grok, Gemini, and DeepSeek. Our further investigation reveals\nthat these idiosyncrasies are rooted in word-level distributions. These\npatterns persist even when the texts are rewritten, translated, or summarized\nby an external LLM, suggesting that they are also encoded in the semantic\ncontent. Additionally, we leverage LLM as judges to generate detailed,\nopen-ended descriptions of each model's idiosyncrasies. Finally, we discuss the\nbroader implications of our findings, including training on synthetic data,\ninferring model similarity, and robust evaluation of LLMs. Code is available at\nhttps://github.com/locuslab/llm-idiosyncrasies.",
    "pdf_url": "http://arxiv.org/pdf/2502.12150v2",
    "published": "2025-02-17T18:59:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12149v2",
    "title": "HARBOR: Exploring Persona Dynamics in Multi-Agent Competition",
    "authors": [
      "Kenan Jiang",
      "Li Xiong",
      "Fei Liu"
    ],
    "abstract": "We investigate factors contributing to LLM agents' success in competitive\nmulti-agent environments, using auctions as a testbed where agents bid to\nmaximize profit. The agents are equipped with bidding domain knowledge,\ndistinct personas that reflect item preferences, and a memory of auction\nhistory. Our work extends the classic auction scenario by creating a realistic\nenvironment where multiple agents bid on houses, weighing aspects such as size,\nlocation, and budget to secure the most desirable homes at the lowest prices.\nParticularly, we investigate three key questions: (a) How does a persona\ninfluence an agent's behavior in a competitive setting? (b) Can an agent\neffectively profile its competitors' behavior during auctions? (c) How can\npersona profiling be leveraged to create an advantage using strategies such as\ntheory of mind? Through a series of experiments, we analyze the behaviors of\nLLM agents and shed light on new findings. Our testbed, called HARBOR, offers a\nvaluable platform for deepening our understanding of multi-agent workflows in\ncompetitive environments.",
    "pdf_url": "http://arxiv.org/pdf/2502.12149v2",
    "published": "2025-02-17T18:58:36+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12148v1",
    "title": "HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation",
    "authors": [
      "Ling Yang",
      "Xinchen Zhang",
      "Ye Tian",
      "Chenming Shang",
      "Minghao Xu",
      "Wentao Zhang",
      "Bin Cui"
    ],
    "abstract": "The remarkable success of the autoregressive paradigm has made significant\nadvancement in Multimodal Large Language Models (MLLMs), with powerful models\nlike Show-o, Transfusion and Emu3 achieving notable progress in unified image\nunderstanding and generation. For the first time, we uncover a common\nphenomenon: the understanding capabilities of MLLMs are typically stronger than\ntheir generative capabilities, with a significant gap between the two. Building\non this insight, we propose HermesFlow, a simple yet general framework designed\nto seamlessly bridge the gap between understanding and generation in MLLMs.\nSpecifically, we take the homologous data as input to curate homologous\npreference data of both understanding and generation. Through Pair-DPO and\nself-play iterative optimization, HermesFlow effectively aligns multimodal\nunderstanding and generation using homologous preference data. Extensive\nexperiments demonstrate the significant superiority of our approach over prior\nmethods, particularly in narrowing the gap between multimodal understanding and\ngeneration. These findings highlight the potential of HermesFlow as a general\nalignment framework for next-generation multimodal foundation models. Code:\nhttps://github.com/Gen-Verse/HermesFlow",
    "pdf_url": "http://arxiv.org/pdf/2502.12148v1",
    "published": "2025-02-17T18:57:51+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12147v2",
    "title": "Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction",
    "authors": [
      "Xiang Fu",
      "Brandon M. Wood",
      "Luis Barroso-Luque",
      "Daniel S. Levine",
      "Meng Gao",
      "Misko Dzamba",
      "C. Lawrence Zitnick"
    ],
    "abstract": "Machine learning interatomic potentials (MLIPs) have become increasingly\neffective at approximating quantum mechanical calculations at a fraction of the\ncomputational cost. However, lower errors on held out test sets do not always\ntranslate to improved results on downstream physical property prediction tasks.\nIn this paper, we propose testing MLIPs on their practical ability to conserve\nenergy during molecular dynamic simulations. If passed, improved correlations\nare found between test errors and their performance on physical property\nprediction tasks. We identify choices which may lead to models failing this\ntest, and use these observations to improve upon highly-expressive models. The\nresulting model, eSEN, provides state-of-the-art results on a range of physical\nproperty prediction tasks, including materials stability prediction, thermal\nconductivity prediction, and phonon calculations.",
    "pdf_url": "http://arxiv.org/pdf/2502.12147v2",
    "published": "2025-02-17T18:57:32+00:00",
    "categories": [
      "physics.comp-ph",
      "cs.LG"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12146v1",
    "title": "Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising Trajectory Sharpening",
    "authors": [
      "Ye Tian",
      "Ling Yang",
      "Xinchen Zhang",
      "Yunhai Tong",
      "Mengdi Wang",
      "Bin Cui"
    ],
    "abstract": "We propose Diffusion-Sharpening, a fine-tuning approach that enhances\ndownstream alignment by optimizing sampling trajectories. Existing RL-based\nfine-tuning methods focus on single training timesteps and neglect\ntrajectory-level alignment, while recent sampling trajectory optimization\nmethods incur significant inference NFE costs. Diffusion-Sharpening overcomes\nthis by using a path integral framework to select optimal trajectories during\ntraining, leveraging reward feedback, and amortizing inference costs. Our\nmethod demonstrates superior training efficiency with faster convergence, and\nbest inference efficiency without requiring additional NFEs. Extensive\nexperiments show that Diffusion-Sharpening outperforms RL-based fine-tuning\nmethods (e.g., Diffusion-DPO) and sampling trajectory optimization methods\n(e.g., Inference Scaling) across diverse metrics including text alignment,\ncompositional capabilities, and human preferences, offering a scalable and\nefficient solution for future diffusion model fine-tuning. Code:\nhttps://github.com/Gen-Verse/Diffusion-Sharpening",
    "pdf_url": "http://arxiv.org/pdf/2502.12146v1",
    "published": "2025-02-17T18:57:26+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12145v2",
    "title": "Fast or Better? Balancing Accuracy and Cost in Retrieval-Augmented Generation with Flexible User Control",
    "authors": [
      "Jinyan Su",
      "Jennifer Healey",
      "Preslav Nakov",
      "Claire Cardie"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to\nmitigate large language model (LLM) hallucinations by incorporating external\nknowledge retrieval. However, existing RAG frameworks often apply retrieval\nindiscriminately,leading to inefficiencies-over-retrieving when unnecessary or\nfailing to retrieve iteratively when required for complex reasoning. Recent\nadaptive retrieval strategies, though adaptively navigates these retrieval\nstrategies, predict only based on query complexity and lacks user-driven\nflexibility, making them infeasible for diverse user application needs. In this\npaper, we introduce a novel user-controllable RAG framework that enables\ndynamic adjustment of the accuracy-cost trade-off. Our approach leverages two\nclassifiers: one trained to prioritize accuracy and another to prioritize\nretrieval efficiency. Via an interpretable control parameter $\\alpha$, users\ncan seamlessly navigate between minimal-cost retrieval and high-accuracy\nretrieval based on their specific requirements. We empirically demonstrate that\nour approach effectively balances accuracy, retrieval cost, and user\ncontrollability, making it a practical and adaptable solution for real-world\napplications. Code is available at https://github.com/JinyanSu1/Flare-Aug.",
    "pdf_url": "http://arxiv.org/pdf/2502.12145v2",
    "published": "2025-02-17T18:56:20+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12144v2",
    "title": "Superconducting phase diagram of finite-layer nickelates Nd$_{n+1}$Ni$_n$O$_{2n+2}$",
    "authors": [
      "Andreas Hausoel",
      "Simone Di Cataldo",
      "Motoharu Kitatani",
      "Oleg Janson",
      "Karsten Held"
    ],
    "abstract": "Following the successful prediction of the superconducting phase diagram for\ninfinite-layer nickelates, here we calculate the superconducting\n$T_{\\mathrm{c}}$ vs. the number of layers $n$ for finite-layer nickelates using\nthe dynamical vertex approximation. To this end, we start with density\nfunctional theory, and include local correlations non-perturbatively by\ndynamical mean-field theory for $n=2$ to 7. For all $n$, the Ni $d_{x^2-y^2}$\norbital crosses the Fermi level, but for $n>4$ there are additional $(\\pi,\n\\pi)$ pockets or tubes that slightly enhance the layer-averaged hole doping of\nthe $d_{x^2-y^2}$ orbitals beyond the leading $1/n$ contribution stemming from\nthe valence electron count. We finally calculate $T_{\\mathrm{c}}$ for the\nsingle-orbital $d_{x^2-y^2}$ Hubbard model by dynamical vertex approximation.",
    "pdf_url": "http://arxiv.org/pdf/2502.12144v2",
    "published": "2025-02-17T18:56:16+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.12143v2",
    "title": "Small Models Struggle to Learn from Strong Reasoners",
    "authors": [
      "Yuetai Li",
      "Xiang Yue",
      "Zhangchen Xu",
      "Fengqing Jiang",
      "Luyao Niu",
      "Bill Yuchen Lin",
      "Bhaskar Ramasubramanian",
      "Radha Poovendran"
    ],
    "abstract": "Large language models (LLMs) excel in complex reasoning tasks, and distilling\ntheir reasoning capabilities into smaller models has shown promise. However, we\nuncover an interesting phenomenon, which we term the Small Model Learnability\nGap: small models ($\\leq$3B parameters) do not consistently benefit from long\nchain-of-thought (CoT) reasoning or distillation from larger models. Instead,\nthey perform better when fine-tuned on shorter, simpler reasoning chains that\nbetter align with their intrinsic learning capacity. To address this, we\npropose Mix Distillation, a simple yet effective strategy that balances\nreasoning complexity by combining long and short CoT examples or reasoning from\nboth larger and smaller models. Our experiments demonstrate that Mix\nDistillation significantly improves small model reasoning performance compared\nto training on either data alone. These findings highlight the limitations of\ndirect strong model distillation and underscore the importance of adapting\nreasoning complexity for effective reasoning capability transfer.",
    "pdf_url": "http://arxiv.org/pdf/2502.12143v2",
    "published": "2025-02-17T18:56:15+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12142v1",
    "title": "pylevin: efficient numerical integration of integrals containing up to three Bessel functions",
    "authors": [
      "Robert Reischke"
    ],
    "abstract": "Integrals involving highly oscillatory Bessel functions are notoriously\nchallenging to compute using conventional integration techniques. While several\nmethods are available, they predominantly cater to integrals with at most a\nsingle Bessel function, resulting in specialised yet highly optimised\nsolutions. Here we present pylevin, a Python package to efficiently compute\nintegrals containing up to three Bessel functions of arbitrary order and\narguments. The implementation makes use of Levin's method and allows for\naccurate and fast integration of these highly oscillatory integrals. In\nbenchmarking pylevin against existing software for single Bessel function\nintegrals, we find its speed comparable, usually within a factor of two, to\nspecialised packages such as FFTLog. Furthermore, when dealing with integrals\ncontaining two or three Bessel functions, pylevin delivers performance up to\nfour orders of magnitude faster than standard adaptive quadrature methods,\nwhile also exhibiting better stability for large Bessel function arguments.\npylevin is available from source via github or directly from PyPi.",
    "pdf_url": "http://arxiv.org/pdf/2502.12142v1",
    "published": "2025-02-17T18:55:58+00:00",
    "categories": [
      "math.NA",
      "astro-ph.CO",
      "astro-ph.GA",
      "cs.NA",
      "physics.comp-ph"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12141v4",
    "title": "Potato Potahto in the FAO-GAEZ Productivity Measures? Nonclassical Measurement Error with Multiple Proxies",
    "authors": [
      "Rafael Araujo",
      "Vitor Possebom"
    ],
    "abstract": "The FAO-GAEZ productivity data are widely used in Economics. However, the\nempirical literature rarely discusses measurement error. We use two proxies to\nderive novel analytical bounds around the effect of agricultural productivity\nin a setting with nonclassical measurement error. These bounds rely on\nassumptions that are weaker than the ones imposed in empirical studies and\nexhaust the information contained in the first two moments of the data. We\nreevaluate three influential studies, documenting that measurement error\nmatters and that the impact of agricultural productivity may be smaller than\npreviously reported. Our methodology has broad applications in empirical\nresearch involving mismeasured variables.",
    "pdf_url": "http://arxiv.org/pdf/2502.12141v4",
    "published": "2025-02-17T18:55:26+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC",
      "stat.ME"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2502.12140v1",
    "title": "Correlative X-ray and electron tomography for scale-bridging, quantitative analysis of complex, hierarchical particle systems",
    "authors": [
      "Alexander GÃ¶tz",
      "Fabian Lutter",
      "Dennis Simon Possart",
      "Daniel Augsburger",
      "Usman Arslan",
      "Sabrina Pechmann",
      "Carmen Rubach",
      "Moritz Buwen",
      "Umair Sultan",
      "Alexander Kichigin",
      "Johannes BÃ¶hmer",
      "Nora Vorlaufer",
      "Peter Suter",
      "Tor Hildebrand",
      "Matthias Thommes",
      "Peter Felfer",
      "Nicolas Vogel",
      "Katharina Breininger",
      "Silke Christiansen",
      "Benjamin Apeleo Zubiri",
      "Erdmann Spiecker"
    ],
    "abstract": "This study presents a comprehensive workflow for investigating particulate\nmaterials through combined 360{\\deg} electron tomography (ET), nano-computed\nX-ray tomography (nanoCT), and micro-computed X-ray tomography (microCT),\nalongside a versatile sample preparation routine. The workflow enables the\ninvestigation of size, morphology, and pore systems across multiple scales,\nfrom individual particles to large hierarchical structures. A customized\ntapered sample shape is fabricated using focused ion beam milling with the aim\nto optimize each imaging technique's field of view, facilitating\nhigh-resolution analysis of small volumes containing single particles, while\nalso allowing for large-scale studies of thousands of particles for statistical\nrelevance. By correlating data from same locations in different imaging\nmodalities, the approach enhances the precision of quantitative analyses. The\nstudy highlights the importance of cross-scale, correlative three-dimensional\nmicroscopy for a comprehensive understanding of complex hierarchical materials.\nPrecise data registration, segmentation using machine learning, and multimodal\nimaging techniques are crucial for unlocking insights into\nprocess-structure-property relationships and thus to optimize functional,\nhierarchical materials.",
    "pdf_url": "http://arxiv.org/pdf/2502.12140v1",
    "published": "2025-02-17T18:55:09+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.12139v2",
    "title": "Resolving the sodiation process in hard carbon anodes with nanostructure specific X-ray imaging",
    "authors": [
      "Martina Olsson",
      "Antoine Klein",
      "Nataliia Mozhzhukhina",
      "Shizhao Xiong",
      "Christian Appel",
      "Mads Carlsen",
      "Leonard Nielsen",
      "Linnea Rensmo",
      "Marianne Liebi",
      "Aleksandar Matic"
    ],
    "abstract": "Hard carbons show significant promise as anode materials for sodium-ion\nbatteries. However, monitoring the sodiation process in the hard carbon\nelectrode during cycling and understanding the sodiation mechanism remain\nchallenging. This article reports on operando 2D scanning small- and wide-angle\nX-ray scattering (SWAXS) and ex situ 3D SAXS tomography of hard carbon\nelectrodes during the sodiation process. Structural changes are monitored with\nspatial and temporal resolution during the electrochemical process and shows\nthat sodiation through micropore filling is the more dominating mechanism in\nthe later stages of sodiation, i.e. in the plateau region of the voltage\nprofile, while intercalation occurs continuously. Spatial inhomogeneities are\nresolved over the electrode and reveal an increased level of inhomogeneity at\nhigher degree of sodiation with regions of different degrees of micropore\nfilling. Resolving the processes spatially enables us to correlate plating,\nstarting from the interface between the electrode and the current collector, to\na higher degree of micropore filling. The work demonstrates how SWAXS imaging\ncan contribute to understanding the sodiation of hard carbon anodes, not only\nby spatially resolved analysis, but also as a method to decouple contributions\nfrom different components in a cell, enabling more accurate scattering analysis\nin in situ environments.",
    "pdf_url": "http://arxiv.org/pdf/2502.12139v2",
    "published": "2025-02-17T18:55:01+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.12138v4",
    "title": "FLARE: Feed-forward Geometry, Appearance and Camera Estimation from Uncalibrated Sparse Views",
    "authors": [
      "Shangzhan Zhang",
      "Jianyuan Wang",
      "Yinghao Xu",
      "Nan Xue",
      "Christian Rupprecht",
      "Xiaowei Zhou",
      "Yujun Shen",
      "Gordon Wetzstein"
    ],
    "abstract": "We present FLARE, a feed-forward model designed to infer high-quality camera\nposes and 3D geometry from uncalibrated sparse-view images (i.e., as few as 2-8\ninputs), which is a challenging yet practical setting in real-world\napplications. Our solution features a cascaded learning paradigm with camera\npose serving as the critical bridge, recognizing its essential role in mapping\n3D structures onto 2D image planes. Concretely, FLARE starts with camera pose\nestimation, whose results condition the subsequent learning of geometric\nstructure and appearance, optimized through the objectives of geometry\nreconstruction and novel-view synthesis. Utilizing large-scale public datasets\nfor training, our method delivers state-of-the-art performance in the tasks of\npose estimation, geometry reconstruction, and novel view synthesis, while\nmaintaining the inference efficiency (i.e., less than 0.5 seconds). The project\npage and code can be found at: https://zhanghe3z.github.io/FLARE/",
    "pdf_url": "http://arxiv.org/pdf/2502.12138v4",
    "published": "2025-02-17T18:54:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12137v1",
    "title": "REVERSUM: A Multi-staged Retrieval-Augmented Generation Method to Enhance Wikipedia Tail Biographies through Personal Narratives",
    "authors": [
      "Sayantan Adak",
      "Pauras Mangesh Meher",
      "Paramita Das",
      "Animesh Mukherjee"
    ],
    "abstract": "Wikipedia is an invaluable resource for factual information about a wide\nrange of entities. However, the quality of articles on less-known entities\noften lags behind that of the well-known ones. This study proposes a novel\napproach to enhancing Wikipedia's B and C category biography articles by\nleveraging personal narratives such as autobiographies and biographies. By\nutilizing a multi-staged retrieval-augmented generation technique -- REVerSum\n-- we aim to enrich the informational content of these lesser-known articles.\nOur study reveals that personal narratives can significantly improve the\nquality of Wikipedia articles, providing a rich source of reliable information\nthat has been underutilized in previous studies. Based on crowd-based\nevaluation, REVerSum generated content outperforms the best performing baseline\nby 17% in terms of integrability to the original Wikipedia article and 28.5\\%\nin terms of informativeness. Code and Data are available at:\nhttps://github.com/sayantan11995/wikipedia_enrichment",
    "pdf_url": "http://arxiv.org/pdf/2502.12137v1",
    "published": "2025-02-17T18:53:42+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12136v1",
    "title": "$p$-Adic Weight Spectral Sequences of Strictly Semi-stable Schemes over Formal Power Series Rings via Arithmetic $\\mathcal{D}$-modules",
    "authors": [
      "Yuanmin Liu"
    ],
    "abstract": "Let $k$ be a perfect field of characteristic $p > 0$. For a strictly\nsemi-stable scheme over $k[[t]]$, we construct the weight spectral sequence in\n$p$-adic cohomology using the theory of arithmetic $\\mathcal{D}$-modules, whose\n$E_1$ terms are described by rigid cohomologies of irreducible components of\nthe closed fiber and whose $E_\\infty$ terms are conjecturally described by the\n(unipotent) nearby cycle of Lazda-P\\'{a}l's rigid cohomology over the bounded\nRobba ring. We also show its functoriality by pushforward and state the\nconjecture of its functoriality by pullback and dual.",
    "pdf_url": "http://arxiv.org/pdf/2502.12136v1",
    "published": "2025-02-17T18:53:32+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12135v2",
    "title": "MagicArticulate: Make Your 3D Models Articulation-Ready",
    "authors": [
      "Chaoyue Song",
      "Jianfeng Zhang",
      "Xiu Li",
      "Fan Yang",
      "Yiwen Chen",
      "Zhongcong Xu",
      "Jun Hao Liew",
      "Xiaoyang Guo",
      "Fayao Liu",
      "Jiashi Feng",
      "Guosheng Lin"
    ],
    "abstract": "With the explosive growth of 3D content creation, there is an increasing\ndemand for automatically converting static 3D models into articulation-ready\nversions that support realistic animation. Traditional approaches rely heavily\non manual annotation, which is both time-consuming and labor-intensive.\nMoreover, the lack of large-scale benchmarks has hindered the development of\nlearning-based solutions. In this work, we present MagicArticulate, an\neffective framework that automatically transforms static 3D models into\narticulation-ready assets. Our key contributions are threefold. First, we\nintroduce Articulation-XL, a large-scale benchmark containing over 33k 3D\nmodels with high-quality articulation annotations, carefully curated from\nObjaverse-XL. Second, we propose a novel skeleton generation method that\nformulates the task as a sequence modeling problem, leveraging an\nauto-regressive transformer to naturally handle varying numbers of bones or\njoints within skeletons and their inherent dependencies across different 3D\nmodels. Third, we predict skinning weights using a functional diffusion process\nthat incorporates volumetric geodesic distance priors between vertices and\njoints. Extensive experiments demonstrate that MagicArticulate significantly\noutperforms existing methods across diverse object categories, achieving\nhigh-quality articulation that enables realistic animation. Project page:\nhttps://chaoyuesong.github.io/MagicArticulate.",
    "pdf_url": "http://arxiv.org/pdf/2502.12135v2",
    "published": "2025-02-17T18:53:27+00:00",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12133v2",
    "title": "Exact colour evolution for jet observables",
    "authors": [
      "Jeffrey R. Forshaw",
      "Simon PlÃ¤tzer",
      "Fernando Torre GonzÃ¡lez"
    ],
    "abstract": "We perform a systematic and comprehensive analysis of sub-leading colour\ncorrections in perturbative QCD processes involving multiple soft gluon\nemissions. This necessitates going beyond the standard parton shower paradigm\nin order to incorporate interference effects and is accomplished using the\nCVolver program, which simulates parton showers at the amplitude level. We can\ncompute cross-sections with full-colour precision and also broken down\nexplicitly in terms of their $N_c$ dependence. In this paper, we focus on the\njet cross-section with a veto of additional jets in some fixed region of\nphase-space, since this is sensitive to wide-angle, soft gluon radiation. We\nconsider $Z \\to q \\bar{q}$, $H \\to gg$, $q\\bar{q} \\to q\\bar{q}$, $qg \\to qg$,\n$gg \\to gg$ and $ZZ \\to q\\bar{q}q\\bar{q}$. We find that non-trivial sub-leading\ncolour effects are generally important at the 5 -- 30\\% level and much more\nthan this for certain interference contributions. Remarkably, for this\nobservable, we find that for all of the $t$-channel gluon exchange processes\nthat we consider, the strictly leading colour approximation, which includes the\nreplacement $C_F \\to C_A/2$, is an excellent approximation to the full colour\nresult (up to an overall colour factor).",
    "pdf_url": "http://arxiv.org/pdf/2502.12133v2",
    "published": "2025-02-17T18:52:29+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12134v2",
    "title": "SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs",
    "authors": [
      "Yige Xu",
      "Xu Guo",
      "Zhiwei Zeng",
      "Chunyan Miao"
    ],
    "abstract": "Chain-of-Thought (CoT) reasoning enables Large Language Models (LLMs) to\nsolve complex reasoning tasks by generating intermediate reasoning steps.\nHowever, most existing approaches focus on hard token decoding, which\nconstrains reasoning within the discrete vocabulary space and may not always be\noptimal. While recent efforts explore continuous-space reasoning, they often\nrequire full-model fine-tuning and suffer from catastrophic forgetting,\nlimiting their applicability to state-of-the-art LLMs that already perform well\nin zero-shot settings with a proper instruction. To address this challenge, we\npropose a novel approach for continuous-space reasoning that does not require\nmodifying the LLM. Specifically, we employ a lightweight fixed assistant model\nto speculatively generate instance-specific soft thought tokens as the initial\nchain of thoughts, which are then mapped into the LLM's representation space\nvia a trainable projection module. Experimental results on five reasoning\nbenchmarks demonstrate that our method enhances LLM reasoning performance\nthrough supervised, parameter-efficient fine-tuning. Source code is available\nat https://github.com/xuyige/SoftCoT.",
    "pdf_url": "http://arxiv.org/pdf/2502.12134v2",
    "published": "2025-02-17T18:52:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12132v1",
    "title": "Electrically tunable strong coupling in a hybrid-2D excitonic metasurface for optical modulation",
    "authors": [
      "Tom Hoekstra",
      "Jorik van de Groep"
    ],
    "abstract": "Atomically thin semiconductors exhibit tunable exciton resonances that can be\nharnessed for dynamic manipulation of visible light in ultra-compact\nmetadevices. However, the rapid nonradiative decay and dephasing of excitons at\nroom temperature limits current active excitonic metasurfaces to few-percent\nefficiencies. Here, we leverage the combined merits of pristine 2D\nheterostructures and non-local dielectric metasurfaces to enhance the excitonic\nlight-matter interaction, achieving strong and electrically tunable\nexciton-photon coupling at ambient conditions in a hybrid-2D excitonic\nmetasurface. Using this, we realize a free-space optical modulator and\nexperimentally demonstrate 9.9 dB of reflectance modulation. The electro-optic\nresponse, characterized by a continuous transition from strong to weak\ncoupling, is mediated by gating-induced variations in the free carrier\nconcentration altering the exciton\\`s nonradiative decay rate. These results\nhighlight how hybrid-2D excitonic metasurfaces offer novel opportunities to\nrealize nanophotonic devices for active wavefront manipulation and optical\ncommunication.",
    "pdf_url": "http://arxiv.org/pdf/2502.12132v1",
    "published": "2025-02-17T18:52:27+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.12131v1",
    "title": "Transformer Dynamics: A neuroscientific approach to interpretability of large language models",
    "authors": [
      "Jesseba Fernando",
      "Grigori Guitchounts"
    ],
    "abstract": "As artificial intelligence models have exploded in scale and capability,\nunderstanding of their internal mechanisms remains a critical challenge.\nInspired by the success of dynamical systems approaches in neuroscience, here\nwe propose a novel framework for studying computations in deep learning\nsystems. We focus on the residual stream (RS) in transformer models,\nconceptualizing it as a dynamical system evolving across layers. We find that\nactivations of individual RS units exhibit strong continuity across layers,\ndespite the RS being a non-privileged basis. Activations in the RS accelerate\nand grow denser over layers, while individual units trace unstable periodic\norbits. In reduced-dimensional spaces, the RS follows a curved trajectory with\nattractor-like dynamics in the lower layers. These insights bridge dynamical\nsystems theory and mechanistic interpretability, establishing a foundation for\na \"neuroscience of AI\" that combines theoretical rigor with large-scale data\nanalysis to advance our understanding of modern neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.12131v1",
    "published": "2025-02-17T18:49:40+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12130v1",
    "title": "Scaling Autonomous Agents via Automatic Reward Modeling And Planning",
    "authors": [
      "Zhenfang Chen",
      "Delin Chen",
      "Rui Sun",
      "Wenjun Liu",
      "Chuang Gan"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\na range of text-generation tasks. However, LLMs still struggle with problems\nrequiring multi-step decision-making and environmental feedback, such as online\nshopping, scientific reasoning, and mathematical problem-solving. Unlike pure\ntext data, collecting large-scale decision-making data is challenging.\nMoreover, many powerful LLMs are only accessible through APIs, which hinders\ntheir fine-tuning for agent tasks due to cost and complexity. To address LLM\nagents' limitations, we propose a framework that can automatically learn a\nreward model from the environment without human annotations. This model can be\nused to evaluate the action trajectories of LLM agents and provide heuristics\nfor task planning. Specifically, our approach involves employing one LLM-based\nagent to navigate an environment randomly, generating diverse action\ntrajectories. Subsequently, a separate LLM is leveraged to assign a task intent\nand synthesize a negative response alongside the correct response for each\ntrajectory. These triplets (task intent, positive response, and negative\nresponse) are then utilized as training data to optimize a reward model capable\nof scoring action trajectories. The effectiveness and generalizability of our\nframework are demonstrated through evaluations conducted on different agent\nbenchmarks. In conclusion, our proposed framework represents a significant\nadvancement in enhancing LLM agents' decision-making capabilities. By\nautomating the learning of reward models, we overcome the challenges of data\nscarcity and API limitations, potentially revolutionizing the application of\nLLMs in complex and interactive environments. This research paves the way for\nmore sophisticated AI agents capable of tackling a wide range of real-world\nproblems requiring multi-step decision-making.",
    "pdf_url": "http://arxiv.org/pdf/2502.12130v1",
    "published": "2025-02-17T18:49:25+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12129v1",
    "title": "When Wyner and Ziv Met Bayes in Quantum-Classical Realm",
    "authors": [
      "Mohammad Aamir Sohail",
      "Touheed Anwar Atif",
      "S. Sandeep Pradhan"
    ],
    "abstract": "In this work, we address the lossy quantum-classical source coding with the\nquantum side-information (QC-QSI) problem. The task is to compress the\nclassical information about a quantum source, obtained after performing a\nmeasurement while incurring a bounded reconstruction error. Here, the decoder\nis allowed to use the side information to recover the classical data obtained\nfrom measurements on the source states. We introduce a new formulation based on\na backward (posterior) channel, replacing the single-letter distortion\nobservable with a single-letter posterior channel to capture reconstruction\nerror. Unlike the rate-distortion framework, this formulation imposes a block\nerror constraint. An analogous formulation is developed for lossy classical\nsource coding with classical side information (C-CSI) problem. We derive an\ninner bound on the asymptotic performance limit in terms of single-letter\nquantum and classical mutual information quantities of the given posterior\nchannel for QC-QSI and C-CSI cases, respectively. Furthermore, we establish a\nconnection between rate-distortion and rate-channel theory, showing that a\nrate-channel compression protocol attains the optimal rate-distortion function\nfor a specific distortion measure and level.",
    "pdf_url": "http://arxiv.org/pdf/2502.12129v1",
    "published": "2025-02-17T18:49:19+00:00",
    "categories": [
      "cs.IT",
      "math.IT",
      "quant-ph"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12128v3",
    "title": "LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked Entities",
    "authors": [
      "Florian Sestak",
      "Artur Toshev",
      "Andreas FÃ¼rst",
      "GÃ¼nter Klambauer",
      "Andreas Mayr",
      "Johannes Brandstetter"
    ],
    "abstract": "Generative models are spearheading recent progress in deep learning,\nshowcasing strong promise for trajectory sampling in dynamical systems as well.\nHowever, whereas latent space modeling paradigms have transformed image and\nvideo generation, similar approaches are more difficult for most dynamical\nsystems. Such systems -- from chemical molecule structures to collective human\nbehavior -- are described by interactions of entities, making them inherently\nlinked to connectivity patterns, entity conservation, and the traceability of\nentities over time. Our approach, LaM-SLidE (Latent Space Modeling of Spatial\nDynamical Systems via Linked Entities), bridges the gap between: (1) keeping\nthe traceability of individual entities in a latent system representation, and\n(2) leveraging the efficiency and scalability of recent advances in image and\nvideo generation, where pre-trained encoder and decoder enable generative\nmodeling directly in latent space. The core idea of LaM-SLidE is the\nintroduction of identifier representations (IDs) that enable the retrieval of\nentity properties and entity composition from latent system representations,\nthus fostering traceability. Experimentally, across different domains, we show\nthat LaM-SLidE performs favorably in terms of speed, accuracy, and\ngeneralizability. Code is available at https://github.com/ml-jku/LaM-SLidE .",
    "pdf_url": "http://arxiv.org/pdf/2502.12128v3",
    "published": "2025-02-17T18:49:13+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12127v2",
    "title": "Multipoint conformal integrals in $D$ dimensions. Part I: Bipartite Mellin-Barnes representation and reconstruction",
    "authors": [
      "K. B. Alkalaev",
      "Semyon Mandrygin"
    ],
    "abstract": "We propose a systematic approach to calculating $n$-point one-loop parametric\nconformal integrals in $D$ dimensions which we call the reconstruction\nprocedure. It relies on decomposing a conformal integral over basis functions\nwhich are generated from a set of master functions by acting with the cyclic\ngroup $\\mathbb{Z}_n$. In order to identify the master functions we introduce a\nbipartite Mellin-Barnes representation by means of splitting a given conformal\nintegral into two additive parts, one of which can be evaluated explicitly in\nterms of multivariate generalized hypergeometric series.\n  For the box and pentagon integrals (i.e. $n=4,5$) we show that a computable\npart of the bipartite representation contains all master functions. In\nparticular, this allows us to evaluate the parametric pentagon integral as a\nsum of ten basis functions generated from two master functions by the cyclic\ngroup $\\mathbb{Z}_5$. The resulting expression can be tested in two ways.\nFirst, when one of propagator powers is set to zero, the pentagon integral is\nreduced to the known box integral, which is also rederived through the\nreconstruction procedure. Second, going to the non-parametric case, we\nreproduce the known expression for the pentagon integral given in terms of\nlogarithms derived earlier within the geometric approach to calculating\nconformal integrals.\n  We conclude by considering the hexagon integral ($n=6$) for which we show\nthat those basis functions which follow from the computable part of the\nbipartite representation are not enough and more basis functions are required.\nIn the second part of our project we will describe a method of constructing a\ncomplete set of master/basis functions in the $n$-point case.",
    "pdf_url": "http://arxiv.org/pdf/2502.12127v2",
    "published": "2025-02-17T18:47:40+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.12126v2",
    "title": "Real operator systems",
    "authors": [
      "David P. Blecher",
      "Travis B. Russell"
    ],
    "abstract": "Operator systems are the unital self-adjoint subspaces of the bounded\noperators on a Hilbert space. Complex operator systems are an important\ncategory containing the C$^*$-algebras and von Neumann algebras, which is\nincreasingly of interest in modern analysis and also in modern quantum physics\n(such as quantum information theory). They have an extensive theory, and have\nvery important applications in all of these subjects. We present here the real\ncase of the theory of (complex) operator systems, and also the real case of\ntheir remarkable tensor product theory, due in the complex case to Paulsen and\nhis coauthors and students (such as Kavruk), building on pioneering earlier\nwork of Kirchberg and others. We uncover several notable differences between\nthe real and complex theory, including the absence of minimal and maximal\nfunctors in the category of real operator systems. We also develop very many\nfoundational structural results for real operator systems, and elucidate how\nthe complexification interacts with the basic constructions in the subject. In\nthe final two sections of our paper we study real analogues of the Kirchberg\nconjectures (and of several important related problems that have attracted much\ninterest recently), and study the deep relationships between them.",
    "pdf_url": "http://arxiv.org/pdf/2502.12126v2",
    "published": "2025-02-17T18:47:38+00:00",
    "categories": [
      "math.OA",
      "math-ph",
      "math.FA",
      "math.MP"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12125v1",
    "title": "Hypernym Bias: Unraveling Deep Classifier Training Dynamics through the Lens of Class Hierarchy",
    "authors": [
      "Roman Malashin",
      "Valeria Yachnaya",
      "Alexander Mullin"
    ],
    "abstract": "We investigate the training dynamics of deep classifiers by examining how\nhierarchical relationships between classes evolve during training. Through\nextensive experiments, we argue that the learning process in classification\nproblems can be understood through the lens of label clustering. Specifically,\nwe observe that networks tend to distinguish higher-level (hypernym) categories\nin the early stages of training, and learn more specific (hyponym) categories\nlater. We introduce a novel framework to track the evolution of the feature\nmanifold during training, revealing how the hierarchy of class relations\nemerges and refines across the network layers. Our analysis demonstrates that\nthe learned representations closely align with the semantic structure of the\ndataset, providing a quantitative description of the clustering process.\nNotably, we show that in the hypernym label space, certain properties of neural\ncollapse appear earlier than in the hyponym label space, helping to bridge the\ngap between the initial and terminal phases of learning. We believe our\nfindings offer new insights into the mechanisms driving hierarchical learning\nin deep networks, paving the way for future advancements in understanding deep\nlearning dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2502.12125v1",
    "published": "2025-02-17T18:47:01+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12124v1",
    "title": "RA-MTR: A Retrieval Augmented Multi-Task Reader based Approach for Inspirational Quote Extraction from Long Documents",
    "authors": [
      "Sayantan Adak",
      "Animesh Mukherjee"
    ],
    "abstract": "Inspirational quotes from famous individuals are often used to convey\nthoughts in news articles, essays, and everyday conversations. In this paper,\nwe propose a novel context-based quote extraction system that aims to extract\nthe most relevant quote from a long text. We formulate this quote extraction as\nan open domain question answering problem first by employing a vector-store\nbased retriever and then applying a multi-task reader. We curate three\ncontext-based quote extraction datasets and introduce a novel multi-task\nframework RA-MTR that improves the state-of-the-art performance, achieving a\nmaximum improvement of 5.08% in BoW F1-score.",
    "pdf_url": "http://arxiv.org/pdf/2502.12124v1",
    "published": "2025-02-17T18:46:46+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12123v2",
    "title": "On the Query Complexity of Verifier-Assisted Language Generation",
    "authors": [
      "Edoardo Botta",
      "Yuchen Li",
      "Aashay Mehta",
      "Jordan T. Ash",
      "Cyril Zhang",
      "Andrej Risteski"
    ],
    "abstract": "Recently, a plethora of works have proposed inference-time algorithms (e.g.\nbest-of-n), which incorporate verifiers to assist the generation process. Their\nquality-efficiency trade-offs have been empirically benchmarked on a variety of\nconstrained generation tasks, but the algorithmic design landscape is still\nlargely poorly understood. In this paper, we develop a mathematical framework\nfor reasoning about constrained generation using a pre-trained language model\ngenerator oracle and a process verifier--which can decide whether a prefix can\nbe extended to a string which satisfies the constraints of choice. We show that\neven in very simple settings, access to a verifier can render an intractable\nproblem (information-theoretically or computationally) to a tractable one. In\nfact, we show even simple algorithms, like tokenwise rejection sampling, can\nenjoy significant benefits from access to a verifier. Empirically, we show that\na natural modification of tokenwise rejection sampling, in which the sampler is\nallowed to \"backtrack\" (i.e., erase the final few generated tokens) has robust\nand substantive benefits over natural baselines (e.g. (blockwise) rejection\nsampling, nucleus sampling)--both in terms of computational efficiency,\naccuracy and diversity.",
    "pdf_url": "http://arxiv.org/pdf/2502.12123v2",
    "published": "2025-02-17T18:46:32+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12122v2",
    "title": "Minimal Ranks, Maximum Confidence: Parameter-efficient Uncertainty Quantification for LoRA",
    "authors": [
      "Patryk MarszaÅek",
      "Klaudia BaÅazy",
      "Jacek Tabor",
      "Tomasz KuÅmierczyk"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) enables parameter-efficient fine-tuning of large\nlanguage models by decomposing weight updates into low-rank matrices,\nsignificantly reducing storage and computational overhead. While effective,\nstandard LoRA lacks mechanisms for uncertainty quantification, leading to\noverconfident and poorly calibrated models. Bayesian variants of LoRA address\nthis limitation, but at the cost of a significantly increased number of\ntrainable parameters, partially offsetting the original efficiency gains.\nAdditionally, these models are harder to train and may suffer from unstable\nconvergence. In this work, we propose a novel parameter-efficient Bayesian LoRA\nvia subspace inference, demonstrating that effective uncertainty quantification\ncan be achieved in very low-dimensional parameter spaces. The proposed method\nachieves strong performance with improved calibration and generalization while\nmaintaining computational efficiency. Our empirical findings show that, with\nthe appropriate projection of the weight space: (1) uncertainty can be\neffectively modeled in a low-dimensional space, and (2) weight covariances\nexhibit low ranks.",
    "pdf_url": "http://arxiv.org/pdf/2502.12122v2",
    "published": "2025-02-17T18:46:29+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12121v2",
    "title": "Mitigating disorder and optimizing topological indicators with vision-transformer-based neural networks in Majorana nanowires",
    "authors": [
      "Jacob R. Taylor",
      "Sankar Das Sarma"
    ],
    "abstract": "Disorder remains a major obstacle to realizing topological Majorana zero\nmodes (MZMs) in superconductor-semiconductor nanowires, and we show how deep\nlearning can be used to recover topological MZMs mitigating disorder even when\nthe pre-mitigation situation manifests no apparent topology. The disorder\npotential, as well as the scattering invariant ($T_V$) normally used to\nclassify a device as topologically non-trivial are not directly measurable\nexperimentally. Additionally, the conventional signatures of MZMs have proved\ninsufficient due to their being accidentally replicated by disorder-induced\ntrivial states. Recent advances in machine learning provide a novel method to\nsolve these problems, allowing the underlying topology, suppressed by disorder,\nto be recovered using effective mitigation procedures. In this work, we\nleverage a vision transformer neural network trained on conductance\nmeasurements along with a CMA-ES optimization framework to dynamically tune\ngate voltages mitigating disorder effects. Unlike prior efforts that relied on\nindirect cost functions, our method directly optimizes $T_V$ alongside\nadditional local density of states-based topological indicators. Using a\nlightweight neural network variant, we demonstrate that even highly disordered\nnanowires initially lacking any topologically non-trivial regions can be\ntransformed into robust topological devices.",
    "pdf_url": "http://arxiv.org/pdf/2502.12121v2",
    "published": "2025-02-17T18:45:37+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.dis-nn"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.12120v2",
    "title": "LLMs on the Line: Data Determines Loss-to-Loss Scaling Laws",
    "authors": [
      "Prasanna Mayilvahanan",
      "ThaddÃ¤us Wiedemer",
      "Sayak Mallick",
      "Matthias Bethge",
      "Wieland Brendel"
    ],
    "abstract": "Scaling laws guide the development of large language models (LLMs) by\noffering estimates for the optimal balance of model size, tokens, and compute.\nMore recently, loss-to-loss scaling laws that relate losses across pretraining\ndatasets and downstream tasks have emerged as a powerful tool for understanding\nand improving LLM performance. In this work, we investigate which factors most\nstrongly influence loss-to-loss scaling. Our experiments reveal that the\npretraining data and tokenizer determine the scaling trend. In contrast, model\nsize, optimization hyperparameters, and even significant architectural\ndifferences, such as between transformer-based models like Llama and\nstate-space models like Mamba, have limited impact. Consequently, practitioners\nshould carefully curate suitable pretraining datasets for optimal downstream\nperformance, while architectures and other settings can be freely optimized for\ntraining efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2502.12120v2",
    "published": "2025-02-17T18:45:25+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12230v1",
    "title": "Interplay between Airy and Coriolis precessions in a real Foucault pendulum",
    "authors": [
      "N. N. Salva",
      "H. R. Salva"
    ],
    "abstract": "We study the precession of a Foucault pendulum using a new approach. We\ncharacterize the support anisotropy by the difference between the maximum and\nminimum periods of the pendulum along the principal axes of the support. Then\nwe compute the total precession rate, taking into account both the Airy\nprecession of a spherical pendulum and the Coriolis precession due to the\nEarth's rotation. To study the resulting motion we developed a calculation\nloop, period after period, which describes the movement of the oscillatory\ntrajectory of the bob. To test our model, we mounted a test pendulum of 480.3\ncm length and measured its periods and precession. The rate of precession is\nsensitive to the dimensions of the pendulum, the anisotropy of the support, and\nthe initial conditions. We find that for certain amplitudes the precession can\nstop entirely, while the pendulum continues to oscillate. It is also possible\nto obtain continuous precession at lower oscillation amplitudes. We give an\nupper bound for this critical oscillation amplitude. We close with a discussion\nof the implications of our findings for the design of Foucault pendulums used\nin demonstrations and lab experiments.",
    "pdf_url": "http://arxiv.org/pdf/2502.12230v1",
    "published": "2025-02-17T18:45:01+00:00",
    "categories": [
      "physics.class-ph",
      "physics.ed-ph"
    ],
    "primary_category": "physics.class-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12119v1",
    "title": "PRISM: Self-Pruning Intrinsic Selection Method for Training-Free Multimodal Data Selection",
    "authors": [
      "Jinhe Bi",
      "Yifan Wang",
      "Danqi Yan",
      "Xun Xiao",
      "Artur Hecker",
      "Volker Tresp",
      "Yunpu Ma"
    ],
    "abstract": "Visual instruction tuning refines pre-trained Multimodal Large Language\nModels (MLLMs) to enhance their real-world task performance. However, the rapid\nexpansion of visual instruction datasets introduces significant data\nredundancy, leading to excessive computational costs. Existing data selection\nmethods predominantly rely on proxy models or loss-based metrics, both of which\nimpose substantial computational overheads due to the necessity of model\ninference and backpropagation. To address this challenge, we propose PRISM, a\nnovel training-free approach for efficient multimodal data selection. Unlike\nexisting methods, PRISM eliminates the reliance on proxy models, warm-up\npretraining, and gradient-based optimization. Instead, it leverages Pearson\ncorrelation analysis to quantify the intrinsic visual encoding properties of\nMLLMs, computing a task-specific correlation score to identify high-value\ninstances. This not only enbles data-efficient selection,but maintains the\noriginal performance. Empirical evaluations across multiple MLLMs demonstrate\nthat PRISM reduces the overall time required for visual instruction tuning and\ndata selection to just 30% of conventional methods, while surpassing fully\nfine-tuned models across eight multimodal and three language understanding\nbenchmarks, achieving a 101.7% relative improvement in final performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.12119v1",
    "published": "2025-02-17T18:43:41+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12118v2",
    "title": "Scaling Test-Time Compute Without Verification or RL is Suboptimal",
    "authors": [
      "Amrith Setlur",
      "Nived Rajaraman",
      "Sergey Levine",
      "Aviral Kumar"
    ],
    "abstract": "Despite substantial advances in scaling test-time compute, an ongoing debate\nin the community is how it should be scaled up to enable continued and\nefficient improvements with scaling. There are largely two approaches: first,\ndistilling successful search or thinking traces; and second, using verification\n(e.g., 0/1 outcome rewards, reward models, or verifiers) to guide reinforcement\nlearning (RL) and search algorithms. In this paper, we prove that finetuning\nLLMs with verifier-based (VB) methods based on RL or search is far superior to\nverifier-free (VF) approaches based on distilling or cloning search traces,\ngiven a fixed amount of compute/data budget. Further, we show that as we scale\ntest-time compute (measured as the output token length) and training data,\nsuboptimality of VF methods scales poorly compared to VB when the base\npre-trained LLM presents a heterogeneous distribution over correct solution\ntraces (e.g., different lengths, styles, etc.) and admits a non-sharp\ndistribution over rewards on traces sampled from it. We formalize this\ncondition using anti-concentration [Erd\\H{o}s, 1945]. This implies a stronger\nresult that VB methods scale better asymptotically, with the performance gap\nbetween VB and VF methods widening as test-time budget grows. We corroborate\nour theory empirically on both didactic and math reasoning problems with\n3/8/32B-sized pre-trained LLMs, where we find verification is crucial for\nscaling test-time compute.",
    "pdf_url": "http://arxiv.org/pdf/2502.12118v2",
    "published": "2025-02-17T18:43:24+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12117v3",
    "title": "The Role of Prescreening in Auctions with Predictions",
    "authors": [
      "Yanwei Sun",
      "Fupeng Sun",
      "Chiwei Yan",
      "Jiahua Wu"
    ],
    "abstract": "Sellers often prescreen potential bidders, restricting participation to a\nselect group of capable participants. Recent advances in machine learning and\ngenerative AI make this strategy increasingly viable by enabling the\ncost-effective identification of high-quality bidders. However, the practice\ndeparts from classic auction theory, which usually favors broad competition\nover selective exclusion. In this paper, we examine whether and under what\nconditions bidder prescreening can be justified. We analyze a setting in which\nbidders have independent and identically distributed private valuations, and\nthe seller observes noisy signals generated by a valuation predictor. The\nseller determines how many top bidders to admit and, after receiving signals,\nselects exactly that many with the highest signal-based rankings. We\ndemonstrate that an auction with prescreening is equivalent to a standard\nauction (i.e., without prescreening) but with correlated valuations. Our\nanalysis shows that, although admitting fewer bidders leads to revenue losses\nin both second-price and first-price auctions, a more accurate predictor can\nmitigate or even fully offset these losses. In contrast, prescreening can\nsignificantly boost revenue in all-pay auctions; notably, when the predictor is\nperfect, admitting only two bidders is optimal. All results remain valid in the\npresence of reserve prices.",
    "pdf_url": "http://arxiv.org/pdf/2502.12117v3",
    "published": "2025-02-17T18:42:02+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12116v1",
    "title": "Floods do not sink prices, historical memory does: How flood risk impacts the Italian housing market",
    "authors": [
      "Anna Bellaver",
      "Lorenzo Costantini",
      "Ariadna Fosch",
      "Anna Monticelli",
      "David Scala",
      "Marco Pangallo"
    ],
    "abstract": "Do home prices incorporate flood risk in the immediate aftermath of specific\nflood events, or is it the repeated exposure over the years that plays a more\nsignificant role? We address this question through the first systematic study\nof the Italian housing market, which is an ideal case study because it is\nhighly exposed to floods, though unevenly distributed across the national\nterritory. Using a novel dataset containing about 550,000 mortgage-financed\ntransactions between 2016 and 2024, as well as hedonic regressions and a\ndifference-in-difference design, we find that: (i) specific floods do not\ndecrease home prices in areas at risk; (ii) the repeated exposure to floods in\nflood-prone areas leads to a price decline, up to 4\\% in the most frequently\nflooded regions; (iii) responses are heterogeneous by buyers' income and age.\nYoung buyers (with limited exposure to prior floods) do not obtain any price\nreduction for settling in risky areas, while experienced buyers do. At the same\ntime, buyers who settle in risky areas have lower incomes than buyers in safe\nareas in the most affected regions. Our results emphasize the importance of\ncultural and institutional factors in understanding how flood risk affects the\nhousing market and socioeconomic outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2502.12116v1",
    "published": "2025-02-17T18:41:23+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2502.12115v4",
    "title": "SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?",
    "authors": [
      "Samuel Miserendino",
      "Michele Wang",
      "Tejal Patwardhan",
      "Johannes Heidecke"
    ],
    "abstract": "We introduce SWE-Lancer, a benchmark of over 1,400 freelance software\nengineering tasks from Upwork, valued at \\$1 million USD total in real-world\npayouts. SWE-Lancer encompasses both independent engineering tasks--ranging\nfrom \\$50 bug fixes to \\$32,000 feature implementations--and managerial tasks,\nwhere models choose between technical implementation proposals. Independent\ntasks are graded with end-to-end tests triple-verified by experienced software\nengineers, while managerial decisions are assessed against the choices of the\noriginal hired engineering managers. We evaluate model performance and find\nthat frontier models are still unable to solve the majority of tasks. To\nfacilitate future research, we open-source a unified Docker image and a public\nevaluation split, SWE-Lancer Diamond\n(https://github.com/openai/SWELancer-Benchmark). By mapping model performance\nto monetary value, we hope SWE-Lancer enables greater research into the\neconomic impact of AI model development.",
    "pdf_url": "http://arxiv.org/pdf/2502.12115v4",
    "published": "2025-02-17T18:41:16+00:00",
    "categories": [
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12114v1",
    "title": "BS-Breath: Respiration Sensing with Cell-free Massive MIMO",
    "authors": [
      "Haoqiu Xiong",
      "Robbert Beerten",
      "Zhuangzhuang Cui",
      "Yang Miao",
      "Sofie Pollin"
    ],
    "abstract": "This paper demonstrates the feasibility of respiration pattern estimation\nutilizing a communication-centric cellfree massive MIMO OFDM Base Station (BS).\nThe sensing target is typically positioned near the User Equipment (UE), which\ntransmits uplink pilots to the BS. Our results demonstrate the potential of\nmassive MIMO systems for accurate and reliable vital sign estimation.\nInitially, we adopt a single antenna sensing solution that combines multiple\nsubcarriers and a breathing projection to align the 2D complex breathing\npattern to a single displacement dimension. Then, Weighted Antenna Combining\n(WAC) aggregates the 1D breathing signals from multiple antennas. The results\ndemonstrate that the combination of space-frequency resources specifically in\nterms of subcarriers and antennas yields higher accuracy than using only a\nsingle antenna or subcarrier. Our results significantly improved respiration\nestimation accuracy by using multiple subcarriers and antennas. With WAC, we\nachieved an average correlation of 0.8 with ground truth data, compared to 0.6\nfor single antenna or subcarrier methods, a 0.2 correlation increase. Moreover,\nthe system produced perfect breathing rate estimates. These findings suggest\nthat the limited bandwidth (18 MHz in the testbed) can be effectively\ncompensated by utilizing spatial resources, such as distributed antennas.",
    "pdf_url": "http://arxiv.org/pdf/2502.12114v1",
    "published": "2025-02-17T18:40:45+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12113v1",
    "title": "A Monocular Event-Camera Motion Capture System",
    "authors": [
      "Leonard Bauersfeld",
      "Davide Scaramuzza"
    ],
    "abstract": "Motion capture systems are a widespread tool in research to record\nground-truth poses of objects. Commercial systems use reflective markers\nattached to the object and then triangulate pose of the object from multiple\ncamera views. Consequently, the object must be visible to multiple cameras\nwhich makes such multi-view motion capture systems unsuited for deployments in\nnarrow, confined spaces (e.g. ballast tanks of ships). In this technical report\nwe describe a monocular event-camera motion capture system which overcomes this\nlimitation and is ideally suited for narrow spaces. Instead of passive markers\nit relies on active, blinking LED markers such that each marker can be uniquely\nidentified from the blinking frequency. The markers are placed at known\nlocations on the tracking object. We then solve the PnP (perspective-n-points)\nproblem to obtain the position and orientation of the object. The developed\nsystem has millimeter accuracy, millisecond latency and we demonstrate that its\nstate estimate can be used to fly a small, agile quadrotor.",
    "pdf_url": "http://arxiv.org/pdf/2502.12113v1",
    "published": "2025-02-17T18:38:27+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12112v4",
    "title": "Role of the counterterms in the conservation of superhorizon curvature perturbations at one loop",
    "authors": [
      "Keisuke Inomata"
    ],
    "abstract": "Recently, several papers have claimed that superhorizon curvature\nperturbations are not conserved at the one-loop level in single-field inflation\nmodels if there is a transient ultra-slow-roll period. In this work, we point\nout that the contributions from the counterterms were overlooked in the recent\npapers. We show that the counterterm contributions play a crucial role in\ncanceling the one-loop power spectrum of superhorizon curvature perturbations\nin the comoving gauge.",
    "pdf_url": "http://arxiv.org/pdf/2502.12112v4",
    "published": "2025-02-17T18:36:33+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12111v1",
    "title": "Insights from leptohadronic modelling of the brightest blazar flare",
    "authors": [
      "Egor Podlesnyi",
      "Foteini Oikonomou"
    ],
    "abstract": "The blazar 3C 454.3 experienced a major flare in November 2010 making it the\nbrightest $\\gamma$-ray source in the sky of the Fermi-LAT. We obtain seven\ndaily consecutive spectral-energy distributions (SEDs) of the flare in the\ninfra-red, optical, ultra-violet, X-ray and $\\gamma$-ray bands with publicly\navailable data. We simulate the physical conditions in the blazar and show that\nthe observed SEDs are well reproduced in the framework of a \"standing feature\"\nwhere the position of the emitting region is almost stationary, located beyond\nthe outer radius of the broad-line region and into which fresh blobs of\nrelativistically moving magnetized plasma are continuously injected. Meanwhile,\na model with a single \"moving blob\" does not describe the data well. We obtain\na robust upper limit to the amount of high-energy protons in the jet of 3C\n454.3 from the electromagnetic SED. We construct a neutrino light curve of 3C\n454.3 and estimate the expected neutrino yield at energies $\\geq 100$ TeV for\n3C 454.3 to be up to $6 \\times 10^{-3}$ $\\nu_{\\mu}$ per year. Finally, we\nextrapolate our model findings to the light curves of all Fermi-LAT\nflat-spectrum radio quasars. We find that next-generation neutrino telescopes\nare expected to detect approximately one multimessenger ($\\gamma + \\nu_{\\mu}$)\nflare per year from bright blazars with neutrino peak energy in the hundreds\nTeV -- hundreds PeV energy range and show that the electromagnetic flare peak\ncan precede the neutrino arrival by months to years.",
    "pdf_url": "http://arxiv.org/pdf/2502.12111v1",
    "published": "2025-02-17T18:36:32+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12110v10",
    "title": "A-MEM: Agentic Memory for LLM Agents",
    "authors": [
      "Wujiang Xu",
      "Kai Mei",
      "Hang Gao",
      "Juntao Tan",
      "Zujie Liang",
      "Yongfeng Zhang"
    ],
    "abstract": "While large language model (LLM) agents can effectively use external tools\nfor complex real-world tasks, they require memory systems to leverage\nhistorical experiences. Current memory systems enable basic storage and\nretrieval but lack sophisticated memory organization, despite recent attempts\nto incorporate graph databases. Moreover, these systems' fixed operations and\nstructures limit their adaptability across diverse tasks. To address this\nlimitation, this paper proposes a novel agentic memory system for LLM agents\nthat can dynamically organize memories in an agentic way. Following the basic\nprinciples of the Zettelkasten method, we designed our memory system to create\ninterconnected knowledge networks through dynamic indexing and linking. When a\nnew memory is added, we generate a comprehensive note containing multiple\nstructured attributes, including contextual descriptions, keywords, and tags.\nThe system then analyzes historical memories to identify relevant connections,\nestablishing links where meaningful similarities exist. Additionally, this\nprocess enables memory evolution - as new memories are integrated, they can\ntrigger updates to the contextual representations and attributes of existing\nhistorical memories, allowing the memory network to continuously refine its\nunderstanding. Our approach combines the structured organization principles of\nZettelkasten with the flexibility of agent-driven decision making, allowing for\nmore adaptive and context-aware memory management. Empirical experiments on six\nfoundation models show superior improvement against existing SOTA baselines.\nThe source code for evaluating performance is available at\nhttps://github.com/WujiangXu/A-mem, while the source code of the agentic memory\nsystem is available at https://github.com/WujiangXu/A-mem-sys.",
    "pdf_url": "http://arxiv.org/pdf/2502.12110v10",
    "published": "2025-02-17T18:36:14+00:00",
    "categories": [
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12977v1",
    "title": "Time-series attribution maps with regularized contrastive learning",
    "authors": [
      "Steffen Schneider",
      "Rodrigo GonzÃ¡lez Laiz",
      "Anastasiia Filippova",
      "Markus Frey",
      "Mackenzie Weygandt Mathis"
    ],
    "abstract": "Gradient-based attribution methods aim to explain decisions of deep learning\nmodels but so far lack identifiability guarantees. Here, we propose a method to\ngenerate attribution maps with identifiability guarantees by developing a\nregularized contrastive learning algorithm trained on time-series data plus a\nnew attribution method called Inverted Neuron Gradient (collectively named\nxCEBRA). We show theoretically that xCEBRA has favorable properties for\nidentifying the Jacobian matrix of the data generating process. Empirically, we\ndemonstrate robust approximation of zero vs. non-zero entries in the\nground-truth attribution map on synthetic datasets, and significant\nimprovements across previous attribution methods based on feature ablation,\nShapley values, and other gradient-based methods. Our work constitutes a first\nexample of identifiable inference of time-series attribution maps and opens\navenues to a better understanding of time-series data, such as for neural\ndynamics and decision-processes within neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.12977v1",
    "published": "2025-02-17T18:34:25+00:00",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.12109v1",
    "title": "Personality Structured Interview for Large Language Model Simulation in Personality Research",
    "authors": [
      "Pengda Wang",
      "Huiqi Zou",
      "Hanjie Chen",
      "Tianjun Sun",
      "Ziang Xiao",
      "Frederick L. Oswald"
    ],
    "abstract": "Although psychometrics researchers have recently explored the use of large\nlanguage models (LLMs) as proxies for human participants, LLMs often fail to\ngenerate heterogeneous data with human-like diversity, which diminishes their\nvalue in advancing social science research. To address these challenges, we\nexplored the potential of the theory-informed Personality Structured Interview\n(PSI) as a tool for simulating human responses in personality research. In this\napproach, the simulation is grounded in nuanced real-human interview\ntranscripts that target the personality construct of interest. We have provided\na growing set of 357 structured interview transcripts from a representative\nsample, each containing an individual's response to 32 open-ended questions\ncarefully designed to gather theory-based personality evidence. Additionally,\ngrounded in psychometric research, we have summarized an evaluation framework\nto systematically validate LLM-generated psychometric data. Results from three\nexperiments demonstrate that well-designed structured interviews could improve\nhuman-like heterogeneity in LLM-simulated personality data and predict\npersonality-related behavioral outcomes (i.e., organizational citizenship\nbehaviors and counterproductive work behavior). We further discuss the role of\ntheory-informed structured interviews in LLM-based simulation and outline a\ngeneral framework for designing structured interviews to simulate human-like\ndata for psychometric research.",
    "pdf_url": "http://arxiv.org/pdf/2502.12109v1",
    "published": "2025-02-17T18:31:57+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12108v1",
    "title": "Using the Path of Least Resistance to Explain Deep Networks",
    "authors": [
      "Sina Salek",
      "Joseph Enguehard"
    ],
    "abstract": "Integrated Gradients (IG), a widely used axiomatic path-based attribution\nmethod, assigns importance scores to input features by integrating model\ngradients along a straight path from a baseline to the input. While effective\nin some cases, we show that straight paths can lead to flawed attributions. In\nthis paper, we identify the cause of these misattributions and propose an\nalternative approach that treats the input space as a Riemannian manifold,\ncomputing attributions by integrating gradients along geodesics. We call this\nmethod Geodesic Integrated Gradients (GIG). To approximate geodesic paths, we\nintroduce two techniques: a k-Nearest Neighbours-based approach for smaller\nmodels and a Stochastic Variational Inference-based method for larger ones.\nAdditionally, we propose a new axiom, Strong Completeness, extending the axioms\nsatisfied by IG. We show that this property is desirable for attribution\nmethods and that GIG is the only method that satisfies it. Through experiments\non both synthetic and real-world data, we demonstrate that GIG outperforms\nexisting explainability methods, including IG.",
    "pdf_url": "http://arxiv.org/pdf/2502.12108v1",
    "published": "2025-02-17T18:29:24+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12107v1",
    "title": "Spindown of massive main sequence stars in the Milky Way",
    "authors": [
      "K. Nathaniel",
      "N. Langer",
      "S. SimÃ³n-DÃ­az",
      "G. Holgado",
      "A. de Burgos",
      "B. Hastings"
    ],
    "abstract": "Context. We need to understand the spin evolution of massive stars to compute\ntheir internal rotationally induced mixing processes, isolate effects of close\nbinary evolution, and predict the rotation rates of white dwarfs, neutron stars\nand black holes.\n  Aims. We discuss the spindown of massive main sequence stars imposed by\nstellar winds.\n  Methods. We use detailed grids of single star evolutionary models to predict\nthe distribution of the surface rotational velocities of core-hydrogen burning\nGalactic massive stars as function of their mass and evolutionary state. We\nthen compare the spin properties of our synthetic populations with\nappropriately selected sub-samples of Galactic main sequence OB-type stars\nextracted from the IACOB survey.\n  Results. We find that below $\\sim 40 M_\\odot$, observations and models agree\nin finding that the surface rotational velocities of Galactic massive stars\nremain relatively constant during their main sequence evolution. The more\nmassive stars in the IACOB sample appear to spin down less than predicted,\nwhile our updated angular momentum loss prescription predicts an enhanced\nspindown. Furthermore, the observations show a population of fast rotators,\nwith $v \\sin I \\gtrsim 200$ km/s persisting for all ages, which is not\nreproduced by our synthetic single star populations.\n  Conclusions. We conclude that the wind-induced spindown of massive main\nsequence stars is yet to be fully understood, and that close binary evolution\nmight significantly contribute to the fraction of rapid rotators in massive\nstars.",
    "pdf_url": "http://arxiv.org/pdf/2502.12107v1",
    "published": "2025-02-17T18:29:00+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12106v1",
    "title": "Personal Danger Signals Reprocessing: New Online Group Intervention for Chronic Pain",
    "authors": [
      "Carmit Himmelblau Gat",
      "Natalia Polyviannaya",
      "Pavel Goldstein"
    ],
    "abstract": "Chronic pain is a significant global health issue, with many patients\nexperiencing persistent pain despite no identifiable organic cause, classified\nas nociplastic pain. Increasing evidence highlights the role of danger signal\nprocessing in the maintenance of chronic pain. In response, we developed\nPersonal Danger Signals Reprocessing (PDSR), an online, group-based\nintervention designed to modify these mechanisms using coaching techniques to\nenhance accessibility and affordability.\n  This study evaluated the efficacy of PDSR in reducing pain and mental health\ncomorbidities. A cohort of women (N=19, mean age 43) participated in an 8-week\nonline program, receiving weekly sessions on chronic pain mechanisms within a\nsystemic framework. Outcomes were assessed at three time points:\npre-intervention, mid-intervention, and post-intervention. A waiting list group\n(N=20, mean age 43.5) completed assessments at the same intervals.\n  Participants in the PDSR group showed significant pain reduction (p < .001),\nwith moderate to large effects observed at mid-intervention (Cohen's D = 0.7)\nand post-intervention (Cohen's D = 1.5) compared to controls. Pain interference\nsignificantly decreased (p < .01), with large reductions in the PDSR group\n(Cohen's D = -1.7, p < .0001). Well-being also improved substantially (p <\n.001, Cohen's D = 1.7-1.8). Secondary outcomes, including pain catastrophizing,\nsleep interference, anxiety, and depressive symptoms, consistently improved\n(all p-values < .01).\n  Findings suggest PDSR is an effective, scalable intervention for reducing\npain, improving function, and enhancing well-being in individuals with chronic\npain.",
    "pdf_url": "http://arxiv.org/pdf/2502.12106v1",
    "published": "2025-02-17T18:27:50+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12105v1",
    "title": "Interplay of Quantum Coherence and Nonequilibrium Quantum Transport: An Exact Density Matrix Formulation in the Heisenberg Framework",
    "authors": [
      "Saikumar Krithivasan",
      "Thingujam Yaiphalemba Meitei",
      "Arijit Sen",
      "Md Manirul Ali"
    ],
    "abstract": "We aim to bridge the gap between quantum coherence, quantum correlations, and\nnonequilibrium quantum transport in a quantum double-dot (QDD) system\ninteracting with fermionic reservoirs. The system-reservoir coupling is modeled\nusing a Fano-Anderson-type Hamiltonian. The density operator elements of the\nQDD system are expressed in terms of expectation values involving various\ncombinations of the fermionic creation and annihilation operators associated\nwith the system. By utilizing the quantum Langevin equation and the Heisenberg\nequation of motion, we derive the precise temporal behavior of these operator\naverages in terms of nonequilibrium Green's functions and subsequently obtain\nthe time evolution of the density operator elements. Our approach is valid in\nboth the strong coupling and non-Markovian regimes. Additionally, we examine\nthe time evolution of quantum coherence in the QDD system, quantifying it using\nstandard measures such as the l1-norm and the relative entropy of coherence. As\nobserved, coherence reaches a non-zero steady-state value, highlighting its\nsignificant potential for applications in quantum information processing and\nquantum technologies. Furthermore, we establish a connection between quantum\ncoherence and transport current in a QDD system serially coupled to fermionic\nreservoirs. We then investigate the effects of coupling strength and reservoir\nmemory by tuning the finite spectral width of the reservoir, examining their\nimpact on both transient and steady-state properties, such as quantum coherence\nand particle current, which could play a crucial role in ultrafast nanodevice\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2502.12105v1",
    "published": "2025-02-17T18:27:14+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12104v2",
    "title": "High-dimensional long-range statistical mechanical models have random walk correlation functions",
    "authors": [
      "Yucheng Liu"
    ],
    "abstract": "We consider long-range percolation, Ising model, and self-avoiding walk on\n$\\mathbb Z^d$, with couplings decaying like $|x|^{-(d+\\alpha)}$ where $0 <\n\\alpha \\le 2$, above the upper critical dimensions. In the spread-out setting\nwhere the lace expansion applies, we show that the two-point function for each\nof these models exactly coincides with a random walk two-point function, up to\na constant prefactor. Using this, for $0<\\alpha < 2$, we prove upper and lower\nbounds of the form $|x|^{-(d-\\alpha)} \\min\\{ 1, (p_c - p)^{-2} |x|^{-2\\alpha}\n\\}$ for the two-point function near the critical point $p_c$. For $\\alpha=2$,\nwe obtain a similar upper bound with logarithmic corrections. We also give a\nsimple proof of the convergence of the lace expansion, assuming diagrammatic\nestimates.",
    "pdf_url": "http://arxiv.org/pdf/2502.12104v2",
    "published": "2025-02-17T18:26:24+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP",
      "60K35, 82B20, 82B27, 82B41, 82B43"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12103v3",
    "title": "CriteoPrivateAds: A Real-World Bidding Dataset to Design Private Advertising Systems",
    "authors": [
      "Mehdi Sebbar",
      "Corentin Odic",
      "Mathieu LÃ©chine",
      "AloÃ¯s Bissuel",
      "Nicolas Chrysanthos",
      "Anthony D'Amato",
      "Alexandre Gilotte",
      "Fabian HÃ¶ring",
      "Sarah Nogueira",
      "Maxime Vono"
    ],
    "abstract": "In the past years, many proposals have emerged in order to address online\nadvertising use-cases without access to third-party cookies. All these\nproposals leverage some privacy-enhancing technologies such as aggregation or\ndifferential privacy. Yet, no public and rich-enough ground truth is currently\navailable to assess the relevancy of aforementioned private advertising\nframeworks. We are releasing the largest, in terms of number of features,\nbidding dataset specifically built in alignment with the design of major\nbrowser vendors proposals such as Chrome Privacy Sandbox. This dataset, coined\nCriteoPrivateAds, stands for an anonymised version of Criteo production logs\nand provides sufficient data to learn bidding models commonly used in online\nadvertising under many privacy constraints (delayed reports, display and\nuser-level differential privacy, user signal quantisation or aggregated\nreports). We ensured that this dataset, while being anonymised, is able to\nprovide offline results close to production performance of adtech companies\nincluding Criteo - making it a relevant ground truth to design private\nadvertising systems. The dataset is available in Hugging Face:\nhttps://huggingface.co/datasets/criteo/CriteoPrivateAd.",
    "pdf_url": "http://arxiv.org/pdf/2502.12103v3",
    "published": "2025-02-17T18:24:48+00:00",
    "categories": [
      "cs.CR",
      "stat.CO"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12102v1",
    "title": "Relational Norms for Human-AI Cooperation",
    "authors": [
      "Brian D. Earp",
      "Sebastian Porsdam Mann",
      "Mateo Aboy",
      "Edmond Awad",
      "Monika Betzler",
      "Marietjie Botes",
      "Rachel Calcott",
      "Mina Caraccio",
      "Nick Chater",
      "Mark Coeckelbergh",
      "Mihaela Constantinescu",
      "Hossein Dabbagh",
      "Kate Devlin",
      "Xiaojun Ding",
      "Vilius Dranseika",
      "Jim A. C. Everett",
      "Ruiping Fan",
      "Faisal Feroz",
      "Kathryn B. Francis",
      "Cindy Friedman",
      "Orsolya Friedrich",
      "Iason Gabriel",
      "Ivar Hannikainen",
      "Julie Hellmann",
      "Arasj Khodadade Jahrome",
      "Niranjan S. Janardhanan",
      "Paul Jurcys",
      "Andreas Kappes",
      "Maryam Ali Khan",
      "Gordon Kraft-Todd",
      "Maximilian Kroner Dale",
      "Simon M. Laham",
      "Benjamin Lange",
      "Muriel Leuenberger",
      "Jonathan Lewis",
      "Peng Liu",
      "David M. Lyreskog",
      "Matthijs Maas",
      "John McMillan",
      "Emilian Mihailov",
      "Timo Minssen",
      "Joshua Teperowski Monrad",
      "Kathryn Muyskens",
      "Simon Myers",
      "Sven Nyholm",
      "Alexa M. Owen",
      "Anna Puzio",
      "Christopher Register",
      "Madeline G. Reinecke",
      "Adam Safron",
      "Henry Shevlin",
      "Hayate Shimizu",
      "Peter V. Treit",
      "Cristina Voinea",
      "Karen Yan",
      "Anda Zahiu",
      "Renwen Zhang",
      "Hazem Zohny",
      "Walter Sinnott-Armstrong",
      "Ilina Singh",
      "Julian Savulescu",
      "Margaret S. Clark"
    ],
    "abstract": "How we should design and interact with social artificial intelligence depends\non the socio-relational role the AI is meant to emulate or occupy. In human\nsociety, relationships such as teacher-student, parent-child, neighbors,\nsiblings, or employer-employee are governed by specific norms that prescribe or\nproscribe cooperative functions including hierarchy, care, transaction, and\nmating. These norms shape our judgments of what is appropriate for each\npartner. For example, workplace norms may allow a boss to give orders to an\nemployee, but not vice versa, reflecting hierarchical and transactional\nexpectations. As AI agents and chatbots powered by large language models are\nincreasingly designed to serve roles analogous to human positions - such as\nassistant, mental health provider, tutor, or romantic partner - it is\nimperative to examine whether and how human relational norms should extend to\nhuman-AI interactions. Our analysis explores how differences between AI systems\nand humans, such as the absence of conscious experience and immunity to\nfatigue, may affect an AI's capacity to fulfill relationship-specific functions\nand adhere to corresponding norms. This analysis, which is a collaborative\neffort by philosophers, psychologists, relationship scientists, ethicists,\nlegal experts, and AI researchers, carries important implications for AI\nsystems design, user behavior, and regulation. While we accept that AI systems\ncan offer significant benefits such as increased availability and consistency\nin certain socio-relational roles, they also risk fostering unhealthy\ndependencies or unrealistic expectations that could spill over into human-human\nrelationships. We propose that understanding and thoughtfully shaping (or\nimplementing) suitable human-AI relational norms will be crucial for ensuring\nthat human-AI interactions are ethical, trustworthy, and favorable to human\nwell-being.",
    "pdf_url": "http://arxiv.org/pdf/2502.12102v1",
    "published": "2025-02-17T18:23:29+00:00",
    "categories": [
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.17478v1",
    "title": "Please, do tell",
    "authors": [
      "Yvonne Lai"
    ],
    "abstract": "\"Math is not a spectator sport.\" \"Lecturing is educational malpractice.\"\nSlogans like these rally some mathematicians to teach classes that feature\n\"active learning\", where lecturing is eschewed for student participation. Yet\nas much as I believe that students must do math to learn math, I also find\nblanket statements to be more about bandwagons than considered reflection on\nteaching. In this column, published in the Fall 2021 AWM Newsletter, I urge us\nto think through the math we offer students and how we set up students to\nlearn. Although I draw primarily from my experiences teaching proofs in\nabstract algebra and real analysis, the scenarios extend to other topics in\nfirst year undergraduate education and beyond.",
    "pdf_url": "http://arxiv.org/pdf/2502.17478v1",
    "published": "2025-02-17T18:21:35+00:00",
    "categories": [
      "math.HO",
      "97"
    ],
    "primary_category": "math.HO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12101v2",
    "title": "Bondi-like Accretion Flow Dynamics: The Role of Gravitational Potential",
    "authors": [
      "Razieh Ranjbar",
      "HÃ©ctor R. Olivares-SÃ¡nchez",
      "Shahram Abbassi"
    ],
    "abstract": "The formation of massive black holes and their coevolution with host galaxies\nare pivotal areas of modern astrophysics. Spherical accretion onto a central\npoint mass serves as a foundational framework in cosmological simulations,\nsemi-analytical models, and observational studies. In this paper, we extend the\nclassical spherical accretion model by incorporating the gravitational\npotential of host galaxies, including contributions from stellar components and\ndark matter halos. Numerical solutions spanning scales from parsecs down to ~\n10 r_s reveal that the flow structure is highly sensitive to the mass and size\nof the dark matter halo. Adding a small amount of angular momentum to the\naccreting gas demonstrates that such flows resemble spherical Bondi accretion,\nwith mass accretion rates converging toward the Bondi rate. We find that the\nlow angular momentum flow resembles the spherical Bondi flow, and its mass\naccretion rate approaches the Bondi accretion rate. Remarkably, due to the\npresence of dark matter, the mass accretion rate increases by more than ~ %100\ncompared to analogous hydrodynamic solutions without dark matter. These\nfindings underscore the critical role of stellar and dark matter gravitational\npotentials in shaping the dynamics and accretion rates of quasi-spherical\nflows, providing new insights into astrophysical accretion processes.",
    "pdf_url": "http://arxiv.org/pdf/2502.12101v2",
    "published": "2025-02-17T18:21:06+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12100v2",
    "title": "3D Vortices and rotating solitons in ultralight dark matter",
    "authors": [
      "Ph. Brax",
      "P. Valageas"
    ],
    "abstract": "We study the formation and the dynamics of vortex lines in rotating scalar\ndark matter halos, focusing on models with quartic repulsive self-interactions.\nIn the nonrelativistic regime, vortex lines and their lattices arise from the\nGross-Pitaevskii equation of motion, as for superfluids and Bose-Einstein\ncondensates studied in laboratory experiments. Indeed, in such systems\nvorticity is supported by the singularities of the phase of the scalar field,\nwhich leads to a discrete set of quantized vortices amid a curl-free velocity\nbackground. In the continuum limit where the number of vortex lines becomes\nvery large, we find that the equilibrium solution is a rotating soliton that\nobeys a solid-body rotation, with an oblate density profile aligned with the\ndirection of the total spin. This configuration is dynamically stable provided\nthe rotational energy is smaller than the self-interaction and gravitational\nenergies. Using numerical simulations in the Thomas-Fermi regime, with\nstochastic initial conditions for a spherical halo with a specific averaged\ndensity profile and angular momentum, we find that a rotating soliton always\nemerges dynamically, within a few dynamical times, and that a network of vortex\nlines aligned with the total spin fills its oblate profile. These vertical\nvortex lines form a regular lattice in the equatorial plane, in agreement with\nthe analytical predictions of uniform vortex density and solid-body rotation.\nThese vortex lines might further extend between halos to form the backbone of\nspinning cosmic filaments.",
    "pdf_url": "http://arxiv.org/pdf/2502.12100v2",
    "published": "2025-02-17T18:20:44+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12099v1",
    "title": "Crime in Proportions: Applying Compositional Data Analysis to European Crime Trends for 2022",
    "authors": [
      "Onur BatÄ±n DoÄan",
      "Fatma SevinÃ§ Kurnaz"
    ],
    "abstract": "This article investigates crime patterns across European countries in 2022\nusing Compositional Data Analysis (CoDA) to address limitations of traditional\nstatistical approaches in dealing with the relative nature of crime data.\nRecognizing crime types as components of a whole, we employ CoDA to explore\nrelationships between different crime categories while respecting their\ninherent interdependencies. The study utilizes k-means clustering to group\ncountries based on their crime profiles, identifying three distinct clusters\nlargely aligning with geographical locations. This clustering is visualized\nthrough t-SNE and geographic mapping, revealing regional similarities. Further\nanalysis using Robust Principal Component Analysis on identified crime clusters\nreveals insightful relationships between specific crime types, such as\nhomicide, smuggling, and financial crimes, and how their prevalence varies\nacross countries. The findings reveals distinct crime patterns across Europe,\nhighlighting regional commonalities while also highlighting divergences like\nNorway and Latvia that deviate from their expected geographical\nclassifications. Moreover, the study identifies specific crime groups; for\nexample, it pairs countries high in corruption and smuggling, such as Austria,\nwith those countries that exhibit a higher relevance to homicide and smuggling,\nsuch as Luxembourg. It also points to the presence of financial crimes like\nfraud in countries such as Romania and Estonia.",
    "pdf_url": "http://arxiv.org/pdf/2502.12099v1",
    "published": "2025-02-17T18:18:43+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12098v1",
    "title": "Bandwidth-Adaptive Spatiotemporal Correspondence Identification for Collaborative Perception",
    "authors": [
      "Peng Gao",
      "Williard Joshua Jose",
      "Hao Zhang"
    ],
    "abstract": "Correspondence identification (CoID) is an essential capability in\nmulti-robot collaborative perception, which enables a group of robots to\nconsistently refer to the same objects within their respective fields of view.\nIn real-world applications, such as connected autonomous driving, vehicles face\nchallenges in directly sharing raw observations due to limited communication\nbandwidth. In order to address this challenge, we propose a novel approach for\nbandwidth-adaptive spatiotemporal CoID in collaborative perception. This\napproach allows robots to progressively select partial spatiotemporal\nobservations and share with others, while adapting to communication constraints\nthat dynamically change over time. We evaluate our approach across various\nscenarios in connected autonomous driving simulations. Experimental results\nvalidate that our approach enables CoID and adapts to dynamic communication\nbandwidth changes. In addition, our approach achieves 8%-56% overall\nimprovements in terms of covisible object retrieval for CoID and data sharing\nefficiency, which outperforms previous techniques and achieves the\nstate-of-the-art performance. More information is available at:\nhttps://gaopeng5.github.io/acoid.",
    "pdf_url": "http://arxiv.org/pdf/2502.12098v1",
    "published": "2025-02-17T18:18:23+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12097v1",
    "title": "Data assimilation performed with robust shape registration and graph neural networks: application to aortic coarctation",
    "authors": [
      "Francesco Romor",
      "Felipe Galarce",
      "Jan BrÃ¼ning",
      "Leonid Goubergrits",
      "Alfonso Caiazzo"
    ],
    "abstract": "Image-based, patient-specific modelling of hemodynamics can improve\ndiagnostic capabilities and provide complementary insights to better understand\nthe hemodynamic treatment outcomes. However, computational fluid dynamics\nsimulations remain relatively costly in a clinical context. Moreover,\nprojection-based reduced-order models and purely data-driven surrogate models\nstruggle due to the high variability of anatomical shapes in a population. A\npossible solution is shape registration: a reference template geometry is\ndesigned from a cohort of available geometries, which can then be\ndiffeomorphically mapped onto it. This provides a natural encoding that can be\nexploited by machine learning architectures and, at the same time, a reference\ncomputational domain in which efficient dimension-reduction strategies can be\nperformed. We compare state-of-the-art graph neural network models with recent\ndata assimilation strategies for the prediction of physical quantities and\nclinically relevant biomarkers in the context of aortic coarctation.",
    "pdf_url": "http://arxiv.org/pdf/2502.12097v1",
    "published": "2025-02-17T18:15:09+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12096v4",
    "title": "Token Communications: A Large Model-Driven Framework for Cross-modal Context-aware Semantic Communications",
    "authors": [
      "Li Qiao",
      "Mahdi Boloursaz Mashhadi",
      "Zhen Gao",
      "Rahim Tafazolli",
      "Mehdi Bennis",
      "Dusit Niyato"
    ],
    "abstract": "In this paper, we introduce token communications (TokCom), a large\nmodel-driven framework to leverage cross-modal context information in\ngenerative semantic communications (GenSC). TokCom is a new paradigm, motivated\nby the recent success of generative foundation models and multimodal large\nlanguage models (GFM/MLLMs), where the communication units are tokens, enabling\nefficient transformer-based token processing at the transmitter and receiver.\nIn this paper, we introduce the potential opportunities and challenges of\nleveraging context in GenSC, explore how to integrate GFM/MLLMs-based token\nprocessing into semantic communication systems to leverage cross-modal context\neffectively at affordable complexity, present the key principles for efficient\nTokCom at various layers in future wireless networks. In a typical image\nsemantic communication setup, we demonstrate a significant improvement of the\nbandwidth efficiency, achieved by TokCom by leveraging the context information\namong tokens. Finally, the potential research directions are identified to\nfacilitate adoption of TokCom in future wireless networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.12096v4",
    "published": "2025-02-17T18:14:18+00:00",
    "categories": [
      "cs.MM",
      "cs.CV",
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2502.12095v1",
    "title": "Descriminative-Generative Custom Tokens for Vision-Language Models",
    "authors": [
      "Pramuditha Perera",
      "Matthew Trager",
      "Luca Zancato",
      "Alessandro Achille",
      "Stefano Soatto"
    ],
    "abstract": "This paper explores the possibility of learning custom tokens for\nrepresenting new concepts in Vision-Language Models (VLMs). Our aim is to learn\ntokens that can be effective for both discriminative and generative tasks while\ncomposing well with words to form new input queries. The targeted concept is\nspecified in terms of a small set of images and a parent concept described\nusing text. We operate on CLIP text features and propose to use a combination\nof a textual inversion loss and a classification loss to ensure that text\nfeatures of the learned token are aligned with image features of the concept in\nthe CLIP embedding space. We restrict the learned token to a low-dimensional\nsubspace spanned by tokens for attributes that are appropriate for the given\nsuper-class. These modifications improve the quality of compositions of the\nlearned token with natural language for generating new scenes. Further, we show\nthat learned custom tokens can be used to form queries for text-to-image\nretrieval task, and also have the important benefit that composite queries can\nbe visualized to ensure that the desired concept is faithfully encoded. Based\non this, we introduce the method of Generation Aided Image Retrieval, where the\nquery is modified at inference time to better suit the search intent. On the\nDeepFashion2 dataset, our method improves Mean Reciprocal Retrieval (MRR) over\nrelevant baselines by 7%.",
    "pdf_url": "http://arxiv.org/pdf/2502.12095v1",
    "published": "2025-02-17T18:13:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12094v1",
    "title": "A Study on Leveraging Search and Self-Feedback for Agent Reasoning",
    "authors": [
      "Karthikeyan K",
      "Michelle Yuan",
      "Elman Mansimov",
      "Katerina Margatina",
      "Anurag Pratik",
      "Daniele Bonadiman",
      "Monica Sunkara",
      "Yi Zhang",
      "Yassine Benajiba"
    ],
    "abstract": "Recent works have demonstrated that incorporating search during inference can\nsignificantly improve reasoning capabilities of language agents. Some\napproaches may make use of the ground truth or rely on model's own generated\nfeedback. The search algorithm uses this feedback to then produce values that\nwill update its criterion for exploring and exploiting various reasoning paths.\nIn this study, we investigate how search and model's self-feedback can be\nleveraged for reasoning tasks. First, we explore differences in ground-truth\nfeedback and self-feedback during search for math reasoning. Second, we observe\nlimitations in applying search techniques to more complex tasks like\ntool-calling and design domain-specific approaches to address these gaps. Our\nexperiments reveal challenges related to generalization when solely relying on\nself-feedback during search. For search to work effectively, either access to\nthe ground-truth is needed or feedback mechanisms need to be carefully designed\nfor the specific task.",
    "pdf_url": "http://arxiv.org/pdf/2502.12094v1",
    "published": "2025-02-17T18:12:36+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12093v1",
    "title": "WeVibe: Weight Change Estimation Through Audio-Induced Shelf Vibrations In Autonomous Stores",
    "authors": [
      "Jiale Zhang",
      "Yuyan Wu",
      "Jesse R Codling",
      "Yen Cheng Chang",
      "Julia Gersey",
      "Pei Zhang",
      "Hae Young Noh",
      "Yiwen Dong"
    ],
    "abstract": "Weight change estimation is crucial in various applications, particularly for\ndetecting pick-up and put-back actions when people interact with the shelf\nwhile shopping in autonomous stores. Moreover, accurate weight change\nestimation allows autonomous stores to automatically identify items being\npicked up or put back, ensuring precise cost estimation. However, the\nconventional approach of estimating weight changes requires specialized\nweight-sensing shelves, which are densely deployed weight scales, incurring\nintensive sensor consumption and high costs. Prior works explored the\nvibration-based weight sensing method, but they failed when the location of\nweight change varies.\n  In response to these limitations, we made the following contributions: (1) We\npropose WeVibe, a first item weight change estimation system through active\nshelf vibration sensing. The main intuition of the system is that the weight\nplaced on the shelf influences the dynamic vibration response of the shelf,\nthus altering the shelf vibration patterns. (2) We model a physics-informed\nrelationship between the shelf vibration response and item weight across\nmultiple locations on the shelf based on structural dynamics theory. This\nrelationship is linear and allows easy training of a weight estimation model at\na new location without heavy data collection. (3) We evaluate our system on a\ngondola shelf organized as the real-store settings. WeVibe achieved a mean\nabsolute error down to 38.07g and a standard deviation of 31.2g with one sensor\nand 10% samples from three weight classes on estimating weight change from 0g\nto 450g, which can be leveraged for differentiating items with more than 100g\ndifferences.",
    "pdf_url": "http://arxiv.org/pdf/2502.12093v1",
    "published": "2025-02-17T18:10:53+00:00",
    "categories": [
      "eess.SP",
      "cs.SY",
      "eess.SY",
      "J.2; J.7"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12092v1",
    "title": "Using economic value signals from primate prefrontal cortex in neuro-engineering applications",
    "authors": [
      "Tevin C. Rouse",
      "Shira M. Lupkin",
      "Vincent B. McGinty"
    ],
    "abstract": "Neural signals related to movement can be measured from intracranial\nrecordings and used in brain-machine interface devices (BMI) to restore\nphysical function in impaired patients. In this study, we explore the use of\nmore abstract neural signals related to economic value in a BMI context. Using\ndata collected from the orbitofrontal cortex in non-human primates, we develop\ndeep learning-based neural decoders that can predict the monkey's choice in a\nvalue-based decision-making task. Out-of-sample performance was improved by\naugmenting the training set with synthesized data, showing the feasibility of\nusing limited training data. We further demonstrate that we can predict the\nmonkey's choice sooner using a neural forecasting module that is equipped with\ntask-related information. These findings support the feasibility of user\npreference-informed neuroengineering devices that leverage abstract cognitive\nsignals.",
    "pdf_url": "http://arxiv.org/pdf/2502.12092v1",
    "published": "2025-02-17T18:09:32+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12091v2",
    "title": "JADES: Nitrogen Enhancement in High-Redshift Broad-Line Active Galactic Nuclei",
    "authors": [
      "Yuki Isobe",
      "Roberto Maiolino",
      "Francesco D'Eugenio",
      "Mirko Curti",
      "Xihan Ji",
      "Ignas JuodÅ¾balis",
      "Jan Scholtz",
      "Anne Feltre",
      "StÃ©phane Charlot",
      "Hannah Ãbler",
      "Andrew J. Bunker",
      "Stefano Carniani",
      "Emma Curtis-Lake",
      "Zhiyuan Ji",
      "Nimisha Kumari",
      "Pierluigi Rinaldi",
      "Brant Robertson",
      "Chris Willott",
      "Joris Witstok"
    ],
    "abstract": "The unexpectedly high nitrogen-to-oxygen (N/O) ratios observed in\nhigh-redshift (z) galaxies have challenged our understanding of early star\nformation. Notably, many of these nitrogen-rich galaxies show signatures of\nactive galactic nuclei (AGNs), suggesting a possible connection between black\nhole formation and nitrogen enrichment. To explore this connection, we analyse\nstacked spectra of z=4-7 broad-line and narrow-line AGNs using deep NIRSpec\ndata from the JADES survey. We identify a significant Niii] quintuplet and a\nhigh electron density ($\\sim10^{4}\\,\\mathrm{cm^{-3}}$) only in the broad-line\nAGN stack, indicating nitrogen-rich ($\\log(\\mathrm{N/C})\\simeq0.5$,\n$\\log(\\mathrm{N/O})>-0.6$) and dense gas similar to the high-z nitrogen-rich\ngalaxies. Our findings suggest that dense nuclear star formation may trap\nnitrogen-rich gas in proto-globular clusters, in line with the high N/O\nobserved in local globular clusters; associated runaway stellar collisions\ncould produce intermediate-mass black hole seeds, as predicted by some models\nand simulations, whose accretion results into AGN signatures. These findings\nsupport scenarios connecting the early black hole seeding and growth to merging\nprocesses within and between proto-globular clusters in primeval galaxies.",
    "pdf_url": "http://arxiv.org/pdf/2502.12091v2",
    "published": "2025-02-17T18:09:22+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12090v2",
    "title": "On cyclotomic nearly-doubly-regular tournaments",
    "authors": [
      "Shohei Satake"
    ],
    "abstract": "Nearly-doubly-regular tournaments have played significant roles in extremal\ngraph theory. In this note, we construct new cyclotomic nearly-doubly-regular\ntournaments and determine their spectrum by establishing a new connection\nbetween cyclotomic nearly-doubly-regular tournaments and almost difference sets\nfrom combinatorial design theory. Furthermore, under the celebrated\nHardy-Littlewood conjecture F in analytic number theory, our results confirm\nthe conjecture due to Sergey Savchenko (J. Graph Theory {\\bf 83} (2016),\n44--77) on the existence of infinitely many nearly-doubly-regular tournaments\nwith the canonical spectrum.",
    "pdf_url": "http://arxiv.org/pdf/2502.12090v2",
    "published": "2025-02-17T18:06:53+00:00",
    "categories": [
      "math.CO",
      "05C20, 05C50"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12089v3",
    "title": "How Compositional Generalization and Creativity Improve as Diffusion Models are Trained",
    "authors": [
      "Alessandro Favero",
      "Antonio Sclocchi",
      "Francesco Cagnetta",
      "Pascal Frossard",
      "Matthieu Wyart"
    ],
    "abstract": "Natural data is often organized as a hierarchical composition of features.\nHow many samples do generative models need in order to learn the composition\nrules, so as to produce a combinatorially large number of novel data? What\nsignal in the data is exploited to learn those rules? We investigate these\nquestions in the context of diffusion models both theoretically and\nempirically. Theoretically, we consider a simple probabilistic context-free\ngrammar - a tree-like graphical model used to represent the hierarchical and\ncompositional structure of data such as language and images. We demonstrate\nthat diffusion models learn the grammar's composition rules with the sample\ncomplexity required for clustering features with statistically similar context,\na process similar to the word2vec algorithm. However, this clustering emerges\nhierarchically: higher-level features associated with longer contexts require\nmore data to be identified. This mechanism leads to a sample complexity that\nscales polynomially with the said context size. As a result, diffusion models\ntrained on an intermediate dataset size generate data coherent up to a certain\nscale, but lacking global coherence. We test these predictions across different\ndomains and find remarkable agreement: both generated texts and images achieve\nprogressively larger coherence lengths as the training time or dataset size\ngrows. We discuss connections between the hierarchical clustering mechanism we\nintroduce here and the renormalization group in physics.",
    "pdf_url": "http://arxiv.org/pdf/2502.12089v3",
    "published": "2025-02-17T18:06:33+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.12088v2",
    "title": "Meta-Statistical Learning: Supervised Learning of Statistical Inference",
    "authors": [
      "Maxime Peyrard",
      "Kyunghyun Cho"
    ],
    "abstract": "This work demonstrates that the tools and principles driving the success of\nlarge language models (LLMs) can be repurposed to tackle distribution-level\ntasks, where the goal is to predict properties of the data-generating\ndistribution rather than labels for individual datapoints. These tasks\nencompass statistical inference problems such as parameter estimation,\nhypothesis testing, or mutual information estimation. Framing these tasks\nwithin traditional machine learning pipelines is challenging, as supervision is\ntypically tied to individual datapoint. We propose meta-statistical learning, a\nframework inspired by multi-instance learning that reformulates statistical\ninference tasks as supervised learning problems. In this approach, entire\ndatasets are treated as single inputs to neural networks, which predict\ndistribution-level parameters. Transformer-based architectures, without\npositional encoding, provide a natural fit due to their permutation-invariance\nproperties. By training on large-scale synthetic datasets, meta-statistical\nmodels can leverage the scalability and optimization infrastructure of\nTransformer-based LLMs. We demonstrate the framework's versatility with\napplications in hypothesis testing and mutual information estimation, showing\nstrong performance, particularly for small datasets where traditional neural\nmethods struggle.",
    "pdf_url": "http://arxiv.org/pdf/2502.12088v2",
    "published": "2025-02-17T18:04:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12087v1",
    "title": "Semiclassical trace formula for the Bochner-SchrÃ¶dinger operator",
    "authors": [
      "Yuri A. Kordyukov"
    ],
    "abstract": "We study the semiclassical Bochner-Schr\\\"odinger operator\n$H_{p}=\\frac{1}{p^2}\\Delta^{L^p\\otimes E}+V$ on tensor powers $L^p$ of a\nHermitian line bundle $L$ twisted by a Hermitian vector bundle $E$ on a\nRiemannian manifold of bounded geometry. For any function $\\varphi\\in\nC^\\infty_c(\\mathbb R)$, we consider the bounded linear operator $\\varphi(H_p)$\nin $L^2(X,L^p\\otimes E)$ defined by the spectral theorem. We prove that its\nsmooth Schwartz kernel on the diagonal admits a complete asymptotic expansion\nin powers of $p^{-1}$ in the semiclassical limit $p\\to \\infty$. In particular,\nwhen the manifold is compact, we get a complete asymptotic expansion for the\ntrace of $\\varphi(H_p)$.",
    "pdf_url": "http://arxiv.org/pdf/2502.12087v1",
    "published": "2025-02-17T18:02:25+00:00",
    "categories": [
      "math.DG",
      "math-ph",
      "math.MP",
      "math.SP"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12086v3",
    "title": "Unifying Explainable Anomaly Detection and Root Cause Analysis in Dynamical Systems",
    "authors": [
      "Yue Sun",
      "Rick S. Blum",
      "Parv Venkitasubramaniam"
    ],
    "abstract": "Dynamical systems, prevalent in various scientific and engineering domains,\nare susceptible to anomalies that can significantly impact their performance\nand reliability. This paper addresses the critical challenges of anomaly\ndetection, root cause localization, and anomaly type classification in\ndynamical systems governed by ordinary differential equations (ODEs). We define\ntwo categories of anomalies: cyber anomalies, which propagate through\ninterconnected variables, and measurement anomalies, which remain localized to\nindividual variables. To address these challenges, we propose the Interpretable\nCausality Ordinary Differential Equation (ICODE) Networks, a model-intrinsic\nexplainable learning framework. ICODE leverages Neural ODEs for anomaly\ndetection while employing causality inference through an explanation channel to\nperform root cause analysis (RCA), elucidating why specific time periods are\nflagged as anomalous. ICODE is designed to simultaneously perform anomaly\ndetection, RCA, and anomaly type classification within a single, interpretable\nframework. Our approach is grounded in the hypothesis that anomalies alter the\nunderlying ODEs of the system, manifesting as changes in causal relationships\nbetween variables. We provide a theoretical analysis of how perturbations in\nlearned model parameters can be utilized to identify anomalies and their root\ncauses in time series data. Comprehensive experimental evaluations demonstrate\nthe efficacy of ICODE across various dynamical systems, showcasing its ability\nto accurately detect anomalies, classify their types, and pinpoint their\norigins.",
    "pdf_url": "http://arxiv.org/pdf/2502.12086v3",
    "published": "2025-02-17T18:01:07+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.13978v2",
    "title": "On the dynamical evolution of randomness Part A: Random experiments as dynamical systems",
    "authors": [
      "Allen Lobo",
      "Saravanan Arumugam"
    ],
    "abstract": "In this work, Bernoulli's Law of Large Numbers, also known as the Golden\ntheorem, has been extended to study the relations between empirical probability\nand empirical randomness of an otherwise random experiment. Using the example\nof a coin toss and a dice role, some interesting results are drawn.\nAnalytically and using numerical computations, empirical randomness of each\noutcome has been shown to increase by \\textit{ chance}, which itself depends on\nthe growth rate of empirical probabilities. The analyses presented in this\nwork, apart form depicting the nature of flow of random experiments in\nrepetitions, also present dynamical behaviours of the random experiment, and\nexperimental and simulation-based verifications of the mathematical analyses.\nIt also presents an appreciation of the beauty of Bernoulli's Golden theorem\nand its applications by extension.",
    "pdf_url": "http://arxiv.org/pdf/2502.13978v2",
    "published": "2025-02-17T18:00:06+00:00",
    "categories": [
      "physics.data-an",
      "math.PR"
    ],
    "primary_category": "physics.data-an"
  },
  {
    "id": "http://arxiv.org/abs/2502.12085v2",
    "title": "APB: Accelerating Distributed Long-Context Inference by Passing Compressed Context Blocks across GPUs",
    "authors": [
      "Yuxiang Huang",
      "Mingye Li",
      "Xu Han",
      "Chaojun Xiao",
      "Weilin Zhao",
      "Sun Ao",
      "Hao Zhou",
      "Jie Zhou",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "While long-context inference is crucial for advancing large language model\n(LLM) applications, its prefill speed remains a significant bottleneck. Current\napproaches, including sequence parallelism strategies and compute reduction\nthrough approximate attention mechanisms, still fall short of delivering\noptimal inference efficiency. This hinders scaling the inputs to longer\nsequences and processing long-context queries in a timely manner. To address\nthis, we introduce APB, an efficient long-context inference framework that\nleverages multi-host approximate attention to enhance prefill speed by reducing\ncompute and enhancing parallelism simultaneously. APB introduces a\ncommunication mechanism for essential key-value pairs within a sequence\nparallelism framework, enabling a faster inference speed while maintaining task\nperformance. We implement APB by incorporating a tailored FlashAttn kernel\nalongside optimized distribution strategies, supporting diverse models and\nparallelism configurations. APB achieves speedups of up to 9.2x, 4.2x, and 1.6x\ncompared with FlashAttn, RingAttn, and StarAttn, respectively, without any\nobservable task performance degradation. We provide the implementation and\nexperiment code of APB in https://github.com/thunlp/APB.",
    "pdf_url": "http://arxiv.org/pdf/2502.12085v2",
    "published": "2025-02-17T17:59:56+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12084v4",
    "title": "VLM2-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues",
    "authors": [
      "Jianshu Zhang",
      "Dongyu Yao",
      "Renjie Pi",
      "Paul Pu Liang",
      "Yi R. Fung"
    ],
    "abstract": "Visually linking matching cues is a crucial ability in daily life, such as\nidentifying the same person in multiple photos based on their cues, even\nwithout knowing who they are. Despite the extensive knowledge that\nvision-language models (VLMs) possess, it remains largely unexplored whether\nthey are capable of performing this fundamental task. To address this, we\nintroduce \\textbf{VLM2-Bench}, a benchmark designed to assess whether VLMs can\nVisually Link Matching cues, with 9 subtasks and over 3,000 test cases.\nComprehensive evaluation across twelve VLMs, along with further analysis of\nvarious language-side and vision-side prompting methods, leads to a total of\neight key findings. We identify critical challenges in models' ability to link\nvisual cues, highlighting a significant performance gap. Based on these\ninsights, we advocate for (i) enhancing core visual capabilities to improve\nadaptability and reduce reliance on prior knowledge, (ii) establishing clearer\nprinciples for integrating language-based reasoning in vision-centric tasks to\nprevent unnecessary biases, and (iii) shifting vision-text training paradigms\ntoward fostering models' ability to independently structure and infer\nrelationships among visual cues.",
    "pdf_url": "http://arxiv.org/pdf/2502.12084v4",
    "published": "2025-02-17T17:57:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12082v2",
    "title": "AdaSplash: Adaptive Sparse Flash Attention",
    "authors": [
      "Nuno GonÃ§alves",
      "Marcos Treviso",
      "AndrÃ© F. T. Martins"
    ],
    "abstract": "The computational cost of softmax-based attention in transformers limits\ntheir applicability to long-context tasks. Adaptive sparsity, of which\n$\\alpha$-entmax attention is an example, offers a flexible data-dependent\nalternative, but existing implementations are inefficient and do not leverage\nthe sparsity to obtain runtime and memory gains. In this work, we propose\nAdaSplash, which combines the efficiency of GPU-optimized algorithms with the\nsparsity benefits of $\\alpha$-entmax. We first introduce a hybrid\nHalley-bisection algorithm, resulting in a 7-fold reduction in the number of\niterations needed to compute the $\\alpha$-entmax transformation. Then, we\nimplement custom Triton kernels to efficiently handle adaptive sparsity.\nExperiments with RoBERTa and ModernBERT for text classification and\nsingle-vector retrieval, along with GPT-2 for language modeling, show that our\nmethod achieves substantial improvements in runtime and memory efficiency\ncompared to existing $\\alpha$-entmax implementations. It approaches -- and in\nsome cases surpasses -- the efficiency of highly optimized softmax\nimplementations like FlashAttention-2, enabling long-context training while\nmaintaining strong task performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.12082v2",
    "published": "2025-02-17T17:56:23+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12081v1",
    "title": "Unhackable Temporal Rewarding for Scalable Video MLLMs",
    "authors": [
      "En Yu",
      "Kangheng Lin",
      "Liang Zhao",
      "Yana Wei",
      "Zining Zhu",
      "Haoran Wei",
      "Jianjian Sun",
      "Zheng Ge",
      "Xiangyu Zhang",
      "Jingyu Wang",
      "Wenbing Tao"
    ],
    "abstract": "In the pursuit of superior video-processing MLLMs, we have encountered a\nperplexing paradox: the \"anti-scaling law\", where more data and larger models\nlead to worse performance. This study unmasks the culprit: \"temporal hacking\",\na phenomenon where models shortcut by fixating on select frames, missing the\nfull video narrative. In this work, we systematically establish a comprehensive\ntheory of temporal hacking, defining it from a reinforcement learning\nperspective, introducing the Temporal Perplexity (TPL) score to assess this\nmisalignment, and proposing the Unhackable Temporal Rewarding (UTR) framework\nto mitigate the temporal hacking. Both theoretically and empirically, TPL\nproves to be a reliable indicator of temporal modeling quality, correlating\nstrongly with frame activation patterns. Extensive experiments reveal that UTR\nnot only counters temporal hacking but significantly elevates video\ncomprehension capabilities. This work not only advances video-AI systems but\nalso illuminates the critical importance of aligning proxy rewards with true\nobjectives in MLLM development.",
    "pdf_url": "http://arxiv.org/pdf/2502.12081v1",
    "published": "2025-02-17T17:55:55+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12080v3",
    "title": "HumanGif: Single-View Human Diffusion with Generative Prior",
    "authors": [
      "Shoukang Hu",
      "Takuya Narihira",
      "Kazumi Fukuda",
      "Ryosuke Sawata",
      "Takashi Shibuya",
      "Yuki Mitsufuji"
    ],
    "abstract": "Previous 3D human creation methods have made significant progress in\nsynthesizing view-consistent and temporally aligned results from sparse-view\nimages or monocular videos. However, it remains challenging to produce\nperpetually realistic, view-consistent, and temporally coherent human avatars\nfrom a single image, as limited information is available in the single-view\ninput setting. Motivated by the success of 2D character animation, we propose\nHumanGif, a single-view human diffusion model with generative prior.\nSpecifically, we formulate the single-view-based 3D human novel view and pose\nsynthesis as a single-view-conditioned human diffusion process, utilizing\ngenerative priors from foundational diffusion models to complement the missing\ninformation. To ensure fine-grained and consistent novel view and pose\nsynthesis, we introduce a Human NeRF module in HumanGif to learn spatially\naligned features from the input image, implicitly capturing the relative camera\nand human pose transformation. Furthermore, we introduce an image-level loss\nduring optimization to bridge the gap between latent and image spaces in\ndiffusion models. Extensive experiments on RenderPeople, DNA-Rendering, THuman\n2.1, and TikTok datasets demonstrate that HumanGif achieves the best perceptual\nperformance, with better generalizability for novel view and pose synthesis.",
    "pdf_url": "http://arxiv.org/pdf/2502.12080v3",
    "published": "2025-02-17T17:55:27+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12079v1",
    "title": "Optimal control in combination therapy for heterogeneous cell populations with drug synergies",
    "authors": [
      "Simon F. Martina-Perez",
      "Samuel W. S. Johnson",
      "Rebecca M. Crossley",
      "Jennifer C. Kasemeier",
      "Paul M. Kulesa",
      "Ruth E. Baker"
    ],
    "abstract": "Cell heterogeneity plays an important role in patient responses to drug\ntreatments. In many cancers, it is associated with poor treatment outcomes.\nMany modern drug combination therapies aim to exploit cell heterogeneity, but\ndetermining how to optimise responses from heterogeneous cell populations while\naccounting for multi-drug synergies remains a challenge. In this work, we\nintroduce and analyse a general optimal control framework that can be used to\nmodel the treatment response of multiple cell populations that are treated with\nmultiple drugs that mutually interact. In this framework, we model the effect\nof multiple drugs on the cell populations using a system of coupled semi-linear\nordinary differential equations and derive general results for the optimal\nsolutions. We then apply this framework to three canonical examples and discuss\nthe wider question of how to relate mathematical optimality to clinically\nobservable outcomes, introducing a systematic approach to propose qualitatively\ndifferent classes of drug dosing inspired by optimal control.",
    "pdf_url": "http://arxiv.org/pdf/2502.12079v1",
    "published": "2025-02-17T17:54:02+00:00",
    "categories": [
      "q-bio.QM",
      "math.OC"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2502.12078v1",
    "title": "Using Infrared Dust Echoes to Identify Bright Quasi-periodic Eruption Sources",
    "authors": [
      "Dheeraj R. Pasham",
      "Eric Coughlin",
      "Sjoert van Velzen",
      "Jason Hinkle"
    ],
    "abstract": "Quasi-periodic eruptions (QPEs) are recurring soft X-ray outbursts from\ngalactic nuclei and represent an intriguing new class of transients. Currently,\n10 QPE sources are reported in the literature, and a major challenge lies in\nidentifying more because they are (apparently) intrinsically and exclusively\nX-ray bright. Here we highlight the unusual infrared (IR) echo of the tidal\ndisruption event (TDE) -- and subsequent QPE source -- AT2019qiz, which rose\ncontinuously and approximately linearly with time over roughly 1000 days\n(between 2019 and 2024). We argue that this continuous long rise alongside the\nrelatively high inferred IR temperature (800-1200 K) cannot be generated by the\nTDE itself, including the late-time/remnant TDE disk, but that the reprocessing\nof the light from the QPEs by a shell of dust can reproduce the observations.\nThis model predicts 1) IR QPEs at the 0.1 percent level that are potentially\ndetectable with the James Webb Space Telescope, and 2) that if the QPEs cease\nin AT2019qiz, the IR light curve should decline steadily and linearly over the\nsame 1000-day timescale. We identify another TDE with similar IR behavior,\nAT2020ysg, which could thus harbor QPEs. Our findings and inferences constitute\na novel method for identifying ``bright'' QPEs (with peak bolometric\nluminosities $\\gtrsim$10$^{44}$ erg/sec), i.e., that the follow-up of optically\nselected TDEs with wide-field infrared surveys can indirectly reveal the\npresence of QPEs. This approach could be particularly effective with the\nupcoming Roman telescope, which could detect dozens of QPE candidates for\nhigh-cadence X-ray follow-up.",
    "pdf_url": "http://arxiv.org/pdf/2502.12078v1",
    "published": "2025-02-17T17:53:37+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12077v1",
    "title": "Optimal recovery of correlated ErdÅs-RÃ©nyi graphs",
    "authors": [
      "Hang Du"
    ],
    "abstract": "For two unlabeled graphs $G_1,G_2$ independently sub-sampled from an\nErd\\H{o}s-R\\'enyi graph $\\mathbf G(n,p)$ by keeping each edge with probability\n$s$, we aim to recover \\emph{as many as possible} of the corresponding vertex\npairs. We establish a connection between the recoverability of vertex pairs and\nthe balanced load allocation in the true intersection graph of $ G_1 $ and $\nG_2 $. Using this connection, we analyze the partial recovery regime where $ p\n= n^{-\\alpha + o(1)} $ for some $ \\alpha \\in (0, 1] $ and $ nps^2 = \\lambda =\nO(1) $. We derive upper and lower bounds for the recoverable fraction in terms\nof $ \\alpha $ and the limiting load distribution $ \\mu_\\lambda $ (as introduced\nin \\cite{AS16}). These bounds coincide asymptotically whenever $ \\alpha^{-1} $\nis not an atom of $ \\mu_\\lambda $. Therefore, for each fixed $ \\lambda $, our\nresult characterizes the asymptotic optimal recovery fraction for all but\ncountably many $ \\alpha \\in (0, 1] $.",
    "pdf_url": "http://arxiv.org/pdf/2502.12077v1",
    "published": "2025-02-17T17:52:26+00:00",
    "categories": [
      "math.PR",
      "60C05"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12229v1",
    "title": "Analytic Versus Algebraic Density of Polynomials",
    "authors": [
      "Christian Berg",
      "Brian Simanek",
      "Richard Wellman"
    ],
    "abstract": "We show that under very mild conditions on a measure $\\mu$ on the interval\n$[0,\\infty)$, the span of $\\{x^k\\}_{k=n}^{\\infty}$ is dense in $L^2(\\mu)$ for\nany $n=0,1,\\ldots$. We present two different proofs of this result, one based\non the density index of Berg and Thill and one based on the Hilbert space\n$L^2(\\mu)\\oplus \\mathbb{C}^{n+1}$. Using the index of determinacy of Berg and\nDur\\'an we prove that if the measure $\\mu$ on $\\mathbb{R}$ has infinite index\nof determinacy then the polynomial ideal $R(x)\\mathbb{C}[x]$ is dense in\n$L^2(\\mu)$ for any polynomial $R$ with zeros having no mass under $\\mu$.",
    "pdf_url": "http://arxiv.org/pdf/2502.12229v1",
    "published": "2025-02-17T17:50:02+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12076v1",
    "title": "The uncollapsed LaFe2As2 phase: compensated, highly doped, electron-phonon coupled, iron-based superconductor",
    "authors": [
      "Ilaria Pallecchi",
      "Akira Iyo",
      "Hiraku Ogino",
      "Marco Affronte",
      "Marina Putti"
    ],
    "abstract": "The recently discovered LaFe2As2 superconducting compound, member of the 122\nfamily of iron pnictide superconductors, becomes superconducting below Tc=13K,\nyet its nominal doping apparently places it in the extreme overdoped limit,\nwhere superconductivity should be suppressed. In this work, we investigate the\nnormal state of magneto- and thermo-electric transport and specific heat of\nthis compound. The experimental data are consistent with the presence of highly\ncompensated electron and hole bands, with around 0.42 electrons per unit cell\njust above Tc, and high effective masses around 3m0. The temperature dependence\nof transport properties strongly resembles that of conventional\nsuperconductors, pointing to a key role of electron-phonon coupling. From these\nevidences, LaFe2As2 can be regarded as the connecting compound between\nunconventional and conventional superconductors.",
    "pdf_url": "http://arxiv.org/pdf/2502.12076v1",
    "published": "2025-02-17T17:48:37+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2502.12075v2",
    "title": "A counterexample to the Jordan-HÃ¶lder property for polarizable semiorthogonal decompositions",
    "authors": [
      "Fabian Haiden",
      "Dongjian Wu"
    ],
    "abstract": "We show that the Jordan-H\\\"older property fails for polarizable\nsemiorthogonal decompositions -- those where every factor admits a Bridgeland\nstability condition. Counterexamples exist among Fukaya categories of surfaces\nand bounded derived categories of smooth projective varieties. Furthermore, we\ngive an example of a smooth and proper pre-triangulated dg category with\npositive rank Grothendieck group which does not admit a stability condition.",
    "pdf_url": "http://arxiv.org/pdf/2502.12075v2",
    "published": "2025-02-17T17:46:10+00:00",
    "categories": [
      "math.RT",
      "math.AG"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12074v2",
    "title": "Lattice QCD Study of Pion Electroproduction and Weak Production from a Nucleon",
    "authors": [
      "Yu-Sheng Gao",
      "Zhao-Long Zhang",
      "Xu Feng",
      "Lu-Chang Jin",
      "Chuan Liu",
      "Ulf-G. MeiÃner"
    ],
    "abstract": "Quantum fluctuations in QCD influence nucleon structure and interactions,\nwith pion production serving as a key probe of chiral dynamics. In this study,\nwe present a lattice QCD calculation of multipole amplitudes at threshold,\nrelated to both pion electroproduction and weak production from a nucleon,\nusing two gauge ensembles near the physical pion mass. We develop a technique\nfor spin projection and construct multiple operators for analyzing the\ngeneralized eigenvalue problem in both the nucleon-pion system in the\ncenter-of-mass frame and the nucleon system with nonzero momentum. The\nnumerical lattice results are then compared with those extracted from\nexperimental data and predicted by low-energy theorems incorporating one-loop\ncorrections.",
    "pdf_url": "http://arxiv.org/pdf/2502.12074v2",
    "published": "2025-02-17T17:45:07+00:00",
    "categories": [
      "hep-lat",
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2502.12073v1",
    "title": "Can LLMs Simulate Social Media Engagement? A Study on Action-Guided Response Generation",
    "authors": [
      "Zhongyi Qiu",
      "Hanjia Lyu",
      "Wei Xiong",
      "Jiebo Luo"
    ],
    "abstract": "Social media enables dynamic user engagement with trending topics, and recent\nresearch has explored the potential of large language models (LLMs) for\nresponse generation. While some studies investigate LLMs as agents for\nsimulating user behavior on social media, their focus remains on practical\nviability and scalability rather than a deeper understanding of how well LLM\naligns with human behavior. This paper analyzes LLMs' ability to simulate\nsocial media engagement through action guided response generation, where a\nmodel first predicts a user's most likely engagement action-retweet, quote, or\nrewrite-towards a trending post before generating a personalized response\nconditioned on the predicted action. We benchmark GPT-4o-mini, O1-mini, and\nDeepSeek-R1 in social media engagement simulation regarding a major societal\nevent discussed on X. Our findings reveal that zero-shot LLMs underperform BERT\nin action prediction, while few-shot prompting initially degrades the\nprediction accuracy of LLMs with limited examples. However, in response\ngeneration, few-shot LLMs achieve stronger semantic alignment with ground truth\nposts.",
    "pdf_url": "http://arxiv.org/pdf/2502.12073v1",
    "published": "2025-02-17T17:43:08+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12072v1",
    "title": "General relativistic quasi-spherical accretion in a dark matter halo",
    "authors": [
      "Razieh Ranjbar",
      "HÃ©ctor R. Olivares-SÃ¡nchez"
    ],
    "abstract": "Context. The Bondi spherical accretion solution has been used to model\naccretion onto compact objects in a variety of situations, from interpretation\nof observations to subgrid models in cosmological simulations. Aims. We aim to\ninvestigate how the presence of dark matter (DM) alters the dynamics and\nphysical properties of accretion onto supermassive black holes on scales\nranging from ~ 10 pc to the event horizon. Methods. In particular, we\ninvestigate Bondi-like accretion flows with zero and low specific angular\nmomentum around supermassive black holes surrounded by dark-matter halos by\nperforming 1D and 2.5D general relativistic hydrodynamics (GRHD) simulations\nusing the black hole accretion code (BHAC). Results. We find notable\ndifferences in the dynamics and structure of spherical accretion flows in the\npresence of DM. The most significant effects include increases in density,\ntemperature, and pressure, as well as variations in radial velocity both inside\nand outside the regions containing DM or even the production of outflow.\nConclusions. This investigation provides valuable insights into the role of\ncosmological effects, particularly DM, in shaping the behavior of accretion\nflows and black holes (BHs). Our simulations may be directly applicable to\nmodel systems with a large black hole-to-halo mass ratio, which are expected to\nbe found at very high redshifts.",
    "pdf_url": "http://arxiv.org/pdf/2502.12072v1",
    "published": "2025-02-17T17:40:29+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12071v1",
    "title": "Translation Mappings of Quasimonotonicity Beyond Smoothness",
    "authors": [
      "Oday Hazaimah"
    ],
    "abstract": "Monotonicity of a mapping implies its pseudomonotonicity and hence\nquasimonotonocity, the converse is not true. In this note we intend to study\nthe situations under which quasimono tonicity of a mapping implies its\nmonotonicity. Thus we generalize some results in the literature related to the\nconnection between monotonocity and its generalized classes for multi-valued\nmappings via translation maps in real topological spaces. No differentiability\nassumption is required but continuity assumption is imposed.",
    "pdf_url": "http://arxiv.org/pdf/2502.12071v1",
    "published": "2025-02-17T17:40:18+00:00",
    "categories": [
      "math.OC",
      "math.FA"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12070v2",
    "title": "KM3NeT Constraint on Lorentz-Violating Superluminal Neutrino Velocity",
    "authors": [
      "KM3NeT Collaboration",
      "O. Adriani",
      "S. Aiello",
      "A. Albert",
      "A. R. Alhebsi",
      "M. Alshamsi",
      "S. Alves Garre",
      "A. Ambrosone",
      "F. Ameli",
      "M. Andre",
      "L. Aphecetche",
      "M. Ardid",
      "S. Ardid",
      "C. ArgÃ¼elles",
      "J. Aublin",
      "F. Badaracco",
      "L. Bailly-Salins",
      "Z. BardaÄovÃ¡",
      "A. Bariego-Quintana",
      "Y. Becherini",
      "M. Bendahman",
      "F. Benfenati Gualandi",
      "M. Benhassi",
      "M. Bennani",
      "D. M. Benoit",
      "E. Berbee",
      "E. Berti",
      "V. Bertin",
      "P. Betti",
      "S. Biagi",
      "M. Boettcher",
      "D. Bonanno",
      "S. Bottai",
      "A. B. Bouasla",
      "J. Boumaaza",
      "M. Bouta",
      "M. Bouwhuis",
      "C. Bozza",
      "R. M. Bozza",
      "H. BrÃ¢nzaÅ",
      "F. Bretaudeau",
      "M. Breuhaus",
      "R. Bruijn",
      "J. Brunner",
      "R. Bruno",
      "E. Buis",
      "R. Buompane",
      "J. Busto",
      "B. Caiffi",
      "D. Calvo",
      "A. Capone",
      "F. Carenini",
      "V. Carretero",
      "T. Cartraud",
      "P. Castaldi",
      "V. Cecchini",
      "S. Celli",
      "L. Cerisy",
      "M. Chabab",
      "A. Chen",
      "S. Cherubini",
      "T. Chiarusi",
      "M. Circella",
      "R. Clark",
      "R. Cocimano",
      "J. A. B. Coelho",
      "A. Coleiro",
      "A. Condorelli",
      "R. Coniglione",
      "P. Coyle",
      "A. Creusot",
      "G. Cuttone",
      "R. Dallier",
      "A. De Benedittis",
      "G. De Wasseige",
      "V. Decoene",
      "P. Deguire",
      "I. Del Rosso",
      "L. S. Di Mauro",
      "I. Di Palma",
      "A. F. DÃ­az",
      "D. Diego-Tortosa",
      "C. Distefano",
      "A. Domi",
      "C. Donzaud",
      "D. Dornic",
      "E. Drakopoulou",
      "D. Drouhin",
      "J. -G. Ducoin",
      "P. Duverne",
      "R. DvornickÃ½",
      "T. Eberl",
      "E. EckerovÃ¡",
      "A. Eddymaoui",
      "T. van Eeden",
      "M. Eff",
      "D. van Eijk",
      "I. El Bojaddaini",
      "S. El Hedri",
      "S. El Mentawi",
      "V. Ellajosyula",
      "A. EnzenhÃ¶fer",
      "G. Ferrara",
      "M. D. FilipoviÄ",
      "F. Filippini",
      "D. Franciotti",
      "L. A. Fusco",
      "S. Gagliardini",
      "T. Gal",
      "J. GarcÃ­a MÃ©ndez",
      "A. Garcia Soto",
      "C. Gatius Oliver",
      "N. GeiÃelbrecht",
      "E. Genton",
      "H. Ghaddari",
      "L. Gialanella",
      "B. K. Gibson",
      "E. Giorgio",
      "I. Goos",
      "P. Goswami",
      "S. R. Gozzini",
      "R. Gracia",
      "C. Guidi",
      "B. Guillon",
      "M. GutiÃ©rrez",
      "C. Haack",
      "H. van Haren",
      "A. Heijboer",
      "L. Hennig",
      "J. J. HernÃ¡ndez-Rey",
      "A. Idrissi",
      "W. Idrissi Ibnsalih",
      "G. Illuminati",
      "O. Janik",
      "D. Joly",
      "M. de Jong",
      "P. de Jong",
      "B. J. Jung",
      "P. KalaczyÅski",
      "N. Kamp",
      "J. Keegans",
      "V. Kikvadze",
      "G. Kistauri",
      "C. Kopper",
      "A. Kouchner",
      "Y. Y. Kovalev",
      "L. Krupa",
      "V. Kueviakoe",
      "V. Kulikovskiy",
      "R. Kvatadze",
      "M. Labalme",
      "R. Lahmann",
      "M. Lamoureux",
      "G. Larosa",
      "C. Lastoria",
      "J. Lazar",
      "A. Lazo",
      "S. Le Stum",
      "G. Lehaut",
      "V. LemaÃ®tre",
      "E. Leonora",
      "N. Lessing",
      "G. Levi",
      "M. Lindsey Clark",
      "F. Longhitano",
      "F. Magnani",
      "J. Majumdar",
      "L. Malerba",
      "F. Mamedov",
      "A. Manfreda",
      "A. Manousakis",
      "M. Marconi",
      "A. Margiotta",
      "A. Marinelli",
      "C. Markou",
      "L. Martin",
      "M. Mastrodicasa",
      "S. Mastroianni",
      "J. Mauro",
      "K. C. K. Mehta",
      "A. Meskar",
      "G. Miele",
      "P. Migliozzi",
      "E. Migneco",
      "M. L. Mitsou",
      "C. M. Mollo",
      "L. Morales-Gallegos",
      "N. Mori",
      "A. Moussa",
      "I. Mozun Mateo",
      "R. Muller",
      "M. R. Musone",
      "M. Musumeci",
      "S. Navas",
      "A. Nayerhoda",
      "C. A. Nicolau",
      "B. Nkosi",
      "B. Ã Fearraigh",
      "V. Oliviero",
      "A. Orlando",
      "E. Oukacha",
      "L. Pacini",
      "D. Paesani",
      "J. Palacios GonzÃ¡lez",
      "G. Papalashvili",
      "P. Papini",
      "V. Parisi",
      "A. Parmar",
      "E. J. Pastor Gomez",
      "C. Pastore",
      "A. M. PÄun",
      "G. E. PÄvÄlaÅ",
      "S. PeÃ±a MartÃ­nez",
      "M. Perrin-Terrin",
      "V. Pestel",
      "R. Pestes",
      "M. Petropavlova",
      "P. Piattelli",
      "A. Plavin",
      "C. PoirÃ¨",
      "V. Popa",
      "T. Pradier",
      "J. Prado",
      "S. Pulvirenti",
      "C. A. Quiroz-Rangel",
      "N. Randazzo",
      "A. Ratnani",
      "S. Razzaque",
      "I. C. Rea",
      "D. Real",
      "G. Riccobene",
      "J. Robinson",
      "A. Romanov",
      "E. Ros",
      "A. Å aina",
      "F. Salesa Greus",
      "D. F. E. Samtleben",
      "A. SÃ¡nchez Losa",
      "S. Sanfilippo",
      "M. Sanguineti",
      "D. Santonocito",
      "P. Sapienza",
      "M. Scaringella",
      "M. Scarnera",
      "J. Schnabel",
      "J. Schumann",
      "H. M. Schutte",
      "J. Seneca",
      "N. Sennan",
      "P. A. Sevle Myhr",
      "I. Sgura",
      "R. Shanidze",
      "A. Sharma",
      "Y. Shitov",
      "F. Å imkovic",
      "A. Simonelli",
      "A. Sinopoulou",
      "B. Spisso",
      "M. Spurio",
      "O. Starodubtsev",
      "D. Stavropoulos",
      "I. Å tekl",
      "D. Stocco",
      "M. Taiuti",
      "G. Takadze",
      "Y. Tayalati",
      "H. Thiersen",
      "S. Thoudam",
      "I. Tosta e Melo",
      "B. TrocmÃ©",
      "V. Tsourapis",
      "E. Tzamariudaki",
      "A. Ukleja",
      "A. Vacheret",
      "V. Valsecchi",
      "V. Van Elewyck",
      "G. Vannoye",
      "E. Vannuccini",
      "G. Vasileiadis",
      "F. Vazquez de Sola",
      "A. Veutro",
      "S. Viola",
      "D. Vivolo",
      "A. van Vliet",
      "A. Y. Wen",
      "E. de Wolf",
      "I. Lhenry-Yvon",
      "S. Zavatarelli",
      "A. Zegarelli",
      "D. Zito",
      "J. D. Zornoza",
      "J. ZÃºÃ±iga",
      "N. Zywucka"
    ],
    "abstract": "Lorentz invariance is a fundamental symmetry of spacetime and foundational to\nmodern physics. One of its most important consequences is the constancy of the\nspeed of light. This invariance, together with the geometry of spacetime,\nimplies that no particle can move faster than the speed of light. In this\narticle, we present the most stringent neutrino-based test of this prediction,\nusing the highest energy neutrino ever detected to date, KM3-230213A. The\narrival of this event, with an energy of $220^{+570}_{-110}\\,\\text{PeV}$, sets\na constraint on $\\delta \\equiv c_\\nu^2-1 < 4\\times10^{-22}$.",
    "pdf_url": "http://arxiv.org/pdf/2502.12070v2",
    "published": "2025-02-17T17:39:42+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12069v1",
    "title": "Distributed Consensus Network: A Modularized Communication Framework and Reliability Probabilistic Analysis",
    "authors": [
      "Yuetai Li",
      "Zhangchen Xu",
      "Yiqi Wang",
      "Zihan Zhou",
      "Lei Zhang",
      "Jon Crowcroft"
    ],
    "abstract": "In this paper, we propose a modularized framework for communication processes\napplicable to crash and Byzantine fault-tolerant consensus protocols. We\nabstract basic communication components and show that the communication process\nof the classic consensus protocols such as RAFT, single-decree Paxos, PBFT, and\nHotstuff, can be represented by the combination of communication components.\nBased on the proposed framework, we develop an approach to analyze the\nconsensus reliability of different protocols, where link loss and node failure\nare measured as a probability. We propose two latency optimization methods and\nimplement a RAFT system to verify our theoretical analysis and the\neffectiveness of the proposed latency optimization methods. We also discuss\ndecreasing consensus failure rate by adjusting protocol designs. This paper\nprovides theoretical guidance for the design of future consensus systems with a\nlow consensus failure rate and latency under the possible communication loss.",
    "pdf_url": "http://arxiv.org/pdf/2502.12069v1",
    "published": "2025-02-17T17:38:46+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12068v3",
    "title": "Fractional Sobolev paths on Wasserstein spaces and their energy-minimizing particle representations",
    "authors": [
      "Ehsan Abedi"
    ],
    "abstract": "We study a generalization of Kantorovich's optimal transportation problem.\nGiven a prescribed family of time-dependent probability measures $(\\mu_t)$, we\naim to find, among all path-continuous stochastic processes whose\none-dimensional time marginals coincide with $(\\mu_t)$ (if there is any), a\nprocess that minimizes a given energy. After discussing a sufficient condition\nfor the energy to ensure the existence of a minimizer, we investigate\nfractional Sobolev energies. Given a deterministic path $(\\mu_t)$ on a\n$p$-Wasserstein space with fractional Sobolev regularity $W^{\\alpha,p}$, where\n$1/p < \\alpha < 1$, we provide conditions under which we prove the existence of\na process that minimizes the energy and construct a process that realizes the\nregularity of $(\\mu_t)$. While continuous paths of low regularity on\nWasserstein spaces naturally appear in stochastic analysis, they can also arise\ndeterministically as solutions to the continuity equation. This paper is\ndevoted to the deterministic setting to gain some understanding of the required\nconditions.",
    "pdf_url": "http://arxiv.org/pdf/2502.12068v3",
    "published": "2025-02-17T17:38:15+00:00",
    "categories": [
      "math.MG",
      "math.OC",
      "math.PR",
      "30H25, 49Q22, 60G07"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12067v2",
    "title": "TokenSkip: Controllable Chain-of-Thought Compression in LLMs",
    "authors": [
      "Heming Xia",
      "Chak Tou Leong",
      "Wenjie Wang",
      "Yongqi Li",
      "Wenjie Li"
    ],
    "abstract": "Chain-of-Thought (CoT) has been proven effective in enhancing the reasoning\ncapabilities of large language models (LLMs). Recent advancements, such as\nOpenAI's o1 and DeepSeek-R1, suggest that scaling up the length of CoT\nsequences during inference could further boost LLM reasoning performance.\nHowever, due to the autoregressive nature of LLM decoding, longer CoT outputs\nlead to a linear increase in inference latency, adversely affecting user\nexperience, particularly when the CoT exceeds 10,000 tokens. To address this\nlimitation, we analyze the semantic importance of tokens within CoT outputs and\nreveal that their contributions to reasoning vary. Building on this insight, we\npropose TokenSkip, a simple yet effective approach that enables LLMs to\nselectively skip less important tokens, allowing for controllable CoT\ncompression. Extensive experiments across various models and tasks demonstrate\nthe effectiveness of TokenSkip in reducing CoT token usage while preserving\nstrong reasoning performance. Notably, when applied to Qwen2.5-14B-Instruct,\nTokenSkip reduces reasoning tokens by 40% (from 313 to 181) on GSM8K, with less\nthan a 0.4% performance drop.",
    "pdf_url": "http://arxiv.org/pdf/2502.12067v2",
    "published": "2025-02-17T17:37:26+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12066v1",
    "title": "CONSTRUCTA: Automating Commercial Construction Schedules in Fabrication Facilities with Large Language Models",
    "authors": [
      "Yifan Zhang",
      "Xue Yang"
    ],
    "abstract": "Automating planning with LLMs presents transformative opportunities for\ntraditional industries, yet remains underexplored. In commercial construction,\nthe complexity of automated scheduling often requires manual intervention to\nensure precision. We propose CONSTRUCTA, a novel framework leveraging LLMs to\noptimize construction schedules in complex projects like semiconductor\nfabrication. CONSTRUCTA addresses key challenges by: (1) integrating\nconstruction-specific knowledge through static RAG; (2) employing\ncontext-sampling techniques inspired by architectural expertise to provide\nrelevant input; and (3) deploying Construction DPO to align schedules with\nexpert preferences using RLHF. Experiments on proprietary data demonstrate\nperformance improvements of +42.3% in missing value prediction, +79.1% in\ndependency analysis, and +28.9% in automated planning compared to baseline\nmethods, showcasing its potential to revolutionize construction workflows and\ninspire domain-specific LLM advancements.",
    "pdf_url": "http://arxiv.org/pdf/2502.12066v1",
    "published": "2025-02-17T17:35:42+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12065v3",
    "title": "Autoformalization in the Wild: Assessing LLMs on Real-World Mathematical Definitions",
    "authors": [
      "Lan Zhang",
      "Marco Valentino",
      "Andre Freitas"
    ],
    "abstract": "Thanks to their linguistic capabilities, LLMs offer an opportunity to bridge\nthe gap between informal mathematics and formal languages through\nautoformalization. However, it is still unclear how well LLMs generalize to\nsophisticated and naturally occurring mathematical statements. To address this\ngap, we investigate the task of autoformalizing real-world mathematical\ndefinitions: a critical component of mathematical discourse. Specifically, we\nintroduce two novel resources for autoformalization, collecting definitions\nfrom Wikipedia (Def_Wiki) and arXiv papers (Def_ArXiv). We then systematically\nevaluate a range of LLMs, analyzing their ability to formalize definitions into\nIsabelle/HOL. Furthermore, we investigate strategies to enhance LLMs'\nperformance including refinement through external feedback from Proof\nAssistants, and formal definition grounding, where we augment LLMs'\nformalizations through relevant contextual elements from formal mathematical\nlibraries. Our findings reveal that definitions present a greater challenge\ncompared to existing benchmarks, such as miniF2F. In particular, we found that\nLLMs still struggle with self-correction, and aligning with relevant\nmathematical libraries. At the same time, structured refinement methods and\ndefinition grounding strategies yield notable improvements of up to 16% on\nself-correction capabilities and 43% on the reduction of undefined errors,\nhighlighting promising directions for enhancing LLM-based autoformalization in\nreal-world scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.12065v3",
    "published": "2025-02-17T17:34:48+00:00",
    "categories": [
      "cs.CL",
      "cs.FL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12064v1",
    "title": "AI-generated Text Detection with a GLTR-based Approach",
    "authors": [
      "LucÃ­a Yan Wu",
      "Isabel Segura-Bedmar"
    ],
    "abstract": "The rise of LLMs (Large Language Models) has contributed to the improved\nperformance and development of cutting-edge NLP applications. However, these\ncan also pose risks when used maliciously, such as spreading fake news, harmful\ncontent, impersonating individuals, or facilitating school plagiarism, among\nothers. This is because LLMs can generate high-quality texts, which are\nchallenging to differentiate from those written by humans. GLTR, which stands\nfor Giant Language Model Test Room and was developed jointly by the MIT-IBM\nWatson AI Lab and HarvardNLP, is a visual tool designed to help detect\nmachine-generated texts based on GPT-2, that highlights the words in text\ndepending on the probability that they were machine-generated. One limitation\nof GLTR is that the results it returns can sometimes be ambiguous and lead to\nconfusion. This study aims to explore various ways to improve GLTR's\neffectiveness for detecting AI-generated texts within the context of the\nIberLef-AuTexTification 2023 shared task, in both English and Spanish\nlanguages. Experiment results show that our GLTR-based GPT-2 model overcomes\nthe state-of-the-art models on the English dataset with a macro F1-score of\n80.19%, except for the first ranking model (80.91%). However, for the Spanish\ndataset, we obtained a macro F1-score of 66.20%, which differs by 4.57%\ncompared to the top-performing model.",
    "pdf_url": "http://arxiv.org/pdf/2502.12064v1",
    "published": "2025-02-17T17:32:55+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12063v7",
    "title": "Low-Rank Thinning",
    "authors": [
      "Annabelle Michael Carrell",
      "Albert Gong",
      "Abhishek Shetty",
      "Raaz Dwivedi",
      "Lester Mackey"
    ],
    "abstract": "The goal in thinning is to summarize a dataset using a small set of\nrepresentative points. Remarkably, sub-Gaussian thinning algorithms like Kernel\nHalving and Compress can match the quality of uniform subsampling while\nsubstantially reducing the number of summary points. However, existing\nguarantees cover only a restricted range of distributions and kernel-based\nquality measures and suffer from pessimistic dimension dependence. To address\nthese deficiencies, we introduce a new low-rank analysis of sub-Gaussian\nthinning that applies to any distribution and any kernel, guaranteeing\nhigh-quality compression whenever the kernel or data matrix is approximately\nlow-rank. To demonstrate the broad applicability of the techniques, we design\npractical sub-Gaussian thinning approaches that improve upon the best known\nguarantees for approximating attention in transformers, accelerating stochastic\ngradient training through reordering, and distinguishing distributions in\nnear-linear time.",
    "pdf_url": "http://arxiv.org/pdf/2502.12063v7",
    "published": "2025-02-17T17:30:14+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.12062v1",
    "title": "Mapping and Execution of Nested Loops on Processor Arrays: CGRAs vs. TCPAs",
    "authors": [
      "Dominik Walter",
      "Marita Halm",
      "Daniel Seidel",
      "Indrayudh Ghosh",
      "Christian Heidorn",
      "Frank Hannig",
      "JÃ¼rgen Teich"
    ],
    "abstract": "Increasing demands for computing power also propel the need for\nenergy-efficient SoC accelerator architectures. One class of such accelerators\nare so-called processor arrays, which typically integrate a two-dimensional\nmesh of interconnected processing elements~(PEs). Such arrays are specifically\ndesigned to accelerate the execution of multidimensional nested loops by\nexploiting the intrinsic parallelism of loops. Moreover, for mapping a given\nloop nest application, two opposed mapping methods have emerged:\nOperation-centric and iteration-centric. Both differ in the granularity of the\nmapping. The operation-centric approach maps individual operations to the PEs\nof the array, while the iteration-centric approach maps entire tiles of\niterations to each PE. The operation-centric approach is applied predominantly\nfor processor arrays often referred to as Coarse-Grained Reconfigurable\nArrays~(CGRAs), while processor arrays supporting an iteration-centric approach\nare referred to as Tightly-Coupled Processor Arrays~(TCPAs) in the following.\nThis work provides a comprehensive comparison of both approaches and related\narchitectures by evaluating their respective benefits and trade-offs. ...",
    "pdf_url": "http://arxiv.org/pdf/2502.12062v1",
    "published": "2025-02-17T17:29:42+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12061v2",
    "title": "Sullivan process near threshold and the pion gravitational form factors",
    "authors": [
      "Yoshitaka Hatta",
      "Jakob Schoenleber"
    ],
    "abstract": "We propose a novel method to experimentally access the gravitational form\nfactors (GFFs) of the charged pion $\\pi^+$ through the Sullivan process in\nelectron-proton scattering. We demonstrate that the cross sections of\n$J/\\psi$-photoproduction and $\\phi$-electroproduction near the respective\nthresholds are dominated by the gluon GFF of the pion to next-to-leading order\nin perturbative QCD. We predict cross sections for the Electron-Ion Collider\nand the Jefferson Lab experiments.",
    "pdf_url": "http://arxiv.org/pdf/2502.12061v2",
    "published": "2025-02-17T17:28:40+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "nucl-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12060v1",
    "title": "Irreversible multi-band effects and Lifshitz transitions at the LaAlO3/SrTiO3 interface under field effect",
    "authors": [
      "Ilaria Pallecchi",
      "Nicolo' Lorenzini",
      "Mian Akif Safeen",
      "Musa Mutlu Can",
      "Emiliano Di Gennaro",
      "Fabio Miletto Granozio",
      "Daniele Marre'"
    ],
    "abstract": "In this work, we investigate the irreversible effects of an applied electric\nfield on the magnetotransport properties of LaAlO3/SrTiO3 conducting\ninterfaces, with focus on their multiband character. We study samples of\ndifferent types, namely with either crystalline or amorphous LaAlO3 overlayer.\nOur two-band analysis highlights the similarity of the electronic properties of\ncrystalline and amorphous interfaces, regardless much different carrier\ndensities and mobilities. Furthermore, filling and depletion of the two bands\nfollow very similar patterns, at least in qualitative terms, in the two types\nof samples. In agreement with previous works on crystalline interfaces, we\nobserve that an irreversible charge depletion takes place after application of\na first positive back gate voltage step. Such charge depletion affects much\nmore, in relative terms, the higher and three-dimensional dyz, dzx bands than\nthe lower and bidimensional dxy, driving the system through the Lifshitz\ntransition from two-band to single band behavior. The quantitative analysis of\nexperimental data evidences the roles of disorder, apparent in the depletion\nregime, and temperature. Noteworthy, filling and depletion of the two bands\nfollow very similar patterns in crystalline and amorphous samples, at least in\nqualitative terms, regardless much different carrier densities and mobilities.",
    "pdf_url": "http://arxiv.org/pdf/2502.12060v1",
    "published": "2025-02-17T17:28:26+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.12059v1",
    "title": "Examples of $p$-harmonic maps",
    "authors": [
      "Anna Balci",
      "Linus Behn",
      "Lars Diening",
      "Johannes Storn"
    ],
    "abstract": "We construct explicit examples of $p$-harmonic maps $u:\\mathbb{R}^n \\to\n\\mathbb{R}^N$. These are more irregular than the previously known examples and\nthus provide new upper bounds for the regularity of $p$-harmonic maps,\nincluding the case of $\\infty$-harmonic maps. To optimize our approach, we\nutilize solutions of the Hurwitz problem from algebra.",
    "pdf_url": "http://arxiv.org/pdf/2502.12059v1",
    "published": "2025-02-17T17:28:24+00:00",
    "categories": [
      "math.AP",
      "35J60, 35B65, 11E39, 11E25, 35J92, 35J94, 35J47"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12228v2",
    "title": "On the nonexistence of a Green functor with values spin$^c$ bordism and spin bordism",
    "authors": [
      "Hassan H. Abdallah",
      "Zachary Halladay",
      "Yigal Kamel"
    ],
    "abstract": "In this note, we show that there does not exist a $C_2$-ring spectrum whose\nunderlying ring spectrum is $\\mathrm{MSpin}^c$ and whose $C_2$-fixed point\nspectrum is $\\mathrm{MSpin}$.",
    "pdf_url": "http://arxiv.org/pdf/2502.12228v2",
    "published": "2025-02-17T17:27:21+00:00",
    "categories": [
      "math.AT"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12058v1",
    "title": "A survey about perceptions of mobility to inform an agent-based simulator of subjective modal choice",
    "authors": [
      "Carole Adam",
      "Benoit Gaudou"
    ],
    "abstract": "In order to adapt to the issues of climate change and public health, urban\npolicies are trying to encourage soft mobility, but the share of the car\nremains significant. Beyond known constraints, we study here the impact of\nperception biases on individual choices. We designed a multi-criteria decision\nmodel, integrating the influence of habits and biases. We then conducted an\nonline survey, which received 650 responses. We used these to calculate\nrealistic mobility perception values, in order to initialise the environment\nand the population of a modal choice simulator, implemented in Netlogo. This\nallows us to visualize the adaptation of the modal distribution in reaction to\nthe evolution of urban planning, depending on whether or not we activate biases\nand habits in individual reasoning.\n  This is an extended and translated version of a demo paper published in\nFrench at JFSMA-JFMS 2024 \"Un simulateur multi-agent de choix modal subjectif\"",
    "pdf_url": "http://arxiv.org/pdf/2502.12058v1",
    "published": "2025-02-17T17:25:18+00:00",
    "categories": [
      "cs.MA",
      "cs.CY"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12057v2",
    "title": "Culture is Not Trivia: Sociocultural Theory for Cultural NLP",
    "authors": [
      "Naitian Zhou",
      "David Bamman",
      "Isaac L. Bleaman"
    ],
    "abstract": "The field of cultural NLP has recently experienced rapid growth, driven by a\npressing need to ensure that language technologies are effective and safe\nacross a pluralistic user base. This work has largely progressed without a\nshared conception of culture, instead choosing to rely on a wide array of\ncultural proxies. However, this leads to a number of recurring limitations:\ncoarse national boundaries fail to capture nuanced differences that lay within\nthem, limited coverage restricts datasets to only a subset of usually\nhighly-represented cultures, and a lack of dynamicity results in static\ncultural benchmarks that do not change as culture evolves. In this position\npaper, we argue that these methodological limitations are symptomatic of a\ntheoretical gap. We draw on a well-developed theory of culture from\nsociocultural linguistics to fill this gap by 1) demonstrating in a case study\nhow it can clarify methodological constraints and affordances, 2) offering\ntheoretically-motivated paths forward to achieving cultural competence, and 3)\narguing that localization is a more useful framing for the goals of much\ncurrent work in cultural NLP.",
    "pdf_url": "http://arxiv.org/pdf/2502.12057v2",
    "published": "2025-02-17T17:25:11+00:00",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12056v1",
    "title": "Etude du graphe divisoriel 6",
    "authors": [
      "Eric Saias"
    ],
    "abstract": "The divisor graph is the non oriented graph whose vertices are the positive\nintegers, and edges are the {a,b} such that a divides b or b divides a. Let\nF(x,y) be the maximum number of integers<= x belonging in one of y pairwise\ndisjoint simple path of the restriction of the divisor graph to integers <= x.\nOur main result is the following. There exist two real numbers K >c>0 such that\nfor every x and y with x>=2y>=2 , we have cx / log(x/y) <= F(x,y) <= Kx /\nlog(x/y). It answers a question of Erd\\\"os.",
    "pdf_url": "http://arxiv.org/pdf/2502.12056v1",
    "published": "2025-02-17T17:24:44+00:00",
    "categories": [
      "math.CO",
      "math.NT"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12055v1",
    "title": "Designing Role Vectors to Improve LLM Inference Behaviour",
    "authors": [
      "Daniele PotertÃ¬",
      "Andrea Seveso",
      "Fabio Mercorio"
    ],
    "abstract": "The influence of personas on Large Language Models (LLMs) has been widely\nstudied, yet their direct impact on performance remains uncertain. This work\nexplores a novel approach to guiding LLM behaviour through role vectors, an\nalternative to persona-based prompting. We construct 29 role vectors derived\nfrom model activations and evaluate their impact on benchmark performance\nacross multiple domains. Our analysis investigates whether these vectors can\neffectively steer models toward domain-specific expertise. We measure two key\ninterventions: (i) activation addition, which reinforces role-specific\ndirections, and (ii) directional ablation, which removes them. Results on\nwell-established benchmarks indicate that role vectors do, in fact, influence\nmodel behaviour, improving task performance in relevant domains while\nmarginally affecting unrelated tasks. This, in turn, suggests that manipulating\ninternal model representations has a greater impact on outcomes than\npersona-based prompting.",
    "pdf_url": "http://arxiv.org/pdf/2502.12055v1",
    "published": "2025-02-17T17:24:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12054v2",
    "title": "PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning",
    "authors": [
      "Xinyu Zhang",
      "Yuxuan Dong",
      "Yanrui Wu",
      "Jiaxing Huang",
      "Chengyou Jia",
      "Basura Fernando",
      "Mike Zheng Shou",
      "Lingling Zhang",
      "Jun Liu"
    ],
    "abstract": "Large language models demonstrate remarkable capabilities across various\ndomains, especially mathematics and logic reasoning. However, current\nevaluations overlook physics-based reasoning - a complex task requiring physics\ntheorems and constraints. We present PhysReason, a 1,200-problem benchmark\ncomprising knowledge-based (25%) and reasoning-based (75%) problems, where the\nlatter are divided into three difficulty levels (easy, medium, hard). Notably,\nproblems require an average of 8.1 solution steps, with hard requiring 15.6,\nreflecting the complexity of physics-based reasoning. We propose the Physics\nSolution Auto Scoring Framework, incorporating efficient answer-level and\ncomprehensive step-level evaluations. Top-performing models like Deepseek-R1,\nGemini-2.0-Flash-Thinking, and o3-mini-high achieve less than 60% on\nanswer-level evaluation, with performance dropping from knowledge questions\n(75.11%) to hard problems (31.95%). Through step-level evaluation, we\nidentified four key bottlenecks: Physics Theorem Application, Physics Process\nUnderstanding, Calculation, and Physics Condition Analysis. These findings\nposition PhysReason as a novel and comprehensive benchmark for evaluating\nphysics-based reasoning capabilities in large language models. Our code and\ndata will be published at https:/dxzxy12138.github.io/PhysReason.",
    "pdf_url": "http://arxiv.org/pdf/2502.12054v2",
    "published": "2025-02-17T17:24:14+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12227v1",
    "title": "Identifying the Best Transition Law",
    "authors": [
      "Mehrasa Ahmadipour",
      "Ã©lise Crepon",
      "AurÃ©lien Garivier"
    ],
    "abstract": "Motivated by recursive learning in Markov Decision Processes, this paper\nstudies best-arm identification in bandit problems where each arm's reward is\ndrawn from a multinomial distribution with a known support. We compare the\nperformance { reached by strategies including notably LUCB without and with use\nof this knowledge. } In the first case, we use classical non-parametric\napproaches for the confidence intervals. In the second case, where a\nprobability distribution is to be estimated, we first use classical deviation\nbounds (Hoeffding and Bernstein) on each dimension independently, and then the\nEmpirical Likelihood method (EL-LUCB) on the joint probability vector. The\neffectiveness of these methods is demonstrated through simulations on scenarios\nwith varying levels of structural complexity.",
    "pdf_url": "http://arxiv.org/pdf/2502.12227v1",
    "published": "2025-02-17T17:23:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12052v2",
    "title": "A Dual-Perspective NLG Meta-Evaluation Framework with Automatic Benchmark and Better Interpretability",
    "authors": [
      "Xinyu Hu",
      "Mingqi Gao",
      "Li Lin",
      "Zhenghan Yu",
      "Xiaojun Wan"
    ],
    "abstract": "In NLG meta-evaluation, evaluation metrics are typically assessed based on\ntheir consistency with humans. However, we identify some limitations in\ntraditional NLG meta-evaluation approaches, such as issues in handling human\nratings and ambiguous selections of correlation measures, which undermine the\neffectiveness of meta-evaluation. In this work, we propose a dual-perspective\nNLG meta-evaluation framework that focuses on different evaluation\ncapabilities, thereby providing better interpretability. In addition, we\nintroduce a method of automatically constructing the corresponding benchmarks\nwithout requiring new human annotations. Furthermore, we conduct experiments\nwith 16 representative LLMs as the evaluators based on our proposed framework,\ncomprehensively analyzing their evaluation performance from different\nperspectives.",
    "pdf_url": "http://arxiv.org/pdf/2502.12052v2",
    "published": "2025-02-17T17:22:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12053v2",
    "title": "Exploring lensing signatures through spectrotemporal correlations: implications for black hole parameter estimation",
    "authors": [
      "Sreehari Harikesh",
      "Shahar Hadar",
      "Doron Chelouche"
    ],
    "abstract": "Extreme gravitational lensing and relativistic frequency shifts, combined\ntogether, imply that radiation emitted from a black hole's vicinity can echo at\ndifferent frequencies and times, leading to spectrotemporal correlations in\nobserved signals. If such correlations are uncovered by future observations,\nthey could provide a probe of the spacetime geometry in the strong-field region\nnear black holes. Here, motivated by these prospects, we numerically compute\nthe two-point correlation function of specific flux fluctuations in a simple\nmodel of line emission by a hotspot in an equatorial circular orbit. We make\nuse of the Adaptive Analytical Ray Tracing (AART) code to generate the light\ncurves we then correlate. Our results for the correlation maps show a clear\ndecomposition into direct emission-dominated, and lensing-dominated\ncontributions. The computation transcends past analytical approximations,\nstudying the main contribution to the correlation function, which is not deep\nin the universal regime. We compute correlation maps for many combinations of\nblack hole mass, spin, inclination, hotspot width, and orbital radius, and\nstudy their dependence on these parameters. The correlation maps are then used\nto train convolutional neural networks which can be used to estimate source\nparameters, achieving promisingly low evaluation errors within the model. Our\nresults could be relevant for future X-ray spectroscopic missions, offering\ninsights into black hole parameter inference.",
    "pdf_url": "http://arxiv.org/pdf/2502.12053v2",
    "published": "2025-02-17T17:22:49+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.IM",
      "gr-qc"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12051v3",
    "title": "How to Upscale Neural Networks with Scaling Law? A Survey and Practical Guidelines",
    "authors": [
      "Ayan Sengupta",
      "Yash Goel",
      "Tanmoy Chakraborty"
    ],
    "abstract": "Neural scaling laws have revolutionized the design and optimization of\nlarge-scale AI models by revealing predictable relationships between model\nsize, dataset volume, and computational resources. Early research established\npower-law relationships in model performance, leading to compute-optimal\nscaling strategies. However, recent studies highlighted their limitations\nacross architectures, modalities, and deployment contexts. Sparse models,\nmixture-of-experts, retrieval-augmented learning, and multimodal models often\ndeviate from traditional scaling patterns. Moreover, scaling behaviors vary\nacross domains such as vision, reinforcement learning, and fine-tuning,\nunderscoring the need for more nuanced approaches. In this survey, we\nsynthesize insights from over 50 studies, examining the theoretical\nfoundations, empirical findings, and practical implications of scaling laws. We\nalso explore key challenges, including data efficiency, inference scaling, and\narchitecture-specific constraints, advocating for adaptive scaling strategies\ntailored to real-world applications. We suggest that while scaling laws provide\na useful guide, they do not always generalize across all architectures and\ntraining strategies.",
    "pdf_url": "http://arxiv.org/pdf/2502.12051v3",
    "published": "2025-02-17T17:20:41+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12050v3",
    "title": "SpeechT: Findings of the First Mentorship in Speech Translation",
    "authors": [
      "Yasmin Moslem",
      "Juan JuliÃ¡n Cea MorÃ¡n",
      "Mariano Gonzalez-Gomez",
      "Muhammad Hazim Al Farouq",
      "Farah Abdou",
      "Satarupa Deb"
    ],
    "abstract": "This work presents the details and findings of the first mentorship in speech\ntranslation (SpeechT), which took place in December 2024 and January 2025. To\nfulfil the mentorship requirements, the participants engaged in key activities,\nincluding data preparation, modelling, and advanced research. The participants\nexplored data augmentation techniques and compared end-to-end and cascaded\nspeech translation systems. The projects covered various languages other than\nEnglish, including Arabic, Bengali, Galician, Indonesian, Japanese, and\nSpanish.",
    "pdf_url": "http://arxiv.org/pdf/2502.12050v3",
    "published": "2025-02-17T17:18:39+00:00",
    "categories": [
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12049v1",
    "title": "Classifying the Stoichiometry of Virus-like Particles with Interpretable Machine Learning",
    "authors": [
      "Jiayang Zhang",
      "Xianyuan Liu",
      "Wei Wu",
      "Sina Tabakhi",
      "Wenrui Fan",
      "Shuo Zhou",
      "Kang Lan Tee",
      "Tuck Seng Wong",
      "Haiping Lu"
    ],
    "abstract": "Virus-like particles (VLPs) are valuable for vaccine development due to their\nimmune-triggering properties. Understanding their stoichiometry, the number of\nprotein subunits to form a VLP, is critical for vaccine optimisation. However,\ncurrent experimental methods to determine stoichiometry are time-consuming and\nrequire highly purified proteins. To efficiently classify stoichiometry classes\nin proteins, we curate a new dataset and propose an interpretable, data-driven\npipeline leveraging linear machine learning models. We also explore the impact\nof feature encoding on model performance and interpretability, as well as\nmethods to identify key protein sequence features influencing classification.\nThe evaluation of our pipeline demonstrates that it can classify stoichiometry\nwhile revealing protein features that possibly influence VLP assembly. The data\nand code used in this work are publicly available at\nhttps://github.com/Shef-AIRE/StoicIML.",
    "pdf_url": "http://arxiv.org/pdf/2502.12049v1",
    "published": "2025-02-17T17:16:42+00:00",
    "categories": [
      "cs.LG",
      "q-bio.BM",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12048v2",
    "title": "A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond",
    "authors": [
      "Shreya Shukla",
      "Jose Torres",
      "Abhijit Mishra",
      "Jacek Gwizdka",
      "Shounak Roychowdhury"
    ],
    "abstract": "Integration of Brain-Computer Interfaces (BCIs) and Generative Artificial\nIntelligence (GenAI) has opened new frontiers in brain signal decoding,\nenabling assistive communication, neural representation learning, and\nmultimodal integration. BCIs, particularly those leveraging\nElectroencephalography (EEG), provide a non-invasive means of translating\nneural activity into meaningful outputs. Recent advances in deep learning,\nincluding Generative Adversarial Networks (GANs) and Transformer-based Large\nLanguage Models (LLMs), have significantly improved EEG-based generation of\nimages, text, and speech. This paper provides a literature review of the\nstate-of-the-art in EEG-based multimodal generation, focusing on (i)\nEEG-to-image generation through GANs, Variational Autoencoders (VAEs), and\nDiffusion Models, and (ii) EEG-to-text generation leveraging Transformer based\nlanguage models and contrastive learning methods. Additionally, we discuss the\nemerging domain of EEG-to-speech synthesis, an evolving multimodal frontier. We\nhighlight key datasets, use cases, challenges, and EEG feature encoding methods\nthat underpin generative approaches. By providing a structured overview of\nEEG-based generative AI, this survey aims to equip researchers and\npractitioners with insights to advance neural decoding, enhance assistive\ntechnologies, and expand the frontiers of brain-computer interaction.",
    "pdf_url": "http://arxiv.org/pdf/2502.12048v2",
    "published": "2025-02-17T17:16:41+00:00",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12047v2",
    "title": "Quantum Byzantine Multiple Access Channels",
    "authors": [
      "Minglai Cai",
      "Christian Deppe"
    ],
    "abstract": "In communication theory, attacks like eavesdropping or jamming are typically\nassumed to occur at the channel level, while communication parties are expected\nto follow established protocols. But what happens if one of the parties turns\nmalicious? In this work, we investigate a compelling scenario: a\nmultiple-access channel with two transmitters and one receiver, where one\ntransmitter deviates from the protocol and acts dishonestly. To address this\nchallenge, we introduce the Byzantine multiple-access classical-quantum channel\nand derive an achievable communication rate for this adversarial setting.",
    "pdf_url": "http://arxiv.org/pdf/2502.12047v2",
    "published": "2025-02-17T17:16:35+00:00",
    "categories": [
      "cs.IT",
      "math.IT",
      "math.QA"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12046v3",
    "title": "Adiabatic Gauge Potential as a Tool for Detecting Chaos in Classical Systems",
    "authors": [
      "Nachiket Karve",
      "Nathan Rose",
      "David Campbell"
    ],
    "abstract": "The interplay between chaos and thermalization in weakly non-integrable\nsystems is a rich and complex subject. Interest in this area is further\nmotivated by a desire to develop a unified picture of chaos for both quantum\nand classical systems. In this work, we study the adiabatic gauge potential\n(AGP), an object typically studied in quantum mechanics that describes\ndeformations of a quantum state under adiabatic variation of the Hamiltonian,\nin classical Fermi-Pasta-Ulam-Tsingou (FPUT) and Toda models. We show how the\ntime variance of the AGP over a trajectory probes the long-time correlations of\na generic observable and can be used to distinguish among nearly integrable,\nweakly chaotic, and strongly chaotic regimes. We draw connections between the\nevolution of the AGP and diffusion and derive a fluctuation-dissipation\nrelation that connects its variance to long-time correlations of the\nobservable. Within this framework, we demonstrate that strongly and weakly\nchaotic regimes correspond to normal and anomalous diffusion, respectively. The\nlatter gives rise to a marked increase in the variance as the time interval is\nincreased, and this behavior serves as the basis for our probe of the onset\ntimes of chaos, which is interpreted as a ``mixing\" time. Numerical results are\npresented for FPUT and Toda systems that highlight integrable, weakly chaotic,\nand strongly chaotic regimes. Further, a hierarchy of $t_{\\text{Lyapunov}} <\nt_{\\text{chaos}} < t_{\\text{thermalization}}$ is found in these models. We\nconclude by commenting on the wide applicability of our method to a broader\nclass of systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.12046v3",
    "published": "2025-02-17T17:13:38+00:00",
    "categories": [
      "nlin.CD",
      "cond-mat.stat-mech",
      "quant-ph"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2502.12045v2",
    "title": "FIP Bias Evolution in an Emerging Active Region as observed in SPICE Synoptic Observations",
    "authors": [
      "T. Varesano",
      "D. M. Hassler",
      "N. Zambrana Prado",
      "J. M. Laming",
      "J. Plowman",
      "D. J. Knipp",
      "M. Molnar",
      "K. Barczynski",
      "The SPICE consortium"
    ],
    "abstract": "We investigate the time evolution of relative elemental abundances in the\ncontext of the first ionization potential effect focusing on an active region.\nOur aim is to characterize this evolution in different types of solar active\nregion structures as well as in different atmospheric layers. We wish to assert\nhow the measured changes relate to different magnetic topologies by computing\nabundance enhancement in different conditions using the ponderomotive force\nmodel.\n  Leveraging spectroscopic observations from the Spectral Imaging of the\nCoronal Environment instrument on board Solar Orbiter, we use extreme\nultraviolet lines from ions formed across a broad temperature range--from the\nupper chromosphere to the low corona--and we perform relative abundance ratios\nfollowing differential emission measure analysis. This methodology yields\nrelative abundance maps from low, intermediate, and high first ionization\npotential elements. We obtain the temporal evolution of a number of abundance\nratios for different structures on the Sun. We compare these results with the\noutcomes of the ponderomotive force model.\n  We find good correlation between the model and our results, suggesting an\nAlfv\\'en-wave driven fractionation of the plasma. Fan loops, loop footpoints\nand active region boundaries exhibit coronal abundances, while the active\nregion core shows more photospheric-like composition. A slow and steady\nincrease in the magnesium to neon relative first ionization potential bias\nvalues is observed, starting around 1.5 and increasing by about 50\\% after two\ndays. The sulfur to oxygen evolution coupled with the model brings evidence of\nresonant waves fractionating the plasma in transition region structures.",
    "pdf_url": "http://arxiv.org/pdf/2502.12045v2",
    "published": "2025-02-17T17:12:37+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12044v2",
    "title": "A versatile experimental method to measure the traction forces at interfaces",
    "authors": [
      "Yingwei Hou",
      "Tao Liu"
    ],
    "abstract": "Measurement of surface forces, including cohesive forces and contact forces,\nis critical for understanding and controlling interactions at interfaces to\noptimize the interfacial performance of applications. The objective of this\npaper is to introduce a general in-situ method that enables the measurement of\n3D micron-scale displacements and corresponding force distribution at\ninterfaces in dry or wet environment. Stereo digital image correlation was used\nto measure the 3D-displacement of a soft and deformable substrate. The\nefficiency and accuracy of the technique were evaluated by applying compression\nto the substrate using a steel ball, with the measured 3D displacements\naligning closely with finite element analysis simulations. To further assess\nthe method's applicability, the wet adhesion between mussel plaques and\nsubstrate was tested under aqueous conditions. The interfacial displacements\nand forces at different stages during the test were measured. The application\nof the technique can be extended for varied circumstances regarding force range\nand substrate materials based on Winkler Spring model.",
    "pdf_url": "http://arxiv.org/pdf/2502.12044v2",
    "published": "2025-02-17T17:12:35+00:00",
    "categories": [
      "physics.ins-det",
      "cond-mat.mtrl-sci",
      "physics.bio-ph",
      "physics.optics"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2502.12043v1",
    "title": "Novel Brans-Dicke Wormhole Solutions in Non-Vacuum Spacetimes",
    "authors": [
      "Amir Hadi Ziaie",
      "Naser Sadeghnezhad",
      "Akbar Jahan"
    ],
    "abstract": "In the present study we search for a new class of wormhole solutions in the\nframework of Brans-Dicke (BD) theory in the presence of anisotropic matter\ndistribution. Considering a linear equation of state (EoS) between radial\npressure and energy density profile we find exact static spherically symmetric\nsolutions to the BD field equations which represent wormhole configurations.\nThe solutions we obtain include both cases with zero and nonzero redshift\nfunctions, for which, the conditions on wormhole geometry together with the\nweak (WEC) and null (NEC) energy conditions put constraints on model parameters\nsuch as, the BD coupling and EoS parameters. These constraints also depend on\nother model parameters such as, the value of BD scalar field and energy density\nat the wormhole throat. The regularity of the obtained solutions is verified by\ncalculating the Kretschmann scalar in order to ensure that curvature\nsingularities are absent in the wormhole spacetime. We then find that BD\nwormholes in the presence of anisotropic matter can exist without violating NEC\nand WEC, either at the throat or across the entire spacetime.",
    "pdf_url": "http://arxiv.org/pdf/2502.12043v1",
    "published": "2025-02-17T17:12:32+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.12042v1",
    "title": "Multi-agent coordination via communication partitions",
    "authors": [
      "Wei-Chen Lee",
      "Alessandro Abate",
      "Michael Wooldridge"
    ],
    "abstract": "Coordinating the behaviour of self-interested agents in the presence of\nmultiple Nash equilibria is a major research challenge for multi-agent systems.\nPre-game communication between all the players can aid coordination in cases\nwhere the Pareto-optimal payoff is unique, but can lead to deadlocks when there\nare multiple payoffs on the Pareto frontier. We consider a communication\npartition, where only players within the same coalition can communicate with\neach other, and they can establish an agreement (a coordinated joint-action) if\nit is envy-free, credible, and Pareto-optimal. We show that under a natural\nassumption about symmetry, certain communication partitions can induce social\noptimal outcomes in singleton congestion games. This game is a reasonable model\nfor a decentralised, anonymous system where players are required to choose from\na range of identical resources, and incur costs that are increasing and convex\nin the total number of players sharing the same resource. The communication\npartition can be seen as a mechanism for inducing efficient outcomes in this\ncontext.",
    "pdf_url": "http://arxiv.org/pdf/2502.12042v1",
    "published": "2025-02-17T17:11:40+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12041v1",
    "title": "Spectral and Entanglement Transitions from Non-Hermitian Skin Pumping",
    "authors": [
      "Qingya Li"
    ],
    "abstract": "Non-Hermitian physics has unveiled unconventional spectral, topological and\ncritical phenomena, challenging traditional band theories. This thesis advances\nits understanding in three aspects. First, the non-Hermitian skin effect (NHSE)\nis shown to protect real spectra in some ansatz models, not relying on crystal\nsymmetries. Second, we discover the phenomenon of scaling-induced non-Hermitian\nexceptional criticality (SIEC), marked by a unconventional negative dip in\nentanglement entropy scaling, deviating from the well-established logarithmic\nbehavior. A scaling-dependent generalized Brillouin zone (GBZ) is developed to\nanalytically predict this SIEC. Third, we formulate a theoretical framework for\nphase-space GBZs, extending the concept of the GBZ to position-dependent\nsystems, particularly for those with spatially inhomogeneous NHSE hoppings.\nUnprecedented phenomena, including GBZ bifurcation which also protects the\nstability of real spectra, are revealed, introducing new forms of topological\nrobustness governed by phase-space GBZ bifurcations. This thesis also explores\nthe NHSE in Bethe lattices, where the hyperbolic-like lattice geometry gives\nrise to a hierarchy of loop sizes that leads to new forms of critical NHSE\nbehavior.",
    "pdf_url": "http://arxiv.org/pdf/2502.12041v1",
    "published": "2025-02-17T17:10:24+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.12040v1",
    "title": "Inferring contact network characteristics from epidemic data via compact mean-field models",
    "authors": [
      "AndrÃ©s GuzmÃ¡n",
      "Federico Malizia",
      "Gyeong Ho Park",
      "Boseung Choi",
      "Diana Cole",
      "IstvÃ¡n Z. Kiss"
    ],
    "abstract": "Modelling epidemics using contact networks provides a significant improvement\nover classical compartmental models by explicitly incorporating the network of\ncontacts. However, while network-based models describe disease spread on a\ngiven contact structure, their potential for inferring the underlying network\nfrom epidemic data remains largely unexplored. In this work, we consider the\nedge-based compartmental model (EBCM), a compact and analytically tractable\nframework, and we integrate it within dynamical survival analysis (DSA) to\ninfer key network properties along with parameters of the epidemic itself.\nDespite correlations between structural and epidemic parameters, our framework\ndemonstrates robustness in accurately inferring contact network properties from\nsynthetic epidemic simulations. Additionally, we apply the framework to\nreal-world outbreaks, namely the 2001 UK foot-and-mouth disease outbreak and\nthe COVID-19 epidemic in Seoul, to estimate both disease parameters and network\ncharacteristics. Our results show that our framework achieves good fits to\nreal-world epidemic data and reliable short-term forecasts. These findings\nhighlight the potential of network-based inference approaches to uncover hidden\ncontact structures, providing insights that can inform the design of targeted\ninterventions and public health strategies.",
    "pdf_url": "http://arxiv.org/pdf/2502.12040v1",
    "published": "2025-02-17T17:08:13+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12038v1",
    "title": "Review on thermoelectric properties of transition metal dichalcogenides",
    "authors": [
      "I. Pallecchi",
      "N. Manca",
      "B. Patil",
      "L. Pellegrino",
      "D. Marre'"
    ],
    "abstract": "Transition metal dichalcogenides (TMDs) are considered an advantageous\nalternative to their celebrated two-dimensional (2D) van der Waals akin\ncompound, graphene, for a number of applications, especially those requiring a\ngapped and possibly tunable band structure. Thermoelectricity is one of the\napplication fields where TMDs could indeed outperform graphene, thanks to their\nlower thermal conductivity, large effective masses, valley degeneracy, varied\nand tunable transport properties, as well as sensitivity of their band\nstructures and phonon spectra to confinement. Yet, despite promising\ntheoretical predictions, thermoelectric properties of TMDs have not been\nextensively investigated so far and a clear assessment of TMDs as viable\nthermoelectric materials, based on experimental results, is still missing. In\nthis paper, we review the experimental findings of literature on thermoelectric\nproperties of TMDs, to sort out the countless combinations of chemical\ncompositions, doping, off-stoichiometry and sample forms which could\npotentially result in optimized and possibly competitive thermoelectric\nproperties. Based on the experimental data of literature, we simulate the\nperformance of an all-TMD thermoelectric device for practical application as a\nmicron sized cryocooler or power generator.",
    "pdf_url": "http://arxiv.org/pdf/2502.12038v1",
    "published": "2025-02-17T17:07:33+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.12037v3",
    "title": "Information geometry of tempered stable processes",
    "authors": [
      "Jaehyung Choi"
    ],
    "abstract": "We find the information geometry of tempered stable processes. Beginning with\nthe derivation of $\\alpha$-divergence between two tempered stable processes, we\nobtain the corresponding Fisher information matrices and the\n$\\alpha$-connections on their statistical manifolds. Furthermore, we explore\nstatistical applications of this geometric framework. Various tempered stable\nprocesses such as generalized tempered stable processes, classical tempered\nstable processes, and rapidly-decreasing tempered stable processes are\npresented as illustrative examples.",
    "pdf_url": "http://arxiv.org/pdf/2502.12037v3",
    "published": "2025-02-17T17:07:06+00:00",
    "categories": [
      "math.DG",
      "cs.IT",
      "math.IT",
      "math.PR"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12036v1",
    "title": "Variational Formulation and Capacity Estimates for Non-Self-Adjoint Fokker-Planck Operators in Divergence Form",
    "authors": [
      "Mingyi Hou"
    ],
    "abstract": "We introduce a variational formulation for a general class of possibly\ndegenerate, non-self-adjoint Fokker-Planck operators in divergence form,\nmotivated by the work of Albritton et al. (2024), and prove that it is suitable\nfor defining the variational capacity. Using this framework, we establish rough\nestimates for the equilibrium potential in the elliptic case, providing a novel\napproach compared to previous methods. Finally, we derive the Eyring-Kramers\nformula for non-self-adjoint elliptic Fokker-Planck operators in divergence\nform, extending the results of Landim et al. (2019) and Lee & Seo (2022).",
    "pdf_url": "http://arxiv.org/pdf/2502.12036v1",
    "published": "2025-02-17T17:06:03+00:00",
    "categories": [
      "math.AP",
      "math.PR",
      "31C25, 37A60, 82C26 (Primary) 49J40, 82C40 (Secondary)"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.12035v1",
    "title": "Planning minimum regret $CO_2$ pipeline networks",
    "authors": [
      "Stephan Bogs",
      "Ali Abdelshafy",
      "Grit Walther"
    ],
    "abstract": "The transition to a low-carbon economy necessitates effective carbon capture\nand storage (CCS) solutions, particularly for hard-to-abate sectors. Herein,\npipeline networks are indispensable for cost-efficient $CO_2$ transportation\nover long distances. However, there is deep uncertainty regarding which\nindustrial sectors will participate in such systems. This poses a significant\nchallenge due to substantial investments as well as the lengthy planning and\ndevelopment timelines required for $CO_2$ pipeline projects, which are further\nconstrained by limited upgrade options for already built infrastructure. The\neconomies of scale inherent in pipeline construction exacerbate these\nchallenges, leading to potential regret over earlier decisions. While numerous\nmodels were developed to optimize the initial layout of pipeline infrastructure\nbased on known demand, a gap exists in addressing the incremental development\nof infrastructure in conjunction with deep uncertainty. Hence, this paper\nintroduces a novel optimization model for $CO_2$ pipeline infrastructure\ndevelopment, minimizing regret as its objective function and incorporating\nvarious upgrade options, such as looping and pressure increases. The model's\neffectiveness is also demonstrated by presenting a comprehensive case study of\nGermany's cement and lime industries. The developed approach quantitatively\nillustrates the trade-off between different options, which can help in deriving\neffective strategies for $CO_2$ infrastructure development.",
    "pdf_url": "http://arxiv.org/pdf/2502.12035v1",
    "published": "2025-02-17T17:05:41+00:00",
    "categories": [
      "math.OC",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12033v1",
    "title": "The geometry of BERT",
    "authors": [
      "Matteo Bonino",
      "Giorgia Ghione",
      "Giansalvo Cirrincione"
    ],
    "abstract": "Transformer neural networks, particularly Bidirectional Encoder\nRepresentations from Transformers (BERT), have shown remarkable performance\nacross various tasks such as classification, text summarization, and question\nanswering. However, their internal mechanisms remain mathematically obscure,\nhighlighting the need for greater explainability and interpretability. In this\ndirection, this paper investigates the internal mechanisms of BERT proposing a\nnovel perspective on the attention mechanism of BERT from a theoretical\nperspective. The analysis encompasses both local and global network behavior.\nAt the local level, the concept of directionality of subspace selection as well\nas a comprehensive study of the patterns emerging from the self-attention\nmatrix are presented. Additionally, this work explores the semantic content of\nthe information stream through data distribution analysis and global\nstatistical measures including the novel concept of cone index. A case study on\nthe classification of SARS-CoV-2 variants using RNA which resulted in a very\nhigh accuracy has been selected in order to observe these concepts in an\napplication. The insights gained from this analysis contribute to a deeper\nunderstanding of BERT's classification process, offering potential avenues for\nfuture architectural improvements in Transformer models and further analysis in\nthe training process.",
    "pdf_url": "http://arxiv.org/pdf/2502.12033v1",
    "published": "2025-02-17T17:03:12+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12032v2",
    "title": "Statistics on monotonically ordered non-crossing partitions",
    "authors": [
      "Natasha Blitvic",
      "Thomas Bray",
      "Jacob Campbell",
      "Alexandru Nica"
    ],
    "abstract": "We study some combinatorial statistics defined on the set NC^{mton}(n) of\nmonotonically ordered non-crossing partitions of {1,...,n}, and on the set\nNC_2^{mton}(2n) of monotonically ordered non-crossing pair-partitions of\n{1,...,2n}. A relevant point in our study is that the disjoint union of the\nNC^{mton}(n)'s has a natural tree structure, with good homogeneity properties,\nwhich can be used to produce recursions for the Laplace transforms of various\nrandom variables of interest. Unlike in the analogous results known for\nunordered non-crossing partitions, the computations of expectations and\nvariances for natural block-counting statistics on NC^{mton}(n) and for the\nexpectation of the area statistic on NC_2^{mton}(2n) turn out to yield a\nlogarithmic regime.",
    "pdf_url": "http://arxiv.org/pdf/2502.12032v2",
    "published": "2025-02-17T17:02:54+00:00",
    "categories": [
      "math.CO",
      "math.PR",
      "60C05"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12031v1",
    "title": "Masked Latent Prediction and Classification for Self-Supervised Audio Representation Learning",
    "authors": [
      "Aurian Quelennec",
      "Pierre Chouteau",
      "Geoffroy Peeters",
      "Slim Essid"
    ],
    "abstract": "Recently, self-supervised learning methods based on masked latent prediction\nhave proven to encode input data into powerful representations. However, during\ntraining, the learned latent space can be further transformed to extract\nhigher-level information that could be more suited for downstream\nclassification tasks. Therefore, we propose a new method: MAsked latenT\nPrediction And Classification (MATPAC), which is trained with two pretext tasks\nsolved jointly. As in previous work, the first pretext task is a masked latent\nprediction task, ensuring a robust input representation in the latent space.\nThe second one is unsupervised classification, which utilises the latent\nrepresentations of the first pretext task to match probability distributions\nbetween a teacher and a student. We validate the MATPAC method by comparing it\nto other state-of-the-art proposals and conducting ablations studies. MATPAC\nreaches state-of-the-art self-supervised learning results on reference audio\nclassification datasets such as OpenMIC, GTZAN, ESC-50 and US8K and outperforms\ncomparable supervised methods results for musical auto-tagging on\nMagna-tag-a-tune.",
    "pdf_url": "http://arxiv.org/pdf/2502.12031v1",
    "published": "2025-02-17T17:02:26+00:00",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2502.12030v1",
    "title": "Fuzzy dark matter fails to explain the dark matter cores",
    "authors": [
      "MarÃ­a Benito",
      "Gert HÃ¼tsi",
      "Kristjan MÃ¼Ã¼rsepp",
      "Jorge SÃ¡nchez~Almeida",
      "Juan Urrutia",
      "Ville Vaskonen",
      "Hardi VeermÃ¤e"
    ],
    "abstract": "Ultrafaint dwarf galaxies (UFDs) are ideal for studying dark matter (DM) due\nto minimal baryonic effects. UFD observations suggest cored DM profiles. We\nfind that the core radius -- stellar mass scaling predicted by fuzzy dark\nmatter (FDM) is at $6.1\\sigma$ tension with UFD observations. Combining\nobservations from 27 UFDs, the required FDM mass $m_a = 3.2_{-0.6}^{+0.8}\\times\n10^{-21}\\,{\\rm eV}$ is also in conflict with existing Lyman-$\\alpha$ bounds.\nOur results suggest that FDM cannot provide a consistent explanation for DM\ncores and imply $m_a > 2.2\\times 10^{-21}\\,{\\rm eV}$ at to $2\\sigma$ CL.",
    "pdf_url": "http://arxiv.org/pdf/2502.12030v1",
    "published": "2025-02-17T17:02:18+00:00",
    "categories": [
      "astro-ph.CO",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12029v3",
    "title": "KnowPath: Knowledge-enhanced Reasoning via LLM-generated Inference Paths over Knowledge Graphs",
    "authors": [
      "Qi Zhao",
      "Hongyu Yang",
      "Qi Song",
      "Xinwei Yao",
      "Xiangyang Li"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious complex tasks, yet they still suffer from hallucinations. By\nincorporating and exploring external knowledge, such as knowledge graphs(KGs),\nLLM's ability to provide factual answers has been enhanced. This approach\ncarries significant practical implications. However, existing methods suffer\nfrom three key limitations: insufficient mining of LLMs' internal knowledge,\nconstrained generation of interpretable reasoning paths, and unclear fusion of\ninternal and external knowledge. Therefore, we propose KnowPath, a\nknowledge-enhanced large model framework driven by the collaboration of\ninternal and external knowledge. It relies on the internal knowledge of the LLM\nto guide the exploration of interpretable directed subgraphs in external\nknowledge graphs, better integrating the two knowledge sources for more\naccurate reasoning. Extensive experiments on multiple real-world datasets\ndemonstrate the effectiveness of KnowPath. Our code and data are available at\nhttps://github.com/tize-72/KnowPath.",
    "pdf_url": "http://arxiv.org/pdf/2502.12029v3",
    "published": "2025-02-17T17:02:01+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12027v1",
    "title": "Enhancing Transparent Object Pose Estimation: A Fusion of GDR-Net and Edge Detection",
    "authors": [
      "Tessa Pulli",
      "Peter HÃ¶nig",
      "Stefan Thalhammer",
      "Matthias Hirschmanner",
      "Markus Vincze"
    ],
    "abstract": "Object pose estimation of transparent objects remains a challenging task in\nthe field of robot vision due to the immense influence of lighting, background,\nand reflections. However, the edges of clear objects have the highest contrast,\nwhich leads to stable and prominent features. We propose a novel approach by\nincorporating edge detection in a pre-processing step for the tasks of object\ndetection and object pose estimation. We conducted experiments to investigate\nthe effect of edge detectors on transparent objects. We examine the performance\nof the state-of-the-art 6D object pose estimation pipeline GDR-Net and the\nobject detector YOLOX when applying different edge detectors as pre-processing\nsteps (i.e., Canny edge detection with and without color information, and\nholistically-nested edges (HED)). We evaluate the physically-based rendered\ndataset Trans6D-32 K of transparent objects with parameters proposed by the BOP\nChallenge. Our results indicate that applying edge detection as a\npre-processing enhances performance for certain objects.",
    "pdf_url": "http://arxiv.org/pdf/2502.12027v1",
    "published": "2025-02-17T16:59:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12026v1",
    "title": "Analysis of the Order Flow Auction under Proposer-Builder Separation",
    "authors": [
      "Ruofei Ma",
      "Wenpin Tang",
      "David Yao"
    ],
    "abstract": "In this paper, we consider the impact of the order flow auction (OFA) in the\ncontext of the proposer-builder separation (PBS) mechanism through a\ngame-theoretic perspective. The OFA is designed to improve user welfare by\nredistributing maximal extractable value (MEV) to the users, in which two\nauctions take place: the order flow auction and the block-building auction. We\nformulate the OFA as a multiplayer game, and focus our analyses on the case of\ntwo competing players (builders). We prove the existence and uniqueness of a\nNash equilibrium for the two-player game, and derive a closed-form solution by\nsolving a quartic equation. Our result shows that the builder with a\ncompetitive advantage pays a relatively lower cost, leading to centralization\nin the builder space. In contrast, the proposer's shares evolve as a martingale\nprocess, which implies decentralization in the proposer (or, validator) space.\nOur analyses rely on various tools from stochastic processes, convex\noptimization, and polynomial equations. We also conduct numerical studies to\ncorroborate our findings, and explore other features of the OFA under the PBS\nmechanism.",
    "pdf_url": "http://arxiv.org/pdf/2502.12026v1",
    "published": "2025-02-17T16:58:06+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2502.12025v1",
    "title": "SafeChain: Safety of Language Models with Long Chain-of-Thought Reasoning Capabilities",
    "authors": [
      "Fengqing Jiang",
      "Zhangchen Xu",
      "Yuetai Li",
      "Luyao Niu",
      "Zhen Xiang",
      "Bo Li",
      "Bill Yuchen Lin",
      "Radha Poovendran"
    ],
    "abstract": "Emerging large reasoning models (LRMs), such as DeepSeek-R1 models, leverage\nlong chain-of-thought (CoT) reasoning to generate structured intermediate\nsteps, enhancing their reasoning capabilities. However, long CoT does not\ninherently guarantee safe outputs, potentially leading to harmful consequences\nsuch as the introduction of security vulnerabilities in code or the spread of\nmisinformation. Current research on large language model (LLM) safety usually\nfocuses on short-answer responses, overlooking the long CoT style outputs of\nLRMs. To bridge this gap, we conduct a systematic study of LRM safety. First,\nwe investigate safety evaluators calibrated against human annotations. Using\nour newly developed metrics, we thoroughly assess the safety of 12\nstate-of-the-art LRMs on StrongReject and WildJailbreak datasets. Our results\nshow that LRMs are not safe compared to their reasoning advance. Further, we\nperform a fine-grained analysis of the reasoning trace and final answer. We\nfind that three decoding strategies-ZeroThink, LessThink, and MoreThink-can\nimprove model safety without additional training. However, these strategies\neither use constrained reasoning traces or incur high inference costs. To\nbetter strengthen LRM safety, we introduce SafeChain, the first-of-its-kind\nsafety training dataset in CoT style. We fine-tune two LRMs with SafeChain,\nshowing that it not only enhances model safety but also preserves performance\nacross 6 reasoning benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2502.12025v1",
    "published": "2025-02-17T16:57:56+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.14894v1",
    "title": "FOCUS on Contamination: A Geospatial Deep Learning Framework with a Noise-Aware Loss for Surface Water PFAS Prediction",
    "authors": [
      "Jowaria Khan",
      "Alexa Friedman",
      "Sydney Evans",
      "Runzi Wang",
      "Kaley Beins",
      "David Andrews",
      "Elizabeth Bondi-Kelly"
    ],
    "abstract": "Per and polyfluoroalkyl substances (PFAS), chemicals found in products like\nnon-stick cookware, are unfortunately persistent environmental pollutants with\nsevere health risks. Accurately mapping PFAS contamination is crucial for\nguiding targeted remediation efforts and protecting public and environmental\nhealth, yet detection across large regions remains challenging due to the cost\nof testing and the difficulty of simulating their spread. In this work, we\nintroduce FOCUS, a geospatial deep learning framework with a label noise-aware\nloss function, to predict PFAS contamination in surface water over large\nregions. By integrating hydrological flow data, land cover information, and\nproximity to known PFAS sources, our approach leverages both spatial and\nenvironmental context to improve prediction accuracy. We evaluate the\nperformance of our approach through extensive ablation studies and comparative\nanalyses against baselines like sparse segmentation, as well as existing\nscientific methods, including Kriging and pollutant transport simulations.\nResults highlight our framework's potential for scalable PFAS monitoring.",
    "pdf_url": "http://arxiv.org/pdf/2502.14894v1",
    "published": "2025-02-17T16:57:10+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "I.2.1; I.2.10; I.4.6; I.4.9; I.4.10; J.2"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12023v1",
    "title": "Thick subcategories of derived categories of gentle algebras",
    "authors": [
      "Callum Page"
    ],
    "abstract": "We study thick subcategories of derived categories of gentle algebras. Any\nthick subcategory of a derived category of a gentle algebra is generated by a\nset of string objects or a set of band objects. We show the thick subcategories\ngenerated by string objects are in bijection with sets of non-crossing paths on\nthe geometric model of the derived category.",
    "pdf_url": "http://arxiv.org/pdf/2502.12023v1",
    "published": "2025-02-17T16:57:01+00:00",
    "categories": [
      "math.RT",
      "16G20, 18G80"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12022v3",
    "title": "Teaching LLMs According to Their Aptitude: Adaptive Reasoning for Mathematical Problem Solving",
    "authors": [
      "Xin Xu",
      "Yan Xu",
      "Tianhao Chen",
      "Yuchen Yan",
      "Chengwu Liu",
      "Zaoyu Chen",
      "Yufei Wang",
      "Yichun Yin",
      "Yasheng Wang",
      "Lifeng Shang",
      "Qun Liu"
    ],
    "abstract": "Existing approaches to mathematical reasoning with large language models\n(LLMs) rely on Chain-of-Thought (CoT) for generalizability or Tool-Integrated\nReasoning (TIR) for precise computation. While efforts have been made to\ncombine these methods, they primarily rely on post-selection or predefined\nstrategies, leaving an open question: whether LLMs can autonomously adapt their\nreasoning strategy based on their inherent capabilities. In this work, we\npropose TATA (Teaching LLMs According to Their Aptitude), an adaptive framework\nthat enables LLMs to personalize their reasoning strategy spontaneously,\naligning it with their intrinsic aptitude. TATA incorporates base-LLM-aware\ndata selection during supervised fine-tuning (SFT) to tailor training data to\nthe model's unique abilities. This approach equips LLMs to autonomously\ndetermine and apply the appropriate reasoning strategy at test time. We\nevaluate TATA through extensive experiments on six mathematical reasoning\nbenchmarks, using both general-purpose and math-specialized LLMs. Empirical\nresults demonstrate that TATA effectively combines the complementary strengths\nof CoT and TIR, achieving superior or comparable performance with improved\ninference efficiency compared to TIR alone. Further analysis underscores the\ncritical role of aptitude-aware data selection in enabling LLMs to make\neffective and adaptive reasoning decisions and align reasoning strategies with\nmodel capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2502.12022v3",
    "published": "2025-02-17T16:56:23+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12020v2",
    "title": "Learning in a Multifield Coherent Ising Machine",
    "authors": [
      "Daan de Bos",
      "Marc Serra-Garcia"
    ],
    "abstract": "We introduce a network of coupled oscillators that can learn to solve a\nclassification task from a set of examples -- performing both training and\ninference through the nonlinear evolution of the system. We accomplish this by\ncombining three key elements to achieve learning: A long-term memory that\nstores learned responses, analogous to the synapses in biological brains; a\nshort-term memory that stores the neural activations, similar to the firing\npatterns of neurons; and an evolution law that updates the synapses in response\nto novel examples, inspired by synaptic plasticity. Achieving all three\nelements in wave-based information processors such as metamaterials is a\nsignificant challenge. Here, we solve it by leveraging the material\nmultistability to implement long-term memory, and harnessing symmetries and\nthermal noise to realize the learning rule. Our analysis reveals that the\nlearning mechanism, although inspired by synaptic plasticity, also shares\nparallelisms with bacterial evolution strategies, where mutation rates increase\nin the presence of noxious stimuli.",
    "pdf_url": "http://arxiv.org/pdf/2502.12020v2",
    "published": "2025-02-17T16:54:54+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.dis-nn",
      "cs.ET",
      "cs.NE",
      "nlin.AO"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.12019v1",
    "title": "Robotic CBCT Meets Robotic Ultrasound",
    "authors": [
      "Feng Li",
      "Yuan Bi",
      "Dianye Huang",
      "Zhongliang Jiang",
      "Nassir Navab"
    ],
    "abstract": "The multi-modality imaging system offers optimal fused images for safe and\nprecise interventions in modern clinical practices, such as computed tomography\n- ultrasound (CT-US) guidance for needle insertion. However, the limited\ndexterity and mobility of current imaging devices hinder their integration into\nstandardized workflows and the advancement toward fully autonomous intervention\nsystems. In this paper, we present a novel clinical setup where robotic cone\nbeam computed tomography (CBCT) and robotic US are pre-calibrated and\ndynamically co-registered, enabling new clinical applications. This setup\nallows registration-free rigid registration, facilitating multi-modal guided\nprocedures in the absence of tissue deformation. First, a one-time\npre-calibration is performed between the systems. To ensure a safe insertion\npath by highlighting critical vasculature on the 3D CBCT, SAM2 segments vessels\nfrom B-mode images, using the Doppler signal as an autonomously generated\nprompt. Based on the registration, the Doppler image or segmented vessel masks\nare then mapped onto the CBCT, creating an optimally fused image with\ncomprehensive detail. To validate the system, we used a specially designed\nphantom, featuring lesions covered by ribs and multiple vessels with simulated\nmoving flow. The mapping error between US and CBCT resulted in an average\ndeviation of 1.72+-0.62 mm. A user study demonstrated the effectiveness of\nCBCT-US fusion for needle insertion guidance, showing significant improvements\nin time efficiency, accuracy, and success rate. Needle intervention performance\nimproved by approximately 50% compared to the conventional US-guided workflow.\nWe present the first robotic dual-modality imaging system designed to guide\nclinical applications. The results show significant performance improvements\ncompared to traditional manual interventions.",
    "pdf_url": "http://arxiv.org/pdf/2502.12019v1",
    "published": "2025-02-17T16:53:03+00:00",
    "categories": [
      "cs.RO",
      "eess.IV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12018v2",
    "title": "Atom of Thoughts for Markov LLM Test-Time Scaling",
    "authors": [
      "Fengwei Teng",
      "Zhaoyang Yu",
      "Quan Shi",
      "Jiayi Zhang",
      "Chenglin Wu",
      "Yuyu Luo"
    ],
    "abstract": "Large Language Models (LLMs) achieve superior performance through\ntraining-time scaling, and test-time scaling further enhances their\ncapabilities by conducting effective reasoning during inference. However, as\nthe scale of reasoning increases, existing test-time scaling methods suffer\nfrom accumulated historical information, which not only wastes computational\nresources but also interferes with effective reasoning. To address this issue,\nwe observe that complex reasoning can be achieved by solving a series of\nindependent and self-contained subquestions. These subquestions are essentially\n\\textit{atomic questions}, exhibiting the memoryless property similar to Markov\nprocesses. Based on this observation, we propose Atom of Thoughts (\\our), where\neach state transition consists of decomposing the current question into a\ndependency-based directed acyclic graph and contracting its subquestions,\nforming a simplified question that maintains answer equivalence with the\noriginal problem. This answer preservation enables the iterative\n\\textit{decomposition-contraction} process to naturally form a meaningful\nMarkov reasoning process. Furthermore, these atomic states can be seamlessly\nintegrated into existing test-time scaling methods, enabling \\our to serve as a\nplug-in enhancement for improving reasoning capabilities. Experiments across\nsix benchmarks demonstrate the effectiveness of \\our both as a standalone\nframework and a plug-in enhancement. Notably, on HotpotQA, when applied to\ngpt-4o-mini, \\our achieves an \\textbf{80.6\\%} F1 score, surpassing o3-mini by\n\\textbf{3.4\\%} and DeepSeek-R1 by \\textbf{10.6\\%}. The code is available at\n\\href{https://github.com/qixucen/atom}{https://github.com/qixucen/atom}.",
    "pdf_url": "http://arxiv.org/pdf/2502.12018v2",
    "published": "2025-02-17T16:52:42+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.18326v1",
    "title": "Pretraining Frequency Predicts Compositional Generalization of CLIP on Real-World Tasks",
    "authors": [
      "ThaddÃ¤us Wiedemer",
      "Yash Sharma",
      "Ameya Prabhu",
      "Matthias Bethge",
      "Wieland Brendel"
    ],
    "abstract": "We investigate the success conditions for compositional generalization of\nCLIP models on real-world data through performance prediction. Prior work shows\nthat CLIP requires exponentially more pretraining data for linear performance\ngains on individual concepts. This sample-inefficient scaling could be\nmitigated if CLIP systematically understood new inputs as compositions of\nlearned components, allowing rare observation to be mapped to common concepts.\nTo explore CLIP's compositional generalization ability, we filter retrieval\ncorpora for samples with object combinations not present in the pretraining\ncorpus. We show that CLIP's performance on these samples can be accurately\npredicted from the pretraining frequencies of individual objects. Our findings\ndemonstrate that CLIP learns to disentangle objects observed in its pretraining\ndata and can recompose them straightforwardly. Additionally, we are the first\nto show how this ability scales with pretraining data. For data curation in\npractice, our results suggest that balancing object occurrences improves\ngeneralization, which should benefit CLIP's efficiency and accuracy without\nscaling data volume.",
    "pdf_url": "http://arxiv.org/pdf/2502.18326v1",
    "published": "2025-02-17T16:52:02+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12016v2",
    "title": "Integrated Information in Relational Quantum Dynamics (RQD)",
    "authors": [
      "Arash Zaghi"
    ],
    "abstract": "We introduce a quantum integrated-information measure $\\Phi$ for multipartite\nstates within the Relational Quantum Dynamics (RQD) framework. $\\Phi(\\rho)$ is\ndefined as the minimum quantum Jensen-Shannon distance between an n-partite\ndensity operator $\\rho$ and any product state over a bipartition of its\nsubsystems. We prove that its square-root induces a genuine metric on state\nspace and that $\\Phi$ is monotonic under all completely positive\ntrace-preserving maps. Restricting the search to bipartitions yields a unique\noptimal split and a unique closest product state. From this geometric picture\nwe derive a canonical entanglement witness directly tied to $\\Phi$ and\nconstruct an integration dendrogram that reveals the full hierarchical\ncorrelation structure of $\\rho$. We further show that there always exists an\n\"optimal observer\"-a channel or basis-that preserves $\\Phi$ better than any\nalternative. Finally, we propose a quantum Markov blanket theorem: the boundary\nof the optimal bipartition isolates subsystems most effectively. Our framework\nunites categorical enrichment, convex-geometric methods, and operational tools,\nforging a concrete bridge between integrated information theory and quantum\ninformation science.",
    "pdf_url": "http://arxiv.org/pdf/2502.12016v2",
    "published": "2025-02-17T16:51:06+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12015v2",
    "title": "The sinusoidal valley: a recipe for high peaks in the scalar and induced tensor spectra",
    "authors": [
      "Aris Katsis"
    ],
    "abstract": "Adding a sine-type interaction to inflationary models with two fields can\nevoke a classical trajectory with many turns in field space. Under conditions\nwe discuss, the enhancement of the spectrum of adiabatic fluctuations resulting\nfrom each turn adds up. A special range of scales away from the CMB-constrained\nregion can then be enhanced by several orders of magnitude, allowing for\ninteresting phenomenological possibilities, such as induced gravitational waves\nor primordial black holes. A localized version of this interaction can also be\nused as an add-on to conventional inflationary models, thus allowing the\ninjection of the large peak in their power spectra. The intuition and the\nconclusions drawn from this simple model remain relevant for more complicated\napplications that usually include extra terms that obscure the simplicity of\nthe mechanism.",
    "pdf_url": "http://arxiv.org/pdf/2502.12015v2",
    "published": "2025-02-17T16:51:04+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12014v1",
    "title": "Coupled Ising-Potts Model: Rich Sets of Critical Temperatures and Translation-Invariant Gibbs Measures",
    "authors": [
      "F. H. Haydarov",
      "B. A. Omirov",
      "U. A. Rozikov"
    ],
    "abstract": "We consider a coupled Ising-Potts model on Cayley trees of order $ k \\geq 2\n$. This model involves spin vectors $ (s, \\sigma) $, and generalizes both the\nIsing and Potts models by incorporating interactions between two types of\nspins: $s = \\pm 1$ and $\\sigma = 1, \\dots, q$. It is applicable to a wide range\nof systems, including multicomponent alloys, spin glasses, biological systems,\nnetworks, and social models.\n  In this paper, we find some translation-invariant splitting Gibbs measures\n(TISGMs) and show, for $k\\geq 2$, that at sufficiently low temperatures, the\nnumber of such measures is at least $2^{q}+1$. This is not an exact upper\nbound; for $k=2$ and $q=5$, we demonstrate that the number of TISGMs reaches\nthe exact bound of 335, which is much larger than $2^5+1=33$. We prove, for\n$q=5$ that there are 12 critical temperatures at which the number of TISGMs\nchanges, and we provide the exact number of TISGMs for each intermediate\ntemperature. Additionally, we identify temperature regions where three TISGMs,\nclose to the free measure, are either extreme or non-extreme among all Gibbs\nmeasures.\n  We also show that the coupled Ising-Potts model exhibits properties absent in\nthe individual Ising and Potts models. In particular, we observe the following\nnew phenomena:\n  1. In both the Ising and Potts models, if a Gibbs measure exists at some\ntemperature $T_0$, then it exists for all $T<T_0$. However, in the coupled\nIsing-Potts model, some TISGMs may only exist at intermediate temperatures\n(neither very low nor very high).\n  2. The 5-state Potts model has three critical temperatures and up to 31\nTISGMs. We show that for $q=5$, the coupled Ising-Potts model has four times as\nmany critical temperatures and approximately 11 times as many TISGMs. Thus, our\nmodel modifies the phase structure more rapidly and exhibits a significantly\nricher class of splitting Gibbs measures.",
    "pdf_url": "http://arxiv.org/pdf/2502.12014v1",
    "published": "2025-02-17T16:49:46+00:00",
    "categories": [
      "math.FA",
      "math.PR",
      "60G57"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12013v2",
    "title": "Unsupervised Structural-Counterfactual Generation under Domain Shift",
    "authors": [
      "Krishn Vishwas Kher",
      "Lokesh Venkata Siva Maruthi Badisa",
      "Kusampudi Venkata Datta Sri Harsha",
      "Chitneedi Geetha Sowmya",
      "Saksham Mittal",
      "SakethaNath Jagarlapudi"
    ],
    "abstract": "Motivated by the burgeoning interest in cross-domain learning, we present a\nnovel generative modeling challenge: generating counterfactual samples in a\ntarget domain based on factual observations from a source domain. Our approach\noperates within an unsupervised paradigm devoid of parallel or joint datasets,\nrelying exclusively on distinct observational samples and causal graphs for\neach domain. This setting presents challenges that surpass those of\nconventional counterfactual generation. Central to our methodology is the\ndisambiguation of exogenous causes into effect-intrinsic and domain-intrinsic\ncategories. This differentiation facilitates the integration of domain-specific\ncausal graphs into a unified joint causal graph via shared effect-intrinsic\nexogenous variables. We propose leveraging Neural Causal models within this\njoint framework to enable accurate counterfactual generation under standard\nidentifiability assumptions. Furthermore, we introduce a novel loss function\nthat effectively segregates effect-intrinsic from domain-intrinsic variables\nduring model training. Given a factual observation, our framework combines the\nposterior distribution of effect-intrinsic variables from the source domain\nwith the prior distribution of domain-intrinsic variables from the target\ndomain to synthesize the desired counterfactuals, adhering to Pearl's causal\nhierarchy. Intriguingly, when domain shifts are restricted to alterations in\ncausal mechanisms without accompanying covariate shifts, our training regimen\nparallels the resolution of a conditional optimal transport problem. Empirical\nevaluations on a synthetic dataset show that our framework generates\ncounterfactuals in the target domain that very closely resemble the ground\ntruth.",
    "pdf_url": "http://arxiv.org/pdf/2502.12013v2",
    "published": "2025-02-17T16:48:16+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12011v1",
    "title": "Reconfigurable Intelligent Surfaces-Assisted Integrated Access and Backhaul",
    "authors": [
      "Charitha Madapatha",
      "Behrooz Makki",
      "Hao Guo",
      "Tommy Svensson"
    ],
    "abstract": "In this paper, we study the impact of reconfigurable intelligent surfaces\n(RISs) on the coverage extension of integrated access and backhaul (IAB)\nnetworks. Particularly, using a finite stochastic geometry model, with random\ndistributions of user equipments (UEs) in a finite region, and planned\nhierachical architecture for IAB, we study the service coverage probability\ndefined as the probability of the event that the UEs' minimum rate requirements\nare satisfied. We present comparisons between different cases including\nIAB-only, IAB assisted with RIS for backhaul as well as IAB assisted by network\ncontrolled repeaters (NCRs). Our investigations focus on wide-area IAB assisted\nwith RIS through the lens of different design architectures and deployments,\nrevealing both conflicts and synergies for minimizing the effect of tree\nfoliage over seasonal changes. Our simulation results reveal both opportunities\nand challenges towards the implementation of RIS in IAB.",
    "pdf_url": "http://arxiv.org/pdf/2502.12011v1",
    "published": "2025-02-17T16:46:15+00:00",
    "categories": [
      "cs.IT",
      "cs.LG",
      "cs.NI",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12010v2",
    "title": "Hyperplane arrangements and the Gauss map of a pencil",
    "authors": [
      "Thiago Fassarella",
      "Nivaldo Medeiros"
    ],
    "abstract": "We show that the coefficients of the characteristic polynomial of a central\nhyperplane arrangement $\\mathcal A$, coincide with the multidegrees of the\nGauss map of a pencil of hypersurfaces naturally associated to $\\mathcal A$. As\na consequence, we obtain a proof of the Heron-Rota-Welsh conjecture for\nmatroids representable over a field of characteristic zero.",
    "pdf_url": "http://arxiv.org/pdf/2502.12010v2",
    "published": "2025-02-17T16:44:11+00:00",
    "categories": [
      "math.AG",
      "math.CO",
      "14E05, 05B35"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12009v1",
    "title": "Beyond Sentiment: Examining the Role of Moral Foundations in User Engagement with News on Twitter",
    "authors": [
      "Jacopo D'Ignazi",
      "Kyriaki Kalimeri",
      "Mariano G. BeirÃ³"
    ],
    "abstract": "This study uses sentiment analysis and the Moral Foundations Theory (MFT) to\ncharacterise news content in social media and examine its association with user\nengagement. We employ Natural Language Processing to quantify the moral and\naffective linguistic markers. At the same time, we automatically define\nthematic macro areas of news from major U.S. news outlets and their Twitter\nfollowers (Jan 2020 - Mar 2021). By applying Non-Negative Matrix Factorisation\nto the obtained linguistic features we extract clusters of similar moral and\naffective profiles, and we identify the emotional and moral characteristics\nthat mostly explain user engagement via regression modelling. We observe that\nSurprise, Trust, and Harm are crucial elements explaining user engagement and\ndiscussion length and that Twitter content from news media outlets has more\nexplanatory power than their linked articles. We contribute with actionable\nfindings evidencing the potential impact of employing specific moral and\naffective nuances in public and journalistic discourse in today's communication\nlandscape. In particular, our results emphasise the need to balance engagement\nstrategies with potential priming risks in our evolving media landscape.",
    "pdf_url": "http://arxiv.org/pdf/2502.12009v1",
    "published": "2025-02-17T16:44:04+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12008v3",
    "title": "Enhanced magnetoelastic stress in disordered iron-gallium alloy thin films revealed by direct measurement",
    "authors": [
      "AdriÃ¡n BeguÃ©",
      "Maria Grazia Proietti",
      "JosÃ© Ignacio Arnaudas",
      "Miguel Ciria"
    ],
    "abstract": "The large magnetostriction in FeGa alloys is relevant for manifold\napplications, but for thin films, it can play a prominent role in controlling\nthe strength of the magnetic anisotropy. Bulk samples show values depending on\nthe extensive preparation procedure compendium, which is limited in its\ntemperature range for high-quality thin-film synthesis. Here, we present a\nstudy of the magnetoelastic coupling coefficients $B_1$ and $B_2$ in epitaxial\nFeGa thin films below 50 nm deposited on the MgO(001) surface at 150 $^\\circ$C\nby the cantilever method. Series of films with 22, 28, and 33 at. % Ga do not\nshow thickness-dependent variations for $B_1$ and $B_2$, but $-B_1$ for the 22\nat. % Ga composition is 10 MPa, roughly 2 times the bulk value and smaller than\nthe bulk-like value of $-B_1$=12.1 MPa obtained for a film with 17 at. % Ga.\nThis enhancement is correlated with the A2 crystal structure for the film\nrather than the coexistence with D0$_3$ or other ordered nanometric\nprecipitates proposed for bulk samples. Synchrotron diffraction excludes the\nformation of long-range L6$_0$, or D0$_3$ precipitates in samples with (001)A2\npeaks at concentrations around 25 at. % Ga, which implies partial chemical\ndisorder. The analysis of extended x-ray absorption fine structure measurements\npoints to a D0$_3$ local order with a residual number of Ga-Ga pairs.\nConsidering that the substrate quenches the movable strain in the A2 phase\ndescribed in dual-phase structures, our results point to the important role of\nthe electronic structure of the iron atoms modified by the presence of Ga in\nthe alloy. This effect enlarges $B_1$ in films with the A2 phase, stabilized\nusing epitaxial growth.",
    "pdf_url": "http://arxiv.org/pdf/2502.12008v3",
    "published": "2025-02-17T16:43:54+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.12007v1",
    "title": "Demographic Attributes Prediction from Speech Using WavLM Embeddings",
    "authors": [
      "Yuchen Yang",
      "Thomas Thebaud",
      "Najim Dehak"
    ],
    "abstract": "This paper introduces a general classifier based on WavLM features, to infer\ndemographic characteristics, such as age, gender, native language, education,\nand country, from speech. Demographic feature prediction plays a crucial role\nin applications like language learning, accessibility, and digital forensics,\nenabling more personalized and inclusive technologies. Leveraging pretrained\nmodels for embedding extraction, the proposed framework identifies key acoustic\nand linguistic fea-tures associated with demographic attributes, achieving a\nMean Absolute Error (MAE) of 4.94 for age prediction and over 99.81% accuracy\nfor gender classification across various datasets. Our system improves upon\nexisting models by up to relative 30% in MAE and up to relative 10% in accuracy\nand F1 scores across tasks, leveraging a diverse range of datasets and large\npretrained models to ensure robustness and generalizability. This study offers\nnew insights into speaker diversity and provides a strong foundation for future\nresearch in speech-based demographic profiling.",
    "pdf_url": "http://arxiv.org/pdf/2502.12007v1",
    "published": "2025-02-17T16:43:47+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12006v2",
    "title": "Scaling of Street Network Centrality with City Population",
    "authors": [
      "R. L. Fagundes",
      "G. G. Piva",
      "A. S. Mata",
      "F. L. Ribeiro"
    ],
    "abstract": "Urban scaling laws reveal how cities evolve as their populations grow, yet\nthe role of street network accessibility in this process remains underexplored.\nWe analyze over 5,000 Brazilian cities to establish a scaling law linking\naverage closeness centrality $\\langle c_C\\rangle$ -- a measure of structural\naccessibility in street networks-to population size N . Our results demonstrate\nthat $\\langle c_C\\rangle$ decays sublinearly as $N^{-\\sigma}$ ($\\sigma \\approx\n0.38$), indicating that larger cities redistribute accessibility from cores to\nperipheries while maintaining navigability through hierarchical shortcuts. This\nscaling arises from the fractal interplay between infrastructure and\npopulation, characterized by a network dimension $d \\approx 2.17$, which\nexceeds that of a 2D grid. The slower decline in closeness centrality ($\\sigma\n< 0.5$) reflects a trade-off: urban expansion reduces proximity but enhances\nconnectivity through optimized path diversity, fostering economic dynamism. By\nintegrating the Molinero & Thurner model with network centrality metrics, we\nprovide a framework to reconcile infrastructure efficiency with equitable\naccessibility in growing cities.",
    "pdf_url": "http://arxiv.org/pdf/2502.12006v2",
    "published": "2025-02-17T16:42:28+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12005v2",
    "title": "Feasibility Evaluation of Quadratic Programs for Constrained Control",
    "authors": [
      "Panagiotis Rousseas",
      "Dimitra Panagou"
    ],
    "abstract": "This paper presents a computationally-efficient method for evaluating the\nfeasibility of Quadratic Programs (QPs) for online constrained control. Based\non the duality principle, we first show that the feasibility of a QP can be\ndetermined by the solution of a properly-defined Linear Program (LP). Our\nanalysis yields a LP that can be solved more efficiently compared to the\noriginal QP problem, and more importantly, is simpler in form and can be solved\nmore efficiently compared to existing methods that assess feasibility via LPs.\nThe computational efficiency of the proposed method compared to existing\nmethods for feasibility evaluation is demonstrated in comparative case studies\nas well as a feasible-constraint selection problem, indicating its promise for\nonline feasibility evaluation of optimization-based controllers.",
    "pdf_url": "http://arxiv.org/pdf/2502.12005v2",
    "published": "2025-02-17T16:42:09+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12004v1",
    "title": "Reionization and its sources",
    "authors": [
      "Anirban Chakraborty",
      "Tirthankar Roy Choudhury"
    ],
    "abstract": "Reionization represents an important phase in the history of our Universe\nwhen ultraviolet radiation from the first luminous sources, primarily stars and\naccreting black holes, ionized the neutral hydrogen atoms in the intergalactic\nmedium (IGM). This process follows the ``Dark Ages'', a period with no luminous\nsources, and is initiated by the formation of the first sources, marking the\n``Cosmic Dawn''. Reionization proceeds through multiple stages: initially,\nionized bubbles form around galaxies, then expand and overlap across the IGM,\nculminating in a fully ionized state, with neutral hydrogen remaining only in\ndense regions. Understanding reionization involves a diverse range of physical\nconcepts, from large-scale structure formation and star formation to radiation\npropagation through the IGM. Observationally, reionization can be explored\nusing the cosmic microwave background (CMB), Lyman-$\\alpha$ absorption,\nhigh-redshift galaxy surveys, and emerging 21~cm experiments, which together\noffer invaluable insights into this transformative epoch.",
    "pdf_url": "http://arxiv.org/pdf/2502.12004v1",
    "published": "2025-02-17T16:42:02+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.12003v2",
    "title": "Advancing Time Series Wildfire Spread Prediction: Modeling Improvements and the WSTS+ Benchmark",
    "authors": [
      "Saad Lahrichi",
      "Jake Bova",
      "Jesse Johnson",
      "Jordan Malof"
    ],
    "abstract": "Recent research has demonstrated the potential of deep neural networks (DNNs)\nto accurately predict wildfire spread on a given day based upon\nhigh-dimensional explanatory data from a single preceding day, or from a time\nseries of T preceding days. Here, we introduce a variety of modeling\nimprovements that achieve state-of-the-art (SOTA) accuracy for both single-day\nand multi-day input scenarios, as evaluated on a large public benchmark for\nnext-day wildfire spread, termed the WildfireSpreadTS (WSTS) benchmark.\nConsistent with prior work, we found that models using time-series input\nobtained the best overall accuracy. Furthermore, we create a new benchmark,\nWSTS+, by incorporating four additional years of historical wildfire data into\nthe WSTS benchmark. Our benchmark doubles the number of unique years of\nhistorical data, expands its geographic scope, and, to our knowledge,\nrepresents the largest public benchmark for time-series-based wildfire spread\nprediction.",
    "pdf_url": "http://arxiv.org/pdf/2502.12003v2",
    "published": "2025-02-17T16:41:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12002v1",
    "title": "NaturalL2S: End-to-End High-quality Multispeaker Lip-to-Speech Synthesis with Differential Digital Signal Processing",
    "authors": [
      "Yifan Liang",
      "Fangkun Liu",
      "Andong Li",
      "Xiaodong Li",
      "Chengshi Zheng"
    ],
    "abstract": "Recent advancements in visual speech recognition (VSR) have promoted progress\nin lip-to-speech synthesis, where pre-trained VSR models enhance the\nintelligibility of synthesized speech by providing valuable semantic\ninformation. The success achieved by cascade frameworks, which combine\npseudo-VSR with pseudo-text-to-speech (TTS) or implicitly utilize the\ntranscribed text, highlights the benefits of leveraging VSR models. However,\nthese methods typically rely on mel-spectrograms as an intermediate\nrepresentation, which may introduce a key bottleneck: the domain gap between\nsynthetic mel-spectrograms, generated from inherently error-prone lip-to-speech\nmappings, and real mel-spectrograms used to train vocoders. This mismatch\ninevitably degrades synthesis quality. To bridge this gap, we propose Natural\nLip-to-Speech (NaturalL2S), an end-to-end framework integrating acoustic\ninductive biases with differentiable speech generation components.\nSpecifically, we introduce a fundamental frequency (F0) predictor to capture\nprosodic variations in synthesized speech. The predicted F0 then drives a\nDifferentiable Digital Signal Processing (DDSP) synthesizer to generate a\ncoarse signal which serves as prior information for subsequent speech\nsynthesis. Additionally, instead of relying on a reference speaker embedding as\nan auxiliary input, our approach achieves satisfactory performance on speaker\nsimilarity without explicitly modelling speaker characteristics. Both objective\nand subjective evaluation results demonstrate that NaturalL2S can effectively\nenhance the quality of the synthesized speech when compared to state-of-the-art\nmethods. Our demonstration page is accessible at\nhttps://yifan-liang.github.io/NaturalL2S/.",
    "pdf_url": "http://arxiv.org/pdf/2502.12002v1",
    "published": "2025-02-17T16:40:23+00:00",
    "categories": [
      "cs.SD",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2502.12001v2",
    "title": "Merging Language and Domain Specific Models: The Impact on Technical Vocabulary Acquisition",
    "authors": [
      "Thibault Rousset",
      "Taisei Kakibuchi",
      "Yusuke Sasaki",
      "Yoshihide Nomura"
    ],
    "abstract": "Advancements in Natural Language Processing have enabled specialized language\nmodels, but integrating domain-specific knowledge into general-purpose models\nin multilingual settings remains challenging, particularly for technical\nvocabulary. This paper investigates the integration of technical vocabulary in\nmerged language models and explores the knowledge transfer mechanisms involved\nwhen combining a general-purpose language-specific model with a domain-specific\nmodel, focusing on the resulting model's comprehension of technical jargon. Our\nexperiments analyze the impact of this merging process on the target model's\nproficiency in handling specialized terminology. We present a quantitative\nevaluation of the performance of the merged model, comparing it with that of\nthe individual constituent models. The findings offer insights into the\neffectiveness of different model merging methods for enhancing domain-specific\nknowledge and highlight potential challenges and future directions in\nleveraging these methods for cross-lingual knowledge transfer in Natural\nLanguage Processing.",
    "pdf_url": "http://arxiv.org/pdf/2502.12001v2",
    "published": "2025-02-17T16:39:28+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.14893v1",
    "title": "NOTA: Multimodal Music Notation Understanding for Visual Large Language Model",
    "authors": [
      "Mingni Tang",
      "Jiajia Li",
      "Lu Yang",
      "Zhiqiang Zhang",
      "Jinghao Tian",
      "Zuchao Li",
      "Lefei Zhang",
      "Ping Wang"
    ],
    "abstract": "Symbolic music is represented in two distinct forms: two-dimensional,\nvisually intuitive score images, and one-dimensional, standardized text\nannotation sequences. While large language models have shown extraordinary\npotential in music, current research has primarily focused on unimodal symbol\nsequence text. Existing general-domain visual language models still lack the\nability of music notation understanding. Recognizing this gap, we propose NOTA,\nthe first large-scale comprehensive multimodal music notation dataset. It\nconsists of 1,019,237 records, from 3 regions of the world, and contains 3\ntasks. Based on the dataset, we trained NotaGPT, a music notation visual large\nlanguage model. Specifically, we involve a pre-alignment training phase for\ncross-modal alignment between the musical notes depicted in music score images\nand their textual representation in ABC notation. Subsequent training phases\nfocus on foundational music information extraction, followed by training on\nmusic notation analysis. Experimental results demonstrate that our NotaGPT-7B\nachieves significant improvement on music understanding, showcasing the\neffectiveness of NOTA and the training pipeline. Our datasets are open-sourced\nat https://huggingface.co/datasets/MYTH-Lab/NOTA-dataset.",
    "pdf_url": "http://arxiv.org/pdf/2502.14893v1",
    "published": "2025-02-17T16:39:19+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12000v2",
    "title": "Ãptimal Algorithm for Fully Dynamic LZ77",
    "authors": [
      "Itai Boneh",
      "Shay Golan",
      "Matan Kraus"
    ],
    "abstract": "The Lempel-Ziv 77 (LZ77) factorization is a fundamental compression scheme\nwidely used in text processing and data compression. In this work, we study the\ntime complexity of maintaining the LZ77 factorization of a dynamic string. We\npresent an algorithm that dynamically maintains the LZ77 factorization of a\nstring $S$ that undergoes edit operations (character substitutions, insertions,\nand deletions). The data structure can be built in $\\tilde{O}(n)$ time on an\ninitial string $S$ of length $n$, and updates are supported in\n$\\tilde{O}(n^{2/3})$ time, where $n$ is the current length of $S$. We also show\nthat there is no algorithm with polynomially faster update time unless the\nStrong Exponential Time Hypothesis fails. Our lower bound holds even for the\nrestricted settings in which only substitution operations are allowed, and only\nthe length of the LZ77 factorization is maintained.",
    "pdf_url": "http://arxiv.org/pdf/2502.12000v2",
    "published": "2025-02-17T16:38:04+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11999v1",
    "title": "Algorithm Engineering of SSSP With Negative Edge Weights",
    "authors": [
      "Alejandro Cassis",
      "Andreas Karrenbauer",
      "AndrÃ© Nusser",
      "Paolo Luigi Rinaldi"
    ],
    "abstract": "Computing shortest paths is one of the most fundamental algorithmic graph\nproblems. It is known since decades that this problem can be solved in\nnear-linear time if all weights are nonnegative. A recent break-through by\n[Bernstein, Nanongkai, Wulff-Nilsen '22] presented a randomized near-linear\ntime algorithm for this problem. A subsequent improvement in [Bringmann,\nCassis, Fischer '23] significantly reduced the number of logarithmic factors\nand thereby also simplified the algorithm. It is surprising and exciting that\nboth of these algorithms are combinatorial and do not contain any fundamental\nobstacles for being practical.\n  We launch the, to the best of our knowledge, first extensive investigation\ntowards a practical implementation of [Bringmann, Cassis, Fischer '23]. To this\nend, we give an accessible overview of the algorithm, discussing what adaptions\nare necessary to obtain a fast algorithm in practice. We manifest these\nadaptions in an efficient implementation. We test our implementation on a\nbenchmark data set that is adapted to be more difficult for our implementation\nin order to allow for a fair comparison. As in [Bringmann, Cassis, Fischer '23]\nas well as in our implementation there are multiple parameters to tune, we\nempirically evaluate their effect and thereby determine the best choices. Our\nimplementation is then extensively compared to one of the state-of-the-art\nalgorithms for this problem [Goldberg, Radzik '93]. On the hardest instance\ntype, we are faster by up to almost two orders of magnitude.",
    "pdf_url": "http://arxiv.org/pdf/2502.11999v1",
    "published": "2025-02-17T16:37:51+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11998v2",
    "title": "Determination of Hubble constant from Megamaser Cosmology Project using Profile Likelihood",
    "authors": [
      "Shubham Barua",
      "Vyaas Ramakrishnan",
      "Shantanu Desai"
    ],
    "abstract": "The Megamaser Cosmology Project inferred a value for the Hubble constant\ngiven by $H_0=73.9 \\pm 3.0 $ km/sec/Mpc. This value was obtained using Bayesian\ninference by marginalizing over six nuisance parameters, corresponding to the\nvelocities of the megamaser galaxy systems. We obtain an independent estimate\nof the Hubble constant with the same data using frequentist inference. For this\npurpose, we use profile likelihood to dispense with the aforementioned nuisance\nparameters. The frequentist estimate of the Hubble constant is given by\n$H_0=73.5^{+3.0}_{-2.9}$ km/sec/Mpc and agrees with the Bayesian estimate to\nwithin $0.2\\sigma$, and both approaches also produce consistent\nconfidence/credible intervals. Therefore, this analysis provides a\nproof-of-principle application of profile likelihood in dealing with nuisance\nparameters in cosmology, which is complementary to Bayesian analysis.",
    "pdf_url": "http://arxiv.org/pdf/2502.11998v2",
    "published": "2025-02-17T16:37:42+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2502.11997v1",
    "title": "Non-invertible symmetry breaking in a frustration-free spin chain",
    "authors": [
      "Akash Sinha",
      "Vivek Kumar Singh",
      "Pramod Padmanabhan",
      "Kun Hao",
      "Vladimir Korepin"
    ],
    "abstract": "A nearest-neighbor, frustration-free spin $\\frac{1}{2}$ chain can be\nconstructed {\\it via} projectors of various ranks \\'{a} la Bravyi-Gosset. We\nshow that in the rank 1 case this system is gapped and has two ground states\nresembling ferromagnetic states. These states spontaneously break the\nnon-invertible symmetry connecting them. The latter is proved using the\nmachinery of algebraic quantum theory. The non-invertible symmetries of this\nsystem do not come from a duality.",
    "pdf_url": "http://arxiv.org/pdf/2502.11997v1",
    "published": "2025-02-17T16:37:07+00:00",
    "categories": [
      "hep-th",
      "cond-mat.stat-mech",
      "cond-mat.str-el",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.11996v1",
    "title": "Correlation functions of degenerate fields in Super-Liouville field theory",
    "authors": [
      "Aleksandra Ivanova"
    ],
    "abstract": "We study four-point correlation functions of degenerated fields in the $NS$\nsector in Super-Liouville field theory. We find integral expressions for these\nfunctions using the BPZ equation, and study some superconformal properties of\nthese solutions. Finally, we present the general form for three-point\ncorrelation functions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11996v1",
    "published": "2025-02-17T16:36:35+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.18492v2",
    "title": "Harmonic Morphisms and Minimal Conformal Foliations on Lie Groups",
    "authors": [
      "Sigmundur Gudmundsson",
      "Thomas Jack Munn"
    ],
    "abstract": "Let $G$ be a Lie group equipped with a left-invariant Riemannian metric. Let\n$K$ be a semisimple and normal subgroup of $G$ generating a left-invariant\nconformal foliation $\\F$ of on $G$. We then show that the foliation $\\F$ is\nRiemannian and minimal. This means that locally the leaves of $\\F$ are fibres\nof a harmonic morphism. We also prove that if the metric restricted to $K$ is\nbiinvariant then $\\F$ is totally geodesic.",
    "pdf_url": "http://arxiv.org/pdf/2502.18492v2",
    "published": "2025-02-17T16:36:24+00:00",
    "categories": [
      "math.DG",
      "53C35, 53C43, 58E20"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11995v2",
    "title": "Presumed Cultural Identity: How Names Shape LLM Responses",
    "authors": [
      "Siddhesh Pawar",
      "Arnav Arora",
      "Lucie-AimÃ©e Kaffee",
      "Isabelle Augenstein"
    ],
    "abstract": "Names are deeply tied to human identity. They can serve as markers of\nindividuality, cultural heritage, and personal history. However, using names as\na core indicator of identity can lead to over-simplification of complex\nidentities. When interacting with LLMs, user names are an important point of\ninformation for personalisation. Names can enter chatbot conversations through\ndirect user input (requested by chatbots), as part of task contexts such as CV\nreviews, or as built-in memory features that store user information for\npersonalisation. We study biases associated with names by measuring cultural\npresumptions in the responses generated by LLMs when presented with common\nsuggestion-seeking queries, which might involve making assumptions about the\nuser. Our analyses demonstrate strong assumptions about cultural identity\nassociated with names present in LLM generations across multiple cultures. Our\nwork has implications for designing more nuanced personalisation systems that\navoid reinforcing stereotypes while maintaining meaningful customisation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11995v2",
    "published": "2025-02-17T16:35:15+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11994v1",
    "title": "Decoherence and vibrational energy relaxation of the electronically excited PtPOP complex in solution",
    "authors": [
      "Benedikt O Birgisson",
      "Asmus Ougaard Dohn",
      "Hannes JÃ³nsson",
      "Gianluca Levi"
    ],
    "abstract": "Understanding the ultrafast vibrational relaxation following photoexcitation\nof molecules in a condensed phase is essential to predict the outcome and\nimprove the efficiency of photoinduced molecular processes. Here, the\nvibrational decoherence and energy relaxation of a binuclear complex,\n[Pt$_2$(P$_2$O$_5$H$_2$)$_4$]$^{4-}$ (PtPOP), upon electronic excitation in\nliquid water and acetonitrile are investigated through direct adiabatic\ndynamics simulations. A quantum mechanics/molecular mechanics (QM/MM) scheme is\nused where the excited state of the complex is modelled with orbital-optimized\ndensity functional calculations while solvent molecules are described using\npotential energy functions. The decoherence time of the Pt-Pt vibration\ndominating the photoinduced dynamics is found to be $\\sim$1.6 ps in both\nsolvents. This is in excellent agreement with experimental measurements in\nwater, where intersystem crossing is slow ($>10$ ps). Pathways for the flow of\nexcess energy are identified by monitoring the power of the solvent on\nvibrational modes. The latter are obtained as generalized normal modes from the\nvelocity covariances, and the power is computed using QM/MM embedding forces.\nExcess vibrational energy is found to be predominantly released through\nshort-range repulsive and attractive interactions between the ligand atoms and\nsurrounding solvent molecules, whereas solute-solvent interactions involving\nthe Pt atoms are less important. Since photoexcitation deposits most of the\nexcess energy into Pt-Pt vibrations, energy dissipation to the solvent is\ninefficient. This study reveals the mechanism behind the exceptionally long\nvibrational coherence of the photoexcited PtPOP complex in solution and\nunderscores the importance of short-range interactions for accurate simulations\nof vibrational energy relaxation of solvated molecules.",
    "pdf_url": "http://arxiv.org/pdf/2502.11994v1",
    "published": "2025-02-17T16:34:16+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11993v2",
    "title": "MultiFlow: A unified deep learning framework for multi-vessel classification, segmentation and clustering of phase-contrast MRI validated on a multi-site single ventricle patient cohort",
    "authors": [
      "Tina Yao",
      "Nicole St. Clair",
      "Madeline Gong",
      "Gabriel F. Miller",
      "Jennifer A. Steeden",
      "Rahul H. Rathod",
      "Vivek Muthurangu",
      "FORCE Investigators"
    ],
    "abstract": "We present a deep learning framework with two models for automated\nsegmentation and large-scale flow phenotyping in a registry of single-ventricle\npatients.\n  MultiFlowSeg simultaneously classifies and segments five key vessels, left\nand right pulmonary arteries, aorta, superior vena cava, and inferior vena\ncava, from velocity encoded phase-contrast magnetic resonance (PCMR) data.\nTrained on 260 CMR exams (5 PCMR scans per exam), it achieved an average Dice\nscore of 0.91 on 50 unseen test cases. The method was then integrated into an\nautomated pipeline where it processed over 5,500 registry exams without human\nassistance, in exams with all 5 vessels it achieved 98% classification and 90%\nsegmentation accuracy.\n  Flow curves from successful segmentations were used to train MultiFlowDTC,\nwhich applied deep temporal clustering to identify distinct flow phenotypes.\nSurvival analysis revealed distinct phenotypes were significantly associated\nwith increased risk of death/transplantation and liver disease, demonstrating\nthe potential of the framework.",
    "pdf_url": "http://arxiv.org/pdf/2502.11993v2",
    "published": "2025-02-17T16:33:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11992v1",
    "title": "On the Logic Elements Associated with Round-Off Errors and Gaussian Blur in Image Registration: A Simple Case of Commingling",
    "authors": [
      "Serap A. Savari"
    ],
    "abstract": "Discrete image registration can be a strategy to reconstruct signals from\nsamples corrupted by blur and noise. We examine superresolution and discrete\nimage registration for one-dimensional spatially-limited piecewise constant\nfunctions which are subject to blur which is Gaussian or a mixture of Gaussians\nas well as to round-off errors. Previous approaches address the signal recovery\nproblem as an optimization problem. We focus on a regime with low blur and\nsuggest that the operations of blur, sampling, and quantization are not unlike\nthe operation of a computer program and have an abstraction that can be studied\nwith a type of logic. When the minimum distance between discontinuity points is\nbetween $1.5$ and 2 times the sampling interval, we can encounter the simplest\nform of a type of interference between discontinuity points that we call\n``commingling.'' We describe a way to reason about two sets of samples of the\nsame signal that will often result in the correct recovery of signal\namplitudes. We also discuss ways to estimate bounds on the distances between\ndiscontinuity points.",
    "pdf_url": "http://arxiv.org/pdf/2502.11992v1",
    "published": "2025-02-17T16:33:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11991v1",
    "title": "Evaluation of the uncertainty in calculating nanodosimetric quantities due to the use of different interaction cross sections in Monte Carlo track structure codes",
    "authors": [
      "Carmen Villagrasa",
      "Giorgio Baiocco",
      "Zine-El-Abidine Chaoui",
      "Michael Dingfelder",
      "SÃ©bastien Incerti",
      "Pavel KundrÃ¡t",
      "Ioanna Kyriakou",
      "Yusuke Matsuya",
      "Takeshi Kai",
      "Alessio Paris",
      "Yann Perrot",
      "Marcin Pietrzak",
      "Jan Schuemann",
      "Hans Rabus"
    ],
    "abstract": "This study evaluates the uncertainty in nanodosimetric calculations caused by\nvariations in interaction cross sections within Monte Carlo Track Structure\n(MCTS) simulation codes. Nanodosimetry relies on accurately simulating particle\ninteractions at the molecular scale. Different MCTS codes employ distinct\nphysical models and datasets for electron interactions in liquid water, a\nsurrogate for biological tissues. The paper focuses on the Ionization Cluster\nSize Distribution (ICSD) generated by electrons of varying energies in\nnanometric volumes. Seven MCTS codes were tested using their native cross\nsections and a common dataset derived from averaging data used in the\nparticipating codes. The results reveal significant discrepancies among the\ncodes in ICSDs and derived biologically relevant nanodosimetric quantities such\nas mean ionization numbers (M1) and probabilities of obtaining two or more\nionizations (F2). The largest variations were observed for low-energy\nelectrons, where the contribution from interaction cross sections dominates the\noverall uncertainties. For instance, M1 values for ICSDs of electron of 20 eV\ncan differ by around 45 % (RSD) and 34 % (RSD) was found for F2 values of ICSDs\nof electrons of 50 eV. Using common cross sections substantially reduced the\ndiscrepancies, suggesting that cross section datasets are the primary source of\nvariability. Finally, estimates of deoxyribonucleic acid (DNA) damage using the\nPARTRAC code highlight tht cross section variations have a non-negligible\nimpact simulated biological outcomes, particularly for double-strand breaks\n(DSBs) Indeed, despite the fact that many other parameters in the simulation\nthat can greatly differ from one code to another, the different interaction\ncross-sections studied in this work can lead to differences in the number of\nDSBs calculated with the PARTRAC code of up to 15%.",
    "pdf_url": "http://arxiv.org/pdf/2502.11991v1",
    "published": "2025-02-17T16:32:10+00:00",
    "categories": [
      "physics.med-ph"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11990v1",
    "title": "Unified Multivariate Ordinal Model for analysis of sensory attributes",
    "authors": [
      "JanaÃ­na Marques e Melo",
      "JoÃ£o CÃ©sar Reis Alves",
      "Gabriel Rodrigues Palma",
      "SÃ­lvia Maria de Freitas",
      "Idemauro Antonio Rodrigues de Lara"
    ],
    "abstract": "Experiments involving sensory analysis of foods and beverages are beneficial\nfor selecting healthy products and assessing the preferences of potential\nconsumers. They are generally planned in incomplete blocks, and their\nattributes, such as aroma, colour, and flavour, are evaluated using a 9-point\nhedonic scale, characterising an ordinal variable response. Also, the\ngeneralised logit model with random effects for panellists is one of the\nappropriate models to relate the multivariate response to the covariates. This\nstudy aims to present a method for analysing sensory attributes through a\nunified multivariate model. Due to the nature of the variable, each separate\nmodel already corresponds to a multivariate analysis, so our proposal would\nincorporate a complete analysis with solely one model. This proposal is based\non multivariate methods for categorical data and maximum likelihood theory. Our\nmethod was evaluated through a simulation study, in which we consider three\ndistinct formulations with two attributes to represent various formulation\nselection scenarios via mixed discrete models. The simulated results\ndemonstrated overall concordance rates exceeding 80\\% for the unified model\ncompared to the separate models. Moreover, as motivation is presented, a study\nof 13 prebiotic beverages based on cashew nut almonds added to grape juice,\nwith 130 potential consumers. The attributes evaluated were overall impression,\naroma, Body, sweetness and flavour, using a 9-point hedonic scale. The selected\nunified model considering all attributes was the non-proportional odds\nmixed-effect model. According to this model, the prebiotic beverage\nformulations most likely to be accepted were: 8\\% sugar and 40\\% grape juice\n($F_4$), 6\\% sugar and 44\\% grape juice ($F_6$), and 9\\% sugar and 30\\% grape\njuice ($F_{13}$). The unified analysis and computational time showed the\nadvantages of this proposal.",
    "pdf_url": "http://arxiv.org/pdf/2502.11990v1",
    "published": "2025-02-17T16:31:24+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.11989v1",
    "title": "Characterizing Photorealism and Artifacts in Diffusion Model-Generated Images",
    "authors": [
      "Negar Kamali",
      "Karyn Nakamura",
      "Aakriti Kumar",
      "Angelos Chatzimparmpas",
      "Jessica Hullman",
      "Matthew Groh"
    ],
    "abstract": "Diffusion model-generated images can appear indistinguishable from authentic\nphotographs, but these images often contain artifacts and implausibilities that\nreveal their AI-generated provenance. Given the challenge to public trust in\nmedia posed by photorealistic AI-generated images, we conducted a large-scale\nexperiment measuring human detection accuracy on 450 diffusion-model generated\nimages and 149 real images. Based on collecting 749,828 observations and 34,675\ncomments from 50,444 participants, we find that scene complexity of an image,\nartifact types within an image, display time of an image, and human curation of\nAI-generated images all play significant roles in how accurately people\ndistinguish real from AI-generated images. Additionally, we propose a taxonomy\ncharacterizing artifacts often appearing in images generated by diffusion\nmodels. Our empirical observations and taxonomy offer nuanced insights into the\ncapabilities and limitations of diffusion models to generate photorealistic\nimages in 2024.",
    "pdf_url": "http://arxiv.org/pdf/2502.11989v1",
    "published": "2025-02-17T16:28:15+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11988v1",
    "title": "Nice q-analogs of orthogonal polynomials with nice moments: Some simple examples",
    "authors": [
      "Johann Cigler"
    ],
    "abstract": "In this note I collect some typical examples of orthogonal polynomials with\nsimple moments where both moments and orthogonal polynomials have nice\nq-analogs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11988v1",
    "published": "2025-02-17T16:28:10+00:00",
    "categories": [
      "math.CA",
      "math.CO"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11987v2",
    "title": "On the average least negative Hecke eigenvalue",
    "authors": [
      "Jackie Voros"
    ],
    "abstract": "We show that the first sign change of Hecke eigenvalues of classical newforms\nhas a finite mean, which we also compute. We distinguish between the first\nnegative prime Hecke eigenvalue, and the first negative Hecke eigenvalue. This\nproblem can be considered to be an analogue of the least quadratic non-residue\nproblem, of which the average was explored by Erd\\H{o}s in 1961. In fact, the\naverage least negative prime Hecke eigenvalue has the same value as the average\nleast quadratic non-residue, under GRH. To compute these averages, we develop\nlarge sieve inequalities that are uniform in both the weight and level aspect.",
    "pdf_url": "http://arxiv.org/pdf/2502.11987v2",
    "published": "2025-02-17T16:26:33+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11986v2",
    "title": "Selective Task Group Updates for Multi-Task Optimization",
    "authors": [
      "Wooseong Jeong",
      "Kuk-Jin Yoon"
    ],
    "abstract": "Multi-task learning enables the acquisition of task-generic knowledge by\ntraining multiple tasks within a unified architecture. However, training all\ntasks together in a single architecture can lead to performance degradation,\nknown as negative transfer, which is a main concern in multi-task learning.\nPrevious works have addressed this issue by optimizing the multi-task network\nthrough gradient manipulation or weighted loss adjustments. However, their\noptimization strategy focuses on addressing task imbalance in shared\nparameters, neglecting the learning of task-specific parameters. As a result,\nthey show limitations in mitigating negative transfer, since the learning of\nshared space and task-specific information influences each other during\noptimization. To address this, we propose a different approach to enhance\nmulti-task performance by selectively grouping tasks and updating them for each\nbatch during optimization. We introduce an algorithm that adaptively determines\nhow to effectively group tasks and update them during the learning process. To\ntrack inter-task relations and optimize multi-task networks simultaneously, we\npropose proximal inter-task affinity, which can be measured during the\noptimization process. We provide a theoretical analysis on how dividing tasks\ninto multiple groups and updating them sequentially significantly affects\nmulti-task performance by enhancing the learning of task-specific parameters.\nOur methods substantially outperform previous multi-task optimization\napproaches and are scalable to different architectures and various numbers of\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11986v2",
    "published": "2025-02-17T16:26:05+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11985v1",
    "title": "Variational Quantum Algorithms for Many-Body Systems",
    "authors": [
      "Mirko Consiglio"
    ],
    "abstract": "Variational quantum algorithms (VQAs) incorporate hybrid quantum-classical\ncomputation aimed at harnessing the power of noisy intermediate-scale quantum\n(NISQ) computers to solve challenging computational problems. In this thesis,\nthree main VQAs are presented, each tackling a different facet of many-body\nphysics.",
    "pdf_url": "http://arxiv.org/pdf/2502.11985v1",
    "published": "2025-02-17T16:25:34+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech",
      "math-ph",
      "math.MP",
      "physics.comp-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11984v3",
    "title": "Blank Space: Adaptive Causal Coding for Streaming Communications Over Multi-Hop Networks",
    "authors": [
      "Adina Waxman",
      "Shai Ginzach",
      "Aviel Glam",
      "Alejandro Cohen"
    ],
    "abstract": "In this work, we introduce Blank Space AC-RLNC (BS), a novel Adaptive and\nCausal Network Coding (AC-RLNC) solution designed to mitigate the triplet\ntrade-off between throughput-delay-efficiency in multi-hop networks. BS\nleverages the network's physical limitations considering the bottleneck from\neach node to the destination. In particular, BS introduces a\nlight-computational re-encoding algorithm, called Network AC-RLNC (NET),\nimplemented independently at intermediate nodes. NET adaptively adjusts the\nForward Error Correction (FEC) rates and schedules idle periods. It\nincorporates two distinct suspension mechanisms: 1) Blank Space Period,\naccounting for the forward-channels bottleneck, and 2) No-New No-FEC approach,\nbased on data availability. The experimental results achieve significant\nimprovements in resource efficiency, demonstrating a 20% reduction in channel\nusage compared to baseline RLNC solutions. Notably, these efficiency gains are\nachieved while maintaining competitive throughput and delay performance,\nensuring improved resource utilization does not compromise network performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11984v3",
    "published": "2025-02-17T16:25:19+00:00",
    "categories": [
      "cs.IT",
      "cs.NI",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11983v1",
    "title": "Design Considerations Based on Stability for a Class of TCP Algorithms",
    "authors": [
      "Sreekanth Prabhakar",
      "Gaurav Raina"
    ],
    "abstract": "Transmission Control Protocol (TCP) continues to be the dominant transport\nprotocol on the Internet. The stability of fluid models has been a key\nconsideration in the design of TCP and the performance evaluation of TCP\nalgorithms. Based on local stability analysis, we formulate some design\nconsiderations for a class of TCP algorithms. We begin with deriving sufficient\nconditions for the local stability of a generalized TCP algorithm in the\npresence of heterogeneous round-trip delays. Within this generalized model, we\nconsider three specific variants of TCP: TCP Reno, Compound TCP, and Scalable\nTCP. The sufficient conditions we derive are scalable across network topologies\nwith one, two, and many bottleneck links. We are interested in networks with\nintermediate and small drop-tail buffers as they offer smaller queuing delays.\nThe small buffer regime is more attractive as the conditions for stability are\ndecentralized. TCP algorithms that follow our design considerations can provide\nstable operation on any network topology, irrespective of the number of\nbottleneck links or delays in the network.",
    "pdf_url": "http://arxiv.org/pdf/2502.11983v1",
    "published": "2025-02-17T16:23:41+00:00",
    "categories": [
      "cs.NI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11982v2",
    "title": "Single-Cell Proteomics Using Mass Spectrometry",
    "authors": [
      "Amanda Momenzadeh",
      "Jesse G. Meyer"
    ],
    "abstract": "Single-cell proteomics (SCP) is transforming our understanding of biological\ncomplexity by shifting from bulk proteomics, where signals are averaged over\nthousands of cells, to the proteome analysis of individual cells. This granular\nperspective reveals distinct cell states, population heterogeneity, and the\nunderpinnings of disease pathogenesis that bulk approaches may obscure.\nHowever, SCP demands exceptional sensitivity, precise cell handling, and robust\ndata processing to overcome the inherent challenges of analyzing picogram-level\nprotein samples without amplification. Recent innovations in sample\npreparation, separations, data acquisition strategies, and specialized mass\nspectrometry instrumentation have substantially improved proteome coverage and\nthroughput. Approaches that integrate complementary omics, streamline\nmulti-step sample processing, and automate workflows through microfluidics and\nspecialized platforms promise to further push SCP boundaries. Advances in\ncomputational methods, especially for data normalization and imputation,\naddress the pervasive issue of missing values, enabling more reliable\ndownstream biological interpretations. Despite these strides, higher\nthroughput, reproducibility, and consensus best practices remain pressing needs\nin the field. This mini review summarizes the latest progress in SCP technology\nand software solutions, highlighting how closer integration of analytical,\ncomputational, and experimental strategies will facilitate deeper and broader\ncoverage of single-cell proteomes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11982v2",
    "published": "2025-02-17T16:22:55+00:00",
    "categories": [
      "q-bio.QM",
      "q-bio.GN"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2502.11981v2",
    "title": "Machine Learning Should Maximize Welfare, but Not by (Only) Maximizing Accuracy",
    "authors": [
      "Nir Rosenfeld",
      "Haifeng Xu"
    ],
    "abstract": "Decades of research in machine learning have given us powerful tools for\nmaking accurate predictions. This has made such tools appealing for use in\nsocial settings and on human inputs. Yet despite a lack of justification for\nwhy the generic approach of accuracy maximization can or should improve our\ncollective well-being -- and mounting evidence of likely adverse outcomes -- it\nremains the widespread default. This position paper asserts that for machine\nlearning to become socially beneficial, it must be embedded within a broader\neconomic framework that explicitly aims to maximize social welfare. The field\nof welfare economics asks: how should we allocate limited resources among\nself-interested agents to maximize overall benefits? We contend that this\nperspective applies to many contemporary applications of machine learning in\nsocial contexts, and advocate for its adoption. Rather than disposing of\nprediction, we propose to leverage this forte of machine learning towards\nwelfare maximization. We demonstrate this idea by portraying a conceptual\nframework that gradually transitions from accuracy maximization (with awareness\nto welfare) to welfare maximization (via accurate prediction). We detail\napplications and use-cases for which this framework can be effective, identify\ntechnical challenges and practical opportunities, and highlight future avenues\nworth pursuing.",
    "pdf_url": "http://arxiv.org/pdf/2502.11981v2",
    "published": "2025-02-17T16:22:46+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11980v2",
    "title": "Quasiconvexity and self-improving size estimates",
    "authors": [
      "Bogdan RaiÅ£Ä"
    ],
    "abstract": "We show that M\\\"uller's $L\\log L$ bound $$F(Du)\\geq 0,\\,Du\\in\nL^p_{\\mathrm{loc}}(\\mathbb{R}^n)\\implies F(Du)\\in L\\log\nL_{\\mathrm{loc}}(\\mathbb{R}^n)$$ for $F =\\det$ and $p=n$ holds for quasiconcave\n$F$ which are homogeneous of degree $p>1$. This contrasts similar Hardy space\nbounds which hold only for null Lagrangians.",
    "pdf_url": "http://arxiv.org/pdf/2502.11980v2",
    "published": "2025-02-17T16:22:43+00:00",
    "categories": [
      "math.AP",
      "Primary: 49J45, Secondary: 28B05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11979v1",
    "title": "Logarithmic Approximation for Road Pricing on Grids",
    "authors": [
      "Andrei Constantinescu",
      "Andrzej Turko",
      "Roger Wattenhofer"
    ],
    "abstract": "Consider a graph $G = (V, E)$ and some commuters, each specified by a tuple\n$(u, v, b)$ consisting of two nodes in the graph $u, v \\in V$ and a\nnon-negative real number $b$, specifying their budget. The goal is to find a\npricing function $p$ of the edges of $G$ that maximizes the revenue generated\nby the commuters. Here, each commuter $(u, v, b)$ either pays the lowest-cost\nof a $u$-$v$ path under the pricing $p$, or 0, if this exceeds their budget\n$b$. We study this problem for the case where $G$ is a bounded-width grid graph\nand give a polynomial-time approximation algorithm with approximation ratio\n$O(\\log |E|)$. Our approach combines existing ideas with new insights. Most\nnotably, we employ a rather seldom-encountered technique that we coin under the\nname 'assume-implement dynamic programming.' This technique involves dynamic\nprogramming where some information about the future decisions of the dynamic\nprogram is guessed in advance and 'assumed' to hold, and then subsequent\ndecisions are forced to 'implement' the guess. This enables computing the cost\nof the current transition by using information that would normally only be\navailable in the future.",
    "pdf_url": "http://arxiv.org/pdf/2502.11979v1",
    "published": "2025-02-17T16:22:28+00:00",
    "categories": [
      "cs.DS",
      "cs.GT"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11978v3",
    "title": "Multi-mode Pulsations in AGB Stars: Insights from 3D RHD CO5BOLD Simulations",
    "authors": [
      "Arief Ahmad",
      "Bernd Freytag",
      "Susanne HÃ¶fner"
    ],
    "abstract": "Stars on the AGB can exhibit acoustic pulsation modes of different radial\norders, along with non-radial modes. These pulsations are essential to the\nmass-loss process and influence the evolutionary pathways of AGB stars. P-L\nrelations serve as a valuable diagnostic for understanding stellar evolution\nalong the AGB. 3D RHD simulations provide a powerful tool for investigating\npulsation phenomena driven by convective processes and their non-linear\ncoupling with stellar oscillations. We investigate multi-mode pulsations in AGB\nstars using advanced 3D 'star-in-a-box' simulations with the CO5BOLD code.\nSignatures of these multi-mode pulsations were weak in our previous 3D models.\nOur focus is on identifying and characterising the various pulsation modes,\nexamining their persistence and transitions, and comparing the results with 1D\nmodel predictions and observational data where applicable. We produced a new\nmodel grid comprising AGB stars with current masses of $0.7$, $0.8$, and\n$1\\,\\mathrm{M}_{\\odot}$. Fourier analysis was applied to dynamic,\ntime-dependent quantities to extract dominant pulsation modes and their\ncorresponding periods. Additionally, wavelet transforms were employed to\nidentify mode-switching behaviour over time. The models successfully reproduce\nthe P-L sequences found in AGB stars. Mode-switching phenomena are found in\nboth the models and wavelet analyses of observational data, allowing us to\ninfer similarities in the underlying pulsation dynamics. These 3D simulations\nhighlight the natural emergence of multi-mode pulsations, including both radial\nand non-radial modes, driven by the self-consistent interplay of convection and\noscillations. Our findings underscore the value of 3D RHD models in capturing\nthe non-linear behaviour of AGB pulsations, providing insights into mode\nswitching, envelope structures, and potential links to episodic mass-loss\nevents.",
    "pdf_url": "http://arxiv.org/pdf/2502.11978v3",
    "published": "2025-02-17T16:22:25+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11977v1",
    "title": "Identification of Polytypism and Their Dislocations in Bilayer MoS2 Using Correlative Transmission Electron Microscopy and Raman Spectroscopy",
    "authors": [
      "Xin Zhou",
      "Tobias Dierke",
      "Mingjian Wu",
      "Shengbo You",
      "Klaus GÃ¶tz",
      "Tobias Unruh",
      "Philipp Pelz",
      "Johannes Will",
      "Janina Maultzsch",
      "Erdmann Spiecker"
    ],
    "abstract": "Stacking orders and topological defects substantially influence the physical\nproperties of 2D van der Waals (vdW) materials. However, the inherent features\nof 2D materials challenge the effectiveness of single characterization\ntechniques in identifying stacking sequences, necessitating correlative\napproaches. Using bilayer MoS2 as a benchmark, we differentiate its polytypism\nand specific dislocations through transmission electron microscopy (TEM) and\nRaman spectroscopy. Perfect and partial dislocations were revealed in TEM,\nwhich are closely linked to the stacking sequences, thus indirectly indicating\nthe 2H and 3R polytypes. 3D electron diffraction reconstruction on relrods and\nlow-frequency Raman spectroscopy further validated these polytypes owing to\ntheir reliance on crystal symmetry. Surprisingly, we unexpectedly resolved both\npolytypes despite starting with 2H bulk crystal, pointing to a possible phase\ntransition during mechanical exfoliation. The correlative TEM-Raman approach\ncan be extended to other 2D materials, paving the way for property alteration\nvia stacking and defect engineering.",
    "pdf_url": "http://arxiv.org/pdf/2502.11977v1",
    "published": "2025-02-17T16:22:23+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11976v3",
    "title": "Constraining first-order phase transition inside neutron stars with application of Bayesian techniques on PSR J0437-4715 NICER data",
    "authors": [
      "Chun Huang",
      "Shashwat Sourav"
    ],
    "abstract": "Understanding the existence of exotic matter phases and phase transitions\nwithin the core of neutron stars is crucial to advancing our knowledge of\ncold-dense matter physics. Recent multi-messenger observations, including\ngravitational waves from neutron star mergers and precise X-ray data from\nNASA's Neutron Star Interior Composition Explorer (NICER) mission, have\nsignificantly constrained the neutron star equation of state (EOS). This study\ninvestigates the effects of phase transitions in neutron stars, focusing on\nNICER's latest observation of PSR J0437--4715. We employ Bayesian inference\ntechniques to evaluate the presence of first-order phase transitions using a\npiecewise polytropic EOS model. Our analysis incorporates data from multiple\nNICER sources, to refine constraints on key phase transition parameters,\nincluding critical density and transition depth. We find that including data\nfrom PSR J0437--4715 improves the evidence of phase transitions and tightens\nthe EOS constraints, especially at higher densities. However, Bayes factor\nanalysis only indicates a slight preference for models without phase\ntransitions and current observational precision is insufficient to draw\ndefinitive conclusions. In particular, this polytropic model identifies the\ncritical phase transition mass of neutron stars as being close to 1.4 solar\nmasses, which coincides with the approximate mass range of PSR J0437--4715.\nThis work emphasizes the importance of precise measurements of PSR J0437--4715\nfor deepening our understanding of neutron star interiors and exploring\npotential new physics at extreme densities.",
    "pdf_url": "http://arxiv.org/pdf/2502.11976v3",
    "published": "2025-02-17T16:22:09+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.SR",
      "nucl-th"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11975v1",
    "title": "Spatial decay of perturbations in hyperbolic equations with optimal boundary control",
    "authors": [
      "Benedikt Oppeneiger",
      "Manuel Schaller",
      "Karl Worthmann"
    ],
    "abstract": "Recently, domain-uniform stabilizability and detectability has been the\ncentral assumption %in order robustness results on the to ensure robustness in\nthe sense of exponential decay of spatially localized perturbations in\noptimally controlled evolution equations. In the present paper we analyze a\nchain of transport equations with boundary and point controls with regard to\nthis property. Both for Dirichlet and Neumann boundary and coupling conditions,\nwe show a necessary and sufficient criterion on control domains which allow for\nthe domain-uniform stabilization of this equation. We illustrate the results by\nmeans of a numerical example.",
    "pdf_url": "http://arxiv.org/pdf/2502.11975v1",
    "published": "2025-02-17T16:21:40+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11974v1",
    "title": "Image Inversion: A Survey from GANs to Diffusion and Beyond",
    "authors": [
      "Yinan Chen",
      "Jiangning Zhang",
      "Yali Bi",
      "Xiaobin Hu",
      "Teng Hu",
      "Zhucun Xue",
      "Ran Yi",
      "Yong Liu",
      "Ying Tai"
    ],
    "abstract": "Image inversion is a fundamental task in generative models, aiming to map\nimages back to their latent representations to enable downstream applications\nsuch as editing, restoration, and style transfer. This paper provides a\ncomprehensive review of the latest advancements in image inversion techniques,\nfocusing on two main paradigms: Generative Adversarial Network (GAN) inversion\nand diffusion model inversion. We categorize these techniques based on their\noptimization methods. For GAN inversion, we systematically classify existing\nmethods into encoder-based approaches, latent optimization approaches, and\nhybrid approaches, analyzing their theoretical foundations, technical\ninnovations, and practical trade-offs. For diffusion model inversion, we\nexplore training-free strategies, fine-tuning methods, and the design of\nadditional trainable modules, highlighting their unique advantages and\nlimitations. Additionally, we discuss several popular downstream applications\nand emerging applications beyond image tasks, identifying current challenges\nand future research directions. By synthesizing the latest developments, this\npaper aims to provide researchers and practitioners with a valuable reference\nresource, promoting further advancements in the field of image inversion. We\nkeep track of the latest works at https://github.com/RyanChenYN/ImageInversion",
    "pdf_url": "http://arxiv.org/pdf/2502.11974v1",
    "published": "2025-02-17T16:20:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11973v1",
    "title": "Generating Text from Uniform Meaning Representation",
    "authors": [
      "Emma Markle",
      "Reihaneh Iranmanesh",
      "Shira Wein"
    ],
    "abstract": "Uniform Meaning Representation (UMR) is a recently developed graph-based\nsemantic representation, which expands on Abstract Meaning Representation (AMR)\nin a number of ways, in particular through the inclusion of document-level\ninformation and multilingual flexibility. In order to effectively adopt and\nleverage UMR for downstream tasks, efforts must be placed toward developing a\nUMR technological ecosystem. Though still limited amounts of UMR annotations\nhave been produced to date, in this work, we investigate the first approaches\nto producing text from multilingual UMR graphs: (1) a pipeline conversion of\nUMR to AMR, then using AMR-to-text generation models, (2) fine-tuning large\nlanguage models with UMR data, and (3) fine-tuning existing AMR-to-text\ngeneration models with UMR data. Our best performing model achieves a\nmultilingual BERTscore of 0.825 for English and 0.882 for Chinese when compared\nto the reference, which is a promising indication of the effectiveness of\nfine-tuning approaches for UMR-to-text generation with even limited amounts of\nUMR data.",
    "pdf_url": "http://arxiv.org/pdf/2502.11973v1",
    "published": "2025-02-17T16:20:22+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11972v2",
    "title": "Waveguide QED Analysis of Quantum-Coherent Links for Modular Quantum Computing",
    "authors": [
      "Junaid Khan",
      "Sergio Navarro Reyes",
      "Sahar Ben Rached",
      "Eduard Alarcon",
      "Peter Haring Bolivar",
      "Carmen G. Almudever",
      "Sergi Abadal"
    ],
    "abstract": "Waveguides potentially offer an effective medium for interconnecting quantum\nprocessors within a modular framework, facilitating the coherent quantum state\ntransfer between the qubits across separate chips. In this work, we analyze a\nquantum communication scenario where two qubits are connected to a shared\nwaveguide, whose resonance frequency may match or not match that of the qubits.\nBoth configurations are simulated from the perspective of quantum\nelectrodynamics (QED) to assess the system behavior and key factors that\ninfluence reliable inter-chip communication. The primary performance metrics\nanalyzed are quantum state transfer fidelity and latency, considering the\nimpact of key system parameters such as the qubit-waveguide detuning, coupling\nstrength, waveguide decay rate, and qubit decay rate. We present the system\ndesign requirements that yield enhanced state transmission fidelity rates and\nlowered latency, and discuss the scalability of waveguide-mediated\ninterconnects considering various configurations of the system.",
    "pdf_url": "http://arxiv.org/pdf/2502.11972v2",
    "published": "2025-02-17T16:20:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11971v4",
    "title": "Robust 6DoF Pose Tracking Considering Contour and Interior Correspondence Uncertainty for AR Assembly Guidance",
    "authors": [
      "Jixiang Chen",
      "Jing Chen",
      "Kai Liu",
      "Haochen Chang",
      "Shanfeng Fu",
      "Jian Yang"
    ],
    "abstract": "Augmented reality assembly guidance is essential for intelligent\nmanufacturing and medical applications, requiring continuous measurement of the\n6DoF poses of manipulated objects. Although current tracking methods have made\nsignificant advancements in accuracy and efficiency, they still face challenges\nin robustness when dealing with cluttered backgrounds, rotationally symmetric\nobjects, and noisy sequences. In this paper, we first propose a robust\ncontour-based pose tracking method that addresses error-prone contour\ncorrespondences and improves noise tolerance. It utilizes a fan-shaped search\nstrategy to refine correspondences and models local contour shape and noise\nuncertainty as mixed probability distribution, resulting in a highly robust\ncontour energy function. Secondly, we introduce a CPU-only strategy to better\ntrack rotationally symmetric objects and assist the contour-based method in\novercoming local minima by exploring sparse interior correspondences. This is\nachieved by pre-sampling interior points from sparse viewpoint templates\noffline and using the DIS optical flow algorithm to compute their\ncorrespondences during tracking. Finally, we formulate a unified energy\nfunction to fuse contour and interior information, which is solvable using a\nre-weighted least squares algorithm. Experiments on public datasets and real\nscenarios demonstrate that our method significantly outperforms\nstate-of-the-art monocular tracking methods and can achieve more than 100 FPS\nusing only a CPU.",
    "pdf_url": "http://arxiv.org/pdf/2502.11971v4",
    "published": "2025-02-17T16:18:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11970v1",
    "title": "A novel method to determine the layer number of 2D TMD materials based on Optical Microscopy and Image Processing",
    "authors": [
      "Bilal Bera Meric",
      "Ayse Erol",
      "Fahrettin Sarcan"
    ],
    "abstract": "Two-dimensional (2D) transition metal dicakcoganite (TMD) materials have\nunique electronic and optical properties. The electronic band structures of the\nmaterials alter as a function of layer numbers, which results in modifications\nto the whole characteristic properties. Therefore, the determination of the\nlayer number is crucial for optoelectronic applications. In this study, a fast\nand easily applicable method is proposed for determining the layer number of\ntwo-dimensional TMD materials by using an optical microscopy and computatial\nmethods. The method uses image processing techniques on digital images taken\nwith a Complementary Metal Oxide Semiconductor (CMOS) camera under a\nconventional reflecting microscope. The chromaticity differences and lightness\ndifference in International Commission on Illumination (Commission\ninternationale de ,CIE) Luv color space values between the layered areas on the\nflakes and substrates are used together to train the model to be identified the\nlayer numbers of the materials and corrected via photoluminescence\nspectroscopy. The random forest clasifier algorithm is applied to predict layer\nnumbers on unknown materials. This approach provides high accuracy under\nvarying microscope configurations such as brightnesses, gain etc. and\nmaterial-substrate combinations. From ML to bulk whole layers numbers of MoS2,\nWSe2 and WS2 flakes are determined with high accuracy by training only a single\nflake of each has various layer numbers. Compared with traditional methods such\nas Raman spectroscopy, atomic force microscopy (AFM) and photoluminescence\n(PL), our method is not only faster but also easier to apply. Moreover, unlike\nthe prominent methods in the literature such as machine learning or\nclustering-based, it requires only single training for a material/substrate\ncombination and further accelerates the processes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11970v1",
    "published": "2025-02-17T16:18:50+00:00",
    "categories": [
      "physics.app-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11969v1",
    "title": "Learning Generalizable Prompt for CLIP with Class Similarity Knowledge",
    "authors": [
      "Sehun Jung",
      "Hyang-won Lee"
    ],
    "abstract": "In vision-language models (VLMs), prompt tuning has shown its effectiveness\nin adapting models to downstream tasks. However, learned prompts struggle to\ngeneralize to unseen classes, as they tend to overfit to the classes that are\ntargeted during prompt tuning. Examining failure cases, we observed that\nlearned prompts disrupt the semantics of unseen classes, generating text\nembeddings with incorrect semantic relationships among classes. To address\nthis, we propose Similarity Alignment Regularization (SAR), which regularizes\nlearnable prompts to preserve the semantic relationships among classes captured\nby hand-crafted prompts. Specifically, we first obtain novel classes related to\nbase classes using ChatGPT-4o and utilize them as potential unseen classes\nduring prompt tuning. Then, by targeting both base and novel classes, SAR\naligns the similarity relationships among text embeddings generated by\nlearnable prompts with the similarity relationships from hand-crafted prompts.\nExtensive experiments applying SAR to existing prompt tuning methods\ndemonstrate its effectiveness in improving generalization to unseen classes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11969v1",
    "published": "2025-02-17T16:18:07+00:00",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11968v1",
    "title": "Theoretical Barriers in Bellman-Based Reinforcement Learning",
    "authors": [
      "Brieuc Pinon",
      "RaphaÃ«l Jungers",
      "Jean-Charles Delvenne"
    ],
    "abstract": "Reinforcement Learning algorithms designed for high-dimensional spaces often\nenforce the Bellman equation on a sampled subset of states, relying on\ngeneralization to propagate knowledge across the state space. In this paper, we\nidentify and formalize a fundamental limitation of this common approach.\nSpecifically, we construct counterexample problems with a simple structure that\nthis approach fails to exploit. Our findings reveal that such algorithms can\nneglect critical information about the problems, leading to inefficiencies.\nFurthermore, we extend this negative result to another approach from the\nliterature: Hindsight Experience Replay learning state-to-state reachability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11968v1",
    "published": "2025-02-17T16:18:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11967v1",
    "title": "Floquet topological state induced by light-driven band inversion in SnTe",
    "authors": [
      "F. Chassot",
      "G. Kremer",
      "A. Pulkkinen",
      "C. Wang",
      "J. Krempasky",
      "J. Minar",
      "G. Springholz",
      "M. Puppin",
      "J. H. Dil",
      "C. Monney"
    ],
    "abstract": "High intensity coherent light can dress matter, realizing new hybrid phases\nthat are not accessible in equilibrium. This effect results from the coherent\ninteraction between Bloch states inside the solid and the periodic field of\nimpinging photons which produces hybrid light-matter states called\nFloquet-Bloch states that can alter properties of the solid. Optically inducing\na topological state in a semiconductor using so-called Floquet engineering is\nan exciting prospect. However, it has not been realized, despite its\ntheoretical prediction more than 10 years ago. Here we show that an\nultrashort-lived topological state that is absent at equilibrium in the ground\nstate of SnTe can be created with femtosecond light pulses. This occurs when\nthe photoexcitation is similar in energy with the band gap of this polar\nsemiconductor. We observe a concomitant renormalization of the band dispersions\nthat reveals the generation of Floquet states connecting to the topological\nstate. We therefore provide the first direct experimental observation of a\nFloquet topological state and propose that it is driven by a light-induced band\ninversion in SnTe. Our discovery opens the way for controlling optically\non-demand the topological properties of semiconductors.",
    "pdf_url": "http://arxiv.org/pdf/2502.11967v1",
    "published": "2025-02-17T16:16:16+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11966v1",
    "title": "Non-particle dark matter",
    "authors": [
      "Anne M. Green"
    ],
    "abstract": "We provide a pedagogical introduction to non-particle dark matter, focused on\nprimordial black holes (PBHs), black holes that may form in the early Universe\nfrom large overdensities. First, we outline the key properties of PBHs and how\nthey meet the requirements to be a dark matter candidate. We then overview how\nPBHs can form, in particular from the collapse of large density perturbations\ngenerated by inflation (a proposed period of accelerated expansion in the early\nUniverse). Next, we describe how PBHs can be probed by observations. Finally,\nwe conclude with a summary focused on the key open questions in the field.",
    "pdf_url": "http://arxiv.org/pdf/2502.11966v1",
    "published": "2025-02-17T16:15:07+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11965v2",
    "title": "A MIMO Wireless Channel Foundation Model via CIR-CSI Consistency",
    "authors": [
      "Jun Jiang",
      "Wenjun Yu",
      "Yunfan Li",
      "Yuan Gao",
      "Shugong Xu"
    ],
    "abstract": "In the field of artificial intelligence, self-supervised learning has\ndemonstrated superior generalization capabilities by leveraging large-scale\nunlabeled datasets for pretraining, which is especially critical for wireless\ncommunication models to adapt to a variety of scenarios. This paper\ninnovatively treats Channel State Information (CSI) and Channel Impulse\nResponse (CIR) as naturally aligned multi-modal data and proposes the first\nMIMO wireless channel foundation model, named CSI-CLIP. By effectively\ncapturing the joint representations of both CIR and CSI, CSI-CLIP exhibits\nremarkable adaptability across scenarios and robust feature extraction\ncapabilities. Experimental results show that in positioning task, CSI-CLIP\nreduces the mean error distance by 22%; in beam management task, it increases\naccuracy by 1% compared to traditional supervised methods, as well as in the\nchannel identification task. These improvements not only highlight the\npotential and value of CSI-CLIP in integrating sensing and communication but\nalso demonstrate its significant advantages over existing techniques. Moreover,\nviewing CSI and CIR as multi-modal pairs and contrastive learning for wireless\nchannel foundation model open up new research directions in the domain of MIMO\nwireless communications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11965v2",
    "published": "2025-02-17T16:13:40+00:00",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11964v2",
    "title": "Transaction Fee Market Design for Parallel Execution",
    "authors": [
      "Bahar Acilan",
      "Andrei Constantinescu",
      "Lioba Heimbach",
      "Roger Wattenhofer"
    ],
    "abstract": "Given the low throughput of blockchains like Bitcoin and Ethereum,\nscalability - the ability to process an increasing number of transactions - has\nbecome a central focus of blockchain research. One promising approach is the\nparallelization of transaction execution across multiple threads. However,\nachieving efficient parallelization requires a redesign of the incentive\nstructure within the fee market. Currently, the fee market does not\ndifferentiate between transactions that access multiple high-demand storage\nkeys (i.e., unique identifiers for individual data entries) versus a single\nlow-demand one, as long as they require the same computational effort.\nAddressing this discrepancy is crucial for enabling more effective parallel\nexecution.\n  In this work, we aim to bridge the gap between the current fee market and the\nneed for parallel execution by exploring alternative fee market designs. To\nthis end, we propose a framework consisting of two key components: a Gas\nComputation Mechanism (GCM), which quantifies the load a transaction places on\nthe network in terms of parallelization and computation, measured in units of\ngas, and a Transaction Fee Mechanism (TFM), which assigns a price to each unit\nof gas. We additionally introduce a set of desirable properties for a GCM,\npropose several candidate mechanisms, and evaluate them against these criteria.\nOur analysis highlights two strong candidates: the weighted area GCM, which\nintegrates smoothly with existing TFMs such as EIP-1559 and satisfies a broad\nsubset of the outlined properties, and the time-proportional makespan GCM,\nwhich assigns gas costs based on the context of the entire block's schedule\nand, through this dependence on the overall execution outcome, captures the\ndynamics of parallel execution more accurately.",
    "pdf_url": "http://arxiv.org/pdf/2502.11964v2",
    "published": "2025-02-17T16:11:00+00:00",
    "categories": [
      "cs.GT",
      "cs.DC"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11963v1",
    "title": "Weyl and Dirac Semimetals for Thermoelectric Applications",
    "authors": [
      "Saurabh Singh",
      "Sarmistha Das",
      "Shiv Kumar"
    ],
    "abstract": "Weyl and Dirac semimetals, characterized by their unique band structures with\nlinear energy dispersion (E vs k) near the Fermi level (EF), have emerged as\npromising candidates for next-generation technology based on thermoelectric\nmaterials. Their exceptional electronic properties, notably high carrier\nmobility and substantial Berry curvature, offer the potential to surmount the\nlimitations inherent in conventional thermoelectric materials. A comprehensive\nunderstanding of the fundamental physics underlying these materials is\nessential. This chapter mainly focused into the topological properties and\ndistinctive electronic band structures of Weyl and Dirac semimetals, providing\na theoretical framework for comprehending their thermoelectric transport\nproperties such as Seebeck coefficients, electrical and thermal conductivity.\nThe pivotal role of Berry curvature in enhancing Seebeck coefficients while\nreducing thermal conductivity is a key focus. Experimental advancements in\nsynthesizing single crystals and characterizing these materials have been\nsignificant. Recent development in material growth and characterization\ntechniques have propelled research forward. The intricate relationship between\nmaterial properties, such as carrier concentration, electronic bandgap, and\ncrystal structure, and thermoelectric performance is explored. Realizing the\npotential of Weyl and Dirac semimetals for practical thermoelectric\napplications necessitates overcoming specific challenges. This chapter outlines\nstrategies to optimize thermoelectric figures of merit (ZT) through band\nengineering, carrier doping, and nanostructuring. Moreover, the exploration of\nhybrid materials and heterostructures offers promising avenues for enhancing\nthermoelectric performance for renewable energy applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11963v1",
    "published": "2025-02-17T16:10:47+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11962v3",
    "title": "Balancing Truthfulness and Informativeness with Uncertainty-Aware Instruction Fine-Tuning",
    "authors": [
      "Tianyi Wu",
      "Jingwei Ni",
      "Bryan Hooi",
      "Jiaheng Zhang",
      "Elliott Ash",
      "See-Kiong Ng",
      "Mrinmaya Sachan",
      "Markus Leippold"
    ],
    "abstract": "Instruction fine-tuning (IFT) can increase the informativeness of large\nlanguage models (LLMs), but may reduce their truthfulness. This trade-off\narises because IFT steers LLMs to generate responses containing long-tail\nknowledge that was not well covered during pre-training. As a result, models\nbecome more informative but less accurate when generalizing to unseen tasks. In\nthis paper, we empirically demonstrate how unfamiliar knowledge in IFT datasets\ncan negatively affect the truthfulness of LLMs, and we introduce two new IFT\nparadigms, $UNIT_{cut}$ and $UNIT_{ref}$, to address this issue. $UNIT_{cut}$\nidentifies and removes unfamiliar knowledge from IFT datasets to mitigate its\nimpact on model truthfulness, whereas $UNIT_{ref}$ trains LLMs to recognize\ntheir uncertainty and explicitly indicate it at the end of their responses. Our\nexperiments show that $UNIT_{cut}$ substantially improves LLM truthfulness,\nwhile $UNIT_{ref}$ maintains high informativeness and reduces hallucinations by\ndistinguishing between confident and uncertain statements.",
    "pdf_url": "http://arxiv.org/pdf/2502.11962v3",
    "published": "2025-02-17T16:10:30+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11961v1",
    "title": "Parameterised algorithms for temporal reconfiguration problems",
    "authors": [
      "Tom Davot",
      "Jessica Enright",
      "Laura Larios-Jones"
    ],
    "abstract": "Given a static vertex-selection problem (e.g. independent set, dominating\nset) on a graph, we can define a corresponding temporal reconfiguration problem\non a temporal graph which asks for a sequence of solutions to the\nvertex-selection problem at each time such that we can reconfigure from one\nsolution to the next. We can think of each solution in the sequence as a set of\nvertices with tokens placed on them; our reconfiguration model allows us to\nslide tokens along active edges of a temporal graph.\n  We show that it is possible to efficiently check whether one solution can be\nreconfigured to another, and show that approximation results on the static\nvertex-selection problem can be adapted with a lifetime factor to the\nreconfiguration version. Our main contributions are fixed-parameter tractable\nalgorithms with respect to: enumeration time of the related static problem; the\ncombination of temporal neighbourhood diversity and lifetime of the input\ngraph; and the combination of lifetime and treewidth of the footprint graph.",
    "pdf_url": "http://arxiv.org/pdf/2502.11961v1",
    "published": "2025-02-17T16:09:00+00:00",
    "categories": [
      "cs.DS",
      "cs.DM",
      "math.CO"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11960v1",
    "title": "Seamless short- to mid-term probabilistic wind power forecasting",
    "authors": [
      "Gabriel Dantas",
      "Jethro Browell"
    ],
    "abstract": "This paper presents a method for probabilistic wind power forecasting that\nquantifies and integrates uncertainties from weather forecasts and\nweather-to-power conversion. By addressing both uncertainty sources, the method\nachieves state-of-the-art results for lead times of 6 to 162 hours, eliminating\nthe need for separate models for short- and mid-term forecasting. It also\nimproves short-term forecasts during high weather uncertainty periods, which\nmethods based on deterministic weather forecasts fail to capture. The study\nreveals that weather-to-power uncertainty is more significant for short-term\nforecasts, while weather forecast uncertainty dominates mid-term forecasts,\nwith the transition point varying between wind farms. Offshore farms typically\nsee this shift at shorter lead times than onshore ones. The findings are\nsupported by an extensive, reproducible case study comprising 73 wind farms in\nGreat Britain over five years.",
    "pdf_url": "http://arxiv.org/pdf/2502.11960v1",
    "published": "2025-02-17T16:07:28+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11959v1",
    "title": "STRIVE: Structured Reasoning for Self-Improvement in Claim Verification",
    "authors": [
      "Haisong Gong",
      "Jing Li",
      "Junfei Wu",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ],
    "abstract": "Claim verification is the task of determining whether a claim is supported or\nrefuted by evidence. Self-improvement methods, where reasoning chains are\ngenerated and those leading to correct results are selected for training, have\nsucceeded in tasks like mathematical problem solving. However, in claim\nverification, this approach struggles. Low-quality reasoning chains may falsely\nmatch binary truth labels, introducing faulty reasoning into the\nself-improvement process and ultimately degrading performance. To address this,\nwe propose STRIVE: Structured Reasoning for Self-Improved Verification. Our\nmethod introduces a structured reasoning design with Claim Decomposition,\nEntity Analysis, and Evidence Grounding Verification. These components improve\nreasoning quality, reduce errors, and provide additional supervision signals\nfor self-improvement. STRIVE begins with a warm-up phase, where the base model\nis fine-tuned on a small number of annotated examples to learn the structured\nreasoning design. It is then applied to generate reasoning chains for all\ntraining examples, selecting only those that are correct and structurally sound\nfor subsequent self-improvement training. We demonstrate that STRIVE achieves\nsignificant improvements over baseline models, with a 31.4% performance gain\nover the base model and 20.7% over Chain of Thought on the HOVER datasets,\nhighlighting its effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2502.11959v1",
    "published": "2025-02-17T16:07:07+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11958v1",
    "title": "Probing late-time annihilations of oscillating asymmetric dark matter via rotation curves of galaxies",
    "authors": [
      "JÃºlia G. Mamprim",
      "Guillermo Gambini",
      "Luan B. Arbeletche",
      "Marcos Olegario",
      "Vitor de Souza"
    ],
    "abstract": "In this paper, we explore the Oscillating Asymmetric Dark Matter (OADM) model\nto address the core-cusp problem, aiming to resolve the discrepancy between the\npredictions of the $\\Lambda\\rm{CDM}$ cosmological model and the observed dark\nmatter profiles in dwarf spheroidal galaxies. The reactivation of dark matter\nannihilation during the structure formation epoch is possible if there is a\nsmall Majorana mass term that breaks the conservation of dark matter particle\nnumber, leading to oscillations between dark matter and its antiparticle. We\nanalyzed the effects of the annihilation mechanism in the galaxy rotation\ncurves of the SPARC and LITTLE THINGS catalogs. We searched for the\ncharacteristics of the OADM model which best describes the data. Our results\nshow that the OADM model can successfully turn originally cusp-type halos into\ncore-type ones according to our data sample.",
    "pdf_url": "http://arxiv.org/pdf/2502.11958v1",
    "published": "2025-02-17T16:06:16+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11957v1",
    "title": "The Ultraviolet Type Ia Supernova CubeSat (UVIa): Science Motivation & Mission Concept",
    "authors": [
      "Keri Hoadley",
      "Curtis McCully",
      "Gillian Kyne",
      "Fernando Cruz Aguirre",
      "Moira Andrews",
      "Christophe Basset",
      "K. Azalee Bostroem",
      "Peter J. Brown",
      "Greyson Davis",
      "Erika T. Hamden",
      "Daniel Harbeck",
      "John Hennessy",
      "Michael Hoenk",
      "Griffin Hosseinzadeh",
      "D. Andrew Howell",
      "April Jewell",
      "Saurabh Jha",
      "Jessica Li",
      "Peter Milne",
      "Leonidas Moustakas",
      "Shouleh Nikzad",
      "Craig Pellegrino",
      "Abigail Polin",
      "David J. Sand",
      "Ken J. Shen",
      "Lisa Storrie-Lombardi"
    ],
    "abstract": "The Ultraviolet (UV) Type Ia Supernova CubeSat (UVIa) is a CubeSat/SmallSat\nmission concept that stands to test critical space-borne UV technology for\nfuture missions like the Habitable Worlds Observatory (HWO) while elucidating\nlong-standing questions about the explosion mechanisms of Type Ia supernovae\n(SNe Ia). UVIa will observe whether any SNe Ia emit excess UV light shortly\nafter explosion to test progenitor/explosion models and provide follow-up over\nmany days to characterize their UV and optical flux variations over time,\nassembling a comprehensive multi-band UV and optical low-redshift anchor sample\nfor upcoming high-redshift SNe Ia surveys (e.g., Euclid, Vera Rubin\nObservatory, Nancy Roman Space Telescope). UVIa's mission profile requires it\nto perform rapid and frequent visits to newly discovered SNe Ia, simultaneously\nobserving each SNe Ia in two UV bands (FUV: 1500-1800A and NUV: 1800-2400A) and\none optical band (u-band: 3000-4200A). In this study, we describe the UVIa\nmission concept science motivation, mission design, and key technology\ndevelopment.",
    "pdf_url": "http://arxiv.org/pdf/2502.11957v1",
    "published": "2025-02-17T16:06:01+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2502.11956v3",
    "title": "Unitality Conditions on Subsystems in Quantum Dynamics",
    "authors": [
      "Anumita Mukhopadhyay",
      "Shibdas Roy",
      "Arun Kumar Pati"
    ],
    "abstract": "It is known that non-unital noise such as the amplitude damping can sometimes\nincrease quantum correlations, while unital noise such as the dephasing usually\ndecreases quantum correlations. It is, therefore, important to delineate the\nconditions, when noise can enhance the quantumness of the system. Here, we show\nthat if the noise acting on the system is unital (non-unital), then the noise\nacting on the environment must also be unital (non-unital), for the evolution\nto be unitary in the joint system-environment space. For example, if the first\ntwo qubits are treated as system and the third qubit is treated as environment,\nthen both the system and the environment evolve unitally in case of a\nthree-qubit GHZ state, and both of them evolve non-unitally in case of a\nthree-qubit W state. Our result may be of interest in quantum information, and\nwe anticipate it to be useful in various contexts, such as to better tackle\nnoise in quantum computing and quantum information processing.",
    "pdf_url": "http://arxiv.org/pdf/2502.11956v3",
    "published": "2025-02-17T16:05:55+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11955v3",
    "title": "pySLAM: An Open-Source, Modular, and Extensible Framework for SLAM",
    "authors": [
      "Luigi Freda"
    ],
    "abstract": "pySLAM is an open-source Python framework for Visual SLAM that supports\nmonocular, stereo, and RGB-D camera inputs. It offers a flexible and modular\ninterface, integrating a broad range of both classical and learning-based local\nfeatures. The framework includes multiple loop closure strategies, a volumetric\nreconstruction pipeline, and support for depth prediction models. It also\noffers a comprehensive set of tools for experimenting with and evaluating\nvisual odometry and SLAM modules. Designed for both beginners and experienced\nresearchers, pySLAM emphasizes rapid prototyping, extensibility, and\nreproducibility across diverse datasets. Its modular architecture facilitates\nthe integration of custom components and encourages research that bridges\ntraditional and deep learning-based approaches. Community contributions are\nwelcome, fostering collaborative development and innovation in the field of\nVisual SLAM. This document presents the pySLAM framework, outlining its main\ncomponents, features, and usage.",
    "pdf_url": "http://arxiv.org/pdf/2502.11955v3",
    "published": "2025-02-17T16:05:31+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11954v1",
    "title": "On a Semiparametric Stochastic Volatility Model",
    "authors": [
      "Yudong Feng",
      "Ashis Gangopadhyay"
    ],
    "abstract": "This paper presents a novel approach to stochastic volatility (SV) modeling\nby utilizing nonparametric techniques that enhance our ability to capture the\nvolatility of financial time series data, with a particular emphasis on the\nnon-Gaussian behavior of asset return distributions. Although traditional\nparametric SV models can be useful, they often suffer from restrictive\nassumptions regarding errors, which may inadequately represent extreme values\nand tail behavior in financial returns. To address these limitations, we\npropose two semiparametric SV models that use data to better approximate error\ndistributions. To facilitate the computation of model parameters, we developed\na Markov Chain Monte Carlo (MCMC) method for estimating model parameters and\nvolatility dynamics. Simulations and empirical tests on S&P 500 data indicate\nthat nonparametric models can minimize bias and variance in volatility\nestimation, providing a more accurate reflection of market expectations about\nvolatility. This methodology serves as a promising alternative to conventional\nparametric models, improving precision in financial risk assessment and\ndeepening our understanding of the volatility dynamics of financial returns.",
    "pdf_url": "http://arxiv.org/pdf/2502.11954v1",
    "published": "2025-02-17T16:05:22+00:00",
    "categories": [
      "stat.CO",
      "stat.AP"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11953v1",
    "title": "Refined PAC-Bayes Bounds for Offline Bandits",
    "authors": [
      "Amaury Gouverneur",
      "Tobias J. Oechtering",
      "Mikael Skoglund"
    ],
    "abstract": "In this paper, we present refined probabilistic bounds on empirical reward\nestimates for off-policy learning in bandit problems. We build on the\nPAC-Bayesian bounds from Seldin et al. (2010) and improve on their results\nusing a new parameter optimization approach introduced by Rodr\\'iguez et al.\n(2024). This technique is based on a discretization of the space of possible\nevents to optimize the \"in probability\" parameter. We provide two\nparameter-free PAC-Bayes bounds, one based on Hoeffding-Azuma's inequality and\nthe other based on Bernstein's inequality. We prove that our bounds are almost\noptimal as they recover the same rate as would be obtained by setting the \"in\nprobability\" parameter after the realization of the data.",
    "pdf_url": "http://arxiv.org/pdf/2502.11953v1",
    "published": "2025-02-17T16:05:14+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.11952v1",
    "title": "A characterization of generalized Lipschitz classes by the rate of convergence of semi-discrete operators",
    "authors": [
      "Danilo Costarelli",
      "Michele Piconi",
      "Gianluca Vinti"
    ],
    "abstract": "In this paper, we establish a comprehensive characterization of the\ngeneralized Lipschitz classes through the study of the rate of convergence of a\nfamily of semi-discrete sampling operators, of Durrmeyer type, in\n$L^p$-setting. To achieve this goal, we provide direct approximation results,\nwhich lead to quantitative estimates based on suitable $K$-functionals in\nSobolev spaces and, consequently, on higher-order moduli of smoothness.\nAdditionally, we introduce a further approach employing the celebrated\nHardy-Littlewood maximal inequality to weaken the assumptions required on the\nkernel functions. These direct theorems are essential for obtaining qualitative\napproximation results in suitable Lipschitz and generalized Lipschitz classes,\nas they also provide conditions for studying the rate of convergence when\nfunctions belonging to Sobolev spaces are considered. The converse implication\nis, in general, delicate, and actually consists in addressing an inverse\napproximation problem allowing to deduce regularity properties of a function\nfrom a given rate of convergence. Thus, through both direct and inverse\nresults, we establish the desired characterization of the considered Lipschitz\nclasses based on the $L^p$-convergence rate of Durrmeyer sampling operators.\nFinally, we provide remarkable applications of the theory, based on suitable\ncombinations of kernels that satisfy the crucial Strang-Fix type condition used\nhere allowing to both enhance the rate of convergence and to predict the\nsignals.",
    "pdf_url": "http://arxiv.org/pdf/2502.11952v1",
    "published": "2025-02-17T16:04:54+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11951v2",
    "title": "Quantum Data Encoding and Variational Algorithms: A Framework for Hybrid Quantum Classical Machine Learning",
    "authors": [
      "Bhavna Bose",
      "Saurav Verma"
    ],
    "abstract": "The development of quantum computers has been the stimulus that enables the\nrealization of Quantum Machine Learning (QML), an area that integrates the\ncalculational framework of quantum mechanics with the adaptive properties of\nclassical machine learning. This article suggests a broad architecture that\nallows the connection between classical data pipelines and quantum algorithms,\nhybrid quantum-classical models emerge as a promising route to scalable and\nnear-term quantum benefit. At the core of this paradigm lies the\nClassical-Quantum (CQ) paradigm, in which the qubit states of high-dimensional\nclassical data are encoded using sophisticated classical encoding strategies\nwhich encode the data in terms of amplitude and angle of rotation, along with\nsuperposition mapping. These techniques allow compression of information\nexponentially into Hilbert space representations, which, together with reduced\nsample complexity, allows greater feature expressivity. We also examine\nvariational quantum circuits, quantum gates expressed as trainable variables\nthat run with classical optimizers to overcome decoherence, noise, and\ngate-depth constraints of the existing Noisy Intermediate-Scale Quantum (NISQ)\ndevices. Experimental comparisons with a Quantum Naive Bayes classifier prove\nthat even small quantum circuits can approximate probabilistic inference with\ncompetitive accuracy compared to classical benchmarks, and have much better\nrobustness to noisy data distributionsThis model does not only explain the\nalgorithmic and architectural design of QML, it also offers a roadmap to the\nimplementation of quantum kernels, variational algorithms, and hybrid feedback\nloops into practice, including optimization, computer vision, and medical\ndiagnostics. The results support the idea that hybrid architectures with strong\ndata encoding and adaptive error protection are key to moving QML out of theory\nto practice.",
    "pdf_url": "http://arxiv.org/pdf/2502.11951v2",
    "published": "2025-02-17T16:04:04+00:00",
    "categories": [
      "cs.CE",
      "cs.LG",
      "quant-ph"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11950v1",
    "title": "Chern-Simons invariants of hyperbolic three-manifolds, mixed Tate motives, and motivic path torsor of augmented character varieties",
    "authors": [
      "Dong Uk Lee"
    ],
    "abstract": "For any complete hyperbolic three-manifold of finite volume, we construct a\nmixed Tate motive defined over the invariant trace field whose image under\nBeilinson regulator equals the PSL2(C)-Chern-Simons invariant, thus equals the\ncomplex volume of the manifold, up to constant. Further, we show that when M\nhas single torus boundary, under some assumption on asymptotic behaviour of the\nChern-Simons invariant near an ideal point, its Hodge realization is a quotient\nof the mixed Hodge structure on the path torsor of the smooth locus of the\ncanonical curve component of the augmented character variety of the\nthree-manifold between a geometric point (giving the complete hyperbolic\nstructure) and some tangential base point at an ideal point whose existence is\nasserted by the assumption. We explain its motivic implication. In the\nappendix, we verify some cases of the assumption. The theory developed here is\nparallel to the motivic theory of polylogarithms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11950v1",
    "published": "2025-02-17T16:03:12+00:00",
    "categories": [
      "math.AG",
      "math.GT",
      "math.NT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11949v1",
    "title": "Massively Scaling Explicit Policy-conditioned Value Functions",
    "authors": [
      "Nico Bohlinger",
      "Jan Peters"
    ],
    "abstract": "We introduce a scaling strategy for Explicit Policy-Conditioned Value\nFunctions (EPVFs) that significantly improves performance on challenging\ncontinuous-control tasks. EPVFs learn a value function V({\\theta}) that is\nexplicitly conditioned on the policy parameters, enabling direct gradient-based\nupdates to the parameters of any policy. However, EPVFs at scale struggle with\nunrestricted parameter growth and efficient exploration in the policy parameter\nspace. To address these issues, we utilize massive parallelization with\nGPU-based simulators, big batch sizes, weight clipping and scaled peturbations.\nOur results show that EPVFs can be scaled to solve complex tasks, such as a\ncustom Ant environment, and can compete with state-of-the-art Deep\nReinforcement Learning (DRL) baselines like Proximal Policy Optimization (PPO)\nand Soft Actor-Critic (SAC). We further explore action-based policy parameter\nrepresentations from previous work and specialized neural network architectures\nto efficiently handle weight-space features, which have not been used in the\ncontext of DRL before.",
    "pdf_url": "http://arxiv.org/pdf/2502.11949v1",
    "published": "2025-02-17T16:02:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11948v3",
    "title": "HalluEntity: Benchmarking and Understanding Entity-Level Hallucination Detection",
    "authors": [
      "Min-Hsuan Yeh",
      "Max Kamachee",
      "Seongheon Park",
      "Yixuan Li"
    ],
    "abstract": "To mitigate the impact of hallucination nature of LLMs, many studies propose\ndetecting hallucinated generation through uncertainty estimation. However,\nthese approaches predominantly operate at the sentence or paragraph level,\nfailing to pinpoint specific spans or entities responsible for hallucinated\ncontent. This lack of granularity is especially problematic for long-form\noutputs that mix accurate and fabricated information. To address this\nlimitation, we explore entity-level hallucination detection. We propose a new\ndata set, HalluEntity, which annotates hallucination at the entity level. Based\non the dataset, we comprehensively evaluate uncertainty-based hallucination\ndetection approaches across 17 modern LLMs. Our experimental results show that\nuncertainty estimation approaches focusing on individual token probabilities\ntend to over-predict hallucinations, while context-aware methods show better\nbut still suboptimal performance. Through an in-depth qualitative study, we\nidentify relationships between hallucination tendencies and linguistic\nproperties and highlight important directions for future research.\n  HalluEntity: https://huggingface.co/datasets/samuelyeh/HalluEntity",
    "pdf_url": "http://arxiv.org/pdf/2502.11948v3",
    "published": "2025-02-17T16:01:41+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11947v2",
    "title": "Learning Automata with Name Allocation",
    "authors": [
      "Florian Frank",
      "Stefan Milius",
      "Jurriaan Rot",
      "Henning Urbat"
    ],
    "abstract": "Automata over infinite alphabets have emerged as a convenient computational\nmodel for processing structures involving data, such as nonces in cryptographic\nprotocols or data values in XML documents. We introduce active learning methods\nfor bar automata, a species of automata that process finite data words\nrepresented as bar strings, which are words with explicit name binding letters.\nBar automata have pleasant algorithmic properties. We develop a framework in\nwhich every learning algorithm for standard deterministic or nondeterministic\nfinite automata over finite alphabets can be used to learn bar automata, with a\nquery complexity determined by that of the chosen learner. The technical key to\nour approach is the algorithmic handling of $\\alpha$-equivalence of bar\nstrings, which allows to bridge the gap between finite and infinite alphabets.\nThe principles underlying our framework are generic and also apply to bar\nB\\\"uchi automata and bar tree automata, leading to the first active learning\nmethods for data languages of infinite words and finite trees.",
    "pdf_url": "http://arxiv.org/pdf/2502.11947v2",
    "published": "2025-02-17T15:59:38+00:00",
    "categories": [
      "cs.FL",
      "68Q45",
      "F.4.3"
    ],
    "primary_category": "cs.FL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11946v2",
    "title": "Step-Audio: Unified Understanding and Generation in Intelligent Speech Interaction",
    "authors": [
      "Ailin Huang",
      "Boyong Wu",
      "Bruce Wang",
      "Chao Yan",
      "Chen Hu",
      "Chengli Feng",
      "Fei Tian",
      "Feiyu Shen",
      "Jingbei Li",
      "Mingrui Chen",
      "Peng Liu",
      "Ruihang Miao",
      "Wang You",
      "Xi Chen",
      "Xuerui Yang",
      "Yechang Huang",
      "Yuxiang Zhang",
      "Zheng Gong",
      "Zixin Zhang",
      "Hongyu Zhou",
      "Jianjian Sun",
      "Brian Li",
      "Chengting Feng",
      "Changyi Wan",
      "Hanpeng Hu",
      "Jianchang Wu",
      "Jiangjie Zhen",
      "Ranchen Ming",
      "Song Yuan",
      "Xuelin Zhang",
      "Yu Zhou",
      "Bingxin Li",
      "Buyun Ma",
      "Hongyuan Wang",
      "Kang An",
      "Wei Ji",
      "Wen Li",
      "Xuan Wen",
      "Xiangwen Kong",
      "Yuankai Ma",
      "Yuanwei Liang",
      "Yun Mou",
      "Bahtiyar Ahmidi",
      "Bin Wang",
      "Bo Li",
      "Changxin Miao",
      "Chen Xu",
      "Chenrun Wang",
      "Dapeng Shi",
      "Deshan Sun",
      "Dingyuan Hu",
      "Dula Sai",
      "Enle Liu",
      "Guanzhe Huang",
      "Gulin Yan",
      "Heng Wang",
      "Haonan Jia",
      "Haoyang Zhang",
      "Jiahao Gong",
      "Junjing Guo",
      "Jiashuai Liu",
      "Jiahong Liu",
      "Jie Feng",
      "Jie Wu",
      "Jiaoren Wu",
      "Jie Yang",
      "Jinguo Wang",
      "Jingyang Zhang",
      "Junzhe Lin",
      "Kaixiang Li",
      "Lei Xia",
      "Li Zhou",
      "Liang Zhao",
      "Longlong Gu",
      "Mei Chen",
      "Menglin Wu",
      "Ming Li",
      "Mingxiao Li",
      "Mingliang Li",
      "Mingyao Liang",
      "Na Wang",
      "Nie Hao",
      "Qiling Wu",
      "Qinyuan Tan",
      "Ran Sun",
      "Shuai Shuai",
      "Shaoliang Pang",
      "Shiliang Yang",
      "Shuli Gao",
      "Shanshan Yuan",
      "Siqi Liu",
      "Shihong Deng",
      "Shilei Jiang",
      "Sitong Liu",
      "Tiancheng Cao",
      "Tianyu Wang",
      "Wenjin Deng",
      "Wuxun Xie",
      "Weipeng Ming",
      "Wenqing He",
      "Wen Sun",
      "Xin Han",
      "Xin Huang",
      "Xiaomin Deng",
      "Xiaojia Liu",
      "Xin Wu",
      "Xu Zhao",
      "Yanan Wei",
      "Yanbo Yu",
      "Yang Cao",
      "Yangguang Li",
      "Yangzhen Ma",
      "Yanming Xu",
      "Yaoyu Wang",
      "Yaqiang Shi",
      "Yilei Wang",
      "Yizhuang Zhou",
      "Yinmin Zhong",
      "Yang Zhang",
      "Yaoben Wei",
      "Yu Luo",
      "Yuanwei Lu",
      "Yuhe Yin",
      "Yuchu Luo",
      "Yuanhao Ding",
      "Yuting Yan",
      "Yaqi Dai",
      "Yuxiang Yang",
      "Zhe Xie",
      "Zheng Ge",
      "Zheng Sun",
      "Zhewei Huang",
      "Zhichao Chang",
      "Zhisheng Guan",
      "Zidong Yang",
      "Zili Zhang",
      "Binxing Jiao",
      "Daxin Jiang",
      "Heung-Yeung Shum",
      "Jiansheng Chen",
      "Jing Li",
      "Shuchang Zhou",
      "Xiangyu Zhang",
      "Xinhao Zhang",
      "Yibo Zhu"
    ],
    "abstract": "Real-time speech interaction, serving as a fundamental interface for\nhuman-machine collaboration, holds immense potential. However, current\nopen-source models face limitations such as high costs in voice data\ncollection, weakness in dynamic control, and limited intelligence. To address\nthese challenges, this paper introduces Step-Audio, the first production-ready\nopen-source solution. Key contributions include: 1) a 130B-parameter unified\nspeech-text multi-modal model that achieves unified understanding and\ngeneration, with the Step-Audio-Chat version open-sourced; 2) a generative\nspeech data engine that establishes an affordable voice cloning framework and\nproduces the open-sourced lightweight Step-Audio-TTS-3B model through\ndistillation; 3) an instruction-driven fine control system enabling dynamic\nadjustments across dialects, emotions, singing, and RAP; 4) an enhanced\ncognitive architecture augmented with tool calling and role-playing abilities\nto manage complex tasks effectively. Based on our new StepEval-Audio-360\nevaluation benchmark, Step-Audio achieves state-of-the-art performance in human\nevaluations, especially in terms of instruction following. On open-source\nbenchmarks like LLaMA Question, shows 9.3% average performance improvement,\ndemonstrating our commitment to advancing the development of open-source\nmulti-modal language technologies. Our code and models are available at\nhttps://github.com/stepfun-ai/Step-Audio.",
    "pdf_url": "http://arxiv.org/pdf/2502.11946v2",
    "published": "2025-02-17T15:58:56+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11945v2",
    "title": "Effective medium theory for the electrical conductivity of random metallic nanowire networks",
    "authors": [
      "Yuri Yu. Tarasevich",
      "Irina V. Vodolazskaya",
      "Andrei V. Eserkepov"
    ],
    "abstract": "Interest in studying the conductive properties of networks made from randomly\ndistributed nanowires is due to their numerous technological applications.\nAlthough the sheet resistance of such networks can be calculated directly, the\ncalculations require many characteristics of the system (distributions of\nlengths, diameters and resistances of nanowires, distribution of junction\nresistance), the measurement of which is difficult. Furthermore, such\ncalculations can hardly offer an analytical dependence of the sheet resistance\non the basic physical parameters of the systems under consideration. Although\nvarious theoretical approaches offer such analytical dependencies, they are\noften based on more or less reasonable assumptions rather than rigorously\nproven statements. Here, we offer an approach based on Foster's theorem to\nreveal a dependence of the sheet resistance of dense nanowire networks on the\nmain parameters of such networks. This theorem offers an additional perspective\non the effective medium theory and extends our insight. Since the application\nof Foster's theorem is particularly effective for regular random resistor\nnetworks, we propose a method for regularizing resistor networks corresponding\nto random nanowire networks. We found an analytical dependence of the effective\nelectrical conductivity on the main parameters of the nanowire network (reduced\nnumber density of nanowires, nanowire resistance, and resistance of contacts\nbetween nanowires).",
    "pdf_url": "http://arxiv.org/pdf/2502.11945v2",
    "published": "2025-02-17T15:58:19+00:00",
    "categories": [
      "cond-mat.dis-nn"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11944v1",
    "title": "Single-Molecule Water Motion on h-BN and Graphene: A Paradigm Shift in Understanding the Behaviour of Water on 2D Material Interfaces",
    "authors": [
      "Philipp Seiler",
      "Anthony Payne",
      "Neubi F. Xavier Jr",
      "Louie Slocombe",
      "Marco Sacchi",
      "Anton TamtÃ¶gl"
    ],
    "abstract": "Understanding water behaviour on 2D materials is crucial for sensing,\nmicrofluidics, and tribology. While water/graphene interactions are well\nstudied, water on hexagonal boron nitride (h-BN) remains largely unexplored.\nDespite structural similarity to graphene, h-BN's slightly polar B-N bonds\nimpart a large band gap, high thermal conductivity, and chemical stability,\nmaking it promising for electronics, lubricants, and coatings. Moreover,\nexisting water studies often focus on multilayer water dynamics, overlooking\nsingle-molecular details. We bridge this gap by studying single-molecular water\nfriction and diffusion on h-BN, comparing it with graphene using helium\nspin-echo experiments and ab initio calculations. Our findings show that water\ndiffusion on h-BN/Ni follows a complex rotational-translational dynamic, unlike\ngraphene. While conventional views treat water motion as discrete jumps between\nequivalent adsorption sites, we demonstrate that on h-BN, water molecules\nrotate freely around their centre of mass. Although the binding energies of\nwater on h-BN and graphene are similar, the activation energy for water\ndynamics on h-BN is 2.5 times lower than on graphene, implying a much lower\nbarrier for molecular mobility. The fundamentally different diffusion\ncharacteristics which classical models cannot capture, underscores the need to\nrethink how we model water on polar 2D materials. Moreover, our analysis\nreveals that the metal substrate strongly influences water friction, with\nh-BN/Ni showing a markedly lower friction than graphene/Ni, in stark contrast\nto the free-standing materials. These findings challenge assumptions about 2D\nmaterial-water interactions, highlighting the crucial role of substrate effects\nin chemistry and material science and offer insights for designing\nnext-generation microfluidic devices that require precise water mobility\ncontrol.",
    "pdf_url": "http://arxiv.org/pdf/2502.11944v1",
    "published": "2025-02-17T15:56:22+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11943v1",
    "title": "All-Optical Photoluminescence Spectra of Nitrogen-Vacancy Ensembles in Diamond at Low Magnetic Fields",
    "authors": [
      "Xiechen Zheng",
      "Jeyson TÃ¡mara-Isaza",
      "Zechuan Yin",
      "Johannes Cremer",
      "John W. Blanchard",
      "Connor A. Hart",
      "Michael Crescimanno",
      "Paul V. Petruzzi",
      "Matthew J. Turner",
      "Ronald L. Walsworth"
    ],
    "abstract": "All-optical (AO), microwave-free magnetometry using nitrogen-vacancy (NV)\ncenters in diamond is attractive due to its broad sample compatibility and\nreduced experimental complexity. In this work, we investigate room-temperature\nAO photoluminescence (PL) at low magnetic fields (<2 mT) using diamonds with NV\nensembles at ppm concentrations. Measured AO-PL contrast features as a function\nof applied magnetic field magnitude and direction are correlated with\nnear-degenerate NV electronic spin and hyperfine transitions from different NV\norientations within the diamond host. Reasonable agreement is found between\nlow-field AO-PL measurements and model-based simulations of the effects of\nresonant dipolar interactions between NV centers. Maximum observed AO-PL\ncontrast depends on both NV concentration and laser illumination intensity at\n532 nm. These results imply different optimal conditions for low-field AO NV\nsensing compared to conventional optically detected magnetic resonance (ODMR)\ntechniques, suggesting new research and application opportunities using AO\nmeasurements with lower system complexity, size, weight, and power.",
    "pdf_url": "http://arxiv.org/pdf/2502.11943v1",
    "published": "2025-02-17T15:56:21+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11942v1",
    "title": "Sharp-PINNs: staggered hard-constrained physics-informed neural networks for phase field modelling of corrosion",
    "authors": [
      "Nanxi Chen",
      "Chuanjie Cui",
      "Rujin Ma",
      "Airong Chen",
      "Sifan Wang"
    ],
    "abstract": "Physics-informed neural networks have shown significant potential in solving\npartial differential equations (PDEs) across diverse scientific fields.\nHowever, their performance often deteriorates when addressing PDEs with\nintricate and strongly coupled solutions. In this work, we present a novel\nSharp-PINN framework to tackle complex phase field corrosion problems. Instead\nof minimizing all governing PDE residuals simultaneously, the Sharp-PINNs\nintroduce a staggered training scheme that alternately minimizes the residuals\nof Allen-Cahn and Cahn-Hilliard equations, which govern the corrosion system.\nTo further enhance its efficiency and accuracy, we design an advanced neural\nnetwork architecture that integrates random Fourier features as coordinate\nembeddings, employs a modified multi-layer perceptron as the primary backbone,\nand enforces hard constraints in the output layer. This framework is\nbenchmarked through simulations of corrosion problems with multiple pits, where\nthe staggered training scheme and network architecture significantly improve\nboth the efficiency and accuracy of PINNs. Moreover, in three-dimensional\ncases, our approach is 5-10 times faster than traditional finite element\nmethods while maintaining competitive accuracy, demonstrating its potential for\nreal-world engineering applications in corrosion prediction.",
    "pdf_url": "http://arxiv.org/pdf/2502.11942v1",
    "published": "2025-02-17T15:56:07+00:00",
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11941v1",
    "title": "Deep Spatio-Temporal Neural Network for Air Quality Reanalysis",
    "authors": [
      "Ammar Kheder",
      "Benjamin Foreback",
      "Lili Wang",
      "Zhi-Song Liu",
      "Michael Boy"
    ],
    "abstract": "Air quality prediction is key to mitigating health impacts and guiding\ndecisions, yet existing models tend to focus on temporal trends while\noverlooking spatial generalization. We propose AQ-Net, a spatiotemporal\nreanalysis model for both observed and unobserved stations in the near future.\nAQ-Net utilizes the LSTM and multi-head attention for the temporal regression.\nWe also propose a cyclic encoding technique to ensure continuous time\nrepresentation. To learn fine-grained spatial air quality estimation, we\nincorporate AQ-Net with the neural kNN to explore feature-based interpolation,\nsuch that we can fill the spatial gaps given coarse observation stations. To\ndemonstrate the efficiency of our model for spatiotemporal reanalysis, we use\ndata from 2013-2017 collected in northern China for PM2.5 analysis. Extensive\nexperiments show that AQ-Net excels in air quality reanalysis, highlighting the\npotential of hybrid spatio-temporal models to better capture environmental\ndynamics, especially in urban areas where both spatial and temporal variability\nare critical.",
    "pdf_url": "http://arxiv.org/pdf/2502.11941v1",
    "published": "2025-02-17T15:52:22+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11940v1",
    "title": "The Dynamic Model of the UR10 Robot and its ROS2 Integration",
    "authors": [
      "Vincenzo Petrone",
      "Enrico Ferrentino",
      "Pasquale Chiacchio"
    ],
    "abstract": "This paper presents the full dynamic model of the UR10 industrial robot. A\ntriple-stage identification approach is adopted to estimate the manipulator's\ndynamic coefficients. First, linear parameters are computed using a standard\nlinear regression algorithm. Subsequently, nonlinear friction parameters are\nestimated according to a sigmoidal model. Lastly, motor drive gains are devised\nto map estimated joint currents to torques. The overall identified model can be\nused for both control and planning purposes, as the accompanied ROS2 software\ncan be easily reconfigured to account for a generic payload. The estimated\nrobot model is experimentally validated against a set of exciting trajectories\nand compared to the state-of-the-art model for the same manipulator, achieving\nhigher current prediction accuracy (up to a factor of 4.43) and more precise\nmotor gains. The related software is available at\nhttps://codeocean.com/capsule/8515919/tree/v2.",
    "pdf_url": "http://arxiv.org/pdf/2502.11940v1",
    "published": "2025-02-17T15:51:57+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11938v1",
    "title": "QoS based resource management for concurrent operation using MCTS",
    "authors": [
      "Sebastian Durst",
      "Kilian Barth",
      "Tobias MÃ¼ller",
      "Pascal Marquardt"
    ],
    "abstract": "Modern AESA technology enables RF systems to not only perform various radar,\ncommunication and electronic warfare tasks on a single aperture, but even to\nexecute multiple tasks concurrently. These capabilities increase system\ncomplexity and require intelligent or cognitive resource management. This paper\nintroduces such a resource management framework based on quality of service\nbased resource allocation and Monte Carlo tree search allowing for optimal\nsystem usage and profound decision-making. Furthermore, we present experimental\nverification in a complex application scenario.",
    "pdf_url": "http://arxiv.org/pdf/2502.11938v1",
    "published": "2025-02-17T15:50:22+00:00",
    "categories": [
      "eess.SP",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11939v1",
    "title": "The shift-homological spectrum and parametrising kernels of rank functions",
    "authors": [
      "Isaac Bird",
      "Jordan Williamson",
      "Alexandra Zvonareva"
    ],
    "abstract": "For any compactly generated triangulated category we introduce two\ntopological spaces, the shift-spectrum and the shift-homological spectrum. We\nuse them to parametrise a family of thick subcategories of the compact objects,\nwhich we call radical. These spaces can be viewed as non-monoidal analogues of\nthe Balmer and homological spectra arising in tensor-triangular geometry: we\nprove that for monogenic tensor-triangulated categories the Balmer spectrum is\na subspace of the shift-spectrum. To construct these analogues we utilise\nquotients of the module category, rather than the lattice theoretic methods\nwhich have been adopted in other approaches. We characterise radical thick\nsubcategories and show in certain cases, such as the perfect derived categories\nof tame hereditary algebras or monogenic tensor-triangulated categories, that\nevery thick subcategory is radical. We establish a close relationship between\nthe shift-homological spectrum and the set of irreducible integral rank\nfunctions, and provide necessary and sufficient conditions for every radical\nthick subcategory to be given by an intersection of kernels of rank functions.\nIn order to facilitate these results, we prove that both spaces we introduce\nmay equivalently be described in terms of the Ziegler spectrum.",
    "pdf_url": "http://arxiv.org/pdf/2502.11939v1",
    "published": "2025-02-17T15:50:22+00:00",
    "categories": [
      "math.CT",
      "math.AT",
      "math.RT",
      "16E35, 16G10, 18E45, 18F99, 18G80"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11937v1",
    "title": "FitLight: Federated Imitation Learning for Plug-and-Play Autonomous Traffic Signal Control",
    "authors": [
      "Yutong Ye",
      "Yingbo Zhou",
      "Zhusen Liu",
      "Xiao Du",
      "Hao Zhou",
      "Xiang Lian",
      "Mingsong Chen"
    ],
    "abstract": "Although Reinforcement Learning (RL)-based Traffic Signal Control (TSC)\nmethods have been extensively studied, their practical applications still raise\nsome serious issues such as high learning cost and poor generalizability. This\nis because the ``trial-and-error'' training style makes RL agents extremely\ndependent on the specific traffic environment, which also requires a long\nconvergence time. To address these issues, we propose a novel Federated\nImitation Learning (FIL)-based framework for multi-intersection TSC, named\nFitLight, which allows RL agents to plug-and-play for any traffic environment\nwithout additional pre-training cost. Unlike existing imitation learning\napproaches that rely on pre-training RL agents with demonstrations, FitLight\nallows real-time imitation learning and seamless transition to reinforcement\nlearning. Due to our proposed knowledge-sharing mechanism and novel hybrid\npressure-based agent design, RL agents can quickly find a best control policy\nwith only a few episodes. Moreover, for resource-constrained TSC scenarios,\nFitLight supports model pruning and heterogeneous model aggregation, such that\nRL agents can work on a micro-controller with merely 16{\\it KB} RAM and 32{\\it\nKB} ROM. Extensive experiments demonstrate that, compared to state-of-the-art\nmethods, FitLight not only provides a superior starting point but also\nconverges to a better final solution on both real-world and synthetic datasets,\neven under extreme resource limitations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11937v1",
    "published": "2025-02-17T15:48:46+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11936v1",
    "title": "Regimes of spray formation in gas-centered swirl coaxial atomizers",
    "authors": [
      "Deivandren Sivakumar",
      "Varun Kulkarni"
    ],
    "abstract": "Spray formation in ambient atmosphere from gas-centered swirl coaxial\natomizers is described by carrying out experiments in a spray test facility.\nThe atomizer discharges a circular air jet and an axisymmetric swirling water\nsheet from its coaxially arranged inner and outer orifices. A high-speed\ndigital imaging system along with a backlight illumination arrangement is\nemployed to record the details of liquid sheet breakup and spray development.\nSpray regimes exhibiting different sheet breakup mechanisms are identified and\ntheir characteristic features presented. The identified spray regimes are\nwave-assisted sheet breakup, perforated sheet breakup, segmented sheet breakup,\nand pulsation spray regime. In the regime of wave-assisted sheet breakup, the\nsheet breakup shows features similar to the breakup of two-dimensional planar\nair-blasted liquid sheets. At high air-to-liquid momentum ratios, the\ninteraction process between the axisymmetric swirling liquid sheet and the\ncircular air jet develops spray processes which are more specific to the\natomizer studied here. The spray exhibits a periodic ejection of liquid masses\nwhose features are dominantly controlled by the central air jet.",
    "pdf_url": "http://arxiv.org/pdf/2502.11936v1",
    "published": "2025-02-17T15:48:32+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.space-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11935v1",
    "title": "A quantitative general Nullstellensatz for Jacobson rings",
    "authors": [
      "Ryota Kuroki"
    ],
    "abstract": "The general Nullstellensatz states that if $A$ is a Jacobson ring, $A[X]$ is\nJacobson. We introduce the notion of an $\\alpha$-Jacobson ring for an ordinal\n$\\alpha$ and prove a quantitative version of the general Nullstellensatz: if\n$A$ is an $\\alpha$-Jacobson ring, $A[X]$ is $(\\alpha+1)$-Jacobson. The\nquantitative general Nullstellensatz implies that $K[X_1,\\ldots,X_n]$ is not\nonly Jacobson but also $(1+n)$-Jacobson for any field $K$. It also implies that\n$\\mathbb{Z}[X_1,\\ldots,X_n]$ is $(2+n)$-Jacobson.",
    "pdf_url": "http://arxiv.org/pdf/2502.11935v1",
    "published": "2025-02-17T15:48:19+00:00",
    "categories": [
      "math.AC",
      "13F20 (Primary) 03F65 (Secondary)"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11934v1",
    "title": "Evaluation of machine learning techniques for conditional generative adversarial networks in inverse design",
    "authors": [
      "Timo Gahlmann",
      "Philippe Tassin"
    ],
    "abstract": "Recently, machine learning has been introduced in the inverse design of\nphysical devices, i.e., the automatic generation of device geometries for a\ndesired physical response. In particular, generative adversarial networks have\nbeen proposed as a promising approach for topological optimization, since such\nneural network models can perform free-form design and simultaneously take into\naccount constraints imposed by the device's fabrication process. In this\ncontext, a plethora of techniques has been developed in the machine learning\ncommunity. Here, we study to what extent new network architectures, such as\ndense residual networks, and other techniques like data augmentation, and the\nuse of noise in the input channels of the discriminator can improve or speed up\nneural networks for inverse design of optical metasurfaces. We also investigate\nstrategies for improving the convergence of the training of generative\nadversarial networks for inverse design, e.g., temporarily freezing the\ndiscriminator weights when the model outperforms the generator and training\ndata blurring during the early epochs. Our results show that only some of these\ntechniques improve inverse design models in terms of accuracy and stability,\nbut also that a combination of them can provide more efficient and robust\nmetasurface designs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11934v1",
    "published": "2025-02-17T15:46:10+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall",
      "physics.app-ph",
      "physics.comp-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.18491v1",
    "title": "Non naturally reductive Einstein metrics on $\\SU(N)$ via generalized flag manifolds",
    "authors": [
      "Andreas Arvanitoyeorgos",
      "Yusuke Sakane",
      "Marina Statha"
    ],
    "abstract": "We obtain new invariant Einstein metrics on the compact Lie group\n  $\\SU(N)$ which are not naturally reductive.\n  This is achieved by using the generalized flag manifold $G/K=\\SU(k_1+\\cdots\n+k_p)/\\s(\\U(k_1)\\times\\cdots\\times\\U(k_p))$ and by taking an appropriate choice\nof orthogonal basis of the center of Lie subalgebra $\\frak k$ for $K$, which\nposes\n  certain symmetry conditions to the $\\Ad(K)$-invariant metrics of $\\SU(N)$. We\nalso study the isometry problem for the Einstein metrics found.",
    "pdf_url": "http://arxiv.org/pdf/2502.18491v1",
    "published": "2025-02-17T15:44:54+00:00",
    "categories": [
      "math.DG",
      "53C25, 53C30, 13P10, 65H10, 68W30"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11933v1",
    "title": "Clifford circuit based heuristic optimization of fermion-to-qubit mappings",
    "authors": [
      "Jeffery Yu",
      "Yuan Liu",
      "Sho Sugiura",
      "Troy Van Voorhis",
      "Sina ZeytinoÄlu"
    ],
    "abstract": "Simulation of interacting fermionic Hamiltonians is one of the most promising\napplications of quantum computers. However, the feasibility of analysing\nfermionic systems with a quantum computer hinges on the efficiency of\nfermion-to-qubit mappings that encode non-local fermionic degrees of freedom in\nlocal qubit degrees of freedom. While recent works have highlighted the\nimportance of designing fermion-to-qubit mappings that are tailored to specific\nproblem Hamiltonians, the methods proposed so far are either restricted to a\nnarrow class of mappings or they use computationally expensive and unscalable\nbrute-force search algorithms. Here, we address this challenge by designing a\n$\\mathrm{\\textbf{heuristic}}$ numerical optimization framework for\nfermion-to-qubit mappings. To this end, we first translate the fermion-to-qubit\nmapping problem to a Clifford circuit optimization problem, and then use\nsimulated annealing to optimize the average Pauli weight of the problem\nHamiltonian. For all fermionic Hamiltonians we have considered, the numerically\noptimized mappings outperform their conventional counterparts, including\nternary-tree-based mappings that are known to be optimal for single creation\nand annihilation operators. We find that our optimized mappings yield between\n$15\\%$ to $40\\%$ improvements on the average Pauli weight when the simulation\nHamiltonian has an intermediate level of complexity. Most remarkably, the\noptimized mappings improve the average Pauli weight for $6 \\times 6$\nnearest-neighbor hopping and Hubbard models by more than $40\\%$ and $20\\%$,\nrespectively. Surprisingly, we also find specific interaction Hamiltonians for\nwhich the optimized mapping outperform $\\mathrm{\\textbf{any}}$\nternary-tree-based mapping. Our results establish heuristic numerical\noptimization as an effective method for obtaining mappings tailored for\nspecific fermionic Hamiltonian.",
    "pdf_url": "http://arxiv.org/pdf/2502.11933v1",
    "published": "2025-02-17T15:44:23+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11932v1",
    "title": "On Representational Dissociation of Language and Arithmetic in Large Language Models",
    "authors": [
      "Riku Kisako",
      "Tatsuki Kuribayashi",
      "Ryohei Sasano"
    ],
    "abstract": "The association between language and (non-linguistic) thinking ability in\nhumans has long been debated, and recently, neuroscientific evidence of brain\nactivity patterns has been considered. Such a scientific context naturally\nraises an interdisciplinary question -- what about such a language-thought\ndissociation in large language models (LLMs)? In this paper, as an initial\nforay, we explore this question by focusing on simple arithmetic skills (e.g.,\n$1+2=$ ?) as a thinking ability and analyzing the geometry of their encoding in\nLLMs' representation space. Our experiments with linear classifiers and cluster\nseparability tests demonstrate that simple arithmetic equations and general\nlanguage input are encoded in completely separated regions in LLMs' internal\nrepresentation space across all the layers, which is also supported with more\ncontrolled stimuli (e.g., spelled-out equations). These tentatively suggest\nthat arithmetic reasoning is mapped into a distinct region from general\nlanguage input, which is in line with the neuroscientific observations of human\nbrain activations, while we also point out their somewhat cognitively\nimplausible geometric properties.",
    "pdf_url": "http://arxiv.org/pdf/2502.11932v1",
    "published": "2025-02-17T15:42:01+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11931v3",
    "title": "Asymmetric simple exclusion process on a random comb: Transport properties in the stationary state",
    "authors": [
      "Mrinal Sarkar",
      "Shamik Gupta"
    ],
    "abstract": "We address the dynamics of interacting particles on a disordered lattice\nformed by a random comb. The dynamics comprises that of the asymmetric simple\nexclusion process, whereby motion to nearest-neighour sites that are empty is\nmore likely in the direction of a bias than in the opposite direction. The\nrandom comb comprises a backbone lattice from each site of which emanates a\nbranch with a random number of sites. The backbone and the branches run in the\ndirection of the bias. The number of branch sites or alternatively the branch\nlengths are sampled independently from a common distribution, specifically, an\nexponential distribution. The system relaxes at long times into a\nnonequilibrium stationary state. We analyse the stationary-state density of\nsites across the random comb, and also explore the transport properties, in\nparticular, the stationary-state drift velocity of particles along the\nbackbone. We show that in the stationary state, the density is uniform along\nthe backbone and nonuniform along the branches, decreasing monotonically from\nthe free-end of a branch to its intersection with the backbone. On the other\nhand, the drift velocity as a function of the bias strength has a non-monotonic\ndependence, first increasing and then decreasing with increase of bias.\nHowever, remarkably, as the particle density increases, the dependence becomes\nno more non-monotonic. We understand this effect as a consequence of an\ninterplay between biased hopping and hard-core exclusion, whereby sites towards\nthe free end of the branches remain occupied for long times and become\neffectively non-participatory in the dynamics of the system. This results in an\neffective reduction of the branch lengths and a motion of the particles that\ntakes place primarily along the backbone.",
    "pdf_url": "http://arxiv.org/pdf/2502.11931v3",
    "published": "2025-02-17T15:41:48+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2502.11930v1",
    "title": "Searching for Low-Mass Exoplanets Amid Stellar Variability with a Fixed Effects Linear Model of Line-by-Line Shape Changes",
    "authors": [
      "Joseph Salzer",
      "Jessi Cisewski-Kehe",
      "Eric B. Ford",
      "Lily L. Zhao"
    ],
    "abstract": "The radial velocity (RV) method, also known as Doppler spectroscopy, is a\npowerful technique for exoplanet discovery and characterization. In recent\nyears, progress has been made thanks to the improvements in the quality of\nspectra from new extreme precision RV spectrometers. However, detecting the RV\nsignals of Earth-like exoplanets remains challenging, as the spectroscopic\nsignatures of low-mass planets can be obscured or confused with intrinsic\nstellar variability. Changes in the shapes of spectral lines across time can\nprovide valuable information for disentangling stellar activity from true\nDoppler shifts caused by low-mass exoplanets. In this work, we present a fixed\neffects linear model to estimate RV signals that controls for changes in line\nshapes by aggregating information from hundreds of spectral lines. Our\nmethodology incorporates a wild-bootstrap approach for modeling uncertainty and\ncross-validation to control for overfitting. We evaluate the model's ability to\nremove stellar activity using solar observations from the NEID spectrograph, as\nthe sun's true center-of-mass motion is precisely known. Including line\nshape-change covariates reduces the RV root-mean-square errors by approximately\n70% (from 1.919 m s$^{-1}$ to 0.575 m s$^{-1}$) relative to using only the\nline-by-line Doppler shifts. The magnitude of the residuals is significantly\nless than that from traditional CCF-based RV estimators and comparable to other\nstate-of-the-art methods for mitigating stellar variability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11930v1",
    "published": "2025-02-17T15:41:40+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "astro-ph.SR",
      "stat.AP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11929v1",
    "title": "Prime numbers and dynamics of the polynomial $x^2-1$",
    "authors": [
      "Ivan Penkov",
      "Michael Stoll"
    ],
    "abstract": "Let $n \\in \\mathbb{Z}_{\\geqslant 2}$. By $P(n)$ we denote the set of all\nprime divisors of the integers in the sequence $n, n^2-1, (n^2-1)^2-1, \\dots$.\nWe ask whether the set $P(n)$ determines $n$ uniquely under the assumption that\n$n \\neq m^2-1$ for $m \\in \\mathbb{Z}_{\\geqslant 2}$. This problem originates in\nthe structure theory of infinite-dimensional Lie algebras. We show that the\nsets $P(n)$ generate infinitely many equivalence classes of positive integers\nunder the equivalence relation $n_1 \\sim n_2 \\iff P(n_1) = P(n_2)$. We also\nprove that the sets $P(n)$ separate all positive integers up to $2^{29}$, and\nwe provide some heuristics on why the answer to our question should be\npositive.",
    "pdf_url": "http://arxiv.org/pdf/2502.11929v1",
    "published": "2025-02-17T15:41:34+00:00",
    "categories": [
      "math.NT",
      "math.DS",
      "37P05, 37P15, 15B30, 17B45, 11Y99"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11928v1",
    "title": "Exploring the BSM parameter space with Neural Network aided Simulation-Based Inference",
    "authors": [
      "Atrideb Chatterjee",
      "Arghya Choudhury",
      "Sourav Mitra",
      "Arpita Mondal",
      "Subhadeep Mondal"
    ],
    "abstract": "Some of the issues that make sampling parameter spaces of various beyond the\nStandard Model (BSM) scenarios computationally expensive are the high\ndimensionality of the input parameter space, complex likelihoods, and stringent\nexperimental constraints. In this work, we explore likelihood-free approaches,\nleveraging neural network-aided Simulation-Based Inference (SBI) to alleviate\nthis issue. We focus on three amortized SBI methods: Neural Posterior\nEstimation (NPE), Neural Likelihood Estimation (NLE), and Neural Ratio\nEstimation (NRE) and perform a comparative analysis through the validation test\nknown as the \\textit{ Test of Accuracy with Random Points} (TARP), as well as\nthrough posterior sample efficiency and computational time. As an example, we\nfocus on the scalar sector of the phenomenological minimal supersymmetric SM\n(pMSSM) and observe that the NPE method outperforms the others and generates\ncorrect posterior distributions of the parameters with a minimal number of\nsamples. The efficacy of this framework will be more evident with additional\nexperimental data, especially for high dimensional parameter space.",
    "pdf_url": "http://arxiv.org/pdf/2502.11928v1",
    "published": "2025-02-17T15:41:25+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "physics.data-an"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11927v1",
    "title": "Continual Learning Should Move Beyond Incremental Classification",
    "authors": [
      "Rupert Mitchell",
      "Antonio Alliegro",
      "Raffaello Camoriano",
      "Dustin CarriÃ³n-Ojeda",
      "Antonio Carta",
      "Georgia Chalvatzaki",
      "Nikhil Churamani",
      "Carlo D'Eramo",
      "Samin Hamidi",
      "Robin Hesse",
      "Fabian Hinder",
      "Roshni Ramanna Kamath",
      "Vincenzo Lomonaco",
      "Subarnaduti Paul",
      "Francesca Pistilli",
      "Tinne Tuytelaars",
      "Gido M van de Ven",
      "Kristian Kersting",
      "Simone Schaub-Meyer",
      "Martin Mundt"
    ],
    "abstract": "Continual learning (CL) is the sub-field of machine learning concerned with\naccumulating knowledge in dynamic environments. So far, CL research has mainly\nfocused on incremental classification tasks, where models learn to classify new\ncategories while retaining knowledge of previously learned ones. Here, we argue\nthat maintaining such a focus limits both theoretical development and practical\napplicability of CL methods. Through a detailed analysis of concrete examples -\nincluding multi-target classification, robotics with constrained output spaces,\nlearning in continuous task domains, and higher-level concept memorization - we\ndemonstrate how current CL approaches often fail when applied beyond standard\nclassification. We identify three fundamental challenges: (C1) the nature of\ncontinuity in learning problems, (C2) the choice of appropriate spaces and\nmetrics for measuring similarity, and (C3) the role of learning objectives\nbeyond classification. For each challenge, we provide specific recommendations\nto help move the field forward, including formalizing temporal dynamics through\ndistribution processes, developing principled approaches for continuous task\nspaces, and incorporating density estimation and generative objectives. In so\ndoing, this position paper aims to broaden the scope of CL research while\nstrengthening its theoretical foundations, making it more applicable to\nreal-world problems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11927v1",
    "published": "2025-02-17T15:40:13+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11926v4",
    "title": "BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages",
    "authors": [
      "Shamsuddeen Hassan Muhammad",
      "Nedjma Ousidhoum",
      "Idris Abdulmumin",
      "Jan Philip Wahle",
      "Terry Ruas",
      "Meriem Beloucif",
      "Christine de Kock",
      "Nirmal Surange",
      "Daniela Teodorescu",
      "Ibrahim Said Ahmad",
      "David Ifeoluwa Adelani",
      "Alham Fikri Aji",
      "Felermino D. M. A. Ali",
      "Ilseyar Alimova",
      "Vladimir Araujo",
      "Nikolay Babakov",
      "Naomi Baes",
      "Ana-Maria Bucur",
      "Andiswa Bukula",
      "Guanqun Cao",
      "Rodrigo Tufino Cardenas",
      "Rendi Chevi",
      "Chiamaka Ijeoma Chukwuneke",
      "Alexandra Ciobotaru",
      "Daryna Dementieva",
      "Murja Sani Gadanya",
      "Robert Geislinger",
      "Bela Gipp",
      "Oumaima Hourrane",
      "Oana Ignat",
      "Falalu Ibrahim Lawan",
      "Rooweither Mabuya",
      "Rahmad Mahendra",
      "Vukosi Marivate",
      "Alexander Panchenko",
      "Andrew Piper",
      "Charles Henrique Porto Ferreira",
      "Vitaly Protasov",
      "Samuel Rutunda",
      "Manish Shrivastava",
      "Aura Cristina Udrea",
      "Lilian Diana Awuor Wanzare",
      "Sophie Wu",
      "Florian Valentin Wunderlich",
      "Hanif Muhammad Zhafran",
      "Tianhui Zhang",
      "Yi Zhou",
      "Saif M. Mohammad"
    ],
    "abstract": "People worldwide use language in subtle and complex ways to express emotions.\nAlthough emotion recognition--an umbrella term for several NLP tasks--impacts\nvarious applications within NLP and beyond, most work in this area has focused\non high-resource languages. This has led to significant disparities in research\nefforts and proposed solutions, particularly for under-resourced languages,\nwhich often lack high-quality annotated datasets. In this paper, we present\nBRIGHTER--a collection of multi-labeled, emotion-annotated datasets in 28\ndifferent languages and across several domains. BRIGHTER primarily covers\nlow-resource languages from Africa, Asia, Eastern Europe, and Latin America,\nwith instances labeled by fluent speakers. We highlight the challenges related\nto the data collection and annotation processes, and then report experimental\nresults for monolingual and crosslingual multi-label emotion identification, as\nwell as emotion intensity recognition. We analyse the variability in\nperformance across languages and text domains, both with and without the use of\nLLMs, and show that the BRIGHTER datasets represent a meaningful step towards\naddressing the gap in text-based emotion recognition.",
    "pdf_url": "http://arxiv.org/pdf/2502.11926v4",
    "published": "2025-02-17T15:39:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11925v2",
    "title": "GRAPHGPT-O: Synergistic Multimodal Comprehension and Generation on Graphs",
    "authors": [
      "Yi Fang",
      "Bowen Jin",
      "Jiacheng Shen",
      "Sirui Ding",
      "Qiaoyu Tan",
      "Jiawei Han"
    ],
    "abstract": "The rapid development of Multimodal Large Language Models (MLLMs) has enabled\nthe integration of multiple modalities, including texts and images, within the\nlarge language model (LLM) framework. However, texts and images are usually\ninterconnected, forming a multimodal attributed graph (MMAG). It is\nunderexplored how MLLMs can incorporate the relational information\n(\\textit{i.e.}, graph structure) and semantic information (\\textit{i.e.,} texts\nand images) on such graphs for multimodal comprehension and generation. In this\npaper, we propose GraphGPT-o, which supports omni-multimodal understanding and\ncreation on MMAGs. We first comprehensively study linearization variants to\ntransform semantic and structural information as input for MLLMs. Then, we\npropose a hierarchical aligner that enables deep graph encoding, bridging the\ngap between MMAGs and MLLMs. Finally, we explore the inference choices,\nadapting MLLM to interleaved text and image generation in graph scenarios.\nExtensive experiments on three datasets from different domains demonstrate the\neffectiveness of our proposed method. Datasets and codes will be open-sourced\nupon acceptance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11925v2",
    "published": "2025-02-17T15:35:36+00:00",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11924v1",
    "title": "Effective field theory and thermal Hall effect of magnons in square-lattice antiferromagnets",
    "authors": [
      "Masataka Kawano"
    ],
    "abstract": "Thermal Hall transport has emerged as a powerful probe of neutral\nquasiparticles and associated gauge fields in insulating materials. Although\nthe emergence of a thermal Hall effect is known to be sensitive to lattice\ngeometry and gauge structures, an intuitive understanding of the conditions for\nits emergence remains limited, especially for edge-shared lattice geometries\nsuch as square and triangular lattices. Here, we develop an effective field\ntheory of magnons in square-lattice antiferromagnets to establish the intuitive\npicture that elucidates the conditions for a finite thermal Hall response. By\nconstructing an effective field theory from a spin model on the square lattice,\nwe show that its low-energy excitations can be described by magnons with an\neffective SU(2) gauge field and Zeeman field that couple to magnon's\npseudospins, which reflect the two-sublattice degrees of freedom in the\nantiferromagnets. The field strength associated with the SU(2) gauge field acts\nas a pseudospin-dependent magnetic field, bending the magnon's trajectories in\nopposite directions depending on their pseudospin. In addition, the effective\nZeeman field induces an imbalance between pseudospin up and down magnons, and\nthe combination of these two fields gives rise to the thermal Hall effect of\nmagnons. This intuitive picture provides a systematic classification of\nmagnetic orders in square-lattice antiferromagnets based on the presence or\nabsence of the thermal Hall effect. We expect that our framework can be\nextended to various other spin models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11924v1",
    "published": "2025-02-17T15:35:16+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11923v1",
    "title": "Research on Research Visibility",
    "authors": [
      "Enrique OrduÃ±a-Malea",
      "Cristina I. Font-JuliÃ¡n"
    ],
    "abstract": "This editorial explores the significance of research visibility within the\nevolving landscape of academic communication, mainly focusing on the role of\nsearch engines as online meta-markets shaping the impact of research. With the\nrapid expansion of scientific output and the increasing reliance on\nalgorithm-driven platforms such as Google and Google Scholar, the online\nvisibility of scholarly work has become an essential factor in determining its\nreach and influence. The need for more rigorous research into academic search\nengine optimization (A-SEO), a field still in its infancy despite its growing\nrelevance, is also discussed, highlighting key challenges in the field,\nincluding the lack of robust research methodologies, the skepticism within the\nacademic community regarding the commercialization of science, and the need for\nstandardization in reporting and measurement techniques. This editorial thus\ninvites a multidisciplinary dialogue on the future of research visibility, with\nsignificant implications for academic publishing, science communication,\nresearch evaluation, and the global scientific ecosystem.",
    "pdf_url": "http://arxiv.org/pdf/2502.11923v1",
    "published": "2025-02-17T15:34:22+00:00",
    "categories": [
      "cs.DL"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11922v1",
    "title": "Removable set for HÃ¶lder continuous solutions of $\\mathscr{A}$-harmonic functions on Finsler manifolds",
    "authors": [
      "Juan Pablo Alcon Apaza"
    ],
    "abstract": "We establish that a closed set $\\mathcal{S}$ is removable for\n$\\alpha$-H\\\"older continuous $\\mathscr{A}$-harmonic functions in a reversible\nFinsler manifold $(\\Omega, F, \\mathtt{V})$ of dimension $n \\geq 2$, provided\nthat (under certain conditions on $(\\Omega, F, \\mathtt{V})$ and the variable\nexponent $p$ ) for each compact subset $K$ of $\\mathcal{S}$, the\n$\\mathrm{n}_1-p_K^{+}+\\alpha\\left(p_K^{+}-1\\right)$-Hausdorff measure of $K$ is\nzero. Here, $p_K^{+}=\\sup _K p$ and $\\mathrm{n}_1$ is chosen so that\n$\\mathtt{V}(B(x, r)) \\leq \\mathtt{K} r^{\\mathrm{n}_1}$ for every ball.\n  The estimates used to remove the singularities will focus on a family\n$\\left\\{u_{\\ell}\\right\\}_{\\ell \\in \\mathcal{J}} \\subset W_{\\mathrm{loc}}^{1,\np(x)}(\\Omega ; \\mathtt{V})$ that converges to $u$ in a certain sense. As a\nsecond main result of this article, we will also obtain an estimate (when $\\lim\n_{d\\left(x, 0_{\\Omega}\\right) \\rightarrow \\infty} p=1$ ) for $$ \\mu_{\\ell}(B(x,\nr)):=\\sup \\left\\{\\int_{B(x, r)} \\mathscr{A} \\left(\\cdot, \\nabla u_{\\ell}\\right)\n\\bullet \\mathcal{D} \\zeta \\mathrm{dV} \\mid 0 \\leq \\zeta \\leq 1 \\text { and }\n\\zeta \\in C_0^{\\infty}(B(x, r))\\right\\}, $$ which is related to the measure\n$\\mu=\\operatorname{div}( \\mathscr{A} (\\cdot, \\nabla u))$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11922v1",
    "published": "2025-02-17T15:34:09+00:00",
    "categories": [
      "math.AP",
      "35J60, 35J70, 35J92, 58J05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11921v1",
    "title": "Joint Evaluation of Fairness and Relevance in Recommender Systems with Pareto Frontier",
    "authors": [
      "Theresia Veronika Rampisela",
      "Tuukka Ruotsalo",
      "Maria Maistro",
      "Christina Lioma"
    ],
    "abstract": "Fairness and relevance are two important aspects of recommender systems\n(RSs). Typically, they are evaluated either (i) separately by individual\nmeasures of fairness and relevance, or (ii) jointly using a single measure that\naccounts for fairness with respect to relevance. However, approach (i) often\ndoes not provide a reliable joint estimate of the goodness of the models, as it\nhas two different best models: one for fairness and another for relevance.\nApproach (ii) is also problematic because these measures tend to be ad-hoc and\ndo not relate well to traditional relevance measures, like NDCG. Motivated by\nthis, we present a new approach for jointly evaluating fairness and relevance\nin RSs: Distance to Pareto Frontier (DPFR). Given some user-item interaction\ndata, we compute their Pareto frontier for a pair of existing relevance and\nfairness measures, and then use the distance from the frontier as a measure of\nthe jointly achievable fairness and relevance. Our approach is modular and\nintuitive as it can be computed with existing measures. Experiments with 4 RS\nmodels, 3 re-ranking strategies, and 6 datasets show that existing metrics have\ninconsistent associations with our Pareto-optimal solution, making DPFR a more\nrobust and theoretically well-founded joint measure for assessing fairness and\nrelevance. Our code: https://github.com/theresiavr/DPFR-recsys-evaluation",
    "pdf_url": "http://arxiv.org/pdf/2502.11921v1",
    "published": "2025-02-17T15:33:28+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11920v2",
    "title": "A limited technical background is sufficient for attack-defense tree acceptability",
    "authors": [
      "Nathan Daniel Schiele",
      "Olga Gadyatskaya"
    ],
    "abstract": "Attack-defense trees (ADTs) are a prominent graphical threat modeling method\nthat is highly recommended for analyzing and communicating security-related\ninformation. Despite this, existing empirical studies of attack trees have\nestablished their acceptability only for users with highly technical (computer\nscience) backgrounds while raising questions about their suitability for threat\nmodeling stakeholders with a limited technical background. Our research\naddresses this gap by investigating the impact of the users' technical\nbackground on ADT acceptability in an empirical study.\n  Our Method Evaluation Model-based study consisted of n = 102 participants (53\nwith a strong computer science background and 49 with a limited computer\nscience background) who were asked to complete a series of ADT-related tasks.\nBy analyzing their responses and comparing the results, we reveal that a very\nlimited technical background is sufficient for ADT acceptability. This finding\nunderscores attack trees' viability as a threat modeling method.",
    "pdf_url": "http://arxiv.org/pdf/2502.11920v2",
    "published": "2025-02-17T15:33:07+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11919v1",
    "title": "From Text to Trust: Empowering AI-assisted Decision Making with Adaptive LLM-powered Analysis",
    "authors": [
      "Zhuoyan Li",
      "Hangxiao Zhu",
      "Zhuoran Lu",
      "Ziang Xiao",
      "Ming Yin"
    ],
    "abstract": "AI-assisted decision making becomes increasingly prevalent, yet individuals\noften fail to utilize AI-based decision aids appropriately especially when the\nAI explanations are absent, potentially as they do not %understand reflect on\nAI's decision recommendations critically. Large language models (LLMs), with\ntheir exceptional conversational and analytical capabilities, present great\nopportunities to enhance AI-assisted decision making in the absence of AI\nexplanations by providing natural-language-based analysis of AI's decision\nrecommendation, e.g., how each feature of a decision making task might\ncontribute to the AI recommendation. In this paper, via a randomized\nexperiment, we first show that presenting LLM-powered analysis of each task\nfeature, either sequentially or concurrently, does not significantly improve\npeople's AI-assisted decision performance. To enable decision makers to better\nleverage LLM-powered analysis, we then propose an algorithmic framework to\ncharacterize the effects of LLM-powered analysis on human decisions and\ndynamically decide which analysis to present. Our evaluation with human\nsubjects shows that this approach effectively improves decision makers'\nappropriate reliance on AI in AI-assisted decision making.",
    "pdf_url": "http://arxiv.org/pdf/2502.11919v1",
    "published": "2025-02-17T15:32:54+00:00",
    "categories": [
      "cs.HC",
      "cs.CL"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11918v1",
    "title": "VLP: Vision-Language Preference Learning for Embodied Manipulation",
    "authors": [
      "Runze Liu",
      "Chenjia Bai",
      "Jiafei Lyu",
      "Shengjie Sun",
      "Yali Du",
      "Xiu Li"
    ],
    "abstract": "Reward engineering is one of the key challenges in Reinforcement Learning\n(RL). Preference-based RL effectively addresses this issue by learning from\nhuman feedback. However, it is both time-consuming and expensive to collect\nhuman preference labels. In this paper, we propose a novel\n\\textbf{V}ision-\\textbf{L}anguage \\textbf{P}reference learning framework, named\n\\textbf{VLP}, which learns a vision-language preference model to provide\npreference feedback for embodied manipulation tasks. To achieve this, we define\nthree types of language-conditioned preferences and construct a vision-language\npreference dataset, which contains versatile implicit preference orders without\nhuman annotations. The preference model learns to extract language-related\nfeatures, and then serves as a preference annotator in various downstream\ntasks. The policy can be learned according to the annotated preferences via\nreward learning or direct policy optimization. Extensive empirical results on\nsimulated embodied manipulation tasks demonstrate that our method provides\naccurate preferences and generalizes to unseen tasks and unseen language\ninstructions, outperforming the baselines by a large margin.",
    "pdf_url": "http://arxiv.org/pdf/2502.11918v1",
    "published": "2025-02-17T15:32:14+00:00",
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11917v3",
    "title": "Infinitary Refinement Types for Temporal Properties in Scott Domains",
    "authors": [
      "Colin Riba",
      "Alexandre Kejikian"
    ],
    "abstract": "We discuss an infinitary refinement type system for input-output temporal\nspecifications of functions that handle infinite objects like streams or\ninfinite trees. Our system is based on a reformulation of Bonsangue and Kok's\ninfinitary extension of Abramsky's Domain Theory in Logical Form to saturated\nproperties. We show that in an interesting range of cases, our system is\ncomplete without the need of an infinitary rule introduced by Bonsangue and Kok\nto reflect the well-filteredness of Scott domains.",
    "pdf_url": "http://arxiv.org/pdf/2502.11917v3",
    "published": "2025-02-17T15:32:08+00:00",
    "categories": [
      "cs.LO",
      "F.3.1; F.3.2; F.4.1"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11916v2",
    "title": "EssayJudge: A Multi-Granular Benchmark for Assessing Automated Essay Scoring Capabilities of Multimodal Large Language Models",
    "authors": [
      "Jiamin Su",
      "Yibo Yan",
      "Fangteng Fu",
      "Han Zhang",
      "Jingheng Ye",
      "Xiang Liu",
      "Jiahao Huo",
      "Huiyu Zhou",
      "Xuming Hu"
    ],
    "abstract": "Automated Essay Scoring (AES) plays a crucial role in educational assessment\nby providing scalable and consistent evaluations of writing tasks. However,\ntraditional AES systems face three major challenges: (1) reliance on\nhandcrafted features that limit generalizability, (2) difficulty in capturing\nfine-grained traits like coherence and argumentation, and (3) inability to\nhandle multimodal contexts. In the era of Multimodal Large Language Models\n(MLLMs), we propose EssayJudge, the first multimodal benchmark to evaluate AES\ncapabilities across lexical-, sentence-, and discourse-level traits. By\nleveraging MLLMs' strengths in trait-specific scoring and multimodal context\nunderstanding, EssayJudge aims to offer precise, context-rich evaluations\nwithout manual feature engineering, addressing longstanding AES limitations.\nOur experiments with 18 representative MLLMs reveal gaps in AES performance\ncompared to human evaluation, particularly in discourse-level traits,\nhighlighting the need for further advancements in MLLM-based AES research.",
    "pdf_url": "http://arxiv.org/pdf/2502.11916v2",
    "published": "2025-02-17T15:31:59+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11915v1",
    "title": "On the robustness of ChatGPT in teaching Korean Mathematics",
    "authors": [
      "Phuong-Nam Nguyen",
      "Quang Nguyen-The",
      "An Vu-Minh",
      "Diep-Anh Nguyen",
      "Xuan-Lam Pham"
    ],
    "abstract": "ChatGPT, an Artificial Intelligence model, has the potential to revolutionize\neducation. However, its effectiveness in solving non-English questions remains\nuncertain. This study evaluates ChatGPT's robustness using 586 Korean\nmathematics questions. ChatGPT achieves 66.72% accuracy, correctly answering\n391 out of 586 questions. We also assess its ability to rate mathematics\nquestions based on eleven criteria and perform a topic analysis. Our findings\nshow that ChatGPT's ratings align with educational theory and test-taker\nperspectives. While ChatGPT performs well in question classification, it\nstruggles with non-English contexts, highlighting areas for improvement. Future\nresearch should address linguistic biases and enhance accuracy across diverse\nlanguages. Domain-specific optimizations and multilingual training could\nimprove ChatGPT's role in personalized education.",
    "pdf_url": "http://arxiv.org/pdf/2502.11915v1",
    "published": "2025-02-17T15:31:27+00:00",
    "categories": [
      "cs.AI",
      "math.HO",
      "I.2.7; K.3.1; G.3"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11914v11",
    "title": "Positive biorthogonal curvature on $S^2 \\times T^2$ via affine connection",
    "authors": [
      "Alexander Pigazzini"
    ],
    "abstract": "We address the long-standing problem of the existence of a Riemannian metric\non \\(S^2\\times T^2\\) with strictly positive biorthogonal curvature (\\(\nK_{\\text{biort}}(\\sigma) > 0 \\)). This work tackles this challenge within a\nweaker, yet geometrically consistent, framework by introducing an affine\nconnection, topologically motivated, on \\( S^2 \\times T^2 \\) with antisymmetric\ntorsion. Crucially, this torsion is calibrated via non-trivial cohomology\nclasses in \\( H^3(S^2 \\times T^2; \\mathbb{R}) \\cong \\mathbb{R}^2 \\), an\napproach that allows overcoming topological constraints such as \\( \\chi = 0 \\).\nWe demonstrate that this construction, while not requiring metric compatibility\n(though retaining the metric ( \\(g\\) ) for norms and orthogonality),\nsuccessfully yields strictly positive biorthogonal curvature across the\nmanifold.",
    "pdf_url": "http://arxiv.org/pdf/2502.11914v11",
    "published": "2025-02-17T15:30:35+00:00",
    "categories": [
      "math.DG",
      "53C05, 53C20, 53C21"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11913v1",
    "title": "PreAdaptFWI: Pretrained-Based Adaptive Residual Learning for Full-Waveform Inversion Without Dataset Dependency",
    "authors": [
      "Xintong Dong",
      "Zhengyi Yuan",
      "Jun Lin",
      "Shiqi Dong",
      "Xunqian Tong",
      "Yue Li"
    ],
    "abstract": "Full-waveform inversion (FWI) is a method that utilizes seismic data to\ninvert the physical parameters of subsurface media by minimizing the difference\nbetween simulated and observed waveforms. Due to its ill-posed nature, FWI is\nsusceptible to getting trapped in local minima. Consequently, various research\nefforts have attempted to combine neural networks with FWI to stabilize the\ninversion process. This study presents a simple yet effective training\nframework that is independent of dataset reliance and requires only moderate\npre-training on a simple initial model to stabilize network outputs. During the\ntransfer learning phase, the conventional FWI gradients will simultaneously\nupdate both the neural network and the proposed adaptive residual learning\nmodule, which learns the residual mapping of large-scale distribution features\nin the network's output, rather than directly fitting the target mapping.\nThrough this synergistic training paradigm, the proposed algorithm effectively\ninfers the physically-informed prior knowledge into a global representation of\nstratigraphic distribution, as well as capturing subtle variations in\ninter-layer velocities within local details, thereby escaping local optima.\nEvaluating the method on two benchmark models under various conditions,\nincluding absent low-frequency data, noise interference, and differing initial\nmodels, along with corresponding ablation experiments, consistently\ndemonstrates the superiority of the proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2502.11913v1",
    "published": "2025-02-17T15:30:17+00:00",
    "categories": [
      "physics.geo-ph",
      "cs.LG"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11912v2",
    "title": "Uncovering the atomic structure of substitutional platinum dopants in MoS$_2$ with single-sideband ptychography",
    "authors": [
      "David Lamprecht",
      "Anna Benzer",
      "Manuel LÃ¤ngle",
      "Mate Capin",
      "Clemens Mangler",
      "Toma Susi",
      "Lado Filipovic",
      "Jani Kotakoski"
    ],
    "abstract": "We substitute individual Pt atoms into monolayer MoS$_2$ and study the\nresulting atomic structures with single-sideband (SSB) ptychography supported\nby ab initio simulations. We demonstrate that while high-angle annular\ndark-field (HAADF) scanning transmission electron microscopy (STEM) imaging\nprovides excellent Z-contrast, distinguishing some defect types such as single\nand double sulfur vacancies remains challenging due to their low relative\ncontrast difference. However, SSB with its nearly linear Z-contrast and high\nphase sensitivity enables reliable identification of these defect\nconfigurations as well as various Pt dopant structures at significantly lower\nelectron doses. Our findings uncover the precise atomic placement and highlight\nthe potential of SSB ptychography for detailed structural analysis of\ndopant-modified 2D materials while minimizing beam-induced damage, offering new\npathways for understanding and engineering atomic-scale features in 2D systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11912v2",
    "published": "2025-02-17T15:30:03+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11911v3",
    "title": "Obstructed Atomic Limit Topological Protection in C4-Symmetric Photonic Crystals for Optical Communications",
    "authors": [
      "OndÅej NovÃ¡k",
      "Martin Veis",
      "Gervasi Herranz"
    ],
    "abstract": "Recent developments in photonic topological phases have revealed that\nprotected edge modes can emerge not only from global topological invariants,\nbut also from symmetry-enforced polarization mismatches between distinct bulk\nphases. In this work, we investigate the capabilities and limitations of a\nsquare-lattice ($C_4$-symmetric) photonic crystal composed of a single\ndielectric material that supports interface-localized modes at the boundary\nbetween regions characterized by distinct obstructed atomic limits (OALs).\nThese modes are confined to a common band gap and exhibit high transmission,\neven in the presence of structural perturbations.\n  Our analysis reveals that the interface modes are stabilized by a mismatch in\nthe position of Wannier centers between the two adjoining crystals. We\ndemonstrate nearly lossless transmission around sharp turns and through\nlocalized defects, though the robustness depends asymmetrically on the side of\nperturbation, reflecting the partial nature of the protection. We also show\nthat increasing the number of photonic crystal periods surrounding the\ninterface enhances both modal confinement and spectral stability. These\nfindings establish polarization mismatch between OALs as a practical and\nfabrication-compatible mechanism for engineering robust photonic transport in\n\\(C_4\\)-symmetric systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11911v3",
    "published": "2025-02-17T15:29:30+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.11910v2",
    "title": "Adversarial Alignment for LLMs Requires Simpler, Reproducible, and More Measurable Objectives",
    "authors": [
      "Leo Schwinn",
      "Yan Scholten",
      "Tom WollschlÃ¤ger",
      "Sophie Xhonneux",
      "Stephen Casper",
      "Stephan GÃ¼nnemann",
      "Gauthier Gidel"
    ],
    "abstract": "Misaligned research objectives have considerably hindered progress in\nadversarial robustness research over the past decade. For instance, an\nextensive focus on optimizing target metrics, while neglecting rigorous\nstandardized evaluation, has led researchers to pursue ad-hoc heuristic\ndefenses that were seemingly effective. Yet, most of these were exposed as\nflawed by subsequent evaluations, ultimately contributing little measurable\nprogress to the field. In this position paper, we illustrate that current\nresearch on the robustness of large language models (LLMs) risks repeating past\npatterns with potentially worsened real-world implications. To address this, we\nargue that realigned objectives are necessary for meaningful progress in\nadversarial alignment. To this end, we build on established cybersecurity\ntaxonomy to formally define differences between past and emerging threat models\nthat apply to LLMs. Using this framework, we illustrate that progress requires\ndisentangling adversarial alignment into addressable sub-problems and returning\nto core academic principles, such as measureability, reproducibility, and\ncomparability. Although the field presents significant challenges, the fresh\nstart on adversarial robustness offers the unique opportunity to build on past\nexperience while avoiding previous mistakes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11910v2",
    "published": "2025-02-17T15:28:40+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11909v3",
    "title": "Neural Guided Diffusion Bridges",
    "authors": [
      "Gefan Yang",
      "Frank van der Meulen",
      "Stefan Sommer"
    ],
    "abstract": "We propose a novel method for simulating conditioned diffusion processes\n(diffusion bridges) in Euclidean spaces. By training a neural network to\napproximate bridge dynamics, our approach eliminates the need for\ncomputationally intensive Markov Chain Monte Carlo (MCMC) methods or score\nmodeling. Compared to existing methods, it offers greater robustness across\nvarious diffusion specifications and conditioning scenarios. This applies in\nparticular to rare events and multimodal distributions, which pose challenges\nfor score-learning- and MCMC-based approaches. We introduce a flexible\nvariational family, partially specified by a neural network, for approximating\nthe diffusion bridge path measure. Once trained, it enables efficient sampling\nof independent bridges at a cost comparable to sampling the unconditioned\n(forward) process.",
    "pdf_url": "http://arxiv.org/pdf/2502.11909v3",
    "published": "2025-02-17T15:28:19+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.11908v1",
    "title": "Approximating a spatially-heterogeneously mass-emitting object by multiple point sources in a diffusion model",
    "authors": [
      "Qiyao Peng",
      "Sander C. Hille"
    ],
    "abstract": "Various biological cells secrete diffusing chemical compounds into their\nenvironment for communication purposes. Secretion usually takes place over the\ncell membrane in a spatially heterogeneous manner. Mathematical models of these\nprocesses will be part of more elaborate models, e.g. of the movement of immune\ncells that react to cytokines in their environment. Here, we compare two\napproaches to modelling of the secretion-diffusion process of signalling\ncompounds. The first is the so-called spatial exclusion model, in which the\nintracellular space is excluded from consideration and the computational space\nis the extracellular environment. The second consists of point source models,\nwhere the secreting cell is replaced by one or more non-spatial point sources\nor sinks, using -- mathematically -- Dirac delta distributions. We propose a\nmulti-Dirac approach and provide explicit expressions for the intensities of\nthe Dirac distributions. We show that two to three well-positioned Dirac points\nsuffice to approximate well a temporally constant but spatially heterogeneous\nflux distribution of compound over the cell membrane, for a wide range of\nvariation in flux density and diffusivity. The multi-Dirac approach is compared\nto a single-Dirac approach that was studied in previous work. Moreover, an\nexplicit Green's function approach is introduced that has significant benefits\nin circumventing numerical instability that may occur when the Dirac sources\nhave high intensities.",
    "pdf_url": "http://arxiv.org/pdf/2502.11908v1",
    "published": "2025-02-17T15:28:03+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.AP"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11907v1",
    "title": "Evaluating singular and near-singular integrals on $C^2$ smooth surfaces with a novel geometric method and closed form expressions",
    "authors": [
      "Andrew Zheng",
      "Spyros Alexakis",
      "Adam R Stinchcombe"
    ],
    "abstract": "Most Fredholm integral equations involve integrals with weakly singular\nkernels. Once the domain of integration is discretized into elements, these\nweakly singular kernels become strongly singular or ``near-singular\". Common\nmethods to compute these integrals when the kernel is a Green's function\ninclude the Duffy transform, polar coordinates with closed analytic formulas,\nand singularity extraction. However, these methods do not generalize well to\nthe normal derivatives of Green's functions. We provide methods to integrate\nboth the Green's function and its normal derivative on smooth surfaces\ndiscretized by triangular elements in three dimensions. For strongly singular\nintegrals involving normal derivatives of Green's functions, we provide two\nmethods that can accurately approximate the true integrals on the true domain.\nThe Geometric method uses geometric information of the true surface of\nintegration to approximate the original integral on the true domain using\npush-forward maps. The Interpolation-Duffy method heuristically cancels out the\nsingularity and then evaluates the integral using a quadrature scheme. Both\nmethods are better than simply setting the singular integrals to zero, while\nbeing faster than adaptive refinement methods. The explicit analytic formulas\nfor integrating polynomials $p$ of degree less than three are provided.",
    "pdf_url": "http://arxiv.org/pdf/2502.11907v1",
    "published": "2025-02-17T15:27:49+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65N38, 65R20"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11906v1",
    "title": "Comparison of Vectorization Capabilities of Different Compilers for X86 and ARM CPUs",
    "authors": [
      "Nazmus Sakib",
      "Tarun Prabhu",
      "Nandakishore Santhi",
      "John Shalf",
      "Abdel-Hameed A. Badawy"
    ],
    "abstract": "Most modern processors contain vector units that simultaneously perform the\nsame arithmetic operation over multiple sets of operands. The ability of\ncompilers to automatically vectorize code is critical to effectively using\nthese units. Understanding this capability is important for anyone writing\ncompute-intensive, high-performance, and portable code. We tested the ability\nof several compilers to vectorize code on x86 and ARM. We used the TSVC2 suite,\nwith modifications that made it more representative of real-world code. On x86,\nGCC reported 54% of the loops in the suite as having been vectorized, ICX\nreported 50%, and Clang, 46%. On ARM, GCC reported 56% of the loops as having\nbeen vectorized, ACFL reported 54%, and Clang, 47%. We found that the\nvectorized code did not always outperform the unvectorized code. In some cases,\ngiven two very similar vectorizable loops, a compiler would vectorize one but\nnot the other. We also report cases where a compiler vectorized a loop on only\none of the two platforms. Based on our experiments, we cannot definitively say\nif any one compiler is significantly better than the others at vectorizing code\non any given platform.",
    "pdf_url": "http://arxiv.org/pdf/2502.11906v1",
    "published": "2025-02-17T15:26:41+00:00",
    "categories": [
      "cs.PF",
      "cs.DC"
    ],
    "primary_category": "cs.PF"
  },
  {
    "id": "http://arxiv.org/abs/2502.12226v2",
    "title": "On Creating a Causally Grounded Usable Rating Method for Assessing the Robustness of Foundation Models Supporting Time Series",
    "authors": [
      "Kausik Lakkaraju",
      "Rachneet Kaur",
      "Parisa Zehtabi",
      "Sunandita Patra",
      "Siva Likitha Valluru",
      "Zhen Zeng",
      "Biplav Srivastava",
      "Marco Valtorta"
    ],
    "abstract": "Foundation Models (FMs) have improved time series forecasting in various\nsectors, such as finance, but their vulnerability to input disturbances can\nhinder their adoption by stakeholders, such as investors and analysts. To\naddress this, we propose a causally grounded rating framework to study the\nrobustness of Foundational Models for Time Series (FMTS) with respect to input\nperturbations. We evaluate our approach to the stock price prediction problem,\na well-studied problem with easily accessible public data, evaluating six\nstate-of-the-art (some multi-modal) FMTS across six prominent stocks spanning\nthree industries. The ratings proposed by our framework effectively assess the\nrobustness of FMTS and also offer actionable insights for model selection and\ndeployment. Within the scope of our study, we find that (1) multi-modal FMTS\nexhibit better robustness and accuracy compared to their uni-modal versions\nand, (2) FMTS pre-trained on time series forecasting task exhibit better\nrobustness and forecasting accuracy compared to general-purpose FMTS\npre-trained across diverse settings. Further, to validate our framework's\nusability, we conduct a user study showcasing FMTS prediction errors along with\nour computed ratings. The study confirmed that our ratings reduced the\ndifficulty for users in comparing the robustness of different systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.12226v2",
    "published": "2025-02-17T15:26:16+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11905v1",
    "title": "Exploring Quantum Control Landscape and Solution Space Complexity through Dimensionality Reduction & Optimization Algorithms",
    "authors": [
      "Haftu W. Fentaw",
      "Steve Campbell",
      "Simon Caton"
    ],
    "abstract": "Understanding the quantum control landscape (QCL) is important for designing\neffective quantum control strategies. In this study, we analyze the QCL for a\nsingle two-level quantum system (qubit) using various control strategies. We\nemploy Principal Component Analysis (PCA), to visualize and analyze the QCL for\nhigher dimensional control parameters. Our results indicate that dimensionality\nreduction techniques such as PCA, can play an important role in understanding\nthe complex nature of quantum control in higher dimensions. Evaluations of\ntraditional control techniques and machine learning algorithms reveal that\nGenetic Algorithms (GA) outperform Stochastic Gradient Descent (SGD), while\nQ-learning (QL) shows great promise compared to Deep Q-Networks (DQN) and\nProximal Policy Optimization (PPO). Additionally, our experiments highlight the\nimportance of reward function design in DQN and PPO demonstrating that using\nimmediate reward results in improved performance rather than delayed rewards\nfor systems with short time steps. A study of solution space complexity was\nconducted by using Cluster Density Index (CDI) as a key metric for analyzing\nthe density of optimal solutions in the landscape. The CDI reflects cluster\nquality and helps determine whether a given algorithm generates regions of high\nfidelity or not. Our results provide insights into effective quantum control\nstrategies, emphasizing the significance of parameter selection and algorithm\noptimization.",
    "pdf_url": "http://arxiv.org/pdf/2502.11905v1",
    "published": "2025-02-17T15:26:15+00:00",
    "categories": [
      "quant-ph",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11904v3",
    "title": "A formal implementation of Behavior Trees to act in robotics",
    "authors": [
      "Felix Ingrand"
    ],
    "abstract": "Behavior Trees (BT) are becoming quite popular as an Acting component of\nautonomous robotic systems. We propose to define a formal semantics to BT by\ntranslating them to a formal language which enables us to perform verification\nof programs written with BT, as well as runtime verification while these BT\nexecute. This allows us to formally verify BT correctness without requiring BT\nprogrammers to master formal languages and without compromising BT most\nvaluable features: modularity, flexibility and reusability. We present the\nformal framework we use: Fiacre, its language and the produced TTS model; Tina,\nits model checking tools and Hippo, its runtime verification engine. We then\nshow how the translation from BT to Fiacre is automatically done, the type of\nformal LTL and CTL properties we can check offline and how to execute the\nformal model online in place of a regular BT engine. We illustrate our approach\non two robotics applications, and show how BT can be extended with state\nvariables, eval nodes, node evaluation results and benefit of other features\navailable in the Fiacre formal framework (e.g., time).",
    "pdf_url": "http://arxiv.org/pdf/2502.11904v3",
    "published": "2025-02-17T15:26:10+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11903v2",
    "title": "MMRC: A Large-Scale Benchmark for Understanding Multimodal Large Language Model in Real-World Conversation",
    "authors": [
      "Haochen Xue",
      "Feilong Tang",
      "Ming Hu",
      "Yexin Liu",
      "Qidong Huang",
      "Yulong Li",
      "Chengzhi Liu",
      "Zhongxing Xu",
      "Chong Zhang",
      "Chun-Mei Feng",
      "Yutong Xie",
      "Imran Razzak",
      "Zongyuan Ge",
      "Jionglong Su",
      "Junjun He",
      "Yu Qiao"
    ],
    "abstract": "Recent multimodal large language models (MLLMs) have demonstrated significant\npotential in open-ended conversation, generating more accurate and personalized\nresponses. However, their abilities to memorize, recall, and reason in\nsustained interactions within real-world scenarios remain underexplored. This\npaper introduces MMRC, a Multi-Modal Real-world Conversation benchmark for\nevaluating six core open-ended abilities of MLLMs: information extraction,\nmulti-turn reasoning, information update, image management, memory recall, and\nanswer refusal. With data collected from real-world scenarios, MMRC comprises\n5,120 conversations and 28,720 corresponding manually labeled questions, posing\na significant challenge to existing MLLMs. Evaluations on 20 MLLMs in MMRC\nindicate an accuracy drop during open-ended interactions. We identify four\ncommon failure patterns: long-term memory degradation, inadequacies in updating\nfactual knowledge, accumulated assumption of error propagation, and reluctance\nto say no. To mitigate these issues, we propose a simple yet effective\nNOTE-TAKING strategy, which can record key information from the conversation\nand remind the model during its responses, enhancing conversational\ncapabilities. Experiments across six MLLMs demonstrate significant performance\nimprovements.",
    "pdf_url": "http://arxiv.org/pdf/2502.11903v2",
    "published": "2025-02-17T15:24:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11902v1",
    "title": "Experimental Validation of String Oscillation in Subharmonic Generation",
    "authors": [
      "Shotaro Kawano",
      "Kenji Kobayashi",
      "Takuya Suzuki",
      "Naoki Ichiji"
    ],
    "abstract": "The lowest notes produced by string instruments are typically limited by the\nfundamental vibration of the strings. However, precise control of bow pressure\ncan lead to the production of even lower notes. Despite significant interest in\nthis counterintuitive technique and various proposed explanations, no\nconclusive evidence has been provided, making detailed discussions of the\nunderlying mechanism challenging. In this study, we employ high-speed imaging\nto visualize the spatial vibration modes of stringed instruments, confirming\nHelmholtz motion and its modifications under subharmonic conditions. Finite\nelement simulations further demonstrated that increased bow pressure amplifies\nfrictional forces, suppressing standard vibrations and allowing subharmonic\nfrequencies to emerge. Our results provide the clear experimental validation of\nthe mechanism underlying subharmonic sound production, providing an avenue for\nfurther exploration of vibrational and oscillatory phenomena.",
    "pdf_url": "http://arxiv.org/pdf/2502.11902v1",
    "published": "2025-02-17T15:24:26+00:00",
    "categories": [
      "physics.class-ph",
      "physics.app-ph"
    ],
    "primary_category": "physics.class-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11901v2",
    "title": "Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarcity",
    "authors": [
      "Dylan Zhang",
      "Justin Wang",
      "Tianran Sun"
    ],
    "abstract": "Existing LMs struggle with proof-oriented programming due to data scarcity,\nwhich manifest in two key ways: (1) a lack of sufficient corpora for\nproof-oriented programming languages such as F*, and (2) the absence of\nlarge-scale, project-level proof-oriented implementations that can teach the\nmodel the intricate reasoning process when performing proof-oriented\nprogramming. We present the first on synthetic data augmentation for project\nlevel proof oriented programming for both generation and repair. Our method\naddresses data scarcity by synthesizing basic proof-oriented programming\nproblems for proficiency in that language; incorporating diverse coding data\nfor reasoning capability elicitation and creating new proofs and repair data\nwithin existing repositories. This approach enables language models to both\nsynthesize and repair proofs for function- and repository-level code. We show\nthat our fine-tuned 14B parameter model, PoPilot, can exceed the performance of\nthe models that outperforms GPT-4o in project-level proof-oriented programming\nby 64% relative margin, and can improve GPT-4o's performance by 54% by\nrepairing its outputs over GPT-4o's self-repair.",
    "pdf_url": "http://arxiv.org/pdf/2502.11901v2",
    "published": "2025-02-17T15:24:11+00:00",
    "categories": [
      "cs.CL",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11900v2",
    "title": "Ansatz-free Hamiltonian learning with Heisenberg-limited scaling",
    "authors": [
      "Hong-Ye Hu",
      "Muzhou Ma",
      "Weiyuan Gong",
      "Qi Ye",
      "Yu Tong",
      "Steven T. Flammia",
      "Susanne F. Yelin"
    ],
    "abstract": "Learning the unknown interactions that govern a quantum system is crucial for\nquantum information processing, device benchmarking, and quantum sensing. The\nproblem, known as Hamiltonian learning, is well understood under the assumption\nthat interactions are local, but this assumption may not hold for arbitrary\nHamiltonians. Previous methods all require high-order inverse polynomial\ndependency with precision, unable to surpass the standard quantum limit and\nreach the gold standard Heisenberg-limited scaling. Whether Heisenberg-limited\nHamiltonian learning is possible without prior assumptions about the\ninteraction structures, a challenge we term \\emph{ansatz-free Hamiltonian\nlearning}, remains an open question. In this work, we present a quantum\nalgorithm to learn arbitrary sparse Hamiltonians without any structure\nconstraints using only black-box queries of the system's real-time evolution\nand minimal digital controls to attain Heisenberg-limited scaling in estimation\nerror. Our method is also resilient to state-preparation-and-measurement\nerrors, enhancing its practical feasibility. We numerically demonstrate our\nansatz-free protocol for learning physical Hamiltonians and validating analog\nquantum simulations, benchmarking our performance against the state-of-the-art\nHeisenberg-limited learning approach. Moreover, we establish a fundamental\ntrade-off between total evolution time and quantum control on learning\narbitrary interactions, revealing the intrinsic interplay between\ncontrollability and total evolution time complexity for any learning algorithm.\nThese results pave the way for further exploration into Heisenberg-limited\nHamiltonian learning in complex quantum systems under minimal assumptions,\npotentially enabling new benchmarking and verification protocols.",
    "pdf_url": "http://arxiv.org/pdf/2502.11900v2",
    "published": "2025-02-17T15:23:59+00:00",
    "categories": [
      "quant-ph",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11899v1",
    "title": "Stationary wave solutions to two dimensional viscous shallow water equations: theory of small and large solutions",
    "authors": [
      "Noah Stevenson",
      "Ian Tice"
    ],
    "abstract": "We study a system of forced viscous shallow water equations with nontrivial\nbathymetry in two spatial dimensions. We develop a well-posedness theory for\nsmall but arbitrary forcing data, as well as for a fixed data profile but large\namplitude. In the latter case, solutions may actually fail to exist for large\namplitude, but in this case we prove that one of three physically meaningful\nbreakdown scenarios occurs. Through the use of implicit function theorem\ntechniques and a priori estimates, we construct both spatially periodic and\nsolitary (non-periodic but spatially localized) solutions. The solitary case is\nsubstantially more complicated, requiring a delicate analysis in weighted\nSobolev spaces. To the best of our knowledge, these results constitute the\nfirst general construction of stationary wave solutions, large or otherwise, to\nthe viscous shallow water equations and the first general analysis of large\nsolitary wave solutions to any viscous free boundary fluid model.",
    "pdf_url": "http://arxiv.org/pdf/2502.11899v1",
    "published": "2025-02-17T15:23:44+00:00",
    "categories": [
      "math.AP",
      "Primary 35Q35, 35C07, 35B30, Secondary 47J07, 76A20, 35M30"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11898v1",
    "title": "A family of triharmonic maps to spheres in all dimensions greater than two",
    "authors": [
      "Volker Branding",
      "Anna Siffert"
    ],
    "abstract": "We present a construction method for triharmonic maps to spheres. In\nparticular, we show that for any $m\\in\\mathbb{N}$ with $m\\geq 3$ there exists a\ntriharmonic map from $\\mathbb{R}^m\\setminus\\{0\\}$ into a round sphere. In\naddition, we provide a construction method for proper $r$-harmonic maps between\nspheres based on a suitable deformation of eigenmaps.",
    "pdf_url": "http://arxiv.org/pdf/2502.11898v1",
    "published": "2025-02-17T15:23:33+00:00",
    "categories": [
      "math.DG",
      "math.AP"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11897v2",
    "title": "DLFR-VAE: Dynamic Latent Frame Rate VAE for Video Generation",
    "authors": [
      "Zhihang Yuan",
      "Siyuan Wang",
      "Rui Xie",
      "Hanling Zhang",
      "Tongcheng Fang",
      "Yuzhang Shang",
      "Shengen Yan",
      "Guohao Dai",
      "Yu Wang"
    ],
    "abstract": "In this paper, we propose the Dynamic Latent Frame Rate VAE (DLFR-VAE), a\ntraining-free paradigm that can make use of adaptive temporal compression in\nlatent space. While existing video generative models apply fixed compression\nrates via pretrained VAE, we observe that real-world video content exhibits\nsubstantial temporal non-uniformity, with high-motion segments containing more\ninformation than static scenes. Based on this insight, DLFR-VAE dynamically\nadjusts the latent frame rate according to the content complexity.\nSpecifically, DLFR-VAE comprises two core innovations: (1) A Dynamic Latent\nFrame Rate Scheduler that partitions videos into temporal chunks and adaptively\ndetermines optimal frame rates based on information-theoretic content\ncomplexity, and (2) A training-free adaptation mechanism that transforms\npretrained VAE architectures into a dynamic VAE that can process features with\nvariable frame rates. Our simple but effective DLFR-VAE can function as a\nplug-and-play module, seamlessly integrating with existing video generation\nmodels and accelerating the video generation process.",
    "pdf_url": "http://arxiv.org/pdf/2502.11897v2",
    "published": "2025-02-17T15:22:31+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11896v1",
    "title": "CAMEL: Continuous Action Masking Enabled by Large Language Models for Reinforcement Learning",
    "authors": [
      "Yanxiao Zhao",
      "Yangge Qian",
      "Jingyang Shan",
      "Xiaolin Qin"
    ],
    "abstract": "Reinforcement learning (RL) in continuous action spaces encounters persistent\nchallenges, such as inefficient exploration and convergence to suboptimal\nsolutions. To address these limitations, we propose CAMEL, a novel framework\nintegrating LLM-generated suboptimal policies into the RL training pipeline.\nCAMEL leverages dynamic action masking and an adaptive epsilon-masking\nmechanism to guide exploration during early training stages while gradually\nenabling agents to optimize policies independently. At the core of CAMEL lies\nthe integration of Python-executable suboptimal policies generated by LLMs\nbased on environment descriptions and task objectives. Although simplistic and\nhard-coded, these policies offer valuable initial guidance for RL agents. To\neffectively utilize these priors, CAMEL employs masking-aware optimization to\ndynamically constrain the action space based on LLM outputs. Additionally,\nepsilon-masking gradually reduces reliance on LLM-generated guidance, enabling\nagents to transition from constrained exploration to autonomous policy\nrefinement. Experimental validation on Gymnasium MuJoCo environments\ndemonstrates the effectiveness of CAMEL. In Hopper-v4 and Ant-v4, LLM-generated\npolicies significantly improve sample efficiency, achieving performance\ncomparable to or surpassing expert masking baselines. For Walker2d-v4, where\nLLMs struggle to accurately model bipedal gait dynamics, CAMEL maintains robust\nRL performance without notable degradation, highlighting the framework's\nadaptability across diverse tasks. While CAMEL shows promise in enhancing\nsample efficiency and mitigating convergence challenges, these issues remain\nopen for further research. Future work aims to generalize CAMEL to multimodal\nLLMs for broader observation-action spaces and automate policy evaluation,\nreducing human intervention and enhancing scalability in RL training pipelines.",
    "pdf_url": "http://arxiv.org/pdf/2502.11896v1",
    "published": "2025-02-17T15:22:19+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11895v1",
    "title": "Continual Quantization-Aware Pre-Training: When to transition from 16-bit to 1.58-bit pre-training for BitNet language models?",
    "authors": [
      "Jacob Nielsen",
      "Peter Schneider-Kamp",
      "Lukas Galke"
    ],
    "abstract": "Large language models (LLMs) require immense resources for training and\ninference. Quantization, a technique that reduces the precision of model\nparameters, offers a promising solution for improving LLM efficiency and\nsustainability. While post-training quantization methods typically achieve 4-8\nbits per parameter, recent research suggests that training LLMs with 1.58 bits\nper weight parameter from scratch can maintain model accuracy while greatly\nreducing memory requirements and energy consumption at inference time. Here, we\ninvestigate a training strategy for quantization-aware pre-training, where the\nmodels are first trained with 16-bit precision and then transition into\n1.58-bit quantization-aware training. Our results on 11 downstream tasks show\nthat this 16-to-1.58-bit training strategy is preferable over full 1.58-bit\ntraining and leaves models closer to those which have undergone 16-bit\ntraining. We further investigate the effects of retaining the optimizer state\nat the transition point and gradually phasing in quantization strength --\nfinding that both techniques alleviate the magnitude of loss spikes, but also\nthat these effects can be compensated through further training.",
    "pdf_url": "http://arxiv.org/pdf/2502.11895v1",
    "published": "2025-02-17T15:21:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11894v1",
    "title": "AI-guided transition path sampling of lipid flip-flop and membrane nanoporation",
    "authors": [
      "Matthias Post",
      "Gerhard Hummer"
    ],
    "abstract": "We study lipid translocation (\"flip-flop\") between the leaflets of a planar\nlipid bilayer with transition path sampling (TPS). Rare flip-flops compete with\nbiological machineries that actively establish asymmetric lipid compositions.\nArtificial Intelligence (AI) guided TPS captures flip-flop without biasing the\ndynamics by initializing molecular dynamics simulations close to the tipping\npoint, i.e., where it is equally likely for a lipid to next go to one or the\nother leaflet. We train a neural network model on the fly to predict the\nrespective probability, i.e., the \"committor\" encoding the mechanism of\nflip-flop. Whereas coarse-grained DMPC lipids \"tunnel\" through the hydrophobic\nbilayer, unaided by water, atomistic DMPC lipids instead utilize spontaneously\nformed water nanopores to traverse to the other side. For longer DSPC lipids,\nthese membrane defects are less stable, with lipid transfer along transient\nwater threads in a locally thinned membrane emerging as a third distinct\nmechanism. Remarkably, in the high (~660) dimensional feature space of the deep\nneural networks, the reaction coordinate becomes effectively linear, in line\nwith Cover's theorem and consistent with the idea of dominant reaction tubes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11894v1",
    "published": "2025-02-17T15:20:47+00:00",
    "categories": [
      "cond-mat.soft",
      "q-bio.BM"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2502.11893v2",
    "title": "Rethinking Benign Overfitting in Two-Layer Neural Networks",
    "authors": [
      "Ruichen Xu",
      "Kexin Chen"
    ],
    "abstract": "Recent theoretical studies (Kou et al., 2023; Cao et al., 2022) have revealed\na sharp phase transition from benign to harmful overfitting when the\nnoise-to-feature ratio exceeds a threshold-a situation common in long-tailed\ndata distributions where atypical data is prevalent. However, harmful\noverfitting rarely happens in overparameterized neural networks. Further\nexperimental results suggested that memorization is necessary for achieving\nnear-optimal generalization error in long-tailed data distributions (Feldman &\nZhang, 2020). We argue that this discrepancy between theoretical predictions\nand empirical observations arises because previous feature-noise data models\noverlook the heterogeneous nature of noise across different data classes. In\nthis paper, we refine the feature-noise data model by incorporating\nclass-dependent heterogeneous noise and re-examine the overfitting phenomenon\nin neural networks. Through a comprehensive analysis of the training dynamics,\nwe establish test loss bounds for the refined model. Our findings reveal that\nneural networks can leverage \"data noise\" to learn implicit features that\nimprove the classification accuracy for long-tailed data. Our analysis also\nprovides a training-free metric for evaluating data influence on test\nperformance. Experimental validation on both synthetic and real-world datasets\nsupports our theoretical results.",
    "pdf_url": "http://arxiv.org/pdf/2502.11893v2",
    "published": "2025-02-17T15:20:04+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11892v1",
    "title": "Pulse Compression by an Optical Push Broom On a Chip",
    "authors": [
      "Boyi Zhang",
      "Maurice Pfeiffer",
      "Mahmoud A. Gaafar",
      "He Li",
      "Xinlun Cai",
      "Juntao Li",
      "Manfred Eich",
      "Alexander Yu. Petrov"
    ],
    "abstract": "In this study, we report a first experimental demonstration of pulse\ncompression by a gradual refractive index front moving in a periodically\nmodulated silicon waveguide, the so-called optical push broom effect. Optical\npush broom captures and confines the input signal pulse in a faster propagating\nrefractive index front, driven by a pump pulse. This is a spatio-temporal\nanalogue of light trapping in a tapered plasmonic waveguide where light is\ncontinuously changing its wavevector approaching zero group velocity and, thus,\nstopped without reflection. Here the signal is accelerated by the front until\nthe signal velocity matches the front velocity, thus stopping the light in\nrespect to the front. We employ the slowly varying envelope approximation to\nmodel this phenomenon. Notably, we well reproduced the experimental frequency\nshift at the output corresponding to the temporal delay at the input.",
    "pdf_url": "http://arxiv.org/pdf/2502.11892v1",
    "published": "2025-02-17T15:19:57+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.11891v1",
    "title": "From Open-Vocabulary to Vocabulary-Free Semantic Segmentation",
    "authors": [
      "Klara Reichard",
      "Giulia Rizzoli",
      "Stefano Gasperini",
      "Lukas Hoyer",
      "Pietro Zanuttigh",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "abstract": "Open-vocabulary semantic segmentation enables models to identify novel object\ncategories beyond their training data. While this flexibility represents a\nsignificant advancement, current approaches still rely on manually specified\nclass names as input, creating an inherent bottleneck in real-world\napplications. This work proposes a Vocabulary-Free Semantic Segmentation\npipeline, eliminating the need for predefined class vocabularies. Specifically,\nwe address the chicken-and-egg problem where users need knowledge of all\npotential objects within a scene to identify them, yet the purpose of\nsegmentation is often to discover these objects. The proposed approach\nleverages Vision-Language Models to automatically recognize objects and\ngenerate appropriate class names, aiming to solve the challenge of class\nspecification and naming quality. Through extensive experiments on several\npublic datasets, we highlight the crucial role of the text encoder in model\nperformance, particularly when the image text classes are paired with generated\ndescriptions. Despite the challenges introduced by the sensitivity of the\nsegmentation text encoder to false negatives within the class tagging process,\nwhich adds complexity to the task, we demonstrate that our fully automated\npipeline significantly enhances vocabulary-free segmentation accuracy across\ndiverse real-world scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.11891v1",
    "published": "2025-02-17T15:17:08+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11890v2",
    "title": "Revisiting Classification Taxonomy for Grammatical Errors",
    "authors": [
      "Deqing Zou",
      "Jingheng Ye",
      "Yulu Liu",
      "Yu Wu",
      "Zishan Xu",
      "Yinghui Li",
      "Hai-Tao Zheng",
      "Bingxu An",
      "Zhao Wei",
      "Yong Xu"
    ],
    "abstract": "Grammatical error classification plays a crucial role in language learning\nsystems, but existing classification taxonomies often lack rigorous validation,\nleading to inconsistencies and unreliable feedback. In this paper, we revisit\nprevious classification taxonomies for grammatical errors by introducing a\nsystematic and qualitative evaluation framework. Our approach examines four\naspects of a taxonomy, i.e., exclusivity, coverage, balance, and usability.\nThen, we construct a high-quality grammatical error classification dataset\nannotated with multiple classification taxonomies and evaluate them grounding\non our proposed evaluation framework. Our experiments reveal the drawbacks of\nexisting taxonomies. Our contributions aim to improve the precision and\neffectiveness of error analysis, providing more understandable and actionable\nfeedback for language learners.",
    "pdf_url": "http://arxiv.org/pdf/2502.11890v2",
    "published": "2025-02-17T15:16:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11889v1",
    "title": "MQG4AI Towards Responsible High-risk AI -- Illustrated for Transparency Focusing on Explainability Techniques",
    "authors": [
      "Miriam Elia",
      "Alba Maria Lopez",
      "Katherin Alexandra Corredor",
      "Bernhard Bauer",
      "Esteban Garcia-Cuesta"
    ],
    "abstract": "As artificial intelligence (AI) systems become increasingly integrated into\ncritical domains, ensuring their responsible design and continuous development\nis imperative. Effective AI quality management (QM) requires tools and\nmethodologies that address the complexities of the AI lifecycle. In this paper,\nwe propose an approach for AI lifecycle planning that bridges the gap between\ngeneric guidelines and use case-specific requirements (MQG4AI). Our work aims\nto contribute to the development of practical tools for implementing\nResponsible AI (RAI) by aligning lifecycle planning with technical, ethical and\nregulatory demands. Central to our approach is the introduction of a flexible\nand customizable Methodology based on Quality Gates, whose building blocks\nincorporate RAI knowledge through information linking along the AI lifecycle in\na continuous manner, addressing AIs evolutionary character. For our present\ncontribution, we put a particular emphasis on the Explanation stage during\nmodel development, and illustrate how to align a guideline to evaluate the\nquality of explanations with MQG4AI, contributing to overall Transparency.",
    "pdf_url": "http://arxiv.org/pdf/2502.11889v1",
    "published": "2025-02-17T15:14:52+00:00",
    "categories": [
      "cs.CY",
      "K.4"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.12225v2",
    "title": "Subjective Logic Encodings",
    "authors": [
      "Jake Vasilakes",
      "Chrysoula Zerva",
      "Sophia Ananiadou"
    ],
    "abstract": "Many existing approaches for learning from labeled data assume the existence\nof gold-standard labels. According to these approaches, inter-annotator\ndisagreement is seen as noise to be removed, either through refinement of\nannotation guidelines, label adjudication, or label filtering. However,\nannotator disagreement can rarely be totally eradicated, especially on more\nsubjective tasks such as sentiment analysis or hate speech detection where\ndisagreement is natural. Therefore, a new approach to learning from labeled\ndata, called data perspectivism, seeks to leverage inter-annotator disagreement\nto learn models that stay true to the inherent uncertainty of the task by\ntreating annotations as opinions of the annotators, rather than gold-standard\nfacts. Despite this conceptual grounding, existing methods under data\nperspectivism are limited to using disagreement as the sole source of\nannotation uncertainty. To expand the possibilities of data perspectivism, we\nintroduce Subjective Logic Encodings (SLEs), a flexible framework for\nconstructing classification targets that explicitly encodes annotations as\nopinions of the annotators. Based on Subjective Logic Theory, SLEs encode\nlabels as Dirichlet distributions and provide principled methods for encoding\nand aggregating various types of annotation uncertainty -- annotator\nconfidence, reliability, and disagreement -- into the targets. We show that\nSLEs are a generalization of other types of label encodings as well as how to\nestimate models to predict SLEs using a distribution matching objective.",
    "pdf_url": "http://arxiv.org/pdf/2502.12225v2",
    "published": "2025-02-17T15:14:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11888v2",
    "title": "Exploring the Most Extreme Gamma-Ray Blazars Using Broadband Spectral Energy Distributions",
    "authors": [
      "M. LÃ¡inez",
      "M. Nievas-Rosillo",
      "A. DomÃ­nguez",
      "J. L. Contreras",
      "J. Becerra GonzÃ¡lez",
      "A. Dinesh",
      "V. S. Paliya"
    ],
    "abstract": "Extreme high-synchrotron peaked blazars (EHSPs) are rare high-energy sources\ncharacterised by synchrotron peaks beyond 10$^{17}$ Hz in their spectral energy\ndistributions (SEDs). Their extreme properties challenge conventional blazar\nemission models and provide a unique opportunity to test the limits of particle\nacceleration and emission mechanisms in relativistic jets. However, the number\nof identified EHSPs is still small, limiting comprehensive studies of their\npopulation and characteristics. This study aims to identify new EHSP candidates\nand characterise their emission properties. A sample of 124 $\\gamma$-ray\nblazars was analysed, selected for their high synchrotron peak frequencies and\n$\\gamma$-ray emission properties, with a focus on sources showing low\nvariability and good broadband data coverage. Their SEDs were constructed using\narchival multi-wavelength data from the SSDC SED Builder service, supplemented\nwith recent Swift-UVOT, Swift-XRT, and Fermi-LAT observations. The SEDs were\nmodelled with a one-zone synchrotron/synchrotron-self-Compton framework,\nclassifying sources by synchrotron peak frequency. We identify 66 new EHSP\ncandidates, significantly expanding the known population. A clear correlation\nbetween synchrotron peak frequency and the magnetic-to-kinetic energy density\nratio is found, with the most extreme EHSPs nearing equipartition. Host galaxy\nemission is detected in many sources, but no significant differences are\nobserved between elliptical and lenticular hosts. Our analysis suggests that\nnine high-synchrotron peaked/EHSPs could be observed by CTAO at $>5\\sigma$ (20\nat $>3\\sigma$) in 20-hour exposures, indicating that while the overall\ndetection rate remains modest, a subset of these sources is within reach of\nnext-generation very-high-energy gamma-ray instruments.",
    "pdf_url": "http://arxiv.org/pdf/2502.11888v2",
    "published": "2025-02-17T15:13:59+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11887v2",
    "title": "Stonefish: Supporting Machine Learning Research in Marine Robotics",
    "authors": [
      "Michele Grimaldi",
      "Patryk Cieslak",
      "Eduardo Ochoa",
      "Vibhav Bharti",
      "Hayat Rajani",
      "Ignacio Carlucho",
      "Maria Koskinopoulou",
      "Yvan R. Petillot",
      "Nuno Gracias"
    ],
    "abstract": "Simulations are highly valuable in marine robotics, offering a cost-effective\nand controlled environment for testing in the challenging conditions of\nunderwater and surface operations. Given the high costs and logistical\ndifficulties of real-world trials, simulators capable of capturing the\noperational conditions of subsea environments have become key in developing and\nrefining algorithms for remotely-operated and autonomous underwater vehicles.\nThis paper highlights recent enhancements to the Stonefish simulator, an\nadvanced open-source platform supporting development and testing of marine\nrobotics solutions. Key updates include a suite of additional sensors, such as\nan event-based camera, a thermal camera, and an optical flow camera, as well\nas, visual light communication, support for tethered operations, improved\nthruster modelling, more flexible hydrodynamics, and enhanced sonar accuracy.\nThese developments and an automated annotation tool significantly bolster\nStonefish's role in marine robotics research, especially in the field of\nmachine learning, where training data with a known ground truth is hard or\nimpossible to collect.",
    "pdf_url": "http://arxiv.org/pdf/2502.11887v2",
    "published": "2025-02-17T15:13:41+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11886v1",
    "title": "LIMR: Less is More for RL Scaling",
    "authors": [
      "Xuefeng Li",
      "Haoyang Zou",
      "Pengfei Liu"
    ],
    "abstract": "In this paper, we ask: what truly determines the effectiveness of RL training\ndata for enhancing language models' reasoning capabilities? While recent\nadvances like o1, Deepseek R1, and Kimi1.5 demonstrate RL's potential, the lack\nof transparency about training data requirements has hindered systematic\nprogress. Starting directly from base models without distillation, we challenge\nthe assumption that scaling up RL training data inherently improves\nperformance. we demonstrate that a strategically selected subset of just 1,389\nsamples can outperform the full 8,523-sample dataset. We introduce Learning\nImpact Measurement (LIM), an automated method to evaluate and prioritize\ntraining samples based on their alignment with model learning trajectories,\nenabling efficient resource utilization and scalable implementation. Our method\nachieves comparable or even superior performance using only 1,389 samples\nversus the full 8,523 samples dataset. Notably, while recent data-efficient\napproaches (e.g., LIMO and s1) show promise with 32B-scale models, we find it\nsignificantly underperforms at 7B-scale through supervised fine-tuning (SFT).\nIn contrast, our RL-based LIMR achieves 16.7% higher accuracy on AIME24 and\noutperforms LIMO and s1 by 13.0% and 22.2% on MATH500. These results\nfundamentally reshape our understanding of RL scaling in LLMs, demonstrating\nthat precise sample selection, rather than data scale, may be the key to\nunlocking enhanced reasoning capabilities. For reproducible research and future\ninnovation, we are open-sourcing LIMR, including implementation of LIM,\ntraining and evaluation code, curated datasets, and trained models at\nhttps://github.com/GAIR-NLP/LIMR.",
    "pdf_url": "http://arxiv.org/pdf/2502.11886v1",
    "published": "2025-02-17T15:13:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11885v1",
    "title": "Fiber-based diffractive deep neural network",
    "authors": [
      "BahadÄ±r Utku Kesgin",
      "Firdevs YÃ¼ce",
      "UÄur TeÄin"
    ],
    "abstract": "Optical computing has reemerged as a promising alternative computing paradigm\nfor providing energy-efficient information processing in the age of artificial\nintelligence. Among various photonic neural network platforms, diffractive\noptical processing systems in free space proved high-performance computing with\nhigh parallelism. Here, we report fiber-based diffractive deep neural networks\nby optimizing the linear coupling of the waveguide modes. Our approach\ndemonstrated high performance in various machine learning tasks such as\nbiomedical disease, fashion, and geospatial classification with a simple\nreadout layer and all-optically. Operating on linear optics, our architecture\nperforms on par with neural networks even in complex datasets where the data\ncannot be separated using linear operations. These results will enable\nefficient and scalable diffractive information processing with waveguides for\nreal-life computing, telecommunications, and imaging applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11885v1",
    "published": "2025-02-17T15:13:19+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.11884v1",
    "title": "Trace operators for Riemann--Liouville fractional equations",
    "authors": [
      "Paola Loreti",
      "Daniela Sforza"
    ],
    "abstract": "We begin with a brief overview of the most commonly used fractional\nderivatives, namely the Caputo and Riemann-Liouville derivatives. We then focus\non the study of the fractional time wave equation with the Riemann-Liouville\nderivative, addressing key questions such as well-posedness, regularity, and a\ntrace result in appropriate interpolation spaces. Additionally, we explore the\nduality relationship with the Caputo fractional time derivative. The analysis\nis based on expanding the solution in terms of Mittag-Leffler functions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11884v1",
    "published": "2025-02-17T15:12:39+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2503.05722v1",
    "title": "The Role of AI, Blockchain, Cloud, and Data (ABCD) in Enhancing Learning Assessments of College Students",
    "authors": [
      "Joel Mark P. Rodriguez",
      "Genesis S. Austria",
      "Glen B. Millar"
    ],
    "abstract": "This study investigates how ABCD technologies can improve learning\nassessments in higher education. The objective is to research how students\nperceive things, plan their behavior, and how ABCD technologies affect\nindividual learning, academic integrity, co-learning, and trust in the\nassessment. Through a quantitative research design, survey responses were\ngathered from university students, and statistical tests, such as correlation\nand regression, were used to establish relationships between Perceived\nUsefulness (PU), Perceived Ease of Use (PEU), and Behavioral Intention (BI)\ntowards ABCD adoption. The results showed that there was no significant\nrelationship between PU, PEU, and BI, which suggests that students' attitudes,\ninstitutional policies, faculty support, and infrastructure matter more in\nadoption than institutional policies, faculty support, and infrastructure.\nWhile students recognize ABCD's efficiency and security benefits, fairness,\nease of use, and engagement issues limit their adoption of these technologies.\nThe research adds to Technology Acceptance Model (TAM) and Constructivist\nLearning Theory (CLT) by emphasizing external drivers of technology adoption.\nThe limitations are based on self-reported data and one institutional sample.\nIt is suggested that universities invest in faculty development,\ninfrastructure, and policy-making to facilitate effective and ethical use of\nABCD technologies in higher education.",
    "pdf_url": "http://arxiv.org/pdf/2503.05722v1",
    "published": "2025-02-17T15:11:44+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11883v1",
    "title": "FairDiverse: A Comprehensive Toolkit for Fair and Diverse Information Retrieval Algorithms",
    "authors": [
      "Chen Xu",
      "Zhirui Deng",
      "Clara Rus",
      "Xiaopeng Ye",
      "Yuanna Liu",
      "Jun Xu",
      "Zhicheng Dou",
      "Ji-Rong Wen",
      "Maarten de Rijke"
    ],
    "abstract": "In modern information retrieval (IR). achieving more than just accuracy is\nessential to sustaining a healthy ecosystem, especially when addressing\nfairness and diversity considerations. To meet these needs, various datasets,\nalgorithms, and evaluation frameworks have been introduced. However, these\nalgorithms are often tested across diverse metrics, datasets, and experimental\nsetups, leading to inconsistencies and difficulties in direct comparisons. This\nhighlights the need for a comprehensive IR toolkit that enables standardized\nevaluation of fairness- and diversity-aware algorithms across different IR\ntasks. To address this challenge, we present FairDiverse, an open-source and\nstandardized toolkit. FairDiverse offers a framework for integrating fair and\ndiverse methods, including pre-processing, in-processing, and post-processing\ntechniques, at different stages of the IR pipeline. The toolkit supports the\nevaluation of 28 fairness and diversity algorithms across 16 base models,\ncovering two core IR tasks (search and recommendation) thereby establishing a\ncomprehensive benchmark. Moreover, FairDiverse is highly extensible, providing\nmultiple APIs that empower IR researchers to swiftly develop and evaluate their\nown fairness and diversity aware models, while ensuring fair comparisons with\nexisting baselines. The project is open-sourced and available on\nhttps://github.com/XuChen0427/FairDiverse.",
    "pdf_url": "http://arxiv.org/pdf/2502.11883v1",
    "published": "2025-02-17T15:11:09+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11882v5",
    "title": "Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration",
    "authors": [
      "Shao Zhang",
      "Xihuai Wang",
      "Wenhao Zhang",
      "Chaoran Li",
      "Junru Song",
      "Tingyu Li",
      "Lin Qiu",
      "Xuezhi Cao",
      "Xunliang Cai",
      "Wen Yao",
      "Weinan Zhang",
      "Xinbing Wang",
      "Ying Wen"
    ],
    "abstract": "Agents built on large language models (LLMs) have excelled in turn-by-turn\nhuman-AI collaboration but struggle with simultaneous tasks requiring real-time\ninteraction. Latency issues and the challenge of inferring variable human\nstrategies hinder their ability to make autonomous decisions without explicit\ninstructions. Through experiments with current independent System 1 and System\n2 methods, we validate the necessity of using Dual Process Theory (DPT) in\nreal-time tasks. We propose DPT-Agent, a novel language agent framework that\nintegrates System 1 and System 2 for efficient real-time simultaneous human-AI\ncollaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and\ncode-as-policy for fast, intuitive, and controllable decision-making.\nDPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous\nreflection to infer human intentions and perform reasoning-based autonomous\ndecisions. We demonstrate the effectiveness of DPT-Agent through further\nexperiments with rule-based agents and human collaborators, showing significant\nimprovements over mainstream LLM-based frameworks. DPT-Agent can effectively\nhelp LLMs convert correct slow thinking and reasoning into executable actions,\nthereby improving performance. To the best of our knowledge, DPT-Agent is the\nfirst language agent framework that achieves successful real-time simultaneous\nhuman-AI collaboration autonomously. Code of DPT-Agent can be found in\nhttps://github.com/sjtu-marl/DPT-Agent.",
    "pdf_url": "http://arxiv.org/pdf/2502.11882v5",
    "published": "2025-02-17T15:09:45+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11881v2",
    "title": "Hypothesis-Driven Theory-of-Mind Reasoning for Large Language Models",
    "authors": [
      "Hyunwoo Kim",
      "Melanie Sclar",
      "Tan Zhi-Xuan",
      "Lance Ying",
      "Sydney Levine",
      "Yang Liu",
      "Joshua B. Tenenbaum",
      "Yejin Choi"
    ],
    "abstract": "Existing LLM reasoning methods have shown impressive capabilities across\nvarious tasks, such as solving math and coding problems. However, applying\nthese methods to scenarios without ground-truth answers or rule-based\nverification methods - such as tracking the mental states of an agent - remains\nchallenging. Inspired by the sequential Monte Carlo algorithm, we introduce\nthought-tracing, an inference-time reasoning algorithm designed to trace the\nmental states of specific agents by generating hypotheses and weighting them\nbased on observations without relying on ground-truth solutions to questions in\ndatasets. Our algorithm is modeled after the Bayesian theory-of-mind framework,\nusing LLMs to approximate probabilistic inference over agents' evolving mental\nstates based on their perceptions and actions. We evaluate thought-tracing on\ndiverse theory-of-mind benchmarks, demonstrating significant performance\nimprovements compared to baseline LLMs. Our experiments also reveal interesting\nbehaviors of the recent reasoning models - e.g., o3 and R1 - on theory-of-mind,\nhighlighting the difference of social reasoning compared to other domains.",
    "pdf_url": "http://arxiv.org/pdf/2502.11881v2",
    "published": "2025-02-17T15:08:50+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.13171v1",
    "title": "Web Phishing Net (WPN): A scalable machine learning approach for real-time phishing campaign detection",
    "authors": [
      "Muhammad Fahad Zia",
      "Sri Harish Kalidass"
    ],
    "abstract": "Phishing is the most prevalent type of cyber-attack today and is recognized\nas the leading source of data breaches with significant consequences for both\nindividuals and corporations. Web-based phishing attacks are the most frequent\nwith vectors such as social media posts and emails containing links to phishing\nURLs that once clicked on render host systems vulnerable to more sinister\nattacks. Research efforts to detect phishing URLs have involved the use of\nsupervised learning techniques that use large amounts of data to train models\nand have high computational requirements. They also involve analysis of\nfeatures derived from vectors including email contents thus affecting user\nprivacy. Additionally, they suffer from a lack of resilience against evolution\nof threats especially with the advent of generative AI techniques to bypass\nthese systems as with AI-generated phishing URLs. Unsupervised methods such as\nclustering techniques have also been used in phishing detection in the past,\nhowever, they are at times unscalable due to the use of pair-wise comparisons.\nThey also lack high detection rates while detecting phishing campaigns. In this\npaper, we propose an unsupervised learning approach that is not only fast but\nscalable, as it does not involve pair-wise comparisons. It is able to detect\nentire campaigns at a time with a high detection rate while preserving user\nprivacy; this includes the recent surge of campaigns with targeted phishing\nURLs generated by malicious entities using generative AI techniques.",
    "pdf_url": "http://arxiv.org/pdf/2502.13171v1",
    "published": "2025-02-17T15:06:56+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11880v1",
    "title": "Bitnet.cpp: Efficient Edge Inference for Ternary LLMs",
    "authors": [
      "Jinheng Wang",
      "Hansong Zhou",
      "Ting Song",
      "Shijie Cao",
      "Yan Xia",
      "Ting Cao",
      "Jianyu Wei",
      "Shuming Ma",
      "Hongyu Wang",
      "Furu Wei"
    ],
    "abstract": "The advent of 1-bit large language models (LLMs), led by BitNet b1.58, has\nspurred interest in ternary LLMs. Despite this, research and practical\napplications focusing on efficient edge inference for ternary LLMs remain\nscarce. To bridge this gap, we introduce Bitnet.cpp, an inference system\noptimized for BitNet b1.58 and ternary LLMs. Given that mixed-precision matrix\nmultiplication (mpGEMM) constitutes the bulk of inference time in ternary LLMs,\nBitnet.cpp incorporates a novel mpGEMM library to facilitate\nsub-2-bits-per-weight, efficient and lossless inference. The library features\ntwo core solutions: Ternary Lookup Table (TL), which addresses spatial\ninefficiencies of previous bit-wise methods, and Int2 with a Scale (I2_S),\nwhich ensures lossless edge inference, both enabling high-speed inference. Our\nexperiments show that Bitnet.cpp achieves up to a 6.25x increase in speed over\nfull-precision baselines and up to 2.32x over low-bit baselines, setting new\nbenchmarks in the field. Additionally, we expand TL to element-wise lookup\ntable (ELUT) for low-bit LLMs in the appendix, presenting both theoretical and\nempirical evidence of its considerable potential. Bitnet.cpp is publicly\navailable at https://github.com/microsoft/BitNet/tree/paper , offering a\nsophisticated solution for the efficient and practical deployment of edge LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11880v1",
    "published": "2025-02-17T15:06:28+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11879v1",
    "title": "Magnetic Fields or Overstable Convective Modes in HR 7495: Exploring the Underlying Causes of the Spike in the 'Hump & Spike' Features",
    "authors": [
      "V. Antoci",
      "M. Cantiello",
      "V. Khalack",
      "A. Henriksen",
      "H. Saio",
      "T. R. White",
      "L. Buchhave"
    ],
    "abstract": "More than 200 A- and F-type stars observed with Kepler exhibit a distinctive\n'hump & spike' feature in their Fourier spectra. The hump is commonly\ninterpreted as unresolved Rossby modes, while the spike has been linked to\nrotational modulation. Two competing interpretations exist for the spike:\nmagnetic phenomena, such as stellar spots, or Overstable Convective (OsC) modes\nresonantly exciting low-frequency g modes within the stellar envelope.\n  We analysed photometric data from Kepler and TESS for HR 7495, the brightest\n'hump & spike' star (V=5.06), covering 4.5 years and four seasons,\nrespectively. Additionally, radial velocity measurements and\nspectropolarimetric data were used to investigate magnetic fields and surface\nfeatures. Furthermore, we analysed model-based artificial light and radial\nvelocity curves to examine the influence of OsC modes on the phase-folded light\ncurves.\n  The phase-folded light curves show that the spike characteristics of HR 7495\nalign more closely with rotational modulation by stellar spots than with OsC\nmodes. No significant magnetic fields were detected, limiting the field's\npossible amplitude and geometry. This supports the hypothesis of a subsurface\nconvective layer operating a dynamo, producing low-amplitude, complex magnetic\nfields. The variability patterns suggest multiple evolving spots. A comparison\nof contemporaneously observed light and RV data with modelled OsC modes reveals\na 0.5 phase offset, strongly disfavouring pulsations as the cause of the spike.\n  While the evolutionary stage of HR 7495 does not entirely preclude the\npossibility of OsC modes, the observational data overwhelmingly support the\nstellar spots hypothesis. Our analysis, combined with previous literature,\nsuggests that if not all A- and F-type, at least the 'hump & spike' stars,\nharbour an undetected weak magnetic field, likely driven by a dynamo mechanism.",
    "pdf_url": "http://arxiv.org/pdf/2502.11879v1",
    "published": "2025-02-17T15:04:48+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11878v1",
    "title": "Forecasting Italian daily electricity generation disaggregated by geographical zones and energy sources using coherent forecast combination",
    "authors": [
      "Daniele Girolimetto",
      "Tommaso Di Fonzo"
    ],
    "abstract": "A novel approach is applied for improving forecast accuracy and achieving\ncoherence in forecasting the Italian daily energy generation time series. In\nhierarchical frameworks such as national energy generation disaggregated by\ngeographical zones and energy sources, independently generated base forecasts\noften result in inconsistencies across the constraints. We deal with this issue\nthrough a coherent balanced multi-task forecast combination approach, which\ncombines unbiased forecasts from multiple experts while ensuring coherence.\nApplied to the daily Italian electricity generation data, our method shows\nsuperior accuracy compared to single-task base and combined forecasts, and a\nstate-of-the-art single-expert reconciliation technique, demonstrating to be an\neffective approach to forecasting linearly constrained multiple time series.",
    "pdf_url": "http://arxiv.org/pdf/2502.11878v1",
    "published": "2025-02-17T15:04:24+00:00",
    "categories": [
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11877v1",
    "title": "JoLT: Joint Probabilistic Predictions on Tabular Data Using LLMs",
    "authors": [
      "Aliaksandra Shysheya",
      "John Bronskill",
      "James Requeima",
      "Shoaib Ahmed Siddiqui",
      "Javier Gonzalez",
      "David Duvenaud",
      "Richard E. Turner"
    ],
    "abstract": "We introduce a simple method for probabilistic predictions on tabular data\nbased on Large Language Models (LLMs) called JoLT (Joint LLM Process for\nTabular data). JoLT uses the in-context learning capabilities of LLMs to define\njoint distributions over tabular data conditioned on user-specified side\ninformation about the problem, exploiting the vast repository of latent\nproblem-relevant knowledge encoded in LLMs. JoLT defines joint distributions\nfor multiple target variables with potentially heterogeneous data types without\nany data conversion, data preprocessing, special handling of missing data, or\nmodel training, making it accessible and efficient for practitioners. Our\nexperiments show that JoLT outperforms competitive methods on low-shot\nsingle-target and multi-target tabular classification and regression tasks.\nFurthermore, we show that JoLT can automatically handle missing data and\nperform data imputation by leveraging textual side information. We argue that\ndue to its simplicity and generality, JoLT is an effective approach for a wide\nvariety of real prediction problems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11877v1",
    "published": "2025-02-17T15:03:54+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.11876v2",
    "title": "Magnetization symmetry for the MnTe altermagnetic candidate",
    "authors": [
      "N. N. Orlova",
      "V. D. Esin",
      "A. V. Timonina",
      "N. N. Kolesnikov",
      "E. V. Deviatov"
    ],
    "abstract": "We experimentally investigate the magnetization angle dependence $M(\\alpha)$\nfor single crystals of MnTe altermagnetic candidate. In high magnetic fields,\nexperimental $M(\\alpha)$ curves mostly reflect standard antiferromagnetic\nspin-flop processes, which are allowed below the N\\'eel vector reorientation\nfield. In low magnetic fields and at low temperatures, spontaneous\nmagnetization appears as a sharp $M(T)$ magnetization jump around 81~K. In this\nregime, $M(\\alpha)$ dependence is quite unusual: the easy magnetization axis is\n$\\pi/2$ rotated either by increasing the field above 1~kOe or the temperature\nabove 81~K. The observed behavior cannot be expected for antiferromagnetics,\ne.g. it differs strongly from the well known weak ferromagnetism. Thus, it\nrequires to take into account the formation of the altermagnetic ground state\nfor MnTe altermagnetic candidate. Despite MnTe is expected to have g-wave order\nparameter, $M(\\alpha)$ magnetization symmetry confirms the prevailing\npopulation of one from three easy axes, as it has been shown previously by\ntemperature-dependent angle-resolved photo-emission spectroscopy.",
    "pdf_url": "http://arxiv.org/pdf/2502.11876v2",
    "published": "2025-02-17T15:03:33+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11875v2",
    "title": "When Adiabaticity Is Not Enough to Study Topological Phases in Solid-State Physics: Comparing the Berry and Aharonov-Anandan Phases in 2D Materials",
    "authors": [
      "Abdiel de JesÃºs Espinosa-Champo",
      "Alejandro Kunold",
      "Gerardo G. Naumis"
    ],
    "abstract": "Topological phases emerge as the parameters of a quantum system vary with\ntime. Under the adiabatic approximation, the time dependence can be eliminated,\nallowing the Berry topological phase to be obtained from a closed trajectory in\nparameter space. In solid-state physics, this approach is commonly applied by\ntaking a reciprocal space wavevector as the parameter, which is assumed to be\nvaried by electromagnetic fields.The Berry curvature is then obtained by\ncomputing the derivatives of Bloch wavefunctions in reciprocal space. However,\nin many systems-especially gapless ones-the adiabatic approximation is never\nsatisfied. This is particularly true in Dirac and Weyl materials, where the\nBerry curvature is often calculated without considering the breakdown of the\nadiabatic condition. In this work, we demonstrate how other time-dependent\ntopological quantities, specifically the Aharonov-Anandan phase, can be used to\nextract information not only about topology but also about band transitions in\n2D materials. In particular, a relationship between the current and the\nAharonov-Anandan phase is proved, showing that photon-induced transitions\nproduce current vortices. To illustrate this, we analyze graphene under\nelectromagnetic radiation from a time-driven perspective, showing how the\nAharonov-Anandan and Berry phases provide complementary insights into topology,\ninterband transitions, and currents. This is achieved by using the Dirac-Bloch\nformalism and by solving the time-dependent equations within Floquet theory.",
    "pdf_url": "http://arxiv.org/pdf/2502.11875v2",
    "published": "2025-02-17T15:02:15+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11874v3",
    "title": "VAQUUM: Are Vague Quantifiers Grounded in Visual Data?",
    "authors": [
      "Hugh Mee Wong",
      "Rick Nouwen",
      "Albert Gatt"
    ],
    "abstract": "Vague quantifiers such as \"a few\" and \"many\" are influenced by various\ncontextual factors, including the number of objects present in a given context.\nIn this work, we evaluate the extent to which vision-and-language models (VLMs)\nare compatible with humans when producing or judging the appropriateness of\nvague quantifiers in visual contexts. We release a novel dataset, VAQUUM,\ncontaining 20,300 human ratings on quantified statements across a total of 1089\nimages. Using this dataset, we compare human judgments and VLM predictions\nusing three different evaluation methods. Our findings show that VLMs, like\nhumans, are influenced by object counts in vague quantifier use. However, we\nfind significant inconsistencies across models in different evaluation\nsettings, suggesting that judging and producing vague quantifiers rely on two\ndifferent processes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11874v3",
    "published": "2025-02-17T15:02:09+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11873v1",
    "title": "Energy load forecasting using Terna public data: a free lunch multi-task combination approach",
    "authors": [
      "Daniele Girolimetto",
      "Tommaso Di Fonzo"
    ],
    "abstract": "We propose a quick-and-simple procedure to augment the accuracy of 15-minutes\nItalian load forecasts disaggregated by bidding zones published by Terna, the\noperator of the Italian electricity system. We show that a stacked-regression\nmulti-task combination approach using Terna and daily random walk naive\nforecasts, is able to produce significantly more accurate forecasts immediately\nafter Terna publishes on its data portal the energy load measurements for the\nprevious day, and the forecasts for the current day.",
    "pdf_url": "http://arxiv.org/pdf/2502.11873v1",
    "published": "2025-02-17T15:01:26+00:00",
    "categories": [
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11872v1",
    "title": "Issues in the Investigations of the Dark Matter Phenomenon in Galaxies: Parcere Personis, Dicere de Vitiis",
    "authors": [
      "Paolo Salucci"
    ],
    "abstract": "It is always more evident that the kinematics of galaxies provide us with\nunique information on the Nature of the dark particles and on the properties of\nthe galaxy Dark Matter (DM) halos. However, in investigating this topic, we\nhave to be very careful about certain issues related to the assumptions that we\ntake or to the practices that we follow. Here, we critically discuss such\nissues, that, today, result of fundamental importance, in that we have realized\nthat the Nature of the DM will be not provided by The Theory but, has to be\ninferred by reverse engineering the observational scenario.",
    "pdf_url": "http://arxiv.org/pdf/2502.11872v1",
    "published": "2025-02-17T15:00:45+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11871v2",
    "title": "An initial-boundary problem for a mixed fractional wave equation",
    "authors": [
      "Erkinjon Karimov",
      "Nasser Al-Salti",
      "Muna Al-Ghabsi"
    ],
    "abstract": "We aim to prove a unique solvability of an initial-boundary value problem\n(IBVP) for a time-fractional wave equation in a rectangular domain. We exploit\nthe spectral expansion method as the main tool and used the solution to Cauchy\nproblems for fractional-order differential equations. Moreover, we apply\ncertain properties of the Mittag-Leffler-type functions of single and two\nvariables to prove the uniform convergence of the solution to the considered\nproblem, represented in the form of infinite series.",
    "pdf_url": "http://arxiv.org/pdf/2502.11871v2",
    "published": "2025-02-17T15:00:36+00:00",
    "categories": [
      "math.AP",
      "35M10, 35R11"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11870v1",
    "title": "Searches for light Dark Matter with Spherical Proportional Counters",
    "authors": [
      "Patrick Knights",
      "Konstantinos Nikolopoulos"
    ],
    "abstract": "Elucidating the nature of dark matter is a key priority that would involve\ndiscovering new fundamental physics and is essential for understanding the\nstructure and evolution of the universe. Despite the decades-long\never-more-sensitive searches, the particle content of dark matter remains\nelusive. Direct searches for dark matter candidates, to-date, focused mainly on\ncandidates in the 10 GeV to 1 TeV, however, more recently lighter candidates\nwith sub-GeV mass have been brought to the spotlight. This is an experimentally\nchallenging mass region, which remains largely uncharted. The spherical\nproportional counter is a new type of gaseous detector which exhibits several\nfeatures that make it ideally suited for the exploration of this mass range. In\nthis article the invention and development of the spherical proportional\ncounter are presented, its applications in the search for particle dark matter\nand beyond are reviewed, and possible future directions are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2502.11870v1",
    "published": "2025-02-17T15:00:17+00:00",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2502.11869v2",
    "title": "On $\\mathcal{F}$-multicolor TurÃ¡n number of hypergraph graphs",
    "authors": [
      "Ping Li"
    ],
    "abstract": "Recently, Imolay, Karl, Nazy and V\\'{a}li explored a generalization of\nTur\\'{a}n's forbidden subgraph problem and Ruzsa-Szrmer\\'{e}di $(6,3)$-problem.\nThey specifically studied the following question: for two graphs $F$ and $G$,\ndetermine the maximum number of edge-disjoint copies of $F$ in a set of $n$\nvertices such that there is no copy of $G$ whose edges come from different\n$F$-copies. The maximum number is denoted by $ex_F(n,G)$ and is called the {\\em\n$F$-multicolor Tur\\'{a}n number} of $G$. One of their main results is that\n$ex_F(n,G)=o(n^2)$ if and only if there exists a homomorphism from $G$ to $F$.\nWe generalize the result to uniformly hypergraph using main tools of Hypergraph\nRegularity Lemma and Counting Lemma.",
    "pdf_url": "http://arxiv.org/pdf/2502.11869v2",
    "published": "2025-02-17T14:59:25+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11868v1",
    "title": "Phylogenetic latent space models for network data",
    "authors": [
      "Federico Pavone",
      "Daniele Durante",
      "Robin J. Ryder"
    ],
    "abstract": "Latent space models for network data characterize each node through a vector\nof latent features whose pairwise similarities define the edge probabilities\namong pairs of nodes. Although this formulation has led to successful\nimplementations and impactful extensions, the overarching focus has been on\ndirectly inferring node embeddings through the latent features rather than\nlearning the generative process underlying the embedding. This focus prevents\nfrom borrowing information among the features of different nodes and fails to\ninfer complex higher-level architectures regulating the formation of the\nnetwork itself. For example, routinely-studied networks often exhibit\nmultiscale structures informing on nested modular hierarchies among nodes that\ncould be learned via tree-based representations of dependencies among latent\nfeatures. We pursue this direction by developing an innovative phylogenetic\nlatent space model that explicitly characterizes the generative process of the\nnodes' feature vectors via a branching Brownian motion, with branching\nstructure parametrized by a phylogenetic tree. This tree constitutes the main\nobject of interest and is learned under a Bayesian perspective to infer\ntree-based modular hierarchies among nodes that explain heterogenous multiscale\npatterns in the network. Identifiability results are derived along with\nposterior consistency theory, and the inference potentials of the\nnewly-proposed model are illustrated in simulations and two real-data\napplications from criminology and neuroscience, where our formulation learns\ncore structures hidden to state-of-the-art alternatives.",
    "pdf_url": "http://arxiv.org/pdf/2502.11868v1",
    "published": "2025-02-17T14:59:18+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.11867v1",
    "title": "On Data-Driven Robust Optimization With Multiple Uncertainty Subsets: Unified Uncertainty Set Representation and Mitigating Conservatism",
    "authors": [
      "Yun Li",
      "Neil Yorke-Smith",
      "Tamas Keviczky"
    ],
    "abstract": "Constructing uncertainty sets as unions of multiple subsets has emerged as an\neffective approach for creating compact and flexible uncertainty\nrepresentations in data-driven robust optimization (RO). This paper focuses on\ntwo separate research questions. The first concerns the computational challenge\nin applying these uncertainty sets in RO-based predictive control. To address\nthis, a monolithic mixed-integer representation of the uncertainty set is\nproposed to uniformly describe the union of multiple subsets, enabling the\ncomputation of the worst-case uncertainty scenario across all subsets within a\nsingle mixed-integer linear programming (MILP) problem. The second research\nquestion focuses on mitigating the conservatism of conventional RO formulations\nby leveraging the structure of the uncertainty set. To achieve this, a novel\nobjective function is proposed to exploit the uncertainty set structure and\nintegrate the existing RO and distributionally robust optimization (DRO)\nformulations, yielding less conservative solutions than conventional RO\nformulations while avoiding the high-dimensional continuous uncertainty\ndistributions and incurring high computational burden typically associated with\nexisting DRO formulations. Given the proposed formulations, numerically\nefficient computation methods based on column-and-constraint generation (CCG)\nare also developed. Extensive simulations across three case studies are\nperformed to demonstrate the effectiveness of the proposed schemes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11867v1",
    "published": "2025-02-17T14:58:33+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.17477v2",
    "title": "Frequency-Aware Masked Autoencoders for Human Activity Recognition using Accelerometers",
    "authors": [
      "Niels R. Lorenzen",
      "Poul J. Jennum",
      "Emmanuel Mignot",
      "Andreas Brink-Kjaer"
    ],
    "abstract": "Wearable accelerometers are widely used for continuous monitoring of physical\nactivity. Supervised machine learning and deep learning algorithms have long\nbeen used to extract meaningful activity information from raw accelerometry\ndata, but progress has been hampered by the limited amount of labeled data that\nis publicly available. Exploiting large unlabeled datasets using\nself-supervised pretraining is a relatively new and underexplored approach in\nthe field of human activity recognition (HAR). We used a time-series\ntransformer masked autoencoder (MAE) approach to self-supervised pretraining\nand propose two novel spectrogram-based loss functions: the log-scale\nmeanmagnitude (LMM) and log-scale magnitude variance (LMV) losses. We compared\nthese losses with the mean squared error (MSE) loss for MAE training. We\nleveraged the large unlabeled UK Biobank accelerometry dataset (n = 109k) for\npretraining and evaluated downstream HAR performance using a linear classifier\nin a smaller labelled dataset. We found that pretraining with the LMM loss\nimproved performance compared to an MAE pretrained with the MSE loss, with\n12.7% increase in subject-wise F1 score when using linear probing. Compared\nwith a state-of-the-art ResNet-based HAR model, our LMM-pretrained transformer\nmodels performed better (+9.8% F1) with linear probing and comparably when\nfine-tuned using an LSTM classifier. The addition of the LMV to the LMM loss\ndecreased performance compared to the LMM loss alone. These findings establish\nthe LMM loss as a robust and effective method for pretraining MAE models on\naccelerometer data for HAR and show the potential of pretraining sequence-based\nmodels for free-living HAR.",
    "pdf_url": "http://arxiv.org/pdf/2502.17477v2",
    "published": "2025-02-17T14:57:51+00:00",
    "categories": [
      "eess.SP",
      "cs.LG",
      "J.3; I.2.6"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11866v1",
    "title": "Southern Newswire Corpus: A Large-Scale Dataset of Mid-Century Wire Articles Beyond the Front Page",
    "authors": [
      "Michael McRae"
    ],
    "abstract": "I introduce a new large-scale dataset of historical wire articles from U.S.\nSouthern newspapers, spanning 1960-1975 and covering multiple wire services:\nThe Associated Press, United Press International, Newspaper Enterprise\nAssociation. Unlike prior work focusing on front-page content, this dataset\ncaptures articles across the entire newspaper, offering broader insight into\nmid-century Southern coverage. The dataset includes a version that has\nundergone an LLM-based text cleanup pipeline to reduce OCR noise, enhancing its\nsuitability for quantitative text analysis. Additionally, duplicate versions of\narticles are retained to enable analysis of editorial differences in language\nand framing across newspapers. Each article is tagged by wire service,\nfacilitating comparative studies of editorial patterns across agencies. This\nresource opens new avenues for research in computational social science,\ndigital humanities, and historical linguistics, providing a detailed\nperspective on how Southern newspapers relayed national and international news\nduring a transformative period in American history. The dataset will be made\navailable upon publication or request for research purposes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11866v1",
    "published": "2025-02-17T14:57:47+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11865v2",
    "title": "The Brillouin flow in a smooth-bore magnetron fed by split cathode",
    "authors": [
      "Y. Bliokh",
      "J. G. Leopold",
      "Ya. E. Krasik"
    ],
    "abstract": "Explosive emission from an axial cathode of a relativistic magnetron produces\nplasma, the radial expansion of which can cause pulse shortening. In a split\ncathode fed magnetron, the electron source and its explosive plasma are outside\nthe space where the high power microwave producing interaction occurs. This\nelectron source is a longitudinal annular electron column expanding radially.\nThis expansion simulates the radial emission from an axial cathode. A\nmathematical model and numerical simulations are presented which enable to\ncalculate the parameters of this electron column, its density, angular\nvelocity, and potential distributions. The Hull Cutoff and Buneman-Hartree\nmodified conditions applicable to the split cathode magnetron are formulated.",
    "pdf_url": "http://arxiv.org/pdf/2502.11865v2",
    "published": "2025-02-17T14:57:40+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11864v1",
    "title": "Does Knowledge About Perceptual Uncertainty Help an Agent in Automated Driving?",
    "authors": [
      "Natalie Grabowsky",
      "Annika MÃ¼tze",
      "Joshua Wendland",
      "Nils Jansen",
      "Matthias Rottmann"
    ],
    "abstract": "Agents in real-world scenarios like automated driving deal with uncertainty\nin their environment, in particular due to perceptual uncertainty. Although,\nreinforcement learning is dedicated to autonomous decision-making under\nuncertainty these algorithms are typically not informed about the uncertainty\ncurrently contained in their environment. On the other hand, uncertainty\nestimation for perception itself is typically directly evaluated in the\nperception domain, e.g., in terms of false positive detection rates or\ncalibration errors based on camera images. Its use for deciding on\ngoal-oriented actions remains largely unstudied. In this paper, we investigate\nhow an agent's behavior is influenced by an uncertain perception and how this\nbehavior changes if information about this uncertainty is available. Therefore,\nwe consider a proxy task, where the agent is rewarded for driving a route as\nfast as possible without colliding with other road users. For controlled\nexperiments, we introduce uncertainty in the observation space by perturbing\nthe perception of the given agent while informing the latter. Our experiments\nshow that an unreliable observation space modeled by a perturbed perception\nleads to a defensive driving behavior of the agent. Furthermore, when adding\nthe information about the current uncertainty directly to the observation\nspace, the agent adapts to the specific situation and in general accomplishes\nits task faster while, at the same time, accounting for risks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11864v1",
    "published": "2025-02-17T14:56:25+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11863v1",
    "title": "FedEAT: A Robustness Optimization Framework for Federated LLMs",
    "authors": [
      "Yahao Pang",
      "Xingyuan Wu",
      "Xiaojin Zhang",
      "Wei Chen",
      "Hai Jin"
    ],
    "abstract": "Significant advancements have been made by Large Language Models (LLMs) in\nthe domains of natural language understanding and automated content creation.\nHowever, they still face persistent problems, including substantial\ncomputational costs and inadequate availability of training data. The\ncombination of Federated Learning (FL) and LLMs (federated LLMs) offers a\nsolution by leveraging distributed data while protecting privacy, which\npositions it as an ideal choice for sensitive domains. However, Federated LLMs\nstill suffer from robustness challenges, including data heterogeneity,\nmalicious clients, and adversarial attacks, which greatly hinder their\napplications. We first introduce the robustness problems in federated LLMs, to\naddress these challenges, we propose FedEAT (Federated Embedding space\nAdversarial Training), a novel framework that applies adversarial training in\nthe embedding space of client LLM and employs a robust aggregation approach,\nspecifically geometric median aggregation, to enhance the robustness of\nFederated LLMs. Our experiments demonstrate that FedEAT effectively improves\nthe robustness of Federated LLMs with minimal performance loss.",
    "pdf_url": "http://arxiv.org/pdf/2502.11863v1",
    "published": "2025-02-17T14:55:46+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12224v2",
    "title": "Fate: Fast Edge Inference of Mixture-of-Experts Models via Cross-Layer Gate",
    "authors": [
      "Zhiyuan Fang",
      "Zicong Hong",
      "Yuegui Huang",
      "Yufeng Lyu",
      "Wuhui Chen",
      "Yue Yu",
      "Fan Yu",
      "Zibin Zheng"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive performance across\nvarious tasks, and their application in edge scenarios has attracted\nsignificant attention. However, sparse-activated Mixture-of-Experts (MoE)\nmodels, which are well suited for edge scenarios, have received relatively\nlittle attention due to their high memory demands. Offload-based methods have\nbeen proposed to address this challenge, but they face difficulties with expert\nprediction. Inaccurate expert predictions can result in prolonged inference\ndelays. To promote the application of MoE models in edge scenarios, we propose\nFate, an offloading system designed for MoE models to enable efficient\ninference in resource-constrained environments. The key insight behind Fate is\nthat gate inputs from adjacent layers can be effectively used for expert\nprefetching, achieving high prediction accuracy without additional GPU\noverhead. Furthermore, Fate employs a shallow-favoring expert caching strategy\nthat increases the expert hit rate to 99\\%. Additionally, Fate integrates\ntailored quantization strategies for cache optimization and IO efficiency.\nExperimental results show that, compared to Load on Demand and Expert\nActivation Path-based method, Fate achieves up to 4.5x and 1.9x speedups in\nprefill speed and up to 4.1x and 2.2x speedups in decoding speed, respectively,\nwhile maintaining inference quality. Moreover, Fate's performance improvements\nare scalable across different memory budgets.",
    "pdf_url": "http://arxiv.org/pdf/2502.12224v2",
    "published": "2025-02-17T14:54:14+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11862v2",
    "title": "Understanding In-Context Machine Translation for Low-Resource Languages: A Case Study on Manchu",
    "authors": [
      "Renhao Pei",
      "Yihong Liu",
      "Peiqin Lin",
      "FranÃ§ois Yvon",
      "Hinrich SchÃ¼tze"
    ],
    "abstract": "In-context machine translation (MT) with large language models (LLMs) is a\npromising approach for low-resource MT, as it can readily take advantage of\nlinguistic resources such as grammar books and dictionaries. Such resources are\nusually selectively integrated into the prompt so that LLMs can directly\nperform translation without any specific training, via their in-context\nlearning capability (ICL). However, the relative importance of each type of\nresource, e.g., dictionary, grammar book, and retrieved parallel examples, is\nnot entirely clear. To address this gap, this study systematically investigates\nhow each resource and its quality affect the translation performance, with the\nManchu language as our case study. To remove any prior knowledge of Manchu\nencoded in the LLM parameters and single out the effect of ICL, we also\nexperiment with an enciphered version of Manchu texts. Our results indicate\nthat high-quality dictionaries and good parallel examples are very helpful,\nwhile grammars hardly help. In a follow-up study, we showcase a promising\napplication of in-context MT: parallel data augmentation as a way to bootstrap\na conventional MT model. When monolingual data abound, generating synthetic\nparallel data through in-context MT offers a pathway to mitigate data scarcity\nand build effective and efficient low-resource neural MT systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11862v2",
    "published": "2025-02-17T14:53:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11861v1",
    "title": "Exploring Large Language Models in Healthcare: Insights into Corpora Sources, Customization Strategies, and Evaluation Metrics",
    "authors": [
      "Shuqi Yang",
      "Mingrui Jing",
      "Shuai Wang",
      "Jiaxin Kou",
      "Manfei Shi",
      "Weijie Xing",
      "Yan Hu",
      "Zheng Zhu"
    ],
    "abstract": "This study reviewed the use of Large Language Models (LLMs) in healthcare,\nfocusing on their training corpora, customization techniques, and evaluation\nmetrics. A systematic search of studies from 2021 to 2024 identified 61\narticles. Four types of corpora were used: clinical resources, literature,\nopen-source datasets, and web-crawled data. Common construction techniques\nincluded pre-training, prompt engineering, and retrieval-augmented generation,\nwith 44 studies combining multiple methods. Evaluation metrics were categorized\ninto process, usability, and outcome metrics, with outcome metrics divided into\nmodel-based and expert-assessed outcomes. The study identified critical gaps in\ncorpus fairness, which contributed to biases from geographic, cultural, and\nsocio-economic factors. The reliance on unverified or unstructured data\nhighlighted the need for better integration of evidence-based clinical\nguidelines. Future research should focus on developing a tiered corpus\narchitecture with vetted sources and dynamic weighting, while ensuring model\ntransparency. Additionally, the lack of standardized evaluation frameworks for\ndomain-specific models called for comprehensive validation of LLMs in\nreal-world healthcare settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.11861v1",
    "published": "2025-02-17T14:53:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11860v1",
    "title": "A measurement-device-independent quantum key distribution network using optical frequency comb",
    "authors": [
      "Wenhan Yan",
      "Xiaodong Zheng",
      "Wenjun Wen",
      "Liangliang Lu",
      "Yifeng Du",
      "Yanqing Lu",
      "Shining Zhu",
      "Xiao-Song Ma"
    ],
    "abstract": "Quantum key distribution (QKD), which promises secure key exchange between\ntwo remote parties, is now moving toward the realization of scalable and secure\nQKD networks (QNs). Fully connected, trusted node-free QNs have been realized\nbased on entanglement distribution, in which the low key rate as well as the\nlarge overhead makes their practical deployment and application challenging.\nHere, we propose and experimentally demonstrate a fully connected multi-user\nQKD network based on a wavelength-multiplexed measurement-device-independent\n(MDI) QKD protocol. By combining this novel protocol with integrated optical\nfrequency combs, we achieve an average secure key rate of 267 bits per second\nfor about 30 dB of link attenuation per user pair -- more than three orders of\nmagnitude higher than previous entanglement-based works. More importantly, we\nrealize secure key sharing between two different pairs of users simultaneously,\nwhich requires four-photon detection and is not possible with the previous\ntwo-photon entanglement distribution. Our work paves the way for the\nrealization of large-scale QKD networks with full connectivity and simultaneous\ncommunication capability among multiple users.",
    "pdf_url": "http://arxiv.org/pdf/2502.11860v1",
    "published": "2025-02-17T14:52:22+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11859v2",
    "title": "Defining and Evaluating Visual Language Models' Basic Spatial Abilities: A Perspective from Psychometrics",
    "authors": [
      "Wenrui Xu",
      "Dalin Lyu",
      "Weihang Wang",
      "Jie Feng",
      "Chen Gao",
      "Yong Li"
    ],
    "abstract": "The Theory of Multiple Intelligences underscores the hierarchical nature of\ncognitive capabilities. To advance Spatial Artificial Intelligence, we pioneer\na psychometric framework defining five Basic Spatial Abilities (BSAs) in Visual\nLanguage Models (VLMs): Spatial Perception, Spatial Relation, Spatial\nOrientation, Mental Rotation, and Spatial Visualization. Benchmarking 13\nmainstream VLMs through nine validated psychometric experiments reveals\nsignificant gaps versus humans (average score 24.95 vs. 68.38), with three key\nfindings: 1) VLMs mirror human hierarchies (strongest in 2D orientation,\nweakest in 3D rotation) with independent BSAs (Pearson's r<0.4); 2) Smaller\nmodels such as Qwen2-VL-7B surpass larger counterparts, with Qwen leading\n(30.82) and InternVL2 lagging (19.6); 3) Interventions like chain-of-thought\n(0.100 accuracy gain) and 5-shot training (0.259 improvement) show limits from\narchitectural constraints. Identified barriers include weak geometry encoding\nand missing dynamic simulation. By linking psychometric BSAs to VLM\ncapabilities, we provide a diagnostic toolkit for spatial intelligence\nevaluation, methodological foundations for embodied AI development, and a\ncognitive science-informed roadmap for achieving human-like spatial\nintelligence.",
    "pdf_url": "http://arxiv.org/pdf/2502.11859v2",
    "published": "2025-02-17T14:50:53+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11858v3",
    "title": "Rethinking Audio-Visual Adversarial Vulnerability from Temporal and Modality Perspectives",
    "authors": [
      "Zeliang Zhang",
      "Susan Liang",
      "Daiki Shimada",
      "Chenliang Xu"
    ],
    "abstract": "While audio-visual learning equips models with a richer understanding of the\nreal world by leveraging multiple sensory modalities, this integration also\nintroduces new vulnerabilities to adversarial attacks.\n  In this paper, we present a comprehensive study of the adversarial robustness\nof audio-visual models, considering both temporal and modality-specific\nvulnerabilities. We propose two powerful adversarial attacks: 1) a temporal\ninvariance attack that exploits the inherent temporal redundancy across\nconsecutive time segments and 2) a modality misalignment attack that introduces\nincongruence between the audio and visual modalities. These attacks are\ndesigned to thoroughly assess the robustness of audio-visual models against\ndiverse threats. Furthermore, to defend against such attacks, we introduce a\nnovel audio-visual adversarial training framework. This framework addresses key\nchallenges in vanilla adversarial training by incorporating efficient\nadversarial perturbation crafting tailored to multi-modal data and an\nadversarial curriculum strategy. Extensive experiments in the Kinetics-Sounds\ndataset demonstrate that our proposed temporal and modality-based attacks in\ndegrading model performance can achieve state-of-the-art performance, while our\nadversarial training defense largely improves the adversarial robustness as\nwell as the adversarial training efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2502.11858v3",
    "published": "2025-02-17T14:50:34+00:00",
    "categories": [
      "cs.SD",
      "cs.CV"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2502.11857v1",
    "title": "A Proposed End-To-End Principle for Data Commons",
    "authors": [
      "Robert L. Grossman"
    ],
    "abstract": "A data commons brings together (or co-locates) data with cloud computing\ninfrastructure and commonly used software services, tools and applications for\nmanaging, analyzing and sharing data to create an interoperable resource for a\nresearch community. We introduce an architectural design principle for data\ncommons called the narrow middle architecture that is broadly based upon the\nend-to-end argument in systems design. We also discuss important core services\nfor data commons and the role of standards.",
    "pdf_url": "http://arxiv.org/pdf/2502.11857v1",
    "published": "2025-02-17T14:49:48+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11856v1",
    "title": "LLMs as a synthesis between symbolic and continuous approaches to language",
    "authors": [
      "Gemma Boleda"
    ],
    "abstract": "Since the middle of the 20th century, a fierce battle is being fought between\nsymbolic and continuous approaches to language and cognition. The success of\ndeep learning models, and LLMs in particular, has been alternatively taken as\nshowing that the continuous camp has won, or dismissed as an irrelevant\nengineering development. However, in this position paper I argue that deep\nlearning models for language actually represent a synthesis between the two\ntraditions. This is because 1) deep learning architectures allow for both\ncontinuous/distributed and symbolic/discrete-like representations and\ncomputations; 2) models trained on language make use this flexibility. In\nparticular, I review recent research in mechanistic interpretability that\nshowcases how a substantial part of morphosyntactic knowledge is encoded in a\nnear-discrete fashion in LLMs. This line of research suggests that different\nbehaviors arise in an emergent fashion, and models flexibly alternate between\nthe two modes (and everything in between) as needed. This is possibly one of\nthe main reasons for their wild success; and it is also what makes them\nparticularly interesting for the study of language and cognition. Is it time\nfor peace?",
    "pdf_url": "http://arxiv.org/pdf/2502.11856v1",
    "published": "2025-02-17T14:48:18+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11855v1",
    "title": "Diffusive spin transport of the spin-1/2 XXZ chain in the Ising regime at zero magnetic field and finite temperature",
    "authors": [
      "Jose M. P. Carmelo",
      "Pedro D. Sacramento"
    ],
    "abstract": "The studies of this paper on the spin-1/2 XXZ chain at finite temperatures\nT>0 have two complementary goals. The first is to identify the spin carriers of\nall its Sq>0 energy eigenstates and to show that their spin elementary currents\nfully control the spin-transport quantities. Here Sq is the q-spin of the\ncontinuous SUq(2) symmetry of the model for anisotropy >1. To achieve this\ngoal, our studies rely on a suitable exact physical-spin representation.Both\nthe spin stiffness and the zero-field spin-diffusion constant are expressed in\nterms of thermal expectation values of the square of the elementary currents\ncarried by the spin carriers. Our second goal is to confirm that the zero-field\nand finite-temperature spin transport is normal diffusive for anisotropy >1. We\nuse two complementary methods that rely on an inequality for the T>0 spin\nstiffness and the above thermal expectation values, respectively, to show that\nthe contributions to ballistic spin transport vanish. Complementarily, for T>0\nand anisotropy >1, the spin-diffusion constant is found to be finite and\nenhanced upon lowering T, reaching its largest yet finite values at low\ntemperatures. Evidence suggests that it diverges in the anisotropy limit to 1\nfor T>0, consistent with T>0 anomalous superdiffusive spin transport at\nanisotropy 1 and zero field.",
    "pdf_url": "http://arxiv.org/pdf/2502.11855v1",
    "published": "2025-02-17T14:47:28+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11854v1",
    "title": "Enhanced Anomaly Detection in IoMT Networks using Ensemble AI Models on the CICIoMT2024 Dataset",
    "authors": [
      "Prathamesh Chandekar",
      "Mansi Mehta",
      "Swet Chandan"
    ],
    "abstract": "The rapid proliferation of Internet of Medical Things (IoMT) devices in\nhealthcare has introduced unique cybersecurity challenges, primarily due to the\ndiverse communication protocols and critical nature of these devices This\nresearch aims to develop an advanced, real-time anomaly detection framework\ntailored for IoMT network traffic, leveraging AI/ML models and the CICIoMT2024\ndataset By integrating multi-protocol (MQTT, WiFi), attack-specific (DoS,\nDDoS), time-series (active/idle states), and device-specific (Bluetooth) data,\nour study captures a comprehensive range of IoMT interactions As part of our\ndata analysis, various machine learning techniques are employed which include\nan ensemble model using XGBoost for improved performance against specific\nattack types, sequential models comprised of LSTM and CNN-LSTM that leverage\ntime dependencies, and unsupervised models such as Autoencoders and Isolation\nForest that are good in general anomaly detection The results of the experiment\nprove with an ensemble model lowers false positive rates and reduced\ndetections.",
    "pdf_url": "http://arxiv.org/pdf/2502.11854v1",
    "published": "2025-02-17T14:46:58+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11853v2",
    "title": "StructTransform: A Scalable Attack Surface for Safety-Aligned Large Language Models",
    "authors": [
      "Shehel Yoosuf",
      "Temoor Ali",
      "Ahmed Lekssays",
      "Mashael AlSabah",
      "Issa Khalil"
    ],
    "abstract": "In this work, we present a series of structure transformation attacks on LLM\nalignment, where we encode natural language intent using diverse syntax spaces,\nranging from simple structure formats and basic query languages (e.g., SQL) to\nnew novel spaces and syntaxes created entirely by LLMs. Our extensive\nevaluation shows that our simplest attacks can achieve close to a 90% success\nrate, even on strict LLMs (such as Claude 3.5 Sonnet) using SOTA alignment\nmechanisms. We improve the attack performance further by using an adaptive\nscheme that combines structure transformations along with existing content\ntransformations, resulting in over 96% ASR with 0% refusals.\n  To generalize our attacks, we explore numerous structure formats, including\nsyntaxes purely generated by LLMs. Our results indicate that such novel\nsyntaxes are easy to generate and result in a high ASR, suggesting that\ndefending against our attacks is not a straightforward process. Finally, we\ndevelop a benchmark and evaluate existing safety-alignment defenses against it,\nshowing that most of them fail with 100% ASR. Our results show that existing\nsafety alignment mostly relies on token-level patterns without recognizing\nharmful concepts, highlighting and motivating the need for serious research\nefforts in this direction. As a case study, we demonstrate how attackers can\nuse our attack to easily generate a sample malware and a corpus of fraudulent\nSMS messages, which perform well in bypassing detection.",
    "pdf_url": "http://arxiv.org/pdf/2502.11853v2",
    "published": "2025-02-17T14:46:38+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11852v3",
    "title": "Algebraic Independence of an Airy Function, Its Derivative, and Antiderivative",
    "authors": [
      "Folkmar Bornemann"
    ],
    "abstract": "Using tools from the Siegel-Shidlovskii theory of transcendental numbers, we\nprove that a nontrivial solution of the Airy equation, its derivative, and an\nantiderivative are algebraically independent over the field of rational\nfunctions. Courtesy of Michael Singer, the result is also derived from general\nconsiderations in differential Galois theory.",
    "pdf_url": "http://arxiv.org/pdf/2502.11852v3",
    "published": "2025-02-17T14:45:42+00:00",
    "categories": [
      "math.CA",
      "math.CV",
      "33C10, 34M15, 11J91, 12H05"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11851v1",
    "title": "Evolution of radiation-induced damage in nuclear graphite -- a comparative structural and microstructural study",
    "authors": [
      "Magdalena Wilczopolska",
      "Kinga Suchorab",
      "Magdalena Gaweda",
      "Malgorzata Frelek-Kozak",
      "Pawel Ciepielewski",
      "Marcin Brykala",
      "Wojciech Chmurzynski",
      "Iwona Jozwik"
    ],
    "abstract": "Graphite, as a material for high-temperature gas-cooled reactors (HTGR), will\nbe exposed to harsh environment. The stability of graphite structure under\nirradiation is of a key importance for efficiency, reliability and security of\nthe Generation IV nuclear reactors. Three types of nuclear grade graphite were\nsubjected to irradiation in this research - two commercially manufactured\n(IG-110 and NBG-17) and the laboratory's in-home material (NCBJ). The samples\nwere exposed to 150 keV Ar+ and He+ ions bombardment at 400 C with fluences\nranging from 1E12 to 2E17 ion/cm2 in order to simulate in-reactor conditions.\nFor analysis of the level of structure damage, type of created defects and\ncrystallite size changes under ion irradiation ex-situ Raman spectroscopy was\nused. The methodology of spectra fitting was developed. Furthermore, SEM\nobservation of irradiated materials was performed. Results showed structural\ndegradation of materials by the means of amorphisation: slight at a low fluence\nlevel, rising rapidly at higher irradiation values. Furthermore, stronger\nstructural disorder was found in the materials irradiated with heavier Ar+ ions\nthan with lighter He+. Microstructural evolution of the nuclear graphites\naligned with the structural deterioration in its stepwise character.",
    "pdf_url": "http://arxiv.org/pdf/2502.11851v1",
    "published": "2025-02-17T14:45:28+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11850v1",
    "title": "Steering the LoCoMotif: Using Domain Knowledge in Time Series Motif Discovery",
    "authors": [
      "Aras Yurtman",
      "Daan Van Wesenbeeck",
      "Wannes Meert",
      "Hendrik Blockeel"
    ],
    "abstract": "Time Series Motif Discovery (TSMD) identifies repeating patterns in time\nseries data, but its unsupervised nature might result in motifs that are not\ninteresting to the user. To address this, we propose a framework that allows\nthe user to impose constraints on the motifs to be discovered, where\nconstraints can easily be defined according to the properties of the desired\nmotifs in the application domain. We also propose an efficient implementation\nof the framework, the LoCoMotif-DoK algorithm. We demonstrate that\nLoCoMotif-DoK can effectively leverage domain knowledge in real and synthetic\ndata, outperforming other TSMD techniques which only support a limited form of\ndomain knowledge.",
    "pdf_url": "http://arxiv.org/pdf/2502.11850v1",
    "published": "2025-02-17T14:44:12+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11849v3",
    "title": "Weak solutions and sharp interface limit of the anisotropic Cahn-Hilliard equation with disparate mobility and inhomogeneous potential",
    "authors": [
      "Charles Elbar",
      "Andrea Poiatti"
    ],
    "abstract": "We study the existence of weak solutions and the corresponding sharp\ninterface limit of an anisotropic Cahn-Hilliard equation with disparate\nmobility, i.e., the mobility is degenerate in one of the two pure phases,\nmaking the diffusion in that phase vanish. The double-well potential is\npolynomial and is weighted by a spatially inhomogeneous coefficient. In the\nlimit when the parameter of the interface width tends to zero, and under an\nenergy convergence assumption, we prove that the weak solutions converge to BV\nsolutions of a weighted anisotropic Hele-Shaw flow. We also add some numerical\nsimulations to analyze the effects of anisotropy on the Cahn-Hilliard equation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11849v3",
    "published": "2025-02-17T14:43:47+00:00",
    "categories": [
      "math.AP",
      "35B40, 35K65, 35G20, 53E40, 76D27"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11848v1",
    "title": "RustSFQ: A Domain-Specific Language for SFQ Circuit Design",
    "authors": [
      "Mebuki Oishi",
      "Sun Tanaka",
      "Shinya Takamaeda-Yamazaki"
    ],
    "abstract": "Cell-based design of a single-flux-quantum (SFQ) digital circuit requires\ninput-output consistency; every output signal must be consumed only once by the\ninput of the following component, which is a unique constraint, unlike the\ntraditional CMOS digital circuit design. While there are some cell libraries\nand simulation tools for SFQ circuit development, they do not verify the\ninput-output consistency, and designers have significant responsibilities to\nensure it manually. Additionally, designers have to carefully manage net names\nwithout unintended duplication and correct connectivity among nets in a netlist\nfor simulations. We propose RustSFQ, a domain-specific language (DSL) embedded\nin Rust that automatically ensures the input-output consistency in the SFQ\ncircuit by leveraging the ownership system of Rust. Each SFQ circuit element is\nrepresented as a function while wires are represented as instances, and the\nRust compiler verifies that multiple elements do not share a single wire\nthrough the ownership system. Circuit descriptions in the RustSFQ are\nsuccessfully compiled into low-level netlists for both analog and digital\ncircuit simulations, and the DSL provides higher productivity than the\nconventional design flow. Using the RustSFQ, we developed an SFQ-based\nReed-Solomon encoder with a 4-bit width for the first time as a case study. We\nconfirmed that the circuit operated correctly at 10 GHz through circuit\nsimulations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11848v1",
    "published": "2025-02-17T14:43:22+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11847v1",
    "title": "Minimal log discrepancy and orbifold curves",
    "authors": [
      "Chi Li",
      "Zhengyi Zhou"
    ],
    "abstract": "We show that the minimal log discrepancy of any isolated Fano cone\nsingularity is at most the dimension of the variety. This is based on its\nrelation with dimensions of moduli spaces of orbifold rational curves. We also\npropose a conjectural characterization of weighted projective spaces as Fano\norbifolds in terms of orbifold rational curves, which would imply the equality\nholds only for smooth points.",
    "pdf_url": "http://arxiv.org/pdf/2502.11847v1",
    "published": "2025-02-17T14:42:17+00:00",
    "categories": [
      "math.AG",
      "math.SG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11846v2",
    "title": "Neural Network Reconstruction of Non-Gaussian Initial Conditions from Dark Matter Halos",
    "authors": [
      "Jelte Bottema",
      "Thomas FlÃ¶ss",
      "P. Daniel Meerburg"
    ],
    "abstract": "We develop a machine learning approach to reconstructing the cosmological\ninitial conditions from late-time dark matter halo number density fields in\nredshift space, with the goal of improving sensitivity to cosmological\nparameters, and in particular primordial non-Gaussianity. Using an U-Net\narchitecture, our model achieves a cross-correlation accuracy of 44% for scales\nout to $k = 0.4 \\text{ h}/\\text{Mpc}$ between reconstructed and true initial\nconditions of Quijote 1 Gpc$^3$ simulation boxes with an average halo number\ndensity of $\\bar{n} = 4\\times 10^{-4}$ (h/Mpc)$^{3}$ in the tracer field at\n$z=0$ . We demonstrate that our reconstruction is likely to be optimal for this\nsetup and that it is highly effective at reducing redshift-space distortions.\nUsing a Fisher analysis, we show that reconstruction improves cosmological\nparameter constraints derived from the power spectrum and bispectrum. By\ncombining the power spectrum monopole, quadrupole, and bispectrum monopole up\nto $k_{\\rm{max}} = 0.52 \\text{ h}/\\text{Mpc}$, our joint analysis of pre- and\npost-reconstructed fields from the Quijote simulation suite finds improved\nmarginalized errors on all cosmological parameters. In particular,\nreconstruction improves constraints on $f_{\\rm{NL}}$ by factors of 1.33, 1.88,\nand 1.57 for local, equilateral, and orthogonal shapes. Our findings\ndemonstrate the effectiveness of reconstruction in decoupling modes, mitigating\nredshift-space distortions and maximizing information on cosmology. The results\nprovide important insights into the amount of cosmological information that can\nbe extracted from small scales, and can potentially be used to complement\nstandard analysis of observational data, upon further development.",
    "pdf_url": "http://arxiv.org/pdf/2502.11846v2",
    "published": "2025-02-17T14:41:52+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11845v1",
    "title": "Signal-adapted decomposition of graph signals",
    "authors": [
      "Harry H. Behjat",
      "Carl-Fredrik Westin",
      "Rik Ossenkoppele",
      "Dimitri Van De Ville"
    ],
    "abstract": "Analysis of signals defined on complex topologies modeled by graphs is a\ntopic of increasing interest. Signal decomposition plays a crucial role in the\nrepresentation and processing of such information, in particular, to process\ngraph signals based on notions of scale (e.g., coarse to fine). The graph\nspectrum is more irregular than for conventional domains; i.e., it is\ninfluenced by graph topology, and, therefore, assumptions about spectral\nrepresentations of graph signals are not easy to make. Here, we propose a tight\nframe design that is adapted to the graph Laplacian spectral content of given\nclasses of graph signals. The design is based on using the ensemble energy\nspectral density, a notion of spectral content of given signal sets that we\ndetermine either directly using the graph Fourier transform or indirectly\nthrough a polynomial-based approximation scheme. The approximation scheme has\nthe benefit that (i) it does not require eigendecomposition of the Laplacian\nmatrix making the method feasible for large graphs, and (ii) it leads to a\nsmooth estimate of the spectral content. A prototype system of spectral kernels\neach capturing an equal amount of energy is initially defined and subsequently\nwarped using the signal set's ensemble energy spectral density such that the\nresulting subbands each capture an equal amount of ensemble energy. This\napproach accounts at the same time for graph topology and signal features, and\nit provides a meaningful interpretation of subbands in terms of coarse-to-fine\nrepresentations. We also show how more simplified designs of signal-adapted\ndecomposition of graph signals can be adopted based on ensemble energy\nestimates. We show the application of proposed methods on the Minnesota road\ngraph and three different designs of brain graphs derived from neuroimaging\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2502.11845v1",
    "published": "2025-02-17T14:39:52+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11844v3",
    "title": "BaxBench: Can LLMs Generate Correct and Secure Backends?",
    "authors": [
      "Mark Vero",
      "Niels MÃ¼ndler",
      "Victor Chibotaru",
      "Veselin Raychev",
      "Maximilian Baader",
      "Nikola JovanoviÄ",
      "Jingxuan He",
      "Martin Vechev"
    ],
    "abstract": "Automatic program generation has long been a fundamental challenge in\ncomputer science. Recent benchmarks have shown that large language models\n(LLMs) can effectively generate code at the function level, make code edits,\nand solve algorithmic coding tasks. However, to achieve full automation, LLMs\nshould be able to generate production-quality, self-contained application\nmodules. To evaluate the capabilities of LLMs in solving this challenge, we\nintroduce BaxBench, a novel evaluation benchmark consisting of 392 tasks for\nthe generation of backend applications. We focus on backends for three critical\nreasons: (i) they are practically relevant, building the core components of\nmost modern web and cloud software, (ii) they are difficult to get right,\nrequiring multiple functions and files to achieve the desired functionality,\nand (iii) they are security-critical, as they are exposed to untrusted\nthird-parties, making secure solutions that prevent deployment-time attacks an\nimperative. BaxBench validates the functionality of the generated applications\nwith comprehensive test cases, and assesses their security exposure by\nexecuting end-to-end exploits. Our experiments reveal key limitations of\ncurrent LLMs in both functionality and security: (i) even the best model,\nOpenAI o1, achieves a mere 62% on code correctness; (ii) on average, we could\nsuccessfully execute security exploits on around half of the correct programs\ngenerated by each LLM; and (iii) in less popular backend frameworks, models\nfurther struggle to generate correct and secure applications. Progress on\nBaxBench signifies important steps towards autonomous and secure software\ndevelopment with LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11844v3",
    "published": "2025-02-17T14:37:47+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11843v1",
    "title": "Can LLM Agents Maintain a Persona in Discourse?",
    "authors": [
      "Pranav Bhandari",
      "Nicolas Fay",
      "Michael Wise",
      "Amitava Datta",
      "Stephanie Meek",
      "Usman Naseem",
      "Mehwish Nasim"
    ],
    "abstract": "Large Language Models (LLMs) are widely used as conversational agents,\nexploiting their capabilities in various sectors such as education, law,\nmedicine, and more. However, LLMs are often subjected to context-shifting\nbehaviour, resulting in a lack of consistent and interpretable\npersonality-aligned interactions. Adherence to psychological traits lacks\ncomprehensive analysis, especially in the case of dyadic (pairwise)\nconversations. We examine this challenge from two viewpoints, initially using\ntwo conversation agents to generate a discourse on a certain topic with an\nassigned personality from the OCEAN framework (Openness, Conscientiousness,\nExtraversion, Agreeableness, and Neuroticism) as High/Low for each trait. This\nis followed by using multiple judge agents to infer the original traits\nassigned to explore prediction consistency, inter-model agreement, and\nalignment with the assigned personality. Our findings indicate that while LLMs\ncan be guided toward personality-driven dialogue, their ability to maintain\npersonality traits varies significantly depending on the combination of models\nand discourse settings. These inconsistencies emphasise the challenges in\nachieving stable and interpretable personality-aligned interactions in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11843v1",
    "published": "2025-02-17T14:36:39+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11842v3",
    "title": "Noncontextual ontological models of operational probabilistic theories",
    "authors": [
      "Sina Soltani",
      "Marco Erba",
      "David Schmid",
      "John H. Selby"
    ],
    "abstract": "An experiment or theory is classically explainable if it can be reproduced by\nsome noncontextual ontological model. In this work, we adapt the notion of\nontological models and generalized noncontextuality so it applies to the\nframework of operational probabilistic theories (OPTs). A defining feature of\nquotiented OPTs, which sets them apart from the closely related framework of\ngeneralized probabilistic theories (GPTs), is their explicit specification of\nthe structure of instruments, these being generalizations of $\\textit{quantum\ninstruments}$ (including nondestructive measurements); in particular, one needs\nto explicitly declare which collections of transformations constitute a valid\ninstrument. We are particularly interested in strongly causal OPTs, in which\nthe choice of a future instrument can be conditioned on a past measurement\noutcome. This instrument structure might seem to permit the possibility of a\ncontextual kind of ontological representation, where the representation of a\ngiven transformation depends on which instrument it is considered a part of.\nHowever, we prove that this is not possible by showing that for strongly causal\nquotiented OPTs the structure of instruments does $\\textit{not}$ allow for such\na contextual ontological representation. It follows that ontological\nrepresentations of strongly causal quotiented OPTs are entirely determined by\ntheir action on individual transformations, with no dependence on the structure\nof instruments.",
    "pdf_url": "http://arxiv.org/pdf/2502.11842v3",
    "published": "2025-02-17T14:36:37+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11841v1",
    "title": "Exerting chemical pressure on the kagome lattice as frustration control in the kapellasite family $A$Cu$_3$(OH)$_{6+x}$(Cl,Br)$_{3-x}$",
    "authors": [
      "Jonas Andreas Krieger",
      "Thomas James Hicken",
      "Hubertus Luetkens",
      "Reinhard K. Kremer",
      "Pascal Puphal"
    ],
    "abstract": "The kapellasite family $A$Cu$_3$(OH)$_{6+x}$(Cl,Br)$_{3-x}$ forms a series of\ncompounds, wherein the chemical pressure realized by the $A-$site cation tunes\nthe spin exchange in the frustrated distorted kagome lattice. Via hydrothermal\nsynthesis we have grown single crystals of the whole series for $A=$\nrare-earths and found a clear structural transition to a superstructure variant\nat a specific chemical pressure level exerted by $A$~=~Dy. Phases with crystal\nstructures in the vicinity of this superstructure transition realize a\ndistorted kagome lattice of the Cu$^{2+}$ cations with characteristic features\nof a spin liquid. Here, subtle structural disorder as well as controlled\nchemical pressure can stabilize the spin liquid phase. We study the crystal\nstructure and the magnetic ground state of these phases via single crystal\nx-ray diffraction, magnetic susceptibility, specific heat and muon spin\nspectroscopy measurements.",
    "pdf_url": "http://arxiv.org/pdf/2502.11841v1",
    "published": "2025-02-17T14:36:29+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11840v1",
    "title": "ChordFormer: A Conformer-Based Architecture for Large-Vocabulary Audio Chord Recognition",
    "authors": [
      "Muhammad Waseem Akram",
      "Stefano Dettori",
      "Valentina Colla",
      "Giorgio Carlo Buttazzo"
    ],
    "abstract": "Chord recognition serves as a critical task in music information retrieval\ndue to the abstract and descriptive nature of chords in music analysis. While\naudio chord recognition systems have achieved significant accuracy for small\nvocabularies (e.g., major/minor chords), large-vocabulary chord recognition\nremains a challenging problem. This complexity also arises from the inherent\nlong-tail distribution of chords, where rare chord types are underrepresented\nin most datasets, leading to insufficient training samples. Effective chord\nrecognition requires leveraging contextual information from audio sequences,\nyet existing models, such as combinations of convolutional neural networks,\nbidirectional long short-term memory networks, and bidirectional transformers,\nface limitations in capturing long-term dependencies and exhibit suboptimal\nperformance on large-vocabulary chord recognition tasks. This work proposes\nChordFormer, a novel conformer-based architecture designed to tackle structural\nchord recognition (e.g., triads, bass, sevenths) for large vocabularies.\nChordFormer leverages conformer blocks that integrate convolutional neural\nnetworks with transformers, thus enabling the model to capture both local\npatterns and global dependencies effectively. By addressing challenges such as\nclass imbalance through a reweighted loss function and structured chord\nrepresentations, ChordFormer outperforms state-of-the-art models, achieving a\n2% improvement in frame-wise accuracy and a 6% increase in class-wise accuracy\non large-vocabulary chord datasets. Furthermore, ChordFormer excels in handling\nclass imbalance, providing robust and balanced recognition across chord types.\nThis approach bridges the gap between theoretical music knowledge and practical\napplications, advancing the field of large-vocabulary chord recognition.",
    "pdf_url": "http://arxiv.org/pdf/2502.11840v1",
    "published": "2025-02-17T14:35:16+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2502.11839v3",
    "title": "The plus construction with respect to subrings of the rationals",
    "authors": [
      "Guille CarriÃ³n Santiago",
      "RamÃ³n Flores",
      "JÃ©rÃ´me Scherer"
    ],
    "abstract": "We construct explicit models of universal $H \\mathbb{Z}[J^{-1}]$-acyclic\nspaces $\\mathcal M$, for any subset $J$ of the prime numbers. The corresponding\nnullification functors provide thus plus construction functors for ordinary\nhomology with $\\mathbb{Z}[J^{-1}]$ coefficients. Motivated by classical results\nabout Quillen's plus construction for integral homology, we prove that the $H\n\\mathbb{Z}[J^{-1}]$-acyclization functor and the $\\mathcal M$-cellularization\nfunctor coincide. We show that the acyclization-plus construction fiber\nsequence is always a cofiber sequence for simply connected spaces, but almost\nnever so when the plus construction is not simply connected, unlike in the\nclassical case.",
    "pdf_url": "http://arxiv.org/pdf/2502.11839v3",
    "published": "2025-02-17T14:34:39+00:00",
    "categories": [
      "math.AT",
      "math.GR",
      "math.KT",
      "19D06, 55P60, 20F05"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11838v1",
    "title": "Mass loss along the red giant branch of the intermediate stellar populations in NGC6752 and NGC2808",
    "authors": [
      "M. Tailo",
      "A. P. Milone",
      "A. F. Marino",
      "F. D'Antona",
      "M. V. Legnardi",
      "T. Ziliotto",
      "E. P. Lagioia",
      "S. Jang",
      "E. Bortolan",
      "P. Ventura",
      "C. Ventura",
      "E. Dondoglio",
      "F. Muratore",
      "A. Mohandasan",
      "M. Barbieri",
      "S. Lionetto",
      "G. Cordoni",
      "F. Dell'Agli"
    ],
    "abstract": "The morphology of the Horizontal Branch (HB) in Globular Clusters (GC) is\namong the early evidences that they contain multiple populations of stars.\nIndeed, the location of each star along the HB depends both on its initial\nhelium content (Y) and on the global average mass loss along the red giant\nbranch ($\\mu$). In most GCs, it is generally straightforward to analyse the\nfirst stellar population (standard Y), and the most extreme one (largest Y),\nwhile it is more tricky to look at the \"intermediate\" populations (mildly\nenhanced Y). In this work, we do this for the GCs NGC6752 and NGC2808; wherever\npossible the helium abundance for each stellar populations is constrained by\nusing independent measurements present in the literature. We compare population\nsynthesis models with photometric catalogues from the Hubble Space Telescope\nTreasury survey to derive the parameters of these HB stars. We find that the\nlocation of helium enriched stars on the HB is reproduced only by adopting a\nhigher value of $\\mu$ with respect to the first generation stars in all the\nanalysed stellar populations. We also find that $\\mu$ correlates with the\nhelium enhancement of the populations. This holds for both clusters. This\nfinding is naturally predicted by the model of ''pre-main sequence disc early\nloss'', previously suggested in the literature, and is consistent with the\nfindings of multiple-populations formation models that foresee the formation of\nsecond generation stars in a cooling flow.",
    "pdf_url": "http://arxiv.org/pdf/2502.11838v1",
    "published": "2025-02-17T14:33:37+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11837v1",
    "title": "Extreme electrodynamics in time-varying media",
    "authors": [
      "M. Scalora",
      "M. A. Vincenti",
      "D. de Ceglia",
      "N. Akozbek",
      "M. Ferrera",
      "C. Rizza",
      "A. AlÃ¹",
      "N. Litchinitser",
      "C. Cojocaru",
      "J. Trull"
    ],
    "abstract": "Abrupt time variations of the properties of optical materials have been at\nthe center of intense research efforts in recent years, with the prospect of\nenabling extreme wave transformations and of leveraging time as a degree of\nfreedom for wave control. While the most viable approach to yield ultrafast\nvariations of the optical material response is through optical pumping of\nnonlinear media, the complex dynamics in these systems are not yet fully\nunderstood. Here, as a relevant case study, we rigorously investigate the\npump-probe dynamics in a 310nm-thick transparent conductive oxide etalon, using\na weak 40 femtosecond probe and a pump that displays peak power densities in\nthe TW/cm^2 range with a duration of a few femtoseconds. We examine the\npump-probe interaction using a hydrodynamic-Maxwell approach that accounts for\ndiffraction, self-focusing and -defocusing, self- and cross-phase modulation,\nprobe gain, and linear and nonlinear material dispersion expanded in the\nperturbative regime up to 9th order for both pump and probe. By allowing the\nintricacies of the pump-probe interaction to proceed in time, we can also\ndefine an effective spatio-temporal permittivity for a more direct evaluation\nof the material ultra-broadband optical behavior. The reported results\nchallenge the conventional modeling of this kind of problem, which has so far\noverlooked pump dynamics, simplistically assigning a local time-dependent\nrefractive index to the probe that may be designed to fit the experimental\ndata, but has no physical connection to the complex pump-probe interaction. Our\napproach unveils new dynamics, pointing towards the possibility to achieve\nextreme pulse compression into the attosecond range and nonlinear diffraction\nover deeply subwavelength propagation distances, thus opening a possible new\npath towards novel and cost-effective tools for integrated photonics and\nattosecond science.",
    "pdf_url": "http://arxiv.org/pdf/2502.11837v1",
    "published": "2025-02-17T14:31:23+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.11836v2",
    "title": "Model Generalization on Text Attribute Graphs: Principles with Large Language Models",
    "authors": [
      "Haoyu Wang",
      "Shikun Liu",
      "Rongzhe Wei",
      "Pan Li"
    ],
    "abstract": "Large language models (LLMs) have recently been introduced to graph learning,\naiming to extend their zero-shot generalization success to tasks where labeled\ngraph data is scarce. Among these applications, inference over text-attributed\ngraphs (TAGs) presents unique challenges: existing methods struggle with LLMs'\nlimited context length for processing large node neighborhoods and the\nmisalignment between node embeddings and the LLM token space. To address these\nissues, we establish two key principles for ensuring generalization and derive\nthe framework LLM-BP accordingly: (1) Unifying the attribute space with\ntask-adaptive embeddings, where we leverage LLM-based encoders and task-aware\nprompting to enhance generalization of the text attribute embeddings; (2)\nDeveloping a generalizable graph information aggregation mechanism, for which\nwe adopt belief propagation with LLM-estimated parameters that adapt across\ngraphs. Evaluations on 11 real-world TAG benchmarks demonstrate that LLM-BP\nsignificantly outperforms existing approaches, achieving 8.10% improvement with\ntask-conditional embeddings and an additional 1.71% gain from adaptive\naggregation. The code and task-adaptive embeddings are publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2502.11836v2",
    "published": "2025-02-17T14:31:00+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12223v1",
    "title": "GLoT: A Novel Gated-Logarithmic Transformer for Efficient Sign Language Translation",
    "authors": [
      "Nada Shahin",
      "Leila Ismail"
    ],
    "abstract": "Machine Translation has played a critical role in reducing language barriers,\nbut its adaptation for Sign Language Machine Translation (SLMT) has been less\nexplored. Existing works on SLMT mostly use the Transformer neural network\nwhich exhibits low performance due to the dynamic nature of the sign language.\nIn this paper, we propose a novel Gated-Logarithmic Transformer (GLoT) that\ncaptures the long-term temporal dependencies of the sign language as a\ntime-series data. We perform a comprehensive evaluation of GloT with the\ntransformer and transformer-fusion models as a baseline, for\nSign-to-Gloss-to-Text translation. Our results demonstrate that GLoT\nconsistently outperforms the other models across all metrics. These findings\nunderscore its potential to address the communication challenges faced by the\nDeaf and Hard of Hearing community.",
    "pdf_url": "http://arxiv.org/pdf/2502.12223v1",
    "published": "2025-02-17T14:31:00+00:00",
    "categories": [
      "cs.CL",
      "cs.CV",
      "I.2.6; I.2.7; I.2.10; I.4.8; I.4.9; I.4.10"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11835v1",
    "title": "Neural Chaos: A Spectral Stochastic Neural Operator",
    "authors": [
      "Bahador Bahmani",
      "Ioannis G. Kevrekidis",
      "Michael D. Shields"
    ],
    "abstract": "Building surrogate models with uncertainty quantification capabilities is\nessential for many engineering applications where randomness, such as\nvariability in material properties, is unavoidable. Polynomial Chaos Expansion\n(PCE) is widely recognized as a to-go method for constructing stochastic\nsolutions in both intrusive and non-intrusive ways. Its application becomes\nchallenging, however, with complex or high-dimensional processes, as achieving\naccuracy requires higher-order polynomials, which can increase computational\ndemands and or the risk of overfitting. Furthermore, PCE requires specialized\ntreatments to manage random variables that are not independent, and these\ntreatments may be problem-dependent or may fail with increasing complexity. In\nthis work, we adopt the spectral expansion formalism used in PCE; however, we\nreplace the classical polynomial basis functions with neural network (NN) basis\nfunctions to leverage their expressivity. To achieve this, we propose an\nalgorithm that identifies NN-parameterized basis functions in a purely\ndata-driven manner, without any prior assumptions about the joint distribution\nof the random variables involved, whether independent or dependent. The\nproposed algorithm identifies each NN-parameterized basis function\nsequentially, ensuring they are orthogonal with respect to the data\ndistribution. The basis functions are constructed directly on the joint\nstochastic variables without requiring a tensor product structure. This\napproach may offer greater flexibility for complex stochastic models, while\nsimplifying implementation compared to the tensor product structures typically\nused in PCE to handle random vectors. We demonstrate the effectiveness of the\nproposed scheme through several numerical examples of varying complexity and\nprovide comparisons with classical PCE.",
    "pdf_url": "http://arxiv.org/pdf/2502.11835v1",
    "published": "2025-02-17T14:30:46+00:00",
    "categories": [
      "cs.CE",
      "physics.comp-ph",
      "stat.ML"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11834v1",
    "title": "Ultrahigh energy cosmic rays and neutrino flux models",
    "authors": [
      "Marco Stein Muzio"
    ],
    "abstract": "In this review we motivate ultrahigh energy neutrino searches and their\nconnection to ultrahigh energy cosmic rays. We give an overview of neutrino\nproduction mechanisms and their potential sources. Several model-independent\nbenchmarks of the ultrahigh energy neutrino flux are discussed. Finally, a\nbrief discussion of approaches for model-dependent neutrino flux predictions\nare given, highlighting a few examples from the literature.",
    "pdf_url": "http://arxiv.org/pdf/2502.11834v1",
    "published": "2025-02-17T14:28:50+00:00",
    "categories": [
      "astro-ph.HE",
      "hep-ph"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11833v2",
    "title": "Active gel theory for cell migration with two myosin isoforms",
    "authors": [
      "Nils O. Winkler",
      "Oliver M. Drozdowski",
      "Falko Ziebert",
      "Ulrich S. Schwarz"
    ],
    "abstract": "Myosin II molecular motors slide actin filaments relatively to each other and\nare essential for force generation, motility and mechanosensing in animal\ncells. For non-muscle cells, evolution has resulted in three different\nisoforms, which have different properties concerning the motor cycle and also\noccur in different abundances in the cells, but their respective biological and\nphysical roles are not fully understood. Here we use active gel theory to\ndemonstrate the complementary roles of isoforms A and B for cell migration. We\nfirst show that our model can be derived both from coarse-graining kinetic\nequations and from nonequilibrium thermodynamics as the macroscopic limit of a\ntwo-component Tonks gas. We then parametrize the model and show that motile\nsolutions exist, in which the more abundant and more dynamic isoform A is\nlocalized to the front and the stronger isoform B to the rear, in agreement\nwith experiments. Exploring parameter space beyond the isoform parameters\ntypical for animal cells, we also find cell oscillations in length and\nvelocity, which might be realized for genetically engineered systems. We also\ndescribe an analytical solution for the stiff limit, which then is used to\ncalculate a state diagram, and the effect of actin polymerization at the\nboundaries, that leads to an imperfect pitchfork bifurcation. Our findings\nhighlight the importance of including isoform-specific molecular details to\ndescribe whole cell behavior.",
    "pdf_url": "http://arxiv.org/pdf/2502.11833v2",
    "published": "2025-02-17T14:28:21+00:00",
    "categories": [
      "q-bio.CB",
      "cond-mat.soft",
      "physics.bio-ph"
    ],
    "primary_category": "q-bio.CB"
  },
  {
    "id": "http://arxiv.org/abs/2502.11832v1",
    "title": "HAAN: A Holistic Approach for Accelerating Normalization Operations in Large Language Models",
    "authors": [
      "Tianfan Peng",
      "Jiajun Qin",
      "Tianhua Xia",
      "Sai Qian Zhang"
    ],
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\n(NLP) tasks by achieving state-of-the-art performance across a range of\nbenchmarks. Central to the success of these models is the integration of\nsophisticated architectural components aimed at improving training stability,\nconvergence speed, and generalization capabilities. Among these components,\nnormalization operation, such as layer normalization (LayerNorm), emerges as a\npivotal technique, offering substantial benefits to the overall model\nperformance. However, previous studies have indicated that normalization\noperations can substantially elevate processing latency and energy usage. In\nthis work, we adopt the principles of algorithm and hardware co-design,\nintroducing a holistic normalization accelerating method named HAAN. The\nevaluation results demonstrate that HAAN can achieve significantly better\nhardware performance compared to state-of-the-art solutions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11832v1",
    "published": "2025-02-17T14:27:27+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11831v1",
    "title": "Intuitive physics understanding emerges from self-supervised pretraining on natural videos",
    "authors": [
      "Quentin Garrido",
      "Nicolas Ballas",
      "Mahmoud Assran",
      "Adrien Bardes",
      "Laurent Najman",
      "Michael Rabbat",
      "Emmanuel Dupoux",
      "Yann LeCun"
    ],
    "abstract": "We investigate the emergence of intuitive physics understanding in\ngeneral-purpose deep neural network models trained to predict masked regions in\nnatural videos. Leveraging the violation-of-expectation framework, we find that\nvideo prediction models trained to predict outcomes in a learned representation\nspace demonstrate an understanding of various intuitive physics properties,\nsuch as object permanence and shape consistency. In contrast, video prediction\nin pixel space and multimodal large language models, which reason through text,\nachieve performance closer to chance. Our comparisons of these architectures\nreveal that jointly learning an abstract representation space while predicting\nmissing parts of sensory input, akin to predictive coding, is sufficient to\nacquire an understanding of intuitive physics, and that even models trained on\none week of unique video achieve above chance performance. This challenges the\nidea that core knowledge -- a set of innate systems to help understand the\nworld -- needs to be hardwired to develop an understanding of intuitive\nphysics.",
    "pdf_url": "http://arxiv.org/pdf/2502.11831v1",
    "published": "2025-02-17T14:27:14+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11830v1",
    "title": "Text Classification in the LLM Era -- Where do we stand?",
    "authors": [
      "Sowmya Vajjala",
      "Shwetali Shimangaud"
    ],
    "abstract": "Large Language Models revolutionized NLP and showed dramatic performance\nimprovements across several tasks. In this paper, we investigated the role of\nsuch language models in text classification and how they compare with other\napproaches relying on smaller pre-trained language models. Considering 32\ndatasets spanning 8 languages, we compared zero-shot classification, few-shot\nfine-tuning and synthetic data based classifiers with classifiers built using\nthe complete human labeled dataset. Our results show that zero-shot approaches\ndo well for sentiment classification, but are outperformed by other approaches\nfor the rest of the tasks, and synthetic data sourced from multiple LLMs can\nbuild better classifiers than zero-shot open LLMs. We also see wide performance\ndisparities across languages in all the classification scenarios. We expect\nthat these findings would guide practitioners working on developing text\nclassification systems across languages.",
    "pdf_url": "http://arxiv.org/pdf/2502.11830v1",
    "published": "2025-02-17T14:25:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11829v1",
    "title": "Code-Vision: Evaluating Multimodal LLMs Logic Understanding and Code Generation Capabilities",
    "authors": [
      "Hanbin Wang",
      "Xiaoxuan Zhou",
      "Zhipeng Xu",
      "Keyuan Cheng",
      "Yuxin Zuo",
      "Kai Tian",
      "Jingwei Song",
      "Junting Lu",
      "Wenhui Hu",
      "Xueyang Liu"
    ],
    "abstract": "This paper introduces Code-Vision, a benchmark designed to evaluate the\nlogical understanding and code generation capabilities of Multimodal Large\nLanguage Models (MLLMs). It challenges MLLMs to generate a correct program that\nfulfills specific functionality requirements based on a given flowchart, which\nvisually represents the desired algorithm or process. Code-Vision comprises\nthree subsets: HumanEval-V, Algorithm, and MATH, which evaluate MLLMs' coding\nabilities across basic programming, algorithmic, and mathematical\nproblem-solving domains. Our experiments evaluate 12 MLLMs on Code-Vision.\nExperimental results demonstrate that there is a large performance difference\nbetween proprietary and open-source models. On Hard problems, GPT-4o can\nachieve 79.3% pass@1, but the best open-source model only achieves 15%. Further\nexperiments reveal that Code-Vision can pose unique challenges compared to\nother multimodal reasoning benchmarks MMCode and MathVista. We also explore the\nreason for the poor performance of the open-source models. All data and codes\nare available at https://github.com/wanghanbinpanda/CodeVision.",
    "pdf_url": "http://arxiv.org/pdf/2502.11829v1",
    "published": "2025-02-17T14:25:45+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11828v1",
    "title": "Intersectional Fairness in Reinforcement Learning with Large State and Constraint Spaces",
    "authors": [
      "Eric Eaton",
      "Marcel Hussing",
      "Michael Kearns",
      "Aaron Roth",
      "Sikata Bela Sengupta",
      "Jessica Sorrell"
    ],
    "abstract": "In traditional reinforcement learning (RL), the learner aims to solve a\nsingle objective optimization problem: find the policy that maximizes expected\nreward. However, in many real-world settings, it is important to optimize over\nmultiple objectives simultaneously. For example, when we are interested in\nfairness, states might have feature annotations corresponding to multiple\n(intersecting) demographic groups to whom reward accrues, and our goal might be\nto maximize the reward of the group receiving the minimal reward. In this work,\nwe consider a multi-objective optimization problem in which each objective is\ndefined by a state-based reweighting of a single scalar reward function. This\ngeneralizes the problem of maximizing the reward of the minimum reward group.\nWe provide oracle-efficient algorithms to solve these multi-objective RL\nproblems even when the number of objectives is exponentially large-for tabular\nMDPs, as well as for large MDPs when the group functions have additional\nstructure. Finally, we experimentally validate our theoretical results and\ndemonstrate applications on a preferential attachment graph MDP.",
    "pdf_url": "http://arxiv.org/pdf/2502.11828v1",
    "published": "2025-02-17T14:25:33+00:00",
    "categories": [
      "cs.LG",
      "cs.GT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11827v1",
    "title": "Influence Operations in Social Networks",
    "authors": [
      "Javier Pastor-Galindo",
      "Pantaleone Nespoli",
      "JosÃ© A. RuipÃ©rez-Valiente",
      "David Camacho"
    ],
    "abstract": "An important part of online activities are intended to control the public\nopinion and behavior, being considered currently a global threat. This article\nidentifies and conceptualizes seven online strategies employed in social media\ninfluence operations. These procedures are quantified through the analysis of\n80 incidents of foreign information manipulation and interference (FIMI),\nestimating their real-world usage and combination. Finally, we suggest future\ndirections for research on influence operations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11827v1",
    "published": "2025-02-17T14:23:41+00:00",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11826v1",
    "title": "Bi-invariant Geodesic Regression with Data from the Osteoarthritis Initiative",
    "authors": [
      "Johannes Schade",
      "Christoph von Tycowicz",
      "Martin Hanik"
    ],
    "abstract": "Many phenomena are naturally characterized by measuring continuous\ntransformations such as shape changes in medicine or articulated systems in\nrobotics. Modeling the variability in such datasets requires performing\nstatistics on Lie groups, that is, manifolds carrying an additional group\nstructure. As the Lie group captures the symmetries in the data, it is\nessential from a theoretical and practical perspective to ask for statistical\nmethods that respect these symmetries; this way they are insensitive to\nconfounding effects, e.g., due to the choice of reference coordinate systems.\nIn this work, we investigate geodesic regression -- a generalization of linear\nregression originally derived for Riemannian manifolds. While Lie groups can be\nendowed with Riemannian metrics, these are generally incompatible with the\ngroup structure. We develop a non-metric estimator using an affine connection\nsetting. It captures geodesic relationships respecting the symmetries given by\nleft and right translations. For its computation, we propose an efficient fixed\npoint algorithm requiring simple differential expressions that can be\ncalculated through automatic differentiation. We perform experiments on a\nsynthetic example and evaluate our method on an open-access, clinical dataset\nstudying knee joint configurations under the progression of osteoarthritis.",
    "pdf_url": "http://arxiv.org/pdf/2502.11826v1",
    "published": "2025-02-17T14:20:54+00:00",
    "categories": [
      "stat.ME",
      "stat.ML",
      "62J02, 22E70, 53Z50"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.11825v3",
    "title": "Quasi-Local Black Hole Horizons: Recent Advances",
    "authors": [
      "Abhay Ashtekar",
      "Badri Krishnan"
    ],
    "abstract": "While the early literature on black holes focused on event horizons,\nsubsequently it was realized that their teleological nature makes them\nunsuitable for many physical applications both in classical and quantum\ngravity. Therefore, over the past two decades, event horizons have been\nsteadily replaced by quasi-local horizons which do not suffer from teleology.\nIn numerical simulations event horizons can be located as an `after thought'\nonly after the entire space-time has been constructed. By contrast, quasi-local\nhorizons naturally emerge in the course of these simulations, providing\npowerful gauge-invariant tools to extract physics from the numerical outputs.\nThey also lead to interesting results in mathematical GR, providing unforeseen\ninsights. For example, for event horizons we only have a qualitative result\nthat their area cannot decrease, while for quasi-local horizons the increase in\nthe area during a dynamical phase is quantitatively related to local physical\nprocesses at the horizon. In binary black hole mergers, there are interesting\ncorrelations between observables associated with quasi-local horizons and those\ndefined at future null infinity. Finally, the quantum Hawking process is\nnaturally described as formation and evaporation of a quasi-local horizon. This\nreview focuses on the dynamical aspects of quasi-local horizons in classical\ngeneral relativity, emphasizing recent results and ongoing research.",
    "pdf_url": "http://arxiv.org/pdf/2502.11825v3",
    "published": "2025-02-17T14:17:21+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11824v3",
    "title": "M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis",
    "authors": [
      "Chengyan Wu",
      "Bolei Ma",
      "Yihong Liu",
      "Zheyu Zhang",
      "Ningyuan Deng",
      "Yanshu Li",
      "Baolan Chen",
      "Yi Zhang",
      "Yun Xue",
      "Barbara Plank"
    ],
    "abstract": "Aspect-based sentiment analysis (ABSA) is a crucial task in information\nextraction and sentiment analysis, aiming to identify aspects with associated\nsentiment elements in text. However, existing ABSA datasets are predominantly\nEnglish-centric, limiting the scope for multilingual evaluation and research.\nTo bridge this gap, we present M-ABSA, a comprehensive dataset spanning 7\ndomains and 21 languages, making it the most extensive multilingual parallel\ndataset for ABSA to date. Our primary focus is on triplet extraction, which\ninvolves identifying aspect terms, aspect categories, and sentiment polarities.\nThe dataset is constructed through an automatic translation process with human\nreview to ensure quality. We perform extensive experiments using various\nbaselines to assess performance and compatibility on M-ABSA. Our empirical\nfindings highlight that the dataset enables diverse evaluation tasks, such as\nmultilingual and multi-domain transfer learning, and large language model\nevaluation, underscoring its inclusivity and its potential to drive\nadvancements in multilingual ABSA research.",
    "pdf_url": "http://arxiv.org/pdf/2502.11824v3",
    "published": "2025-02-17T14:16:01+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11823v2",
    "title": "Scalable data-analysis framework for long-duration gravitational waves from compact binaries using short Fourier transforms",
    "authors": [
      "Rodrigo Tenorio",
      "Davide Gerosa"
    ],
    "abstract": "We introduce a framework based on short Fourier transforms (SFTs) to analyze\nlong-duration gravitational wave signals from compact binaries. Targeted\nsystems include binary neutron stars observed by third-generation ground-based\ndetectors and massive black hole binaries observed by the LISA space mission.\nIn short, ours is an extremely fast, scalable, and parallelizable\nimplementation of the gravitational wave inner product, a core operation of\ngravitational wave matched filtering. By operating on disjoint data segments,\nSFTs allow for efficient handling of noise nonstationarities, data gaps, and\ndetector-induced signal modulations. We present a pilot application to early\nwarning problems in both ground- and space-based next-generation detectors.\nOverall, SFTs reduce the computing cost of evaluating an inner product by three\nto five orders of magnitude, depending on the specific application, with\nrespect to a nonoptimized approach. We release public tools to operate using\nthe SFT framework, including a vectorized and hardware-accelerated\nreimplementation of a time-domain waveform. The inner product is the key\nbuilding block of all gravitational wave data treatments; by speeding up this\nlow-level element so massively, SFTs provide an extremely promising solution\nfor current and future gravitational wave data-analysis problems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11823v2",
    "published": "2025-02-17T14:15:49+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.HE",
      "astro-ph.IM",
      "physics.data-an"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2503.00015v1",
    "title": "The Quantum Ratio",
    "authors": [
      "Kenichi Konishi",
      "Hans-Thomas Elze"
    ],
    "abstract": "The concept of the Quantum Ratio was born out of the efforts to find a simple\nbut universal criterion if the center of mass (CM) of an isolated (microscopic\nor macroscopic) body behaves quantum mechanically or classically, and under\nwhich conditions. It is defined as the ratio between the quantum fluctuation\nrange, which is the spatial extension of the pure-state CM wave function, and\nthe linear size of the body (the space support of the internal, bound-state\nwave function). The two cases where the ratio is smaller than unity or much\nlarger than unity, roughly correspond to the body's CM behaving classically or\nquantum mechanically, respectively. An important notion following from the\nintroduction of quantum ratio is that the elementary particles (thus the\nelectron and the photon) are quantum mechanical. This is so even when the\nenvironment-induced decoherence turns them into a mixed state. Decoherence\n(mixed state) and classical state should not be identified. This simple\nobservation is further elaborated, by analyzing some atomic or molecular\nprocesses. It may have far-reaching implications on the way quantum mechanics\nworks, e.g., in biological systems.",
    "pdf_url": "http://arxiv.org/pdf/2503.00015v1",
    "published": "2025-02-17T14:15:36+00:00",
    "categories": [
      "quant-ph",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11822v1",
    "title": "Assessing the impacts of tradable credit schemes through agent-based simulation",
    "authors": [
      "Renming Liu",
      "Dimitrios Argyros",
      "Yu Jiang",
      "Moshe E. Ben-Akiva",
      "Ravi Seshadri",
      "Carlos Lima Azevedo"
    ],
    "abstract": "Tradable credit schemes (TCS) have been attracting interest from the\ntransportation research community as an appealing alternative to congestion\npricing, due to the advantages of revenue neutrality and equity. Nonetheless,\nexisting research has largely employed network and market equilibrium\napproaches with simplistic characterizations of transportation demand, supply,\ncredit market operations, and market behavior. Agent- and activity-based\nsimulation affords a natural means to comprehensively assess TCS by more\nrealistically modeling demand, supply, and individual market interactions. We\npropose an integrated simulation framework for modeling a TCS, and implements\nit within the state-of-the-art open-source urban simulation platform\nSimMobility, including: (a) a flexible TCS design that considers multiple trips\nand explicitly accounts for individual trading behaviors; (b) a simulation\nframework that captures the complex interactions between a TCS regulator, the\ntraveler, and the TCS market itself, with the flexibility to test future TCS\ndesigns and relevant mobility models; and (c) a set of simulation experiments\non a large mesoscopic multimodal network combined with a Bayesian Optimization\napproach for TCS optimal design. The experiment results indicate network and\nmarket performance to stabilize over the day-to-day process, showing the\nalignment of our agent-based simulation with the known theoretical properties\nof TCS. We confirm the efficiency of TCS in reducing congestion under the\nadopted market behavioral assumptions and open the door for simulating\ndifferent individual behaviors. We measure how TCS impacts differently the\nlocal network, heterogeneous users, the different travel behaviors, and how\ntesting different TCS designs can avoid negative market trading behaviors.",
    "pdf_url": "http://arxiv.org/pdf/2502.11822v1",
    "published": "2025-02-17T14:15:24+00:00",
    "categories": [
      "cs.GT",
      "cs.SE",
      "stat.ML"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12222v1",
    "title": "IMPACTX: Improving Model Performance by Appropriately predicting CorrecT eXplanations",
    "authors": [
      "Andrea Apicella",
      "Salvatore Giugliano",
      "Francesco IsgrÃ²",
      "Roberto Prevete"
    ],
    "abstract": "The eXplainable Artificial Intelligence (XAI) research predominantly\nconcentrates to provide explainations about AI model decisions, especially Deep\nLearning (DL) models. However, there is a growing interest in using XAI\ntechniques to automatically improve the performance of the AI systems\nthemselves.\n  This paper proposes IMPACTX, a novel approach that leverages XAI as a fully\nautomated attention mechanism, without requiring external knowledge or human\nfeedback. Experimental results show that IMPACTX has improved performance\nrespect to the standalone ML model by integrating an attention mechanism based\nan XAI method outputs during the model training. Furthermore, IMPACTX directly\nprovides proper feature attribution maps for the model's decisions, without\nrelying on external XAI methods during the inference process.\n  Our proposal is evaluated using three widely recognized DL models\n(EfficientNet-B2, MobileNet, and LeNet-5) along with three standard image\ndatasets: CIFAR-10, CIFAR-100, and STL-10. The results show that IMPACTX\nconsistently improves the performance of all the inspected DL models across all\nevaluated datasets, and it directly provides appropriate explanations for its\nresponses.",
    "pdf_url": "http://arxiv.org/pdf/2502.12222v1",
    "published": "2025-02-17T14:15:20+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11821v1",
    "title": "Unitary orthonormal bases of finite dimensional inclusions",
    "authors": [
      "Keshab Chandra Bakshi",
      "B V Rajarama Bhat"
    ],
    "abstract": "We study unitary orthonormal bases in the sense of Pimsner and Popa for\ninclusions $(\\mathcal{B}\\subseteq \\mathcal{A}, E),$ where $\\mathcal{A},\n\\mathcal{B}$ are finite dimensional von Neumann algebras and $E$ is a\nconditional expectation map from $\\mathcal{A}$ onto $\\mathcal{B}$. It is shown\nthat existence of such bases requires that the associated inclusion matrix\nsatisfies a spectral condition forcing dimension vectors to be Perron-Frobenius\neigenvectors and the conditional expectation map preserves the Markov trace.\nSubject to these conditions, explicit unitary orthonormal bases are constructed\nif either one of the algebras is abelian or simple. They generalize complex\nHadamard matrices, Weyl unitary bases, and a recent work of Crann et al which\ncorrespond to the special cases of $\\mathcal{A}$ being abelian, simple, and\ngeneral multi-matrix algebras respectively with $\\mathcal{B}$ being the algebra\nof complex numbers. For the first time $\\mathcal{B}$ is more general. As an\napplication of these results it is shown that if $(\\mathcal{B}\\subseteq\n\\mathcal{A}, E),$ admits a unitary orthonormal basis then the Connes-St{\\o}rmer\nrelative entropy $H(\\mathcal{A}_1|\\mathcal{A})$ equals the logarithm of the\nsquare of the norm of the inclusion matrix, where $\\mathcal{A}_1$ denotes the\nJones basic construction of the inclusion. As a further application, we prove\nthe existence of unitary orthonormal bases for a large class of depth 2\nsubfactors with abelian relative commutant.",
    "pdf_url": "http://arxiv.org/pdf/2502.11821v1",
    "published": "2025-02-17T14:14:55+00:00",
    "categories": [
      "math.OA",
      "cs.IT",
      "math-ph",
      "math.IT",
      "math.MP",
      "quant-ph",
      "46L08, 46L7, 15A63, 15B34, 81P45"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11820v2",
    "title": "A Diagnostic to Find and Help Combat Stochastic Positivity Issues -- with a Focus on Continuous Treatments",
    "authors": [
      "Katharina Ring",
      "Michael Schomaker"
    ],
    "abstract": "The positivity assumption is central in the identification of a causal\neffect, and especially the stochastic variant is an issue many applied\nresearchers face, yet is rarely discussed, especially in conjunction with\ncontinuous treatments or Modified Treatment Policies. One common recommendation\nfor dealing with a violation is to change the estimand. However, an applied\nresearcher is faced with two problems: First, how can she tell whether there is\na stochastic positivity violation given her estimand of interest, preferably\nwithout having to estimate a model first? Second, if she finds a problem with\nstochastic positivity, how should she change her estimand in order to arrive at\nan estimand which does not face the same issues? We suggest a novel diagnostic\nwhich allows the researcher to answer both questions by providing insights into\nhow well an estimation for a certain estimand can be made for each observation\nusing the data at hand. We provide a simulation study on the general behaviour\nof different Modified Treatment Policies (MTPs) at different levels of\nstochastic positivity violations and show how the diagnostic helps understand\nwhere bias is to be expected. We illustrate the application of our proposed\ndiagnostic in a pharmacoepidemiological study based on data from CHAPAS-3, a\ntrial comparing different treatment regimens for children living with HIV.",
    "pdf_url": "http://arxiv.org/pdf/2502.11820v2",
    "published": "2025-02-17T14:13:09+00:00",
    "categories": [
      "stat.AP",
      "stat.OT",
      "62D20"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11819v3",
    "title": "Entanglement and Effective Field Theories",
    "authors": [
      "Jorge Gamboa"
    ],
    "abstract": "We investigate the emergence of geometric phases in chiral transformations\nwithin gauge theories coupled to fermions. We begin by analyzing the Schwinger\nmodel in (1+1) dimensions, where chiral symmetry is explicitly modified due to\nthe dynamical generation of a photon mass. This model provides a controlled\nsetting to study the interplay between anomalies and vacuum structure.\n  Building on these insights, we extend our analysis to four-dimensional QED by\npromoting the vacuum angle $\\theta$ to a dynamical field $\\theta(x)$. This\ngeneralization allows us to explore how the axial anomaly and the presence of a\nnontrivial vacuum structure modify the conventional chiral symmetry.\n  Using the adiabatic approximation, we demonstrate that chiral transformations\nare modified by the emergence of a nontrivial Berry phase, which introduces a\ngeometric correction that depends on the topological properties of the vacuum.\nThis result suggests that chiral transformations acquire an effective gauge\nstructure in parameter space, in the presence of a dynamical $\\theta(x)$ field,\nleading to new physical consequences at low energies.\n  This framework establishes a novel connection between chiral symmetries,\nanomalies, and geometric phases, offering a unified approach to describing\ntopological effects, vacuum structure, and infrared modifications in gauge\ntheories with fermions. Moreover, our results suggest that Berry phases play a\ncrucial role in the infrared structure of QED, potentially providing a\nmechanism for regularizing infrared divergences in theories with axial\nanomalies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11819v3",
    "published": "2025-02-17T14:12:51+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.11818v1",
    "title": "Study of the $c\\bar{c}s\\bar{s}$ system in the chiral quark model",
    "authors": [
      "Xiaoyun Chen",
      "Yue Tan",
      "Xuejie Liu",
      "Jialun Ping"
    ],
    "abstract": "Recently, a charmonium $X(3960)$ in $B$ decays in the $D_s^+D_s^-$\ninvariant-mass spectrum is discovered by the LHCb Collaboration with the\nquantum number $J^{PC}=0^{++}$. Motivated by the discovery, in this work, we\nsystematically investigated the $c\\bar{c}s\\bar{s}$ tetraquark states with the\nquantum numbers $J^{PC}=0^{++}, 1^{++}, 1^{+-}, 2^{++}$ in the framework of the\nchiral quark model(CQM). In our calculations, we considered the meson-meson\nstructure of the tetraquark states and the diquark-antidiquark structure, as\nwell as the channel-coupling of all channels of these two configurations are\nconsidered in this work. For example, all color structures including color\nsinglet, hidden color channel, and the mixing of them are also taken into\naccount. The numerical results indicates that no bound states were found in our\nmodel. But there exist several resonant states by using the stabilization\nmethod, the real scaling method (RSM) so called. Among these states, the\n$0^{++}$ resonant state with mass 3927 MeV matches very well with the energy of\nthe newly discovered exotic state $X(3960)$ reported by the LHCb collaboration.\nAs a result, our calculations suggest that $X(3960)$ can be interpreted as a\n$c\\bar{c}s\\bar{s}$ tetraquark state with quantum number $J^{PC}=0^{++}$. Apart\nform that, we also find several resonance states with mass 4179 MeV, 4376 MeV\nwith $0^{++}$. For $1^{++}$, there is likely one resonance state in the energy\nrange of 4310$\\sim$4336 MeV, along with two resonance states at the energy of\n4395 MeV and 4687 MeV, respectively. Besides, two resonance states at 4300 MeV\nand 4355 MeV for $1^{+-}$, as well as one state at 4788 MeV for $2^{++}$, are\nfound, which are likely to be new exotic states. More experimental data is\nneeded to confirm the existence of these resonance states.",
    "pdf_url": "http://arxiv.org/pdf/2502.11818v1",
    "published": "2025-02-17T14:11:52+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11817v1",
    "title": "AAKT: Enhancing Knowledge Tracing with Alternate Autoregressive Modeling",
    "authors": [
      "Hao Zhou",
      "Wenge Rong",
      "Jianfei Zhang",
      "Qing Sun",
      "Yuanxin Ouyang",
      "Zhang Xiong"
    ],
    "abstract": "Knowledge Tracing (KT) aims to predict students' future performances based on\ntheir former exercises and additional information in educational settings. KT\nhas received significant attention since it facilitates personalized\nexperiences in educational situations. Simultaneously, the autoregressive\nmodeling on the sequence of former exercises has been proven effective for this\ntask. One of the primary challenges in autoregressive modeling for Knowledge\nTracing is effectively representing the anterior (pre-response) and posterior\n(post-response) states of learners across exercises. Existing methods often\nemploy complex model architectures to update learner states using question and\nresponse records. In this study, we propose a novel perspective on knowledge\ntracing task by treating it as a generative process, consistent with the\nprinciples of autoregressive models. We demonstrate that knowledge states can\nbe directly represented through autoregressive encodings on a question-response\nalternate sequence, where model generate the most probable representation in\nhidden state space by analyzing history interactions. This approach underpins\nour framework, termed Alternate Autoregressive Knowledge Tracing (AAKT).\nAdditionally, we incorporate supplementary educational information, such as\nquestion-related skills, into our framework through an auxiliary task, and\ninclude extra exercise details, like response time, as additional inputs. Our\nproposed framework is implemented using advanced autoregressive technologies\nfrom Natural Language Generation (NLG) for both training and prediction.\nEmpirical evaluations on four real-world KT datasets indicate that AAKT\nconsistently outperforms all baseline models in terms of AUC, ACC, and RMSE.\nFurthermore, extensive ablation studies and visualized analysis validate the\neffectiveness of key components in AAKT.",
    "pdf_url": "http://arxiv.org/pdf/2502.11817v1",
    "published": "2025-02-17T14:09:51+00:00",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11816v1",
    "title": "IMTS-Mixer: Mixer-Networks for Irregular Multivariate Time Series Forecasting",
    "authors": [
      "Christian KlÃ¶tergens",
      "Tim Dernedde",
      "Lars Schmidt-Thieme"
    ],
    "abstract": "Forecasting Irregular Multivariate Time Series (IMTS) has recently emerged as\na distinct research field, necessitating specialized models to address its\nunique challenges. While most forecasting literature assumes regularly spaced\nobservations without missing values, many real-world datasets - particularly in\nhealthcare, climate research, and biomechanics - violate these assumptions.\nTime Series (TS)-mixer models have achieved remarkable success in regular\nmultivariate time series forecasting. However, they remain unexplored for IMTS\ndue to their requirement for complete and evenly spaced observations. To bridge\nthis gap, we introduce IMTS-Mixer, a novel forecasting architecture designed\nspecifically for IMTS. Our approach retains the core principles of TS mixer\nmodels while introducing innovative methods to transform IMTS into fixed-size\nmatrix representations, enabling their seamless integration with mixer modules.\nWe evaluate IMTS-Mixer on a benchmark of four real-world datasets from various\ndomains. Our results demonstrate that IMTS-Mixer establishes a new\nstate-of-the-art in forecasting accuracy while also improving computational\nefficiency.",
    "pdf_url": "http://arxiv.org/pdf/2502.11816v1",
    "published": "2025-02-17T14:06:36+00:00",
    "categories": [
      "cs.LG",
      "I.5"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11815v1",
    "title": "A purely analytic derivation of Bonnet surfaces",
    "authors": [
      "Robert Conte",
      "A. Michel Grundland"
    ],
    "abstract": "Bonnet has characterized his surfaces by a geometric condition. What is done\nhere is a characterization of the same surfaces by two analytic conditions: (i)\nthe mean curvature $H$ of a surface in $\\mathbb{R}^3$ should admit a reduction\nto an ordinary differential equation; (ii) this latter equation should possess\nthe Painlev\\'e property.",
    "pdf_url": "http://arxiv.org/pdf/2502.11815v1",
    "published": "2025-02-17T14:05:38+00:00",
    "categories": [
      "math.DG",
      "math-ph",
      "math.MP",
      "33E17, 34Mxx, 35A20, 35Q99"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11814v1",
    "title": "An Efficiently Computable Lower Bound for the Independence Number of Hypergraphs",
    "authors": [
      "Marco Aldi",
      "Thor Gabrielsen",
      "Daniele Grandini",
      "Joy Harris",
      "Kyle Kelley"
    ],
    "abstract": "We introduce a lower bound for the independence number of an arbitrary\n$k$-uniform hypergraph that only depends on the number of vertices and number\nof edges of the hypergraph.",
    "pdf_url": "http://arxiv.org/pdf/2502.11814v1",
    "published": "2025-02-17T14:04:11+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11813v3",
    "title": "Gravitational lensing by charged black hole with global monopole in the strong field limit",
    "authors": [
      "Yi-Ling Lan",
      "Yun-Feng Qu",
      "Jiawei Hu",
      "Hongwei Yu"
    ],
    "abstract": "We investigate gravitational lensing near a charged black hole with a global\nmonopole in the strong field regime, focusing on the combined effects of the\nglobal monopole and black hole charge on key observables in gravitational\nlensing both analytically and numerically. Our results reveal that the\ndependence of the angular separation on charge is intricately tied to the\ndeficit angle caused by the global monopole. In particular, we identify three\ncritical values of the global monopole parameter that determine whether the\nangular separation increases monotonically, decreases monotonically, or\nexhibits extrema as the charge varies. A similar complex dependence is found\nfor the flux ratio as a function of the deficit angle, and for the\nmagnification of the first relativistic image as a function of charge. These\nbehaviors contrast sharply with the monotonic changes observed in the absence\nof either a global monopole or charge. Our findings highlight that the effects\nof the charge and global monopole on gravitational lensing cannot be described\nas simple additive contributions. Instead, their combined effects lead to a\nrich and interdependent behavior that enhances our understanding of\nstrong-field gravitational lensing. While the charge and global monopole are\nexpected to be small in typical astrophysical contexts, the results presented\nhere could be experimentally explored in analog gravity systems, where these\nparameters are not constrained. This opens the door to potential experimental\nverification of the phenomena predicted in this study.",
    "pdf_url": "http://arxiv.org/pdf/2502.11813v3",
    "published": "2025-02-17T13:59:47+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11812v2",
    "title": "Towards Understanding Fine-Tuning Mechanisms of LLMs via Circuit Analysis",
    "authors": [
      "Xu Wang",
      "Yan Hu",
      "Wenyu Du",
      "Reynold Cheng",
      "Benyou Wang",
      "Difan Zou"
    ],
    "abstract": "Fine-tuning significantly improves the performance of Large Language Models\n(LLMs), yet its underlying mechanisms remain poorly understood. This paper aims\nto provide an in-depth interpretation of the fine-tuning process through\ncircuit analysis, a popular tool in Mechanistic Interpretability (MI). Unlike\nprevious studies (Prakash et al. 2024; Chhabra et al. 2024) that focus on tasks\nwhere pre-trained models already perform well, we develop a set of mathematical\ntasks where fine-tuning yields substantial performance gains, which are closer\nto the practical setting. In our experiments, we identify circuits at various\ncheckpoints during fine-tuning and examine the interplay between circuit\nanalysis, fine-tuning methods, and task complexities. First, we find that while\ncircuits maintain high node similarity before and after fine-tuning, their\nedges undergo significant changes, in contrast to prior work that shows\ncircuits only add some additional components after fine-tuning. Based on these\nobservations, we develop a circuit-aware Low-Rank Adaptation (LoRA) method,\nwhich assigns ranks to layers based on edge changes in the circuits.\nExperimental results demonstrate that our circuit-based LoRA algorithm achieves\nan average performance improvement of 2.46% over standard LoRA with similar\nparameter sizes. Furthermore, we explore how combining circuits from subtasks\ncan enhance fine-tuning in compositional tasks, providing new insights into the\ndesign of such tasks and deepening the understanding of circuit dynamics and\nfine-tuning mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11812v2",
    "published": "2025-02-17T13:59:41+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11811v4",
    "title": "FineFilter: A Fine-grained Noise Filtering Mechanism for Retrieval-Augmented Large Language Models",
    "authors": [
      "Qianchi Zhang",
      "Hainan Zhang",
      "Liang Pang",
      "Ziwei Wang",
      "Hongwei Zheng",
      "Yongxin Tong",
      "Zhiming Zheng"
    ],
    "abstract": "Retrieved documents containing noise will hinder Retrieval-Augmented\nGeneration (RAG) from detecting answer clues, necessitating noise filtering\nmechanisms to enhance accuracy. Existing methods use reranking or summarization\nto identify the most relevant sentences, but directly and accurately locating\nanswer clues from these large-scale and complex documents remains challenging.\nUnlike these document-level operations, we treat noise filtering as a\nsentence-level MinMax optimization problem: first identifying potential clues\nfrom multiple documents, then ranking them by relevance, and finally retaining\nthe minimum number of clues through truncation. In this paper, we propose\nFineFilter, a novel fine-grained noise filtering mechanism for RAG, consisting\nof a clue extractor, a reranker, and a truncator. We optimize each module to\ntackle complex reasoning challenges: (1) The clue extractor first uses\nsentences containing the answer and similar ones as fine-tuning targets, aiming\nto extract sufficient potential clues; (2) The reranker is trained to\nprioritize effective clues based on the real feedback from the generation\nmodule, with clues capable of generating correct answers as positive samples\nand others as negative; (3) The truncator takes the minimum number of clues\nneeded to answer the question (truncation point) as fine-tuning targets, and\nperforms truncation on the reranked clues to achieve fine-grained noise\nfiltering. Experiments on three QA datasets demonstrate that FineFilter\nsignificantly improves QA performance over baselines on both LLaMA3 and\nMistral. Further analysis confirms its effectiveness in complex reasoning,\nrobustness to unreliable retrieval, and generalization to different scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.11811v4",
    "published": "2025-02-17T13:55:42+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11810v1",
    "title": "Exploring Novel 2D Analogues of Goldene: Electronic, Mechanical, and Optical Properties of Silverene and Copperene",
    "authors": [
      "Emanuel J. A. dos Santos",
      "Rodrigo A. F. Alves",
      "Alexandre C. Dias",
      "Marcelo L. Pereira Junior",
      "Douglas S. GalvÃ£o",
      "Luiz A. Ribeiro Junior"
    ],
    "abstract": "Two-dimensional (2D) materials have garnered significant attention due to\ntheir unique properties and broad application potential. Building on the\nsuccess of goldene, a monolayer lattice of gold atoms, we explore its proposed\nsilver and copper analogs, silverene and copperene, using density functional\ntheory calculations. Our findings reveal that silverene and copperene are\nenergetically stable, with formation energies of -2.3 eV/atom and -3.1 eV/atom,\nclosely matching goldene's -2.9 eV/atom. Phonon dispersion and ab initio\nmolecular dynamics simulations confirm their structural and dynamical stability\nat room temperature, showing no bond breaking or structural reconfiguration.\nMechanical analyses indicate isotropy, with Young's moduli of 73 N/m, 44 N/m,\nand 59 N/m for goldene, silverene, and copperene, respectively, alongside\nPoisson's ratios of 0.46, 0.42, and 0.41. These results suggest comparable\nrigidity and deformation characteristics. Electronic band structure analysis\nhighlights their metallic nature, with variations in the band profiles at\nnegative energy levels. Despite their metallic character, these materials\nexhibit optical properties akin to semiconductors, pointing to potential\napplications in optoelectronics.",
    "pdf_url": "http://arxiv.org/pdf/2502.11810v1",
    "published": "2025-02-17T13:54:28+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "00-xx",
      "J.2; I.6"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11809v4",
    "title": "Geometric Origins of Bias in Deep Neural Networks: A Human Visual System Perspective",
    "authors": [
      "Yanbiao Ma",
      "Bowei Liu",
      "Andi Zhang"
    ],
    "abstract": "Bias formation in deep neural networks (DNNs) remains a critical yet poorly\nunderstood challenge, influencing both fairness and reliability in artificial\nintelligence systems. Inspired by the human visual system, which decouples\nobject manifolds through hierarchical processing to achieve object recognition,\nwe propose a geometric analysis framework linking the geometric complexity of\nclass-specific perceptual manifolds in DNNs to model bias. Our findings reveal\nthat differences in geometric complexity can lead to varying recognition\ncapabilities across categories, introducing biases. To support this analysis,\nwe present the Perceptual-Manifold-Geometry library, designed for calculating\nthe geometric properties of perceptual manifolds. The toolkit has been\ndownloaded and installed over 4,500 times. This work provides a novel geometric\nperspective on bias formation in modern learning systems and lays a theoretical\nfoundation for developing more equitable and robust artificial intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2502.11809v4",
    "published": "2025-02-17T13:54:02+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11808v1",
    "title": "On the $1$-cohomology of $\\mathrm{SL}(n,{\\mathbb K})$ on the dual of its adjoint module",
    "authors": [
      "Ilaria Cardinali",
      "Luca Giuzzi",
      "Antonio Pasini"
    ],
    "abstract": "Given a field $\\mathbb K$, for any $n\\geq 3$ the first cohomology group\n$H^1(G_n,A^*_n)$ of the special linear group $G_n = \\mathrm{SL}(n,{\\mathbb K})$\nover the dual $A^*_n$ of its adjoint module $A_n$ is isomorphic to the space\n$\\mathrm{Der}({\\mathbb K})$ of the derivations of $\\mathbb K$, except possibly\nwhen $|{\\mathbb K}| \\in \\{2, 4\\}$ and $n$ is even. This fact is stated by S.\nSmith and H. V\\\"{o}lklein in their paper \"A geometric presentation for the\nadjont module of $\\mathrm{SL}_3(k)$\" (J. Algebra 127 (1989), 127--138). They\nclaim that when $|{\\mathbb K}| > 9$ this fact follows from the main result of\nV\\\"{o}lklein's paper \"The 1-cohomology of the adjoint module of a Chevalley\ngroup\" (Forum Math. 1 (1989), 1--13), but say nothing that can help the reader\nto deduce it from that result. When $|{\\mathbb K}| \\leq 9$ they obtain the\nisomorphism $H^1(G_n,A^*_n) \\cong \\mathrm{Der}({\\mathbb K})$ by means of other\nresults from homological algebra, which however miss the case $|{\\mathbb K}|\n\\in\\{2, 4\\}$ with $n $ even. In the present paper we shall provide a\nstraightforward proof of the isomorphism $H^1(G_n,A^*_n) \\cong\n\\mathrm{Der}({\\mathbb K})$ under the hypothesis $n > 3$. Our proof also covers\nthe above mentioned missing case.",
    "pdf_url": "http://arxiv.org/pdf/2502.11808v1",
    "published": "2025-02-17T13:53:04+00:00",
    "categories": [
      "math.GR",
      "20G10, 20J06"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11807v1",
    "title": "Quark Transverse Spin-Momentum Correlation of the Nucleon from Lattice QCD: The Boer-Mulders Function",
    "authors": [
      "Lingquan Ma",
      "Jun Hua",
      "Andreas SchÃ¤fer",
      "Hai-Tao Shu",
      "Yushan Su",
      "Peng Sun",
      "Lisa Walter",
      "Wei Wang",
      "Xiaonu Xiong",
      "Yi-Bo Yang",
      "Jian-Hui Zhang",
      "Qi-An Zhang"
    ],
    "abstract": "We present the first lattice QCD calculation of the quark transverse\nspin-momentum correlation, i.e., the naive time-reversal-odd Boer-Mulders\nfunction, of the nucleon, using large-momentum effective theory (LaMET). The\ncalculation is carried out on an ensemble with lattice spacing $a=0.098$ fm and\npion mass $338$ MeV, at various proton momenta up to $2.11$ GeV. We have\nimplemented perturbative matching up to the next-to-next-to-leading order\ntogether with a renormalization-group resummation improvement. The result\nexhibits a decay behavior with increasing transverse separation $b_\\perp$. We\nalso compare the results in the nucleon and pion.",
    "pdf_url": "http://arxiv.org/pdf/2502.11807v1",
    "published": "2025-02-17T13:52:05+00:00",
    "categories": [
      "hep-lat",
      "hep-ph"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2502.11806v2",
    "title": "Exploring Translation Mechanism of Large Language Models",
    "authors": [
      "Hongbin Zhang",
      "Kehai Chen",
      "Xuefeng Bai",
      "Xiucheng Li",
      "Yang Xiang",
      "Min Zhang"
    ],
    "abstract": "Large language models (LLMs) have succeeded remarkably in multilingual\ntranslation tasks. However, the inherent translation mechanisms of LLMs remain\npoorly understood, largely due to sophisticated architectures and vast\nparameter scales. In response to this issue, this study explores the\ntranslation mechanism of LLM from the perspective of computational components\n(e.g., attention heads and MLPs). Path patching is utilized to explore causal\nrelationships between components, detecting those crucial for translation tasks\nand subsequently analyzing their behavioral patterns in human-interpretable\nterms. Comprehensive analysis reveals that translation is predominantly\nfacilitated by a sparse subset of specialized attention heads (less than 5\\%),\nwhich extract source language, indicator, and positional features. MLPs\nsubsequently integrate and process these features by transiting towards\nEnglish-centric latent representations. Notably, building on the above\nfindings, targeted fine-tuning of only 64 heads achieves translation\nimprovement comparable to full-parameter tuning while preserving general\ncapabilities.",
    "pdf_url": "http://arxiv.org/pdf/2502.11806v2",
    "published": "2025-02-17T13:50:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11805v1",
    "title": "Empirical plunge profiles of time-frequency localization operators",
    "authors": [
      "Simon Halvdansson"
    ],
    "abstract": "For time-frequency localization operators with symbol $R\\Omega$, we work out\nthe exact large $R$ eigenvalue behavior for rotationally invariant $\\Omega$ and\nconjecture that the same relation holds for all scaled symbols $R \\Omega$ as\nlong as the window is the standard Gaussian. Specifically, we conjecture that\nthe $k$-th eigenvalue of the localization operator with symbol $R\\Omega$\nconverges to $\\frac{1}{2}\\operatorname{erfc}\\big(\n\\sqrt{2\\pi}\\frac{k-|R\\Omega|}{|\\partial R\\Omega|} \\big)$ as $R \\to \\infty$. To\nsupport the conjecture, we compute the eigenvalues of discrete frame\nmultipliers with various symbols using LTFAT and find that they agree with the\nbehavior of the conjecture to a large degree.",
    "pdf_url": "http://arxiv.org/pdf/2502.11805v1",
    "published": "2025-02-17T13:48:59+00:00",
    "categories": [
      "math.FA",
      "math.CA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11804v4",
    "title": "Identification of Stochastic Gravitational Wave Backgrounds from Cosmic String Using Machine Learning",
    "authors": [
      "Xianghe Ma",
      "Borui Wang",
      "Nan Yang",
      "Jin Li",
      "Brendan McCane",
      "Mengfei Sun",
      "Jie Wu",
      "Minghui Zhang",
      "Yan Meng"
    ],
    "abstract": "Cosmic strings play a crucial role in enhancing our understanding of the\nfundamental structure and evolution of the universe, unifying our knowledge of\ncosmology, and potentially unveiling new physical laws and phenomena. The\nadvent and operation of space-based detectors provide an important opportunity\nfor detecting stochastic gravitational wave backgrounds (SGWB) generated by\ncosmic strings. However, the intricate nature of SGWB poses a formidable\nchallenge in distinguishing its signal from the complex noise by some\ntraditional methods. Therefore, we attempt to identify SGWB based on machine\nlearning. Our findings show that the joint detection of LISA and Taiji\nsignificantly outperforms individual detectors, and even in the presence of\nnumerous low signal-to-noise ratio(SNR) signals, the identification accuracy\nremains exceptionally high with 95%. Although our discussion is based solely on\nsimulated data, the relevant methods can provide data-driven analytical\ncapabilities for future observations of SGWB.",
    "pdf_url": "http://arxiv.org/pdf/2502.11804v4",
    "published": "2025-02-17T13:48:35+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11803v2",
    "title": "High-Harmonic Generation in a Crystal Driven by Quantum Light",
    "authors": [
      "Rasmus Vesterager Gothelf",
      "Christian Saugbjerg Lange",
      "Lars Bojer Madsen"
    ],
    "abstract": "We study intraband high-harmonic generation (HHG) in a crystal driven by\nquantum light. Previous theoretical studies have developed a framework based on\ncoherent state expansions in terms of P distributions to consider nonclassical\ndriving fields for HHG in atoms. Here, we adapt this framework to the context\nof solids and consider an intraband model of ZnO. We investigate the effect of\nthe quantum optical nature of the driving field on the harmonic spectra\nincluding the cutoff and the intensity scaling of the harmonics with driving\nfield intensity. Based on analytical calculations in the Floquet limit, we\nexplain why driving with thermal light or bright-squeezed vacuum (BSV) produces\na much higher cutoff than when driving with fields described by coherent or\nFock states. Further, we derive an expression for the generated time-dependent\nelectric field and its fluctuations and find that it inherits characteristics\nof the driving field. Finally, we discuss the limitations of an approximative\npositive P representation, which is introduced to be able to reduce the\nnumerical complexity for Fock and BSV driving fields.",
    "pdf_url": "http://arxiv.org/pdf/2502.11803v2",
    "published": "2025-02-17T13:48:14+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11802v1",
    "title": "The Lamm-RiviÃ¨re system II: energy identity",
    "authors": [
      "Chang-Yu Guo",
      "Wen-Juan Qi",
      "Zhao-Min Sun",
      "Changyou Wang"
    ],
    "abstract": "In this paper, we establish an angular energy quantization for the following\nfourth order inhomogeneous Lamm-Rivi\\`ere system $$\n\\Delta^2u=\\Delta(V\\cdot\\nabla u)+\\text{div}(w\\nabla u)+W\\cdot\\nabla u+f $$ in\ndimension four, with an inhomogeneous term $f\\in L\\log L$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11802v1",
    "published": "2025-02-17T13:48:11+00:00",
    "categories": [
      "math.AP",
      "math.DG"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11801v2",
    "title": "3D Gaussian Inpainting with Depth-Guided Cross-View Consistency",
    "authors": [
      "Sheng-Yu Huang",
      "Zi-Ting Chou",
      "Yu-Chiang Frank Wang"
    ],
    "abstract": "When performing 3D inpainting using novel-view rendering methods like Neural\nRadiance Field (NeRF) or 3D Gaussian Splatting (3DGS), how to achieve texture\nand geometry consistency across camera views has been a challenge. In this\npaper, we propose a framework of 3D Gaussian Inpainting with Depth-Guided\nCross-View Consistency (3DGIC) for cross-view consistent 3D inpainting. Guided\nby the rendered depth information from each training view, our 3DGIC exploits\nbackground pixels visible across different views for updating the inpainting\nmask, allowing us to refine the 3DGS for inpainting purposes.Through extensive\nexperiments on benchmark datasets, we confirm that our 3DGIC outperforms\ncurrent state-of-the-art 3D inpainting methods quantitatively and\nqualitatively.",
    "pdf_url": "http://arxiv.org/pdf/2502.11801v2",
    "published": "2025-02-17T13:46:47+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11800v1",
    "title": "Residual Learning towards High-fidelity Vehicle Dynamics Modeling with Transformer",
    "authors": [
      "Jinyu Miao",
      "Rujun Yan",
      "Bowei Zhang",
      "Tuopu Wen",
      "Kun Jiang",
      "Mengmeng Yang",
      "Jin Huang",
      "Zhihua Zhong",
      "Diange Yang"
    ],
    "abstract": "The vehicle dynamics model serves as a vital component of autonomous driving\nsystems, as it describes the temporal changes in vehicle state. In a long\nperiod, researchers have made significant endeavors to accurately model vehicle\ndynamics. Traditional physics-based methods employ mathematical formulae to\nmodel vehicle dynamics, but they are unable to adequately describe complex\nvehicle systems due to the simplifications they entail. Recent advancements in\ndeep learning-based methods have addressed this limitation by directly\nregressing vehicle dynamics. However, the performance and generalization\ncapabilities still require further enhancement. In this letter, we address\nthese problems by proposing a vehicle dynamics correction system that leverages\ndeep neural networks to correct the state residuals of a physical model instead\nof directly estimating the states. This system greatly reduces the difficulty\nof network learning and thus improves the estimation accuracy of vehicle\ndynamics. Furthermore, we have developed a novel Transformer-based dynamics\nresidual correction network, DyTR. This network implicitly represents state\nresiduals as high-dimensional queries, and iteratively updates the estimated\nresiduals by interacting with dynamics state features. The experiments in\nsimulations demonstrate the proposed system works much better than physics\nmodel, and our proposed DyTR model achieves the best performances on dynamics\nstate residual correction task, reducing the state prediction errors of a\nsimple 3 DoF vehicle model by an average of 92.3% and 59.9% in two dataset,\nrespectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.11800v1",
    "published": "2025-02-17T13:43:52+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11799v3",
    "title": "Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning",
    "authors": [
      "Peiying Yu",
      "Guoxin Chen",
      "Jingjing Wang"
    ],
    "abstract": "Despite the remarkable capabilities of large language models (LLMs) in\nvarious reasoning tasks, they still struggle with table reasoning tasks,\nparticularly in maintaining consistency throughout multi-step reasoning\nprocesses. While existing approaches have explored various decomposition\nstrategies, they often lack effective mechanisms to identify and correct errors\nin intermediate reasoning steps, leading to cascading error propagation. To\naddress these issues, we propose Table-Critic, a novel multi-agent framework\nthat facilitates collaborative criticism and iterative refinement of the\nreasoning process until convergence to correct solutions. Our framework\nconsists of four specialized agents: a Judge for error identification, a Critic\nfor comprehensive critiques, a Refiner for process improvement, and a Curator\nfor pattern distillation. To effectively deal with diverse and unpredictable\nerror types, we introduce a self-evolving template tree that systematically\naccumulates critique knowledge through experience-driven learning and guides\nfuture reflections. Extensive experiments have demonstrated that Table-Critic\nachieves substantial improvements over existing methods, achieving superior\naccuracy and error correction rates while maintaining computational efficiency\nand lower solution degradation rate.",
    "pdf_url": "http://arxiv.org/pdf/2502.11799v3",
    "published": "2025-02-17T13:42:12+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11798v2",
    "title": "BackdoorDM: A Comprehensive Benchmark for Backdoor Learning on Diffusion Model",
    "authors": [
      "Weilin Lin",
      "Nanjun Zhou",
      "Yanyun Wang",
      "Jianze Li",
      "Hui Xiong",
      "Li Liu"
    ],
    "abstract": "Backdoor learning is a critical research topic for understanding the\nvulnerabilities of deep neural networks. While the diffusion model (DM) has\nbeen broadly deployed in public over the past few years, the understanding of\nits backdoor vulnerability is still in its infancy compared to the extensive\nstudies in discriminative models. Recently, many different backdoor attack and\ndefense methods have been proposed for DMs, but a comprehensive benchmark for\nbackdoor learning on DMs is still lacking. This absence makes it difficult to\nconduct fair comparisons and thorough evaluations of the existing approaches,\nthus hindering future research progress. To address this issue, we propose\n\\textit{BackdoorDM}, the first comprehensive benchmark designed for backdoor\nlearning on DMs. It comprises nine state-of-the-art (SOTA) attack methods, four\nSOTA defense strategies, and three useful visualization analysis tools. We\nfirst systematically classify and formulate the existing literature in a\nunified framework, focusing on three different backdoor attack types and five\nbackdoor target types, which are restricted to a single type in discriminative\nmodels. Then, we systematically summarize the evaluation metrics for each type\nand propose a unified backdoor evaluation method based on multimodal large\nlanguage model (MLLM). Finally, we conduct a comprehensive evaluation and\nhighlight several important conclusions. We believe that BackdoorDM will help\novercome current barriers and contribute to building a trustworthy artificial\nintelligence generated content (AIGC) community. The codes are released in\nhttps://github.com/linweiii/BackdoorDM.",
    "pdf_url": "http://arxiv.org/pdf/2502.11798v2",
    "published": "2025-02-17T13:39:05+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11797v1",
    "title": "Streamlining Equal Shares",
    "authors": [
      "Sonja Kraiczy",
      "Isaac Robinson",
      "Edith Elkind"
    ],
    "abstract": "Participatory budgeting (PB) is a form of citizen participation that allows\ncitizens to decide how public funds are spent. Through an election, citizens\nexpress their preferences on various projects (spending proposals). A voting\nmechanism then determines which projects will be approved. The Method of Equal\nShares (MES) is the state of the art algorithm for a proportional, voting based\napproach to participatory budgeting and has been implemented in cities across\nPoland and Switzerland. A significant drawback of MES is that it is not\n\\textit{exhaustive} meaning that it often leaves a portion of the budget\nunspent that could be used to fund additional projects. To address this, in\npractice the algorithm is combined with a completion heuristic - most often the\n``add-one\" heuristic which artificially increases the budget until a\nheuristically chosen threshold. This heuristic is computationally inefficient\nand will become computationally impractical if PB is employed on a larger\nscale. We propose the more efficient \\textsc{add-opt} heuristic for Exact Equal\nShares (EES), a variation of MES that is known to retain many of its desirable\nproperties. We solve the problem of identifying the next budget for which the\noutcome for EES changes in $O(mn)$ time for cardinal utilities and $O(m^2n)$\ntime for uniform utilities, where $m$ is the number of projects and $n$ is the\nnumber of voters. Our solution to this problem inspires the efficient\n\\textsc{add-opt} heuristic which bypasses the need to search through each\nintermediary budget. We perform comprehensive experiments on real-word PB\ninstances from Pabulib and show that completed EES outcomes usually match the\nproportion of budget spent by completed MES outcomes. Furthermore, the\n\\textsc{add-opt} heuristic matches the proportion of budget spend by add-one\nfor EES.",
    "pdf_url": "http://arxiv.org/pdf/2502.11797v1",
    "published": "2025-02-17T13:36:25+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11796v3",
    "title": "Finite-time blowup of a Brownian particle in a repulsive potential",
    "authors": [
      "P. L. Krapivsky",
      "Baruch Meerson"
    ],
    "abstract": "We consider a Brownian particle performing an overdamped motion in a\npower-law repulsive potential. If the potential grows with the distance faster\nthan quadratically, the particle escapes to infinity in a finite time. We\ndetermine the average blowup time and study the probability distribution of the\nblowup time. In particular, we show that the long-time tail of this probability\ndistribution decays purely exponentially, while the short-time tail exhibits an\nessential singularity. These qualitative features turn out to be quite\nuniversal, as they occur for all rapidly growing power-law potentials in\narbitrary spatial dimensions. The quartic potential is especially tractable,\nand we analyze it in more detail.",
    "pdf_url": "http://arxiv.org/pdf/2502.11796v3",
    "published": "2025-02-17T13:35:00+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "math-ph",
      "math.MP",
      "math.PR"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2502.11795v1",
    "title": "Morita theory for quantales",
    "authors": [
      "Bachuki Mesablishvili"
    ],
    "abstract": "Morita theory for quantales is developed. The main result of the paper is a\ncharacterization of those quantaloids (categories enriched in the symmetric\nmonoidal closed category of sup-lattices) that are equivalent to modular\ncategories over quantales. Based on this characterization, necessary and\nsufficient conditions are derived for two quantales to be Morita-equivalent, i.\ne. have equivalent module categories. As an application, it is shown that the\ncategory of internal sup-lattices in a Grothendieck topos is equivalent to the\nmodule category over a suitable chosen ordinary quantale.",
    "pdf_url": "http://arxiv.org/pdf/2502.11795v1",
    "published": "2025-02-17T13:34:29+00:00",
    "categories": [
      "math.CT",
      "math.QA",
      "18B25, 18C15, 18C20, 18D20, 18E08, 18F10, 18F75, 18M05"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11794v1",
    "title": "Improving electron tomography of mesoporous silica by Ga intrusion",
    "authors": [
      "Alexander Kichigin",
      "Johannes BÃ¶hmer",
      "Moritz Buwen",
      "Benjamin Apeleo Zubiri",
      "Mingjian Wu",
      "Johannes Will",
      "Dominik Drobek",
      "Alexander GÃ¶tz",
      "Nora Vorlaufer",
      "Jakob SÃ¶llner",
      "Matthias Thommes",
      "Peter Felfer",
      "Thomas Przybilla",
      "Erdmann Spiecker"
    ],
    "abstract": "Electron tomography (ET) offers nanoscale 3D characterization of mesoporous\nmaterials but is often limited by their low scattering contrast. Here, we\nintroduce a gallium (Ga) intrusion strategy for mesoporous silica that\ndramatically improves imaging contrast - a key benefit that enables more\naccurate 3D reconstructions. By infiltrating Ga through a modified mercury\nintrusion porosimetry process, the high-angle annular dark-field (HAADF) STEM\nsignal is enhanced by 5 times, resulting in a 34% improvement in reconstruction\nresolution and a 49% enhancement in interface sharpness. In addition, the\nincreased sample conductivity facilitates focused ion beam (FIB) milling by\nminimizing charging effects and reducing drift. This approach enables precise\nsegmentation and quantitative analysis of pore connectivity and size\ndistribution, thereby extending the applicability of ET to light-element\nnon-conductive materials and advancing structure-property characterization of\ncomplex porous systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11794v1",
    "published": "2025-02-17T13:33:21+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.11793v2",
    "title": "Competition between terahertz magnetoelectric and NÃ©el spin-orbit torque driven spin dynamics in metallic antiferromagnets",
    "authors": [
      "R. M. Dubrovin",
      "A. V. Kimel",
      "A. K. Zvezdin"
    ],
    "abstract": "Although magnetoelectric effects in metals are usually neglected, assuming\nthat applied electric fields are screened by free charge carriers, the skin\ndepth, defining the penetration depth of the fields, is non-zero and for THz\nelectric fields typically reaches 400 nm. Hence, if the thickness of an\nantiferromagnetic film is of the order of tens of nm, electric field induced\neffects cannot be neglected. Here, we theoretically study the THz electric\nfield induced spin dynamics in the metallic antiferromagnet\n$\\mathrm{Mn}_{2}\\mathrm{Au}$, whose spin arrangements allow it to exhibit a\nlinear magnetoelectric effect. We show that the THz magnetoelectric torque in\nmetallic antiferromagnets is proportional to the time derivative of the\npolarization induced by the THz electric field. Our simulations reveal that the\nmagnetoelectric driven spin dynamics is indeed not negligible, and for a fair\nexplanation of previously published experimental results in\n$\\mathrm{Mn}_{2}\\mathrm{Au}$ competition between THz magnetoelectric and N\\'eel\nspin-orbit torques must be taken into account. Thus, it is shown that even in\nmetallic antiferromagnets the THz magnetoelectric effect on spins can be strong\nand thus cannot be neglected.",
    "pdf_url": "http://arxiv.org/pdf/2502.11793v2",
    "published": "2025-02-17T13:33:17+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11792v1",
    "title": "Software Process as a Service: Towards A Software Process Ecosystem",
    "authors": [
      "Oliver Greulich",
      "Christoph Knieke",
      "Bassel Rafie",
      "Andreas Rausch",
      "Marco Kuhrmann"
    ],
    "abstract": "In large-scale projects operated in regulated environments, standard\ndevelopment processes are employed to meet strict compliance demands. Since\nsuch processes are usually complex, providing process users with access to\ntheir required process, which should be tailored to a project's needs is a\nchallenging task that requires proper tool support. In this paper, we present a\nprocess ecosystem in which software processes are provided as web-based\nservices. We outline the general idea, describe the modeling approach, and we\nillustrate the concept's realization using a proof-of-concept case based on a\nlarge software process line that is mandatory to use for IT projects in the\nGerman public sector. The suitability is evaluated with three experts that\nvalued the improved accessibly and usability of the process and the end-user\nsupport tool.",
    "pdf_url": "http://arxiv.org/pdf/2502.11792v1",
    "published": "2025-02-17T13:30:19+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11791v1",
    "title": "Forbidden configurations and dominating bicliques in undirected 2-quasi best match graphs",
    "authors": [
      "Annachiara Korchmaros",
      "Peter F. Stadler"
    ],
    "abstract": "2-quasi best match graphs (2-qBMGs) are directed graphs that capture a\n  notion of close relatedness in phylogenetics. Here, we investigate the\n  undirected underlying graph of a 2-qBMG (un-2qBMG) and show that they\n  contain neither a path $P_l$ nor a cycle $C_l$ of length $l\\geq 6$ as an\n  induced subgraph. This property guarantees the existence of specific\n  vertex decompositions with dominating bicliques that provide further\n  insights into their structure.",
    "pdf_url": "http://arxiv.org/pdf/2502.11791v1",
    "published": "2025-02-17T13:29:14+00:00",
    "categories": [
      "math.CO",
      "05C38, 05C69, 05C90"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11790v2",
    "title": "Quiver Grassmannians for the Bott-Samelson resolution of type A Schubert varieties",
    "authors": [
      "Giulia Iezzi"
    ],
    "abstract": "We realise the Bott-Samelson resolutions of type A Schubert varieties as\nquiver Grassmannians. In order to explicitly describe this isomorphism, we\nintroduce the notion of a \\textit{geometrically compatible} decomposition for\nany permutation in $S_n$. For smooth type A Schubert varieties, we identify a\nsuitable dimension vector such that the corresponding quiver Grassmannian is\nisomorphic to the Schubert variety. To obtain these isomorphisms, we construct\na special quiver with relations and investigate two classes of quiver\nGrassmannians for this quiver.",
    "pdf_url": "http://arxiv.org/pdf/2502.11790v2",
    "published": "2025-02-17T13:28:29+00:00",
    "categories": [
      "math.RT",
      "math.AG",
      "math.CO"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11789v2",
    "title": "Personality Editing for Language Models through Relevant Knowledge Editing",
    "authors": [
      "Seojin Hwang",
      "Yumin Kim",
      "Byeongjeong Kim",
      "Donghoon Shin",
      "Hwanhee Lee"
    ],
    "abstract": "Large Language Models (LLMs) play a vital role in applications like\nconversational agents and content creation, where controlling a model's\npersonality is crucial for maintaining tone, consistency, and engagement.\nHowever, traditional prompt-based techniques for controlling personality often\nfall short, as they do not effectively mitigate the model's inherent biases. In\nthis paper, we introduce a novel method PALETTE that enhances personality\ncontrol through knowledge editing. By generating adjustment queries inspired by\npsychological assessments, our approach systematically adjusts responses to\npersonality-related queries similar to modifying factual knowledge, thereby\nachieving controlled shifts in personality traits. Experimental results from\nboth automatic and human evaluations demonstrate that our method enables more\nstable and well-balanced personality control in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11789v2",
    "published": "2025-02-17T13:28:14+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11788v1",
    "title": "Comparison of Offset and Ratio Weighted Regressions in Tweedie Models with Application to Mid-Term Cancellations",
    "authors": [
      "Boucher Jean-Philippe",
      "Coulibaly RaÃ¯ssa"
    ],
    "abstract": "In property and casualty insurance, particularly in automobile insurance,\nrisk exposure is traditionally associated with the coverage duration. However,\nfactors such as early contract cancellations demand more precise modelling to\nensure accurate premium pricing. This study introduces and compares two\napproaches for modelling total claims (or loss costs) in insurance portfolios\nwith a high proportion of policies that have partial year exposure: the offset\nand ratio methods. We demonstrate that both approaches can be viewed as\nweighted regressions under the Tweedie distribution framework. Through an\nanalysis based on the financial balance property, we find that the ratio\napproach outperforms the offset method. This comparison is illustrated using an\nautomobile insurance portfolio, where a significant share of policyholders\nterminate their contracts before the coverage period concludes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11788v1",
    "published": "2025-02-17T13:26:36+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11787v2",
    "title": "A Shape Lemma for Ideals of Differential Operators",
    "authors": [
      "Manuel Kauers",
      "Christoph Koutschan",
      "Thibaut Verron"
    ],
    "abstract": "We propose a version of the classical shape lemma for zero-dimensional ideals\nof a commutative multivariate polynomial ring to the noncommutative setting of\nzero-dimensional ideals in an algebra of differential operators.",
    "pdf_url": "http://arxiv.org/pdf/2502.11787v2",
    "published": "2025-02-17T13:26:16+00:00",
    "categories": [
      "cs.SC",
      "math.AC"
    ],
    "primary_category": "cs.SC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11786v1",
    "title": "A method for signal components identification in acoustic signal with non-Gaussian background noise using clustering of data in time-frequency domain",
    "authors": [
      "A Drewnicka",
      "A Michalak",
      "R Zimroz",
      "A Kumar",
      "A WyÅomaÅska",
      "J Wodecki"
    ],
    "abstract": "This paper presents a novel method for fault detection in vibration/acoustic\nsignals contaminated with non-Gaussian noise, specifically addressing the\nchallenge of random impulsive and wideband disturbances in industrial\nmeasurements. While damage detection in Gaussian noise environments is well\nunderstood, high-amplitude non-cyclic impulsive disturbances arising from\nrandom aspects of industrial processes, such as non-uniform operations and\nrandom impacts, pose significant analytical challenges. The proposed method\nanalyzes the distribution densities of spectral vectors derived from\nspectrograms. It considers a simple additive model consisting of the signal of\ninterest (SOI) and Gaussian and non-Gaussian noise. Using the density-based\nspatial clustering algorithm (DBSCAN), the method isolates distinct classes of\nspectral vectors from the spectrogram, effectively separating different signal\nbehaviors and extracting fault-related information. The effectiveness of the\nproposed method was validated using an envelope spectrum-based indicator\n(ENVSI) and successfully demonstrated on real signals from an industrial\nmachine with a faulty bearing.",
    "pdf_url": "http://arxiv.org/pdf/2502.11786v1",
    "published": "2025-02-17T13:25:16+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11785v2",
    "title": "Changing the Rules of the Game: Reasoning about Dynamic Phenomena in Multi-Agent Systems",
    "authors": [
      "Rustam Galimullin",
      "Maksim Gladyshev",
      "Munyque Mittelmann",
      "Nima Motamed"
    ],
    "abstract": "The design and application of multi-agent systems (MAS) require reasoning\nabout the effects of modifications on their underlying structure. In\nparticular, such changes may impact the satisfaction of system specifications\nand the strategic abilities of their autonomous components. In this paper, we\nare concerned with the problem of verifying and synthesising modifications (or\nupdates) of MAS. We propose an extension of the Alternating-Time Temporal Logic\n($\\mathsf{ATL}$) that enables reasoning about the dynamics of model change,\ncalled the Logic for $\\mathsf{ATL}$ Model Building ($\\mathsf{LAMB}$). We show\nhow $\\mathsf{LAMB}$ can express various intuitions and ideas about the dynamics\nof MAS, from normative updates to mechanism design. As the main technical\nresult, we prove that, while being strictly more expressive than\n$\\mathsf{ATL}$, $\\mathsf{LAMB}$ enjoys a P-complete model-checking procedure.",
    "pdf_url": "http://arxiv.org/pdf/2502.11785v2",
    "published": "2025-02-17T13:23:37+00:00",
    "categories": [
      "cs.LO",
      "cs.MA",
      "F.4.1; I.2.4; I.2.11"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11784v1",
    "title": "Structure, Positivity and Classical Simulability of Kirkwood-Dirac Distributions",
    "authors": [
      "JÄdrzej Burkat",
      "Sergii Strelchuk"
    ],
    "abstract": "The Kirkwood-Dirac (KD) quasiprobability distribution is known for its role\nin quantum metrology, thermodynamics, as well as the foundations of quantum\nmechanics. Here, we study the superoperator evolution of KD distributions and\nshow that unitaries which preserve KD positivity do not always correspond to a\nstochastic evolution of quasiprobabilities. Conversely, we show that stochastic\nKD superoperators are always induced by generalised permutations within the KD\nreference bases. We identify bounds for pure KD positive states in\ndistributions defined on mutually unbiased bases, showing that they always form\nuniform distributions, in full analogy to the stabilizer states. Subsequently,\nwe show that the discrete Fourier transform of KD distributions on qudits in\nthe Fourier basis follows a self-similarity constraint and provides the\nexpectation values of the state with respect to the Weyl-Heisenberg unitaries,\nwhich can then be transformed into the (odd-dimensional) Wigner distribution.\nThis defines a direct mapping between the Wigner, and qudit KD distributions\nwithout a reconstruction of the density matrix. Finally, we identify instances\nwhere the classical sampling-based simulation algorithm of Pashayan et al.\n[Phys. Rev. Lett. 115, 070501] becomes exponentially inefficient in spite of\nthe state being KD positive throughout its evolution.",
    "pdf_url": "http://arxiv.org/pdf/2502.11784v1",
    "published": "2025-02-17T13:20:10+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11783v1",
    "title": "Femtosecond-and-atom-resolved solvation dynamics of a Na$^+$ ion in a helium nanodroplet",
    "authors": [
      "Simon H. Albrechtsen",
      "Jeppe K. Christensen",
      "Christian E. Petersen",
      "Constant A. Schouder",
      "Pedro Javier Carchi-Villalta",
      "Iker SÃ¡nchez-PÃ©rez",
      "Massimiliano Bartolomei",
      "TomÃ¡s GonzÃ¡lez-Lezana",
      "Fernando Pirani",
      "Henrik Stapelfeldt"
    ],
    "abstract": "Recently, it was shown how the primary steps of solvation of a single Na$^+$\nion, instantly created at the surface of a nanometer-sized droplet of liquid\nhelium, can be followed at the atomic level [Albrectsen et al. Nature\n$\\textbf{623}$, 319 (2023)]. This involved measuring, with femtosecond time\nresolution, the gradual attachment of individual He atoms to the Na$^+$ ion as\nwell as the energy dissipated from the local region of the ion. In the current\nwork, we provide a more comprehensive and detailed description of the\nexperimental findings of the solvation dynamics, and present an improved\nPoisson-statistical analysis of the time-resovled yields of the solvation\ncomplexes, Na$^+$He$_n$. For droplets containing an average of 5200 He atoms,\nthis analysis gives a binding rate of $1.84\\pm0.09$ atoms/ps for the binding of\nthe first five He atoms to the Na$^+$ ion. Also, thanks to accurate heoretical\nvalues for the evaporation energies of the Na$^+$He$_n$ complexes, obtained by\nPath Integral Monte Carlo methos using a new potential energy surface presented\nhere for the first time, we improved the determination of the time-dependent\nremoval of the solvation energy from the region around the sodium ion. We find\nthat it follows Newton's law of cooling for the first 6 ps. Measurements were\ncarried out for three different average droplet sizes, $\\langle N_D\\rangle = $\n9000, 5200 and 3600 helium atoms, and differences between these results are\ndiscussed.",
    "pdf_url": "http://arxiv.org/pdf/2502.11783v1",
    "published": "2025-02-17T13:17:09+00:00",
    "categories": [
      "physics.atm-clus"
    ],
    "primary_category": "physics.atm-clus"
  },
  {
    "id": "http://arxiv.org/abs/2502.11782v1",
    "title": "Exploring the Versal AI Engine for 3D Gaussian Splatting",
    "authors": [
      "Kotaro Shimamura",
      "Ayumi Ohno",
      "Shinya Takamaeda-Yamazaki"
    ],
    "abstract": "Dataflow-oriented spatial architectures are the emerging paradigm for higher\ncomputation performance and efficiency.\n  AMD Versal AI Engine is a commercial spatial architecture consisting of tiles\nof VLIW processors supporting SIMD operations arranged in a two-dimensional\nmesh.\n  The architecture requires the explicit design of task assignments and\ndataflow configurations for each tile to maximize performance, demanding\nadvanced techniques and meticulous design.\n  However, a few works revealed the performance characteristics of the Versal\nAI Engine through practical workloads.\n  In this work, we provide the comprehensive performance evaluation of the\nVersal AI Engine using Gaussian feature computation in 3D Gaussian splatting as\na practical workload, and we then propose a novel dedicated algorithm to fully\nexploit the hardware architecture.\n  The computations of 3D Gaussian splatting include matrix multiplications and\ncolor computations utilizing high-dimensional spherical harmonic coefficients.\n  These tasks are processed efficiently by leveraging the SIMD capabilities and\ntheir instruction-level parallelism.\n  Additionally, pipelined processing is achieved by assigning different tasks\nto individual cores, thereby fully exploiting the spatial parallelism of AI\nEngines.\n  The proposed method demonstrated a 226-fold throughput increase in\nsimulation-based evaluation, outperforming a naive approach.\n  These findings provide valuable insights for application development that\neffectively harnesses the spatial and architectural advantages of AI Engines.",
    "pdf_url": "http://arxiv.org/pdf/2502.11782v1",
    "published": "2025-02-17T13:16:44+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.18490v1",
    "title": "Event-based Solutions for Human-centered Applications: A Comprehensive Review",
    "authors": [
      "Mira Adra",
      "Simone Melcarne",
      "Nelida Mirabet-Herranz",
      "Jean-Luc Dugelay"
    ],
    "abstract": "Event cameras, often referred to as dynamic vision sensors, are\ngroundbreaking sensors capable of capturing changes in light intensity\nasynchronously, offering exceptional temporal resolution and energy efficiency.\nThese attributes make them particularly suited for human-centered applications,\nas they capture both the most intricate details of facial expressions and the\ncomplex motion dynamics of the human body. Despite growing interest, research\nin human-centered applications of event cameras remains scattered, with no\ncomprehensive overview encompassing both body and face tasks. This survey\nbridges that gap by being the first to unify these domains, presenting an\nextensive review of advancements, challenges, and opportunities. We also\nexamine less-explored areas, including event compression techniques and\nsimulation frameworks, which are essential for the broader adoption of event\ncameras. This survey is designed to serve as a foundational reference that\nhelps both new and experienced researchers understand the current state of the\nfield and identify promising directions for future work in human-centered event\ncamera applications. A summary of this survey can be found at\nhttps://github.com/nmirabeth/event_human",
    "pdf_url": "http://arxiv.org/pdf/2502.18490v1",
    "published": "2025-02-17T13:15:19+00:00",
    "categories": [
      "cs.CV",
      "I.5.4; I.5.0; I.4.9; I.4.0"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11781v1",
    "title": "Quantum Tunneling Enhanced Hydrogen Desorption from Graphene Surface: Atomic versus Molecular Mechanism",
    "authors": [
      "Yangwu Tong",
      "Yong Yang"
    ],
    "abstract": "We study the desorption mechanism of hydrogen isotopes from graphene surface\nusing first-principles calculations, with focus on the effects of quantum\ntunneling. At low temperatures, quantum tunneling plays a dominant role in the\ndesorption process of both hydrogen monomers and dimers. In the case of dimer\ndesorption, two types of mechanisms, namely the traditional one-step desorption\nin the form of molecules (molecular mechanism), and the two-step desorption in\nthe form of individual atoms (atomic mechanism) are studied and compared. For\nthe ortho-dimers, the dominant desorption mechanism is found to switch from the\nmolecular mechanism to the atomic mechanism above a critical temperature, which\nis respectively ~ 300 K and 200 K for H and D.",
    "pdf_url": "http://arxiv.org/pdf/2502.11781v1",
    "published": "2025-02-17T13:15:10+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11780v3",
    "title": "Robust Optimization of Rank-Dependent Models with Uncertain Probabilities",
    "authors": [
      "Guanyu Jin",
      "Roger J. A. Laeven",
      "Dick den Hertog"
    ],
    "abstract": "This paper studies distributionally robust optimization for a rich class of\nrisk measures with ambiguity sets defined by $\\phi$-divergences. The risk\nmeasures are allowed to be non-linear in probabilities, are represented by\nChoquet integrals possibly induced by a probability weighting function, and\nencompass many well-known examples. Optimization for this class of risk\nmeasures is challenging due to their rank-dependent nature. We show that for\nvarious shapes of probability weighting functions, including concave, convex\nand inverse $S$-shaped, the robust optimization problem can be reformulated\ninto a rank-independent problem. In the case of a concave probability weighting\nfunction, the problem can be reformulated further into a convex optimization\nproblem that admits explicit conic representability for a collection of\ncanonical examples. While the number of constraints in general scales\nexponentially with the dimension of the state space, we circumvent this\ndimensionality curse and develop two types of algorithms. They yield tight\nupper and lower bounds on the exact optimal value and are formally shown to\nconverge asymptotically. This is illustrated numerically in a robust newsvendor\nproblem and a robust portfolio choice problem.",
    "pdf_url": "http://arxiv.org/pdf/2502.11780v3",
    "published": "2025-02-17T13:15:02+00:00",
    "categories": [
      "math.OC",
      "econ.TH",
      "90C17, 91B06"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11779v3",
    "title": "Efficient Response Generation Strategy Selection for Fine-Tuning Large Language Models Through Self-Aligned Perplexity",
    "authors": [
      "Xuan Ren",
      "Qi Chen",
      "Lingqiao Liu"
    ],
    "abstract": "Fine-tuning large language models (LLMs) typically relies on producing large\nsets of input-output pairs. Yet for a given question, there can be many valid\noutputs. In practice, these outputs are often derived by distilling knowledge\nfrom teacher models, and they can vary depending on the specific teacher model\nor prompting strategy employed. Recent findings show that how these training\noutputs are generated can significantly affect the performance of the\nfine-tuned model, raising an important question: how do we pick the best data\ngeneration method from among numerous possibilities? Rather than exhaustively\ntraining and evaluating on each candidate, this paper proposes a scalable\napproximate method that assesses a small subset of generated data to estimate\nits suitability for a specific target LLM. Our central idea is that effective\noutputs should be familiar to the target LLM. While previous work measures\nfamiliarity with perplexity, we find that perplexity might be suboptimal in\ncharacterizing familiarity through empirical analyses and practical\nobservations. To address this, we introduce self-aligned perplexity, a novel\nmetric capturing how closely candidate outputs adhere to the target LLM's own\nstyle and reasoning patterns. In this way, we can identify the most effective\ngeneration strategy on a small sample, then apply it to produce the complete\ntraining set. We demonstrate that training on data generated by the chosen\nmethod yields significant improvements across diverse reasoning-focused\nbenchmarks, particularly in cases where different candidate methods lead to\nhighly divergent training outcomes. Our implementation is publicly available at\nhttps://github.com/XuanRen4470/SPPL.",
    "pdf_url": "http://arxiv.org/pdf/2502.11779v3",
    "published": "2025-02-17T13:14:11+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11778v1",
    "title": "Private Synthetic Graph Generation and Fused Gromov-Wasserstein Distance",
    "authors": [
      "Leoni Carla Wirth",
      "Gholamali Aminian",
      "Gesine Reinert"
    ],
    "abstract": "Networks are popular for representing complex data. In particular,\ndifferentially private synthetic networks are much in demand for method and\nalgorithm development. The network generator should be easy to implement and\nshould come with theoretical guarantees. Here we start with complex data as\ninput and jointly provide a network representation as well as a synthetic\nnetwork generator. Using a random connection model, we devise an effective\nalgorithmic approach for generating attributed synthetic graphs which is\n$\\epsilon$-differentially private at the vertex level, while preserving utility\nunder an appropriate notion of distance which we develop. We provide\ntheoretical guarantees for the accuracy of the private synthetic graphs using\nthe fused Gromov-Wasserstein distance, which extends the Wasserstein metric to\nstructured data. Our method draws inspiration from the PSMM method of\n\\citet{he2023}.",
    "pdf_url": "http://arxiv.org/pdf/2502.11778v1",
    "published": "2025-02-17T13:13:16+00:00",
    "categories": [
      "stat.ML",
      "cs.DS",
      "cs.LG",
      "math.PR"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.11777v1",
    "title": "Deep Neural Networks for Accurate Depth Estimation with Latent Space Features",
    "authors": [
      "Siddiqui Muhammad Yasir",
      "Hyunsik Ahn"
    ],
    "abstract": "Depth estimation plays a pivotal role in advancing human-robot interactions,\nespecially in indoor environments where accurate 3D scene reconstruction is\nessential for tasks like navigation and object handling. Monocular depth\nestimation, which relies on a single RGB camera, offers a more affordable\nsolution compared to traditional methods that use stereo cameras or LiDAR.\nHowever, despite recent progress, many monocular approaches struggle with\naccurately defining depth boundaries, leading to less precise reconstructions.\nIn response to these challenges, this study introduces a novel depth estimation\nframework that leverages latent space features within a deep convolutional\nneural network to enhance the precision of monocular depth maps. The proposed\nmodel features dual encoder-decoder architecture, enabling both color-to-depth\nand depth-to-depth transformations. This structure allows for refined depth\nestimation through latent space encoding. To further improve the accuracy of\ndepth boundaries and local features, a new loss function is introduced. This\nfunction combines latent loss with gradient loss, helping the model maintain\nthe integrity of depth boundaries. The framework is thoroughly tested using the\nNYU Depth V2 dataset, where it sets a new benchmark, particularly excelling in\ncomplex indoor scenarios. The results clearly show that this approach\neffectively reduces depth ambiguities and blurring, making it a promising\nsolution for applications in human-robot interaction and 3D scene\nreconstruction.",
    "pdf_url": "http://arxiv.org/pdf/2502.11777v1",
    "published": "2025-02-17T13:11:35+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11776v1",
    "title": "Parabolic Dijkgraaf-Witten invariants of links in the $3$-sphere",
    "authors": [
      "Koki Yanagida"
    ],
    "abstract": "We define a new invariant of links in the $3$-sphere and call it the\nparabolic Dijkgraaf-Witten (DW) invariant. This invariant is a generalization\nof the reduced DW invariant derived by Karuo. In this paper, we compute the\ninvariant of several links over which double branched coverings are\nhomeomorphic to the lens spaces. Moreover, we introduce a procedure for\ncomputing partial information of the parabolic DW invariant using only link\ndiagrams.",
    "pdf_url": "http://arxiv.org/pdf/2502.11776v1",
    "published": "2025-02-17T13:11:00+00:00",
    "categories": [
      "math.GT",
      "57K10"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2503.05721v1",
    "title": "What Are They Filtering Out? A Survey of Filtering Strategies for Harm Reduction in Pretraining Datasets",
    "authors": [
      "Marco Antonio Stranisci",
      "Christian Hardmeier"
    ],
    "abstract": "Data filtering strategies are a crucial component to develop safe Large\nLanguage Models (LLM), since they support the removal of harmful contents from\npretraining datasets. There is a lack of research on the actual impact of these\nstrategies on vulnerable groups to discrimination, though, and their\neffectiveness has not been yet systematically addressed. In this paper we\npresent a benchmark study of data filtering strategies for harm reduction aimed\nat providing a systematic overview on these approaches. We survey 55 technical\nreports of English LMs and LLMs to identify the existing filtering strategies\nin literature and implement an experimental setting to test their impact\nagainst vulnerable groups. Our results show that the positive impact that\nstrategies have in reducing harmful contents from documents has the side effect\nof increasing the underrepresentation of vulnerable groups to discrimination in\ndatasets.",
    "pdf_url": "http://arxiv.org/pdf/2503.05721v1",
    "published": "2025-02-17T13:10:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11775v1",
    "title": "video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model",
    "authors": [
      "Guangzhi Sun",
      "Yudong Yang",
      "Jimin Zhuang",
      "Changli Tang",
      "Yixuan Li",
      "Wei Li",
      "Zejun MA",
      "Chao Zhang"
    ],
    "abstract": "While recent advancements in reasoning optimization have significantly\nenhanced the capabilities of large language models (LLMs), existing efforts to\nimprove reasoning have been limited to solving mathematical problems and\nfocusing on visual graphical inputs, neglecting broader applications in general\nvideo understanding.This paper proposes video-SALMONN-o1, the first open-source\nreasoning-enhanced audio-visual LLM designed for general video understanding\ntasks. To enhance its reasoning abilities, we develop a reasoning-intensive\ndataset featuring challenging audio-visual questions with step-by-step\nsolutions. We also propose process direct preference optimization (pDPO), which\nleverages contrastive step selection to achieve efficient step-level reward\nmodelling tailored for multimodal inputs. Additionally, we introduce RivaBench,\nthe first reasoning-intensive video understanding benchmark, featuring over\n4,000 high-quality, expert-curated question-answer pairs across scenarios such\nas standup comedy, academic presentations, and synthetic video detection.\nvideo-SALMONN-o1 achieves 3-8% accuracy improvements over the LLaVA-OneVision\nbaseline across different video reasoning benchmarks. Besides, pDPO achieves\n6-8% improvements compared to the supervised fine-tuning model on RivaBench.\nEnhanced reasoning enables video-SALMONN-o1 zero-shot synthetic video detection\ncapabilities.",
    "pdf_url": "http://arxiv.org/pdf/2502.11775v1",
    "published": "2025-02-17T13:07:40+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11774v1",
    "title": "Interpretable Machine Learning for Kronecker Coefficients",
    "authors": [
      "Giorgi Butbaia",
      "Kyu-Hwan Lee",
      "Fabian Ruehle"
    ],
    "abstract": "We analyze the saliency of neural networks and employ interpretable machine\nlearning models to predict whether the Kronecker coefficients of the symmetric\ngroup are zero or not. Our models use triples of partitions as input features,\nas well as b-loadings derived from the principal component of an embedding that\ncaptures the differences between partitions. Across all approaches, we achieve\nan accuracy of approximately 83% and derive explicit formulas for a decision\nfunction in terms of b-loadings. Additionally, we develop transformer-based\nmodels for prediction, achieving the highest reported accuracy of over 99%.",
    "pdf_url": "http://arxiv.org/pdf/2502.11774v1",
    "published": "2025-02-17T13:07:37+00:00",
    "categories": [
      "cs.LG",
      "math.CO",
      "math.RT",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11773v2",
    "title": "Globular subdivisions are dihomotopy equivalences",
    "authors": [
      "Philippe Gaucher"
    ],
    "abstract": "We prove that any globular subdivision of multipointed $d$-spaces gives rise\nto a dihomotopy equivalence between the associated flows. As a straightforward\napplication, the flows associated to two multipointed $d$-spaces related by a\nfinite zigzag of globular subdivisions have isomorphic branching and merging\nhomology theories and isomorphic underlying homotopy types.",
    "pdf_url": "http://arxiv.org/pdf/2502.11773v2",
    "published": "2025-02-17T13:07:04+00:00",
    "categories": [
      "math.AT",
      "math.CT",
      "55U35 (Primary), 55U99, 68Q85 (Secondary)"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2506.12017v1",
    "title": "Optimized Amplitude Amplification for Quantum State Preparation",
    "authors": [
      "Artem Chernikov",
      "Karina Zakharova",
      "Sergey Sysoev"
    ],
    "abstract": "In this paper, we present an algorithm for preparing quantum states of the\nform $\\sum_{i=0}^{n-1} \\alpha_i |i\\rangle$, where the coefficients $\\alpha_i$\nare specified by a quantum oracle. Our method achieves this task twice as fast\nas the best existing algorithm known to the authors. Such state preparation is\nessential for quantum algorithms that process large classical inputs, including\nmatrix inversion and linear system solvers. The standard approach relies on\namplitude amplification, a process that may require multiple, time-consuming\noracle queries. Consequently, reducing the number of queries - and thereby the\noverall time complexity can lead to significant performance improvements in\npractice.",
    "pdf_url": "http://arxiv.org/pdf/2506.12017v1",
    "published": "2025-02-17T13:04:26+00:00",
    "categories": [
      "quant-ph",
      "cs.CC"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11772v1",
    "title": "Simultaneous estimations of quantum state and detector through multiple quantum processes",
    "authors": [
      "Shuixin Xiao",
      "Weichao Liang",
      "Yuanlong Wang",
      "Daoyi Dong",
      "Ian R. Petersen",
      "Valery Ugrinovskii"
    ],
    "abstract": "The estimation of all the parameters in an unknown quantum state or\nmeasurement device, commonly known as quantum state tomography (QST) and\nquantum detector tomography (QDT), is crucial for comprehensively\ncharacterizing and controlling quantum systems. In this paper, we introduce a\nframework, in two different bases, that utilizes multiple quantum processes to\nsimultaneously identify a quantum state and a detector. We develop a\nclosed-form algorithm for this purpose and prove that the mean squared error\n(MSE) scales as $O(1/N) $ for both QST and QDT, where $N $ denotes the total\nnumber of state copies. This scaling aligns with established patterns observed\nin previous works that addressed QST and QDT as independent tasks. Furthermore,\nwe formulate the problem as a sum of squares (SOS) optimization problem with\nsemialgebraic constraints, where the physical constraints of the state and\ndetector are characterized by polynomial equalities and inequalities. The\neffectiveness of our proposed methods is validated through numerical examples.",
    "pdf_url": "http://arxiv.org/pdf/2502.11772v1",
    "published": "2025-02-17T13:02:36+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2503.16448v1",
    "title": "Towards Open Diversity-Aware Social Interactions",
    "authors": [
      "Loizos Michael",
      "Ivano Bison",
      "Matteo Busso",
      "Luca Cernuzzi",
      "Amalia De GÃ¶tzen",
      "Shyam Diwakar",
      "Kobi Gal",
      "Amarsanaa Ganbold",
      "George Gaskell",
      "Daniel Gatica-Perez",
      "Jessica Heesen",
      "Daniele Miorandi",
      "Salvador Ruiz-Correa",
      "Laura Schelenz",
      "Avi Segal",
      "Carles Sierra",
      "Hao Xu",
      "Fausto Giunchiglia"
    ],
    "abstract": "Social Media and the Internet have catalyzed an unprecedented potential for\nexposure to human diversity in terms of demographics, talents, opinions,\nknowledge, and the like. However, this potential has not come with new, much\nneeded, instruments and skills to harness it. This paper presents our work on\npromoting richer and deeper social relations through the design and development\nof the \"Internet of Us\", an online platform that uses diversity-aware\nArtificial Intelligence to mediate and empower human social interactions. We\ndiscuss the multiple facets of diversity in social settings, the\nmultidisciplinary work that is required to reap the benefits of diversity, and\nthe vision for a diversity-aware hybrid human-AI society.",
    "pdf_url": "http://arxiv.org/pdf/2503.16448v1",
    "published": "2025-02-17T13:02:14+00:00",
    "categories": [
      "cs.HC",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2503.05720v3",
    "title": "That is Unacceptable: the Moral Foundations of Canceling",
    "authors": [
      "Soda Marem Lo",
      "Oscar Araque",
      "Rajesh Sharma",
      "Marco Antonio Stranisci"
    ],
    "abstract": "Canceling is a morally-driven phenomenon that hinders the development of safe\nsocial media platforms and contributes to ideological polarization. To address\nthis issue we present the Canceling Attitudes Detection (CADE) dataset, an\nannotated corpus of canceling incidents aimed at exploring the factors of\ndisagreements in evaluating people canceling attitudes on social media.\nSpecifically, we study the impact of annotators' morality in their perception\nof canceling, showing that morality is an independent axis for the explanation\nof disagreement on this phenomenon. Annotator's judgments heavily depend on the\ntype of controversial events and involved celebrities. This shows the need to\ndevelop more event-centric datasets to better understand how harms are\nperpetrated in social media and to develop more aware technologies for their\ndetection.",
    "pdf_url": "http://arxiv.org/pdf/2503.05720v3",
    "published": "2025-02-17T13:01:06+00:00",
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11771v1",
    "title": "The Validation Gap: A Mechanistic Analysis of How Language Models Compute Arithmetic but Fail to Validate It",
    "authors": [
      "Leonardo Bertolazzi",
      "Philipp Mondorf",
      "Barbara Plank",
      "Raffaella Bernardi"
    ],
    "abstract": "The ability of large language models (LLMs) to validate their output and\nidentify potential errors is crucial for ensuring robustness and reliability.\nHowever, current research indicates that LLMs struggle with self-correction,\nencountering significant challenges in detecting errors. While studies have\nexplored methods to enhance self-correction in LLMs, relatively little\nattention has been given to understanding the models' internal mechanisms\nunderlying error detection. In this paper, we present a mechanistic analysis of\nerror detection in LLMs, focusing on simple arithmetic problems. Through\ncircuit analysis, we identify the computational subgraphs responsible for\ndetecting arithmetic errors across four smaller-sized LLMs. Our findings reveal\nthat all models heavily rely on $\\textit{consistency heads}$--attention heads\nthat assess surface-level alignment of numerical values in arithmetic\nsolutions. Moreover, we observe that the models' internal arithmetic\ncomputation primarily occurs in higher layers, whereas validation takes place\nin middle layers, before the final arithmetic results are fully encoded. This\nstructural dissociation between arithmetic computation and validation seems to\nexplain why current LLMs struggle to detect even simple arithmetic errors.",
    "pdf_url": "http://arxiv.org/pdf/2502.11771v1",
    "published": "2025-02-17T13:00:44+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11770v1",
    "title": "Cognitive-Aligned Document Selection for Retrieval-augmented Generation",
    "authors": [
      "Bingyu Wan",
      "Fuxi Zhang",
      "Zhongpeng Qi",
      "Jiayi Ding",
      "Jijun Li",
      "Baoshi Fan",
      "Yijia Zhang",
      "Jun Zhang"
    ],
    "abstract": "Large language models (LLMs) inherently display hallucinations since the\nprecision of generated texts cannot be guaranteed purely by the parametric\nknowledge they include. Although retrieval-augmented generation (RAG) systems\nenhance the accuracy and reliability of generative models by incorporating\nexternal documents, these retrieved documents often fail to adequately support\nthe model's responses in practical applications. To address this issue, we\npropose GGatrieval (Fine-\\textbf{G}rained \\textbf{G}rounded \\textbf{A}lignment\nRe\\textbf{trieval} for verifiable generation), which leverages an LLM to\ndynamically update queries and filter high-quality, reliable retrieval\ndocuments. Specifically, we parse the user query into its syntactic components\nand perform fine-grained grounded alignment with the retrieved documents. For\nquery components that cannot be individually aligned, we propose a dynamic\nsemantic compensation mechanism that iteratively refines and rewrites the query\nwhile continuously updating the retrieval results. This iterative process\ncontinues until the retrieved documents sufficiently support the query's\nresponse. Our approach introduces a novel criterion for filtering retrieved\ndocuments, closely emulating human strategies for acquiring targeted\ninformation. This ensures that the retrieved content effectively supports and\nverifies the generated outputs. On the ALCE benchmark, our method significantly\nsurpasses a wide range of baselines, achieving state-of-the-art performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11770v1",
    "published": "2025-02-17T13:00:15+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11769v1",
    "title": "Quasi-perfect spatiotemporal optical vortex with suppressed mode degradation",
    "authors": [
      "Shunlin Huang",
      "Xiong Shen",
      "Renjing Chen",
      "Jun Liu",
      "Ruxin Li"
    ],
    "abstract": "Spatiotemporal optical vortex (STOV) carrying transverse orbital angular\nmomentum (OAM) enriches the family of vortex beams and exhibit unique\nproperties. Typically, a high-order STOV with an intensity null degrades into\nmultiple first-order STOVs embedded within a single wave packet during\npropagation, a phenomenon known as time diffraction or mode degradation.\nHowever, this degradation limits the applicability of STOVs in specialized\nfields. Therefore, the generation of mode degradation-suppressed STOVs\n(MDS-STOVs) is of significant for both practical applications and theoretical\nstudies. Herein, we theoretically analyze the generation of MDS-STOVs by\nutilizing a conical phase to localize the energy of the STOV into a ring-shaped\nstructure. For MDS-STOVs with large topological charges (TCs), the ring-shaped\nprofile can be well-maintained, and the rapid expansion of the beam size with\nincreasing TC is significantly suppressed compared to conventional STOVs. As a\nresult, these MDS-STOVs can be regarded as quasi-perfect STOVs (QPSTOVs).\nFurthermore, QPSTOVs exhibit strong resistance to group delay dispersion (GDD),\neliminating the need for precise dispersion control and facilitating their\ngeneration and application. This work advances our understanding of the\nphysical properties of light carrying transverse OAM and opens up exciting\navenues for the application of STOVs in diverse fields, such as optical\ncommunication and quantum information processing.",
    "pdf_url": "http://arxiv.org/pdf/2502.11769v1",
    "published": "2025-02-17T12:59:41+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.11768v1",
    "title": "Seismic regularity coefficient changes precede stronger earthquakes in Santorini swarm",
    "authors": [
      "Stanislaw Lasocki",
      "Beata Orlecka-Sikora",
      "Anastasios Kostoglou",
      "Vasileios G. Karakostas",
      "Eleftheria E. Papadimitrio"
    ],
    "abstract": "We have been analyzing the ongoing seismic swarm in Santorini, Greece, with\nthe Seismic Regularity (dc) and Seismic Strain Dynamics (SSD) coefficients,\nwhich quantify temporal changes in seismic process organization and strain\nenergy release. Stronger earthquakes are preceded by characteristic down-up\nchanges of dc. Such a change indicates an increase in the seismic process\nregularity followed by a fast transition to a more irregular and chaotic\nseismic regime.",
    "pdf_url": "http://arxiv.org/pdf/2502.11768v1",
    "published": "2025-02-17T12:58:26+00:00",
    "categories": [
      "physics.geo-ph",
      "nlin.CD"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11767v2",
    "title": "From Selection to Generation: A Survey of LLM-based Active Learning",
    "authors": [
      "Yu Xia",
      "Subhojyoti Mukherjee",
      "Zhouhang Xie",
      "Junda Wu",
      "Xintong Li",
      "Ryan Aponte",
      "Hanjia Lyu",
      "Joe Barrow",
      "Hongjie Chen",
      "Franck Dernoncourt",
      "Branislav Kveton",
      "Tong Yu",
      "Ruiyi Zhang",
      "Jiuxiang Gu",
      "Nesreen K. Ahmed",
      "Yu Wang",
      "Xiang Chen",
      "Hanieh Deilamsalehy",
      "Sungchul Kim",
      "Zhengmian Hu",
      "Yue Zhao",
      "Nedim Lipka",
      "Seunghyun Yoon",
      "Ting-Hao Kenneth Huang",
      "Zichao Wang",
      "Puneet Mathur",
      "Soumyabrata Pal",
      "Koyel Mukherjee",
      "Zhehao Zhang",
      "Namyong Park",
      "Thien Huu Nguyen",
      "Jiebo Luo",
      "Ryan A. Rossi",
      "Julian McAuley"
    ],
    "abstract": "Active Learning (AL) has been a powerful paradigm for improving model\nefficiency and performance by selecting the most informative data points for\nlabeling and training. In recent active learning frameworks, Large Language\nModels (LLMs) have been employed not only for selection but also for generating\nentirely new data instances and providing more cost-effective annotations.\nMotivated by the increasing importance of high-quality data and efficient model\ntraining in the era of LLMs, we present a comprehensive survey on LLM-based\nActive Learning. We introduce an intuitive taxonomy that categorizes these\ntechniques and discuss the transformative roles LLMs can play in the active\nlearning loop. We further examine the impact of AL on LLM learning paradigms\nand its applications across various domains. Finally, we identify open\nchallenges and propose future research directions. This survey aims to serve as\nan up-to-date resource for researchers and practitioners seeking to gain an\nintuitive understanding of LLM-based AL techniques and deploy them to new\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11767v2",
    "published": "2025-02-17T12:58:17+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11766v1",
    "title": "Warmup-Distill: Bridge the Distribution Mismatch between Teacher and Student before Knowledge Distillation",
    "authors": [
      "Zengkui Sun",
      "Yijin Liu",
      "Fandong Meng",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ],
    "abstract": "The widespread deployment of Large Language Models (LLMs) is hindered by the\nhigh computational demands, making knowledge distillation (KD) crucial for\ndeveloping compact smaller ones. However, the conventional KD methods endure\nthe distribution mismatch issue between the teacher and student models, leading\nto the poor performance of distillation. For instance, the widely-used KL-based\nmethods suffer the mode-averaging and mode-collapsing problems, since the\nmismatched probabitliy distribution between both models. Previous studies\nmainly optimize this issue via different distance calculations towards the\ndistribution of both models. Unfortunately, the distribution mismatch issue\nstill exists in the early stage of the distillation. Hence, to reduce the\nimpact of distribution mismatch, we propose a simple yet efficient method,\nnamed Warmup-Distill, which aligns the distillation of the student to that of\nthe teacher in advance of distillation. Specifically, we first detect the\ndistribution of the student model in practical scenarios with its internal\nknowledge, and then modify the knowledge with low probability via the teacher\nas the checker. Consequently, Warmup-Distill aligns the internal student's\nknowledge to that of the teacher, which expands the distribution of the student\nwith the teacher's, and assists the student model to learn better in the\nsubsequent distillation. Experiments on the seven benchmarks demonstrate that\nWarmup-Distill could provide a warmup student more suitable for distillation,\nwhich outperforms the vanilla student by as least +0.4 averaged score among all\nbenchmarks. Noteably, with the assistance of Warmup-Distill, the distillation\non the math task could yield a further improvement, at most +1.9% accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2502.11766v1",
    "published": "2025-02-17T12:58:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11765v2",
    "title": "Square skyrmion lattice in multiorbital $f$-electron systems",
    "authors": [
      "Yan Zha",
      "Satoru Hayami"
    ],
    "abstract": "We report the emergence of a square-shaped skyrmion lattice in multi-orbital\n$f$-electron systems with easy-axis magnetic anisotropy on a centrosymmetric\nsquare lattice. By performing mean-field calculations for an effective\nlocalized model consisting of two Kramers doublets, we construct the\nlow-temperature phase diagram in a static external magnetic field.\nConsequently, we find that a square-shaped skyrmion lattice with the skyrmion\nnumber of one appears in the intermediate-field region when the crystal field\nsplitting between the two doublets is small. Furthermore, we identify another\ndouble-$Q$ state with a nonzero net scalar chirality at zero- and low-field\nregions, which is attributed to the help of the multi-orbital degree of\nfreedom. Our results offer another route to search for skyrmion-hosting\nmaterials in centrosymmetric $f$-electron tetragonal systems with multi-orbital\ndegrees of freedom, e.g., Ce-based compounds. This contrasts with conventional\nother $f$-electron systems hosting skyrmion lattices, such as Gd- and Eu-based\ncompounds without orbital angular momentum.",
    "pdf_url": "http://arxiv.org/pdf/2502.11765v2",
    "published": "2025-02-17T12:56:50+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11764v2",
    "title": "Quasinormal modes of massive scalar fields in five-dimensional Myers-Perry black holes with two arbitrary rotation parameters",
    "authors": [
      "Zi-Yang Huang",
      "Jia-Hui Huang"
    ],
    "abstract": "We investigate the quasinormal modes of massive scalar fields in the\nbackground of five-dimensional Myers-Perry black holes. In particular, we\nexplore the case for Myers-Perry black holes with two arbitrary rotation\nparameters. Since the Klein-Gordon equation for the scalar field is separable,\nwe numerically compute the scalar quasinormal modes by using the radial and\nangular equations. Two methods, the continued fraction method and matrix\nmethod, are used in the numerical calculation. We find that all obtained modes\nhave negative imaginary parts and are decaying modes. We also consider the\nimpact of the rotation parameters, scalar field mass $\\mu$ and azimuthal\nnumbers on the scalar quasinormal modes. Besides, when the scalar mass $\\mu$\nbecomes relatively large, we also find the long-living scalar modes. Our\nnumerical results also demonstrate the symmetries of the QNMs explicitly.",
    "pdf_url": "http://arxiv.org/pdf/2502.11764v2",
    "published": "2025-02-17T12:55:55+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11763v1",
    "title": "Lightweight Deepfake Detection Based on Multi-Feature Fusion",
    "authors": [
      "Siddiqui Muhammad Yasir",
      "Hyun Kim"
    ],
    "abstract": "Deepfake technology utilizes deep learning based face manipulation techniques\nto seamlessly replace faces in videos creating highly realistic but\nartificially generated content. Although this technology has beneficial\napplications in media and entertainment misuse of its capabilities may lead to\nserious risks including identity theft cyberbullying and false information. The\nintegration of DL with visual cognition has resulted in important technological\nimprovements particularly in addressing privacy risks caused by artificially\ngenerated deepfake images on digital media platforms. In this study we propose\nan efficient and lightweight method for detecting deepfake images and videos\nmaking it suitable for devices with limited computational resources. In order\nto reduce the computational burden usually associated with DL models our method\nintegrates machine learning classifiers in combination with keyframing\napproaches and texture analysis. Moreover the features extracted with a\nhistogram of oriented gradients (HOG) local binary pattern (LBP) and KAZE bands\nwere integrated to evaluate using random forest extreme gradient boosting extra\ntrees and support vector classifier algorithms. Our findings show a\nfeature-level fusion of HOG LBP and KAZE features improves accuracy to 92% and\n96% on FaceForensics++ and Celeb-DFv2 respectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.11763v1",
    "published": "2025-02-17T12:55:41+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11762v2",
    "title": "Layer-Resolved Quantum Transport in Twisted Bilayer Graphene: Counterflow and Machine Learning Predictions",
    "authors": [
      "Matheus H. Gobbo Kuhn",
      "L. A. Silva",
      "D. A. Bahamon"
    ],
    "abstract": "The layer-resolved quantum transport response of a twisted bilayer graphene\ndevice is investigated by driving a current through the bottom layer and\nmeasuring the induced voltage in the top layer. Devices with four- and\neight-layer differentiated contacts were analyzed, revealing that in a\nnanoribbon geometry (four contacts), a longitudinal counterflow current emerges\nin the top layer, while in a square-junction configuration (eight contacts),\nthis counterflow is accompanied by a transverse, or Hall, component. These\neffects persist despite weak coupling to contacts, onsite disorder, lattice\nrelaxation and variations in device size. The observed counterflow response\nindicates a circulating interlayer current, which generates an in-plane\nmagnetic moment excited by the injected current. Finally, due to the intricate\nrelationship between the electrical layer response, energy, and twist angle, a\nclusterized machine learning model was trained, validated, and tested to\npredict various conductances.",
    "pdf_url": "http://arxiv.org/pdf/2502.11762v2",
    "published": "2025-02-17T12:55:35+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11761v1",
    "title": "Structural and Electronic Properties of Ta2O5 with One Formula Unit",
    "authors": [
      "Yangwu Tong",
      "Huimin Tang",
      "Yong Yang"
    ],
    "abstract": "Based on particle swarm optimization (PSO) algorithm and density functional\ntheory (DFT) calculations, we identify a stable triclinic crystal structure of\nTa2O5 (named as {\\gamma}1-Ta2O5) at atmospheric pressure whose unit cell\ncontains one formula unit (Z=1). Comparison with the Z=1 Ta2O5 structures from\nthe Materials Project [APL Mater. 1, 011002 (2013)] reveals that\n{\\gamma}1-Ta2O5 is energetically the most stable among the Z=1 Ta2O5 phases,\nand is the second most stable among all the Ta2O5 phases. Characterization of\n{\\gamma}1-Ta2O5 is carried out by analyzing the X-ray powder diffraction\npatterns, the elastic, vibrational, thermal and electronic properties. The\nelectronic structures of {\\gamma}1-Ta2O5 are calculated using standard DFT as\nwell as many-body perturbation theory within the GW approximation. The results\nindicate that {\\gamma}1-Ta2O5 is a wide band gap semiconductor with an indirect\ngap of ~ 3.361 eV.",
    "pdf_url": "http://arxiv.org/pdf/2502.11761v1",
    "published": "2025-02-17T12:55:04+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11760v1",
    "title": "An edge labeling of graphs from Rados partition regularity condition",
    "authors": [
      "Arun J Manattu",
      "Aparna Lakshmanan S"
    ],
    "abstract": "A vertex $v$ is called an AR-vertex, if $v$ has distinct edge weight sums for\neach distinct subset of edges incident on $v$. i.e., if $\\{x_1,x_2,\\dots,x_k\\}$\nare the edge labels of the edges incident on $v$, then the $2^k$ subset sums\nare all distinct. An injective edge labeling $f$ of a graph $G$ is said to be\nan AR-labeling of $G$, if $f:E \\rightarrow \\mathbb{N}$ is such that every\nvertex in $G$ is an AR-vertex under $f$. A graph $G$ is said to be an AR-graph,\nif there exists an AR-labeling $f:E\\rightarrow \\{1,2,\\dots,m\\}$, where $m$\ndenotes the number of edges of $G$. A study of AR-labeling and AR-graphs is\ninitiated in this paper.",
    "pdf_url": "http://arxiv.org/pdf/2502.11760v1",
    "published": "2025-02-17T12:55:02+00:00",
    "categories": [
      "math.CO",
      "05C78, 05C55"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11759v1",
    "title": "Approximate radial symmetry for $p$-Laplace equations via the moving planes method",
    "authors": [
      "Michele Gatti"
    ],
    "abstract": "We investigate quasi-symmetry for small perturbations of the\nGidas-Ni-Nirenberg problem involving the $p$-Laplacian and for small\nperturbations the critical $p$-Laplace equation for $p>2$.\n  To achieve these results, we provide a quantitative review of the work by\nDamascelli & Sciunzi (Calc. Var. Partial Differential Equations 25 (2006), no.\n2, 139-159) concerning the weak Harnack comparison inequality and the local\nboundedness comparison inequality. Moreover, we prove a comparison principle\nfor small domains.",
    "pdf_url": "http://arxiv.org/pdf/2502.11759v1",
    "published": "2025-02-17T12:54:59+00:00",
    "categories": [
      "math.AP",
      "35B33, 35B35, 35J92 (Primary) 35B51 (Secondary)"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11758v1",
    "title": "EBOP MAVEN: A machine learning model for predicting eclipsing binary light curve fitting parameters",
    "authors": [
      "Stephen Overall",
      "John Southworth"
    ],
    "abstract": "Detached eclipsing binary stars (dEBs) are a key source of data on\nfundamental stellar parameters. While there is a vast source of candidate\nsystems in the light curve databases of survey missions such as Kepler and\nTESS, published catalogues of well-characterised systems fall short of\nreflecting this abundance. We seek to improve the efficiency of efforts to\nprocess these data with the development of a machine learning model to inspect\ndEB light curves and predict the input parameters for subsequent formal\nanalysis by the jktebop code.",
    "pdf_url": "http://arxiv.org/pdf/2502.11758v1",
    "published": "2025-02-17T12:53:58+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11757v1",
    "title": "Convolution-type operators in grand Lorentz spaces",
    "authors": [
      "Erlan D. Nursultanov",
      "Humberto Rafeiro",
      "Durvudkhan Suragan"
    ],
    "abstract": "We introduce and study a novel grand Lorentz space-that we believe is\nappropriate for critical cases-that lies \"between\" the Lorentz-Karamata space\nand the recently defined grand Lorentz space from [1]. We prove both Young's\nand O'Neil's inequalities in the newly introduced grand Lorentz spaces, which\nallows us to derive a Hardy-Littlewood-Sobolev-type inequality. We also discuss\nK\\\"othe duality for grand Lorentz spaces, from which we obtain a new K\\\"othe\ndual space theorem in grand Lebesgue spaces.",
    "pdf_url": "http://arxiv.org/pdf/2502.11757v1",
    "published": "2025-02-17T12:53:35+00:00",
    "categories": [
      "math.FA",
      "46E30, 46B70, 26D15"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11756v1",
    "title": "On the Computation of the Fisher Information in Continual Learning",
    "authors": [
      "Gido M. van de Ven"
    ],
    "abstract": "One of the most popular methods for continual learning with deep neural\nnetworks is Elastic Weight Consolidation (EWC), which involves computing the\nFisher Information. The exact way in which the Fisher Information is computed\nis however rarely described, and multiple different implementations for it can\nbe found online. This blog post discusses and empirically compares several\noften-used implementations, which highlights that many currently reported\nresults for EWC could likely be improved by changing the way the Fisher\nInformation is computed.",
    "pdf_url": "http://arxiv.org/pdf/2502.11756v1",
    "published": "2025-02-17T12:52:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11755v3",
    "title": "Gravitational lensing and accretion disk imaging of a Buchdahl dense core",
    "authors": [
      "Takahisa Igata",
      "Motoki Omamiuda",
      "Yohsuke Takamori"
    ],
    "abstract": "In this paper, we investigate the gravitational lensing and accretion disk\nimaging characteristics of a dense core modeled by the Buchdahl spacetime. By\nimposing the appropriate energy conditions and ensuring the absence of\ncurvature singularities, we delineate the parameter space in which the dense\ncore mimics key gravitational features of black holes while exhibiting unique\ndeviations. We derive the photon orbital equation and calculate deflection\nangles, clearly distinguishing between weak- and strong-deflection regimes.\nFurthermore, we construct a mapping from the illuminated, geometrically thin\naccretion disk onto the observer's screen -- focusing on the isoradial curves\ncorresponding to a representative source ring. For compactness values below a\ncritical threshold, only a finite number of disk images are formed. In this\nrange, their secondary and higher-order images typically display double-loop\nstructures, with each loop individually capturing the entire source ring.\nNotably, the highest-order image sometimes appears as a single, crescent-shaped\nloop that does not enclose the screen's center, implying the existence of a\ncutoff angle that restricts the imaged portion of the source ring. In contrast,\nfor compactness values above the critical threshold, an infinite sequence of\ndouble-loop structures appears -- a behavior closely linked to the presence of\na photon sphere. These findings suggest that the lensing signatures of dense\ncores can distinguish them from black holes, offering new insights for\nhigh-resolution observations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11755v3",
    "published": "2025-02-17T12:51:50+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11754v1",
    "title": "New insights into crystallographic relation and lattice dynamics effects in {CdO/MgO} superlattices grown by plasma-assisted molecular beam epitaxy",
    "authors": [
      "Aleksandra Wierzbicka",
      "Ewa Przezdziecka",
      "Igor Perlikowski",
      "Eunika Zielony",
      "Abinash Adhikari",
      "Anastasiia Lysak"
    ],
    "abstract": "This article explores the structural properties of molecular beam epitaxy\ngrown {CdO/MgO} superlattices on sapphire substrates of different\ncrystallographic orientations (a-, c-, r-, and m-plane). The investigations\ninvolve a comprehensive analysis using X-ray diffraction and Raman\nspectroscopy. High-resolution X-ray diffraction studies unveil a significant\ninfluence of surface symmetry on both the substrates and the epitaxial layers,\nparticularly with respect to the occurrence of twins in the superlattices.\nRemarkably, no twins are observed on r-oriented sapphire substrates, resulting\nin improved interface and crystallographic quality. The results of studies\ndemonstrated in this work show that the growth rate of CdO sublayers within\n{CdO/MgO} superlattices is intricately dependent on the substrate orientation.\nNotably, the c-plane and m-plane sapphire substrates yielded thicker CdO\nsublayers, indicating comparable growth rates for these crystallographic\norientations. Conversely, the a-plane and r-plane orientations seemed to favor\na slower growth rate of CdO sublayers.",
    "pdf_url": "http://arxiv.org/pdf/2502.11754v1",
    "published": "2025-02-17T12:50:06+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11753v2",
    "title": "HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real and Synthetic Claims",
    "authors": [
      "Michiel van der Meer",
      "Pavel Korshunov",
      "SÃ©bastien Marcel",
      "Lonneke van der Plas"
    ],
    "abstract": "Misinformation can be countered with fact-checking, but the process is costly\nand slow. Identifying checkworthy claims is the first step, where automation\ncan help scale fact-checkers' efforts. However, detection methods struggle with\ncontent that is (1) multimodal, (2) from diverse domains, and (3) synthetic. We\nintroduce HintsOfTruth, a public dataset for multimodal checkworthiness\ndetection with 27K real-world and synthetic image/claim pairs. The mix of real\nand synthetic data makes this dataset unique and ideal for benchmarking\ndetection methods. We compare fine-tuned and prompted Large Language Models\n(LLMs). We find that well-configured lightweight text-based encoders perform\ncomparably to multimodal models but the former only focus on identifying\nnon-claim-like content. Multimodal LLMs can be more accurate but come at a\nsignificant computational cost, making them impractical for large-scale\napplications. When faced with synthetic data, multimodal models perform more\nrobustly.",
    "pdf_url": "http://arxiv.org/pdf/2502.11753v2",
    "published": "2025-02-17T12:49:55+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11752v1",
    "title": "Early Detection of Human Handover Intentions in Human-Robot Collaboration: Comparing EEG, Gaze, and Hand Motion",
    "authors": [
      "Parag Khanna",
      "Nona Rajabi",
      "Sumeyra U. Demir Kanik",
      "Danica Kragic",
      "MÃ¥rten BjÃ¶rkman",
      "Christian Smith"
    ],
    "abstract": "Human-robot collaboration (HRC) relies on accurate and timely recognition of\nhuman intentions to ensure seamless interactions. Among common HRC tasks,\nhuman-to-robot object handovers have been studied extensively for planning the\nrobot's actions during object reception, assuming the human intention for\nobject handover. However, distinguishing handover intentions from other actions\nhas received limited attention. Most research on handovers has focused on\nvisually detecting motion trajectories, which often results in delays or false\ndetections when trajectories overlap. This paper investigates whether human\nintentions for object handovers are reflected in non-movement-based\nphysiological signals. We conduct a multimodal analysis comparing three data\nmodalities: electroencephalogram (EEG), gaze, and hand-motion signals. Our\nstudy aims to distinguish between handover-intended human motions and\nnon-handover motions in an HRC setting, evaluating each modality's performance\nin predicting and classifying these actions before and after human movement\ninitiation. We develop and evaluate human intention detectors based on these\nmodalities, comparing their accuracy and timing in identifying handover\nintentions. To the best of our knowledge, this is the first study to\nsystematically develop and test intention detectors across multiple modalities\nwithin the same experimental context of human-robot handovers. Our analysis\nreveals that handover intention can be detected from all three modalities.\nNevertheless, gaze signals are the earliest as well as the most accurate to\nclassify the motion as intended for handover or non-handover.",
    "pdf_url": "http://arxiv.org/pdf/2502.11752v1",
    "published": "2025-02-17T12:48:49+00:00",
    "categories": [
      "cs.RO",
      "cs.HC"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11751v1",
    "title": "Language Models Can See Better: Visual Contrastive Decoding For LLM Multimodal Reasoning",
    "authors": [
      "Yuqi Pang",
      "Bowen Yang",
      "Haoqin Tu",
      "Yun Cao",
      "Zeyu Zhang"
    ],
    "abstract": "Although Large Language Models (LLMs) excel in reasoning and generation for\nlanguage tasks, they are not specifically designed for multimodal challenges.\nTraining Multimodal Large Language Models (MLLMs), however, is\nresource-intensive and constrained by various training limitations. In this\npaper, we propose the Modular-based Visual Contrastive Decoding (MVCD)\nframework to move this obstacle. Our framework leverages LLMs' In-Context\nLearning (ICL) capability and the proposed visual contrastive-example decoding\n(CED), specifically tailored for this framework, without requiring any\nadditional training. By converting visual signals into text and focusing on\ncontrastive output distributions during decoding, we can highlight the new\ninformation introduced by contextual examples, explore their connections, and\navoid over-reliance on prior encoded knowledge. MVCD enhances LLMs' visual\nperception to make it see and reason over the input visuals. To demonstrate\nMVCD's effectiveness, we conduct experiments with four LLMs across five\nquestion answering datasets. Our results not only show consistent improvement\nin model accuracy but well explain the effective components inside our decoding\nstrategy. Our code will be available at https://github.com/Pbhgit/MVCD.",
    "pdf_url": "http://arxiv.org/pdf/2502.11751v1",
    "published": "2025-02-17T12:47:00+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2503.16447v1",
    "title": "SHIFT: An Interdisciplinary Framework for Scaffolding Human Attention and Understanding in Explanatory Tasks",
    "authors": [
      "AndrÃ© GroÃ",
      "Birte Richter",
      "Britta Wrede"
    ],
    "abstract": "In this work, we present a domain-independent approach for adaptive\nscaffolding in robotic explanation generation to guide tasks in human-robot\ninteraction. We present a method for incorporating interdisciplinary research\nresults into a computational model as a pre-configured scoring system\nimplemented in a framework called SHIFT. This involves outlining a procedure\nfor integrating concepts from disciplines outside traditional computer science\ninto a robotics computational framework. Our approach allows us to model the\nhuman cognitive state into six observable states within the human partner\nmodel. To study the pre-configuration of the system, we implement a\nreinforcement learning approach on top of our model. This approach allows\nadaptation to individuals who deviate from the configuration of the scoring\nsystem. Therefore, in our proof-of-concept evaluation, the model's adaptability\non four different user types shows that the models' adaptation performs better,\ni.e., recouped faster after exploration and has a higher accumulated reward\nwith our pre-configured scoring system than without it. We discuss further\nstrategies of speeding up the learning phase to enable a realistic adaptation\nbehavior to real users. The system is accessible through docker and supports\nquerying via ROS.",
    "pdf_url": "http://arxiv.org/pdf/2503.16447v1",
    "published": "2025-02-17T12:46:31+00:00",
    "categories": [
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11750v2",
    "title": "Rheological response of soft Solid/Liquid Composites",
    "authors": [
      "Elina Gilbert",
      "Christophe Poulard",
      "Anniina Salonen"
    ],
    "abstract": "Understanding a material's dissipative response is important for their use in\nmany applications, such as adhesion. In dispersions the interplay between\nmatrix and inclusions complicates any description. Fractional rheology is\nconveniently used to fit the storage and loss moduli of complex materials,\nalthough the physical picture is often elusive. We study the rheology of soft\nsolid/liquid composites of liquid poly(ethylene glycol) (PEG) droplets in a\nsoft poly(dimethylsiloxane) (PDMS) matrix. We analyze the influence of the\ndroplets through fractional rheology and a time-concentration superposition.\nViscous dissipation increases proportionally with volume fraction, and we show\nthat a simple, well-fitting model can induce misinterpretation of the physics\nin a complex material.",
    "pdf_url": "http://arxiv.org/pdf/2502.11750v2",
    "published": "2025-02-17T12:46:24+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2502.11749v1",
    "title": "JotlasNet: Joint Tensor Low-Rank and Attention-based Sparse Unrolling Network for Accelerating Dynamic MRI",
    "authors": [
      "Yinghao Zhang",
      "Haiyan Gui",
      "Ningdi Yang",
      "Yue Hu"
    ],
    "abstract": "Joint low-rank and sparse unrolling networks have shown superior performance\nin dynamic MRI reconstruction. However, existing works mainly utilized matrix\nlow-rank priors, neglecting the tensor characteristics of dynamic MRI images,\nand only a global threshold is applied for the sparse constraint to the\nmulti-channel data, limiting the flexibility of the network. Additionally, most\nof them have inherently complex network structure, with intricate interactions\namong variables. In this paper, we propose a novel deep unrolling network,\nJotlasNet, for dynamic MRI reconstruction by jointly utilizing tensor low-rank\nand attention-based sparse priors. Specifically, we utilize tensor low-rank\nprior to exploit the structural correlations in high-dimensional data.\nConvolutional neural networks are used to adaptively learn the low-rank and\nsparse transform domains. A novel attention-based soft thresholding operator is\nproposed to assign a unique learnable threshold to each channel of the data in\nthe CNN-learned sparse domain. The network is unrolled from the elaborately\ndesigned composite splitting algorithm and thus features a simple yet efficient\nparallel structure. Extensive experiments on two datasets (OCMR, CMRxRecon)\ndemonstrate the superior performance of JotlasNet in dynamic MRI\nreconstruction.",
    "pdf_url": "http://arxiv.org/pdf/2502.11749v1",
    "published": "2025-02-17T12:43:04+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.5; I.2.6; I.4.1"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11748v3",
    "title": "ILIAS: Instance-Level Image retrieval At Scale",
    "authors": [
      "Giorgos Kordopatis-Zilos",
      "Vladan StojniÄ",
      "Anna Manko",
      "Pavel Å uma",
      "Nikolaos-Antonios Ypsilantis",
      "Nikos Efthymiadis",
      "Zakaria Laskar",
      "JiÅÃ­ Matas",
      "OndÅej Chum",
      "Giorgos Tolias"
    ],
    "abstract": "This work introduces ILIAS, a new test dataset for Instance-Level Image\nretrieval At Scale. It is designed to evaluate the ability of current and\nfuture foundation models and retrieval techniques to recognize particular\nobjects. The key benefits over existing datasets include large scale, domain\ndiversity, accurate ground truth, and a performance that is far from saturated.\nILIAS includes query and positive images for 1,000 object instances, manually\ncollected to capture challenging conditions and diverse domains. Large-scale\nretrieval is conducted against 100 million distractor images from YFCC100M. To\navoid false negatives without extra annotation effort, we include only query\nobjects confirmed to have emerged after 2014, i.e. the compilation date of\nYFCC100M. An extensive benchmarking is performed with the following\nobservations: i) models fine-tuned on specific domains, such as landmarks or\nproducts, excel in that domain but fail on ILIAS ii) learning a linear\nadaptation layer using multi-domain class supervision results in performance\nimprovements, especially for vision-language models iii) local descriptors in\nretrieval re-ranking are still a key ingredient, especially in the presence of\nsevere background clutter iv) the text-to-image performance of the\nvision-language foundation models is surprisingly close to the corresponding\nimage-to-image case. website: https://vrg.fel.cvut.cz/ilias/",
    "pdf_url": "http://arxiv.org/pdf/2502.11748v3",
    "published": "2025-02-17T12:42:38+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11747v2",
    "title": "Open-Ended and Knowledge-Intensive Video Question Answering",
    "authors": [
      "Md Zarif Ul Alam",
      "Hamed Zamani"
    ],
    "abstract": "Video question answering that requires external knowledge beyond the visual\ncontent remains a significant challenge in AI systems. While models can\neffectively answer questions based on direct visual observations, they often\nfalter when faced with questions requiring broader contextual knowledge. To\naddress this limitation, we investigate knowledge-intensive video question\nanswering (KI-VideoQA) through the lens of multi-modal retrieval-augmented\ngeneration, with a particular focus on handling open-ended questions rather\nthan just multiple-choice formats. Our comprehensive analysis examines various\nretrieval augmentation approaches using cutting-edge retrieval and vision\nlanguage models, testing both zero-shot and fine-tuned configurations. We\ninvestigate several critical dimensions: the interplay between different\ninformation sources and modalities, strategies for integrating diverse\nmulti-modal contexts, and the dynamics between query formulation and retrieval\nresult utilization. Our findings reveal that while retrieval augmentation shows\npromise in improving model performance, its success is heavily dependent on the\nchosen modality and retrieval methodology. The study also highlights the\ncritical role of query construction and retrieval depth optimization in\neffective knowledge integration. Through our proposed approach, we achieve a\nsubstantial 17.5% improvement in accuracy on multiple choice questions in the\nKnowIT VQA dataset, establishing new state-of-the-art performance levels.",
    "pdf_url": "http://arxiv.org/pdf/2502.11747v2",
    "published": "2025-02-17T12:40:35+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11746v1",
    "title": "Dynamic Continuous Variable Quantum Key Distribution for Securing a Future Global Quantum Network",
    "authors": [
      "Mikhael T. Sayat",
      "Sebastian P. Kish",
      "Ping Koy Lam",
      "Nicholas J. Rattenbury",
      "John E. Cater"
    ],
    "abstract": "Continuous variable quantum key distribution (CVQKD) is a developing method\nto secure information exchange in future quantum networks. With the recent\ndevelopments in quantum technology and greater access to space, a global\nquantum network secured by CVQKD could be within reach. In this work, the\nstructures of existing QKD networks are analysed, and how they can be fit into\na general overarching three-layer QKD network architecture for the endeavour of\na global QKD network. Such a network could comprise of different links in fibre\nand free-space. The finite size limit secret key rates (SKRs) with\nmultidimensional reconciliation were calculated for the different links for\nwhich CVQKD can be used in such a network. The results show that CVQKD\ngenerally achieves longer distances and larger SKRs in inter-satellite,\nsatellite-to-ground, fibre, and underwater links in descending order. The\ndifferent links and nodes were classified and secret key distribution was\nstudied as a graph problem. The link capacity, a routing metric for secret key\ndistribution, which considers a dynamic SKR based on dynamic links is\npresented. Its use in simulated CVQKD networks is presented for the aim of\nspatiotemporal secret key distribution through a dynamic CVQKD network.",
    "pdf_url": "http://arxiv.org/pdf/2502.11746v1",
    "published": "2025-02-17T12:39:12+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11745v1",
    "title": "Understanding RowHammer Under Reduced Refresh Latency: Experimental Analysis of Real DRAM Chips and Implications on Future Solutions",
    "authors": [
      "Yahya Can TuÄrul",
      "A. Giray YaÄlÄ±kÃ§Ä±",
      "Ä°smail Emir YÃ¼ksel",
      "Ataberk Olgun",
      "OÄuzhan Canpolat",
      "Nisa BostancÄ±",
      "Mohammad Sadrosadati",
      "OÄuz Ergin",
      "Onur Mutlu"
    ],
    "abstract": "RowHammer is a major read disturbance mechanism in DRAM where repeatedly\naccessing (hammering) a row of DRAM cells (DRAM row) induces bitflips in\nphysically nearby DRAM rows (victim rows). To ensure robust DRAM operation,\nstate-of-the-art mitigation mechanisms restore the charge in potential victim\nrows (i.e., they perform preventive refresh or charge restoration). With newer\nDRAM chip generations, these mechanisms perform preventive refresh more\naggressively and cause larger performance, energy, or area overheads.\nTherefore, it is essential to develop a better understanding and in-depth\ninsights into the preventive refresh to secure real DRAM chips at low cost. In\nthis paper, our goal is to mitigate RowHammer at low cost by understanding the\nimpact of reduced preventive refresh latency on RowHammer. To this end, we\npresent the first rigorous experimental study on the interactions between\nrefresh latency and RowHammer characteristics in real DRAM chips. Our\nexperimental characterization using 388 real DDR4 DRAM chips from three major\nmanufacturers demonstrates that a preventive refresh latency can be\nsignificantly reduced (by 64%). To investigate the impact of reduced preventive\nrefresh latency on system performance and energy efficiency, we reduce the\npreventive refresh latency and adjust the aggressiveness of existing RowHammer\nsolutions by developing a new mechanism, Partial Charge Restoration for\nAggressive Mitigation (PaCRAM). Our results show that PaCRAM reduces the\nperformance and energy overheads induced by five state-of-the-art RowHammer\nmitigation mechanisms with small additional area overhead. Thus, PaCRAM\nintroduces a novel perspective into addressing RowHammer vulnerability at low\ncost by leveraging our experimental observations. To aid future research, we\nopen-source our PaCRAM implementation at https://github.com/CMU-SAFARI/PaCRAM.",
    "pdf_url": "http://arxiv.org/pdf/2502.11745v1",
    "published": "2025-02-17T12:39:03+00:00",
    "categories": [
      "cs.AR",
      "cs.CR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12221v1",
    "title": "ReF Decompile: Relabeling and Function Call Enhanced Decompile",
    "authors": [
      "Yunlong Feng",
      "Bohan Li",
      "Xiaoming Shi",
      "Qingfu Zhu",
      "Wanxiang Che"
    ],
    "abstract": "The goal of decompilation is to convert compiled low-level code (e.g.,\nassembly code) back into high-level programming languages, enabling analysis in\nscenarios where source code is unavailable. This task supports various reverse\nengineering applications, such as vulnerability identification, malware\nanalysis, and legacy software migration. The end-to-end decompile method based\non large langauge models (LLMs) reduces reliance on additional tools and\nminimizes manual intervention due to its inherent properties. However, previous\nend-to-end methods often lose critical information necessary for reconstructing\ncontrol flow structures and variables when processing binary files, making it\nchallenging to accurately recover the program's logic. To address these issues,\nwe propose the \\textbf{ReF Decompile} method, which incorporates the following\ninnovations: (1) The Relabelling strategy replaces jump target addresses with\nlabels, preserving control flow clarity. (2) The Function Call strategy infers\nvariable types and retrieves missing variable information from binary files.\nExperimental results on the Humaneval-Decompile Benchmark demonstrate that ReF\nDecompile surpasses comparable baselines and achieves state-of-the-art (SOTA)\nperformance of $61.43\\%$.",
    "pdf_url": "http://arxiv.org/pdf/2502.12221v1",
    "published": "2025-02-17T12:38:57+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2503.00014v1",
    "title": "LSD of the Commutator of two data Matrices",
    "authors": [
      "Javed Hazarika",
      "Debashis Paul"
    ],
    "abstract": "We study the spectral properties of a class of random matrices of the form\n$S_n^{-} = n^{-1}(X_1 X_2^* - X_2 X_1^*)$ where $X_k = \\Sigma_k^{1/2}Z_k$,\n$Z_k$'s are independent $p\\times n$ complex-valued random matrices, and\n$\\Sigma_k$ are $p\\times p$ positive semi-definite matrices that commute and are\nindependent of the $Z_k$'s for $k=1,2$. We assume that $Z_k$'s have independent\nentries with zero mean and unit variance. The skew-symmetric/skew-Hermitian\nmatrix $S_n^{-}$ will be referred to as a random commutator matrix associated\nwith the samples $X_1$ and $X_2$. We show that, when the dimension $p$ and\nsample size $n$ increase simultaneously, so that $p/n \\to c \\in (0,\\infty)$,\nthere exists a limiting spectral distribution (LSD) for $S_n^{-}$, supported on\nthe imaginary axis, under the assumptions that the joint spectral distribution\nof $\\Sigma_1, \\Sigma_2$ converges weakly and the entries of $Z_k$'s have\nmoments of sufficiently high order. This nonrandom LSD can be described through\nits Stieltjes transform, which satisfies a system of Mar\\v{c}enko-Pastur-type\nfunctional equations. Moreover, we show that the companion matrix $S_n^{+} =\nn^{-1}(X_1X_2^* + X_2X_1^*)$, under identical assumptions, has an LSD supported\non the real line, which can be similarly characterized.",
    "pdf_url": "http://arxiv.org/pdf/2503.00014v1",
    "published": "2025-02-17T12:35:32+00:00",
    "categories": [
      "math.ST",
      "math.PR",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2502.11744v2",
    "title": "FUNCTO: Function-Centric One-Shot Imitation Learning for Tool Manipulation",
    "authors": [
      "Chao Tang",
      "Anxing Xiao",
      "Yuhong Deng",
      "Tianrun Hu",
      "Wenlong Dong",
      "Hanbo Zhang",
      "David Hsu",
      "Hong Zhang"
    ],
    "abstract": "Learning tool use from a single human demonstration video offers a highly\nintuitive and efficient approach to robot teaching. While humans can\neffortlessly generalize a demonstrated tool manipulation skill to diverse tools\nthat support the same function (e.g., pouring with a mug versus a teapot),\ncurrent one-shot imitation learning (OSIL) methods struggle to achieve this. A\nkey challenge lies in establishing functional correspondences between\ndemonstration and test tools, considering significant geometric variations\namong tools with the same function (i.e., intra-function variations). To\naddress this challenge, we propose FUNCTO (Function-Centric OSIL for Tool\nManipulation), an OSIL method that establishes function-centric correspondences\nwith a 3D functional keypoint representation, enabling robots to generalize\ntool manipulation skills from a single human demonstration video to novel tools\nwith the same function despite significant intra-function variations. With this\nformulation, we factorize FUNCTO into three stages: (1) functional keypoint\nextraction, (2) function-centric correspondence establishment, and (3)\nfunctional keypoint-based action planning. We evaluate FUNCTO against exiting\nmodular OSIL methods and end-to-end behavioral cloning methods through\nreal-robot experiments on diverse tool manipulation tasks. The results\ndemonstrate the superiority of FUNCTO when generalizing to novel tools with\nintra-function geometric variations. More details are available at\nhttps://sites.google.com/view/functo.",
    "pdf_url": "http://arxiv.org/pdf/2502.11744v2",
    "published": "2025-02-17T12:34:42+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11743v1",
    "title": "Robust Partial-Label Learning by Leveraging Class Activation Values",
    "authors": [
      "Tobias Fuchs",
      "Florian Kalinke"
    ],
    "abstract": "Real-world training data is often noisy; for example, human annotators assign\nconflicting class labels to the same instances. Partial-label learning (PLL) is\na weakly supervised learning paradigm that allows training classifiers in this\ncontext without manual data cleaning. While state-of-the-art methods have good\npredictive performance, their predictions are sensitive to high noise levels,\nout-of-distribution data, and adversarial perturbations. We propose a novel PLL\nmethod based on subjective logic, which explicitly represents uncertainty by\nleveraging the magnitudes of the underlying neural network's class activation\nvalues. Thereby, we effectively incorporate prior knowledge about the class\nlabels by using a novel label weight re-distribution strategy that we prove to\nbe optimal. We empirically show that our method yields more robust predictions\nin terms of predictive performance under high PLL noise levels, handling\nout-of-distribution examples, and handling adversarial perturbations on the\ntest instances.",
    "pdf_url": "http://arxiv.org/pdf/2502.11743v1",
    "published": "2025-02-17T12:30:05+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11742v2",
    "title": "Range and Bird's Eye View Fused Cross-Modal Visual Place Recognition",
    "authors": [
      "Jianyi Peng",
      "Fan Lu",
      "Bin Li",
      "Yuan Huang",
      "Sanqing Qu",
      "Guang Chen"
    ],
    "abstract": "Image-to-point cloud cross-modal Visual Place Recognition (VPR) is a\nchallenging task where the query is an RGB image, and the database samples are\nLiDAR point clouds. Compared to single-modal VPR, this approach benefits from\nthe widespread availability of RGB cameras and the robustness of point clouds\nin providing accurate spatial geometry and distance information. However,\ncurrent methods rely on intermediate modalities that capture either the\nvertical or horizontal field of view, limiting their ability to fully exploit\nthe complementary information from both sensors. In this work, we propose an\ninnovative initial retrieval + re-rank method that effectively combines\ninformation from range (or RGB) images and Bird's Eye View (BEV) images. Our\napproach relies solely on a computationally efficient global descriptor\nsimilarity search process to achieve re-ranking. Additionally, we introduce a\nnovel similarity label supervision technique to maximize the utility of limited\ntraining data. Specifically, we employ points average distance to approximate\nappearance similarity and incorporate an adaptive margin, based on similarity\ndifferences, into the vanilla triplet loss. Experimental results on the KITTI\ndataset demonstrate that our method significantly outperforms state-of-the-art\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.11742v2",
    "published": "2025-02-17T12:29:26+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11741v3",
    "title": "SQL-o1: A Self-Reward Heuristic Dynamic Search Method for Text-to-SQL",
    "authors": [
      "Shuai Lyu",
      "Haoran Luo",
      "Ripeng Li",
      "Zhonghong Ou",
      "Jiangfeng Sun",
      "Yang Qin",
      "Xiaoran Shang",
      "Meina Song",
      "Yifan Zhu"
    ],
    "abstract": "Text-to-SQL (Text2SQL) aims to map natural language questions to executable\nSQL queries. Although large language models (LLMs) have driven significant\nprogress, current approaches struggle with poor transferability to open-source\nLLMs, limited robustness against logic and function errors in complex queries,\nand inefficiencies in structured search. We introduce SQL-o1, a\nself-reward-driven heuristic search framework built on an agent-based\narchitecture to enhance model reasoning capabilities. SQL-o1 leverages Monte\nCarlo Tree Search (MCTS) for structured, multi-step exploration, and\nincorporates a dynamic pruning strategy to accelerate inference without\nsacrificing accuracy. On the Spider and Bird benchmarks, SQL-o1 achieves a\n+10.8 execution accuracy improvement on the complex Bird dataset, surpassing\neven GPT-4-based models. Notably, it exhibits strong few-shot generalization\nand robust cross-model transferability across open-source LLMs. Our code is\navailable at:https://github.com/ShuaiLyu0110/SQL-o1.",
    "pdf_url": "http://arxiv.org/pdf/2502.11741v3",
    "published": "2025-02-17T12:28:11+00:00",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2502.11740v1",
    "title": "Mitigating Visual Knowledge Forgetting in MLLM Instruction-tuning via Modality-decoupled Gradient Descent",
    "authors": [
      "Junda Wu",
      "Yuxin Xiong",
      "Xintong Li",
      "Yu Xia",
      "Ruoyu Wang",
      "Yu Wang",
      "Tong Yu",
      "Sungchul Kim",
      "Ryan A. Rossi",
      "Lina Yao",
      "Jingbo Shang",
      "Julian McAuley"
    ],
    "abstract": "Recent MLLMs have shown emerging visual understanding and reasoning abilities\nafter being pre-trained on large-scale multimodal datasets. Unlike\npre-training, where MLLMs receive rich visual-text alignment,\ninstruction-tuning is often text-driven with weaker visual supervision, leading\nto the degradation of pre-trained visual understanding and causing visual\nforgetting. Existing approaches, such as direct fine-tuning and continual\nlearning methods, fail to explicitly address this issue, often compressing\nvisual representations and prioritizing task alignment over visual retention,\nwhich further worsens visual forgetting. To overcome this limitation, we\nintroduce a novel perspective leveraging effective rank to quantify the\ndegradation of visual representation richness, interpreting this degradation\nthrough the information bottleneck principle as excessive compression that\nleads to the degradation of crucial pre-trained visual knowledge. Building on\nthis view, we propose a modality-decoupled gradient descent (MDGD) method that\nregulates gradient updates to maintain the effective rank of visual\nrepresentations while mitigating the over-compression effects described by the\ninformation bottleneck. By explicitly disentangling the optimization of visual\nunderstanding from task-specific alignment, MDGD preserves pre-trained visual\nknowledge while enabling efficient task adaptation. To enable lightweight\ninstruction-tuning, we further develop a memory-efficient fine-tuning approach\nusing gradient masking, which selectively updates a subset of model parameters\nto enable parameter-efficient fine-tuning (PEFT), reducing computational\noverhead while preserving rich visual representations. Extensive experiments\nacross various downstream tasks and backbone MLLMs demonstrate that MDGD\neffectively mitigates visual forgetting from pre-trained tasks while enabling\nstrong adaptation to new tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11740v1",
    "published": "2025-02-17T12:26:34+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11739v2",
    "title": "The structure of weakly stable CMC hypersurfaces with free boundary",
    "authors": [
      "Jia Li"
    ],
    "abstract": "In this paper, we prove that a complete noncompact weakly stable free\nboundary CMC $H$-hypersurface $(M^{n},\\partial M)$ properly immersed in $(N^\n{n+1},\\partial N)$ must have one end, provided that $N$ has bounded geometry\nand weakly convex boundary, satisfies $\\inf\\Ric_{N}>-\\frac{1}{n}H^2$ and\n$\\biRic_{N}\\geq \\frac{(n-5)}{4}H^2$. Secondly, we establish a non-existence\nresult for noncompact free boundary CMC hypersurfaces under certain conditions,\nas detailed in Theorem \\ref{thm 4}. Finally, we give a rigidity theorem for\nfree boundary minimal hypersurfaces in $5$-manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2502.11739v2",
    "published": "2025-02-17T12:24:58+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11738v1",
    "title": "Surrogate-based ABC matches generalized Bayesian inference under specific discrepancy and kernel choices",
    "authors": [
      "Marko JÃ¤rvenpÃ¤Ã¤",
      "Jukka Corander",
      "Henri Pesonen"
    ],
    "abstract": "Generalized Bayesian inference (GBI) is an alternative inference framework\nmotivated by robustness to modeling errors, where a specific loss function is\nused to link the model parameters with observed data, instead of the\nlog-likelihood used in standard Bayesian inference. Approximate Bayesian\nComputation (ABC) refers in turn to a family of methods approximating the\nposterior distribution via a discrepancy function between the observed and\nsimulated data instead of using the likelihood. In this paper we discuss the\nconnection between ABC and GBI, when the loss function is defined as an\nexpected discrepancy between the observed and simulated data from the model\nunder consideration. We show that the resulting generalized posterior\ncorresponds to an ABC-posterior when the latter is obtained under a Gaussian\nprocess -based surrogate model. We illustrate the behavior of the\napproximations as a function of specific discrepancy and kernel choices to\nprovide insights of the relationships between these different approximate\ninference paradigms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11738v1",
    "published": "2025-02-17T12:23:56+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.11737v1",
    "title": "2FA: Navigating the Challenges and Solutions for Inclusive Access",
    "authors": [
      "Alexander Lengert"
    ],
    "abstract": "The digital age requires strong security measures to protect online\nactivities. Two-Factor Authentication (2FA) has emerged as a critical solution.\nHowever, its implementation presents significant challenges, particularly in\nterms of accessibility for people with disabilities. This paper examines the\nintricacies of deploying 2FA in a way that is secure and accessible to all\nusers by outlining the concrete challenges for people who are affected by\nvarious types of impairments. This research investigates the implications of\n2FA on digital inclusivity and proposes solutions to enhance accessibility. An\nanalysis was conducted to examine the implementation and availability of\nvarious 2FA methods across popular online platforms. The results reveal a\ndiverse landscape of authentication strategies. While 2FA significantly\nimproves account security, its current adoption is hampered by inconsistencies\nacross platforms and a lack of standardised, accessible options for users with\ndisabilities. Future advancements in 2FA technologies, including but not\nlimited to autofill capabilities and the adoption of Fast IDentity Onlines\n(FIDO) protocols, offer possible directions for more inclusive authentication\nmechanisms. However, ongoing research is necessary to address the evolving\nneeds of users with disabilities and to mitigate new security challenges. This\npaper proposes a collaborative approach among stakeholders to ensure that\nsecurity improvements do not compromise accessibility. It promotes a digital\nenvironment where security and inclusivity mutually reinforce each other.",
    "pdf_url": "http://arxiv.org/pdf/2502.11737v1",
    "published": "2025-02-17T12:23:53+00:00",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.HC",
      "68M11, 68M12, 94A60, 94A62",
      "H.1.2; H.4; K.4; K.6; C.2"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11736v3",
    "title": "ReviewEval: An Evaluation Framework for AI-Generated Reviews",
    "authors": [
      "Madhav Krishan Garg",
      "Tejash Prasad",
      "Tanmay Singhal",
      "Chhavi Kirtani",
      "Murari Mandal",
      "Dhruv Kumar"
    ],
    "abstract": "The escalating volume of academic research, coupled with a shortage of\nqualified reviewers, necessitates innovative approaches to peer review. In this\nwork, we propose: 1. ReviewEval, a comprehensive evaluation framework for\nAI-generated reviews that measures alignment with human assessments, verifies\nfactual accuracy, assesses analytical depth, identifies degree of\nconstructiveness and adherence to reviewer guidelines; and 2. ReviewAgent, an\nLLM-based review generation agent featuring a novel alignment mechanism to\ntailor feedback to target conferences and journals, along with a\nself-refinement loop that iteratively optimizes its intermediate outputs and an\nexternal improvement loop using ReviewEval to improve upon the final reviews.\nReviewAgent improves actionable insights by 6.78% and 47.62% over existing AI\nbaselines and expert reviews respectively. Further, it boosts analytical depth\nby 3.97% and 12.73%, enhances adherence to guidelines by 10.11% and 47.26%\nrespectively. This paper establishes essential metrics for AIbased peer review\nand substantially enhances the reliability and impact of AI-generated reviews\nin academic research.",
    "pdf_url": "http://arxiv.org/pdf/2502.11736v3",
    "published": "2025-02-17T12:22:11+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12220v2",
    "title": "A thermal Green-Naghdi model with time dependent bathymetry and complete Coriolis force",
    "authors": [
      "Darryl D. Holm",
      "Oliver D. Street"
    ],
    "abstract": "This paper extends the theoretical Euler-Poincar\\'e framework for modelling\nocean mixed layer dynamics. Through a symmetry-broken Lie group invariant\nvariational principle, we derive a generalised Green-Naghdi equation with time\ndependent bathymetry, a complete Coriolis force, and inhomogeneity of the\nthermal buoyancy. The nature of the model derived here lends it a potential\nfuture application to wave dynamics generated by changes to the bathymetry.",
    "pdf_url": "http://arxiv.org/pdf/2502.12220v2",
    "published": "2025-02-17T12:21:43+00:00",
    "categories": [
      "physics.ao-ph",
      "physics.flu-dyn",
      "37K58 (Primary) 76U60, 37N10 (Secondary)"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11734v1",
    "title": "Implementation of a high-efficiency muon veto system for the GeSparK alpha-beta/gamma coincidence detector",
    "authors": [
      "A. Barresi",
      "D. Chiesa",
      "M. Nastasi",
      "E. Previtali",
      "M. Sisti"
    ],
    "abstract": "One of the main background sources of low background high purity germanium\n(HPGe) detectors is the cosmic muon showers produced in the interaction with\nthe lead and copper shield surrounding the detector that can induce signals not\ndistinguishable from radioactivity events. Plastic scintillators are widely\nused to implement active veto systems to reduce this contribution and increase\nthe measurement sensitivity. In this work, we present the implementation of a\nhigh-efficiency muon veto system for the alpha-beta/gamma coincidence detector,\ncalled GeSparK. The veto system consists of six plastic scintillator detectors\naccurately positioned around the HPGe and liquid scintillator detectors. The\nfinal design includes two detectors above and four inside the passive shielding\nbetween the copper and lead layers. In this way, we could limit both their size\nand the event rate produced by external radioactivity. A dedicated background\nmeasurement showed that the achieved background reduction is a bit less than\n93%.",
    "pdf_url": "http://arxiv.org/pdf/2502.11734v1",
    "published": "2025-02-17T12:21:13+00:00",
    "categories": [
      "physics.ins-det"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2502.11735v3",
    "title": "MT-RAIG: Novel Benchmark and Evaluation Framework for Retrieval-Augmented Insight Generation over Multiple Tables",
    "authors": [
      "Kwangwook Seo",
      "Donguk Kwon",
      "Dongha Lee"
    ],
    "abstract": "Recent advancements in table-based reasoning have expanded beyond\nfactoid-level QA to address insight-level tasks, where systems should\nsynthesize implicit knowledge in the table to provide explainable analyses.\nAlthough effective, existing studies remain confined to scenarios where a\nsingle gold table is given alongside the user query, failing to address cases\nwhere users seek comprehensive insights from multiple unknown tables. To bridge\nthese gaps, we propose MT-RAIG Bench, design to evaluate systems on\nRetrieval-Augmented Insight Generation over Mulitple-Tables. Additionally, to\ntackle the suboptimality of existing automatic evaluation methods in the table\ndomain, we further introduce a fine-grained evaluation framework MT-RAIG Eval,\nwhich achieves better alignment with human quality judgments on the generated\ninsights. We conduct extensive experiments and reveal that even frontier LLMs\nstill struggle with complex multi-table reasoning, establishing our MT-RAIG\nBench as a challenging testbed for future research.",
    "pdf_url": "http://arxiv.org/pdf/2502.11735v3",
    "published": "2025-02-17T12:21:13+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11733v3",
    "title": "Plant in Cupboard, Orange on Rably, Inat Aphone. Benchmarking Incremental Learning of Situation and Language Model using a Text-Simulated Situated Environment",
    "authors": [
      "Jonathan Jordan",
      "Sherzod Hakimov",
      "David Schlangen"
    ],
    "abstract": "Large Language Models (LLMs) serve not only as chatbots but as key components\nin agent systems, where their common-sense knowledge significantly impacts\nperformance as language-based planners for situated or embodied action. We\nassess LLMs' incremental learning (based on feedback from the environment), and\ncontrolled in-context learning abilities using a text-based environment. We\nintroduce challenging yet interesting set of experiments to test i) how agents\ncan incrementally solve tasks related to every day objects in typical rooms in\na house where each of them are discovered by interacting within the\nenvironment, ii) controlled in-context learning abilities and efficiency of\nagents by providing short info about locations of objects and rooms to check\nhow faster the task can be solved, and finally iii) using synthetic\npseudo-English words to gauge how well LLMs are at inferring meaning of unknown\nwords from environmental feedback. Results show that larger commercial models\nhave a substantial gap in performance compared to open-weight but almost all\nmodels struggle with the synthetic words experiments.",
    "pdf_url": "http://arxiv.org/pdf/2502.11733v3",
    "published": "2025-02-17T12:20:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11732v2",
    "title": "Quantum inequalities and their applications",
    "authors": [
      "Linzhe Huang"
    ],
    "abstract": "In recent years, various quantum inequalities have been established on\nquantum symmetries in the framework of quantum Fourier analysis. We provide a\ndetailed introduction to quantum inequalities including Hausdorff-Young\ninequality, Young's inequality, uncertainty principles, entropic convolution\ninequalities etc on subfactors, an important type of quantum symmetries. We\ncite several applications of the complete positivity of the comultiplication in\ncategory theory and subfactor theory, which indicate the fundamental\ndifferences between quantum inequalities and non-commutative inequalities. We\nalso review the Perron-Frobenius theorem together with the algebraic structures\nof eigenvector spaces.",
    "pdf_url": "http://arxiv.org/pdf/2502.11732v2",
    "published": "2025-02-17T12:20:36+00:00",
    "categories": [
      "math.OA",
      "46L37, 43A30"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11731v1",
    "title": "GraphMorph: Tubular Structure Extraction by Morphing Predicted Graphs",
    "authors": [
      "Zhao Zhang",
      "Ziwei Zhao",
      "Dong Wang",
      "Liwei Wang"
    ],
    "abstract": "Accurately restoring topology is both challenging and crucial in tubular\nstructure extraction tasks, such as blood vessel segmentation and road network\nextraction. Diverging from traditional approaches based on pixel-level\nclassification, our proposed method, named GraphMorph, focuses on branch-level\nfeatures of tubular structures to achieve more topologically accurate\npredictions. GraphMorph comprises two main components: a Graph Decoder and a\nMorph Module. Utilizing multi-scale features extracted from an image patch by\nthe segmentation network, the Graph Decoder facilitates the learning of\nbranch-level features and generates a graph that accurately represents the\ntubular structure in this patch. The Morph Module processes two primary inputs:\nthe graph and the centerline probability map, provided by the Graph Decoder and\nthe segmentation network, respectively. Employing a novel SkeletonDijkstra\nalgorithm, the Morph Module produces a centerline mask that aligns with the\npredicted graph. Furthermore, we observe that employing centerline masks\npredicted by GraphMorph significantly reduces false positives in the\nsegmentation task, which is achieved by a simple yet effective post-processing\nstrategy. The efficacy of our method in the centerline extraction and\nsegmentation tasks has been substantiated through experimental evaluations\nacross various datasets. Source code will be released soon.",
    "pdf_url": "http://arxiv.org/pdf/2502.11731v1",
    "published": "2025-02-17T12:18:24+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11730v1",
    "title": "Time crystal optomechanics",
    "authors": [
      "J. T. MÃ¤kinen",
      "P. J. Heikkinen",
      "S. Autti",
      "V. V. Zavjalov",
      "V. B. Eltsov"
    ],
    "abstract": "Time crystals are an enigmatic phase of matter in which a quantum mechanical\nsystem displays repetitive, observable motion - they spontaneously break the\ntime translation symmetry. On the other hand optomechanical systems, where\nmechanical and optical degrees of freedom are coupled, are well established and\nenable a range of applications and measurements with unparalleled precision.\nHere, we connect a time crystal formed of magnetic quasiparticles, magnons, to\na mechanical resonator, a gravity wave mode on a nearby liquid surface, and\nshow that their joint dynamics evolves as a cavity optomechanical system. Our\nresults pave way for exploiting the spontaneous coherence of time crystals in\nan optomechanical setting and remove the experimental barrier between time\ncrystals and other phases of condensed matter.",
    "pdf_url": "http://arxiv.org/pdf/2502.11730v1",
    "published": "2025-02-17T12:14:21+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.other",
      "cond-mat.quant-gas"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11729v1",
    "title": "On Quantizing Neural Representation for Variable-Rate Video Coding",
    "authors": [
      "Junqi Shi",
      "Zhujia Chen",
      "Hanfei Li",
      "Qi Zhao",
      "Ming Lu",
      "Tong Chen",
      "Zhan Ma"
    ],
    "abstract": "This work introduces NeuroQuant, a novel post-training quantization (PTQ)\napproach tailored to non-generalized Implicit Neural Representations for\nvariable-rate Video Coding (INR-VC). Unlike existing methods that require\nextensive weight retraining for each target bitrate, we hypothesize that\nvariable-rate coding can be achieved by adjusting quantization parameters (QPs)\nof pre-trained weights. Our study reveals that traditional quantization\nmethods, which assume inter-layer independence, are ineffective for\nnon-generalized INR-VC models due to significant dependencies across layers. To\naddress this, we redefine variable-rate INR-VC as a mixed-precision\nquantization problem and establish a theoretical framework for sensitivity\ncriteria aimed at simplified, fine-grained rate control. Additionally, we\npropose network-wise calibration and channel-wise quantization strategies to\nminimize quantization-induced errors, arriving at a unified formula for\nrepresentation-oriented PTQ calibration. Our experimental evaluations\ndemonstrate that NeuroQuant significantly outperforms existing techniques in\nvarying bitwidth quantization and compression efficiency, accelerating encoding\nby up to eight times and enabling quantization down to INT2 with minimal\nreconstruction loss. This work introduces variable-rate INR-VC for the first\ntime and lays a theoretical foundation for future research in rate-distortion\noptimization, advancing the field of video coding technology. The materials\nwill be available at https://github.com/Eric-qi/NeuroQuant.",
    "pdf_url": "http://arxiv.org/pdf/2502.11729v1",
    "published": "2025-02-17T12:13:21+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11728v1",
    "title": "Matrix Low-dimensional Qubit Casting Based Quantum Electromagnetic Transient Network Simulation Program",
    "authors": [
      "Qi Lou",
      "Yijun Xu",
      "Wei Gu"
    ],
    "abstract": "In modern power systems, the integration of converter-interfaced generations\nrequires the development of electromagnetic transient network simulation\nprograms (EMTP) that can capture rapid fluctuations. However, as the power\nsystem scales, the EMTP's computing complexity increases exponentially, leading\nto a curse of dimensionality that hinders its practical application. Facing\nthis challenge, quantum computing offers a promising approach for achieving\nexponential acceleration. To realize this in noisy intermediate-scale quantum\ncomputers, the variational quantum linear solution (VQLS) was advocated because\nof its robustness against depolarizing noise. However, it suffers data\ninflation issues in its preprocessing phase, and no prior research has applied\nquantum computing to high-frequency switching EMT networks.To address these\nissues, this paper first designs the matrix low-dimension qubit casting (MLQC)\nmethod to address the data inflation problem in the preprocessing of the\nadmittance matrix for VQLS in EMT networks. Besides, we propose a real-only\nquantum circuit reduction method tailored to the characteristics of the EMT\nnetwork admittance matrices. Finally, the proposed quantum EMTP algorithm\n(QEMTP) has been successfully verified for EMT networks containing a large\nnumber of high-frequency switching elements.",
    "pdf_url": "http://arxiv.org/pdf/2502.11728v1",
    "published": "2025-02-17T12:13:20+00:00",
    "categories": [
      "quant-ph",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11727v1",
    "title": "T-calibration in semi-parametric models",
    "authors": [
      "Anja MÃ¼hlemann",
      "Johanna Ziegel"
    ],
    "abstract": "This note relates the calibration of models to the consistent loss functions\nfor the target functional of the model. We demonstrate that a model is\ncalibrated if and only if there is a parameter value that is optimal under all\nconsistent loss functions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11727v1",
    "published": "2025-02-17T12:12:17+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2502.11726v1",
    "title": "No-reference geometry quality assessment for colorless point clouds via list-wise rank learning",
    "authors": [
      "Zheng Li",
      "Bingxu Xie",
      "Chao Chu",
      "Weiqing Li",
      "Zhiyong Su"
    ],
    "abstract": "Geometry quality assessment (GQA) of colorless point clouds is crucial for\nevaluating the performance of emerging point cloud-based solutions (e.g.,\nwatermarking, compression, and 3-Dimensional (3D) reconstruction).\nUnfortunately, existing objective GQA approaches are traditional full-reference\nmetrics, whereas state-of-the-art learning-based point cloud quality assessment\n(PCQA) methods target both color and geometry distortions, neither of which are\nqualified for the no-reference GQA task. In addition, the lack of large-scale\nGQA datasets with subjective scores, which are always imprecise, biased, and\ninconsistent, also hinders the development of learning-based GQA metrics.\nDriven by these limitations, this paper proposes a no-reference geometry-only\nquality assessment approach based on list-wise rank learning, termed LRL-GQA,\nwhich comprises of a geometry quality assessment network (GQANet) and a\nlist-wise rank learning network (LRLNet). The proposed LRL-GQA formulates the\nno-reference GQA as a list-wise rank problem, with the objective of directly\noptimizing the entire quality ordering. Specifically, a large dataset\ncontaining a variety of geometry-only distortions is constructed first, named\nLRL dataset, in which each sample is label-free but coupled with quality\nranking information. Then, the GQANet is designed to capture intrinsic\nmulti-scale patch-wise geometric features in order to predict a quality index\nfor each point cloud. After that, the LRLNet leverages the LRL dataset and a\nlikelihood loss to train the GQANet and ranks the input list of degraded point\nclouds according to their distortion levels. In addition, the pre-trained\nGQANet can be fine-tuned further to obtain absolute quality scores.\nExperimental results demonstrate the superior performance of the proposed\nno-reference LRL-GQA method compared with existing full-reference GQA metrics.",
    "pdf_url": "http://arxiv.org/pdf/2502.11726v1",
    "published": "2025-02-17T12:11:56+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11725v1",
    "title": "Adversarially Robust CLIP Models Can Induce Better (Robust) Perceptual Metrics",
    "authors": [
      "Francesco Croce",
      "Christian Schlarmann",
      "Naman Deep Singh",
      "Matthias Hein"
    ],
    "abstract": "Measuring perceptual similarity is a key tool in computer vision. In recent\nyears perceptual metrics based on features extracted from neural networks with\nlarge and diverse training sets, e.g. CLIP, have become popular. At the same\ntime, the metrics extracted from features of neural networks are not\nadversarially robust. In this paper we show that adversarially robust CLIP\nmodels, called R-CLIP$_\\textrm{F}$, obtained by unsupervised adversarial\nfine-tuning induce a better and adversarially robust perceptual metric that\noutperforms existing metrics in a zero-shot setting, and further matches the\nperformance of state-of-the-art metrics while being robust after fine-tuning.\nMoreover, our perceptual metric achieves strong performance on related tasks\nsuch as robust image-to-image retrieval, which becomes especially relevant when\napplied to \"Not Safe for Work\" (NSFW) content detection and dataset filtering.\nWhile standard perceptual metrics can be easily attacked by a small\nperturbation completely degrading NSFW detection, our robust perceptual metric\nmaintains high accuracy under an attack while having similar performance for\nunperturbed images. Finally, perceptual metrics induced by robust CLIP models\nhave higher interpretability: feature inversion can show which images are\nconsidered similar, while text inversion can find what images are associated to\na given prompt. This also allows us to visualize the very rich visual concepts\nlearned by a CLIP model, including memorized persons, paintings and complex\nqueries.",
    "pdf_url": "http://arxiv.org/pdf/2502.11725v1",
    "published": "2025-02-17T12:11:01+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11724v1",
    "title": "Incomplete Modality Disentangled Representation for Ophthalmic Disease Grading and Diagnosis",
    "authors": [
      "Chengzhi Liu",
      "Zile Huang",
      "Zhe Chen",
      "Feilong Tang",
      "Yu Tian",
      "Zhongxing Xu",
      "Zihong Luo",
      "Yalin Zheng",
      "Yanda Meng"
    ],
    "abstract": "Ophthalmologists typically require multimodal data sources to improve\ndiagnostic accuracy in clinical decisions. However, due to medical device\nshortages, low-quality data and data privacy concerns, missing data modalities\nare common in real-world scenarios. Existing deep learning methods tend to\naddress it by learning an implicit latent subspace representation for different\nmodality combinations. We identify two significant limitations of these\nmethods: (1) implicit representation constraints that hinder the model's\nability to capture modality-specific information and (2) modality\nheterogeneity, causing distribution gaps and redundancy in feature\nrepresentations. To address these, we propose an Incomplete Modality\nDisentangled Representation (IMDR) strategy, which disentangles features into\nexplicit independent modal-common and modal-specific features by guidance of\nmutual information, distilling informative knowledge and enabling it to\nreconstruct valuable missing semantics and produce robust multimodal\nrepresentations. Furthermore, we introduce a joint proxy learning module that\nassists IMDR in eliminating intra-modality redundancy by exploiting the\nextracted proxies from each class. Experiments on four ophthalmology multimodal\ndatasets demonstrate that the proposed IMDR outperforms the state-of-the-art\nmethods significantly.",
    "pdf_url": "http://arxiv.org/pdf/2502.11724v1",
    "published": "2025-02-17T12:10:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11723v1",
    "title": "Energy-Conscious LLM Decoding: Impact of Text Generation Strategies on GPU Energy Consumption",
    "authors": [
      "Alireza Nik",
      "Michael A. Riegler",
      "PÃ¥l Halvorsen"
    ],
    "abstract": "Decoding strategies significantly influence the quality and diversity of the\ngenerated texts in large language models (LLMs), yet their impact on\ncomputational resource consumption, particularly GPU energy usage, is\ninsufficiently studied. This paper investigates the relationship between text\ngeneration decoding methods and energy efficiency, focusing on the trade-off\nbetween generation quality and GPU energy consumption across diverse tasks and\ndecoding configurations. By benchmarking multiple strategies across different\ntext generation tasks, such as Translation, Code Summarization, and Math\nProblem Solving, we reveal how selecting appropriate decoding techniques with\ntheir tuned hyperparameters affects text quality and has measurable\nimplications for resource utilization, emphasizing the need for balanced\noptimization. To the best of our knowledge, this study is among the first to\nexplore decoding strategies in LLMs through the lens of energy consumption,\noffering actionable insights for designing resource-aware applications that\nmaintain high-quality text generation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11723v1",
    "published": "2025-02-17T12:10:25+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11722v1",
    "title": "Evidence for an accretion bridge in the DX Cha circumbinary system from VLTI/MATISSE observations",
    "authors": [
      "TÃ­mea JuhÃ¡sz",
      "JÃ³zsef Varga",
      "PÃ©ter ÃbrahÃ¡m",
      "Ãgnes KÃ³spÃ¡l",
      "Foteini Lykou",
      "Lei Chen",
      "Attila MoÃ³r",
      "Fernando Cruz-SÃ¡enz de Miera",
      "Bruno Lopez",
      "Alexis Matter",
      "Roy van Boekel",
      "Michiel Hogerheijde",
      "Margaux Abello",
      "Jean-Charles Augereau",
      "Paul Boley",
      "William C. Danchi",
      "Thomas Henning",
      "Mathis Letessier",
      "Jie Ma",
      "Philippe Priolet",
      "Marten Scheuck",
      "Gerd Weigelt",
      "Sebastian Wolf"
    ],
    "abstract": "DX Cha (HD 104237) is a spectroscopic binary consisting of a Herbig\nA7.5Ve-A8Ve primary star and a K3-type companion. Here we report on new $3.55$\nmicrometer interferometric observations of this source with the Multi Aperture\nMid-Infrared Spectroscopic Experiment (MATISSE) at the Very Large Telescope\nInterferometer (VLTI). To model the four MATISSE observations obtained between\n2020 and 2023, we constructed a time-dependent interferometric model of the\nsystem, using the oimodeler software. The model consists of an asymmetric ring\nand two point sources on a Keplerian orbit. Our best-fit model consists of a\ncircumbinary ring with a diameter of $0.86$ au ($8.1$ mas), featuring a strong\nazimuthal asymmetry. We found that the position angle of the asymmetry changes\ntens of degrees between the MATISSE epochs. The ring is relatively narrow, with\na full width at half maximum (FWHM) of $\\sim$$0.13$ au ($1.23$ mas). The\npresence of circumstellar dust emission so close to the binary is unexpected,\nas previous hydrodynamic simulations predicted an inner disk cavity with a\ndiameter of $\\sim$$4$ au ($\\sim$$37.5$ mas). Thus, we argue that the narrow\nenvelope of material we detected is probably not a gravitationally stable\ncircumbinary ring, but may be part of tidal accretion streamers channeling\nmaterial from the inner edge of the disk toward the stars.",
    "pdf_url": "http://arxiv.org/pdf/2502.11722v1",
    "published": "2025-02-17T12:10:14+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11721v1",
    "title": "Enhancing Recommendation Explanations through User-Centric Refinement",
    "authors": [
      "Jingsen Zhang",
      "Zihang Tian",
      "Xueyang Feng",
      "Xu Chen"
    ],
    "abstract": "Generating natural language explanations for recommendations has become\nincreasingly important in recommender systems. Traditional approaches typically\ntreat user reviews as ground truth for explanations and focus on improving\nreview prediction accuracy by designing various model architectures. However,\ndue to limitations in data scale and model capability, these explanations often\nfail to meet key user-centric aspects such as factuality, personalization, and\nsentiment coherence, significantly reducing their overall helpfulness to users.\nIn this paper, we propose a novel paradigm that refines initial explanations\ngenerated by existing explainable recommender models during the inference stage\nto enhance their quality in multiple aspects. Specifically, we introduce a\nmulti-agent collaborative refinement framework based on large language models.\nTo ensure alignment between the refinement process and user demands, we employ\na plan-then-refine pattern to perform targeted modifications. To enable\ncontinuous improvements, we design a hierarchical reflection mechanism that\nprovides feedback on the refinement process from both strategic and content\nperspectives. Extensive experiments on three datasets demonstrate the\neffectiveness of our framework.",
    "pdf_url": "http://arxiv.org/pdf/2502.11721v1",
    "published": "2025-02-17T12:08:18+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.15783v1",
    "title": "Convergence of Iterative Water-Filling in Multi-User Non-Cooperative Power Control: A Comprehensive Analysis for Sequential, Simultaneous, and Asynchronous Schemes",
    "authors": [
      "Tong Wang"
    ],
    "abstract": "Non-cooperative game theory provides a robust framework for analyzing\ndistributed resource allocation in multi-user wireless networks, with\n\\emph{Iterative Water-Filling} (IWF) emerging as a canonical solution for power\ncontrol problems. Although classical fixed-point theorems guarantee the\nexistence of a Nash Equilibrium (NE) under mild concavity and compactness\nconditions, the convergence of practical iterative algorithms to that\nequilibrium remains a challenging endeavor. This challenge intensifies under\nvarying update schedules, interference regimes, and imperfections such as\nchannel estimation errors or feedback delay.\n  In this paper, we present an in-depth examination of IWF in multi-user\nsystems under three different update schemes: (1) synchronous \\emph{sequential}\nupdates, (2) synchronous \\emph{simultaneous} updates, and (3) \\emph{totally\nasynchronous} updates. We first formulate the water-filling operator in a\nmulti-carrier environment, then recast the iterative process as a fixed-point\nproblem. Using contraction mapping principles, we demonstrate sufficient\nconditions under which IWF converges to a unique NE and highlight how spectral\nradius constraints, diagonal dominance, and careful step-size selection are\npivotal for guaranteeing convergence. We further discuss robustness to\nmeasurement noise, partial updates, and network scaling to emphasize the\npractical viability of these schemes. This comprehensive analysis unifies\ndiverse threads in the literature while offering novel insights into\nasynchronous implementations. Our findings enable network designers to\nascertain system parameters that foster both stable convergence and efficient\nspectrum usage.",
    "pdf_url": "http://arxiv.org/pdf/2502.15783v1",
    "published": "2025-02-17T12:07:05+00:00",
    "categories": [
      "eess.SY",
      "cs.GT",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11720v1",
    "title": "Can you pass that tool?: Implications of Indirect Speech in Physical Human-Robot Collaboration",
    "authors": [
      "Yan Zhang",
      "Tharaka Sachintha Ratnayake",
      "Cherie Sew",
      "Jarrod Knibbe",
      "Jorge Goncalves",
      "Wafa Johal"
    ],
    "abstract": "Indirect speech acts (ISAs) are a natural pragmatic feature of human\ncommunication, allowing requests to be conveyed implicitly while maintaining\nsubtlety and flexibility. Although advancements in speech recognition have\nenabled natural language interactions with robots through direct, explicit\ncommands -- roviding clarity in communication -- the rise of large language\nmodels presents the potential for robots to interpret ISAs. However, empirical\nevidence on the effects of ISAs on human-robot collaboration (HRC) remains\nlimited. To address this, we conducted a Wizard-of-Oz study (N=36), engaging a\nparticipant and a robot in collaborative physical tasks. Our findings indicate\nthat robots capable of understanding ISAs significantly improve human's\nperceived robot anthropomorphism, team performance, and trust. However, the\neffectiveness of ISAs is task- and context-dependent, thus requiring careful\nuse. These results highlight the importance of appropriately integrating direct\nand indirect requests in HRC to enhance collaborative experiences and task\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11720v1",
    "published": "2025-02-17T12:05:04+00:00",
    "categories": [
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11719v2",
    "title": "Synergizing Covert Transmission and mmWave ISAC for Secure IoT Systems",
    "authors": [
      "Lingyun Xu",
      "Bowen Wang",
      "Ziyang Cheng"
    ],
    "abstract": "This work focuses on the synergy of physical layer covert transmission and\nmillimeter wave (mmWave) integrated sensing and communication (ISAC) to improve\nthe performance, and enable secure internet of things (IoT) systems.\nSpecifically, we employ a physical layer covert transmission as a prism, which\ncan achieve simultaneously transmitting confidential signals to a covert\ncommunication user equipment (UE) in the presence of a warden and regular\ncommunication UEs. We design the transmit beamforming to guarantee information\ntransmission security, communication quality-of-service (QoS) and sensing\naccuracy. By considering two different beamforming architectures, i.e., fully\ndigital beamforming (FDBF) and hybrid beamforming (HBF), an optimal design\nmethod and a low-cost beamforming scheme are proposed to address the\ncorresponding problems, respectively. Furthermore, building on the previously\nderived algorithm, two robust variants are proposed to address the more\nchallenging case where the warden's CSI is imperfect. Numerical simulations\nvalidate the effectiveness and superiority of the proposed FDBF/HBF algorithms\ncompared with traditional algorithms in terms of information transmission\nsecurity, communication QoS and target detection performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11719v2",
    "published": "2025-02-17T12:03:50+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11718v4",
    "title": "\"See the World, Discover Knowledge\": A Chinese Factuality Evaluation for Large Vision Language Models",
    "authors": [
      "Jihao Gu",
      "Yingyao Wang",
      "Pi Bu",
      "Chen Wang",
      "Ziming Wang",
      "Tengtao Song",
      "Donglai Wei",
      "Jiale Yuan",
      "Yingxiu Zhao",
      "Yancheng He",
      "Shilong Li",
      "Jiaheng Liu",
      "Meng Cao",
      "Jun Song",
      "Yingshui Tan",
      "Xiang Li",
      "Wenbo Su",
      "Zhicheng Zheng",
      "Xiaoyong Zhu",
      "Bo Zheng"
    ],
    "abstract": "The evaluation of factual accuracy in large vision language models (LVLMs)\nhas lagged behind their rapid development, making it challenging to fully\nreflect these models' knowledge capacity and reliability. In this paper, we\nintroduce the first factuality-based visual question-answering benchmark in\nChinese, named ChineseSimpleVQA, aimed at assessing the visual factuality of\nLVLMs across 8 major topics and 56 subtopics. The key features of this\nbenchmark include a focus on the Chinese language, diverse knowledge types, a\nmulti-hop question construction, high-quality data, static consistency, and\neasy-to-evaluate through short answers. Moreover, we contribute a rigorous data\nconstruction pipeline and decouple the visual factuality into two parts: seeing\nthe world (i.e., object recognition) and discovering knowledge. This decoupling\nallows us to analyze the capability boundaries and execution mechanisms of\nLVLMs. Subsequently, we evaluate 34 advanced open-source and closed-source\nmodels, revealing critical performance gaps within this field. Our\nevaluation-friendly code and data have already been open-sourced.",
    "pdf_url": "http://arxiv.org/pdf/2502.11718v4",
    "published": "2025-02-17T12:02:23+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11717v1",
    "title": "Superconducting Diode Effects: Mechanisms, Materials and Applications",
    "authors": [
      "Jiajun Ma",
      "Ruiya Zhan",
      "Xiao Lin"
    ],
    "abstract": "Superconducting diode effects (SDEs) generally emerge in superconducting\nsystems where both time-reversal and inversion symmetries are broken, showing\nnonreciprocal current characteristics: nondissipative in one direction and\nohmic in the opposite. Since the discovery of the SDEs by Ando et al. in the\nnoncentrosymmetric superconductor [Nb/V/Ta]n in 2020, notable progress has been\nachieved on both the theoretical and experimental fronts. It has been proposed\nthat intrinsic SDEs are closely linked to various exotic superconducting\nstates, such as the Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) state, topological\nsuperconductivity, and chiral superconductivity. Recently, SDEs have emerged as\nimportant experimental tools for detecting symmetry breaking in exotic\nsuperconducting states. This advancement not only enhances our understanding of\nthe fundamental nature of SDEs but also opens new possibilities for their\napplications in superconducting physics and related fields. This review focuses\non the recent experimental progress in the observation of the SDEs and\ndiscusses their primary mechanisms from the perspective of material properties\nand symmetry breaking. Finally, we summarize the observed rectification\nefficiency of SDE devices and discuss future research directions in this\nrapidly developing field.",
    "pdf_url": "http://arxiv.org/pdf/2502.11717v1",
    "published": "2025-02-17T12:00:37+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2502.11716v2",
    "title": "The three obdurate conjectures of differential geometry",
    "authors": [
      "Brendan Guilfoyle",
      "Wilhelm Klingenberg"
    ],
    "abstract": "We explore the role of symmetry in three obdurate conjectures of differential\ngeometry: the Carath\\'eodory, the Willmore and the Lawson Conjectures. All\nthree Conjectures concern surfaces in 3-dimensional space-forms, which have a\nhigh degree of symmetry. It is shown that this symmetry is broken and more\ngeneral ambient metrics are considered, none of the Conjectures continue to\nhold.\n  The subtle manner in which symmetry enters the first Conjecture is also\nexplained in detail.",
    "pdf_url": "http://arxiv.org/pdf/2502.11716v2",
    "published": "2025-02-17T12:00:34+00:00",
    "categories": [
      "math.DG",
      "53A05, 35K51, 32V40"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11715v1",
    "title": "Proactive Depot Discovery: A Generative Framework for Flexible Location-Routing",
    "authors": [
      "Site Qu",
      "Guoqiang Hu"
    ],
    "abstract": "The Location-Routing Problem (LRP), which combines the challenges of facility\n(depot) locating and vehicle route planning, is critically constrained by the\nreliance on predefined depot candidates, limiting the solution space and\npotentially leading to suboptimal outcomes. Previous research on LRP without\npredefined depots is scant and predominantly relies on heuristic algorithms\nthat iteratively attempt depot placements across a planar area. Such approaches\nlack the ability to proactively generate depot locations that meet specific\ngeographic requirements, revealing a notable gap in current research landscape.\nTo bridge this gap, we propose a data-driven generative DRL framework, designed\nto proactively generate depots for LRP without predefined depot candidates,\nsolely based on customer requests data which include geographic and demand\ninformation. It can operate in two distinct modes: direct generation of exact\ndepot locations, and the creation of a multivariate Gaussian distribution for\nflexible depots sampling. By extracting depots' geographic pattern from\ncustomer requests data, our approach can dynamically respond to logistical\nneeds, identifying high-quality depot locations that further reduce total\nrouting costs compared to traditional methods. Extensive experiments\ndemonstrate that, for a same group of customer requests, compared with those\ndepots identified through random attempts, our framework can proactively\ngenerate depots that lead to superior solution routes with lower routing cost.\nThe implications of our framework potentially extend into real-world\napplications, particularly in emergency medical rescue and disaster relief\nlogistics, where rapid establishment and adjustment of depot locations are\nparamount, showcasing its potential in addressing LRP for dynamic and\nunpredictable environments.",
    "pdf_url": "http://arxiv.org/pdf/2502.11715v1",
    "published": "2025-02-17T12:00:28+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11714v1",
    "title": "Monotonicity of the jump set and jump amplitudes in one-dimensional TV denoising",
    "authors": [
      "Riccardo Cristoferi",
      "Rita Ferreira",
      "Irene Fonseca",
      "JosÃ© A. Iglesias"
    ],
    "abstract": "We revisit the classical problem of denoising a one-dimensional scalar-valued\nfunction by minimizing the sum of an $L^2$ fidelity term and the total\nvariation, scaled by a regularization parameter. This study focuses on proving\nthat the jump set of solutions, corresponding to discontinuities or edges, as\nwell as the amplitude of the jumps are nonincreasing as the regularization\nparameter increases. Our results apply to input functions in $L^\\infty$ with\nleft and right approximate limits everywhere, extending beyond the traditional\nsetting of functions of bounded variation. The proof leverages competitor\nconstructions and convexity properties of the taut string problem, a well-known\nequivalent formulation of the TV model. Such a monotonicity property reflects\nthat the extent to which geometric and topological features of the original\nsignal are preserved is consistent with the amount of smoothing desired when\nformulating the denoising method.",
    "pdf_url": "http://arxiv.org/pdf/2502.11714v1",
    "published": "2025-02-17T11:59:42+00:00",
    "categories": [
      "math.OC",
      "26A45, 26A46, 94A12, 68U10"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11713v1",
    "title": "Nonlinearity Cancellation Based on Optimized First Order Perturbative Kernels",
    "authors": [
      "Alex Alvarado",
      "Astrid Barreiro",
      "Gabriele Liga"
    ],
    "abstract": "The potential offered by interference cancellation based on optimized regular\nperturbation kernels of the Manakov equation is studied. Theoretical gains of\nup to 2.5 dB in effective SNR are demonstrated.",
    "pdf_url": "http://arxiv.org/pdf/2502.11713v1",
    "published": "2025-02-17T11:59:00+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11712v1",
    "title": "Component-aware Unsupervised Logical Anomaly Generation for Industrial Anomaly Detection",
    "authors": [
      "Xuan Tong",
      "Yang Chang",
      "Qing Zhao",
      "Jiawen Yu",
      "Boyang Wang",
      "Junxiong Lin",
      "Yuxuan Lin",
      "Xinji Mai",
      "Haoran Wang",
      "Zeng Tao",
      "Yan Wang",
      "Wenqiang Zhang"
    ],
    "abstract": "Anomaly detection is critical in industrial manufacturing for ensuring\nproduct quality and improving efficiency in automated processes. The scarcity\nof anomalous samples limits traditional detection methods, making anomaly\ngeneration essential for expanding the data repository. However, recent\ngenerative models often produce unrealistic anomalies increasing false\npositives, or require real-world anomaly samples for training. In this work, we\ntreat anomaly generation as a compositional problem and propose ComGEN, a\ncomponent-aware and unsupervised framework that addresses the gap in logical\nanomaly generation. Our method comprises a multi-component learning strategy to\ndisentangle visual components, followed by subsequent generation editing\nprocedures. Disentangled text-to-component pairs, revealing intrinsic logical\nconstraints, conduct attention-guided residual mapping and model training with\niteratively matched references across multiple scales. Experiments on the\nMVTecLOCO dataset confirm the efficacy of ComGEN, achieving the best AUROC\nscore of 91.2%. Additional experiments on the real-world scenario of Diesel\nEngine and widely-used MVTecAD dataset demonstrate significant performance\nimprovements when integrating simulated anomalies generated by ComGEN into\nautomated production workflows.",
    "pdf_url": "http://arxiv.org/pdf/2502.11712v1",
    "published": "2025-02-17T11:54:43+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11711v2",
    "title": "Knowledge-aware contrastive heterogeneous molecular graph learning",
    "authors": [
      "Mukun Chen",
      "Jia Wu",
      "Shirui Pan",
      "Fu Lin",
      "Bo Du",
      "Xiuwen Gong",
      "Wenbin Hu"
    ],
    "abstract": "Molecular representation learning is pivotal in predicting molecular\nproperties and advancing drug design. Traditional methodologies, which\npredominantly rely on homogeneous graph encoding, are limited by their\ninability to integrate external knowledge and represent molecular structures\nacross different levels of granularity. To address these limitations, we\npropose a paradigm shift by encoding molecular graphs into heterogeneous\nstructures, introducing a novel framework: Knowledge-aware Contrastive\nHeterogeneous Molecular Graph Learning (KCHML). This approach leverages\ncontrastive learning to enrich molecular representations with embedded external\nknowledge. KCHML conceptualizes molecules through three distinct graph\nviews-molecular, elemental, and pharmacological-enhanced by heterogeneous\nmolecular graphs and a dual message-passing mechanism. This design offers a\ncomprehensive representation for property prediction, as well as for downstream\ntasks such as drug-drug interaction (DDI) prediction. Extensive benchmarking\ndemonstrates KCHML's superiority over state-of-the-art molecular property\nprediction models, underscoring its ability to capture intricate molecular\nfeatures.",
    "pdf_url": "http://arxiv.org/pdf/2502.11711v2",
    "published": "2025-02-17T11:53:58+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12219v1",
    "title": "Towards Efficient Molecular Property Optimization with Graph Energy Based Models",
    "authors": [
      "Luca Miglior",
      "Lorenzo Simone",
      "Marco Podda",
      "Davide Bacciu"
    ],
    "abstract": "Optimizing chemical properties is a challenging task due to the vastness and\ncomplexity of chemical space. Here, we present a generative energy-based\narchitecture for implicit chemical property optimization, designed to\nefficiently generate molecules that satisfy target properties without explicit\nconditional generation. We use Graph Energy Based Models and a training\napproach that does not require property labels. We validated our approach on\nwell-established chemical benchmarks, showing superior results to\nstate-of-the-art methods and demonstrating robustness and efficiency towards de\nnovo drug design.",
    "pdf_url": "http://arxiv.org/pdf/2502.12219v1",
    "published": "2025-02-17T11:53:07+00:00",
    "categories": [
      "q-bio.BM",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2502.11710v1",
    "title": "The Worse The Better: Content-Aware Viewpoint Generation Network for Projection-related Point Cloud Quality Assessment",
    "authors": [
      "Zhiyong Su",
      "Bingxu Xie",
      "Zheng Li",
      "Jincan Wu",
      "Weiqing Li"
    ],
    "abstract": "Through experimental studies, however, we observed the instability of final\npredicted quality scores, which change significantly over different viewpoint\nsettings. Inspired by the \"wooden barrel theory\", given the default\ncontent-independent viewpoints of existing projection-related PCQA approaches,\nthis paper presents a novel content-aware viewpoint generation network (CAVGN)\nto learn better viewpoints by taking the distribution of geometric and\nattribute features of degraded point clouds into consideration. Firstly, the\nproposed CAVGN extracts multi-scale geometric and texture features of the\nentire input point cloud, respectively. Then, for each default\ncontent-independent viewpoint, the extracted geometric and texture features are\nrefined to focus on its corresponding visible part of the input point cloud.\nFinally, the refined geometric and texture features are concatenated to\ngenerate an optimized viewpoint. To train the proposed CAVGN, we present a\nself-supervised viewpoint ranking network (SSVRN) to select the viewpoint with\nthe worst quality projected image to construct a default-optimized viewpoint\ndataset, which consists of thousands of paired default viewpoints and\ncorresponding optimized viewpoints. Experimental results show that the\nprojection-related PCQA methods can achieve higher performance using the\nviewpoints generated by the proposed CAVGN.",
    "pdf_url": "http://arxiv.org/pdf/2502.11710v1",
    "published": "2025-02-17T11:50:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11709v3",
    "title": "Superconducting and spin-density wave phases probed by scanning tunneling spectroscopy in the organic conductor $\\mathrm{(TMTSF)_{2}ClO_{4}}$",
    "authors": [
      "Mohammadmehdi Torkzadeh",
      "Pascale Senzier",
      "Claude Bourbonnais",
      "Abdelouahab Sedeki",
      "CÃ©cile MÃ©ziere",
      "Marie HervÃ©",
      "Francois Debontridder",
      "Pascal David",
      "Tristan Cren",
      "Claire Marrache-Kikuchi",
      "Denis Jerome",
      "Christophe Brun"
    ],
    "abstract": "By scanning tunneling microscopy (STM) we have probed the local\nquasi-particle density of states (DOS) of the Bechgaard salt organic\nsuperconductor $\\mathrm{(TMTSF)_{2}ClO_{4}}$ in slowly cooled single crystals\ncleaved under ultrahigh vacuum conditions. In well STM imaged crystallographic\nsurface planes, the local DOS has been probed for different surface areas at\ntemperatures above and below the critical temperature of superconducting or\ninsulating spin-density wave states. While a rather homogeneous superconducting\nstate is expected in the bulk from previous studies, depending on the degree of\ndisorder introduced by cleavage in the anion lattice, an inhomogeneous granular\nstate is predominantly observed at the surface. A pronounced linear V-shape\nprofile of the local DOS is observed from intermediate to the lowest energy\nscale in the less disordered superconducting surface areas. This supports the\nexistence of an unconventional d-wave like order parameter with nodes at low\nenergy, which is preceded by more energetic fluctuations attributed to quantum\ncriticality of the material. At higher energy disorder combined to correlations\ndeplete further the DOS. By contrast a non-linear U-shape characterizes the\nlocal low energy DOS profile for the more disordered and insulating surface\nareas of the spin-density wave state. The experimental results are compared\nquantitatively with those predicted by the renormalization group theory of the\nquasi-one dimensional electron gas model and its description of the\nsuperconducting and spin-density wave states that are interlinked by quantum\ncriticality in the Bechgaard salts.",
    "pdf_url": "http://arxiv.org/pdf/2502.11709v3",
    "published": "2025-02-17T11:49:49+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2502.11708v1",
    "title": "Design and Implementation of Flutter based Multi-platform Docker Controller App",
    "authors": [
      "Adarsh Saxena",
      "Sudhakar Singh",
      "Shiv Prakash",
      "Nand Lal Yadav",
      "Tiansheng Yang",
      "Rajkumar Singh Rathore",
      "Shreya Singh"
    ],
    "abstract": "This paper focuses on developing a Flutter application for controlling Docker\nresources remotely. The application provides a user-friendly interface for\nexecuting various Docker-related commands on the server where the Docker engine\nis installed. The application uses the SSH protocol to establish a secure\nconnection with the server and execute the commands. Further, an alternative\napproach is also explored, which involves connecting the application with the\nDocker engine using HTTP. This proposed Docker controller application provides\na significant advantage for managing Docker resources remotely, which is highly\nbeneficial in DevOps fields. It provides a user-friendly interface to manage\ncontainers, making it easy to create, start, stop, restart, and remove\ncontainers. It abstracts away the complexities of working with Docker commands,\nallowing users to interact with containers more intuitively. It can be used to\nmanage a number of docker engines from one place making it easy to control and\nmonitor all the docker resources. Its performance, security, and scalability\nare evaluated using various testing techniques, and the results are found\nsatisfactory. Further improvements may include enhancing the application's\nfeatures, optimizing the performance, and exploring other possible approaches\nfor establishing the connection between the application and the Docker engine.",
    "pdf_url": "http://arxiv.org/pdf/2502.11708v1",
    "published": "2025-02-17T11:48:02+00:00",
    "categories": [
      "cs.SE",
      "cs.ET"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11707v2",
    "title": "Ad-hoc Concept Forming in the Game Codenames as a Means for Evaluating Large Language Models",
    "authors": [
      "Sherzod Hakimov",
      "Lara Pfennigschmidt",
      "David Schlangen"
    ],
    "abstract": "This study utilizes the game Codenames as a benchmarking tool to evaluate\nlarge language models (LLMs) with respect to specific linguistic and cognitive\nskills. LLMs play each side of the game, where one side generates a clue word\ncovering several target words and the other guesses those target words. We\ndesigned various experiments by controlling the choice of words (abstract vs.\nconcrete words, ambiguous vs. monosemic) or the opponent (programmed to be\nfaster or slower in revealing words). Recent commercial and open-weight models\nwere compared side-by-side to find out factors affecting their performance. The\nevaluation reveals details about their strategies, challenging cases, and\nlimitations of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11707v2",
    "published": "2025-02-17T11:46:46+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11706v1",
    "title": "A deep BSDE approach for the simultaneous pricing and delta-gamma hedging of large portfolios consisting of high-dimensional multi-asset Bermudan options",
    "authors": [
      "Balint Negyesi",
      "Cornelis W. Oosterlee"
    ],
    "abstract": "A deep BSDE approach is presented for the pricing and delta-gamma hedging of\nhigh-dimensional Bermudan options, with applications in portfolio risk\nmanagement. Large portfolios of a mixture of multi-asset European and Bermudan\nderivatives are cast into the framework of discretely reflected BSDEs. This\nsystem is discretized by the One Step Malliavin scheme (Negyesi et al. [2024,\n2025]) of discretely reflected Markovian BSDEs, which involves a $\\Gamma$\nprocess, corresponding to second-order sensitivities of the associated option\nprices. The discretized system is solved by a neural network regression Monte\nCarlo method, efficiently for a large number of underlyings. The resulting\noption Deltas and Gammas are used to discretely rebalance the corresponding\nreplicating strategies. Numerical experiments are presented on both\nhigh-dimensional basket options and large portfolios consisting of multiple\noptions with varying early exercise rights, moneyness and volatility. These\nexamples demonstrate the robustness and accuracy of the method up to $100$ risk\nfactors. The resulting hedging strategies significantly outperform benchmark\nmethods both in the case of standard delta- and delta-gamma hedging.",
    "pdf_url": "http://arxiv.org/pdf/2502.11706v1",
    "published": "2025-02-17T11:46:40+00:00",
    "categories": [
      "q-fin.CP",
      "q-fin.RM",
      "91G20, 68T07, 91G60, 65C30"
    ],
    "primary_category": "q-fin.CP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11705v2",
    "title": "LLM Agents Making Agent Tools",
    "authors": [
      "Georg WÃ¶lflein",
      "Dyke Ferber",
      "Daniel Truhn",
      "Ognjen ArandjeloviÄ",
      "Jakob Nikolas Kather"
    ],
    "abstract": "Tool use has turned large language models (LLMs) into powerful agents that\ncan perform complex multi-step tasks by dynamically utilising external software\ncomponents. However, these tools must be implemented in advance by human\ndevelopers, hindering the applicability of LLM agents in domains demanding\nlarge numbers of highly specialised tools, like in life sciences and medicine.\nMotivated by the growing trend of scientific studies accompanied by public code\nrepositories, we propose ToolMaker, an agentic framework that autonomously\ntransforms papers with code into LLM-compatible tools. Given a GitHub URL and\nshort task description, ToolMaker autonomously installs dependencies and\ngenerates code to perform the task, using a closed-loop self-correction\nmechanism for debugging. To evaluate our approach, we introduce a benchmark\ncomprising 15 complex computational tasks spanning various domains with over\n100 unit tests to assess correctness and robustness. Our method correctly\nimplements 80% of the tasks, substantially outperforming current\nstate-of-the-art software engineering agents. ToolMaker therefore is a step\ntowards fully autonomous agent-based scientific workflows. Our code and\nbenchmark are publicly available at https://github.com/KatherLab/ToolMaker.",
    "pdf_url": "http://arxiv.org/pdf/2502.11705v2",
    "published": "2025-02-17T11:44:11+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11704v1",
    "title": "Motivic counting of rational curves with tangency conditions via universal torsors",
    "authors": [
      "LoÃ¯s Faisant"
    ],
    "abstract": "Using the formalism of Cox rings and universal torsors, we prove a\ndecomposition of the Grothendieck motive of the moduli space of morphisms from\nan arbitrary smooth projective curve to a Mori Dream Space (MDS).\n  For the simplest cases of MDS, that of toric varieties, we use this\ndecomposition to prove an instance of the motivic Batyrev--Manin--Peyre\nprinciple for curves satisfying tangency conditions with respect to the\nboundary divisors, often called Campana curves.",
    "pdf_url": "http://arxiv.org/pdf/2502.11704v1",
    "published": "2025-02-17T11:43:01+00:00",
    "categories": [
      "math.AG",
      "math.NT",
      "14H10, 14E18, 11G50, 14G40, 14J45"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11703v2",
    "title": "CMQCIC-Bench: A Chinese Benchmark for Evaluating Large Language Models in Medical Quality Control Indicator Calculation",
    "authors": [
      "Guangya Yu",
      "Yanhao Li",
      "Zongying Jiang",
      "Yuxiong Jin",
      "Li Dai",
      "Yupian Lin",
      "Ruihui Hou",
      "Weiyan Zhang",
      "Yongqi Fan",
      "Qi Ye",
      "Jingping Liu",
      "Tong Ruan"
    ],
    "abstract": "Medical quality control indicators are essential to assess the qualifications\nof healthcare institutions for medical services. With the impressive\nperformance of large language models (LLMs) like GPT-4 in the medical field,\nleveraging these technologies for the Medical Quality Control Indicator\nCalculation (MQCIC) presents a promising approach. In this work, (1) we\nintroduce a real-world task MQCIC and propose an open-source Chinese electronic\nmedical records (EMRs)-based dataset (CMQCIC-Bench) comprising 785 instances\nand 76 indicators. (2) We propose a semi-automatic method to enhance the rule\nrepresentation. Then we propose the Clinical Facts-based Inferential Rule\n(CF-IR) method that disentangles the clinical fact verification and inferential\nrule reasoning actions. (3) We conduct comprehensive experiments on 20\nrepresentative LLMs, covering general and medical models. Our findings reveal\nthat CF-IR outperforms Chain-of-Thought methods in MQCIC tasks. (4) We conduct\nan error analysis and investigate the capabilities of clinical fact\nverification and inferential rule reasoning, providing insights to improve\nperformance in the MQCIC further. The dataset and code is available in this\nrepository https://github.com/YuY-2001/C-MQCIC.",
    "pdf_url": "http://arxiv.org/pdf/2502.11703v2",
    "published": "2025-02-17T11:40:48+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11702v1",
    "title": "Anatomy of anomalous Hall effect due to magnetic fluctuations",
    "authors": [
      "Ola Kenji Forslund",
      "Xiaoxiong Liu",
      "Soohyeon Shin",
      "Chun Lin",
      "Masafumi Horio",
      "Qisi Wang",
      "Kevin Kramer",
      "Saumya Mukherjee",
      "Timur Kim",
      "Cephise Cacho",
      "Chennan Wang",
      "Tian Shang",
      "Victor Ukleev",
      "Jonathan S. White",
      "Pascal Puphal",
      "Yasmine Sassa",
      "Ekaterina Pomjakushina",
      "Titus Neupert",
      "Johan Chang"
    ],
    "abstract": "The anomalous Hall {\\color{black} e}ffect (AHE) has emerged as a key\nindicator of time-reversal symmetry breaking (TRSB) and topological features in\nelectronic band structures. Absent of a magnetic field, the AHE requires\nspontaneous TRSB but has proven hard to probe due to averaging over domains.\nThe anomalous component of the Hall effect is thus frequently derived from\nextrapolating the magnetic field dependence of the Hall response. We show that\ndiscerning whether the AHE is an intrinsic property of the field free system\nbecomes intricate in the presence of strong magnetic fluctuations.\n{\\color{black}As a study case,} we use the Weyl semimetal PrAlGe, where TRSB\ncan be toggled via a ferromagnetic transition, providing a transparent view of\nthe AHE's topological origin. Through a combination of thermodynamic, transport\nand muon spin relaxation measurements, we contrast the behaviour below the\nferromagnetic transition temperature to that of strong magnetic fluctuations\nabove. Our results {\\color{black}on PrAlGe provide general insights into the}\ninterpretation of anomalous Hall signals in systems where TRSB is debated, such\nas families of Kagome metals or certain transition metal dichalcogenides.",
    "pdf_url": "http://arxiv.org/pdf/2502.11702v1",
    "published": "2025-02-17T11:40:44+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11701v1",
    "title": "A Cholesky decomposition-based asset selection heuristic for sparse tangent portfolio optimization",
    "authors": [
      "Hyunglip Bae",
      "Haeun Jeon",
      "Minsu Park",
      "Yongjae Lee",
      "Woo Chang Kim"
    ],
    "abstract": "In practice, including large number of assets in mean-variance portfolios can\nlead to higher transaction costs and management fees. To address this, one\ncommon approach is to select a smaller subset of assets from the larger pool,\nconstructing more efficient portfolios. As a solution, we propose a new asset\nselection heuristic which generates a pre-defined list of asset candidates\nusing a surrogate formulation and re-optimizes the cardinality-constrained\ntangent portfolio with these selected assets. This method enables faster\noptimization and effectively constructs portfolios with fewer assets, as\ndemonstrated by numerical analyses on historical stock returns. Finally, we\ndiscuss a quantitative metric that can provide a initial assessment of the\nperformance of the proposed heuristic based on asset covariance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11701v1",
    "published": "2025-02-17T11:39:50+00:00",
    "categories": [
      "q-fin.MF",
      "q-fin.PM"
    ],
    "primary_category": "q-fin.MF"
  },
  {
    "id": "http://arxiv.org/abs/2502.11700v1",
    "title": "Density fluctuation in the solar corona and solar wind: A comparative analysis of radio-occultation observations and magnetohydrodynamic simulation",
    "authors": [
      "Shota Chiba",
      "Munehito Shoda",
      "Takeshi Imamura"
    ],
    "abstract": "Recent in-situ observations and numerical models indicated various types of\nmagnetohydrodynamic (MHD) waves contributing to the solar wind acceleration.\nAmong them is an MHD wave decomposition at distances closer than 50 $R_{\\odot}$\nusing data taken by the first perihelion pass of Parker Solar Probe (PSP).\nHowever, the underlying physical processes responsible for the formation of the\nsolar wind have not yet been observationally confirmed at distances closer than\n10 $R_{\\odot}$. We aim to infer the mode population of density fluctuations\nobserved by radio occultation, which has all been attributed to slow\nmagnetoacoustic waves. We compare the radio occultation observations conducted\nin 2016 using the JAXA's Venus orbiter Akatsuki with the MHD simulation. The\ntime-frequency analysis was applied to the density fluctuations observed by the\nradio occultation and those reproduced in the MHD model. The time-spatial\nspectrum of the density fluctuation in the model exhibits two components that\nare considered to be fast and slow magnetoacoustic waves. The fast\nmagnetoacoustic waves in the model tend to have periods shorter than the slow\nmagnetoacoustic waves, and the superposition of these modes has a broadened\nspectrum extending in the range of approximately 20$-$1000 s, which resembles\nthat of the observed waves. Based on this comparison, it is probable that the\ndensity oscillations observed by radio occultation include fast and slow\nmagnetoacoustic waves, and that fast magnetoacoustic waves are predominant at\nshort periods and slow magnetoacoustic waves are prevalent at long periods.\nThis is qualitatively similar to the results of the mode decomposition obtained\nfrom the PSP's first perihelion at more distance regions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11700v1",
    "published": "2025-02-17T11:38:16+00:00",
    "categories": [
      "astro-ph.SR",
      "physics.plasm-ph"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11699v1",
    "title": "Mixing for dynamical systems driven by stationary noises",
    "authors": [
      "Sergei Kuksin",
      "Armen Shirikyan"
    ],
    "abstract": "The paper deals with the problem of long-time asymptotic behaviour of\nsolutions for classes of ODEs and PDEs, perturbed by stationary noises. The\nlatter are not assumed to be $\\delta$-correlated in time, so that the evolution\nin question is not necessarily Markovian. We first prove an abstract result\nwhich imply the mixing for random dynamical systems satisfying appropriate\ndissipativity and controllability conditions. It is applicable to a large class\nof evolution equations, and we illustrate it on the examples of a chain of\nanharmonic oscillators coupled to heat reservoirs, the 2d Navier-Stokes system,\nand a complex Ginzburg-Landau equation. Our results also apply to the general\ntheory of random processes on the 1d lattice and allow one to get for them\nresults related to Dobrushin's theorems on reconstructing processes via their\nconditional distributions. The proof is based on an iterative construction with\nquadratic convergence. It uses the method of Kantorovich functional, introduced\nin [KPS02, Kuk02, Kuk06] in the context of randomly forced PDEs, and some ideas\nsuggested in [Shi15, KNS20] to prove mixing with the help of controllability\nproperties of an associated system",
    "pdf_url": "http://arxiv.org/pdf/2502.11699v1",
    "published": "2025-02-17T11:37:39+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.AP",
      "math.CA",
      "math.DS",
      "math.MP",
      "35Q30, 35Q56, 37H30, 37L40, 60G10, 60H25, 60J05, 76D06, 76F25"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11698v1",
    "title": "Mutual Validation of Datasets for Analyzing Tilt Angles in Solar Active Regions",
    "authors": [
      "Lang Qin",
      "Jie Jiang",
      "Ruihui Wang"
    ],
    "abstract": "The tilt angle of solar active regions (AR) is crucial for the\nBabcock-Leighton type dynamo models in the buildup of polar field. However,\ndivergent results regarding properties of tilt angles were reported due to\ntheir wide scatter, caused by intrinsic solar mechanisms and measurement\nerrors. Here, we mutually validate the magnetogram-based AR tilt angle dataset\nfrom Wang, Jiang, & Luo with the Debrecen Photoheliographic Data by identifying\ncommon data points where both datasets provide comparable tilt angles for the\nsame AR/sunspot. The mutually validated datasets effectively reduce measurement\nerrors, enabling a more accurate analysis of the intrinsic properties of tilt\nangles. Our mutually validated datasets reveal that the difference between\nwhite-light-based and magnetogram-based tilt angles has no significant\ndifference. Also, the datasets show that an upward revision of average tilt\nangle ($\\bar\\alpha$) and a downward revision of the tilt scatter\n($\\sigma_\\alpha$) compared to previous results are necessary, with typical\nvalues of about 7$^\\circ$ and 16$^\\circ$, respectively. The $\\sigma_\\alpha$\nvalues demonstrate a strong correlation with AR flux and sunspot area, with the\ndependency functions re-evaluated using mutually validated datasets.\nFurthermore, both $\\bar\\alpha$ and the tilt coefficient for the weak cycle 24\nare larger than those for cycle 23. This supports the tilt quenching mechanism,\nwhich posits an anti-correlation between the cycle-averaged tilt angle and\ncycle amplitude. Additionally, tilt angle from the mutually validated dataset\nhas a weak non-monotonic relationship with magnetic flux and does not depend on\nthe maximum magnetic field strength of ARs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11698v1",
    "published": "2025-02-17T11:37:37+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11697v1",
    "title": "MVTokenFlow: High-quality 4D Content Generation using Multiview Token Flow",
    "authors": [
      "Hanzhuo Huang",
      "Yuan Liu",
      "Ge Zheng",
      "Jiepeng Wang",
      "Zhiyang Dou",
      "Sibei Yang"
    ],
    "abstract": "In this paper, we present MVTokenFlow for high-quality 4D content creation\nfrom monocular videos. Recent advancements in generative models such as video\ndiffusion models and multiview diffusion models enable us to create videos or\n3D models. However, extending these generative models for dynamic 4D content\ncreation is still a challenging task that requires the generated content to be\nconsistent spatially and temporally. To address this challenge, MVTokenFlow\nutilizes the multiview diffusion model to generate multiview images on\ndifferent timesteps, which attains spatial consistency across different\nviewpoints and allows us to reconstruct a reasonable coarse 4D field. Then,\nMVTokenFlow further regenerates all the multiview images using the rendered 2D\nflows as guidance. The 2D flows effectively associate pixels from different\ntimesteps and improve the temporal consistency by reusing tokens in the\nregeneration process. Finally, the regenerated images are spatiotemporally\nconsistent and utilized to refine the coarse 4D field to get a high-quality 4D\nfield. Experiments demonstrate the effectiveness of our design and show\nsignificantly improved quality than baseline methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.11697v1",
    "published": "2025-02-17T11:34:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11696v1",
    "title": "Determining the minimum size of maximal 1-plane graphs",
    "authors": [
      "Yuanqiu Huang",
      "Zhangdong Ouyang",
      "Licheng Zhang",
      "Fengming Dong"
    ],
    "abstract": "A 1-plane graph is a graph together with a drawing in the plane in such a way\nthat each edge is crossed at most once. A 1-plane graph is maximal if no edge\ncan be added without violating either 1-planarity or simplicity. Let $m(n)$\ndenote the minimum size of a maximal $1$-plane graph of order $n$. Brandenburg\net al. established that\n  $m(n)\\ge 2.1n-\\frac{10}{3}$ for all $n\\ge 4$, which was improved by Bar\\'{a}t\nand T\\'{o}th to $m(n)\\ge \\frac{20}{9}n-\\frac{10}{3}$. In this paper, we confirm\nthat $m(n)=\\left\\lceil\\frac{7}{3}n\\right\\rceil-3$ for all $n\\ge 5$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11696v1",
    "published": "2025-02-17T11:34:22+00:00",
    "categories": [
      "math.CO",
      "05C10"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11695v1",
    "title": "Information Sharing Among Countries: A Perspective from Country-Specific Websites in Global Brands",
    "authors": [
      "Amit Pariyar",
      "Yohei Murakami",
      "Donghui Lin",
      "Toru Ishida"
    ],
    "abstract": "Multiple official languages within a country along with languages common with\nother countries demand content consistency in both shared and unshared\nlanguages during information sharing. However, inconsistency due to conflict in\ncontent shared and content updates not propagated in languages between\ncountries poses a problem. Towards addressing inconsistency, this research\nqualitatively studied traits for information sharing among countries inside\nglobal brands as depicted by content shared in their country-specific websites.\nFirst, inconsistency in content shared is illustrated among websites\nhighlighting the problem in information sharing among countries. Second,\ncontent propagation among countries that vary in scales and coupling for\nspecific content categories are revealed. Scales suggested that corporate and\ncustomer support related information tend to be shared globally and locally\nrespectively while product related information is both locally and regionally\nsuitable for sharing. Higher occurrences of propagation when sharing corporate\nrelated information also showed tendency for high coupling between websites\nsuggesting the suitability for rigid consistency policy compared to other\ncategories. This study also proposed a simplistic approach with pattern of\nsharing to enable consistent information sharing.",
    "pdf_url": "http://arxiv.org/pdf/2502.11695v1",
    "published": "2025-02-17T11:32:30+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11694v1",
    "title": "Connecting Earth and Moon via the L1 Lagrangian point",
    "authors": [
      "A. K. de Almeida Jr",
      "V. M. de Oliveira",
      "T. Vaillant",
      "D. Maia",
      "A. C. M. Correia",
      "D. Barbosa",
      "L. T. B. Santos"
    ],
    "abstract": "The renewed global interest in lunar exploration requires new orbital\nstrategies to ensure flight safety which can benefit extended lunar missions\nand service a plethora of planned instruments in the lunar orbit and surface.\nWe investigate here the equivalent fuel consumption cost to transfer from (to)\na given orbit and enter (leave) at any point of an invariant manifold\nassociated with a Lyapunov orbit around the Earth-Moon $L_1$ Lagrangian point\nusing bi-impulsive maneuvers. Whereas solving this type of transfer is\ngenerally computationally expensive, we simulate here tens of millions of\ntransfers orbits, for different times of flight, Jacobi constants and spatial\nlocation on the manifold. We are able to reduce computational cost by taking\nadvantage of the efficient procedure given by the Theory of Functional\nConnections for solving boundary value problems, represented with special\nconstraints created to the purposes of this work. We develop here the\nmethodology for constructing these transfers, and apply it to find a low-cost\ntransfer from an orbit around the Earth to a stable manifold and another\nlow-cost transfer from an unstable manifold to an orbit around the Moon. In the\nend, we obtain an innovative Earth-to-Moon transfer that involves a gravity\nassist maneuver with the Moon and allows a long stationed stage at the Lyapunov\norbit around $L_1$ which can be used for designing multi-purpose missions for\nextended periods of time with low fuel costs. This is paramount to optimize new\nexploration concepts.",
    "pdf_url": "http://arxiv.org/pdf/2502.11694v1",
    "published": "2025-02-17T11:32:02+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2502.11693v1",
    "title": "Observation of the Dirac Dispersions in Co-doped CaFe2As2",
    "authors": [
      "Marcin Rosmus",
      "Natalia Olszowska",
      "Rafal Kurleto",
      "Zbigniew Bukowski",
      "Pawel Starowicz"
    ],
    "abstract": "We performed an angle-resolved photoemission spectroscopy (ARPES) study of\nthe electronic structure of the CaFe$_2$As$_2$ 122-iron pnictide, a parent\ncompound, and two iron-based superconductors CaFe$_{2-x}$Co$_x$As$_2$ ($x =\n0.07$ and 0.15). We studied the band structure of this system across the phase\ndiagram with the transition from the orthorhombic spin density wave (SDW) phase\nto the tetragonal paramagnetic phase. We observed characteristic features of\nthe electronic structures corresponding to the antiferromagnetic phase in the\nparent compound and the samples with low cobalt concentration ($x = 0.07$). For\nhighly doped systems ($x = 0.15$), the measurements revealed the concentric\nbranches of the Fermi surface, which are associated with paramagnetic and\nsuperconducting 122-iron pnictides. We found the existence of Dirac cones\nlocated at 30 meV below Fermi energy for nonsuperconducting CaFe$_2$As$_2$ and\nsuperconducting CaFe$_{1.93}$Co$_{0.07}$As$_2$ orthorhombic SDW systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11693v1",
    "published": "2025-02-17T11:30:48+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2502.11692v1",
    "title": "An introduction to random rule-based chemical networks",
    "authors": [
      "Jeremie Unterberger"
    ],
    "abstract": "We introduce in this article a random model of reactivity in which a\nprimitive rule, if accepted, generates an infinite number of rules by context\nderivation. The model may be thought of as a toy model of chemical reactivity,\nwhere reactions are accepted if their randomly distributed activation energy is\nbelow a certain threshold. It may be simulated by induction on the level\n(length of the word). We describe some statistical features of the model,\nregarding the number and complexity of the rules, and the shape of the reaction\nnetwork. The complexity index of a rule is defined as the number of covalent\nbonds involved in the rearrangement. The Bernoulli parameter (acceptation\nprobability) of the rules is chosen as fixed in a first model (Model I), and\nexponentially decreasing in the complexity index in a second one (Model II).\nThe two models have very different behaviors, Model II exhibiting a non-trivial\nphase diagram. The main tool for mathematical analysis is an approximate\nmapping to a Galton-Watson tree with generation-dependent progeny\ndistributions. Detailed simulations, demonstrating a general agreement with\ntheoretical estimates, are provided at the end. Extensions to realistic bond\nformation/breaking rules for molecules will be presented elsewhere.",
    "pdf_url": "http://arxiv.org/pdf/2502.11692v1",
    "published": "2025-02-17T11:30:12+00:00",
    "categories": [
      "math.PR",
      "05C80, 92C42, 92E20"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11691v2",
    "title": "Causal Inference for Qualitative Outcomes",
    "authors": [
      "Riccardo Di Francesco",
      "Giovanni Mellace"
    ],
    "abstract": "Causal inference methods such as instrumental variables, regression\ndiscontinuity, and difference-in-differences are widely used to identify and\nestimate treatment effects. However, when outcomes are qualitative, their\napplication poses fundamental challenges. This paper highlights these\nchallenges and proposes an alternative framework that focuses on well-defined\nand interpretable estimands. We show that conventional identification\nassumptions suffice for identifying the new estimands and outline simple,\nintuitive estimation strategies that remain fully compatible with conventional\neconometric methods. We provide an accompanying open-source R package,\n$\\texttt{causalQual}$, which is publicly available on CRAN.",
    "pdf_url": "http://arxiv.org/pdf/2502.11691v2",
    "published": "2025-02-17T11:29:33+00:00",
    "categories": [
      "econ.EM"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2503.00013v3",
    "title": "Reduced order modeling of the unsteady pressure on turbine rotor blades using deep learning",
    "authors": [
      "Dominique Joachim",
      "Salesses Lionel",
      "Thomas Jean-FranÃ§ois",
      "Baert Lieven",
      "Benamara Tariq",
      "Mastrippolito Franck",
      "Flament Theo"
    ],
    "abstract": "In transonic turbine stages, complex interactions between trailing edge\nshocks from nozzle guide vanes and rotor blades generate unsteady wall pressure\nfields, impacting rotor aerodynamic performance and structural integrity. While\nshock-related phenomena are prominent, unsteady pressure fluctuations can also\narise in subsonic regimes from wake interactions. Traditional methods like\nUnsteady Reynolds-Averaged Navier-Stokes (URANS) simulations are accurate but\ncomputationally expensive. To address this, a novel deep learning-based Reduced\nOrder Model (ROM) is proposed, built on a database of URANS simulations, to\npredict unsteady pressure fields on turbine rotor blades at a fraction of the\ncost. The model consists of a Variational Auto-Encoder (VAE) integrated with a\nGated Recurrent Unit (GRU) to capture time-series data, overcoming the\nlimitations of traditional linear ROMs in capturing nonlinear phenomena, such\nas moving shocks. The goal is to develop a ROM that accurately reproduces\nunsteady pressure fields from URANS simulations while reducing computational\ncosts. The ROM is applied to the Turbine Aero-Thermal External Flows (TATEF2)\nproject configuration, a representative test case in turbomachinery research.\nModel performance is evaluated using machine learning quality metrics and\ndesign-oriented criteria, including the accuracy of the first harmonic in the\nFourier transform of the unsteady pressure field. The impact of the simulation\ndatabase size on model accuracy is also analyzed, considering the number of\ntraining simulations required for task-specific accuracy as a key factor in\nindustrial applicability.",
    "pdf_url": "http://arxiv.org/pdf/2503.00013v3",
    "published": "2025-02-17T11:29:16+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11690v1",
    "title": "On the Locality of the LovÃ¡sz Local Lemma",
    "authors": [
      "Peter Davies-Peck"
    ],
    "abstract": "The Lov\\'asz Local Lemma is a versatile result in probability theory,\ncharacterizing circumstances in which a collection of $n$ `bad events', each\noccurring with probability at most $p$ and dependent on a set of underlying\nrandom variables, can be avoided. It is a central tool of the probabilistic\nmethod, since it can be used to show that combinatorial objects satisfying some\ndesirable properties must exist. While the original proof was existential,\nsubsequent work has shown algorithms for the Lov\\'asz Local Lemma: that is, in\ncircumstances in which the lemma proves the existence of some object, these\nalgorithms can constructively find such an object. One main strand of these\nalgorithms, which began with Moser and Tardos's well-known result (JACM 2010),\ninvolves iteratively resampling the dependent variables of satisfied bad events\nuntil none remain satisfied.\n  In this paper, we present a novel analysis that can be applied to\nresampling-style Lov\\'asz Local Lemma algorithms. This analysis shows that an\noutput assignment for the dependent variables of most events can be determined\nonly from $O(\\log \\log_{1/p} n)$-radius local neighborhoods, and that the\nevents whose variables may still require resampling can be identified from\nthese neighborhoods. This allows us to improve randomized complexities for the\nconstructive Lov\\'asz Local Lemma (with polynomial criterion) in several\nparallel and distributed models. In particular, we obtain:\n  1) A LOCAL algorithm with $O(\\log\\log_{1/p} n)$ node-averaged complexity\n(while matching the $O(\\log_{1/p} n)$ worst-case complexity of Chung, Pettie,\nand Su).\n  2) An algorithm for the LCA and VOLUME models requiring $d^{O(\\log\\log_{1/p}\nn)}$ probes per query.\n  3) An $O(\\log\\log\\log_{1/p} n)$-round algorithm for CONGESTED CLIQUE, linear\nspace MPC, and Heterogenous MPC.",
    "pdf_url": "http://arxiv.org/pdf/2502.11690v1",
    "published": "2025-02-17T11:28:55+00:00",
    "categories": [
      "cs.DS",
      "cs.DC",
      "math.PR"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11689v2",
    "title": "Improve LLM-as-a-Judge Ability as a General Ability",
    "authors": [
      "Jiachen Yu",
      "Shaoning Sun",
      "Xiaohui Hu",
      "Jiaxu Yan",
      "Kaidong Yu",
      "Xuelong Li"
    ],
    "abstract": "LLM-as-a-Judge leverages the generative and reasoning capabilities of large\nlanguage models (LLMs) to evaluate LLM responses across diverse scenarios,\nproviding accurate preference signals. This approach plays a vital role in\naligning LLMs with human values, ensuring ethical and reliable AI outputs that\nalign with societal norms. Recent studies have raised many methods to train LLM\nas generative judges, but most of them are data consuming or lack accuracy, and\nonly focus on LLM's judge ability. In this work, we regard judge ability as a\ngeneral ability of LLM and implement a two-stage training approach, comprising\nsupervised fine-tuning (SFT) warm-up and direct preference optimization (DPO)\nenhancement, to achieve judge style adaptation and improve judgment accuracy.\nAdditionally, we introduce an efficient data synthesis method to generate\njudgmental content. Experimental results demonstrate that our approach,\nutilizing only about 2% to 40% of the data required by other methods, achieves\nSOTA performance on RewardBench. Furthermore, our training method enhances the\ngeneral capabilities of the model by constructing complicated judge task, and\nthe judge signals provided by our model have significantly enhanced the\ndownstream DPO training performance of our internal models in our test to\noptimize policy model with Judge Model. We also open-source our model weights\nand training data to facilitate further research.",
    "pdf_url": "http://arxiv.org/pdf/2502.11689v2",
    "published": "2025-02-17T11:28:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2503.16446v1",
    "title": "Is User Perception the Key to Unlocking the Full Potential of Business Process Management Systems (BPMS)? Enhancing BPMS Efficacy Through User Perception",
    "authors": [
      "Alicia Martin-Navarro",
      "Maria Paula Lechuga-Sancho",
      "Marek Szelagowski",
      "Jose Aurelio Medina-Garrido"
    ],
    "abstract": "This study investigates factors influencing employees' perceptions of the\nusefulness of Business Process Management Systems (BPMS) in commercial\nsettings. It explores the roles of system dependency, system quality, and the\nquality of information and knowledge in the adoption and use of BPMS. Data were\ncollected using a structured questionnaire from end-users in various firms and\nanalyzed with Partial Least Squares (PLS). The survey evaluated perceptions of\nservice quality, input quality, system attributes, and overall system quality.\nThe findings indicate that service quality, input quality, and specific system\nattributes significantly influence perceived system quality, while system\ndependency and information quality are predictors of perceived usefulness. The\nresults highlight the importance of user training, support, and high-quality\ninformation in enhancing satisfaction and BPMS. This research offers empirical\nevidence on the factors impacting user perceptions and acceptance, emphasizing\nthe need for user-centric approaches in BPMS.",
    "pdf_url": "http://arxiv.org/pdf/2503.16446v1",
    "published": "2025-02-17T11:28:29+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11688v1",
    "title": "From Isolates to Families: Using Neural Networks for Automated Language Affiliation",
    "authors": [
      "Frederic Blum",
      "Steffen Herbold",
      "Johann-Mattis List"
    ],
    "abstract": "In historical linguistics, the affiliation of languages to a common language\nfamily is traditionally carried out using a complex workflow that relies on\nmanually comparing individual languages. Large-scale standardized collections\nof multilingual wordlists and grammatical language structures might help to\nimprove this and open new avenues for developing automated language affiliation\nworkflows. Here, we present neural network models that use lexical and\ngrammatical data from a worldwide sample of more than 1,000 languages with\nknown affiliations to classify individual languages into families. In line with\nthe traditional assumption of most linguists, our results show that models\ntrained on lexical data alone outperform models solely based on grammatical\ndata, whereas combining both types of data yields even better performance. In\nadditional experiments, we show how our models can identify long-ranging\nrelations between entire subgroups, how they can be employed to investigate\npotential relatives of linguistic isolates, and how they can help us to obtain\nfirst hints on the affiliation of so far unaffiliated languages. We conclude\nthat models for automated language affiliation trained on lexical and\ngrammatical data provide comparative linguists with a valuable tool for\nevaluating hypotheses about deep and unknown language relations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11688v1",
    "published": "2025-02-17T11:25:32+00:00",
    "categories": [
      "cs.CL",
      "J.5"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11687v1",
    "title": "ReVeil: Unconstrained Concealed Backdoor Attack on Deep Neural Networks using Machine Unlearning",
    "authors": [
      "Manaar Alam",
      "Hithem Lamri",
      "Michail Maniatakos"
    ],
    "abstract": "Backdoor attacks embed hidden functionalities in deep neural networks (DNN),\ntriggering malicious behavior with specific inputs. Advanced defenses monitor\nanomalous DNN inferences to detect such attacks. However, concealed backdoors\nevade detection by maintaining a low pre-deployment attack success rate (ASR)\nand restoring high ASR post-deployment via machine unlearning. Existing\nconcealed backdoors are often constrained by requiring white-box or black-box\naccess or auxiliary data, limiting their practicality when such access or data\nis unavailable. This paper introduces ReVeil, a concealed backdoor attack\ntargeting the data collection phase of the DNN training pipeline, requiring no\nmodel access or auxiliary data. ReVeil maintains low pre-deployment ASR across\nfour datasets and four trigger patterns, successfully evades three popular\nbackdoor detection methods, and restores high ASR post-deployment through\nmachine unlearning.",
    "pdf_url": "http://arxiv.org/pdf/2502.11687v1",
    "published": "2025-02-17T11:25:28+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11686v2",
    "title": "Parallel-in-Time Kalman Smoothing Using Orthogonal Transformations",
    "authors": [
      "Shahaf Gargir",
      "Sivan Toledo"
    ],
    "abstract": "We present a numerically-stable parallel-in-time linear Kalman smoother. The\nsmoother uses a novel highly-parallel QR factorization for a class of\nstructured sparse matrices for state estimation, and an adaptation of the\nSelInv selective-inversion algorithm to evaluate the covariance matrices of\nestimated states. Our implementation of the new algorithm, using the Threading\nBuilding Blocks (TBB) library, scales well on both Intel and ARM multi-core\nservers, achieving speedups of up to 47x on 64 cores. The algorithm performs\nmore arithmetic than sequential smoothers; consequently it is 1.8x to 2.5x\nslower on a single core. The new algorithm is faster and scales better than the\nparallel Kalman smoother proposed by S\\\"arkk\\\"a and Garc\\'{\\i}a-Fern\\'andez in\n2021.",
    "pdf_url": "http://arxiv.org/pdf/2502.11686v2",
    "published": "2025-02-17T11:23:29+00:00",
    "categories": [
      "cs.DC",
      "eess.SP"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11685v2",
    "title": "Phase-change materials for volatile threshold resistive switching and neuronal device applications",
    "authors": [
      "Huandong Chen",
      "Jayakanth Ravichandran"
    ],
    "abstract": "Volatile threshold resistive switching and neuronal oscillations in\nphase-change materials, specifically those undergoing metal-to-insulator\ntransitions, offer unique attributes such as fast and low-field volatile\nswitching, tunability, and stochastic dynamics. These characteristics are\nparticularly promising for emulating neuronal behaviors and solving complex\ncomputational problems. In this review, we summarize recent advances in the\ndevelopment of volatile resistive switching devices and neuronal oscillators\nbased on three representative materials with coincident electronic and\nstructural phase transitions, at different levels of technological readiness:\nthe well-studied correlated oxide VO2, the charge-density-wave transition metal\ndichalcogenide 1T-TaS2, and the emerging phase-change chalcogenide perovskite\nBaTiS3. We discuss progresses from the perspective of materials development and\ndevice implementation. Finally, we emphasize the major challenges that must be\naddressed for practical applications of these phase-change materials and\nprovide our outlook on the future research directions in this rapidly evolving\nfield.",
    "pdf_url": "http://arxiv.org/pdf/2502.11685v2",
    "published": "2025-02-17T11:22:35+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11684v1",
    "title": "MathFimer: Enhancing Mathematical Reasoning by Expanding Reasoning Steps through Fill-in-the-Middle Task",
    "authors": [
      "Yuchen Yan",
      "Yongliang Shen",
      "Yang Liu",
      "Jin Jiang",
      "Xin Xu",
      "Mengdi Zhang",
      "Jian Shao",
      "Yueting Zhuang"
    ],
    "abstract": "Mathematical reasoning represents a critical frontier in advancing large\nlanguage models (LLMs). While step-by-step approaches have emerged as the\ndominant paradigm for mathematical problem-solving in LLMs, the quality of\nreasoning steps in training data fundamentally constrains the performance of\nthe models. Recent studies has demonstrated that more detailed intermediate\nsteps can enhance model performance, yet existing methods for step expansion\neither require more powerful external models or incur substantial computational\ncosts. In this paper, we introduce MathFimer, a novel framework for\nmathematical reasoning step expansion inspired by the \"Fill-in-the-middle\" task\nfrom code completion. By decomposing solution chains into prefix-suffix pairs\nand training models to reconstruct missing intermediate steps, we develop a\nspecialized model, MathFimer-7B, on our carefully curated NuminaMath-FIM\ndataset. We then apply these models to enhance existing mathematical reasoning\ndatasets by inserting detailed intermediate steps into their solution chains,\ncreating MathFimer-expanded versions. Through comprehensive experiments on\nmultiple mathematical reasoning datasets, including MathInstruct, MetaMathQA\nand etc., we demonstrate that models trained on MathFimer-expanded data\nconsistently outperform their counterparts trained on original data across\nvarious benchmarks such as GSM8K and MATH. Our approach offers a practical,\nscalable solution for enhancing mathematical reasoning capabilities in LLMs\nwithout relying on powerful external models or expensive inference procedures.",
    "pdf_url": "http://arxiv.org/pdf/2502.11684v1",
    "published": "2025-02-17T11:22:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11683v1",
    "title": "Global Solvability for the Compressible Hookean Viscoelastic Fluids with a Free Boundary in Some Classes of Large Data",
    "authors": [
      "Fei Jiang",
      "Youyi Zhao"
    ],
    "abstract": "Recently Jiang-Jiang established a global (in time) existence result for\nunique strong solutions of the two-dimensional (2D) free-boundary problem of an\nincompressible Hookean viscoelastic fluid, the rest state of which is defined\nin a slab, in some classes of large data [28]. In particular, Jiang-Jiang's\nmathematical result shows that, if the initial free boundary is flat, the way\nthe elastic deformation under the large elasticity coefficient $\\kappa$ acts on\nthe free boundary prevents the natural tendency of the fluid to form\nsingularities, even when the initial velocity is properly large. However it is\nnot clear whether their result can be extended to the corresponding 3D case. In\nthis paper, we further find a similar result in the 3D stratified (immiscible)\ncompressible Hookean viscoelastic fluids in an infinite slab with two\nrestrictive conditions: that the elasticity coefficients of two fluids are\nequal, and that the initial density functions satisfy the asymptotic stability\ncondition in Lagrangian coordinates. These two restrictive conditions in the\ncompressible case contribute us to avoid the essential obstacles that would be\nfaced in the extension of Jiang-Jiang's result from two dimensions to our 3D\ncase. In addition, we can further obtain a new result regarding the vanishing\nphenomena of the nonlinear interactions of solutions with the fixed initial\nvelocity and the initial zero perturbation deformation. Such a new result\nroughly presents that the solutions of the problem considered by us can be\napproximated by the ones of a linear problem for sufficiently large $\\kappa$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11683v1",
    "published": "2025-02-17T11:21:53+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11682v1",
    "title": "Double Momentum and Error Feedback for Clipping with Fast Rates and Differential Privacy",
    "authors": [
      "Rustem Islamov",
      "Samuel Horvath",
      "Aurelien Lucchi",
      "Peter Richtarik",
      "Eduard Gorbunov"
    ],
    "abstract": "Strong Differential Privacy (DP) and Optimization guarantees are two\ndesirable properties for a method in Federated Learning (FL). However, existing\nalgorithms do not achieve both properties at once: they either have optimal DP\nguarantees but rely on restrictive assumptions such as bounded\ngradients/bounded data heterogeneity, or they ensure strong optimization\nperformance but lack DP guarantees. To address this gap in the literature, we\npropose and analyze a new method called Clip21-SGD2M based on a novel\ncombination of clipping, heavy-ball momentum, and Error Feedback. In\nparticular, for non-convex smooth distributed problems with clients having\narbitrarily heterogeneous data, we prove that Clip21-SGD2M has optimal\nconvergence rate and also near optimal (local-)DP neighborhood. Our numerical\nexperiments on non-convex logistic regression and training of neural networks\nhighlight the superiority of Clip21-SGD2M over baselines in terms of the\noptimization performance for a given DP-budget.",
    "pdf_url": "http://arxiv.org/pdf/2502.11682v1",
    "published": "2025-02-17T11:16:21+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11681v4",
    "title": "RIDE: Enhancing Large Language Model Alignment through Restyled In-Context Learning Demonstration Exemplars",
    "authors": [
      "Yuncheng Hua",
      "Lizhen Qu",
      "Zhuang Li",
      "Hao Xue",
      "Flora D. Salim",
      "Gholamreza Haffari"
    ],
    "abstract": "Alignment tuning is crucial for ensuring large language models (LLMs) behave\nethically and helpfully. Current alignment approaches require high-quality\nannotations and significant training resources. This paper proposes a low-cost,\ntuning-free method using in-context learning (ICL) to enhance LLM alignment.\nThrough an analysis of high-quality ICL demos, we identified style as a key\nfactor influencing LLM alignment capabilities and explicitly restyled ICL\nexemplars based on this stylistic framework. Additionally, we combined the\nrestyled demos to achieve a balance between the two conflicting aspects of LLM\nalignment--factuality and safety. We packaged the restyled examples as prompts\nto trigger few-shot learning, improving LLM alignment. Compared to the best\nbaseline approach, with an average score of 5.00 as the maximum, our method\nachieves a maximum 0.10 increase on the Alpaca task (from 4.50 to 4.60), a 0.22\nenhancement on the Just-eval benchmark (from 4.34 to 4.56), and a maximum\nimprovement of 0.32 (from 3.53 to 3.85) on the MT-Bench dataset. We release the\ncode and data at https://github.com/AnonymousCode-ComputerScience/RIDE.",
    "pdf_url": "http://arxiv.org/pdf/2502.11681v4",
    "published": "2025-02-17T11:16:19+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11680v1",
    "title": "Spectral structure learning for clinical time series",
    "authors": [
      "Ivan Lerner",
      "Anita Burgun",
      "Francis Bach"
    ],
    "abstract": "We develop and evaluate a structure learning algorithm for clinical time\nseries. Clinical time series are multivariate time series observed in multiple\npatients and irregularly sampled, challenging existing structure learning\nalgorithms. We assume that our times series are realizations of StructGP, a\nk-dimensional multi-output or multi-task stationary Gaussian process (GP), with\nindependent patients sharing the same covariance function. StructGP encodes\nordered conditional relations between time series, represented in a directed\nacyclic graph. We implement an adapted NOTEARS algorithm, which based on a\ndifferentiable definition of acyclicity, recovers the graph by solving a series\nof continuous optimization problems. Simulation results show that up to mean\ndegree 3 and 20 tasks, we reach a median recall of 0.93% [IQR, 0.86, 0.97]\nwhile keeping a median precision of 0.71% [0.57-0.84], for recovering directed\nedges. We further show that the regularization path is key to identifying the\ngraph. With StructGP, we proposed a model of time series dependencies, that\nflexibly adapt to different time series regularity, while enabling us to learn\nthese dependencies from observations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11680v1",
    "published": "2025-02-17T11:13:39+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11679v2",
    "title": "Change-point problem: Direct estimation using a geometry inspired identifiable reparameterization",
    "authors": [
      "Buddhananda Banerjee",
      "Arnab Kumar Laha"
    ],
    "abstract": "Estimation of mean shift in a temporally ordered sequence of random variables\nwith a possible existence of change-point is an important problem in many\ndisciplines. In the available literature of more than fifty years the\nestimation methods of the mean shift is usually dealt as a two-step problem. A\ntest for the existence of a change-point is followed by an estimation process\nof the mean shift, which is known as testimator. The problem suffers from over\nparametrization. When viewed as an estimation problem, we establish that the\nmaximum likelihood estimator (MLE) always gives a false alarm indicting an\nexistence of a change-point in the given sequence even though there is no\nchange-point at all. After modelling the parameter space as a modified horn\ntorus. We introduce a new method of estimation of the parameters. The newly\nintroduced estimation method of the mean shift is assessed with a proper\nRiemannian metric on that conic manifold. It is seen that its performance is\nsuperior compared to that of the MLE. The proposed method is implemented on\nBitcoin data and compared its performance with the performance of the MLE.",
    "pdf_url": "http://arxiv.org/pdf/2502.11679v2",
    "published": "2025-02-17T11:13:17+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.11678v2",
    "title": "Exploring LLM-based Student Simulation for Metacognitive Cultivation",
    "authors": [
      "Haoxuan Li",
      "Jifan Yu",
      "Xin Cong",
      "Yang Dang",
      "Daniel Zhang-li",
      "Yisi Zhan",
      "Huiqin Liu",
      "Zhiyuan Liu"
    ],
    "abstract": "Metacognitive education plays a crucial role in cultivating students'\nself-regulation and reflective thinking, providing essential support for those\nwith learning difficulties through academic advising. Simulating students with\ninsufficient learning capabilities using large language models offers a\npromising approach to refining pedagogical methods without ethical concerns.\nHowever, existing simulations often fail to authentically represent students'\nlearning struggles and face challenges in evaluation due to the lack of\nreliable metrics and ethical constraints in data collection. To address these\nissues, we propose a pipeline for automatically generating and filtering\nhigh-quality simulated student agents. Our approach leverages a two-round\nautomated scoring system validated by human experts and employs a score\npropagation module to obtain more consistent scores across the student graph.\nExperimental results demonstrate that our pipeline efficiently identifies\nhigh-quality student agents, and we discuss the traits that influence the\nsimulation's effectiveness. By simulating students with varying degrees of\nlearning difficulties, our work paves the way for broader applications in\npersonalized learning and educational assessment.",
    "pdf_url": "http://arxiv.org/pdf/2502.11678v2",
    "published": "2025-02-17T11:12:47+00:00",
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.15782v1",
    "title": "Model-free system identification of surface ships in waves via Hankel dynamic mode decomposition with control",
    "authors": [
      "Giorgio Palma",
      "Andrea Serani",
      "Shawn Aram",
      "David W. Wundrow",
      "David Drazen",
      "Matteo Diez"
    ],
    "abstract": "This study introduces and compares the Hankel dynamic mode decomposition with\ncontrol (Hankel-DMDc) and a novel Bayesian extension of Hankel-DMDc as\nmodel-free (i.e., data-driven and equation-free) approaches for system\nidentification and prediction of free-running ship motions in irregular waves.\nThe proposed DMDc methods create a reduced-order model using limited data from\nthe system state and incoming wave elevation histories, with the latter and\nrudder angle serving as forcing inputs. The inclusion of delayed states of the\nsystem as additional dimensions per the Hankel-DMDc improves the representation\nof the underlying non-linear dynamics of the system by DMD. The approaches are\nstatistically assessed using data from free-running simulations of a 5415M\nhull's course-keeping in irregular beam-quartering waves at sea state 7, a\nhighly severe condition characterized by nonlinear responses near\nroll-resonance. The results demonstrate robust performance and remarkable\ncomputational efficiency. The results indicate that the proposed methods\neffectively identify the dynamic system in analysis. Furthermore, the Bayesian\nformulation incorporates uncertainty quantification and enhances prediction\naccuracy. Ship motions are predicted with good agreement with test data over a\n15 encounter waves observation window. No significant accuracy degradation is\nnoted along the test sequences, suggesting the method can support accurate and\nefficient maritime design and operational planning.",
    "pdf_url": "http://arxiv.org/pdf/2502.15782v1",
    "published": "2025-02-17T11:11:14+00:00",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11677v2",
    "title": "Towards Fully Exploiting LLM Internal States to Enhance Knowledge Boundary Perception",
    "authors": [
      "Shiyu Ni",
      "Keping Bi",
      "Jiafeng Guo",
      "Lulu Yu",
      "Baolong Bi",
      "Xueqi Cheng"
    ],
    "abstract": "Large language models (LLMs) exhibit impressive performance across diverse\ntasks but often struggle to accurately gauge their knowledge boundaries,\nleading to confident yet incorrect responses. This paper explores leveraging\nLLMs' internal states to enhance their perception of knowledge boundaries from\nefficiency and risk perspectives. We investigate whether LLMs can estimate\ntheir confidence using internal states before response generation, potentially\nsaving computational resources. Our experiments on datasets like Natural\nQuestions, HotpotQA, and MMLU reveal that LLMs demonstrate significant\npre-generation perception, which is further refined post-generation, with\nperception gaps remaining stable across varying conditions. To mitigate risks\nin critical domains, we introduce Confidence Consistency-based Calibration\n($C^3$), which assesses confidence consistency through question reformulation.\n$C^3$ significantly improves LLMs' ability to recognize their knowledge gaps,\nenhancing the unknown perception rate by 5.6% on NQ and 4.9% on HotpotQA. Our\nfindings suggest that pre-generation confidence estimation can optimize\nefficiency, while $C^3$ effectively controls output risks, advancing the\nreliability of LLMs in practical applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11677v2",
    "published": "2025-02-17T11:11:09+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11676v1",
    "title": "Iterative Procedure for Non-Linear Fractional Integro-Differential Equations via Daftardar--Jafari Polynomials",
    "authors": [
      "Qasim Khan",
      "Anthony Suen"
    ],
    "abstract": "In this paper, we introduce a novel approach called the Iterative Aboodh\nTransform Method (IATM) which utilizes Daftardar--Jafari polynomials for\nsolving non-linear problems. Such method is employed to derive solutions for\nnon-linear fractional partial integro-differential equations (FPIDEs). The key\nnovelty of the suggested method is that it can be used for handling solutions\nof non-linear FPIDEs in a very simple and effective way. {More precisely, we\nshow that Daftardar--Jafari polynomials have simple calculations as compared to\nAdomian polynomials with higher accuracy}. The results obtained within the\nDaftardar--Jafari polynomials are demonstrated with graphs and tables, and the\nIATM's absolute error confirms the higher accuracy of the suggested method.",
    "pdf_url": "http://arxiv.org/pdf/2502.11676v1",
    "published": "2025-02-17T11:10:48+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.AP"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11675v1",
    "title": "Breaking the Low Concentration Barrier of Single-Molecule Fluorescence Quantification to the Sub-Picomolar Range",
    "authors": [
      "Malavika Kayyil Veedu",
      "JÃ©rÃ´me Wenger"
    ],
    "abstract": "Single-molecule fluorescence techniques provide exceptional sensitivity to\nprobe biomolecular interactions. However, their application to accurately\nquantify analytes at the picomolar concentrations relevant for biosensing\nremains challenged by a severe degradation in the signal-to-background ratio.\nThis so-called 'low concentration barrier' is a major factor hindering the\nbroad application of single-molecule fluorescence to biosensing. Here we break\ninto the low concentration limit while keeping intact the confocal microscope\narchitecture and without requiring complex microfluidics or preconcentration\nstages. Using fluorescence lifetime correlation spectroscopy (FLCS) and adding\na diaphragm to the laser excitation beam, we achieve a limit of quantitation\n(LOQ) down to 0.1 pM, significantly below the state-of-the-art. We identify the\nphysical parameters setting the LOQ and introduce a broadly applicable figure\nof merit (FoM) that determines the LOQ and allows for a clear comparison\nbetween experimental configurations. Our approach preserves the ability to\nmonitor dynamic interactions, diffusion times, and distinguish species in\ncomplex mixtures. We illustrate this feature by measuring the\nbiotin-streptavidin association rate constant which is highly challenging to\nassess quantitatively due to the strong affinity of the biotin-streptavidin\ninteraction. These findings push the boundaries of single-molecule fluorescence\ndetection for biosensing applications at sub-picomolar concentrations with high\naccuracy and simplified systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11675v1",
    "published": "2025-02-17T11:09:50+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.11674v1",
    "title": "On a tree-based variant of bandwidth and forbidding simple topological minors",
    "authors": [
      "Hugo Jacob",
      "William Lochet",
      "Christophe Paul"
    ],
    "abstract": "We obtain structure theorems for graphs excluding a fan (a path with a\nuniversal vertex) or a dipole ($K_{2,k}$) as a topological minor. The\ncorresponding decompositions can be computed in FPT linear time. This is\nmotivated by the study of a graph parameter we call treebandwidth which extends\nthe graph parameter bandwidth by replacing the linear layout by a rooted tree\nsuch that neighbours in the graph are in ancestor-descendant relation in the\ntree.\n  We deduce an approximation algorithm for treebandwidth running in FPT linear\ntime from our structure theorems. We complement this result with a precise\ncharacterisation of the parameterised complexity of computing the parameter\nexactly.",
    "pdf_url": "http://arxiv.org/pdf/2502.11674v1",
    "published": "2025-02-17T11:07:14+00:00",
    "categories": [
      "cs.DM",
      "cs.CC",
      "cs.DS",
      "math.CO"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2503.00012v1",
    "title": "Revision of the linear stability paradox for known bounded shear flows",
    "authors": [
      "Sergey G. Chefranov",
      "Alexander G. Chefranov"
    ],
    "abstract": "The well-known paradox of linear stability for the some bounded shear flows\nis not solved up to now and is bypassed on the basis of the non-linear\nmechanisms consideration. We prove that it is arising only due to an idealized\nassumption of an exact space periodicity for the small hydrodynamic\nperturbations. When finite non-zero viscosity is taken into account only\nquasi-periodic boundary conditions must be used. The conditions of linear\ninstability to the Hagen-Poiseuille flow and to the plane Couette flow are\nobtained.",
    "pdf_url": "http://arxiv.org/pdf/2503.00012v1",
    "published": "2025-02-17T11:04:30+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11673v2",
    "title": "Best of Both Worlds: Regret Minimization versus Minimax Play",
    "authors": [
      "Adrian MÃ¼ller",
      "Jon Schneider",
      "Stratis Skoulakis",
      "Luca Viano",
      "Volkan Cevher"
    ],
    "abstract": "In this paper, we investigate the existence of online learning algorithms\nwith bandit feedback that simultaneously guarantee $O(1)$ regret compared to a\ngiven comparator strategy, and $\\tilde{O}(\\sqrt{T})$ regret compared to any\nfixed strategy, where $T$ is the number of rounds. We provide the first\naffirmative answer to this question whenever the comparator strategy supports\nevery action. In the context of zero-sum games with min-max value zero, both in\nnormal- and extensive form, we show that our results allow us to guarantee to\nrisk at most $O(1)$ loss while being able to gain $\\Omega(T)$ from exploitable\nopponents, thereby combining the benefits of both no-regret algorithms and\nminimax play.",
    "pdf_url": "http://arxiv.org/pdf/2502.11673v2",
    "published": "2025-02-17T11:04:01+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11672v2",
    "title": "Exact Upper and Lower Bounds for the Output Distribution of Neural Networks with Random Inputs",
    "authors": [
      "Andrey Kofnov",
      "Daniel Kapla",
      "Ezio Bartocci",
      "Efstathia Bura"
    ],
    "abstract": "We derive exact upper and lower bounds for the cumulative distribution\nfunction (cdf) of the output of a neural network (NN) over its entire support\nsubject to noisy (stochastic) inputs. The upper and lower bounds converge to\nthe true cdf over its domain as the resolution increases. Our method applies to\nany feedforward NN using continuous monotonic piecewise twice continuously\ndifferentiable activation functions (e.g., ReLU, tanh and softmax) and\nconvolutional NNs, which were beyond the scope of competing approaches. The\nnovelty and instrumental tool of our approach is to bound general NNs with ReLU\nNNs. The ReLU NN-based bounds are then used to derive the upper and lower\nbounds of the cdf of the NN output. Experiments demonstrate that our method\ndelivers guaranteed bounds of the predictive output distribution over its\nsupport, thus providing exact error guarantees, in contrast to competing\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.11672v2",
    "published": "2025-02-17T11:01:03+00:00",
    "categories": [
      "cs.LG",
      "stat.ME",
      "stat.ML",
      "62E15 (Primary) 46N30, 62H10 (Secondary)",
      "G.3; I.5.1"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11671v2",
    "title": "Diversity-oriented Data Augmentation with Large Language Models",
    "authors": [
      "Zaitian Wang",
      "Jinghan Zhang",
      "Xinhao Zhang",
      "Kunpeng Liu",
      "Pengfei Wang",
      "Yuanchun Zhou"
    ],
    "abstract": "Data augmentation is an essential technique in natural language processing\n(NLP) for enriching training datasets by generating diverse samples. This\nprocess is crucial for improving the robustness and generalization capabilities\nof NLP models. However, a significant challenge remains: \\textit{Insufficient\nAttention to Sample Distribution Diversity}. Most existing methods focus on\nincreasing the sample numbers while neglecting the sample distribution\ndiversity, which can lead to model overfitting. In response, we explore data\naugmentation's impact on dataset diversity and propose a\n\\textbf{\\underline{D}}iversity-\\textbf{\\underline{o}}riented data\n\\textbf{\\underline{Aug}}mentation framework (\\textbf{DoAug}). %\n\\(\\mathscr{DoAug}\\) Specifically, we utilize a diversity-oriented fine-tuning\napproach to train an LLM as a diverse paraphraser, which is capable of\naugmenting textual datasets by generating diversified paraphrases. Then, we\napply the LLM paraphraser to a selected coreset of highly informative samples\nand integrate the paraphrases with the original data to create a more diverse\naugmented dataset. Finally, we conduct extensive experiments on 12 real-world\ntextual datasets. The results show that our fine-tuned LLM augmenter improves\ndiversity while preserving label consistency, thereby enhancing the robustness\nand performance of downstream tasks. Specifically, it achieves an average\nperformance gain of \\(10.52\\%\\), surpassing the runner-up baseline with more\nthan three percentage points.",
    "pdf_url": "http://arxiv.org/pdf/2502.11671v2",
    "published": "2025-02-17T11:00:40+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11670v1",
    "title": "Application of maximal subgroups of exceptional groups in s-arc-transitivity of vertex-primitive digraphs (I)",
    "authors": [
      "Fu-Gang Yin",
      "Lei Chen"
    ],
    "abstract": "The investigation of maximal subgroups of simple groups of Lie type is\nintimately related to the study of primitive actions. With the recent\npublication of Craven's paper giving the complete list of the maximal subgroups\nof \\(F_{4}(q)\\), \\(E_{6}(q)\\) and \\({}^{2}E_{6}(q)\\), we are able to thoroughly\nanalyse the primitive action of an exceptional group on an \\(s\\)-arc-transitive\ndigraph and partially answer the following question posed by Giudici and Xia:\nIs there an upper bound on $s$ for finite vertex-primitive $s$-arc-transitive\ndigraphs that are not directed cycles? Giudici and Xia reduced this question to\nthe case where the automorphism group of the digraph is an almost simple group.\nSubsequently, it was proved that $s\\leq 2$ when the simple group is a\nprojective special linear group, projective symplectic group or an alternating\ngroup, and $s\\leq 1$ when the simple group is a Suzuki group, a small Ree\ngroup, or one of the 22 sporadic groups. In this work, we proved that $s\\leq 2$\nwhen the simple group is $ {}^3D_4(q)$, $G_2(q)$, ${}^2F_4(q)$, $F_4(q)$,\n$E_6(q)$ or ${}^2E_6(q)$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11670v1",
    "published": "2025-02-17T11:00:35+00:00",
    "categories": [
      "math.GR",
      "20B25, 05C25"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12218v2",
    "title": "Thermodynamics of EMD-AdS black hole with deformed horizon",
    "authors": [
      "Yusheng Z. He",
      "Jia-Hui Huang",
      "Jinbo Yang"
    ],
    "abstract": "We show that the horizon shapes of static Einstein-Maxwell-dilaton (EMD)\nblack holes can be deformed through an approach analogous to those observed in\nnovel topological black hole solutions supported by two massless axion fields.\nParticularly, the radial part of the spacetime remains unchanged, while the\nangular part has a non-constant Ricci scalar, signaling the presence of\nanisotropy. We further explore the implications of this anisotropy for the\nthermodynamic properties of the black hole. The validity of the Misner-Sharp\n(MS) mass and the unified first law are also addressed in this study.",
    "pdf_url": "http://arxiv.org/pdf/2502.12218v2",
    "published": "2025-02-17T10:58:05+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11669v1",
    "title": "Deep Subspace Learning for Surface Anomaly Classification Based on 3D Point Cloud Data",
    "authors": [
      "Xuanming Cao",
      "Chengyu Tao",
      "Juan Du"
    ],
    "abstract": "Surface anomaly classification is critical for manufacturing system fault\ndiagnosis and quality control. However, the following challenges always hinder\naccurate anomaly classification in practice: (i) Anomaly patterns exhibit\nintra-class variation and inter-class similarity, presenting challenges in the\naccurate classification of each sample. (ii) Despite the predefined classes,\nnew types of anomalies can occur during production that require to be detected\naccurately. (iii) Anomalous data is rare in manufacturing processes, leading to\nlimited data for model learning. To tackle the above challenges simultaneously,\nthis paper proposes a novel deep subspace learning-based 3D anomaly\nclassification model. Specifically, starting from a lightweight encoder to\nextract the latent representations, we model each class as a subspace to\naccount for the intra-class variation, while promoting distinct subspaces of\ndifferent classes to tackle the inter-class similarity. Moreover, the explicit\nmodeling of subspaces offers the capability to detect out-of-distribution\nsamples, i.e., new types of anomalies, and the regularization effect with much\nfewer learnable parameters of our proposed subspace classifier, compared to the\npopular Multi-Layer Perceptions (MLPs). Extensive numerical experiments\ndemonstrate our method achieves better anomaly classification results than\nbenchmark methods, and can effectively identify the new types of anomalies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11669v1",
    "published": "2025-02-17T10:57:53+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.11668v2",
    "title": "NablAFx: A Framework for Differentiable Black-box and Gray-box Modeling of Audio Effects",
    "authors": [
      "Marco ComunitÃ ",
      "Christian J. Steinmetz",
      "Joshua D. Reiss"
    ],
    "abstract": "We present NablAFx, an open-source framework developed to support research in\ndifferentiable black-box and gray-box modeling of audio effects. Built in\nPyTorch, NablAFx offers a versatile ecosystem to configure, train, evaluate,\nand compare various architectural approaches. It includes classes to manage\nmodel architectures, datasets, and training, along with features to compute and\nlog losses, metrics and media, and plotting functions to facilitate detailed\nanalysis. It incorporates implementations of established black-box\narchitectures and conditioning methods, as well as differentiable DSP blocks\nand controllers, enabling the creation of both parametric and non-parametric\ngray-box signal chains. The code is accessible at\nhttps://github.com/mcomunita/nablafx.",
    "pdf_url": "http://arxiv.org/pdf/2502.11668v2",
    "published": "2025-02-17T10:56:32+00:00",
    "categories": [
      "cs.SD"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2502.11667v1",
    "title": "A comprehensive Gaia view of ellipsoidal and rotational red giant binaries",
    "authors": [
      "Camila Navarrete",
      "Alejandra Recio-Blanco",
      "Patrick de Laverny",
      "Ana Escorza"
    ],
    "abstract": "The latest Gaia Focused Product Release (FPR) provided variability\ninformation for $\\sim$1000 long-period red giant binaries, the largest sample\nto date of this binary type having both photometric and spectroscopic time\nseries observations. We cross-matched the Gaia DR3 measurements with the\ncatalogue of long-period red giant candidates from the Gaia FPR, having\nphotometric and radial velocity variability information. Combined with the\nphoto-geometric distances, the extinction, bolometric magnitude, luminosity,\nspectroscopic radius and mass were estimated. ELL variables are characterized\nto be low to intermediate-mass stars, with radii as large as the Roche lobe\nradius of the binary. Eccentricities tend to be lower for primary stars with\nsmaller radii, as the expected result of tidal circularization. Combined with\nthe orbital properties, estimates for the minimum mass of the companion agree\nwith the scenario of a low-mass compact object as the secondary star. There are\nat least 14 ELL binaries with orbital periods and masses compatible with model\npredictions for Type Ia SN progenitors. For the rotational variables, their\norbital periods, enhanced chromospheric activity, smaller radii and low mass\npoint to a different type of binaries than the original ELL sample. The\nvelocity dispersion is much higher in ELL than in rotational binaries, probably\nindicating older/younger dynamical ages. The enhanced [$\\alpha$/Fe] abundances\nfor some of the ELL binaries resemble the population of young $\\alpha$-rich\nbinaries in the thick disk. An episode of mass transfer in those systems may\nhave produced the enhanced $\\alpha$ abundances, and the enhanced [Ce/Fe]\nabundances reported in a few ELL binaries. Luminosities, radii and masses were\nderived for 243 ELL and 39 rotational binary candidates, the largest Galactic\nsample of these variables, having chemo-dynamical and physical\nparameterization.",
    "pdf_url": "http://arxiv.org/pdf/2502.11667v1",
    "published": "2025-02-17T10:56:29+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11666v1",
    "title": "Towards the classification of scattered binomials",
    "authors": [
      "Daniele Bartoli",
      "Francesco Ghiandoni",
      "Alessandro Giannoni",
      "Giuseppe Marino"
    ],
    "abstract": "Let \\( q \\) be a prime power and \\( n \\) an integer. An \\( \\mathbb{F}_q\n\\)-linearized polynomial \\( f \\) is said to be scattered if it satisfies the\ncondition that for all \\( x, y \\in \\mathbb{F}_q^n \\setminus \\{ 0 \\} \\),\nwhenever \\( \\frac{f(x)}{x} = \\frac{f(y)}{y} \\), it follows that \\( \\frac{x}{y}\n\\in \\mathbb{F}_q \\).\n  In this paper, we focus on scattered binomials. Two families of scattered\nbinomials are currently known: the one from Lunardon and Polverino (LP), given\nby $f(x) = \\delta x^{q^s} + x^{q^{n-s}},$ and the one from Csajb\\'ok, Marino,\nPolverino, and Zanella (CMPZ), given by $f(x) = \\delta x^{q^s} + x^{q^{s +\nn/2}},$ where \\( n = 6 \\) or \\( n = 8 \\).\n  Using algebraic varieties as a tool, we prove some necessary conditions for a\nbinomial to be scattered. As a corollary, we obtain that when \\( q \\) is\nsufficiently large and \\( n \\) is prime, a binomial is scattered if and only if\nit is of the form (LP). Moreover we obtain a complete classification of\nscattered binomial in $\\Fn$ when $n\\leq8$ and $q$ is large enough.",
    "pdf_url": "http://arxiv.org/pdf/2502.11666v1",
    "published": "2025-02-17T10:54:48+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11665v2",
    "title": "On the kernel learning problem",
    "authors": [
      "Yang Li",
      "Feng Ruan"
    ],
    "abstract": "The classical kernel ridge regression problem aims to find the best fit for\nthe output $Y$ as a function of the input data $X\\in \\mathbb{R}^d$, with a\nfixed choice of regularization term imposed by a given choice of a reproducing\nkernel Hilbert space, such as a Sobolev space. Here we consider a\ngeneralization of the kernel ridge regression problem, by introducing an extra\nmatrix parameter $U$, which aims to detect the scale parameters and the feature\nvariables in the data, and thereby improve the efficiency of kernel ridge\nregression. This naturally leads to a nonlinear variational problem to optimize\nthe choice of $U$. We study various foundational mathematical aspects of this\nvariational problem, and in particular how this behaves in the presence of\nmultiscale structures in the data.",
    "pdf_url": "http://arxiv.org/pdf/2502.11665v2",
    "published": "2025-02-17T10:54:01+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.CA",
      "math.FA",
      "math.OC"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.11664v3",
    "title": "VRoPE: Rotary Position Embedding for Video Large Language Models",
    "authors": [
      "Zikang Liu",
      "Longteng Guo",
      "Yepeng Tang",
      "Tongtian Yue",
      "Junxian Cai",
      "Kai Ma",
      "Qingbin Liu",
      "Xi Chen",
      "Jing Liu"
    ],
    "abstract": "Rotary Position Embedding (RoPE) has shown strong performance in text-based\nLarge Language Models (LLMs), but extending it to video remains a challenge due\nto the intricate spatiotemporal structure of video frames. Existing\nadaptations, such as RoPE-3D, attempt to encode spatial and temporal dimensions\nseparately but suffer from two major limitations: positional bias in attention\ndistribution and disruptions in video-text transitions. To overcome these\nissues, we propose Video Rotary Position Embedding (VRoPE), a novel positional\nencoding method tailored for Video-LLMs. Specifically, we introduce a more\nbalanced encoding strategy that mitigates attention biases, ensuring a more\nuniform distribution of spatial focus. Additionally, our approach restructures\npositional indices to ensure a smooth transition between video and text tokens.\nExtensive experiments on different models demonstrate that VRoPE consistently\noutperforms previous RoPE variants, achieving significant improvements in video\nunderstanding, temporal reasoning, and retrieval tasks. Code will be available\nat https://github.com/johncaged/VRoPE.",
    "pdf_url": "http://arxiv.org/pdf/2502.11664v3",
    "published": "2025-02-17T10:53:57+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11663v1",
    "title": "MaskGWM: A Generalizable Driving World Model with Video Mask Reconstruction",
    "authors": [
      "Jingcheng Ni",
      "Yuxin Guo",
      "Yichen Liu",
      "Rui Chen",
      "Lewei Lu",
      "Zehuan Wu"
    ],
    "abstract": "World models that forecast environmental changes from actions are vital for\nautonomous driving models with strong generalization. The prevailing driving\nworld model mainly build on video prediction model. Although these models can\nproduce high-fidelity video sequences with advanced diffusion-based generator,\nthey are constrained by their predictive duration and overall generalization\ncapabilities. In this paper, we explore to solve this problem by combining\ngeneration loss with MAE-style feature-level context learning. In particular,\nwe instantiate this target with three key design: (1) A more scalable Diffusion\nTransformer (DiT) structure trained with extra mask construction task. (2) we\ndevise diffusion-related mask tokens to deal with the fuzzy relations between\nmask reconstruction and generative diffusion process. (3) we extend mask\nconstruction task to spatial-temporal domain by utilizing row-wise mask for\nshifted self-attention rather than masked self-attention in MAE. Then, we adopt\na row-wise cross-view module to align with this mask design. Based on above\nimprovement, we propose MaskGWM: a Generalizable driving World Model embodied\nwith Video Mask reconstruction. Our model contains two variants: MaskGWM-long,\nfocusing on long-horizon prediction, and MaskGWM-mview, dedicated to multi-view\ngeneration. Comprehensive experiments on standard benchmarks validate the\neffectiveness of the proposed method, which contain normal validation of\nNuscene dataset, long-horizon rollout of OpenDV-2K dataset and zero-shot\nvalidation of Waymo dataset. Quantitative metrics on these datasets show our\nmethod notably improving state-of-the-art driving world model.",
    "pdf_url": "http://arxiv.org/pdf/2502.11663v1",
    "published": "2025-02-17T10:53:56+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11662v1",
    "title": "Enhanced Gilbert Damping via Cubic Spin-Orbit Coupling at 2DHG/Ferromagnetic Insulator Interface",
    "authors": [
      "Sushmita Saha",
      "Alestin Mawrie"
    ],
    "abstract": "We investigate the enhancement of Gilbert damping at 2DHG/ferromagnetic\ninsulator (FI) interfaces, where spin pumping from the FI layer injects spins\ninto the 2DHG, and cubic Rashba spin-orbit coupling (RSOC) significantly boosts\nspin relaxation and spin-pumping efficiency compared to 2DEG systems. The\ndominant contribution to spin damping arises from interband transitions which\ndoes exhibits conductivity-like behavior as the temperature, \\( T \\to 0 \\). Our\nresults reveal that damping remains stronger than in 2DEG due to the persistent\ninfluence of cubic RSOC. The interplay between RSOC and magnon absorption\nbroadens the spectral response, with the damping peak shifting more notably at\nhigher temperatures. Stronger RSOC expands the magnon interaction phase space,\nthus widening the damping spectrum. A key observation emerges with the Fermi\nlevel (\\(E_f\\)): a finite \\(E_f\\) sustains spin imbalance and enhances damping,\nwhereas \\(E_f = 0\\) suppresses it, unlike in 2DEG. The electric field\ntunability of RSOC enables real-time control over spin relaxation and angular\nmomentum transfer, offering a pathway toward voltage-controlled spintronic\ndevices. These findings highlight the superior potential of 2DHG for tailoring\nspin dynamics via electric and thermal effects.",
    "pdf_url": "http://arxiv.org/pdf/2502.11662v1",
    "published": "2025-02-17T10:53:54+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11661v1",
    "title": "Single-dimensional Contract Design: Efficient Algorithms and Learning",
    "authors": [
      "Martino Bernasconi",
      "Matteo Castiglioni",
      "Andrea Celli"
    ],
    "abstract": "We study a Bayesian contract design problem in which a principal interacts\nwith an unknown agent. We consider the single-parameter uncertainty model\nintroduced by Alon et al. [2021], in which the agent's type is described by a\nsingle parameter, i.e., the cost per unit-of-effort. Despite its simplicity,\nseveral works have shown that single-dimensional contract design is not\nnecessarily easier than its multi-dimensional counterpart in many respects.\nPerhaps the most surprising result is the reduction by Castiglioni et al .\n[2025] from multi- to single-dimensional contract design. However, their\nreduction preserves only multiplicative approximations, leaving open the\nquestion of whether additive approximations are easier to obtain than\nmultiplicative ones. In this paper, we answer this question -- to some extent\n-- positively. In particular, we provide an additive PTAS for these problems\nwhile also ruling out the existence of an additive FPTAS. This, in turn,\nimplies that no reduction from multi- to single-dimensional contracts can\npreserve additive approximations. Moreover, we show that single-dimensional\ncontract design is fundamentally easier than its multi-dimensional counterpart\nfrom a learning perspective. Under mild assumptions, we show that optimal\ncontracts can be learned efficiently, providing results on both regret and\nsample complexity.",
    "pdf_url": "http://arxiv.org/pdf/2502.11661v1",
    "published": "2025-02-17T10:52:24+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11660v1",
    "title": "Accelerating Elliptic Curve Point Additions on Versal AI Engine for Multi-scalar Multiplication",
    "authors": [
      "Ayumi Ohno",
      "Kotaro Shimamura",
      "Shinya Takamaeda-Yamazaki"
    ],
    "abstract": "Multi-scalar multiplication (MSM) is crucial in cryptographic applications\nand computationally intensive in zero-knowledge proofs. MSM involves\naccumulating the products of scalars and points on an elliptic curve over a\n377-bit modulus, and the Pippenger algorithm converts MSM into a series of\nelliptic curve point additions (PADDs) with high parallelism. This study\ninvestigates accelerating MSM on the Versal ACAP platform, an emerging hardware\nthat employs a spatial architecture integrating 400 AI Engines (AIEs) with\nprogrammable logic and a processing system. AIEs are SIMD-based VLIW processors\ncapable of performing vector multiply-accumulate operations, making them\nwell-suited for multiplication-heavy workloads in PADD. Unlike simpler\nmultiplication tasks in previous studies, cryptographic computations also\nrequire complex operations such as carry propagation. These operations\nnecessitate architecture-aware optimizations, including intra-core dedicated\ncoding style to fully exploit VLIW capabilities and inter-core strategy for\nspatial task mapping. We propose various optimizations to accelerate PADDs,\nincluding (1) algorithmic optimizations for carry propagation employing a\ncarry-save-like technique to exploit VLIW and SIMD capabilities and (2) a\ncomparison of four distinct spatial mappings to enhance intra- and inter-task\nparallelism. Our approach achieves a computational efficiency that utilizes\n50.2% of the theoretical memory bandwidth and provides 568 speedup over the\nintegrated CPU on the AIE evaluation board.",
    "pdf_url": "http://arxiv.org/pdf/2502.11660v1",
    "published": "2025-02-17T10:50:07+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11659v2",
    "title": "An Innovative Brain-Computer Interface Interaction System Based on the Large Language Model",
    "authors": [
      "Jing Jin",
      "Yutao Zhang",
      "Ruitian Xu",
      "Yixin Chen"
    ],
    "abstract": "Recent advancements in large language models (LLMs) provide a more effective\npathway for upgrading brain-computer interface (BCI) technology in terms of\nuser interaction. The widespread adoption of BCIs in daily application\nscenarios is still limited by factors such as their single functionality,\nrestricted paradigm design, weak multilingual support, and low levels of\nintelligence. In this paper, we propose an innovative BCI system that deeply\nintegrates a steady-state visual evoked potential (SSVEP) speller with an LLM\napplication programming interface (API). It allows natural language input\nthrough the SSVEP speller and dynamically calls large models to generate SSVEP\nparadigms. The command prompt, blinking frequency, and layout position are\nadjustable to meet the user's control requirements in various scenarios. More\nthan ten languages are compatible with the multilingual support of LLM. A\nvariety of task scenarios, such as home appliance control, robotic arm\noperation, and unmanned aerial vehicle (UAV) management are provided. The task\ninterfaces of the system can be personalized according to the user's habits,\nusage scenarios, and equipment characteristics. By combining the SSVEP speller\nwith an LLM, the system solves numerous challenges faced by current BCI systems\nand makes breakthroughs in functionality, intelligence, and multilingual\nsupport. The introduction of LLM not only enhances user experience but also\nexpands the potential applications of BCI technology in real-world\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2502.11659v2",
    "published": "2025-02-17T10:49:40+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11658v3",
    "title": "\"I'm not for sale\" -- Perceptions and limited awareness of privacy risks by digital natives about location data",
    "authors": [
      "Antoine Boutet",
      "Victor Morel"
    ],
    "abstract": "Although mobile devices benefit users in their daily lives in numerous ways,\nthey also raise several privacy concerns. For instance, they can reveal\nsensitive information that can be inferred from location data. This location\ndata is shared through service providers as well as mobile applications.\nUnderstanding how and with whom users share their location data -- as well as\nusers' perception of the underlying privacy risks --, are important notions to\ngrasp in order to design usable privacy-enhancing technologies. In this work,\nwe perform a quantitative and qualitative analysis of smartphone users'\nawareness, perception and self-reported behavior towards location data-sharing\nthrough a survey of n=99 young adult participants (i.e., digital natives). We\ncompare stated practices with actual behaviors to better understand their\nmental models, and survey participants' understanding of privacy risks before\nand after the inspection of location traces and the information that can be\ninferred therefrom.\n  Our empirical results show that participants have risky privacy practices:\nabout 54% of participants underestimate the number of mobile applications to\nwhich they have granted access to their data, and 33% forget or do not think of\nrevoking access to their data. Also, by using a demonstrator to perform\ninferences from location data, we observe that slightly more than half of\nparticipants (57%) are surprised by the extent of potentially inferred\ninformation, and that 47% intend to reduce access to their data via permissions\nas a result of using the demonstrator. Last, a majority of participants have\nlittle knowledge of the tools to better protect themselves, but are nonetheless\nwilling to follow suggestions to improve privacy (51%). Educating people,\nincluding digital natives, about privacy risks through transparency tools seems\na promising approach.",
    "pdf_url": "http://arxiv.org/pdf/2502.11658v3",
    "published": "2025-02-17T10:49:23+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11657v2",
    "title": "How does ion temperature gradient turbulence depend on magnetic geometry? Insights from data and machine learning",
    "authors": [
      "Matt Landreman",
      "Jong Youl Choi",
      "Caio Alves",
      "Prasanna Balaprakash",
      "R. Michael Churchill",
      "Rory Conlin",
      "Gareth Roberg-Clark"
    ],
    "abstract": "Magnetic geometry has a significant effect on the level of turbulent\ntransport in fusion plasmas. Here, we model and analyze this dependence using\nmultiple machine learning methods and a dataset of > 200,000 nonlinear\nsimulations of ion-temperature-gradient turbulence in diverse non-axisymmetric\ngeometries. The dataset is generated using a large collection of both optimized\nand randomly generated stellarator equilibria. At fixed gradients, the\nturbulent heat flux varies between geometries by several orders of magnitude.\nTrends are apparent among the configurations with particularly high or low heat\nflux. Regression and classification techniques from machine learning are then\napplied to extract patterns in the dataset. Due to a symmetry of the\ngyrokinetic equation, the heat flux and regressions thereof should be invariant\nto translations of the raw features in the parallel coordinate, similar to\ntranslation invariance in computer vision applications. Multiple regression\nmodels including convolutional neural networks (CNNs) and decision trees can\nachieve reasonable predictive power for the heat flux in held-out test\nconfigurations, with highest accuracy for the CNNs. Using Spearman correlation,\nsequential feature selection, and Shapley values to measure feature importance,\nit is consistently found that the most important geometric lever on the heat\nflux is the flux surface compression in regions of bad curvature. The second\nmost important feature relates to the magnitude of geodesic curvature. These\ntwo features align remarkably with surrogates that have been proposed based on\ntheory, while the methods here allow a natural extension to more features for\nincreased accuracy. The dataset, released with this publication, may also be\nused to test other proposed surrogates, and we find many previously published\nproxies do correlate well with both the heat flux and stability boundary.",
    "pdf_url": "http://arxiv.org/pdf/2502.11657v2",
    "published": "2025-02-17T10:48:26+00:00",
    "categories": [
      "physics.plasm-ph",
      "cs.LG"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11656v1",
    "title": "Uncovering the Impact of Chain-of-Thought Reasoning for Direct Preference Optimization: Lessons from Text-to-SQL",
    "authors": [
      "Hanbing Liu",
      "Haoyang Li",
      "Xiaokang Zhang",
      "Ruotong Chen",
      "Haiyong Xu",
      "Tian Tian",
      "Qi Qi",
      "Jing Zhang"
    ],
    "abstract": "Direct Preference Optimization (DPO) has proven effective in complex\nreasoning tasks like math word problems and code generation. However, when\napplied to Text-to-SQL datasets, it often fails to improve performance and can\neven degrade it. Our investigation reveals the root cause: unlike math and code\ntasks, which naturally integrate Chain-of-Thought (CoT) reasoning with DPO,\nText-to-SQL datasets typically include only final answers (gold SQL queries)\nwithout detailed CoT solutions. By augmenting Text-to-SQL datasets with\nsynthetic CoT solutions, we achieve, for the first time, consistent and\nsignificant performance improvements using DPO. Our analysis shows that CoT\nreasoning is crucial for unlocking DPO's potential, as it mitigates reward\nhacking, strengthens discriminative capabilities, and improves scalability.\nThese findings offer valuable insights for building more robust Text-to-SQL\nmodels. To support further research, we publicly release the code and\nCoT-enhanced datasets.",
    "pdf_url": "http://arxiv.org/pdf/2502.11656v1",
    "published": "2025-02-17T10:47:17+00:00",
    "categories": [
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11655v1",
    "title": "Object-Centric Image to Video Generation with Language Guidance",
    "authors": [
      "Angel Villar-Corrales",
      "Gjergj Plepi",
      "Sven Behnke"
    ],
    "abstract": "Accurate and flexible world models are crucial for autonomous systems to\nunderstand their environment and predict future events. Object-centric models,\nwith structured latent spaces, have shown promise in modeling object dynamics\nand interactions, but often face challenges in scaling to complex datasets and\nincorporating external guidance, limiting their applicability in robotics. To\naddress these limitations, we propose TextOCVP, an object-centric model for\nimage-to-video generation guided by textual descriptions. TextOCVP parses an\nobserved scene into object representations, called slots, and utilizes a\ntext-conditioned transformer predictor to forecast future object states and\nvideo frames. Our approach jointly models object dynamics and interactions\nwhile incorporating textual guidance, thus leading to accurate and controllable\npredictions. Our method's structured latent space offers enhanced control over\nthe prediction process, outperforming several image-to-video generative\nbaselines. Additionally, we demonstrate that structured object-centric\nrepresentations provide superior controllability and interpretability,\nfacilitating the modeling of object dynamics and enabling more precise and\nunderstandable predictions. Videos and code are available at\nhttps://play-slot.github.io/TextOCVP/.",
    "pdf_url": "http://arxiv.org/pdf/2502.11655v1",
    "published": "2025-02-17T10:46:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11654v1",
    "title": "Bose-Bose gases with nonuniversal corrections to the interactions: a droplet phase",
    "authors": [
      "Emerson Chiquillo"
    ],
    "abstract": "Through an effective quantum field theory within Bogoliubov's framework and\ntaking into account nonuniversal effects of the interatomic potential we\nanalytically derive the leading Gaussian zero- and finite-temperature\ncorrections to the equation of state of ultracold interacting Bose-Bose gases.\nWe calculate the ground-state energy per particle at zero and low temperature\nfor three-, two- and one-dimensional two-component bosonic gases. By tuning the\nnonuniversal contribution to the interactions we address and establish\nconditions under which the formation and stability of a self-bound liquidlike\nphase or droplet with nonuniversal corrections to the interactions DNUC) is\nfavorable. At zero temperature in three-dimensions and considering the\nnonuniversal corrections to the attractive interactions as a fitting parameter\nthe energy per particle for DNUC is in good agreement with some diffusion Monte\nCarlo results. In two dimensions the DNUC present small deviations regarding\nconventional droplets. For the one-dimensional DNUC the handling of the\nnonuniversal effects to the interactions achieves a qualitative agreement with\nthe trend of some available Monte Carlo data in usual droplets. We also\nintroduce some improved Gross-Pitaevskii equations to describe self-trapped\nDNUC in three, two and one dimension. We briefly discuss some aspects at low\ntemperature regarding nonuniversal corrections to the interactions in Bose-Bose\ngases. We derive the dependencies on the nonuniversal contribution to the\ninteractions but also on the difference between intra- and inter-species\ncoupling constants. This last dependence crucially affect the three- and the\ntwo-dimensional DNUC driving thus to a thermal-induced instability. This\nthermal instability is also present in one-dimensional Bose-Bose gases, but it\nis not relevant on the formation of DNUC...",
    "pdf_url": "http://arxiv.org/pdf/2502.11654v1",
    "published": "2025-02-17T10:46:01+00:00",
    "categories": [
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2502.11653v1",
    "title": "Training Channel Selection for Learning-based 1-bit Precoding in Massive MU-MIMO",
    "authors": [
      "Sitian Li",
      "Andreas Burg",
      "Alexios Balatsoukas-Stimming"
    ],
    "abstract": "Learning-based algorithms have gained great popularity in communications\nsince they often outperform even carefully engineered solutions by learning\nfrom training samples. In this paper, we show that the selection of appropriate\ntraining examples can be important for the performance of such learning-based\nalgorithms. In particular, we consider non-linear 1-bit precoding for massive\nmulti-user MIMO systems using the C2PO algorithm. While previous works have\nalready shown the advantages of learning critical coefficients of this\nalgorithm, we demonstrate that straightforward selection of training samples\nthat follow the channel model distribution does not necessarily lead to the\nbest result. Instead, we provide a strategy to generate training data based on\nthe specific properties of the algorithm, which significantly improves its\nerror floor performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11653v1",
    "published": "2025-02-17T10:45:45+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11652v1",
    "title": "A new banded Petrov--Galerkin spectral method",
    "authors": [
      "Ouyuan Qin",
      "Lu Cheng",
      "Kuan Xu"
    ],
    "abstract": "We propose a Petrov--Galerkin spectral method for ODEs with variable\ncoefficients. When the variable coefficients are smooth, the new method yields\na strictly banded linear system, which can be efficiently constructed and\nsolved in linear complexity. The performance advantage of our method is\ndemonstrated through benchmarking against Mortensen's Galerkin method and the\nultraspherical spectral method. Furthermore, we introduce a systematic approach\nfor designing the recombined basis and establish that our new method serves as\na unifying framework that encompasses all existing banded Galerkin spectral\nmethods. This significantly addresses the ongoing challenge of developing\nrecombined bases and sparse Galerkin spectral method. Additionally, the\naccelerating techniques presented in this paper can also enhance the\nperformance of the ultraspherical spectral method.",
    "pdf_url": "http://arxiv.org/pdf/2502.11652v1",
    "published": "2025-02-17T10:45:15+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11651v2",
    "title": "MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease Progression",
    "authors": [
      "Linjie Mu",
      "Zhongzhen Huang",
      "Shengqian Qin",
      "Yakun Zhu",
      "Shaoting Zhang",
      "Xiaofan Zhang"
    ],
    "abstract": "Large vision-language models (LVLMs) have shown great promise in medical\napplications, particularly in visual question answering (MedVQA) and diagnosis\nfrom medical images. However, existing datasets and models often fail to\nconsider critical aspects of medical diagnostics, such as the integration of\nhistorical records and the analysis of disease progression over time. In this\npaper, we introduce MMXU (Multimodal and MultiX-ray Understanding), a novel\ndataset for MedVQA that focuses on identifying changes in specific regions\nbetween two patient visits. Unlike previous datasets that primarily address\nsingle-image questions, MMXU enables multi-image questions, incorporating both\ncurrent and historical patient data. We demonstrate the limitations of current\nLVLMs in identifying disease progression on MMXU-\\textit{test}, even those that\nperform well on traditional benchmarks. To address this, we propose a\nMedRecord-Augmented Generation (MAG) approach, incorporating both global and\nregional historical records. Our experiments show that integrating historical\nrecords significantly enhances diagnostic accuracy by at least 20\\%, bridging\nthe gap between current LVLMs and human expert performance. Additionally, we\nfine-tune models with MAG on MMXU-\\textit{dev}, which demonstrates notable\nimprovements. We hope this work could illuminate the avenue of advancing the\nuse of LVLMs in medical diagnostics by emphasizing the importance of historical\ncontext in interpreting medical images. Our dataset is released at github:\nhttps://github.com/linjiemu/MMXU.",
    "pdf_url": "http://arxiv.org/pdf/2502.11651v2",
    "published": "2025-02-17T10:43:38+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11650v1",
    "title": "\"I'm 73, you can't expect me to have multiple passwords\": Password Management Concerns and Solutions of Irish Older Adults",
    "authors": [
      "Ashley Sheil",
      "Jacob Camilleri",
      "Michelle O'Keeffe",
      "Melanie Gruben",
      "Moya Cronin",
      "Hazel Murray"
    ],
    "abstract": "Based on Irish older adult's perceptions, practices, and challenges regarding\npassword management, the goal of this study was to compile suitable advice that\ncan benefit this demographic. To achieve this, we first conducted semi\nstructured interviews (n=37), we then collated advice based on best practice\nand what we learned from these interviews. We facilitated two independent focus\ngroups (n=31) to evaluate and adjust this advice and tested the finalized\nadvice through an observational study (n=15). The participants were aged\nbetween 59 and 86 and came from various counties in Ireland, both rural and\nurban. The findings revealed that managing multiple passwords was a significant\nsource of frustration, leading some participants to adopt novel and informal\nstrategies for storing them. A notable hesitation to adopt digital password\nmanagers and passphrases was also observed. Participants appreciated guidance\non improving their password practices, with many affirming that securely\nwriting down passwords was a practical strategy. Irish older adults\ndemonstrated strong intuition regarding cybersecurity, notably expressing\nconcerns over knowledge-based security checks used by banks and government\ninstitutions. This study aims to contribute to the aggregation of practical\npassword advice suited to older adults, making password security more\nmanageable and less burdensome for this demographic.",
    "pdf_url": "http://arxiv.org/pdf/2502.11650v1",
    "published": "2025-02-17T10:42:13+00:00",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11649v3",
    "title": "Competing LLM Agents in a Non-Cooperative Game of Opinion Polarisation",
    "authors": [
      "Amin Qasmi",
      "Usman Naseem",
      "Mehwish Nasim"
    ],
    "abstract": "We introduce a novel non-cooperative game to analyse opinion formation and\nresistance, incorporating principles from social psychology such as\nconfirmation bias, resource constraints, and influence penalties. Our\nsimulation features Large Language Model (LLM) agents competing to influence a\npopulation, with penalties imposed for generating messages that propagate or\ncounter misinformation. This framework integrates resource optimisation into\nthe agents' decision-making process. Our findings demonstrate that while higher\nconfirmation bias strengthens opinion alignment within groups, it also\nexacerbates overall polarisation. Conversely, lower confirmation bias leads to\nfragmented opinions and limited shifts in individual beliefs. Investing heavily\nin a high-resource debunking strategy can initially align the population with\nthe debunking agent, but risks rapid resource depletion and diminished\nlong-term influence",
    "pdf_url": "http://arxiv.org/pdf/2502.11649v3",
    "published": "2025-02-17T10:41:55+00:00",
    "categories": [
      "cs.AI",
      "cs.SI",
      "I.6; I.2.7"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11648v3",
    "title": "Astrometric Measurements and Analysis of Double Star System BRT 376",
    "authors": [
      "Xinyue Wang"
    ],
    "abstract": "Using new telescope images and archival data, we investigated the positions\nand motions of the stars in double star system 06160-0745 BRT 376. We found\nthat the two stars share nearly identical parallaxes and exhibit a low relative\nproper motion, suggesting they move together through space. Furthermore, their\ncombined 3D velocity is less than the calculated escape velocity, indicating\nthey are gravitationally bound rather than just physically near each other.\nThese findings point to 06160-0745 BRT 376 being a true binary system. Future\nobservations will help refine our understanding of its orbital path and further\nilluminate the nature of stars in close, interacting pairs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11648v3",
    "published": "2025-02-17T10:40:17+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.13170v2",
    "title": "Unveiling the Magic of Code Reasoning through Hypothesis Decomposition and Amendment",
    "authors": [
      "Yuze Zhao",
      "Tianyun Ji",
      "Wenjun Feng",
      "Zhenya Huang",
      "Qi Liu",
      "Zhiding Liu",
      "Yixiao Ma",
      "Kai Zhang",
      "Enhong Chen"
    ],
    "abstract": "The reasoning abilities are one of the most enigmatic and captivating aspects\nof large language models (LLMs). Numerous studies are dedicated to exploring\nand expanding the boundaries of this reasoning capability. However, tasks that\nembody both reasoning and recall characteristics are often overlooked. In this\npaper, we introduce such a novel task, code reasoning, to provide a new\nperspective for the reasoning abilities of LLMs. We summarize three\nmeta-benchmarks based on established forms of logical reasoning, and\ninstantiate these into eight specific benchmark tasks. Our testing on these\nbenchmarks reveals that LLMs continue to struggle with identifying satisfactory\nreasoning pathways. Additionally, we present a new pathway exploration pipeline\ninspired by human intricate problem-solving methods. This Reflective Hypothesis\nDecomposition and Amendment (RHDA) pipeline consists of the following iterative\nsteps: (1) Proposing potential hypotheses based on observations and decomposing\nthem; (2) Utilizing tools to validate hypotheses and reflection outcomes; (3)\nRevising hypothesis in light of observations. Our approach effectively\nmitigates logical chain collapses arising from forgetting or hallucination\nissues in multi-step reasoning, resulting in performance gains of up to\n$3\\times$. Finally, we expanded this pipeline by applying it to simulate\ncomplex household tasks in real-world scenarios, specifically in VirtualHome,\nenhancing the handling of failure cases. We release our code and all of results\nat https://github.com/TnTWoW/code_reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2502.13170v2",
    "published": "2025-02-17T10:39:58+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11647v2",
    "title": "DELMAN: Dynamic Defense Against Large Language Model Jailbreaking with Model Editing",
    "authors": [
      "Yi Wang",
      "Fenghua Weng",
      "Sibei Yang",
      "Zhan Qin",
      "Minlie Huang",
      "Wenjie Wang"
    ],
    "abstract": "Large Language Models (LLMs) are widely applied in decision making, but their\ndeployment is threatened by jailbreak attacks, where adversarial users\nmanipulate model behavior to bypass safety measures. Existing defense\nmechanisms, such as safety fine-tuning and model editing, either require\nextensive parameter modifications or lack precision, leading to performance\ndegradation on general tasks, which is unsuitable to post-deployment safety\nalignment. To address these challenges, we propose DELMAN (Dynamic Editing for\nLLMs JAilbreak DefeNse), a novel approach leveraging direct model editing for\nprecise, dynamic protection against jailbreak attacks. DELMAN directly updates\na minimal set of relevant parameters to neutralize harmful behaviors while\npreserving the model's utility. To avoid triggering a safe response in benign\ncontext, we incorporate KL-divergence regularization to ensure the updated\nmodel remains consistent with the original model when processing benign\nqueries. Experimental results demonstrate that DELMAN outperforms baseline\nmethods in mitigating jailbreak attacks while preserving the model's utility,\nand adapts seamlessly to new attack instances, providing a practical and\nefficient solution for post-deployment model protection.",
    "pdf_url": "http://arxiv.org/pdf/2502.11647v2",
    "published": "2025-02-17T10:39:21+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11646v3",
    "title": "Hyper-SET: Designing Transformers via Hyperspherical Energy Minimization",
    "authors": [
      "Yunzhe Hu",
      "Difan Zou",
      "Dong Xu"
    ],
    "abstract": "Transformer-based models have achieved remarkable success, but their core\ncomponents, Transformer layers, are largely heuristics-driven and engineered\nfrom the bottom up, calling for a prototypical model with high interpretability\nand practical competence. To this end, we conceptualize a principled, top-down\napproach grounded in energy-based interpretation. Specifically, we formalize\ntoken dynamics as a joint maximum likelihood estimation on the hypersphere,\nfeaturing two properties: semantic alignment in the high-dimensional space and\ndistributional uniformity in the low-dimensional space. By quantifying them\nwith extended Hopfield energy functions, we instantiate this idea as a\nconstrained energy minimization problem, which enables designs of symmetric\nattention and feedforward modules with RMS normalization. We further present\n\\textit{Hyper-Spherical Energy Transformer} (Hyper-SET), a recurrent-depth\nalternative to vanilla Transformers naturally emerging from iterative energy\noptimization on the hypersphere. With shared parameters across layers,\nHyper-SET can scale to arbitrary depth with fewer parameters. Theoretically\ngrounded and compact, it achieves competitive or superior performance across\ndiverse tasks, including Sudoku solving, image classification, and masked image\nmodeling. We also design novel variations under the proposed general principle,\nsuch as linear attention and gated feedforward layer. Moreover, we showcase its\nscalability with depth-wise LoRA. Our results highlight Hyper-SET as a step\ntoward interpretable and principled Transformer design.",
    "pdf_url": "http://arxiv.org/pdf/2502.11646v3",
    "published": "2025-02-17T10:39:11+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11645v1",
    "title": "Deviation Ratings: A General, Clone-Invariant Rating Method",
    "authors": [
      "Luke Marris",
      "Siqi Liu",
      "Ian Gemp",
      "Georgios Piliouras",
      "Marc Lanctot"
    ],
    "abstract": "Many real-world multi-agent or multi-task evaluation scenarios can be\nnaturally modelled as normal-form games due to inherent strategic (adversarial,\ncooperative, and mixed motive) interactions. These strategic interactions may\nbe agentic (e.g. players trying to win), fundamental (e.g. cost vs quality), or\ncomplementary (e.g. niche finding and specialization). In such a formulation,\nit is the strategies (actions, policies, agents, models, tasks, prompts, etc.)\nthat are rated. However, the rating problem is complicated by redundancy and\ncomplexity of N-player strategic interactions. Repeated or similar strategies\ncan distort ratings for those that counter or complement them. Previous work\nproposed ``clone invariant'' ratings to handle such redundancies, but this was\nlimited to two-player zero-sum (i.e. strictly competitive) interactions. This\nwork introduces the first N-player general-sum clone invariant rating, called\ndeviation ratings, based on coarse correlated equilibria. The rating is\nexplored on several domains including LLMs evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11645v1",
    "published": "2025-02-17T10:39:04+00:00",
    "categories": [
      "cs.GT",
      "cs.CL",
      "cs.MA",
      "stat.OT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11644v1",
    "title": "InTec: integrated things-edge computing: a framework for distributing machine learning pipelines in edge AI systems",
    "authors": [
      "Habib Larian",
      "Faramarz Safi-Esfahani"
    ],
    "abstract": "With the rapid expansion of the Internet of Things (IoT), sensors,\nsmartphones, and wearables have become integral to daily life, powering smart\napplications in home automation, healthcare, and intelligent transportation.\nHowever, these advancements face significant challenges due to latency and\nbandwidth constraints imposed by traditional cloud based machine learning (ML)\nframeworks. The need for innovative solutions is evident as cloud computing\nstruggles with increased latency and network congestion. Previous attempts to\noffload parts of the ML pipeline to edge and cloud layers have yet to fully\nresolve these issues, often worsening system response times and network\ncongestion due to the computational limitations of edge devices. In response to\nthese challenges, this study introduces the InTec (Integrated Things Edge\nComputing) framework, a groundbreaking innovation in IoT architecture. Unlike\nexisting methods, InTec fully leverages the potential of a three tier\narchitecture by strategically distributing ML tasks across the Things, Edge,\nand Cloud layers. This comprehensive approach enables real time data processing\nat the point of data generation, significantly reducing latency, optimizing\nnetwork traffic, and enhancing system reliability. InTec effectiveness is\nvalidated through empirical evaluation using the MHEALTH dataset for human\nmotion detection in smart homes, demonstrating notable improvements in key\nmetrics: an 81.56 percent reduction in response time, a 10.92 percent decrease\nin network traffic, a 9.82 percent improvement in throughput, a 21.86 percent\nreduction in edge energy consumption, and a 25.83 percent reduction in cloud\nenergy consumption. These advancements establish InTec as a new benchmark for\nscalable, responsive, and energy efficient IoT applications, demonstrating its\npotential to revolutionize how the ML pipeline is integrated into Edge AI (EI)\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11644v1",
    "published": "2025-02-17T10:38:00+00:00",
    "categories": [
      "cs.DC",
      "cs.AI",
      "68M14, 68T05"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11643v1",
    "title": "Observation of space-time surface plasmon polaritons",
    "authors": [
      "Naoki Ichiji",
      "Hibiki Kikuchi",
      "Murat Yessenov",
      "Kenneth L. Schepler",
      "Ayman F. Abouraddy",
      "Atsushi Kubo"
    ],
    "abstract": "Surface plasmon polaritons (SPPs) are surface-bound waves at metal-dielectric\ninterfaces that exhibit strong out-of-plane field confinement, a key feature\nfor applications is nano-scale sensing and imaging. However, this advantage is\noffset by diffractive spreading during in-plane propagation, leading to\ntransverse spatial delocalization. Conventional strategies to combat\ndiffraction through spatial structuring are not applicable for dimensionally\nrestricted SPPs -- except for cosine plasmons that are not localized or Airy\nplasmons that propagate along a curved trajectory. Here, we report the first\nrealization of space-time SPPs (ST-SPPs), ultrashort (16 fs) diffraction-free\nSPPs that propagate in a straight line, whose unique propagation\ncharacteristics stem from precise sculpting of their spatiotemporal spectra. By\nfirst synthesizing a spatiotemporally structured field in free space, we couple\nthe field to an axially invariant ST-SPP at a metal-dielectric surface via an\nultra-broadband nanoslit coupling mechanism, further enabling control over the\nST-SPP group velocity and propagation characteristics. Time-resolved two-photon\nfluorescence interference microscopy enables reconstructing the surface-bound\nfield in space and time, thereby verifying their predicted phase-tilted\nspatiotemporal wave-front and diffraction-free propagation. Our work opens new\navenues for combining spatiotemporally structured light with the\nfield-localization associated with nanophotonics, and may thus enable novel\napplications in surface-enhanced sensing and nonlinear optical interactions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11643v1",
    "published": "2025-02-17T10:37:55+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.11642v1",
    "title": "GaussianMotion: End-to-End Learning of Animatable Gaussian Avatars with Pose Guidance from Text",
    "authors": [
      "Gyumin Shim",
      "Sangmin Lee",
      "Jaegul Choo"
    ],
    "abstract": "In this paper, we introduce GaussianMotion, a novel human rendering model\nthat generates fully animatable scenes aligned with textual descriptions using\nGaussian Splatting. Although existing methods achieve reasonable text-to-3D\ngeneration of human bodies using various 3D representations, they often face\nlimitations in fidelity and efficiency, or primarily focus on static models\nwith limited pose control. In contrast, our method generates fully animatable\n3D avatars by combining deformable 3D Gaussian Splatting with text-to-3D score\ndistillation, achieving high fidelity and efficient rendering for arbitrary\nposes. By densely generating diverse random poses during optimization, our\ndeformable 3D human model learns to capture a wide range of natural motions\ndistilled from a pose-conditioned diffusion model in an end-to-end manner.\nFurthermore, we propose Adaptive Score Distillation that effectively balances\nrealistic detail and smoothness to achieve optimal 3D results. Experimental\nresults demonstrate that our approach outperforms existing baselines by\nproducing high-quality textures in both static and animated results, and by\ngenerating diverse 3D human models from various textual inputs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11642v1",
    "published": "2025-02-17T10:36:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11641v3",
    "title": "A Zero-Knowledge Proof for the Syndrome Decoding Problem in the Lee Metric",
    "authors": [
      "Mladen KovaÄeviÄ",
      "Tatjana GrbiÄ",
      "Darko Äapko",
      "Nemanja NediÄ",
      "Srdjan VukmiroviÄ"
    ],
    "abstract": "The syndrome decoding problem is one of the NP-complete problems lying at the\nfoundation of code-based cryptography. The variant thereof where the distance\nbetween vectors is measured with respect to the Lee metric, rather than the\nmore commonly used Hamming metric, has been analyzed recently in several works\ndue to its potential relevance for building more efficient code-based\ncryptosystems. The purpose of this article is to present a zero-knowledge proof\nof knowledge for this variant of the problem.",
    "pdf_url": "http://arxiv.org/pdf/2502.11641v3",
    "published": "2025-02-17T10:35:18+00:00",
    "categories": [
      "cs.CR",
      "cs.IT",
      "math.IT",
      "94A60, 68P25"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11640v2",
    "title": "Generalized Yosida Approximation and Multi-Valued Stochastic Evolution Inclusions",
    "authors": [
      "Wujing Fan",
      "Wei Hong",
      "Wei Liu"
    ],
    "abstract": "In this paper, we generalize the classical Yosida approximation by utilizing\na nonstandard duality mapping to establish the existence and uniqueness of both\n(probabilistically) weak and strong solutions and demonstrate the continuous\ndependence on initial values for a class of multi-valued stochastic evolution\ninclusions within the variational framework.\n  Furthermore, leveraging this generalized Yosida approximation, we derive the\nfinite-time extinction of solutions with probability one and also provide an\nexplicit upper bound of the moment of extinction time for multi-valued\nstochastic evolution inclusions perturbed by linear multiplicative noise. The\nmain results are applicable to various examples, including multi-valued\nstochastic porous media equations, stochastic $\\Phi$-Laplace equations and\nstochastic evolution inclusions involving subdifferentials.",
    "pdf_url": "http://arxiv.org/pdf/2502.11640v2",
    "published": "2025-02-17T10:33:54+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11639v2",
    "title": "Neural Interpretable Reasoning",
    "authors": [
      "Pietro Barbiero",
      "Giuseppe Marra",
      "Gabriele Ciravegna",
      "David Debot",
      "Francesco De Santis",
      "Michelangelo Diligenti",
      "Mateo Espinosa Zarlenga",
      "Francesco Giannini"
    ],
    "abstract": "We formalize a novel modeling framework for achieving interpretability in\ndeep learning, anchored in the principle of inference equivariance. While the\ndirect verification of interpretability scales exponentially with the number of\nvariables of the system, we show that this complexity can be mitigated by\ntreating interpretability as a Markovian property and employing neural\nre-parametrization techniques. Building on these insights, we propose a new\nmodeling paradigm -- neural generation and interpretable execution -- that\nenables scalable verification of equivariance. This paradigm provides a general\napproach for designing Neural Interpretable Reasoners that are not only\nexpressive but also transparent.",
    "pdf_url": "http://arxiv.org/pdf/2502.11639v2",
    "published": "2025-02-17T10:33:24+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2503.16445v1",
    "title": "FINCH: Locally Visualizing Higher-Order Feature Interactions in Black Box Models",
    "authors": [
      "Anna Kleinau",
      "Bernhard Preim",
      "Monique Meuschke"
    ],
    "abstract": "In an era where black-box AI models are integral to decision-making across\nindustries, robust methods for explaining these models are more critical than\never. While these models leverage complex feature interplay for accurate\npredictions, most explanation methods only assign relevance to individual\nfeatures. There is a research gap in methods that effectively illustrate\ninteractions between features, especially in visualizing higher-order\ninteractions involving multiple features, which challenge conventional\nrepresentation methods. To address this challenge in local explanations focused\non individual instances, we employ a visual, subset-based approach to reveal\nrelevant feature interactions. Our visual analytics tool FINCH uses coloring\nand highlighting techniques to create intuitive, human-centered visualizations,\nand provides additional views that enable users to calibrate their trust in the\nmodel and explanations. We demonstrate FINCH in multiple case studies,\ndemonstrating its generalizability, and conducted an extensive human study with\nmachine learning experts to highlight its helpfulness and usability. With this\napproach, FINCH allows users to visualize feature interactions involving any\nnumber of features locally.",
    "pdf_url": "http://arxiv.org/pdf/2503.16445v1",
    "published": "2025-02-17T10:33:20+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11637v2",
    "title": "On the definition of \"almost LUR (ALUR)\" notion",
    "authors": [
      "Constantin Zalinescu"
    ],
    "abstract": "The notion of almost LUR (ALUR) point is introduced in the paper [P.\nBandyopadhyay et al., Some generalizations of locally uniform rotundity, J.\nMath. Anal. Appl., 252, 906-916 (2000)], where one says that the point $x$ of\nthe unit sphere $S_{X}$ of a Banach space is an almost LUR (ALUR) point of\n$B_{X}$ if for any sequences $\\{x_{n}\\}\\subseteq B_{X}$ and\n$\\{x_{m}^{\\ast}\\}\\subseteq B_{X^{\\ast}}$, the condition\n$\\lim_{m}\\lim_{n}x_{m}^{\\ast}\\left(\\frac{x_{n}+x}{2}\\right)=1$ implies\n$\\lim_{n}\\left\\Vert x_{n}-x\\right\\Vert =0$, without mentioning what is meant by\n$\\lim_{m}\\lim_{n}\\gamma_{m,n}=\\gamma$ for $\\gamma$,\n$\\gamma_{m,n}\\in\\mathbb{R}$; $X$ is ALUR if $X$ is almost LUR at any $x\\in\nS_{X}$. Of course, the natural definition for this iterated limit would be that\nfor each $m$ sufficiently large there exists\n$\\mu_{m}:=\\lim_{n\\rightarrow\\infty}\\gamma_{m,n}\\in\\mathbb{R}$ and $\\gamma\n=\\lim_{m\\rightarrow\\infty}\\mu_{m}$. However, as seen in some proofs where\n$\\lim_{m}\\lim_{n}$ appears, this interpretation is not confirmed. In this paper\nwe examine several works in which almost LUR is mentioned and, especially, the\nproofs of those results in which the above definition of \"almost LUR\" point (or\nspace) is invoked. Moreover, we analyze similar problems related to the notion\nCWALUR which extend ALUR. Furthermore, we mention several gaps in the proofs of\nsome results. Finally, we propose the change of $\\lim_{m}\\lim_{n}$ by\n$\\lim_{m}\\liminf_{n}$ in the definitions of several types of ALUR points;\nmoreover, we provide the complete proofs of two results from the literature in\nwhich $\\lim_{m}\\lim_{n}$ were used effectively, using $\\lim_{m}\\liminf_{n}$\ninstead.",
    "pdf_url": "http://arxiv.org/pdf/2502.11637v2",
    "published": "2025-02-17T10:31:24+00:00",
    "categories": [
      "math.FA",
      "46A20"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11638v2",
    "title": "Safeguarding AI in Medical Imaging: Post-Hoc Out-of-Distribution Detection with Normalizing Flows",
    "authors": [
      "Dariush Lotfi",
      "Mohammad-Ali Nikouei Mahani",
      "Mohamad Koohi-Moghadam",
      "Kyongtae Ty Bae"
    ],
    "abstract": "In AI-driven medical imaging, the failure to detect out-of-distribution (OOD)\ndata poses a severe risk to clinical reliability, potentially leading to\ncritical diagnostic errors. Current OOD detection methods often demand\nimpractical retraining or modifications to pre-trained models, hindering their\nadoption in regulated clinical environments. To address this challenge, we\npropose a post-hoc normalizing flow-based approach that seamlessly integrates\nwith existing pre-trained models without altering their weights. Our evaluation\nused a novel in-house built dataset, MedOOD, meticulously curated to simulate\nclinically relevant distributional shifts, alongside the MedMNIST benchmark\ndataset. On our in-house MedOOD dataset, our method achieved an AUROC of\n84.61%, outperforming state-of-the-art methods like ViM (80.65%) and MDS\n(80.87%). Similarly, on MedMNIST, it reached an exceptional AUROC of 93.8%,\nsurpassing leading approaches such as ViM (88.08%) and ReAct (87.05%). This\nsuperior performance, coupled with its post-hoc integration capability,\npositions our method as a vital safeguard for enhancing safety in medical\nimaging workflows. The model and code to build OOD datasets are publicly\naccessible at https://github.com/dlotfi/MedOODFlow.",
    "pdf_url": "http://arxiv.org/pdf/2502.11638v2",
    "published": "2025-02-17T10:31:24+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.13169v1",
    "title": "A common approach to singular perturbation and homogenization III: Nonlinear periodic homogenization with localized defects",
    "authors": [
      "Lutz Recke"
    ],
    "abstract": "We consider periodic homogenization with localized defects for semilinear\nelliptic equations and systems of the type $$\n\\nabla\\cdot\\Big(\\Big(A(x/\\varepsilon)+B(x/\\varepsilon)\\Big)\\nabla\nu(x)+c(x,u(x)\\Big)=d(x,u(x)) \\mbox{ in } \\Omega $$ with Dirichlet boundary\nconditions. For small $\\varepsilon>0$ we show existence of weak solutions\n$u=u_\\varepsilon$ as well as their local uniqueness for $\\|u-u_0\\|_\\infty\n\\approx 0$, where $u_0$ is a given non-degenerate weak solution to the\nhomogenized problem. Moreover, we prove that $\\|u_\\varepsilon-u_0\\|_\\infty\\to\n0$ for $\\varepsilon \\to 0$, and we estimate the corresponding rate of\nconvergence. Our assumptions are, roughly speaking, as follows: $\\Omega$ is a\nbounded Lipschitz domain, $A$, $B$, $c(\\cdot,u)$ and $d(\\cdot,u)$ are bounded\nand measurable, $c(x,\\cdot)$ and $d(x,\\cdot)$ are $C^1$-smooth, $A$ is\nperiodic, and $B$ is a localized defect. Neither global uniqueness is supposed\nnor growth restriction for $c(x,\\cdot)$ or $d(x,\\cdot)$.\n  The main tool of the proofs is an abstract result of implicit function\ntheorem type which permits a common approach to nonlinear singular perturbation\nand homogenization.",
    "pdf_url": "http://arxiv.org/pdf/2502.13169v1",
    "published": "2025-02-17T10:30:50+00:00",
    "categories": [
      "math.AP",
      "35B27 35D30 35J57 35J61 47J07 58C15"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.15781v1",
    "title": "Assessing Pedagogical Readiness for Digital Innovation: A Mixed-Methods Study",
    "authors": [
      "Ning Yulin",
      "Solomon Danquah Danso"
    ],
    "abstract": "Digital innovation in education has revolutionized teaching and learning\nprocesses, demanding a rethink of pedagogical competence among educators. This\nstudy evaluates the preparation of instructors to use digital technologies into\ntheir educational practices. The study used a mixed-methods approach,\nintegrating both qualitative interviews and quantitative surveys to evaluate\nteachers' institutional support systems, beliefs, and technical proficiency.\nThe results show that even while a large number of educators acknowledge the\nbenefits of digital tools, problems including poor professional development and\nchange aversion still exist. In order to improve digital pedagogical\npreparation, the study emphasizes the necessity of focused training initiatives\nand encouraging institutional regulations. There is discussion on the\nimplications for educational institutions and policymakers.",
    "pdf_url": "http://arxiv.org/pdf/2502.15781v1",
    "published": "2025-02-17T10:29:24+00:00",
    "categories": [
      "physics.ed-ph",
      "cs.CY"
    ],
    "primary_category": "physics.ed-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11636v1",
    "title": "On Fillmore's theorem over integrally closed domains",
    "authors": [
      "Alexander Stasinski"
    ],
    "abstract": "A well-known theorem of Fillmore says that if $A\\in\\operatorname{M}_{n}(K)$\nis a non-scalar matrix over a field $K$ and $\\gamma_{1},\\dots,\\gamma_{n}\\in K$\nare such that $\\gamma_{1}+\\dots+\\gamma_{n}=\\operatorname{Tr}(A)$, then $A$ is\n$K$-similar to a matrix with diagonal $(\\gamma_{1},\\dots,\\gamma_{n})$. Building\non work of Borobia, Tan extended this by proving that if $R$ is a unique\nfactorisation domain with field of fractions $K$ and\n$A\\in\\operatorname{M}_{n}(R)$ is non-scalar, then $A$ is $K$-similar to a\nmatrix in $\\operatorname{M}_{n}(R)$ with diagonal\n$(\\gamma_{1},\\dots,\\gamma_{n})$. We note that Tan's argument actually works\nwhen $R$ is any integrally closed domain and show that the result cannot be\ngeneralised further by giving an example of a matrix over a non-integrally\nclosed domain for which the result fails. Moreover, Tan gave a necessary\ncondition for $A\\in\\operatorname{M}_{n}(R)$ to be $R$-similar to a matrix with\ndiagonal $(\\gamma_{1},\\dots,\\gamma_{n})$. We show that when $R$ is a PID and\n$n\\geq3$, Tan's condition is also sufficient.",
    "pdf_url": "http://arxiv.org/pdf/2502.11636v1",
    "published": "2025-02-17T10:28:00+00:00",
    "categories": [
      "math.RA"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11635v2",
    "title": "Open orbits in causal flag manifolds, modular flows and wedge regions",
    "authors": [
      "Karl-Hermann Neeb"
    ],
    "abstract": "We study open orbits of symmetric subgroups of a simple connected\n  Lie group G on a causal flag manifold.\n  First we show that a flag manifold M of G carries an invariant causal\nstructure if and only if G is hermitian\n  of tube type and M is the conformal completion\n  of the corresponding simple euclidean Jordan algebra,\n  resp., the Shilov boundary of the associated symmetric tube domain.\n  We then study open orbits in M under symmetric subgroups,\n  also called causal\n  Makarevic spaces, from the perspective of applications in Algebraic Quantum\nField Theory (AQFT). A key motivation is the geometry of corresponding modular\nflows.\n  The open orbits are reductive causal symmetric\n  spaces, which arise in two flavors:\n  compactly causal and non-compactly causal ones.\n  In the non-compactly causal case we determine the corresponding Euler\nelements\n  and their positivity regions. For compactly causal spaces,\n  modular flows do not always exist and we determine\n  when this is the case. Then the positivity regions of the modular flows are\nnot globally hyperbolic,\n  but these spaces contain other interesting\n  globally hyperbolic subsets that can be described\n  in terms of the conformally flat Jordan coordinates via Cayley charts.\n  We discuss the Lorentzian case, involving de Sitter\n  and anti-de Sitter space in some detail.",
    "pdf_url": "http://arxiv.org/pdf/2502.11635v2",
    "published": "2025-02-17T10:24:49+00:00",
    "categories": [
      "math.DG",
      "math-ph",
      "math.MP",
      "22E46, 81R05, 53C50"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11634v1",
    "title": "Electromagnetic Waves in Cosmological Space-Time II. Luminosity Distance",
    "authors": [
      "Denitsa Staicova",
      "Michail Stoilov"
    ],
    "abstract": "In this article, we continue our investigation on how the electromagnetic\nwaves propagate in the Friedman-Lemaitre-Robertson-Walker spacetime. Unlike the\nstandard approach, which relies on null geodesics and geometric optics\napproximation, we derive explicit solutions for electromagnetic waves in\nexpanding spacetime and examine their implications for cosmological\nobservations. In particular, our analysis reveals potential modifications to\nthe standard luminosity distance formula. Its effect on other cosmological\nparameters, e.g., the amount of cold dust matter in the Universe, is considered\nand estimated from Type Ia supernovae data. We see that this alternative model\nis able to fit the supernova data, but it gives a qualitatively different\nUniverse without a cosmological constant but with stiff or ultra-stiff matter.",
    "pdf_url": "http://arxiv.org/pdf/2502.11634v1",
    "published": "2025-02-17T10:24:30+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11633v1",
    "title": "CLASS: Enhancing Cross-Modal Text-Molecule Retrieval Performance and Training Efficiency",
    "authors": [
      "Hongyan Wu",
      "Peijian Zeng",
      "Weixiong Zheng",
      "Lianxi Wang",
      "Nankai Lin",
      "Shengyi Jiang",
      "Aimin Yang"
    ],
    "abstract": "Cross-modal text-molecule retrieval task bridges molecule structures and\nnatural language descriptions. Existing methods predominantly focus on aligning\ntext modality and molecule modality, yet they overlook adaptively adjusting the\nlearning states at different training stages and enhancing training efficiency.\nTo tackle these challenges, this paper proposes a Curriculum Learning-bAsed\ncroSS-modal text-molecule training framework (CLASS), which can be integrated\nwith any backbone to yield promising performance improvement. Specifically, we\nquantify the sample difficulty considering both text modality and molecule\nmodality, and design a sample scheduler to introduce training samples via an\neasy-to-difficult paradigm as the training advances, remarkably reducing the\nscale of training samples at the early stage of training and improving training\nefficiency. Moreover, we introduce adaptive intensity learning to increase the\ntraining intensity as the training progresses, which adaptively controls the\nlearning intensity across all curriculum stages. Experimental results on the\nChEBI-20 dataset demonstrate that our proposed method gains superior\nperformance, simultaneously achieving prominent time savings.",
    "pdf_url": "http://arxiv.org/pdf/2502.11633v1",
    "published": "2025-02-17T10:24:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.15780v1",
    "title": "Feature Engineering Approach to Building Load Prediction: A Case Study for Commercial Building Chiller Plant Optimization in Tropical Weather",
    "authors": [
      "Zhan Wang",
      "Chen Weidong",
      "Huang Zhifeng",
      "Md Raisul Islam",
      "Chua Kian Jon"
    ],
    "abstract": "In tropical countries with high humidity, air conditioning can account for up\nto 60% of a building's energy use. For commercial buildings with centralized\nsystems, the efficiency of the chiller plant is vital, and model predictive\ncontrol provides an effective strategy for optimizing operations through\ndynamic adjustments based on accurate load predictions. Artificial neural\nnetworks are effective for modelling nonlinear systems but are prone to\noverfitting due to their complexity. Effective feature engineering can mitigate\nthis issue. While weather data are crucial for load prediction, they are often\nused as raw numerical inputs without advanced processing. Clustering features\nis a technique that can reduce model complexity and enhance prediction\naccuracy. Although previous studies have explored clustering algorithms for\nload prediction, none have applied them to multidimensional weather data,\nrevealing a research gap. This study presents a cooling load prediction model\nthat combines a neural network with Kalman filtering and K-means clustering.\nApplied to real world data from a commercial skyscraper in Singapore's central\nbusiness district, the model achieved a 46.5% improvement in prediction\naccuracy. An optimal chiller sequencing strategy was also developed through\ngenetic algorithm optimization of the predictive load, potentially saving 13.8%\nin energy. Finally, the study evaluated the integration of thermal energy\nstorage into the chiller plant design, demonstrating potential reductions in\ncapital and operational costs of 26% and 13%, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.15780v1",
    "published": "2025-02-17T10:22:43+00:00",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11632v1",
    "title": "O-MMGP: Optimal Mesh Morphing Gaussian Process Regression for Solving PDEs with non-Parametric Geometric Variations",
    "authors": [
      "Abbas Kabalan",
      "Fabien Casenave",
      "Felipe Bordeu",
      "Virginie Ehrlacher"
    ],
    "abstract": "We address the computational challenges of solving parametric PDEs with non\nparametrized geometric variations and non-reducible problems, such as those\ninvolving shocks and discontinuities of variable positions. Traditional\ndimensionality reduction methods like POD struggle with these scenarios due to\nslowly decaying Kolmogorov widths. To overcome this, we propose a novel\nnon-linear dimensionality reduction technique to reduce the required modes for\nrepresentation. The non-linear reduction is obtained through a POD after\napplying a transformation on the fields, which we call optimal mappings, and is\na solution to an optimization problem in infinite dimension. The proposed\nlearning framework combines morphing techniques, non-linear dimensionality\nreduction, and Gaussian Process Regression (GPR). The problem is reformulated\non a reference geometry before applying the dimensionality reduction. Our\nmethod learns both the optimal mapping, and the solution fields, using a series\nof GPR models, enabling efficient and accurate modeling of complex parametric\nPDEs with geometrical variability. The results obtained concur with current\nstate-of-the-art models. We mainly compare our method with the winning solution\nof the ML4CFD NeurIPS 2024 competition.",
    "pdf_url": "http://arxiv.org/pdf/2502.11632v1",
    "published": "2025-02-17T10:21:44+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11631v3",
    "title": "Advancing the heralded photon-number-state characterization by understanding the interplay of experimental settings",
    "authors": [
      "Daniel Borrero Landazabal",
      "Kaisa Laiho"
    ],
    "abstract": "We theoretically explore the properties of heralded number states including\nup to three photons that are generated from single-mode twin beams. We\ninvestigate the effects of different parameters involved in the state\npreparation by using the fidelity, normalized second-order factorial moment of\nphoton number for the heralded state $(g^{(2)}_h)$, and photon-number parity as\nfigures of merit. Especially, the photon-number parity offers a practical and\nrobust tool for inferring the target state quality by capturing the\ncontamination of all undesired photon-number contributions. We focus on\nexpressing our results in terms of experimentally easily accessible parameters\nsuch as the coincidences-to-accidentals ratio and the detection efficiencies.\nOur results identify the optimal parameter regions for generating high quality\nphoton-number states by heralding and provide useful insights for advancing\ntheir use in quantum technologies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11631v3",
    "published": "2025-02-17T10:20:39+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11630v1",
    "title": "Reachability in Trace-Pushdown Systems",
    "authors": [
      "Chris KÃ¶cher",
      "Dietrich Kuske"
    ],
    "abstract": "We consider the reachability relation of pushdown systems whose pushdown\nholds a Mazurkiewicz trace instead of just a word as in classical systems.\nUnder two natural conditions on the transition structure of such systems, we\nprove that the reachability relation is lc-rational, a new notion that\nrestricts the class of rational trace relations. We also develop the theory of\nthese lc-rational relations to the point where they allow to infer that\nforwards-reachability of a trace-pushdown system preserves the rationality and\nbackwards-reachability the recognizability of sets of configurations. As a\nconsequence, we obtain that it is decidable whether one recognizable set of\nconfigurations can be reached from some rational set of configurations. All our\nconstructions are polynomial (assuming the dependence alphabet to be fixed).\n  These findings generalize results by Caucal on classical pushdown systems\n(namely the rationality of the reachability relation of such systems) and\ncomplement results by Zetzsche (namely the decidability for arbitrary\ntransition structures under severe restrictions on the dependence alphabet).",
    "pdf_url": "http://arxiv.org/pdf/2502.11630v1",
    "published": "2025-02-17T10:20:34+00:00",
    "categories": [
      "cs.FL"
    ],
    "primary_category": "cs.FL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11629v2",
    "title": "Causal Models in Requirement Specifications for Machine Learning: A vision",
    "authors": [
      "Hans-Martin Heyn",
      "Yufei Mao",
      "Roland Weiss",
      "Eric Knauss"
    ],
    "abstract": "Specifying data requirements for machine learning (ML) software systems\nremains a challenge in requirements engineering (RE). This vision paper\nexplores causal modelling as an RE activity that allows the systematic\nintegration of prior domain knowledge into the design of ML software systems.\nWe propose a workflow to elicit low-level model and data requirements from\nhigh-level prior knowledge using causal models. The approach is demonstrated on\nan industrial fault detection system. This paper outlines future research\nneeded to establish causal modelling as an RE practice.",
    "pdf_url": "http://arxiv.org/pdf/2502.11629v2",
    "published": "2025-02-17T10:20:17+00:00",
    "categories": [
      "cs.SE",
      "D.2.1; D.2.2"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11628v1",
    "title": "Simulation-based Super-Resolution EBSD for Measurements of Relative Deformation Gradient Tensors",
    "authors": [
      "Aimo Winkelmann",
      "Grzegorz Cios",
      "Konrad PerzyÅski",
      "Tomasz Tokarski",
      "Klaus Mehnert",
      "Åukasz Madej",
      "Piotr BaÅa"
    ],
    "abstract": "We summarize a data analysis approach for electron backscatter diffraction\n(EBSD) which uses high-resolution Kikuchi pattern simulations to measure\nisochoric relative deformation gradient tensors from experimentally measured\nKikuchi patterns of relatively low resolution. Simulation-based supersampling\nof the theoretical test diffraction patterns enables a significant precision\nimprovement of tensor parameters obtained in best-fit determinations of strains\nand orientations from low-resolution experimental patterns. As an application,\nwe demonstrate high-resolution orientation and strain analysis for the model\ncase of hardness test indents on a Si(100) wafer, using Kikuchi patterns of\nvariable resolution. The approach shows noise levels near $1 \\times 10^{-4}$ in\nthe relative deviatoric strain norm and in the relative rotation angles on\nnominally strain-free regions of the silicon wafer. The strain and rotation\nmeasurements are interpreted by finite element simulations. While confirming\nthe basic findings of previously published studies, the present approach\nenables a potential reduction in the necessary pattern data size by about two\norders of magnitude. We estimate that pattern resolutions in the order of\n$256\\times256$ pixels should be enough to solve a majority of EBSD analysis\ntasks using pattern matching techniques.",
    "pdf_url": "http://arxiv.org/pdf/2502.11628v1",
    "published": "2025-02-17T10:18:09+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11627v1",
    "title": "RemoteChess: Enhancing Older Adults' Social Connectedness via Designing a Virtual Reality Chinese Chess (Xiangqi) Community",
    "authors": [
      "Qianjie Wei",
      "Xiaoying Wei",
      "Yiqi Liang",
      "Fan Lin",
      "Nuonan Si",
      "Mingming Fan"
    ],
    "abstract": "The decline of social connectedness caused by distance and physical\nlimitations severely affects older adults' well-being and mental health. While\nvirtual reality (VR) is promising for older adults to socialize remotely,\nexisting social VR designs primarily focus on verbal communication (e.g.,\nreminiscent, chat). Actively engaging in shared activities is also an important\naspect of social connection. We designed RemoteChess, which constructs a social\ncommunity and a culturally relevant activity (i.e., Chinese chess) for older\nadults to play while engaging in social interaction. We conducted a user study\nwith groups of older adults interacting with each other through RemoteChess.\nOur findings indicate that RemoteChess enhanced participants' social\nconnectedness by offering familiar environments, culturally relevant social\ncatalysts, and asymmetric interactions. We further discussed design guidelines\nfor designing culturally relevant social activities in VR to promote social\nconnectedness for older adults.",
    "pdf_url": "http://arxiv.org/pdf/2502.11627v1",
    "published": "2025-02-17T10:17:47+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11626v1",
    "title": "High-spatial-resolution simulations of Be star disks in binary systems: I. Structure and kinematics of coplanar disks",
    "authors": [
      "A. C. Rubio",
      "A. C. Carciofi",
      "J. E. Bjorkman",
      "T. H. de Amorim",
      "A. T. Okazaki",
      "M. W. Suffak",
      "C. E. Jones",
      "P. P. Candido"
    ],
    "abstract": "Binarity in massive stars has proven to be an important aspect in the their\nevolution. For Be stars, it might be the cause of their spin up, and thus part\nof the mechanism behind the formation of their viscous decretion disks.\nDetecting companions in systems with Be stars is challenging, making it\ndifficult to obtain observational constraints on their binary fraction. We\nexplore the effects of a binary companion in a system with a Be star, from disk\nformation to quasi steady-state using smoothed particle hydrodynamics (SPH)\nsimulations of coplanar, circular binary systems. High spatial resolution is\nachieved by adopting particle splitting in the SPH code, as well as a more\nrealistic description of the secondary star and the disk viscosity. The tidal\nforces considerably affect the Be disk, forming distinct regions in the system,\nwith observational consequences that can be used to infer the presence of a\notherwise undetectable companion. With the upgraded code, we can probe a region\napproximately 4 times larger than previously possible. We describe the\nconfiguration and kinematics of each part of the system, and provide a summary\nof their expected observational signals. Material that enters the Roche lobe of\nthe companion is partially captured by it, forming a rotationally supported,\ndisk-like structure. Material not accreted escapes and forms a circumbinary\ndisk around the system. This is the first work to describe the region beyond\nthe truncation region of the Be disk and its observational consequences with\ndetail. We argue that observational features of previously unclear origin, such\nas the intermittent shell features and emission features of HR 2142 and HD\n55606, originate in areas beyond the truncation region. This new understanding\nof the behavior of disks in Be binaries will allow not just for better\ninterpretation of existing data, but also for the planning of future\nobservations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11626v1",
    "published": "2025-02-17T10:16:27+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11625v1",
    "title": "Comparative Analysis of EMCEE, Gaussian Process, and Masked Autoregressive Flow in Constraining the Hubble Constant Using Cosmic Chronometers Dataset",
    "authors": [
      "Jing Niu",
      "Jie-Feng Chen",
      "Peng He",
      "Tong-Jie Zhang"
    ],
    "abstract": "The Hubble constant ($\\mathrm{H}_0$) is essential for understanding the\nuniverse's evolution. Different methods, such as Affine Invariant Markov chain\nMonte Carlo Ensemble sampler (EMCEE), Gaussian Process (GP), and Masked\nAutoregressive Flow (MAF), are used to constrain $\\mathrm{H}_0$ using $H(z)$\ndata. However, these methods produce varying $\\mathrm{H}_0$ values when applied\nto the same dataset. To investigate these differences, we compare the methods\nbased on their sensitivity to individual data points and their accuracy in\nconstraining $\\mathrm{H}_0$. We introduce Multiple Random Sampling Analysis\n(MRSA) to assess their sensitivity to individual data points. Our findings\nreveal that GP is more sensitive to individual data points than both MAF and\nEMCEE, with MAF being more sensitive than EMCEE. Sensitivity also depends on\nredshift: EMCEE and GP are more sensitive to $H(z)$ at higher redshifts, while\nMAF is more sensitive at lower redshifts. For accuracy assessment, we simulate\n$H_{\\mathrm{sim}}(z_{\\mathrm{sim}})$ datasets with a prior\n$\\mathrm{H}_{\\mathrm{0prior}}$. Comparing the constrained $\\mathrm{H_{0sim}}$\nvalues with $\\mathrm{H}_{\\mathrm{0prior}}$ shows that EMCEE is the most\naccurate, followed by MAF, with GP being the least accurate, regardless of the\nsimulation method.",
    "pdf_url": "http://arxiv.org/pdf/2502.11625v1",
    "published": "2025-02-17T10:15:22+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11624v1",
    "title": "High-Temperature Superconductivity from Finite-Range Attractive Interaction",
    "authors": [
      "Dmitry Miserev",
      "Joel Hutchinson",
      "Herbert Schoeller",
      "Jelena Klinovaja",
      "Daniel Loss"
    ],
    "abstract": "In this letter we consider $D$-dimensional interacting Fermi liquids, and\ndemonstrate that an attractive interaction with a finite range $R_s$ that is\nmuch greater than the Fermi wavelength $\\lambda_F$ breaks the conventional BCS\ntheory of superconductivity. In contrast to the BCS prediction of a finite\nsuperconducting gap for all attractive contact interactions, we show that a\nfinite-range interaction does not induce a superconducting gap. Instead, the\npair susceptibility develops a power-law singularity at zero momentum and zero\nfrequency signaling quantum critical behavior without long-range ordering.\nStarting from this, we show that superconductivity can be stabilized by adding\na short-range attractive interaction, which is always present in real\nelectronic systems. As an example, we consider a layered quasi-two-dimensional\nmaterial with attractive electron-electron interactions mediated by optical\nphonons. We demonstrate a dome shape of the critical temperature $T_c$ versus\ndoping, strongly suppressed isotope effect, and a weak dependence of the\noptimal doping and maximal $T_c^* \\sim 0.1 E_F$ on the interaction range at\n$R_s \\gg \\lambda_F$, $E_F$ is the Fermi energy. We believe that these results\ncould be relevant to high-temperature superconductors.",
    "pdf_url": "http://arxiv.org/pdf/2502.11624v1",
    "published": "2025-02-17T10:13:31+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11623v2",
    "title": "An ultra-compact deterministic source of maximally entangled photon pairs",
    "authors": [
      "M. Langer",
      "P. Ruchka",
      "A. Rahimi",
      "S. Jakovljevic",
      "Y. G. Zena",
      "A. Danilov",
      "M. Pal",
      "R. Bassoli",
      "F. H. P. Fitzek",
      "O. G. Schmidt",
      "H. Giessen",
      "C. Hopfmann"
    ],
    "abstract": "We present an ultra-compact source of maximally entangled on-demand photon\npairs. Our results are based on coupling of single GaAs quantum dots that are\nembedded in monolithic micro-lenses to a single-mode fiber with directly\nattached to 3D-printed micro-optics (NA of 0.6) inside a cryogenic environment.\nThis approach, which is geared towards future integration into industrial\nenvironments, yields state-of-the-art entangled photon pair creation\nperformance while retaining flexibility and adjustability required for\nlong-term operation of such a device - all while dramatically reducing the\noverall system footprint. We demonstrate near diffraction-limited performance\nand hyperspectral imaging utilizing a 3D-printed micro-objective with a full\nwidth at half maximum resolution limit of 604(16) nm when operating the system\nat a cryogenic temperature of 3.8 K. Furthermore, we prove that this system can\nbe used to achieve single photon emission rates of 392(20) kHz at a 76 MHz pump\nrate and purities of 99.2(5) % using two-photon resonant excitation. Utilizing\nthe exciton-biexciton emission cascade available in GaAs quantum dots under\nresonant excitation, near maximally entangled photon pairs with peak\nentanglement negatives 2n of 0.96(2) in a 4 ps time window, and 0.81(1) when\naveraged over one exciton lifetime, are demonstrated.",
    "pdf_url": "http://arxiv.org/pdf/2502.11623v2",
    "published": "2025-02-17T10:07:54+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11622v1",
    "title": "Exactness and the topology of the space of invariant random equivalence relations",
    "authors": [
      "HÃ©ctor JardÃ³n-SÃ¡nchez",
      "Sam Mellick",
      "Antoine Poulin",
      "Konrad WrÃ³bel"
    ],
    "abstract": "We characterize exactness of a countable group $\\Gamma$ in terms of invariant\nrandom equivalence relations (IREs) on $\\Gamma$. Specifically, we show that\n$\\Gamma$ is exact if and only if every weak limit of finite IREs is an amenable\nIRE. In particular, for exact groups this implies amenability of the restricted\nrerooting relation associated to the ideal Bernoulli Voronoi tessellation, the\ndiscrete analog of the ideal Poisson Voronoi tesselation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11622v1",
    "published": "2025-02-17T10:06:15+00:00",
    "categories": [
      "math.GR",
      "math.DS",
      "math.PR"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11621v1",
    "title": "Effects of antiferromagnetic coupling and pinning on domain wall dynamics in synthetic ferrimagnets",
    "authors": [
      "Sougata Mallick",
      "Nicolas Reyren",
      "AndrÃ© Thiaville",
      "Philippe Ohresser",
      "Nicolas Jaouen",
      "Vincent Cros",
      "Vincent Jeudy"
    ],
    "abstract": "Domain wall (DW) dynamics in antiferromagnetic (AFM) systems offer the\nadvantages over their ferromagnetic counterparts of having faster and more\nenergy efficient manipulation due to the absence of net magnetization, leading\nto reduced magnetic crosstalk and improved performance in spintronic devices. A\ncomprehensive analysis of DW dynamics across regimes such as creep, depinning,\nand flow is well established in ferromagnetic systems but remains lacking in\nAFM-coupled systems. In this study, we explore the nature of DW dynamics in\nsynthetic ferrimagnetic multilayers composed of Pt|Co|Tb|Al for different Tb\nthickness, focusing on the underlying pinning parameters, and on the different\nregimes of DW dynamics driven by spin-orbit torques (SOTs). We find that due to\nthe AFM coupling between Co and Tb, the magnetic moment of Tb increases with Tb\nthickness resulting in a reduced saturation magnetization and an enhanced\ndepinning field. The DW disorder interaction is found to vary weakly with the\nAFM coupling between Co and Tb, while the complete withdrawal of the Tb layer\nstrongly increases the anisotropy and the DW pinning. Furthermore, we propose a\nnovel approach to measure effective SOTs by comparing depinning transitions in\ncurrent and field-induced DW motion. This research reveals new insights into DW\ndynamics in coupled AFM systems, highlighting enhancements in mobility through\noptimized SOTs and pinning landscapes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11621v1",
    "published": "2025-02-17T10:05:13+00:00",
    "categories": [
      "cond-mat.other"
    ],
    "primary_category": "cond-mat.other"
  },
  {
    "id": "http://arxiv.org/abs/2502.11620v3",
    "title": "Assessing Correctness in LLM-Based Code Generation via Uncertainty Estimation",
    "authors": [
      "Arindam Sharma",
      "Cristina David"
    ],
    "abstract": "In this work, we explore uncertainty estimation as a proxy for correctness in\nLLM-generated code. To this end, we adapt two state-of-the-art techniques from\nnatural language generation -- one based on entropy and another on mutual\ninformation -- to the domain of code generation. Given the distinct semantic\nproperties of code, we introduce modifications, including a semantic\nequivalence check based on symbolic execution. Our findings indicate a strong\ncorrelation between the uncertainty computed through these techniques and\ncorrectness, highlighting the potential of uncertainty estimation for quality\nassessment. Additionally, we propose a simplified version of the entropy-based\nmethod that assumes a uniform distribution over the LLM's responses,\ndemonstrating comparable effectiveness. Using these techniques, we develop an\nabstention policy that prevents the model from making predictions when\nuncertainty is high, reducing incorrect outputs to near zero. Our evaluation on\nthe LiveCodeBench shows that our approach significantly outperforms a baseline\nrelying solely on LLM-reported log-probabilities.",
    "pdf_url": "http://arxiv.org/pdf/2502.11620v3",
    "published": "2025-02-17T10:03:01+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11619v1",
    "title": "Membership Inference Attacks for Face Images Against Fine-Tuned Latent Diffusion Models",
    "authors": [
      "Lauritz Christian Holme",
      "Anton Mosquera Storgaard",
      "Siavash Arjomand Bigdeli"
    ],
    "abstract": "The rise of generative image models leads to privacy concerns when it comes\nto the huge datasets used to train such models. This paper investigates the\npossibility of inferring if a set of face images was used for fine-tuning a\nLatent Diffusion Model (LDM). A Membership Inference Attack (MIA) method is\npresented for this task. Using generated auxiliary data for the training of the\nattack model leads to significantly better performance, and so does the use of\nwatermarks. The guidance scale used for inference was found to have a\nsignificant influence. If a LDM is fine-tuned for long enough, the text prompt\nused for inference has no significant influence. The proposed MIA is found to\nbe viable in a realistic black-box setup against LDMs fine-tuned on\nface-images.",
    "pdf_url": "http://arxiv.org/pdf/2502.11619v1",
    "published": "2025-02-17T10:01:24+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11618v2",
    "title": "Real-time Neural Rendering of LiDAR Point Clouds",
    "authors": [
      "Joni Vanherck",
      "Brent Zoomers",
      "Tom Mertens",
      "Lode Jorissen",
      "Nick Michiels"
    ],
    "abstract": "Static LiDAR scanners produce accurate, dense, colored point clouds, but\noften contain obtrusive artifacts which makes them ill-suited for direct\ndisplay. We propose an efficient method to render photorealistic images of such\nscans without any expensive preprocessing or training of a scene-specific\nmodel. A naive projection of the point cloud to the output view using 1x1\npixels is fast and retains the available detail, but also results in\nunintelligible renderings as background points leak in between the foreground\npixels. The key insight is that these projections can be transformed into a\nrealistic result using a deep convolutional model in the form of a U-Net, and a\ndepth-based heuristic that prefilters the data. The U-Net also handles\nLiDAR-specific problems such as missing parts due to occlusion, color\ninconsistencies and varying point densities. We also describe a method to\ngenerate synthetic training data to deal with imperfectly-aligned ground truth\nimages. Our method achieves real-time rendering rates using an off-the-shelf\nGPU and outperforms the state-of-the-art in both speed and quality.",
    "pdf_url": "http://arxiv.org/pdf/2502.11618v2",
    "published": "2025-02-17T10:01:13+00:00",
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11617v1",
    "title": "In-Context Parametric Inference: Point or Distribution Estimators?",
    "authors": [
      "Sarthak Mittal",
      "Yoshua Bengio",
      "Nikolay Malkin",
      "Guillaume Lajoie"
    ],
    "abstract": "Bayesian and frequentist inference are two fundamental paradigms in\nstatistical estimation. Bayesian methods treat hypotheses as random variables,\nincorporating priors and updating beliefs via Bayes' theorem, whereas\nfrequentist methods assume fixed but unknown hypotheses, relying on estimators\nlike maximum likelihood. While extensive research has compared these\napproaches, the frequentist paradigm of obtaining point estimates has become\npredominant in deep learning, as Bayesian inference is challenging due to the\ncomputational complexity and the approximation gap of posterior estimation\nmethods. However, a good understanding of trade-offs between the two approaches\nis lacking in the regime of amortized estimators, where in-context learners are\ntrained to estimate either point values via maximum likelihood or maximum a\nposteriori estimation, or full posteriors using normalizing flows, score-based\ndiffusion samplers, or diagonal Gaussian approximations, conditioned on\nobservations. To help resolve this, we conduct a rigorous comparative analysis\nspanning diverse problem settings, from linear models to shallow neural\nnetworks, with a robust evaluation framework assessing both in-distribution and\nout-of-distribution generalization on tractable tasks. Our experiments indicate\nthat amortized point estimators generally outperform posterior inference,\nthough the latter remain competitive in some low-dimensional problems, and we\nfurther discuss why this might be the case.",
    "pdf_url": "http://arxiv.org/pdf/2502.11617v1",
    "published": "2025-02-17T10:00:24+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11616v1",
    "title": "User-Centric Data Management in Decentralized Internet of Behaviors System",
    "authors": [
      "Shiqi Zhang",
      "Dapeng Wu",
      "Honggang Wang",
      "Ruyan Wang"
    ],
    "abstract": "The Internet of Behaviors (IoB) is an emerging concept that utilizes devices\nto collect human behavior and provide intelligent services. Although some\nresearch has focused on human behavior analysis and data collection within IoB,\nthe associated security and privacy challenges remain insufficiently explored.\nThis paper analyzes the security and privacy risks at different stages of\nbehavioral data generating, uploading, and using, while also considering the\ndynamic characteristics of user activity areas. Then, we propose a\nblockchain-based distributed IoB data storage and sharing framework, which is\ncategorized into sensing, processing, and management layers based on these\nstages. To accommodate both identity authentication and behavioral privacy,\nzero-knowledge proofs are used in the sensing layer to separate the correlation\nbetween behavior and identity, which is further extended to a distributed\narchitecture for cross-domain authentication. In the processing layer, an\nimproved consensus protocol is proposed to enhance the decision-making\nefficiency of distributed IoB by analyzing the geographical and computational\ncapability of the servers. In the management layer, user permission differences\nand the privacy of access targets are considered. Different types of behavior\nare modeled as corresponding relationships between keys, and fine-grained\nsecure access is achieved through function secret sharing. Simulation results\ndemonstrate the effectiveness of the proposed framework in multi-scenario IoB,\nwith average consensus and authentication times reduced by 74% and 56%,\nrespectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.11616v1",
    "published": "2025-02-17T09:59:25+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11615v1",
    "title": "Topological dimension of the Gromov-Hausdorff and Gromov-Prokhorov spaces",
    "authors": [
      "Hiroki Nakajima",
      "Takamitsu Yamauchi",
      "NicolÃ² Zava"
    ],
    "abstract": "The Gromov-Hausdorff distance is a dissimilarity metric capturing how far two\nspaces are from being isometric. The Gromov-Prokhorov distance is a similar\nnotion for metric measure spaces. In this paper, we study the topological\ndimension of the Gromov-Hausdorff and Gromov-Prokhorov spaces. We show that the\ndimension of the space of isometry classes of metric spaces with at most $n$\npoints endowed with the Gromov-Hausdorff distance is $\\frac{n(n-1)}{2}$, and\nthat of mm-isomorphism classes of metric measure spaces whose support consists\nof $n$ points is $\\frac{(n+2)(n-1)}{2}$. Hence, the spaces of all isometry\nclasses of finite metric spaces and of all mm-isomorphism classes of finite\nmetric measure spaces are strongly countable dimensional. If, instead, the\ncardinalities are not limited, the spaces are strongly infinite-dimensional.",
    "pdf_url": "http://arxiv.org/pdf/2502.11615v1",
    "published": "2025-02-17T09:58:51+00:00",
    "categories": [
      "math.MG",
      "math.GN",
      "51F99, 54F45, 53C23, 54E35, 60D05, 49Q22"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11614v2",
    "title": "Is Human-Like Text Liked by Humans? Multilingual Human Detection and Preference Against AI",
    "authors": [
      "Yuxia Wang",
      "Rui Xing",
      "Jonibek Mansurov",
      "Giovanni Puccetti",
      "Zhuohan Xie",
      "Minh Ngoc Ta",
      "Jiahui Geng",
      "Jinyan Su",
      "Mervat Abassy",
      "Saad El Dine Ahmed",
      "Kareem Elozeiri",
      "Nurkhan Laiyk",
      "Maiya Goloburda",
      "Tarek Mahmoud",
      "Raj Vardhan Tomar",
      "Alexander Aziz",
      "Ryuto Koike",
      "Masahiro Kaneko",
      "Artem Shelmanov",
      "Ekaterina Artemova",
      "Vladislav Mikhailov",
      "Akim Tsvigun",
      "Alham Fikri Aji",
      "Nizar Habash",
      "Iryna Gurevych",
      "Preslav Nakov"
    ],
    "abstract": "Prior studies have shown that distinguishing text generated by large language\nmodels (LLMs) from human-written one is highly challenging, and often no better\nthan random guessing. To verify the generalizability of this finding across\nlanguages and domains, we perform an extensive case study to identify the upper\nbound of human detection accuracy. Across 16 datasets covering 9 languages and\n9 domains, 19 annotators achieved an average detection accuracy of 87.6\\%, thus\nchallenging previous conclusions. We find that major gaps between human and\nmachine text lie in concreteness, cultural nuances, and diversity. Prompting by\nexplicitly explaining the distinctions in the prompts can partially bridge the\ngaps in over 50\\% of the cases. However, we also find that humans do not always\nprefer human-written text, particularly when they cannot clearly identify its\nsource.",
    "pdf_url": "http://arxiv.org/pdf/2502.11614v2",
    "published": "2025-02-17T09:56:46+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11613v2",
    "title": "Parameter estimation in a dynamic Chung-Lu random graph",
    "authors": [
      "Rajat Subhra Hazra",
      "Michel Mandjes",
      "Jiesen Wang"
    ],
    "abstract": "In this paper we consider a dynamic version of the Chung-Lu random graph in\nwhich the edges alternate between being present and absent. The main\ncontribution concerns a technique by which one can estimate the underlying\ndynamics from partial information, in particular from snapshots of the total\nnumber of edges present. The efficacy of our inference method is demonstrated\nthrough a series of numerical experiments.",
    "pdf_url": "http://arxiv.org/pdf/2502.11613v2",
    "published": "2025-02-17T09:56:38+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11612v3",
    "title": "Maximum Entropy Reinforcement Learning with Diffusion Policy",
    "authors": [
      "Xiaoyi Dong",
      "Jian Cheng",
      "Xi Sheryl Zhang"
    ],
    "abstract": "The Soft Actor-Critic (SAC) algorithm with a Gaussian policy has become a\nmainstream implementation for realizing the Maximum Entropy Reinforcement\nLearning (MaxEnt RL) objective, which incorporates entropy maximization to\nencourage exploration and enhance policy robustness. While the Gaussian policy\nperforms well on simpler tasks, its exploration capacity and potential\nperformance in complex multi-goal RL environments are limited by its inherent\nunimodality. In this paper, we employ the diffusion model, a powerful\ngenerative model capable of capturing complex multimodal distributions, as the\npolicy representation to fulfill the MaxEnt RL objective, developing a method\nnamed MaxEnt RL with Diffusion Policy (MaxEntDP). Our method enables efficient\nexploration and brings the policy closer to the optimal MaxEnt policy.\nExperimental results on Mujoco benchmarks show that MaxEntDP outperforms the\nGaussian policy and other generative models within the MaxEnt RL framework, and\nperforms comparably to other state-of-the-art diffusion-based online RL\nalgorithms. Our code is available at https://github.com/diffusionyes/MaxEntDP.",
    "pdf_url": "http://arxiv.org/pdf/2502.11612v3",
    "published": "2025-02-17T09:55:58+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11611v1",
    "title": "Identifying Gender Stereotypes and Biases in Automated Translation from English to Italian using Similarity Networks",
    "authors": [
      "Fatemeh Mohammadi",
      "Marta Annamaria Tamborini",
      "Paolo Ceravolo",
      "Costanza Nardocci",
      "Samira Maghool"
    ],
    "abstract": "This paper is a collaborative effort between Linguistics, Law, and Computer\nScience to evaluate stereotypes and biases in automated translation systems. We\nadvocate gender-neutral translation as a means to promote gender inclusion and\nimprove the objectivity of machine translation. Our approach focuses on\nidentifying gender bias in English-to-Italian translations. First, we define\ngender bias following human rights law and linguistics literature. Then we\nproceed by identifying gender-specific terms such as she/lei and he/lui as key\nelements. We then evaluate the cosine similarity between these target terms and\nothers in the dataset to reveal the model's perception of semantic relations.\nUsing numerical features, we effectively evaluate the intensity and direction\nof the bias. Our findings provide tangible insights for developing and training\ngender-neutral translation algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11611v1",
    "published": "2025-02-17T09:55:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11610v2",
    "title": "Accuracy Assessment of OpenAlex and Clarivate Scholar ID with an LLM-Assisted Benchmark",
    "authors": [
      "Renyu Zhao",
      "Yunxin Chen"
    ],
    "abstract": "In quantitative SciSci (science of science) studies, accurately identifying\nindividual scholars is paramount for scientific data analysis. However, the\nvariability in how names are represented-due to commonality, abbreviations, and\ndifferent spelling conventions-complicates this task. While identifier systems\nlike ORCID are being developed, many scholars remain unregistered, and numerous\npublications are not included. Scholarly databases such as Clarivate and\nOpenAlex have introduced their own ID systems as preliminary name\ndisambiguation solutions. This study evaluates the effectiveness of these\nsystems across different groups to determine their suitability for various\napplication scenarios. We sampled authors from the top quartile (Q1) of Web of\nScience (WOS) journals based on country, discipline, and number of\ncorresponding author papers. For each group, we selected 100 scholars and\nmeticulously annotated all their papers using a Search-enhanced Large Language\nModel method. Using these annotations, we identified the corresponding IDs in\nOpenAlex and Clarivate, extracted all associated papers, filtered for Q1 WOS\njournals, and calculated precision and recall by comparing against the\nannotated dataset.",
    "pdf_url": "http://arxiv.org/pdf/2502.11610v2",
    "published": "2025-02-17T09:54:46+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11609v2",
    "title": "Exploiting Task Relationships for Continual Learning Using Transferability-Aware Task Embeddings",
    "authors": [
      "Yanru Wu",
      "Jianning Wang",
      "Xiangyu Chen",
      "Enming Zhang",
      "Yang Tan",
      "Hanbing Liu",
      "Yang Li"
    ],
    "abstract": "Continual learning (CL) has been a critical topic in contemporary deep neural\nnetwork applications, where higher levels of both forward and backward transfer\nare desirable for an effective CL performance. Existing CL strategies primarily\nfocus on task models, either by regularizing model updates or by separating\ntask-specific and shared components, while often overlooking the potential of\nleveraging inter-task relationships to enhance transfer. To address this gap,\nwe propose a transferability-aware task embedding, termed H-embedding, and\nconstruct a hypernet framework under its guidance to learn task-conditioned\nmodel weights for CL tasks. Specifically, H-embedding is derived from an\ninformation theoretic measure of transferability and is designed to be online\nand easy to compute. Our method is also characterized by notable practicality,\nrequiring only the storage of a low-dimensional task embedding per task and\nsupporting efficient end-to-end training. Extensive evaluations on benchmarks\nincluding CIFAR-100, ImageNet-R, and DomainNet show that our framework performs\nprominently compared to various baseline and SOTA approaches, demonstrating\nstrong potential in capturing and utilizing intrinsic task relationships. Our\ncode is publicly available at\nhttps://anonymous.4open.science/r/H-embedding_guided_hypernet/.",
    "pdf_url": "http://arxiv.org/pdf/2502.11609v2",
    "published": "2025-02-17T09:52:19+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2503.04773v3",
    "title": "Invisible Walls in Cities: Leveraging Large Language Models to Predict Urban Segregation Experience with Social Media Content",
    "authors": [
      "Bingbing Fan",
      "Lin Chen",
      "Songwei Li",
      "Jian Yuan",
      "Fengli Xu",
      "Pan Hui",
      "Yong Li"
    ],
    "abstract": "Understanding experienced segregation in urban daily life is crucial for\naddressing societal inequalities and fostering inclusivity. The abundance of\nuser-generated reviews on social media encapsulates nuanced perceptions and\nfeelings associated with different places, offering rich insights into\nsegregation. However, leveraging this data poses significant challenges due to\nits vast volume, ambiguity, and confluence of diverse perspectives. To tackle\nthese challenges, we propose using Large Language Models (LLMs) to automate\nonline review mining for segregation prediction. We design a Reflective LLM\nCoder to digest social media content into insights consistent with real-world\nfeedback, and eventually produce a codebook capturing key dimensions that\nsignal segregation experience, such as cultural resonance and appeal,\naccessibility and convenience, and community engagement and local involvement.\nGuided by the codebook, LLMs can generate both informative review summaries and\nratings for segregation prediction. Moreover, we design a\nREasoning-and-EMbedding (RE'EM) framework, which combines the reasoning and\nembedding capabilities of language models to integrate multi-channel features\nfor segregation prediction. Experiments on real-world data demonstrate that our\nframework greatly improves prediction accuracy, with a 22.79% elevation in R2\nand a 9.33% reduction in MSE. The derived codebook is generalizable across\nthree different cities, consistently improving prediction accuracy. Moreover,\nour user study confirms that the codebook-guided summaries provide cognitive\ngains for human participants in perceiving POIs' social inclusiveness. Our\nstudy marks an important step toward understanding implicit social barriers and\ninequalities, demonstrating the great potential of promoting social\ninclusiveness with AI.",
    "pdf_url": "http://arxiv.org/pdf/2503.04773v3",
    "published": "2025-02-17T09:52:17+00:00",
    "categories": [
      "cs.CL",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11608v1",
    "title": "Effect of Numerically Controlled Oscillator Bit Width in Phase Meters",
    "authors": [
      "Yuan-Ze Jiang",
      "Yu-Jie Feng",
      "Liu-Yang Chen",
      "Bai-Fu Lu",
      "Qi Xia",
      "Ze-Bing Zhou",
      "Yu-Rong Liang"
    ],
    "abstract": "Projects aiming to detect gravitational waves (GWs) in space in the\nmillihertz range will utilize interferometers to measure the separations\nbetween free-falling test masses. The phasemeter measures the phase changes of\nthe interference signals caused by the test masses' relative movements. The\nmeasurement sensitivity of the phasemeter is one of the key factors in the\ndetection. In this work, we reviewed the core metrology of the phasemeter and\nevaluated the ultra-low noise performance of the phasemeter with analog\nsignals. Frequency readout noise related to the bit width of the numerically\ncontrolled oscillator (NCO) inside the phasemeter is identified as one of the\nmain noise sources of phase measurement theoretically and experimentally. After\nincreasing the NCO bit widths, the single-channel phase noise of the phasemeter\nreached 2.0 {\\mu}rad/Hz^{1/2} at 6 mHz, and the differential phase noise\nreached 0.4 {\\mu}rad/Hz^{1/2} at 6 mHz. The phase noise performances remained\nconsistent within the carrier frequency range of 4.9 MHz to 25.1 MHz.",
    "pdf_url": "http://arxiv.org/pdf/2502.11608v1",
    "published": "2025-02-17T09:51:12+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2502.11607v2",
    "title": "GraphThought: Graph Combinatorial Optimization with Thought Generation",
    "authors": [
      "Zixiao Huang",
      "Lifeng Guo",
      "Wenhao Li",
      "Junjie Sheng",
      "Chuyun Shen",
      "Haosheng Chen",
      "Bo Jin",
      "Changhong Lu",
      "Xiangfeng Wang"
    ],
    "abstract": "Graph combinatorial optimization (GCO) problems are central to domains like\nlogistics and bioinformatics. While traditional solvers dominate, large\nlanguage models (LLMs) offer new possibilities for structured reasoning, yet\nstruggle with complex GCO tasks requiring rigorous combinatorial analysis and\nmulti-step deduction, often producing hallucinated steps. We first formalize\nthe Optimal Thoughts Design (OTD) problem, which provides a structured guidance\nfor producing high-quality intermediate reasoning steps. Building on this\nformulation, we introduce GraphThought, a novel framework that generates\neffective reasoning sequences through either heuristic-guided forward search or\nsolver-aligned backward reasoning. By fine-tuning LLMs on these structured\nthought sequences, we develop Llama-GT, an 8B-parameter model that achieves\nstate-of-the-art performance on the GraphArena benchmark, outperforming\nsignificantly larger models like DeepSeek-V3. Our results demonstrate that when\nscaffolded with structured reasoning priors, principled thought generation can\nsignificantly enhance LLM performance on GCO tasks without requiring increased\nmodel scale.",
    "pdf_url": "http://arxiv.org/pdf/2502.11607v2",
    "published": "2025-02-17T09:50:41+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11606v1",
    "title": "Modular Algorithms For Computing GrÃ¶bner Bases in Free Algebras",
    "authors": [
      "Clemens Hofstadler",
      "Viktor Levandovskyy"
    ],
    "abstract": "In this work, we extend modular techniques for computing Gr\\\"obner bases\ninvolving rational coefficients to (two-sided) ideals in free algebras. We show\nthat the infinite nature of Gr\\\"obner bases in this setting renders the\nclassical approach infeasible. Therefore, we propose a new method that relies\non signature-based algorithms. Using the data of signatures, we can overcome\nthe limitations of the classical approach and obtain a practical modular\nalgorithm. Moreover, the final verification test in this setting is both more\ngeneral and more efficient than the classical one. We provide a first\nimplementation of our modular algorithm in SageMath. Initial experiments show\nthat the new algorithm can yield significant speedups over the non-modular\napproach.",
    "pdf_url": "http://arxiv.org/pdf/2502.11606v1",
    "published": "2025-02-17T09:47:23+00:00",
    "categories": [
      "cs.SC",
      "math.RA"
    ],
    "primary_category": "cs.SC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11605v2",
    "title": "Uniform Resampling vs. Image Blur: Aliasing Approximation via Isotropic Gaussian Filtering",
    "authors": [
      "Suayb S. Arslan",
      "Lukas Vogelsang",
      "Michal Fux",
      "Pawan Sinha"
    ],
    "abstract": "One of the key approximations to range simulation is downscaling the image,\ndictated by the natural trigonometric relationships that arise due to\nlong-distance viewing. It is well-known that standard downsampling applied to\nan image without prior low-pass filtering leads to a type of signal distortion\ncalled \\textit{aliasing}. In this study, we aim at modeling the distortion due\nto aliasing and show that a downsampled/upsampled image after an interpolation\nprocess can be very well approximated through the application of isotropic\nGaussian low-pass filtering to the original image. In other words, the\ndistortion due to aliasing can approximately be generated by low-pass filtering\nthe image with a carefully determined cut-off frequency. We have found that the\nstandard deviation of the isotropic Gaussian kernel $\\sigma$ and the reduction\nfactor $m$ (also called downsampling ratio) satisfy an approximate $m \\approx 2\n\\sigma$ relationship. We provide both theoretical and practical arguments using\ntwo relatively small face datasets (Chicago DB, LRFID) as well as TinyImageNet\nto corroborate this empirically observed relationship.",
    "pdf_url": "http://arxiv.org/pdf/2502.11605v2",
    "published": "2025-02-17T09:47:19+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11604v2",
    "title": "An Actor-Critic Algorithm with Function Approximation for Risk Sensitive Cost Markov Decision Processes",
    "authors": [
      "Soumyajit Guin",
      "Vivek S. Borkar",
      "Shalabh Bhatnagar"
    ],
    "abstract": "In this paper, we consider the risk-sensitive cost criterion with\nexponentiated costs for Markov decision processes and develop a model-free\npolicy gradient algorithm in this setting. Unlike additive cost criteria such\nas average or discounted cost, the risk-sensitive cost criterion is less\nstudied due to the complexity resulting from the multiplicative structure of\nthe resulting Bellman equation. We develop an actor-critic algorithm with\nfunction approximation in this setting and provide its asymptotic convergence\nanalysis. We also show the results of numerical experiments that demonstrate\nthe superiority in performance of our algorithm over other recent algorithms in\nthe literature.",
    "pdf_url": "http://arxiv.org/pdf/2502.11604v2",
    "published": "2025-02-17T09:44:23+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11603v1",
    "title": "DR.GAP: Mitigating Bias in Large Language Models using Gender-Aware Prompting with Demonstration and Reasoning",
    "authors": [
      "Hongye Qiu",
      "Yue Xu",
      "Meikang Qiu",
      "Wenjie Wang"
    ],
    "abstract": "Large Language Models (LLMs) exhibit strong natural language processing\ncapabilities but also inherit and amplify societal biases, including gender\nbias, raising fairness concerns. Existing debiasing methods face significant\nlimitations: parameter tuning requires access to model weights, prompt-based\napproaches often degrade model utility, and optimization-based techniques lack\ngeneralizability. To address these challenges, we propose DR.GAP (Demonstration\nand Reasoning for Gender-Aware Prompting), an automated and model-agnostic\napproach that mitigates gender bias while preserving model performance. DR.GAP\nselects bias-revealing examples and generates structured reasoning to guide\nmodels toward more impartial responses. Extensive experiments on coreference\nresolution and QA tasks across multiple LLMs (GPT-3.5, Llama3, and\nLlama2-Alpaca) demonstrate its effectiveness, generalization ability, and\nrobustness. DR.GAP can generalize to vision-language models (VLMs), achieving\nsignificant bias reduction.",
    "pdf_url": "http://arxiv.org/pdf/2502.11603v1",
    "published": "2025-02-17T09:43:36+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11602v2",
    "title": "Cheesemap: A High-Performance Point-Indexing Data Structure for Neighbor Search in LiDAR Data",
    "authors": [
      "Ruben Laso",
      "Miguel Yermo"
    ],
    "abstract": "Point cloud data, as the representation of three-dimensional spatial\ninformation, is a fundamental piece of information in various domains where\nindexing and querying these point clouds efficiently is crucial for tasks such\nas object recognition, autonomous navigation, and environmental modeling. In\nthis paper, we present a comprehensive comparative analysis of various data\nstructures combined with neighboring search methods across different types of\npoint clouds. Additionally, we introduce a novel data structure, cheesemap, to\nhandle 3D LiDAR point clouds. Exploring the sparsity and irregularity in the\ndistribution of points, there are three flavors of the cheesemap: dense,\nsparse, and mixed. Results show that the cheesemap can outperform\nstate-of-the-art data structures in terms of execution time per query,\nparticularly for ALS (Aerial Laser Scanning) point clouds. Memory consumption\nis also minimal, especially in the sparse and mixed representations, making the\ncheesemap a suitable choice for applications involving three-dimensional point\nclouds.",
    "pdf_url": "http://arxiv.org/pdf/2502.11602v2",
    "published": "2025-02-17T09:42:36+00:00",
    "categories": [
      "cs.DS",
      "cs.PF",
      "E.1"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11601v1",
    "title": "Weak coupling approach to magnetic and orbital susceptibilities for superconducting states in multiorbital electron-phonon coupled model",
    "authors": [
      "Natsuki Okada",
      "Tatsuya Miki",
      "Shintaro Hoshino"
    ],
    "abstract": "Alkali-doped fullerides are molecular-based superconductors with multiple\nactive orbitals. In this paper, using the Eliashberg theory with the\nretardation effect of Jahn-Teller phonons, we study the response of the\nspin-singlet superconducting state relevant to fulleride materials. The spin\nZeeman field is not active for the singlet pairing state, and the magnetic\norbital field, which physically generates a circular electron motion inside the\nfullerene molecule, is also shown to be inactive. On the other hand, the\nelectric orbital (or quadrupolar) field, which corresponds to a uniaxial\ndistortion, remains active across the superconducting phase transition. This is\nunderstood by the orbital-symmetric structure of the Cooper pair, which is\nsusceptible to the electric orbital field, while it is not the case for the\nmagnetic orbital field which tends to create an antisymmetric part.",
    "pdf_url": "http://arxiv.org/pdf/2502.11601v1",
    "published": "2025-02-17T09:40:41+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2502.11600v2",
    "title": "Large Deviation Theory for Bose Gas of Photons and Planck's Oscillators",
    "authors": [
      "D. P. Shinde"
    ],
    "abstract": "We utilize large deviation theorems to analyze the distributions of a Bose\ngas of photons and Planck's identical linear oscillators. By applying the\nBoltzmann-Sanov and Cram\\'er-Chernoff theorems, we calculate the large\ndeviation probabilities, entropies, and rate functions for the spatial and\nenergy distributions of both photons and Planck's oscillators. Our study\nreproduces the results of Bose and Planck within the framework of large\ndeviation theory.",
    "pdf_url": "http://arxiv.org/pdf/2502.11600v2",
    "published": "2025-02-17T09:38:43+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2502.11599v2",
    "title": "Self-orthogonal codes from plateaued functions and their applications in quantum codes and LCD codes",
    "authors": [
      "Yadi Wei",
      "Jiaxin Wang",
      "Fang-Wei Fu"
    ],
    "abstract": "Self-orthogonal codes have received great attention due to their important\napplications in quantum codes, LCD codes and lattices. Recently, several\nfamilies of self-orthogonal codes containing the all-$1$ vector were\nconstructed by augmentation technique. In this paper, utilizing plateaued\nfunctions, we construct some classes of linear codes which do not contain the\nall-$1$ vector. We also investigate their punctured codes. The weight\ndistributions of the constructed codes are explicitly determined. Under certain\nconditions, these codes are proved to be self-orthogonal. Furthermore, some\nclasses of optimal linear codes are obtained from their duals. Using the\nself-orthogonal punctured codes, we also construct several new families of at\nleast almost optimal quantum codes and optimal LCD codes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11599v2",
    "published": "2025-02-17T09:38:38+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11598v2",
    "title": "Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?",
    "authors": [
      "Leyi Pan",
      "Aiwei Liu",
      "Shiyu Huang",
      "Yijian Lu",
      "Xuming Hu",
      "Lijie Wen",
      "Irwin King",
      "Philip S. Yu"
    ],
    "abstract": "The radioactive nature of Large Language Model (LLM) watermarking enables the\ndetection of watermarks inherited by student models when trained on the outputs\nof watermarked teacher models, making it a promising tool for preventing\nunauthorized knowledge distillation. However, the robustness of watermark\nradioactivity against adversarial actors remains largely unexplored. In this\npaper, we investigate whether student models can acquire the capabilities of\nteacher models through knowledge distillation while avoiding watermark\ninheritance. We propose two categories of watermark removal approaches:\npre-distillation removal through untargeted and targeted training data\nparaphrasing (UP and TP), and post-distillation removal through inference-time\nwatermark neutralization (WN). Extensive experiments across multiple model\npairs, watermarking schemes and hyper-parameter settings demonstrate that both\nTP and WN thoroughly eliminate inherited watermarks, with WN achieving this\nwhile maintaining knowledge transfer efficiency and low computational overhead.\nGiven the ongoing deployment of watermarking techniques in production LLMs,\nthese findings emphasize the urgent need for more robust defense strategies.\nOur code is available at\nhttps://github.com/THU-BPM/Watermark-Radioactivity-Attack.",
    "pdf_url": "http://arxiv.org/pdf/2502.11598v2",
    "published": "2025-02-17T09:34:19+00:00",
    "categories": [
      "cs.CL",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11597v1",
    "title": "Automatic target validation based on neuroscientific literature mining for tractography",
    "authors": [
      "Xavier Vasques",
      "Renaud Richardet",
      "Sean L Hill",
      "David Slater",
      "Jean-Cedric Chappelier",
      "Etienne Pralong",
      "Jocelyne Bloch",
      "Bogdan Draganski",
      "Laura Cif"
    ],
    "abstract": "Target identification for tractography studies requires solid anatomical\nknowledge validated by an extensive literature review across species for each\nseed structure to be studied. Manual literature review to identify targets for\na given seed region is tedious and potentially subjective. Therefore,\ncomplementary approaches would be useful. We propose to use text-mining models\nto automatically suggest potential targets from the neuroscientific literature,\nfull-text articles and abstracts, so that they can be used for anatomical\nconnection studies and more specifically for tractography. We applied\ntext-mining models to three structures: two well-studied structures, since\nvalidated deep brain stimulation targets, the internal globus pallidus and the\nsubthalamic nucleus and, the nucleus accumbens, an exploratory target for\ntreating psychiatric disorders. We performed a systematic review of the\nliterature to document the projections of the three selected structures and\ncompared it with the targets proposed by text-mining models, both in rat and\nprimate (including human). We ran probabilistic tractography on the nucleus\naccumbens and compared the output with the results of the text-mining models\nand literature review. Overall, text-mining the literature could find three\ntimes as many targets as two man-weeks of curation could. The overall\nefficiency of the text-mining against literature review in our study was 98%\nrecall (at 36% precision), meaning that over all the targets for the three\nselected seeds, only one target has been missed by text-mining. We demonstrate\nthat connectivity for a structure of interest can be extracted from a very\nlarge amount of publications and abstracts. We believe this tool will be useful\nin helping the neuroscience community to facilitate connectivity studies of\nparticular brain regions. The text mining tools used for the study are part of\nthe HBP Neuroinformatics Platform, publicly available at\nhttp://connectivity-brainer.rhcloud.com",
    "pdf_url": "http://arxiv.org/pdf/2502.11597v1",
    "published": "2025-02-17T09:30:42+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11596v1",
    "title": "LLM Embeddings for Deep Learning on Tabular Data",
    "authors": [
      "Boshko Koloski",
      "Andrei Margeloiu",
      "Xiangjian Jiang",
      "BlaÅ¾ Å krlj",
      "Nikola Simidjievski",
      "Mateja Jamnik"
    ],
    "abstract": "Tabular deep-learning methods require embedding numerical and categorical\ninput features into high-dimensional spaces before processing them. Existing\nmethods deal with this heterogeneous nature of tabular data by employing\nseparate type-specific encoding approaches. This limits the cross-table\ntransfer potential and the exploitation of pre-trained knowledge. We propose a\nnovel approach that first transforms tabular data into text, and then leverages\npre-trained representations from LLMs to encode this data, resulting in a\nplug-and-play solution to improv ing deep-learning tabular methods. We\ndemonstrate that our approach improves accuracy over competitive models, such\nas MLP, ResNet and FT-Transformer, by validating on seven classification\ndatasets.",
    "pdf_url": "http://arxiv.org/pdf/2502.11596v1",
    "published": "2025-02-17T09:28:51+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11595v1",
    "title": "End-to-End Reliability in Wireless IEEE 802.1Qbv Time-Sensitive Networks",
    "authors": [
      "S. Egger",
      "J. Gross",
      "J. Sachs",
      "G. P. Sharma",
      "C. Becker",
      "F. DÃ¼rr"
    ],
    "abstract": "Industrial cyber-physical systems require dependable network communication\nwith formal end-to-end reliability guarantees. Striving towards this goal,\nrecent efforts aim to advance the integration of 5G into Time-Sensitive\nNetworking (TSN). However, we show that IEEE 802.1Qbv TSN schedulers that are\nunattuned to 5G packet delay variations may jeopardize any reliability\nguarantees provided by the 5G system. We demonstrate this on a case where a\n99.99% reliability in the inner 5G network diminishes to below 10% when looking\nat end-to-end communication in TSN. In this paper, we overcome this shortcoming\nby introducing Full Interleaving Packet Scheduling (FIPS) as a\nwireless-friendly IEEE 802.1Qbv scheduler. To the best of our knowledge, FIPS\nis the first to provide formal end-to-end QoS guarantees in wireless TSN. FIPS\nallows a controlled batching of TSN streams, which improves schedulability in\nterms of the number of wireless TSN streams by a factor of up to x45. Even in\nfailure cases, FIPS isolates the otherwise cascading QoS violations to the\naffected streams and protects all other streams. With formal end-to-end\nreliability, improved schedulability, and fault isolation, FIPS makes a\nsubstantial advance towards dependability in wireless TSN.",
    "pdf_url": "http://arxiv.org/pdf/2502.11595v1",
    "published": "2025-02-17T09:28:49+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11594v2",
    "title": "iMOVE: Instance-Motion-Aware Video Understanding",
    "authors": [
      "Jiaze Li",
      "Yaya Shi",
      "Zongyang Ma",
      "Haoran Xu",
      "Feng Cheng",
      "Huihui Xiao",
      "Ruiwen Kang",
      "Fan Yang",
      "Tingting Gao",
      "Di Zhang"
    ],
    "abstract": "Enhancing the fine-grained instance spatiotemporal motion perception\ncapabilities of Video Large Language Models is crucial for improving their\ntemporal and general video understanding. However, current models struggle to\nperceive detailed and complex instance motions. To address these challenges, we\nhave made improvements from both data and model perspectives. In terms of data,\nwe have meticulously curated iMOVE-IT, the first large-scale\ninstance-motion-aware video instruction-tuning dataset. This dataset is\nenriched with comprehensive instance motion annotations and spatiotemporal\nmutual-supervision tasks, providing extensive training for the model's\ninstance-motion-awareness. Building on this foundation, we introduce iMOVE, an\ninstance-motion-aware video foundation model that utilizes Event-aware\nSpatiotemporal Efficient Modeling to retain informative instance spatiotemporal\nmotion details while maintaining computational efficiency. It also incorporates\nRelative Spatiotemporal Position Tokens to ensure awareness of instance\nspatiotemporal positions. Evaluations indicate that iMOVE excels not only in\nvideo temporal understanding and general video understanding but also\ndemonstrates significant advantages in long-term video understanding.",
    "pdf_url": "http://arxiv.org/pdf/2502.11594v2",
    "published": "2025-02-17T09:28:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11592v1",
    "title": "Competition Between Multiferroic and Magnetic Soliton Lattice States in DyFeO$_3$",
    "authors": [
      "S. E. Nikitin",
      "N. D. Andriushin",
      "Ã. S. FjellvÃ¥g",
      "E. Pomjakushina",
      "A. A. Turrini",
      "S. Artyukhin",
      "C. W. Schneider",
      "M. Mostovoy"
    ],
    "abstract": "Simultaneous breaking of time reversal and inversion symmetries in\nmultiferroics couples ferroelectricity to magnetism and is a source of unusual\nphysical phenomena that can be used in next-generation electronic devices. A\nnotable example is DyFeO$_3$, which under applied magnetic fields exhibits a\ngiant linear magnetoelectric response and a large spontaneous electric\npolarization induced by coexisting orders of Fe and Dy spins. Here, we use\nhigh-resolution neutron diffraction to show that at zero field DyFeO$_3$ hosts\nan incommensurate magnetic soliton lattice formed by spatially ordered Dy\ndomain walls with an average domain size of 231(8) \\AA. The long-ranged\ninteraction between the domain walls is mediated by magnons propagating through\nthe Fe subsystem and is analogous to the Yukawa force in particle physics. An\napplied magnetic field destroys the long-ranged incommensurate order, unlocks\nthe linear magnetoelectric response and stabilizes the ferroelectric state. The\nmagnetic domain walls are electrically charged and the soliton array dimerizes\nwhen both electric and magnetic fields are applied. Numerical simulations with\nexperimental parameters suggest, that the generic competition between the\nferroelectric and incommensurate states can be effectively controlled by an\napplied electric field.",
    "pdf_url": "http://arxiv.org/pdf/2502.11592v1",
    "published": "2025-02-17T09:28:18+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11593v1",
    "title": "A population synthesis study of the Gaia 100 pc unresolved white dwarf-main sequence binary population",
    "authors": [
      "Alejandro Santos-GarcÃ­a",
      "Santiago Torres",
      "Alberto Rebassa-Mansergas",
      "Alex J. Brown"
    ],
    "abstract": "Binary stars consisting of a white dwarf and a main sequence star (WDMS) are\nvaluable for studying key astrophysical questions. However, observational\nbiases strongly affect the known population, particularly unresolved systems\nwhere the main sequence star outshines the white dwarf. This work aims to\ncomprehensively simulate the population of unresolved WDMS binaries within 100\npc of the Sun and to compare the outcome with the currently most complete\nvolume-limited sample available from Gaia data. We employ a population\nsynthesis code, MRBIN, extensively developed by our group and based on Monte\nCarlo techniques, which uses a standard binary stellar evolutionary code\nadapted to cover a wide range of stars across all ages, masses, and\nmetallicities. Selection criteria matching those of Gaia observations are\napplied to generate synthetic populations comparable to the observed WDMS\nsample. The synthetic data accurately populate the expected regions in the Gaia\ncolor-magnitude diagram. However, simulations predict a lower number of\nextremely low-mass white dwarfs, suggesting potential issues in observed mass\nderivations. Additionally, our analysis constrains the common envelope\nefficiency to 0.1-0.4, consistent with previous findings, and estimates a total\ncompleteness of about 25% for the observed sample, confirming the strong\nobservational limitations for unresolved WDMS.",
    "pdf_url": "http://arxiv.org/pdf/2502.11593v1",
    "published": "2025-02-17T09:28:18+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11591v1",
    "title": "Morphological Neuron Classification Using Machine Learning",
    "authors": [
      "Xavier Vasques",
      "Laurent Vanel",
      "Guillaume Villette",
      "Laura Cif"
    ],
    "abstract": "Classification and quantitative characterization of neuronal morphologies\nfrom histological neuronal reconstruction is challenging since it is still\nunclear how to delineate a neuronal cell class and which are the best features\nto define them by. The morphological neuron characterization represents a\nprimary source to address anatomical comparisons, morphometric analysis of\ncells, or brain modeling. The objectives of this paper are (i) to develop and\nintegrate a pipeline that goes from morphological feature extraction to\nclassification and (ii) to assess and compare the accuracy of machine learning\nalgorithms to classify neuron morphologies. The algorithms were trained on 430\ndigitally reconstructed neurons subjectively classified into layers and/or\nm-types using young and/or adult development state population of the\nsomatosensory cortex in rats. For supervised algorithms, linear discriminant\nanalysis provided better classification results in comparison with others. For\nunsupervised algorithms, the affinity propagation and the Ward algorithms\nprovided slightly better results.",
    "pdf_url": "http://arxiv.org/pdf/2502.11591v1",
    "published": "2025-02-17T09:26:10+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11590v1",
    "title": "On the Moutard transformation singularity for the Davey--Stewartson II equation",
    "authors": [
      "Yi C. Huang"
    ],
    "abstract": "We indicate explicitly how to obtain the Moutard transformation singularity\nfor the Davey--Stewartson II equation with two indeterminancy points. We also\njustify an arbitrary order ``mass drop\" phenomenon via this singularity\nformation scheme.",
    "pdf_url": "http://arxiv.org/pdf/2502.11590v1",
    "published": "2025-02-17T09:25:46+00:00",
    "categories": [
      "math.AP",
      "nlin.SI",
      "Primary: 35Q53, Secondary: 37K35, 35B44, 49Q05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11589v1",
    "title": "Infinitely many saturated travelling waves for epidemic models with distributed-contacts",
    "authors": [
      "Matthieu Alfaro",
      "Maxime Herda",
      "Andrea Natale"
    ],
    "abstract": "We consider an epidemic model with distributed-contacts. When the contact\nkernel concentrates, one formally reaches a very degenerate Fisher-KPP equation\nwith a diffusion term that is not in divergence form. We make an exhaustive\nstudy of its travelling waves. For every admissible speed, there exists not\nonly a non-saturated (smooth) wave but also infinitely many saturated (sharp)\nones. Furthermore their tails may differ from what is usually expected. These\nresults are thus in sharp contrast with their counterparts on related models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11589v1",
    "published": "2025-02-17T09:25:03+00:00",
    "categories": [
      "math.AP",
      "35K65, 35C07, 92D30"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11588v1",
    "title": "A Unified Modeling Framework for Automated Penetration Testing",
    "authors": [
      "Yunfei Wang",
      "Shixuan Liu",
      "Wenhao Wang",
      "Changling Zhou",
      "Chao Zhang",
      "Jiandong Jin",
      "Cheng Zhu"
    ],
    "abstract": "The integration of artificial intelligence into automated penetration testing\n(AutoPT) has highlighted the necessity of simulation modeling for the training\nof intelligent agents, due to its cost-efficiency and swift feedback\ncapabilities. Despite the proliferation of AutoPT research, there is a\nrecognized gap in the availability of a unified framework for simulation\nmodeling methods. This paper presents a systematic review and synthesis of\nexisting techniques, introducing MDCPM to categorize studies based on\nliterature objectives, network simulation complexity, dependency of technical\nand tactical operations, and scenario feedback and variation. To bridge the gap\nin unified method for multi-dimensional and multi-level simulation modeling,\ndynamic environment modeling, and the scarcity of public datasets, we introduce\nAutoPT-Sim, a novel modeling framework that based on policy automation and\nencompasses the combination of all sub dimensions. AutoPT-Sim offers a\ncomprehensive approach to modeling network environments, attackers, and\ndefenders, transcending the constraints of static modeling and accommodating\nnetworks of diverse scales. We publicly release a generated standard network\nenvironment dataset and the code of Network Generator. By integrating publicly\navailable datasets flexibly, support is offered for various simulation modeling\nlevels focused on policy automation in MDCPM and the network generator help\nresearchers output customized target network data by adjusting parameters or\nfine-tuning the network generator.",
    "pdf_url": "http://arxiv.org/pdf/2502.11588v1",
    "published": "2025-02-17T09:21:53+00:00",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11587v1",
    "title": "Reduction of Magnetic-Field-Induced Shift in Quantum Frequency Standards Based on Coherent Population Trapping",
    "authors": [
      "V. I. Vishnyakov",
      "D. V. Brazhnikov",
      "M. N. Skvortsov"
    ],
    "abstract": "We investigate the magnetic-field-induced frequency shift (MFS) of the clock\n\"0-0\" transition in the microwave quantum frequency standard (atomic clock)\nbased on coherent population trapping (CPT) in $^{87}$Rb vapor. To scan the CPT\nresonance and to form the error signal, a method analogous to the\nPound-Drever-Hall (PDH) technique in the optical frequency range is employed,\nwhere the modulating frequency ($f_m$) significantly exceeds the resonance\nlinewidth (FWHM). The experiments demonstrate that this technique offers\nbrilliant capabilities for controlling the sensitivity of the clock transition\nfrequency to magnetic field variations in the vapor cell compared to the\nconventional method with low-frequency modulation ($f_m$$\\,\\ll\\,$FWHM).\nSpecifically, the PDH technique provides several optimal values of the bias\nmagnetic field generated by the solenoid, at which the \"0-0\" transition\nfrequency exhibits extremely low sensitivity to small variations in the\nexternal magnetic field. Furthermore, these magnetic field values can be easily\nadjusted by changing $f_m$, which is relevant for optimization of the atomic\nclock's operating regime. The experimental results show that by using the PDH\ntechnique, the influence of MFS on the clock transition can be suppressed down\nto $\\approx\\,$$3.2$$\\,\\times\\,$$10^{-13}$$\\delta B^2$ mG$^{-2}$. These findings\ncan be leveraged both to relax stringent requirements for magnetic field\nshielding in state-of-the-art CPT-based miniature atomic clocks (MACs) and to\nbuild a new generation of such clocks with long-term frequency stability better\nthan $10^{-12}$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11587v1",
    "published": "2025-02-17T09:21:23+00:00",
    "categories": [
      "physics.atom-ph",
      "quant-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11586v1",
    "title": "Syllables to Scenes: Literary-Guided Free-Viewpoint 3D Scene Synthesis from Japanese Haiku",
    "authors": [
      "Chunan Yu",
      "Yidong Han",
      "Chaotao Ding",
      "Ying Zang",
      "Lanyun Zhu",
      "Xinhao Chen",
      "Zejian Li",
      "Renjun Xu",
      "Tianrun Chen"
    ],
    "abstract": "In the era of the metaverse, where immersive technologies redefine human\nexperiences, translating abstract literary concepts into navigable 3D\nenvironments presents a fundamental challenge in preserving semantic and\nemotional fidelity. This research introduces HaikuVerse, a novel framework for\ntransforming poetic abstraction into spatial representation, with Japanese\nHaiku serving as an ideal test case due to its sophisticated encapsulation of\nprofound emotions and imagery within minimal text. While existing text-to-3D\nmethods struggle with nuanced interpretations, we present a literary-guided\napproach that synergizes traditional poetry analysis with advanced generative\ntechnologies. Our framework centers on two key innovations: (1) Hierarchical\nLiterary-Criticism Theory Grounded Parsing (H-LCTGP), which captures both\nexplicit imagery and implicit emotional resonance through structured semantic\ndecomposition, and (2) Progressive Dimensional Synthesis (PDS), a multi-stage\npipeline that systematically transforms poetic elements into coherent 3D scenes\nthrough sequential diffusion processes, geometric optimization, and real-time\nenhancement. Extensive experiments demonstrate that HaikuVerse significantly\noutperforms conventional text-to-3D approaches in both literary fidelity and\nvisual quality, establishing a new paradigm for preserving cultural heritage in\nimmersive digital spaces. Project website at:\nhttps://syllables-to-scenes.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.11586v1",
    "published": "2025-02-17T09:18:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11585v1",
    "title": "Calibration of Vehicular Traffic Simulation Models by Local Optimization",
    "authors": [
      "Davide Andrea Guastella",
      "Alejandro Morales-HernÃ ndez",
      "Bruno Cornelis",
      "Gianluca Bontempi"
    ],
    "abstract": "Simulation is a valuable tool for traffic management experts to assist them\nin refining and improving transportation systems and anticipating the impact of\npossible changes in the infrastructure network before their actual\nimplementation. Calibrating simulation models using traffic count data is\nchallenging because of the complexity of the environment, the lack of data, and\nthe uncertainties in traffic dynamics. This paper introduces a novel stochastic\nsimulation-based traffic calibration technique. The novelty of the proposed\nmethod is: (i) it performs local traffic calibration, (ii) it allows\ncalibrating simulated traffic in large-scale environments, (iii) it requires\nonly the traffic count data. The local approach enables decentralizing the\ncalibration task to reach near real-time performance, enabling the fostering of\ndigital twins. Using only traffic count data makes the proposed method generic\nso that it can be applied in different traffic scenarios at various scales\n(from neighborhood to region). We assess the proposed technique on a model of\nBrussels, Belgium, using data from real traffic monitoring devices. The\nproposed method has been implemented using the open-source traffic simulator\nSUMO. Experimental results show that the traffic model calibrated using the\nproposed method is on average 16% more accurate than those obtained by the\nstate-of-the-art methods, using the same dataset. We also make available the\noutput traffic model obtained from real data.",
    "pdf_url": "http://arxiv.org/pdf/2502.11585v1",
    "published": "2025-02-17T09:17:01+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11584v1",
    "title": "Runtime Enforcement of CPS against Signal Temporal Logic",
    "authors": [
      "Han Su",
      "Saumya Shankar",
      "Srinivas Pinisetty",
      "Partha S. Roop",
      "Naijun Zhan"
    ],
    "abstract": "Cyber-Physical Systems (CPSs), especially those involving autonomy, need\nguarantees of their safety. Runtime Enforcement (RE) is a lightweight method to\nformally ensure that some specified properties are satisfied over the\nexecutions of the system. Hence, there is recent interest in the RE of CPS.\nHowever, existing methods are not designed to tackle specifications suitable\nfor the hybrid dynamics of CPS. With this in mind, we develop runtime\nenforcement of CPS using properties defined in Signal Temporal Logic (STL).\n  In this work, we aim to construct a runtime enforcer for a given STL formula\nto minimally modify a signal to satisfy the formula. To achieve this, the STL\nformula to be enforced is first translated into a timed transducer, while the\nsignal to be corrected is encoded as timed words. We provide timed transducers\nfor the temporal operators \\emph{until} and \\emph{release} noting that other\ntemporal operators can be expressed using these two. Our approach enables\neffective enforcement of STL properties for CPS. A case study is provided to\nillustrate the approach and generate empirical evidence of its suitability for\nCPS.",
    "pdf_url": "http://arxiv.org/pdf/2502.11584v1",
    "published": "2025-02-17T09:16:58+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11583v2",
    "title": "Distributional Autoencoders Know the Score",
    "authors": [
      "Andrej Leban"
    ],
    "abstract": "This work presents novel and desirable properties of a recently introduced\nclass of autoencoders - the Distributional Principal Autoencoder (DPA) - which\ncombines distributionally correct reconstruction with principal components-like\ninterpretability of the encodings. First, we show formally that the level sets\nof the encoder orient themselves exactly with regard to the score of the data\ndistribution. This both explains the method's often remarkable performance in\ndisentangling the factors of variation of the data, as well as opens up\npossibilities of recovering its distribution while having access to samples\nonly. In settings where the score itself has physical meaning - such as when\nthe data obeys the Boltzmann distribution - we demonstrate that the method can\nrecover scientifically important quantities such as the minimum free energy\npath. Second, we prove that if the data lies on a manifold that can be\napproximated by the encoder, the optimal encoder's components beyond the\ndimension of the manifold will carry absolutely no additional information about\nthe data distribution. This promises potentially new ways of determining the\nnumber of relevant dimensions of the data. The results thus demonstrate that\nthe DPA elegantly combines two often disparate goals of unsupervised learning:\nthe learning of the data distribution and the learning of the intrinsic data\ndimensionality.",
    "pdf_url": "http://arxiv.org/pdf/2502.11583v2",
    "published": "2025-02-17T09:16:25+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.11582v1",
    "title": "Curves on Compact Arithmetic Quotients of Hyperbolic 2-ball",
    "authors": [
      "Zhehao Li"
    ],
    "abstract": "We study the geometry of the simplest type of compact arithmetic quotients of\nthe hyperbolic 2-ball $\\mathbb{B}^2$, which has a moduli interpretation for\ncertain types of abelian varieties of dimension 6 with\n$\\mathcal{O}_F$-endomorphism, where $F$ is a CM extension of a real quadratic\nfield $\\mathbb{Q}(\\sqrt{D})$. Under mild assumption, we prove that for any\nfixed $g$, when the defining discriminant $D$ is large, there will be no\ncomplex curves of genus $g$ on this type of arithmetic quotients. The proof\nuses the technique of volume estimates, which requires us to understand the\ndistribution of special subvarieties and the geometry near quotient and cusp\nsingularities.",
    "pdf_url": "http://arxiv.org/pdf/2502.11582v1",
    "published": "2025-02-17T09:15:22+00:00",
    "categories": [
      "math.AG",
      "math.DG",
      "math.NT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11581v2",
    "title": "Instability of marginally outer trapped surfaces from initial data set symmetry",
    "authors": [
      "Abbas M. Sherif"
    ],
    "abstract": "Let $(\\tilde{\\Sigma},h_{ab},K_{ab})$ be an initial data set and let $x^a$ be\na symmetry vector of $\\tilde{\\Sigma}$. Consider a MOTS $\\mathcal{S}$ in\n$\\tilde{\\Sigma}$ and let the symmetry vector be decomposable along the unit\nnormal to $\\mathcal{S}$ in $\\tilde{\\Sigma}$, and along $\\mathcal{S}$. In this\nnote we present some basic results with regards to the stability of\n$\\mathcal{S}$. The vector decomposition allows us to characterize the\ninstability of $\\mathcal{S}$ by the nature of the zero set of the normal\ncomponent to $\\mathcal{S}$ and the divergence of the component along\n$\\mathcal{S}$. Further observations are made under the assumption of\n$\\mathcal{S}$ having a constant mean curvature, and $\\tilde{\\Sigma}$ being an\nEinstein manifold.",
    "pdf_url": "http://arxiv.org/pdf/2502.11581v2",
    "published": "2025-02-17T09:15:08+00:00",
    "categories": [
      "math.DG",
      "gr-qc"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11580v1",
    "title": "A very young tau-Herculid meteor cluster observed during a 2022 shower outburst",
    "authors": [
      "Pavel Koten",
      "David Äapek",
      "Juraj TÃ³th",
      "LukÃ¡Å¡ ShrbenÃ½",
      "JiÅÃ­ BoroviÄka",
      "Jeremie Vaubaillon",
      "Fabian Zander",
      "David Buttsworth",
      "Stefan Loehle"
    ],
    "abstract": "To date only very few meteor clusters have been instrumentally recorded. This\nmeans that every new detection is an important contribution to the\nunderstanding of these phenomena, which are thought to be evidence of the\nmeteoroid fragmentation in the Solar System. On 31 May 2022, at 6:48:55 UT, a\ncluster consisting of 52 meteors was detected within 8.5 seconds during a\npredicted outburst of the tau-Herculid meteor shower. The aim of this paper is\nto reconstruct the atmospheric trajectories of the meteors and use the\ncollected information to deduce the origin of the cluster. The meteors were\nrecorded by two video cameras during an airborne campaign. Due to only the\nsingle station observation, their trajectories were estimated under the\nassumption that they belonged to the meteor shower. The mutual positions of the\nfragments, together with their photometric masses, was used to model the\nprocesses leading to the formation of the cluster. The physical properties of\nthe cluster meteors are very similar to the properties of the tau-Herculids.\nThis finding confirms the assumption of the shower membership used for the\ncomputation of atmospheric trajectories. This was the third cluster that we\nhave studied in detail, but the first one where we do not see the mass\nseparation of the particles. The cluster is probably less than 2.5 days old,\nwhich is too short for such a complete mass separation. Such an age would imply\ndisintegration due to thermal stress. However, we cannot rule out an age of\nonly a few hours, which would allow for other fragmentation mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11580v1",
    "published": "2025-02-17T09:13:37+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11579v1",
    "title": "Walks along a weak square sequence and the non-semiproperness of Namba forcings",
    "authors": [
      "Kenta Tsukuura"
    ],
    "abstract": "In this paper, we demonstrate that if, for every $\\kappa$-complete fine\nfilter $F$ over $\\mathcal{P}_{\\kappa}\\lambda$, the associated Namba forcing\n$\\mathrm{Nm}(\\kappa,\\lambda,F)$ is semiproper, then $\\square(\\mu,{<}\\aleph_1)$\nfails for all regular $\\mu \\in [\\lambda, 2^{\\lambda}]$ under the certain\ncardinal arithmetic. In particular, this result establishes that the\nconsistency strength of the semiproperness of $\\mathrm{Nm}(\\aleph_2,F)$ for\nevery $\\aleph_2$-complete filter $F$ over $\\aleph_2$ exceeds the strength of\ninfinitely many Woodin cardinals.\n  Minimal walk methods associated with a square sequece play a central role in\nthis paper. These observations introduce two-cardinal walks with naive\n$C$-sequences and show that the existence of non-reflecting stationary subsets\nimplies $\\mathcal{P}_{\\kappa}\\lambda \\not\\to\n[I_{\\kappa\\lambda}^{+}]^{3}_{\\lambda}$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11579v1",
    "published": "2025-02-17T09:13:30+00:00",
    "categories": [
      "math.LO"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11578v1",
    "title": "Language Complexity Measurement as a Noisy Zero-Shot Proxy for Evaluating LLM Performance",
    "authors": [
      "Birger Moell",
      "Johan Boye"
    ],
    "abstract": "Large Language Models (LLMs) have made significant strides in natural\nlanguage generation but often face challenges in tasks requiring precise\ncalculations and structural analysis. This paper investigates the performance\nof state-of-the-art LLMs on language complexity measurement tasks, through the\ncomputation of the LIX readability metric and Average Dependency Distance\n(ADD). Using Swedish high school and university-level essays, we evaluate the\nmodels' abilities to compute LIX scores and perform dependency parsing,\ncomparing their results to established ground truths. Our findings reveal that\nwhile all models demonstrate some capacity for these tasks, ChatGPT-o1-mini\nperforms most consistently, achieving the highest accuracy in both LIX\ncomputation and dependency parsing. Additionally, we observe a strong\nsignificant correlation -0.875 p 0.026 (N=6) between the models' accuracy in\ncomputing LIX and their overall performance on the Massive Multitask Language\nUnderstanding (MMLU) benchmark. These results suggest that language complexity\nmeasurement abilities can serve as a noisy zero-shot proxies for assessing the\ngeneral capabilities of LLMs, providing a practical method for model evaluation\nwithout the need for extensive benchmarking datasets.",
    "pdf_url": "http://arxiv.org/pdf/2502.11578v1",
    "published": "2025-02-17T09:09:58+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11577v1",
    "title": "When tiny convective spread affects a midlatitude jet: spread sequence",
    "authors": [
      "Edward Groot",
      "Michael Riemer"
    ],
    "abstract": "We investigate the evolution of spread over three days in a numerical\nensemble experiment starting from tiny initial condition uncertainty. We\nsimulate a real event during which three mesoscale convective systems occur in\nclose proximity to the midlatitude jet. The spread evolution is compared with\nan existing conceptual three-stage model. Each system follows the first stage,\ncharacterised by development of convective variability. Nevertheless, we find\nsignificant variation among the systems in their propensity to interact with\nthe jet stream, which characterises conceptual stage 2. One exemplary\nconvective system follows the conceptual evolution of Baumgart et al., i.e.,\nconvective uncertainty initially projects onto the jet by upper-tropospheric\noutflow, which further amplifies spread through nonlinear growth as it\npropagates downstream. Rossby-like dispersion in the downstream spread is\nstrongly associated with the convective variability. In contrast, for another\nconvective system, convective variability projects onto the local anticyclonic\nflow aloft. Subsequently, this anticyclonic perturbation hardly (if at all)\nprojects convective uncertainty onto the particularly straight jet stream,\nwhich truncates the conceptual evolution. For the third system, negligible\nfingerprints of second and third stages are identified. Alongside convective\nheating, longwave radiation jointly dominates the spread evolution near the\nconvective systems (as opposed to earlier studies). Longwave-radiative\ntendencies of convective anvils outlive the accompanied heating tendencies and\nextend spatially. Furthermore, we link convective variability of the exemplary\nsystem directly to longwave-radiative tendencies. Therefore, longwave radiation\nappears to contributes substantially to stages 1 and 2 here. Finally, we\nidentify flow dependence of the impact of convection on the jet. (Truncated\nabstract)",
    "pdf_url": "http://arxiv.org/pdf/2502.11577v1",
    "published": "2025-02-17T09:08:39+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11576v1",
    "title": "New Potential Ultra-compact X-ray Binaries for Space-based Gravitational Wave Detectors From Low-Mass Main-Sequence Companion Channel",
    "authors": [
      "Minghua Chen",
      "Jinzhong liu"
    ],
    "abstract": "We investigate the formation and evolution of Ultra-Compact X-ray Binaries\n(UCXBs) using the COMPAS binary evolution code, starting from the Zero Age Main\nSequence (ZAMS). Focusing on the low-mass MS companion channel, we simulate\ngravitational wave (GW) signals from UCXBs with LEGWORK and evaluate their\ndetectability by space-based observatories such as Taiji and TianQin. By\nincorporating signal-to-noise ratio (SNR) calculations with a threshold of SNR\n> 5, we provide a realistic framework to assess the detectability of the GW\nsource. Our analysis suggests that the Milky Way currently hosts 7-32\nobservable UCXBs from the MS companion channel. Taiji or LISA alone could\ndetect 1-6 sources over an 8-year observation period, while TianQin, due to its\nhigh-frequency sensitivity, contributes to detecting systems with extremely\nshort orbital periods and can also detect 1-4 sources. Comparison with\nsensitivity curves validates UCXBs as detectable GW sources, particularly at\ngreater Galactic distances. This study improves our understanding of the\nevolution of UCXBs and their role as GW sources. By integrating population\nsynthesis, SNR-based analyses, and observational data, we establish UCXBs as\nsignificant targets for GW astronomy, paving the way for future missions and\ntheoretical studies of compact binary systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11576v1",
    "published": "2025-02-17T09:08:20+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.12217v1",
    "title": "Optimal Brain Iterative Merging: Mitigating Interference in LLM Merging",
    "authors": [
      "Zhixiang Wang",
      "Zhenyu Mao",
      "Yixuan Qiao",
      "Yunfang Wu",
      "Biye Li"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities, but\ntheir high computational costs pose challenges for customization. Model merging\noffers a cost-effective alternative, yet existing methods suffer from\ninterference among parameters, leading to performance degradation. In this\nwork, we propose Optimal Brain Iterative Merging (OBIM), a novel method\ndesigned to mitigate both intra-model and inter-model interference. OBIM\nconsists of two key components: (1) A saliency measurement mechanism that\nevaluates parameter importance based on loss changes induced by individual\nweight alterations, reducing intra-model interference by preserving only\nhigh-saliency parameters. (2) A mutually exclusive iterative merging framework,\nwhich incrementally integrates models using a binary mask to avoid direct\nparameter averaging, thereby mitigating inter-model interference. We validate\nOBIM through experiments on both Supervised Fine-Tuned (SFT) models and\npost-pretrained checkpoints. The results show that OBIM significantly\noutperforms existing merging techniques. Overall, OBIM provides an effective\nand practical solution for enhancing LLM merging.",
    "pdf_url": "http://arxiv.org/pdf/2502.12217v1",
    "published": "2025-02-17T09:07:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11575v1",
    "title": "Branes in String/M-Theory",
    "authors": [
      "J. X. Lu"
    ],
    "abstract": "This is the writeup of lectures delivered in Asian Pacific introductory\nschool on superstring and the related topics in Beijing (2006) and the expanded\nversion of these lectures in the 3rd summer school on strings, fields and\nholography in Nanjing (2023). It intends to give a historical as well as a\npedagogical account of the development in finding the 1/2 BPS extended string\nsolitons in the early stage of the so-called second string revolution before\nwhich those objects were thought to be unrelated to strings. Non-susy solutions\nwhich are related to brane/anti brane systems or non-BPS systems are also\ndiscussed.",
    "pdf_url": "http://arxiv.org/pdf/2502.11575v1",
    "published": "2025-02-17T09:07:34+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.11573v1",
    "title": "InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning",
    "authors": [
      "Congkai Xie",
      "Shuo Cai",
      "Wenjun Wang",
      "Pengxiang Li",
      "Zhijie Sang",
      "Kejing Yang",
      "Yiming Zhang",
      "Zhen Li",
      "Guanghao Zhu",
      "Zeyu Liu",
      "Yang Yu",
      "Yuhang Liu",
      "Su Lu",
      "Baoyi He",
      "Qi Zhou",
      "Xiaotian Han",
      "Jianbo Yuan",
      "Shengyu Zhang",
      "Fei Wu",
      "Hongxia Yang"
    ],
    "abstract": "Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)\nhave made significant advancements in reasoning capabilities. However, they\nstill face challenges such as high computational demands and privacy concerns.\nThis paper focuses on developing efficient Small Language Models (SLMs) and\nMultimodal Small Language Models (MSLMs) that retain competitive reasoning\nabilities. We introduce a novel training pipeline that enhances reasoning\ncapabilities and facilitates deployment on edge devices, achieving\nstate-of-the-art performance while minimizing development costs. \\InfR~ aims to\nadvance AI systems by improving reasoning, reducing adoption barriers, and\naddressing privacy concerns through smaller model sizes. Resources are\navailable at https://github. com/Reallm-Labs/InfiR.",
    "pdf_url": "http://arxiv.org/pdf/2502.11573v1",
    "published": "2025-02-17T09:07:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11574v2",
    "title": "Large Language Models and Mathematical Reasoning Failures",
    "authors": [
      "Johan Boye",
      "Birger Moell"
    ],
    "abstract": "This paper investigates the mathematical reasoning capabilities of large\nlanguage models (LLMs) using 50 newly constructed high-school-level word\nproblems. Unlike prior studies that focus solely on answer correctness, we\nrigorously analyze both final answers and solution steps to identify reasoning\nfailures. Evaluating eight state-of-the-art models - including Mixtral, Llama,\nGemini, GPT-4o, and OpenAI's o1 variants - we find that while newer models\n(e.g., o3-mini, deepseek-r1) achieve higher accuracy, all models exhibit errors\nin spatial reasoning, strategic planning, and arithmetic, sometimes producing\ncorrect answers through flawed logic. Common failure modes include unwarranted\nassumptions, over-reliance on numerical patterns, and difficulty translating\nphysical intuition into mathematical steps. Manual analysis reveals that models\nstruggle with problems requiring multi-step deduction or real-world knowledge,\ndespite possessing broad mathematical knowledge. Our results underscore the\nimportance of evaluating reasoning processes, not just answers, and caution\nagainst overestimating LLMs' problem-solving proficiency. The study highlights\npersistent gaps in LLMs' generalization abilities, emphasizing the need for\ntargeted improvements in structured reasoning and constraint handling.",
    "pdf_url": "http://arxiv.org/pdf/2502.11574v2",
    "published": "2025-02-17T09:07:32+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11572v2",
    "title": "Improving Rare-Word Recognition of Whisper in Zero-Shot Settings",
    "authors": [
      "Yash Jogi",
      "Vaibhav Aggarwal",
      "Shabari S Nair",
      "Yash Verma",
      "Aayush Kubba"
    ],
    "abstract": "Whisper, despite being trained on 680K hours of web-scaled audio data, faces\ndifficulty in recognising rare words like domain-specific terms, with a\nsolution being contextual biasing through prompting. To improve upon this\nmethod, in this paper, we propose a supervised learning strategy to fine-tune\nWhisper for contextual biasing instruction. We demonstrate that by using only\n670 hours of Common Voice English set for fine-tuning, our model generalises to\n11 diverse open-source English datasets, achieving a 45.6% improvement in\nrecognition of rare words and 60.8% improvement in recognition of words unseen\nduring fine-tuning over the baseline method. Surprisingly, our model's\ncontextual biasing ability generalises even to languages unseen during\nfine-tuning.",
    "pdf_url": "http://arxiv.org/pdf/2502.11572v2",
    "published": "2025-02-17T09:06:34+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11571v2",
    "title": "FaMTEB: Massive Text Embedding Benchmark in Persian Language",
    "authors": [
      "Erfan Zinvandi",
      "Morteza Alikhani",
      "Mehran Sarmadi",
      "Zahra Pourbahman",
      "Sepehr Arvin",
      "Reza Kazemi",
      "Arash Amini"
    ],
    "abstract": "In this paper, we introduce a comprehensive benchmark for Persian (Farsi)\ntext embeddings, built upon the Massive Text Embedding Benchmark (MTEB). Our\nbenchmark includes 63 datasets spanning seven different tasks: classification,\nclustering, pair classification, reranking, retrieval, summary retrieval, and\nsemantic textual similarity. The datasets are formed as a combination of\nexisting, translated, and newly generated data, offering a diverse evaluation\nframework for Persian language models. Given the increasing use of text\nembedding models in chatbots, evaluation datasets are becoming inseparable\ningredients in chatbot challenges and Retrieval-Augmented Generation systems.\nAs a contribution, we include chatbot evaluation datasets in the MTEB benchmark\nfor the first time. In addition, in this paper, we introduce the new task of\nsummary retrieval which is not part of the tasks included in standard MTEB.\nAnother contribution of this paper is the introduction of a substantial number\nof new Persian language NLP datasets suitable for training and evaluation, some\nof which have no previous counterparts in Persian. We evaluate the performance\nof several Persian and multilingual embedding models in a range of tasks. This\nwork introduces an open-source benchmark with datasets, code and a public\nleaderboard.",
    "pdf_url": "http://arxiv.org/pdf/2502.11571v2",
    "published": "2025-02-17T09:05:21+00:00",
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11570v2",
    "title": "Towards a Trustworthy Anomaly Detection for Critical Applications through Approximated Partial AUC Loss",
    "authors": [
      "Arnaud Bougaham",
      "BenoÃ®t FrÃ©nay"
    ],
    "abstract": "Anomaly Detection is a crucial step for critical applications such in the\nindustrial, medical or cybersecurity domains. These sectors share the same\nrequirement of handling differently the different types of classification\nerrors. Indeed, even if false positives are acceptable, false negatives are\nnot, because it would reflect a missed detection of a quality issue, a disease\nor a cyber threat. To fulfill this requirement, we propose a method that\ndynamically applies a trustworthy approximated partial AUC ROC loss (tapAUC). A\nbinary classifier is trained to optimize the specific range of the AUC ROC\ncurve that prevents the True Positive Rate (TPR) to reach 100% while minimizing\nthe False Positive Rate (FPR). The optimal threshold that does not trigger any\nfalse negative is then kept and used at the test step. The results show a TPR\nof 92.52% at a 20.43% FPR for an average across 6 datasets, representing a TPR\nimprovement of 4.3% for a FPR cost of 12.2% against other state-of-the-art\nmethods. The code is available at https://github.com/ArnaudBougaham/tapAUC.",
    "pdf_url": "http://arxiv.org/pdf/2502.11570v2",
    "published": "2025-02-17T08:59:59+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11569v2",
    "title": "Towards Reasoning Ability of Small Language Models",
    "authors": [
      "Gaurav Srivastava",
      "Shuxiang Cao",
      "Xuan Wang"
    ],
    "abstract": "Reasoning has long been viewed as an emergent property of large language\nmodels (LLMs), appearing at or above a certain scale ($\\sim$100B parameters).\nHowever, recent studies challenge this assumption, showing that small language\nmodels (SLMs) can also achieve competitive reasoning performance. SLMs are\nincreasingly favored for their efficiency and deployability. However, there is\na lack of systematic study on the reasoning abilities of diverse SLMs,\nincluding those trained from scratch or derived from LLMs through quantization,\npruning, and distillation. This raises a critical question: Can SLMs achieve\nreasoning abilities comparable to LLMs? In this work, we systematically survey,\nbenchmark, and analyze 72 SLMs from six model families across 14 reasoning\nbenchmarks. For reliable evaluation, we examine four evaluation methods and\ncompare four LLM judges against human evaluations on 800 data points. We repeat\nall experiments three times to ensure a robust performance assessment.\nAdditionally, we analyze the impact of different prompting strategies in small\nmodels. Beyond accuracy, we also evaluate model robustness under adversarial\nconditions and intermediate reasoning steps. Our findings challenge the\nassumption that scaling is the only way to achieve strong reasoning. Instead,\nwe foresee a future where SLMs with strong reasoning capabilities can be\ndeveloped through structured training or post-training compression. They can\nserve as efficient alternatives to LLMs for reasoning-intensive tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11569v2",
    "published": "2025-02-17T08:59:16+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11568v1",
    "title": "A solution to the Hubble tension with self-interacting ultralight dark matter",
    "authors": [
      "Jae-Weon Lee"
    ],
    "abstract": "We show that oscillations of self-interacting ultralight dark matter with a\ncharacteristic energy scale $ \\tilde{m} \\simeq 1~eV $ naturally act as an extra\nradiation component just before the recombination era, decreasing the sound\nhorizon radius of the photon-baryon fluid. This reduction leads to an increase\nin the present-day Hubble parameter, potentially resolving the Hubble tension\nwithout the need for exotic matter or energy. The required mass and quartic\nself-interaction coupling are consistent with current astronomical constraints,\nincluding the relic dark matter density. This model could also reduce the $S_8$\ntension often associated with other early-time solutions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11568v1",
    "published": "2025-02-17T08:59:02+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11567v2",
    "title": "Minimum-dissipation model and symmetry-preserving discretization for scalar transport in a turbulent flow",
    "authors": [
      "Jing Sun",
      "F. Xavier Trias",
      "Roel Verstappen"
    ],
    "abstract": "This work extends the minimum-dissipation model of large-eddy simulation and\nsymmetry-preserving discretization to account for active or passive scalar\ntransport and complex physical mechanisms.This novel scalar-minimum-dissipation\nmodel exhibits several desirable properties. It includes the effect of scalar\ntransport, in addition to shear, on the suppression and production of\nturbulence. It switches off at no-slip walls, ensuring accurate capture of\nnear-wall flow behavior without needing a wall model. It also switches off in\nlaminar and transitional flows so that it is capable of predicting\nlaminar-turbulent transition. The new scalar-minimum-dissipation model combined\nwith the symmetry-preserving discretization is successfully tested in a\ndifferentially heated cavity in OpenFOAM. The results show that the\nsymmetry-preserving discretization significantly improves predictions of flow\nquantity and heat transfer on highly stretched meshes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11567v2",
    "published": "2025-02-17T08:57:11+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11566v2",
    "title": "Ergodic closing lemmas and invariant Lagrangians",
    "authors": [
      "Erman Cineli",
      "Sobhan Seyfaddini",
      "Shira Tanny"
    ],
    "abstract": "Motivated by the ergodic closing lemma of Ma\\~n\\'e, we investigate the\n$C^\\infty$ closing lemma in higher-dimensional Hamiltonian systems, with a\nfocus on the statistical behavior of periodic orbits generated by\n$C^\\infty$-small perturbations. We demonstrate that, under certain\nFloer-theoretic conditions, invariant or recurrent Lagrangian submanifolds can\ngive rise to periodic orbits whose statistical properties are controllable. For\ninstance, we show that for Hamiltonian systems preserving the zero section in\n$T^*\\mathbb{T}^n$, $C^\\infty$ generically, there exist periodic orbits\nconverging to an invariant measure supported on the zero section.",
    "pdf_url": "http://arxiv.org/pdf/2502.11566v2",
    "published": "2025-02-17T08:55:38+00:00",
    "categories": [
      "math.DS",
      "math.SG"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11565v1",
    "title": "STARS-Enabled Full-Duplex Two-Way mMIMO System Under Spatially-Correlated Channels",
    "authors": [
      "Anastasios Papazafeiropoulos",
      "Pandelis Kourtessis",
      "Symeon Chatzinotas",
      "Dimitra I. Kaklamani",
      "Iakovos S. Venieris"
    ],
    "abstract": "\\underline{S}imultaneous \\underline{t}ransmitting \\underline{a}nd\n\\underline{r}eflecting \\underline{s}urface (STARS)-assisted systems have\nemerged to fill this gap by providing $ 360^{\\circ}$ wireless coverage. In\nparallel,\n  full-duplex (FD) communication offers a higher achievable rate through\nefficient spectrum utilization compared to the half-duplex (HD) counterpart.\nMoreover, two-way/bi-directional communications in an FD system can further\nenhance the system's spectral efficiency. Hence, in this paper, we propose a\nSTARS-enabled massive MIMO deployment in an FD two-way communication network\nfor highly efficient spectrum utilization, while covering the dead zones around\nthe STARS. This model enables simultaneous information exchange between\nmultiple nodes, while \\emph{potentially} doubling the spectral efficiency (SE).\nBy invoking the use-and-then-forget (UaTF) combining scheme, we derive a\nclosed-form expression for an achievable SE at each user of the system\nconsidering both uplink and downlink communications based on statistical\nchannel state information (CSI), while also accounting for imperfect CSI and\ncorrelated fading conditions. Moreover, we formulate an optimization problem to\nobtain an optimal passive beamforming matrix design at the STARS that maximizes\nthe sum achievable SE. The considered problem is non-convex and we propose a\nprovably-convergent low-complexity algorithm, termed as \\underline{pro}jected\n\\underline{gr}adient \\underline{a}scent \\underline{m}ethod (ProGrAM), to obtain\na stationary solution. Extensive numerical results are provided to establish\nthe performance superiority of the FD STARS-enabled system over the HD\nSTARS-enabled and FD conventional RIS (cRIS)-enabled counterparts, and also to\nshow the effect of different parameters of interest on the system performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11565v1",
    "published": "2025-02-17T08:54:33+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11564v1",
    "title": "Continuous Diffusion Model for Language Modeling",
    "authors": [
      "Jaehyeong Jo",
      "Sung Ju Hwang"
    ],
    "abstract": "Diffusion models have emerged as a promising alternative to autoregressive\nmodels in modeling discrete categorical data. Yet diffusion models that\ndirectly work on discrete data space do not fully exploit the power of\niterative refinement, as the signals are lost during the transition between\ndiscrete states. Existing continuous diffusion models for discrete data have\nlimited performance compared to discrete approaches, and the unclear link\nbetween them restricts the development of diffusion models for discrete data.\nIn this work, we propose a continuous diffusion model for language modeling\nthat incorporates the geometry of the underlying categorical distribution. We\nestablish a connection between the discrete diffusion and continuous flow on\nthe statistical manifold, and building on the analogy, we introduce a simple\ndesign for the diffusion process that generalizes previous discrete diffusion\nmodels. We further propose a simulation-free training framework based on radial\nsymmetry and a simple technique to address the high dimensionality of the\nmanifold. Comprehensive experiments on language modeling benchmarks and other\nmodalities show that our method outperforms existing discrete diffusion models\nand approaches the performance of autoregressive models. Codes available at\n\\href{https://github.com/harryjo97/RDLM}{https://github.com/harryjo97/RDLM}.",
    "pdf_url": "http://arxiv.org/pdf/2502.11564v1",
    "published": "2025-02-17T08:54:29+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11563v1",
    "title": "Leader and Follower: Interactive Motion Generation under Trajectory Constraints",
    "authors": [
      "Runqi Wang",
      "Caoyuan Ma",
      "Jian Zhao",
      "Hanrui Xu",
      "Dongfang Sun",
      "Haoyang Chen",
      "Lin Xiong",
      "Zheng Wang",
      "Xuelong Li"
    ],
    "abstract": "With the rapid advancement of game and film production, generating\ninteractive motion from texts has garnered significant attention due to its\npotential to revolutionize content creation processes. In many practical\napplications, there is a need to impose strict constraints on the motion range\nor trajectory of virtual characters. However, existing methods that rely solely\non textual input face substantial challenges in accurately capturing the user's\nintent, particularly in specifying the desired trajectory. As a result, the\ngenerated motions often lack plausibility and accuracy. Moreover, existing\ntrajectory - based methods for customized motion generation rely on retraining\nfor single - actor scenarios, which limits flexibility and adaptability to\ndifferent datasets, as well as interactivity in two-actor motions. To generate\ninteractive motion following specified trajectories, this paper decouples\ncomplex motion into a Leader - Follower dynamic, inspired by role allocation in\npartner dancing. Based on this framework, this paper explores the motion range\nrefinement process in interactive motion generation and proposes a\ntraining-free approach, integrating a Pace Controller and a Kinematic\nSynchronization Adapter. The framework enhances the ability of existing models\nto generate motion that adheres to trajectory by controlling the leader's\nmovement and correcting the follower's motion to align with the leader.\nExperimental results show that the proposed approach, by better leveraging\ntrajectory information, outperforms existing methods in both realism and\naccuracy.",
    "pdf_url": "http://arxiv.org/pdf/2502.11563v1",
    "published": "2025-02-17T08:52:45+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11562v1",
    "title": "Reinforced Information Retrieval",
    "authors": [
      "Chaofan Li",
      "Zheng Liu",
      "Jianlyv Chen",
      "Defu Lian",
      "Yingxia Shao"
    ],
    "abstract": "While retrieval techniques are widely used in practice, they still face\nsignificant challenges in cross-domain scenarios. Recently,\ngeneration-augmented methods have emerged as a promising solution to this\nproblem. These methods enhance raw queries by incorporating additional\ninformation from an LLM-based generator, facilitating more direct retrieval of\nrelevant documents. However, existing methods struggle with highly specialized\nsituations that require extensive domain expertise. To address this problem, we\npresent \\textbf{Reinforced-IR}, a novel approach that jointly adapts a\npre-trained retriever and generator for precise cross-domain retrieval. A key\ninnovation of Reinforced-IR is its \\textbf{Self-Boosting} framework, which\nenables retriever and generator to learn from each other's feedback.\nSpecifically, the generator is reinforced to generate query augmentations that\nenhance the retriever's performance, while the retriever is trained to better\ndiscriminate the relevant documents identified by the generator. This iterative\nprocess allows the end-to-end retrieval performance to be progressively\noptimized using an unlabeled corpus from the target domain. In our experiment,\nReinforced-IR outperforms existing domain adaptation methods by a large margin,\nleading to substantial improvements in retrieval quality across a wide range of\napplication scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.11562v1",
    "published": "2025-02-17T08:52:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2503.00011v1",
    "title": "Fluid Antenna Enabled Over-the-Air Federated Learning: Joint Optimization of Positioning, Beamforming, and User Selection",
    "authors": [
      "Yang Zhao",
      "Minrui Xu",
      "Ping Wang",
      "Dusit Niyato"
    ],
    "abstract": "Over-the-air (OTA) federated learning (FL) effectively utilizes communication\nbandwidth, yet it is vulnerable to errors during analog aggregation. While\nremoving users with unfavorable channel conditions can mitigate these errors,\nit also reduces the available local training data for FL, which in turn hinders\nthe convergence rate of the training process. To tackle this issue, we propose\nusing fluid antenna (FA) techniques to enhance the degrees of freedom within\nthe channel space, ultimately boosting the convergence speed of FL training.\nMoreover, we develop a novel approach that effectively coordinates uplink\nreceiver beamforming, user selection, and FA positioning to optimize the\nconvergence rate of OTA FL training in dynamic wireless environments. We\naddress this challenging stochastic optimization by reformulating it as a\nmixed-integer programming problem by utilizing the training loss upper bound.\nWe then introduce a penalty dual decomposition (PDD) method to solve the\nmixed-integer mixed programming problem. Experimental results indicate that\nincorporating FA techniques significantly accelerates the training convergence\nof FL and greatly surpasses conventional methods.",
    "pdf_url": "http://arxiv.org/pdf/2503.00011v1",
    "published": "2025-02-17T08:49:29+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11561v2",
    "title": "Resident fitness computation in linear time and other algorithmic aspects of interacting trajectories",
    "authors": [
      "Katalin Friedl",
      "ViktÃ³ria Nemkin",
      "AndrÃ¡s TÃ³biÃ¡s"
    ],
    "abstract": "The notion of a system of interacting trajectories was recently introduced by\nHermann, Gonz\\'alez Casanova, Soares dos Santos, T\\'obi\\'as and Wakolbinger.\nSuch a system of $[0,1]$-valued piecewise linear trajectories arises as a\nscaling limit of the system of logarithmic subpopulation sizes in a\npopulation-genetic model (more precisely, a Moran model) with mutation and\nselection. By definition, the resident fitness is initially 0 and afterwards it\nincreases by the ultimate slope of each trajectory that reaches height 1.\n  We show that although the interaction of $n$ trajectories may yield\n$\\Omega(n^2)$ slope changes in total, the resident fitness function can be\ncomputed algorithmically in $O(n)$ time. Our algorithm uses the so-called\ncontinued lines representation of the system of interacting trajectories. In\nthe special case of Poissonian interacting trajectories where the birth times\nof the trajectories form a Poisson process and the initial slopes are random\nand i.i.d., we provide a linear bound on the expected total number of slope\nchanges.",
    "pdf_url": "http://arxiv.org/pdf/2502.11561v2",
    "published": "2025-02-17T08:48:29+00:00",
    "categories": [
      "cs.DS",
      "math.PR",
      "68Q25, 68W40, 60K05, 92D15"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11560v1",
    "title": "A Survey of Automatic Prompt Engineering: An Optimization Perspective",
    "authors": [
      "Wenwu Li",
      "Xiangfeng Wang",
      "Wenhao Li",
      "Bo Jin"
    ],
    "abstract": "The rise of foundation models has shifted focus from resource-intensive\nfine-tuning to prompt engineering, a paradigm that steers model behavior\nthrough input design rather than weight updates. While manual prompt\nengineering faces limitations in scalability, adaptability, and cross-modal\nalignment, automated methods, spanning foundation model (FM) based\noptimization, evolutionary methods, gradient-based optimization, and\nreinforcement learning, offer promising solutions. Existing surveys, however,\nremain fragmented across modalities and methodologies. This paper presents the\nfirst comprehensive survey on automated prompt engineering through a unified\noptimization-theoretic lens. We formalize prompt optimization as a maximization\nproblem over discrete, continuous, and hybrid prompt spaces, systematically\norganizing methods by their optimization variables (instructions, soft prompts,\nexemplars), task-specific objectives, and computational frameworks. By bridging\ntheoretical formulation with practical implementations across text, vision, and\nmultimodal domains, this survey establishes a foundational framework for both\nresearchers and practitioners, while highlighting underexplored frontiers in\nconstrained optimization and agent-oriented prompt design.",
    "pdf_url": "http://arxiv.org/pdf/2502.11560v1",
    "published": "2025-02-17T08:48:07+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11559v1",
    "title": "Auto-Search and Refinement: An Automated Framework for Gender Bias Mitigation in Large Language Models",
    "authors": [
      "Yue Xu",
      "Chengyan Fu",
      "Li Xiong",
      "Sibei Yang",
      "Wenjie Wang"
    ],
    "abstract": "Pre-training large language models (LLMs) on vast text corpora enhances\nnatural language processing capabilities but risks encoding social biases,\nparticularly gender bias. While parameter-modification methods like fine-tuning\nmitigate bias, they are resource-intensive, unsuitable for closed-source\nmodels, and lack adaptability to evolving societal norms. Instruction-based\napproaches offer flexibility but often compromise task performance. To address\nthese limitations, we propose $\\textit{FaIRMaker}$, an automated and\nmodel-independent framework that employs an $\\textbf{auto-search and\nrefinement}$ paradigm to adaptively generate Fairwords, which act as\ninstructions integrated into input queries to reduce gender bias and enhance\nresponse quality. Extensive experiments demonstrate that $\\textit{FaIRMaker}$\nautomatically searches for and dynamically refines Fairwords, effectively\nmitigating gender bias while preserving task integrity and ensuring\ncompatibility with both API-based and open-source LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11559v1",
    "published": "2025-02-17T08:44:04+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11558v2",
    "title": "An alternative formulation of infra-red counterterms",
    "authors": [
      "I. Jack"
    ],
    "abstract": "We present an alternative procedure for defining infra-red counterterms\nwithin dimensional regularisation for use in the $R^*$ procedure. The\ncounterterms are given by simple closed expressions, and lead to the standard\nMSbar UV counterterms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11558v2",
    "published": "2025-02-17T08:43:59+00:00",
    "categories": [
      "hep-th",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.11557v1",
    "title": "Fast Maximum Common Subgraph Search: A Redundancy-Reduced Backtracking Approach",
    "authors": [
      "Kaiqiang Yu",
      "Kaixin Wang",
      "Cheng Long",
      "Laks Lakshmanan",
      "Reynold Cheng"
    ],
    "abstract": "Given two input graphs, finding the largest subgraph that occurs in both,\ni.e., finding the maximum common subgraph, is a fundamental operator for\nevaluating the similarity between two graphs in graph data analysis. Existing\nworks for solving the problem are of either theoretical or practical interest,\nbut not both. Specifically, the algorithms with a theoretical guarantee on the\nrunning time are known to be not practically efficient; algorithms following\nthe recently proposed backtracking framework called McSplit, run fast in\npractice but do not have any theoretical guarantees. In this paper, we propose\na new backtracking algorithm called RRSplit, which at once achieves better\npractical efficiency and provides a non-trivial theoretical guarantee on the\nworst-case running time. To achieve the former, we develop a series of\nreductions and upper bounds for reducing redundant computations, i.e., the time\nfor exploring some unpromising branches of exploration that hold no maximum\ncommon subgraph. To achieve the latter, we formally prove that RRSplit incurs a\nworst-case time complexity which matches the best-known complexity for the\nproblem. Finally, we conduct extensive experiments on four benchmark graph\ncollections, and the results demonstrate that our algorithm outperforms the\npractical state-of-the-art by several orders of magnitude.",
    "pdf_url": "http://arxiv.org/pdf/2502.11557v1",
    "published": "2025-02-17T08:43:49+00:00",
    "categories": [
      "cs.DB",
      "cs.DS"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2502.11556v4",
    "title": "Lyapunov-like Stability Inequality with an Asymmetric Matrix and Application to Suboptimal LQ Control Design",
    "authors": [
      "Avinash Kumar"
    ],
    "abstract": "The Lyapunov inequality is an indispensable tool for stability analysis in\nthe linear control theory. This work proposes a new variant of this inequality\nwhere-in the constituent matrix is allowed to be asymmetric. After developing\nthe stability conditions based on the proposed inequality for a class of linear\nsystems, we utilize these conditions to derive new results for the suboptimal\nlinear quadratic control problem where we characterize the cost of the\nstabilizing controllers. We also demonstrate, by a numerical example, that the\nproposed results can be easily molded for the structured suboptimal consensus\nprotocol design for multi-agent system where we also see that the asymmetry\ncondition of the design matrix turns up inherently.",
    "pdf_url": "http://arxiv.org/pdf/2502.11556v4",
    "published": "2025-02-17T08:42:58+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11555v1",
    "title": "Equilibrate RLHF: Towards Balancing Helpfulness-Safety Trade-off in Large Language Models",
    "authors": [
      "Yingshui Tan",
      "Yilei Jiang",
      "Yanshi Li",
      "Jiaheng Liu",
      "Xingyuan Bu",
      "Wenbo Su",
      "Xiangyu Yue",
      "Xiaoyong Zhu",
      "Bo Zheng"
    ],
    "abstract": "Fine-tuning large language models (LLMs) based on human preferences, commonly\nachieved through reinforcement learning from human feedback (RLHF), has been\neffective in improving their performance. However, maintaining LLM safety\nthroughout the fine-tuning process remains a significant challenge, as\nresolving conflicts between safety and helpfulness can be non-trivial.\nTypically, the safety alignment of LLM is trained on data with safety-related\ncategories. However, our experiments find that naively increasing the scale of\nsafety training data usually leads the LLMs to an ``overly safe'' state rather\nthan a ``truly safe'' state, boosting the refusal rate through extensive\nsafety-aligned data without genuinely understanding the requirements for safe\nresponses. Such an approach can inadvertently diminish the models' helpfulness.\nTo understand the phenomenon, we first investigate the role of safety data by\ncategorizing them into three different groups, and observe that each group\nbehaves differently as training data scales up. To boost the balance between\nsafety and helpfulness, we propose an Equilibrate RLHF framework including a\nFine-grained Data-centric (FDC) approach that achieves better safety alignment\neven with fewer training data, and an Adaptive Message-wise Alignment (AMA)\napproach, which selectively highlight the key segments through a gradient\nmasking strategy. Extensive experimental results demonstrate that our approach\nsignificantly enhances the safety alignment of LLMs while balancing safety and\nhelpfulness.",
    "pdf_url": "http://arxiv.org/pdf/2502.11555v1",
    "published": "2025-02-17T08:40:30+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12216v1",
    "title": "Tactic: Adaptive Sparse Attention with Clustering and Distribution Fitting for Long-Context LLMs",
    "authors": [
      "Kan Zhu",
      "Tian Tang",
      "Qinyu Xu",
      "Yile Gu",
      "Zhichen Zeng",
      "Rohan Kadekodi",
      "Liangyu Zhao",
      "Ang Li",
      "Arvind Krishnamurthy",
      "Baris Kasikci"
    ],
    "abstract": "Long-context models are essential for many applications but face\ninefficiencies in loading large KV caches during decoding. Prior methods\nenforce fixed token budgets for sparse attention, assuming a set number of\ntokens can approximate full attention. However, these methods overlook\nvariations in the importance of attention across heads, layers, and contexts.\nTo address these limitations, we propose Tactic, a sparsity-adaptive and\ncalibration-free sparse attention mechanism that dynamically selects tokens\nbased on their cumulative attention scores rather than a fixed token budget. By\nsetting a target fraction of total attention scores, Tactic ensures that token\nselection naturally adapts to variations in attention sparsity. To efficiently\napproximate this selection, Tactic leverages clustering-based sorting and\ndistribution fitting, allowing it to accurately estimate token importance with\nminimal computational overhead. We show that Tactic outperforms existing sparse\nattention algorithms, achieving superior accuracy and up to 7.29x decode\nattention speedup. This improvement translates to an overall 1.58x end-to-end\ninference speedup, making Tactic a practical and effective solution for\nlong-context LLM inference in accuracy-sensitive applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.12216v1",
    "published": "2025-02-17T08:39:43+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11554v1",
    "title": "Toward Metaphor-Fluid Conversation Design for Voice User Interfaces",
    "authors": [
      "Smit Desai",
      "Jessie Chin",
      "Dakuo Wang",
      "Benjamin Cowan",
      "Michael Twidale"
    ],
    "abstract": "Metaphors play a critical role in shaping user experiences with Voice User\nInterfaces (VUIs), yet existing designs often rely on static, human-centric\nmetaphors that fail to adapt to diverse contexts and user needs. This paper\nintroduces Metaphor-Fluid Design, a novel approach that dynamically adjusts\nmetaphorical representations based on conversational use-contexts. We compare\nthis approach to a Default VUI, which characterizes the present implementation\nof commercial VUIs commonly designed around the persona of an assistant,\noffering a uniform interaction style across contexts. In Study 1 (N=130),\nmetaphors were mapped to four key use-contexts-commands, information seeking,\nsociality, and error recovery-along the dimensions of formality and hierarchy,\nrevealing distinct preferences for task-specific metaphorical designs. Study 2\n(N=91) evaluates a Metaphor-Fluid VUI against a Default VUI, showing that the\nMetaphor-Fluid VUI enhances perceived intention to adopt, enjoyment, and\nlikability by aligning better with user expectations for different contexts.\nHowever, individual differences in metaphor preferences highlight the need for\npersonalization. These findings challenge the one-size-fits-all paradigm of VUI\ndesign and demonstrate the potential of Metaphor-Fluid Design to create more\nadaptive and engaging human-AI interactions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11554v1",
    "published": "2025-02-17T08:36:12+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.ET"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11553v1",
    "title": "Multiband dispersion and warped vortices of strongly-interacting photons",
    "authors": [
      "Bankim Chandra Das",
      "Dmytro Kiselov",
      "Lee Drori",
      "Ariel Nakav",
      "Alexander Poddubny",
      "Ofer Firstenberg"
    ],
    "abstract": "We study quantum correlations between interacting photons realized through\nco-propagating Rydberg polaritons. We show that the evolution of the $n$-photon\nwavefunction is governed by a multiband dispersion featuring one massive mode\nand $n-1$ degenerate modes, such as two Dirac cones for $n=3$. The band\nstructure exhibits an $n$-fold rotational symmetry, including an $n$-fold\nwarped light cone, in contrast to the single-band, parabolic approximation\noften assumed for interacting polaritons. For three photons, the dispersion\nbreaks the symmetry between a photon pair propagating ahead versus behind a\nsingle photon. We confirm these findings experimentally by measuring the\nthree-photon phase and intensity correlation functions, revealing trigonal\nwarping of the quantum vortex-ring generated by the three-photon interactions.\nOur analytical results are supported by rigorous numerical modeling that fully\naccounts for the photon propagation before, inside, and after the finite atomic\nmedium. These findings advance the understanding of multi-photon interactions\nand the development of future multi-photon control tools.",
    "pdf_url": "http://arxiv.org/pdf/2502.11553v1",
    "published": "2025-02-17T08:35:10+00:00",
    "categories": [
      "quant-ph",
      "physics.atom-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11552v2",
    "title": "The JCMT BISTRO Survey: Magnetic Fields Align with Orbital Structure in the Galactic Center",
    "authors": [
      "Janik Karoly",
      "Derek Ward-Thompson",
      "Kate Pattle",
      "Steven N. Longmore",
      "James Di Francesco",
      "Anthony Whitworth",
      "Doug Johnstone",
      "Sarah Sadavoy",
      "Patrick M. Koch",
      "Meng-Zhe Yang",
      "Ray Furuya",
      "Xing Lu",
      "Motohide Tamura",
      "Victor Debattista",
      "David Eden",
      "Jihye Hwang",
      "Frederick Poidevin",
      "Bijas Najimudeen",
      "Szu-Ting Chen",
      "Eun Jung Chung",
      "Simon Coude",
      "Sheng-Jun Lin",
      "Yasuo Doi",
      "Takashi Onaka",
      "Lapo Fanciullo",
      "Tie Liu",
      "Guangxing Li",
      "Pierre Bastien",
      "Tetsuo Hasegawa",
      "Woojin Kwon",
      "Shih-Ping Lai",
      "Keping Qiu"
    ],
    "abstract": "We present the magnetic field in the dense material of the Central Molecular\nZone (CMZ) of the Milky Way, traced in 850 $\\mu$m polarized dust emission as\npart of the James Clerk Maxwell Telescope (JCMT) B-fields In STar-forming\nRegion Observations (BISTRO) Survey. We observe a highly ordered magnetic field\nacross the CMZ between Sgr B2 and Sgr C, which is strongly preferentially\naligned with the orbital gas flows within the clouds of the CMZ. We find that\nthe observed relative orientations are non-random at a $>$99% confidence level\nand are consistent with models in which the magnetic field vectors are aligned\nwithin 30$^{o}$ to the gas flows in 3D. The deviations from aligned magnetic\nfields are most prominent at positive Galactic longitudes, where the CMZ clouds\nare more massive, denser, and more actively forming stars. Our observed\nstrongly preferentially parallel magnetic field morphology leads us to\nhypothesize that in the absence of star formation, the magnetic field in the\nCMZ is entrained in the orbital gas flows around Sgr A$^{*}$, while\ngravitational collapse and feedback in star-forming regions can locally reorder\nthe field. This magnetic field behavior is similar to that observed in the CMZ\nof the nuclear starburst galaxy NGC 253. This suggests that despite its current\nlow star formation rate, the CMZ of the Milky Way is analogous to those of more\ndistant, actively star-forming, galaxies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11552v2",
    "published": "2025-02-17T08:34:34+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11551v2",
    "title": "A note on the Howe Duality conjecture for symplectic-orthogonal and unitary pairs",
    "authors": [
      "Johannes Droschl"
    ],
    "abstract": "In this short note we expand on recent results on the degenerate principle\nseries $I(s,\\chi)$ of classical groups associated to $s\\in \\mathbb{C}$ and a\nquadratic character $\\chi$. In particular, we strengthen the result for $s\\in\n\\mathbb{R}_{\\ge 0}$, which allows us to give as a corollary a new proof of the\nHowe duality conjecture for symplectic-orthogonal and unitary pairs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11551v2",
    "published": "2025-02-17T08:31:33+00:00",
    "categories": [
      "math.RT",
      "22E46, 22E50"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11550v1",
    "title": "Trinity: A Scalable and Forward-Secure DSSE for Spatio-Temporal Range Query",
    "authors": [
      "Zhijun Li",
      "Kuizhi Liu",
      "Minghui Xu",
      "Xiangyu Wang",
      "Yinbin Miao",
      "Jianfeng Ma",
      "Xiuzhen Cheng"
    ],
    "abstract": "Cloud-based outsourced Location-based services have profound impacts on\nvarious aspects of people's lives but bring security concerns. Existing\nspatio-temporal data secure retrieval schemes have significant shortcomings\nregarding dynamic updates, either compromising privacy through leakage during\nupdates (forward insecurity) or incurring excessively high update costs that\nhinder practical application. Under these circumstances, we first propose a\nbasic filter-based spatio-temporal range query scheme \\TrinityI that supports\nlow-cost dynamic updates and automatic expansion. Furthermore, to improve\nsecurity, reduce storage cost, and false positives, we propose a forward secure\nand verifiable scheme \\TrinityII that simultaneously minimizes storage\noverhead. A formal security analysis proves that \\TrinityI and \\TrinityII are\nIndistinguishable under Selective Chosen-Plaintext Attack (IND-SCPA). Finally,\nextensive experiments demonstrate that our design \\TrinityII significantly\nreduces storage requirements by 80\\%, enables data retrieval at the 1\nmillion-record level in just 0.01 seconds, and achieves 10 $\\times$ update\nefficiency than state-of-art.",
    "pdf_url": "http://arxiv.org/pdf/2502.11550v1",
    "published": "2025-02-17T08:30:42+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11549v3",
    "title": "A Radio-Frequency Emitter Design for the Low-Frequency Regime in Atomic Experiments",
    "authors": [
      "Yudong Wei",
      "Zhongshu Hu",
      "Yajing Guo",
      "Zhentian Qian",
      "Shengjie Jin",
      "Xuzong Chen",
      "Xiong-jun Liu"
    ],
    "abstract": "Radio-frequency (RF) control is a key technique in cold atom experiments. We\npresent a compact and efficient RF circuit based on a capacitive transformer\nnetwork, where a low-frequency coil operating up to 30MHz serves as both an\nintrinsic inductor and a power-sharing element. The design enables high current\ndelivery and flexible impedance matching across a wide frequency range. We\nintegrate both broadband and narrowband RF networks into a unified\nconfiguration that overcomes the geometric constraints imposed by the metallic\nchamber. In evaporative cooling, the broadband network allows a reduction of\nthe applied RF input power from 14.7dBW to -3.5dBW, owing to its non-zero coil\ncurrent even at ultra-low frequencies. This feature enables the Bose-Fermi\nmixture to be cooled below 10{\\mu}K. In a Landau-Zener protocol, the coil\ndriven by the narrowband network transfers 80% of rubidium atoms from |F = 2,mF\n= 2> to |2,-2> in 1 millisecond, achieving a Rabi frequency of approximately 9\nkHz at an input power of 0.1dBW.",
    "pdf_url": "http://arxiv.org/pdf/2502.11549v3",
    "published": "2025-02-17T08:30:38+00:00",
    "categories": [
      "physics.atom-ph",
      "cond-mat.quant-gas"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11548v1",
    "title": "Dijkgraaf-Witten invariant in topological $K$-theory",
    "authors": [
      "Koki Yanagida"
    ],
    "abstract": "Given a finite group $G$, we define a new invariant of odd-dimensional\noriented closed manifolds and call it the KDW invariant. This invariant is a\nDijkgraaf--Witten invariant in terms of $K$-theory. In this paper, we compute\nthe invariant of the Brieskorn homology spheres with\n$G=\\mathrm{PSL}_2(\\mathbb{F}_p)$. We should remark that, in this computational\nresult, the fundamental groups of the Brieskorn homology spheres and\n$\\mathrm{PSL}_2(\\mathbb{F}_p)$ are not nilpotent.",
    "pdf_url": "http://arxiv.org/pdf/2502.11548v1",
    "published": "2025-02-17T08:29:39+00:00",
    "categories": [
      "math.GT",
      "55N15"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11547v1",
    "title": "Contraction Dynamics in Heterogeneous Spatial Environments",
    "authors": [
      "Carlos Barajas",
      "Jean-Jacques Slotine",
      "Domitilla Del Vecchio"
    ],
    "abstract": "Understanding the asymptotic behavior of reaction-diffusion (RD) systems is\ncrucial for modeling processes ranging from species coexistence in ecology to\nbiochemical interactions within cells. In this work, we analyze RD systems in\nwhich diffusion is modeled using the $\\theta$-diffusion framework, while the\nreaction dynamics are spatially varying. We demonstrate that spatial\nheterogeneity affects the asymptotic behavior of such systems. Using\ncontraction theory, we derive conditions that guarantee the exponential\nconvergence of system trajectories, regardless of initial conditions. These\nconditions explicitly account for the influence of spatial heterogeneity in\nboth the diffusion and reaction terms. As an application, we study a\nbiochemical system and derive the quasi-steady-state (QSS) approximation,\nillustrating how spatial heterogeneity modulates the effective binding rates of\nbiomolecular species.",
    "pdf_url": "http://arxiv.org/pdf/2502.11547v1",
    "published": "2025-02-17T08:29:29+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11546v2",
    "title": "DCAD-2000: A Multilingual Dataset across 2000+ Languages with Data Cleaning as Anomaly Detection",
    "authors": [
      "Yingli Shen",
      "Wen Lai",
      "Shuo Wang",
      "Xueren Zhang",
      "Kangyang Luo",
      "Alexander Fraser",
      "Maosong Sun"
    ],
    "abstract": "The rapid development of multilingual large language models (LLMs) highlights\nthe need for high-quality, diverse, and clean multilingual datasets. In this\npaper, we introduce DCAD-2000 (Data Cleaning as Anomaly Detection), a\nlarge-scale multilingual corpus built using newly extracted Common Crawl data\nand existing multilingual datasets. DCAD-2000 includes over 2,282 languages,\n46.72TB of data, and 8.63 billion documents, spanning 155 high- and\nmedium-resource languages and 159 writing scripts. To overcome the limitations\nof current data cleaning methods, which rely on manual heuristic thresholds, we\npropose reframing data cleaning as an anomaly detection task. This dynamic\nfiltering approach significantly enhances data quality by identifying and\nremoving noisy or anomalous content. We evaluate the quality of DCAD-2000 on\nthe FineTask benchmark, demonstrating substantial improvements in multilingual\ndataset quality and task performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11546v2",
    "published": "2025-02-17T08:28:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11545v1",
    "title": "A Search for Low-frequency Radio Pulses from Long Gamma-ray Bursts with the Murchison Widefield Array",
    "authors": [
      "Fan Xu",
      "G. E. Anderson",
      "Jun Tian",
      "B. W. Meyers",
      "S. J. Tingay",
      "Yong-Feng Huang",
      "Zi-Teng Wang",
      "B. Venville",
      "C. P. Lee",
      "A. Rowlinson",
      "P. Hancock",
      "A. Williams",
      "M. Sokolowski"
    ],
    "abstract": "It has been proposed that coherent radio emission could be emitted during or\nshortly following a gamma-ray burst (GRB). Here we present a low-frequency\n($170-200$ MHz) search for radio pulses associated with long-duration GRBs\nusing the Murchison Widefield Array (MWA). The MWA, with its rapid-response\nsystem, is capable of performing GRB follow-up observations within\napproximately $30$ seconds. Our single pulse search, with temporal and spectral\nresolutions of $100\\ \\mu$s and $10$ kHz, covers dispersion measures up to\n$5000$ pc cm$^{-3}$. Two single pulse candidates are identified with\nsignificance greater than $6\\sigma$, surviving a friends-of-friends analysis.\nWe rule out random fluctuations as their origin at a confidence level of $97\\%$\n($2.2\\sigma$). We caution that radio frequency interference from digital TV\n(DTV) is most likely the origin of these pulses since the DTV frequency bands\nalmost cover the entire observing frequency band. If they are astrophysical\nsignals, we estimate the peak flux densities for our pulse candidates of\n$3.6\\pm0.6$ Jy and $10.5\\pm1.5$ Jy, with corresponding fluences of $431\\pm74$\nJy ms and $211\\pm37$ Jy ms, respectively. Based on these observations and the\nassumption of a magnetar origin for the pulse, we constrain the radio emission\nefficiency as $\\epsilon_{\\rm{r}}\\sim10^{-3}$ for both candidates, which is\nconsistent with pulsar observations. Our results highlight the promising\npotential of new-generation radio telescopes like the MWA to probe the central\nengines of GRBs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11545v1",
    "published": "2025-02-17T08:26:09+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11544v1",
    "title": "Evaluating o1-Like LLMs: Unlocking Reasoning for Translation through Comprehensive Analysis",
    "authors": [
      "Andong Chen",
      "Yuchen Song",
      "Wenxin Zhu",
      "Kehai Chen",
      "Muyun Yang",
      "Tiejun Zhao",
      "Min zhang"
    ],
    "abstract": "The o1-Like LLMs are transforming AI by simulating human cognitive processes,\nbut their performance in multilingual machine translation (MMT) remains\nunderexplored. This study examines: (1) how o1-Like LLMs perform in MMT tasks\nand (2) what factors influence their translation quality. We evaluate multiple\no1-Like LLMs and compare them with traditional models like ChatGPT and GPT-4o.\nResults show that o1-Like LLMs establish new multilingual translation\nbenchmarks, with DeepSeek-R1 surpassing GPT-4o in contextless tasks. They\ndemonstrate strengths in historical and cultural translation but exhibit a\ntendency for rambling issues in Chinese-centric outputs. Further analysis\nreveals three key insights: (1) High inference costs and slower processing\nspeeds make complex translation tasks more resource-intensive. (2) Translation\nquality improves with model size, enhancing commonsense reasoning and cultural\ntranslation. (3) The temperature parameter significantly impacts output\nquality-lower temperatures yield more stable and accurate translations, while\nhigher temperatures reduce coherence and precision.",
    "pdf_url": "http://arxiv.org/pdf/2502.11544v1",
    "published": "2025-02-17T08:23:46+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11543v2",
    "title": "Computational Study of Magnetic Behaviour in Ni-Adsorbed Nb2C-OF MXene using Density Functional Theory",
    "authors": [
      "Zarah Khan",
      "Saleem Ayaz Khan",
      "Ayesha Zaheer",
      "Syed Rizwan"
    ],
    "abstract": "Magnetic 2D materials have achieved significantly consideration owing to\ntheir encouraging applications. A variation of these 2D materials by occurrence\nof defects, by the transition-metal doping or adsorption or by the surface\nfunctionalization can initiate both the spin-polarization and magnetic\nproperties in these materials. Density functional theory (DFT) is used to\ndetermine the electric, magnetic properties along with the electronic\nstructures and stability of synthesized two-dimensional materials. This work\ndescribes the magnetic properties of Ni-ad-Nb2C-OF MXene. The study focuses on\nthe computational approach based first principal calculation providing insight\nonto the magnetic properties of adsorbed compound and comparing it with\npristine Nb2C-OF MXene. The pristine Nb2C-OF and Ni-ad-Nb2C-OF structures are\nsimulated and optimized using Wien2k software. Using exchange-correlational\nfunctionals; spin-GGA and spin-GGA+U (for Nickel U= 6eV), Ni-ad-Nb2C-OF\nelectronic band structure is found to be metallic having magnetic moment\ncalculated +1.01516{\\mu}_\\b{eta} showing its non-superconducting and\nferromagnetic behaviour. Owing to this magnetic nature, this 2D compound can be\nused for new upcoming applications such as spintronics and nano magnetic data\nstorage devices.",
    "pdf_url": "http://arxiv.org/pdf/2502.11543v2",
    "published": "2025-02-17T08:16:08+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11542v1",
    "title": "A note on optimization of the second positive Neumann eigenvalue for parallelograms",
    "authors": [
      "Vladimir Lotoreichik",
      "Jonathan Rohleder"
    ],
    "abstract": "It has recently been conjectured by Bogosel, Henrot, and Michetti that the\nsecond positive eigenvalue of the Neumann Laplacian is maximized, among all\nplanar convex domains of fixed perimeter, by the rectangle with one edge length\nequal to twice the other. In this note we prove that this conjecture is true\nwithin the class of parallelogram domains.",
    "pdf_url": "http://arxiv.org/pdf/2502.11542v1",
    "published": "2025-02-17T08:14:31+00:00",
    "categories": [
      "math.SP",
      "math-ph",
      "math.AP",
      "math.MP"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11541v3",
    "title": "MuSC: Improving Complex Instruction Following with Multi-granularity Self-Contrastive Training",
    "authors": [
      "Hui Huang",
      "Jiaheng Liu",
      "Yancheng He",
      "Shilong Li",
      "Bing Xu",
      "Conghui Zhu",
      "Muyun Yang",
      "Tiejun Zhao"
    ],
    "abstract": "Complex instruction-following with elaborate constraints is imperative for\nLarge Language Models (LLMs). While existing methods have constructed data for\ncomplex instruction alignment, they all rely on a more advanced model,\nespecially GPT-4, limiting their application. In this paper, we propose a\nMulti-granularity Self-Contrastive Training (MuSC) framework, to improve the\ncomplex instruction alignment without relying on a stronger model. Our method\nis conducted on both coarse and fine granularity. On coarse-granularity, we\nconstruct constraint-aware preference data based on instruction decomposition\nand recombination. On fine-granularity, we perform token-aware preference\noptimization with dynamic token-level supervision. Our method is evaluated on\nopen-sourced models, and experiment results show our method achieves\nsignificant improvement on both complex and general instruction-following\nbenchmarks, surpassing previous self-alignment methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.11541v3",
    "published": "2025-02-17T08:12:49+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.15779v2",
    "title": "Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer",
    "authors": [
      "Euntae Choi",
      "Sumin Song",
      "Woosang Lim",
      "Sungjoo Yoo"
    ],
    "abstract": "We propose Rotate, Clip, and Partition (RCP), a quantization-aware training\n(QAT) approach that first realizes extreme compression of LLMs with\nW2A4KV4(2-bit weight, 4-bit activation, and 4-bit KV cache) configuration. RCP\nintegrates recent rotation techniques with a novel non-uniform weight quantizer\ndesign, by quantitatively analyzing the impact of random rotation on 2-bit\nweight quantization. Our weight quantizer features Learnable Direct\nPartitioning (LDP), which introduces learnable parameters to directly learn\nnon-uniform intervals jointly with LLM weights. We also present a specialized\nGPU kernel that supports GEMV on non-uniform W2A4. Experiments show that RCP\ncan compress LLaMA-2-7B to W2A4KV4 with a loss of only 2.84 WikiText2 ppl and\n5.29 times reduced memory footprint. Furthermore, RCP can quantize challenging\nmobile-targeted LLaMA-3.2 models and domain-specific WizardCoder-7B and\nMetaMath-7B with no critical problems such as convergence failure and\nrepetition. Code is available at https://github.com/ songsm921/RCP.",
    "pdf_url": "http://arxiv.org/pdf/2502.15779v2",
    "published": "2025-02-17T08:12:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2503.05719v1",
    "title": "Investigating Role of Personal Factors in Shaping Responses to Active Shooter Incident using Machine Learning",
    "authors": [
      "Ruying Liu",
      "BurÃ§in Becerik-Gerber",
      "Gale M. Lucas"
    ],
    "abstract": "This study bridges the knowledge gap on how personal factors affect building\noccupants' responses in active shooter situations by applying interpretable\nmachine learning methods to data from 107 participants. The personal factors\nstudied are training methods, prior training experience, sense of direction,\nand gender. The response performance measurements consist of decisions (run,\nhide, multiple), vulnerability (corresponding to the time a participant is\nvisible to a shooter), and pre-evacuation time. The results indicate that the\npropensity to run significantly determines overall response strategies,\novershadowing vulnerability, and pre-evacuation time. The training method is a\ncritical factor where VR-based training leads to better responses than\nvideo-based training. A better sense of direction and previous training\nexperience are correlated with a greater propensity to run and less\nvulnerability. Gender slightly influences decisions and vulnerability but\nsignificantly impacts pre-evacuation time, with females evacuating slower,\npotentially due to higher risk perception. This study underscores the\nimportance of personal factors in shaping responses to active shooter\nincidents.",
    "pdf_url": "http://arxiv.org/pdf/2503.05719v1",
    "published": "2025-02-17T08:10:56+00:00",
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11540v1",
    "title": "Statistical and Deterministic RCS Characterization for ISAC Channel Modeling",
    "authors": [
      "Ali Waqar Azim",
      "Ahmad Bazzi",
      "Roberto Bomfin",
      "Nikolaos Giakoumidis",
      "Theodore S. Rappaport",
      "Marwa Chafii"
    ],
    "abstract": "In this study, we perform a statistical analysis of the radar cross section\n(RCS) for various test targets in an indoor factory at \\(25\\)-\\(28\\) GHz, with\nthe goal of formulating parameters that may be used for target identification\nand other sensing applications for future wireless systems. The analysis is\nconducted based on measurements in monostatic and bistatic configurations for\nbistatic angles of \\(20^\\circ\\), \\(40^\\circ\\), and \\(60^\\circ\\), which are\nfunctions of transmitter-receiver (T-R) and target positions, via accurate\n\\(3\\)dB beamwidth of \\(10^\\circ\\) in both azimuth and elevation planes. The\ntest targets include unmanned aerial vehicles, an autonomous mobile robot, and\na robotic arm. We utilize parametric statistical distributions to fit the\nmeasured RCS data. The analysis reveals that the \\textit{lognormal and gamma\ndistributions} are effective in modeling the RCS of the test targets over\ndifferent reflecting points of the target itself, i.e. when target is in\nmotion. Additionally, we provide a framework for evaluating the deterministic\nbistatic RCS of a rectangular sheet of laminated wood, due to its widespread\nuse in indoor hotspot environments. Novel deterministic and statistical RCS\nmodels are evaluated, incorporating dependencies on the bistatic angle, T-R\ndistance (\\(2\\)m -\\(10\\)m) and the target. The results demonstrate that some\nproposed RCS models accurately fit the measured data, highlighting their\napplicability in bistatic configurations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11540v1",
    "published": "2025-02-17T08:10:09+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11539v1",
    "title": "Fluctuation-dissipation theorems for multi-phase flow with memory in porous media",
    "authors": [
      "Dick Bedeaux",
      "Signe Kjelstrup",
      "Steffen Berg",
      "Umar Alfazazi",
      "Ryan T. Armstrong"
    ],
    "abstract": "Recent works have reported on the collective behavior of multiphase systems\nunder fractional flow. Such behavior has been linked to pressure and/or flux\nfluctuations under stationary flow conditions that occur over a broad range of\nresonance frequencies and associated relaxation times. However, there currently\nexists no theoretical development to deal with such phenomena. The aim of this\npaper is to develop a fundamental theory that can describe such behavior.\nFluctuation-dissipation theorems for the case with memory are formulated,\nproviding a new route to obtain frequency-dependent porous media permeability.\n  We propose that multiphase flow systems can be explained by a multipeak\nLorentzian memory function and provide supporting experimental data from the\nflow of decane and water in a porous medium made of glass beads. Our\nfluctuation dissipation theorems provide information on different types of\nrelaxation phenomena and resonance frequencies that occur during fractional\nflow. We show, using experimental data, that Green-Kubo-like expressions can be\nformulated for two-phase fluid flow driven by a constant pressure drop. The\nresulting autocorrelation functions, or rather their Fourier transforms,\nexhibit multiple Lorentzian peak shapes. Resonances are similar to those of\nelectric conductance. The analysis offers a new route to steady-state relative\npermeability measurements, including information on the relaxation times and\nresonance regimes that exist during fractional flow. Overall, the theory\npresented and supported by fractional flow experiments provides a rich set of\npossible directions for future developments that could fundamentally change the\nway multiphase flow systems are understood and studied.",
    "pdf_url": "http://arxiv.org/pdf/2502.11539v1",
    "published": "2025-02-17T08:08:38+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11538v2",
    "title": "Efficient malicious information detection method based on set partitioning for large-scale Internet of Things",
    "authors": [
      "Yuhan Suo",
      "Runqi Chai",
      "Kaiyuan Chen",
      "Senchun Chai",
      "Wannian Liang",
      "Yuanqing Xia"
    ],
    "abstract": "With the large-scale integration of Internet of Things (IoT) into enterprise\ninformation management systems, organizations are pursuing digital\ntransformation that hinges on real-time data insights-and yet face escalating\nsecurity and governance risks. Detecting and responding to threats at scale\nwithout impairing system efficiency has therefore become a critical\ninformation-management and decision-support challenge for today's executives.\nThis paper develops a distributed, gain-based anomaly-detection framework\ntailored to IoT-enabled enterprise systems, underpinned by an optimized\nsensor-subset partitioning strategy. Starting from the perspective of set\npartitioning strategies, this study analyzes the key factor that contributes to\nthe performance differences between distributed and centralized algorithms. By\nexamining the gain mutual influence of sensor subsets, an optimal set\npartitioning strategy is designed to minimize inter-subset mutual influence\nwhile enhancing intra-subset correlation. To further reduce the computational\ncost of gain updates, a suboptimal partitioning strategy based on Grassmann\ndistance is proposed, improving the efficiency of selecting suspicious sensors.\nTheoretical analysis demonstrates that this approach effectively reduces the\ncomputational cost of gain updates while maintaining detection performance.\nFinally, simulation results validate the effectiveness of the proposed method\nin enhancing attack detection performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11538v2",
    "published": "2025-02-17T08:07:55+00:00",
    "categories": [
      "cs.DC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11537v3",
    "title": "Uncovering Untapped Potential in Sample-Efficient World Model Agents",
    "authors": [
      "Lior Cohen",
      "Kaixin Wang",
      "Bingyi Kang",
      "Uri Gadot",
      "Shie Mannor"
    ],
    "abstract": "World model (WM) agents enable sample-efficient reinforcement learning by\nlearning policies entirely from simulated experience. However, existing\ntoken-based world models (TBWMs) are limited to visual inputs and discrete\nactions, restricting their adoption and applicability. Moreover, although both\nintrinsic motivation and prioritized WM replay have shown promise in improving\nWM performance and generalization, they remain underexplored in this setting,\nparticularly in combination. We introduce Simulus, a highly modular TBWM agent\nthat integrates (1) a modular multi-modality tokenization framework, (2)\nintrinsic motivation, (3) prioritized WM replay, and (4)\nregression-as-classification for reward and return prediction. Simulus achieves\nstate-of-the-art sample efficiency for planning-free WMs across three diverse\nbenchmarks. Ablation studies reveal the individual contribution of each\ncomponent while highlighting their synergy. Our code and model weights are\npublicly available at https://github.com/leor-c/Simulus.",
    "pdf_url": "http://arxiv.org/pdf/2502.11537v3",
    "published": "2025-02-17T08:06:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11536v2",
    "title": "CSST Large Scale Structure Analysis Pipeline: III. Emission-line Redshift Measurement for Slitless Spectra",
    "authors": [
      "Jipeng Sui",
      "Hu Zou",
      "Xiaohu Yang",
      "Xianzhong Zheng",
      "Run Wen",
      "Yizhou Gu",
      "Weiyu Ding",
      "Lu Feng",
      "Hong Guo",
      "Wei-Jian Guo",
      "Yunkun Han",
      "Yipeng Jing",
      "Cheng Li",
      "Wenxiong Li",
      "Shufei Liu",
      "Zhixia Shen",
      "Gaurav Singh",
      "Jiali Wang",
      "Peng Wei",
      "Yunao Xiao",
      "Suijian Xue",
      "Hu Zhan",
      "Pengjie Zhang",
      "Gongbo Zhao"
    ],
    "abstract": "The China Space Station Telescope (CSST) is a forthcoming space-based optical\ntelescope designed to co-orbit with the Chinese Space Station. With a planned\nslitless spectroscopic survey spanning a broad wavelength range of $255-1000$nm\nand an average spectral resolution exceeding 200, the CSST holds significant\npotential for cosmic large-scale structure analysis. In this study, we focus on\nredshift determinations from slitless spectra through emission line analysis\nwithin the CSST framework. Our tailored redshift measurement process involves\nidentifying emission lines in one-dimensional slitless spectra, aligning\nobserved wavelengths with their rest-frame counterparts from prominent galaxy\nemissions, and calculating wavelength shifts to determine redshifts accurately.\nTo validate our redshift measurement algorithm, we leverage simulated spectra\ngenerated by the CSST emulator for slitless spectroscopy. The outcomes\ndemonstrate a remarkable redshift completeness exceeding 95 per cent for\nemission line galaxies (ELGs), alongside a purity surpassing 85 per cent. The\nredshift uncertainty remains impressively below than $\\sim 0.001$. Notably,\nwhen concentrating on galaxies with more than three matched emission lines, the\ncompleteness of ELGs and the purity of measurable galaxies can reach 98 per\ncent and 97 per cent, respectively. Furthermore, we explore the influence of\nparameters like magnitude, spectral signal-to-noise ratio, and redshift on\nredshift completeness and purity. The discussion also delves into redshift\ndegeneracies stemming from emission-line matching confusion. Our developed\nredshift measurement process will be applied to extensive simulated datasets\nand forthcoming CSST slitless spectroscopic observations for further\ncosmological and extragalactic analyses.",
    "pdf_url": "http://arxiv.org/pdf/2502.11536v2",
    "published": "2025-02-17T08:05:39+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11535v1",
    "title": "Disentangled Iterative Surface Fitting for Contact-stable Grasp Planning",
    "authors": [
      "Tomoya Yamanokuchi",
      "Alberto Bacchin",
      "Emilio Olivastri",
      "Takamitsu Matsubara",
      "Emanuele Menegatti"
    ],
    "abstract": "In this work, we address the limitation of surface fitting-based grasp\nplanning algorithm, which primarily focuses on geometric alignment between the\ngripper and object surface while overlooking the stability of contact point\ndistribution, often resulting in unstable grasps due to inadequate contact\nconfigurations. To overcome this limitation, we propose a novel surface fitting\nalgorithm that integrates contact stability while preserving geometric\ncompatibility. Inspired by human grasping behavior, our method disentangles the\ngrasp pose optimization into three sequential steps: (1) rotation optimization\nto align contact normals, (2) translation refinement to improve Center of Mass\n(CoM) alignment, and (3) gripper aperture adjustment to optimize contact point\ndistribution. We validate our approach through simulations on ten YCB dataset\nobjects, demonstrating an 80% improvement in grasp success over conventional\nsurface fitting methods that disregard contact stability. Further details can\nbe found on our project page:\nhttps://tomoya-yamanokuchi.github.io/disf-project-page/.",
    "pdf_url": "http://arxiv.org/pdf/2502.11535v1",
    "published": "2025-02-17T08:05:36+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11534v1",
    "title": "SurgPose: a Dataset for Articulated Robotic Surgical Tool Pose Estimation and Tracking",
    "authors": [
      "Zijian Wu",
      "Adam Schmidt",
      "Randy Moore",
      "Haoying Zhou",
      "Alexandre Banks",
      "Peter Kazanzides",
      "Septimiu E. Salcudean"
    ],
    "abstract": "Accurate and efficient surgical robotic tool pose estimation is of\nfundamental significance to downstream applications such as augmented reality\n(AR) in surgical training and learning-based autonomous manipulation. While\nsignificant advancements have been made in pose estimation for humans and\nanimals, it is still a challenge in surgical robotics due to the scarcity of\npublished data. The relatively large absolute error of the da Vinci end\neffector kinematics and arduous calibration procedure make calibrated\nkinematics data collection expensive. Driven by this limitation, we collected a\ndataset, dubbed SurgPose, providing instance-aware semantic keypoints and\nskeletons for visual surgical tool pose estimation and tracking. By marking\nkeypoints using ultraviolet (UV) reactive paint, which is invisible under white\nlight and fluorescent under UV light, we execute the same trajectory under\ndifferent lighting conditions to collect raw videos and keypoint annotations,\nrespectively. The SurgPose dataset consists of approximately 120k surgical\ninstrument instances (80k for training and 40k for validation) of 6 categories.\nEach instrument instance is labeled with 7 semantic keypoints. Since the videos\nare collected in stereo pairs, the 2D pose can be lifted to 3D based on\nstereo-matching depth. In addition to releasing the dataset, we test a few\nbaseline approaches to surgical instrument tracking to demonstrate the utility\nof SurgPose. More details can be found at surgpose.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2502.11534v1",
    "published": "2025-02-17T08:04:53+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11533v1",
    "title": "Be Cautious When Merging Unfamiliar LLMs: A Phishing Model Capable of Stealing Privacy",
    "authors": [
      "Zhenyuan Guo",
      "Yi Shi",
      "Wenlong Meng",
      "Chen Gong",
      "Chengkun Wei",
      "Wenzhi Chen"
    ],
    "abstract": "Model merging is a widespread technology in large language models (LLMs) that\nintegrates multiple task-specific LLMs into a unified one, enabling the merged\nmodel to inherit the specialized capabilities of these LLMs. Most task-specific\nLLMs are sourced from open-source communities and have not undergone rigorous\nauditing, potentially imposing risks in model merging. This paper highlights an\noverlooked privacy risk: \\textit{an unsafe model could compromise the privacy\nof other LLMs involved in the model merging.} Specifically, we propose PhiMM, a\nprivacy attack approach that trains a phishing model capable of stealing\nprivacy using a crafted privacy phishing instruction dataset. Furthermore, we\nintroduce a novel model cloaking method that mimics a specialized capability to\nconceal attack intent, luring users into merging the phishing model. Once\nvictims merge the phishing model, the attacker can extract personally\nidentifiable information (PII) or infer membership information (MI) by querying\nthe merged model with the phishing instruction. Experimental results show that\nmerging a phishing model increases the risk of privacy breaches. Compared to\nthe results before merging, PII leakage increased by 3.9\\% and MI leakage\nincreased by 17.4\\% on average. We release the code of PhiMM through a link.",
    "pdf_url": "http://arxiv.org/pdf/2502.11533v1",
    "published": "2025-02-17T08:04:52+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11532v1",
    "title": "Control-CLIP: Decoupling Category and Style Guidance in CLIP for Specific-Domain Generation",
    "authors": [
      "Zexi Jia",
      "Chuanwei Huang",
      "Hongyan Fei",
      "Yeshuang Zhu",
      "Zhiqiang Yuan",
      "Jinchao Zhang",
      "Jie Zhou"
    ],
    "abstract": "Text-to-image diffusion models have shown remarkable capabilities of\ngenerating high-quality images closely aligned with textual inputs. However,\nthe effectiveness of text guidance heavily relies on the CLIP text encoder,\nwhich is trained to pay more attention to general content but struggles to\ncapture semantics in specific domains like styles. As a result, generation\nmodels tend to fail on prompts like \"a photo of a cat in Pokemon style\" in\nterms of simply producing images depicting \"a photo of a cat\". To fill this\ngap, we propose Control-CLIP, a novel decoupled CLIP fine-tuning framework that\nenables the CLIP model to learn the meaning of category and style in a\ncomplement manner. With specially designed fine-tuning tasks on minimal data\nand a modified cross-attention mechanism, Control-CLIP can precisely guide the\ndiffusion model to a specific domain. Moreover, the parameters of the diffusion\nmodel remain unchanged at all, preserving the original generation performance\nand diversity. Experiments across multiple domains confirm the effectiveness of\nour approach, particularly highlighting its robust plug-and-play capability in\ngenerating content with various specific styles.",
    "pdf_url": "http://arxiv.org/pdf/2502.11532v1",
    "published": "2025-02-17T08:03:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11531v2",
    "title": "Transport equations for Osgood velocity fields",
    "authors": [
      "Ulrik Skre Fjordholm",
      "Ola Isaac HÃ¸gÃ¥sen MÃ¦hlen"
    ],
    "abstract": "We consider the transport equation with a velocity field satisfying the\nOsgood condition. The weak formulation is not meaningful in the usual Lebesgue\nsense, meaning that the usual DiPerna--Lions treatment of the problem is not\napplicable {(in particular, the divergence of the velocity might be\nunbounded)}. Instead, we use Riemann--Stieltjes integration to interpret the\nweak formulation, leading to a well-posedness theory in regimes not covered by\nexisting works. The most general results are for the one-dimensional problem,\nwith generalisations to multiple dimensions in the particular case of\nlog-Lipschitz velocities.",
    "pdf_url": "http://arxiv.org/pdf/2502.11531v2",
    "published": "2025-02-17T08:03:47+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11530v1",
    "title": "Non-equilibrium distribution function in ultra-fast processes",
    "authors": [
      "K. S. Glavatskiy"
    ],
    "abstract": "A simple expression for the non-equilibrium distribution function in\nultra-fast transient processes is proposed. Postulating its dependence on\ntemporal derivatives of the equilibrium integrals of motion, non-equilibrium\nanalogues of the thermodynamic relationships are derived and the conditions\nthat maximize the non-equilibrium entropy are identified. A rigorous threshold\nbetween ``slow\" and ``fast\" processes is suggested, identifying the range of\napplicability of classical quasi-equilibrium description. The proposed theory\nis validated by deriving the known law of inertial heat conduction, which\naccounts for finite speed of thermal propagation. Finally, a new expression for\nthe non-equilibrium work is derived, revealing two kinds of pressure that\nemerge in fast non-equilibrium.",
    "pdf_url": "http://arxiv.org/pdf/2502.11530v1",
    "published": "2025-02-17T08:03:43+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "math-ph",
      "math.MP",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2502.11529v2",
    "title": "Axial Behaviour of Pre-Damaged RC Short Columns Retrofitted with Square Corrugated Steel Jackets",
    "authors": [
      "Ligui Yang",
      "Fan Yang",
      "Yuyin Wang",
      "Shuangshuang Jin",
      "Yong Fang",
      "Yunwen Chen",
      "Qilong Xia"
    ],
    "abstract": "This study proposes a strengthening method employing square corrugated steel\njackets as external confinement, which significantly enhances both the bearing\ncapacity and ductility of existing reinforced concrete (RC) columns. Axial\ncompression tests were conducted on ten short column specimens to evaluate the\neffects of corrugated steel thickness (1.6, 2.0, and 2.7 mm), preloading level\nbefore jacketing (40%, 60%, and 100% of the original capacity), and connection\ntype (welding vs. bolting). A computational model was developed to predict the\nultimate bearing capacity of the strengthened sections. The main findings are\nas follows: (1) The corrugated steel jackets increased the ultimate bearing\ncapacity of the existing RC columns by 34.6% to 67.3%. (2) Given the relatively\nlow confinement efficiency in square sections, thinner corrugated steel plates\ncan be used in a material-efficient manner to achieve comparable strengthening\neffects. (3) Fully welded connections between corrugated plates induce less\nstress concentration and provide better transverse confinement effectiveness\ncompared to bolted connections. (4) In a pre-unloaded column, greater existed\ndamage causes concrete softening and increased lateral expansion under\nre-compression. This dilation promotes a tighter interaction between the core\nconcrete and the outer jacket, activating stronger passive confinement after\nbeing jacketed. (5) The low longitudinal stresses in the jacket indicate that\nits primary role is to provide lateral confinement rather than to resist axial\nloads directly. (6) It is recommended to employ a calculation method that\naccounts for both pre-damage and confinement effects to ensure a conservative\nand reliable design of corrugated steel-jacketed RC columns with pre-damage.",
    "pdf_url": "http://arxiv.org/pdf/2502.11529v2",
    "published": "2025-02-17T08:00:10+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11528v1",
    "title": "A Survey of Personalized Large Language Models: Progress and Future Directions",
    "authors": [
      "Jiahong Liu",
      "Zexuan Qiu",
      "Zhongyang Li",
      "Quanyu Dai",
      "Jieming Zhu",
      "Minda Hu",
      "Menglin Yang",
      "Irwin King"
    ],
    "abstract": "Large Language Models (LLMs) excel in handling general knowledge tasks, yet\nthey struggle with user-specific personalization, such as understanding\nindividual emotions, writing styles, and preferences. Personalized Large\nLanguage Models (PLLMs) tackle these challenges by leveraging individual user\ndata, such as user profiles, historical dialogues, content, and interactions,\nto deliver responses that are contextually relevant and tailored to each user's\nspecific needs. This is a highly valuable research topic, as PLLMs can\nsignificantly enhance user satisfaction and have broad applications in\nconversational agents, recommendation systems, emotion recognition, medical\nassistants, and more. This survey reviews recent advancements in PLLMs from\nthree technical perspectives: prompting for personalized context (input level),\nfinetuning for personalized adapters (model level), and alignment for\npersonalized preferences (objective level). To provide deeper insights, we also\ndiscuss current limitations and outline several promising directions for future\nresearch. Updated information about this survey can be found at the\nhttps://github.com/JiahongLiu21/Awesome-Personalized-Large-Language-Models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11528v1",
    "published": "2025-02-17T07:58:31+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11527v1",
    "title": "Application of Many-body Non-perturbative Theories to the Three-Dimensional Attractive Hubbard Model",
    "authors": [
      "Junnian Xiong",
      "Hui Li",
      "Yingze Su",
      "Dingping Li"
    ],
    "abstract": "The attractive Fermi-Hubbard model stands out as a simple model for studying\nthe pairing and superconductivity of fermions on a lattice. In this article, we\napply several many-body theories in the three-dimensional attractive Hubbard\nmodel. Specifically, we compare the results of various GW methods with DQMC\nsimulations and observe that they provide reliable results in the weak to\nintermediate coupling regime. The critical exponents also agree well with the\naccurate results obtained from the 3D XY model. In the superconducting phase,\nthe post-GW method significantly improves the description of Green's functions\nand density of states. Additionally, we propose a method to determine the\ntemperature at which the pseudogap appears.",
    "pdf_url": "http://arxiv.org/pdf/2502.11527v1",
    "published": "2025-02-17T07:57:33+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11526v1",
    "title": "Monogamy and polygamy for multi-qudit generalized $W$-class states based on concurrence of assistance and Tsallis-$q$ entanglement of assistance",
    "authors": [
      "Wen Zhou",
      "Zhong-Xi Shen",
      "Dong-Ping Xuan",
      "Zhi-Xi Wang",
      "Shao-Ming Fei"
    ],
    "abstract": "By analyzing the reduced density matrices derived from a generalized\n$W$-class state under any partition, we present new analytical monogamy\ninequalities satisfied by the $\\alpha$-th ($\\alpha\\geq\\gamma,~\\gamma\\geq2$)\npower and $\\beta$-th ($0\\leq\\beta\\leq\\frac{\\gamma}{2},~\\gamma\\geq2$) power of\nthe concurrence of assistance for multi-qudit generalized $W$-class states,\nwhich are demonstrated to be tighter than previous studies through detailed\nexamples. Furthermore, using the Tsallis-$q$ entanglement of assistance, we\nalso establish new monogamy and polygamy relations, which are shown to be valid\neven for multipartite higher-dimensional states that the CKW inequality is\nviolated.",
    "pdf_url": "http://arxiv.org/pdf/2502.11526v1",
    "published": "2025-02-17T07:56:06+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11525v2",
    "title": "Beyond Single-Task: Robust Multi-Task Length Generalization for LLMs",
    "authors": [
      "Yi Hu",
      "Shijia Kang",
      "Haotong Yang",
      "Haotian Xu",
      "Muhan Zhang"
    ],
    "abstract": "Length generalization, the ability to solve problems longer than those seen\nduring training, remains a critical challenge for large language models (LLMs).\nPrevious work modifies positional encodings (PEs) and data formats to improve\nlength generalization on specific symbolic tasks such as addition and sorting.\nHowever, these approaches are fundamentally limited to special tasks, often\ndegrading general language performance. Furthermore, they are typically\nevaluated on small transformers trained from scratch on single tasks and can\ncause performance drop when applied during post-training stage of practical\nLLMs with general capabilities. Hu et al., (2024) proposed Rule-Following\nFine-Tuning (RFFT) to improve length generalization in the post-training stage\nof LLMs. Despite its compatibility with practical models and strong\nperformance, RFFT is proposed for single tasks too, requiring re-training for\neach individual task with extensive examples. In this paper, we study length\ngeneralization in multi-task settings and propose Meta Rule-Following\nFine-Tuning (Meta-RFFT), the first framework enabling robust cross-task length\ngeneralization. As our first contribution, we construct a large length\ngeneralization dataset containing 86 tasks spanning code execution, number\nprocessing, symbolic and logical reasoning tasks, beyond the common addition or\nmultiplication tasks. Secondly, we show that cross-task length generalization\nis possible with Meta-RFFT. After training on a large number of tasks and\ninstances, the models achieve remarkable length generalization ability on\nunseen tasks with minimal fine-tuning or one-shot prompting. For example, after\nfine-tuning on 1 to 5 digit addition, our 32B model achieves 95% accuracy on 30\ndigit addition, significantly outperforming the state-of-the-art reasoning\nmodels (DeepSeek-R1-671B: 72%), despite never seeing this task during\nRF-pretraining.",
    "pdf_url": "http://arxiv.org/pdf/2502.11525v2",
    "published": "2025-02-17T07:54:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11524v2",
    "title": "The Scaled Polarity transform and related inequalities",
    "authors": [
      "Shoni Gilboa",
      "Alexander Segal",
      "Boaz A. Slomka"
    ],
    "abstract": "In this paper we deal with generalizations of the Mahler volume product for\nlog-concave functions. We show that the polarity transform $\\mathcal A$ can be\nrescaled so that the Mahler product it induces has upper and lower bounds of\nthe same asymptotics. We discuss a similar result for the $\\mathcal J$\ntransform.\n  As an application, we extend the K\\\"onig-Milman duality of entropy result to\nthe class of geometric log-concave functions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11524v2",
    "published": "2025-02-17T07:54:45+00:00",
    "categories": [
      "math.FA",
      "52A41, 26A51, 46B10"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11523v2",
    "title": "AI-Assisted Thin Section Image Processing for Pore-Throat Characterization in Tight Clastic Rocks",
    "authors": [
      "Muhammad Risha"
    ],
    "abstract": "The characterization of pore-throat structures in tight sandstones is crucial\nfor understanding fluid flow in hydrocarbon reservoirs and groundwater systems.\nBoth thin-section and Mercury Intrusion Capillary Pressure (MICP) offer\ninsights rock petrophysical parameters. However, thin-section analysis is\nlimited by its 2D nature and subjective interpretation, while MICP provides 3D\npore-throat distributions, it lacks direct visualization of pore morphology.\nThis study evaluates AI-assisted thin-section image analysis for pore-throat\ncharacterization by comparing its results to MICP-derived measurements. A\nmachine learning-based workflow was developed using color thresholding, K-Means\nclustering, and medial axis transformation to segment pore structures in\nthin-section images. Throat width, porosity, and permeability were\nquantitatively assessed against MICP to determine the accuracy and reliability\nof the technique. The analysis of 26 sandstone samples outlined differences\nbetween the two methods. Thin-section analysis showed porosity values from\n1.37% to 53.37%, with average pore-throat sizes between 5.63 micron and 30.09\nmicron, while permeability estimates ranged from 0.01 mD to 344.35 mD.\nCorrelation analysis showed moderate agreement for throat size (r=0.62) and\npermeability (r=0.61), but weaker for porosity (r=0.32), highlighting the\ndifferences in how each method captures pore connectivity. Results demonstrate\nthat the AI-assisted segmentation provides a scalable and reproducible approach\nbut is constrained by thin-section imaging resolution. While MICP remains\nreliable for permeability evaluation, its comparison with AI-driven image\nanalysis helps assess the reliability of the method. Future research should\nrefine segmentation algorithms, incorporate pretrained data to validate\nAI-derived pore-throat attributes for improved reservoir quality assessment and\npredictive modeling.",
    "pdf_url": "http://arxiv.org/pdf/2502.11523v2",
    "published": "2025-02-17T07:54:30+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.13977v1",
    "title": "Purely Electronic Chirality without Structural Chirality",
    "authors": [
      "Takayuki Ishitobi",
      "Kazumasa Hattori"
    ],
    "abstract": "We introduce the concept of purely electronic chirality, which arises in the\nabsence of structural chirality. In condensed matter physics and chemistry,\nchirality has conventionally been understood as a mirror-image asymmetry in\ncrystal or molecular structures. We demonstrate that certain electronic orders\nexhibit chirality-related properties without atomic displacement. Specifically,\nwe investigate quadrupole orders to realize such purely electronic chirality\nwith handedness that can be tuned by magnetic fields. As a representative\nexample, we analyze a model featuring $120^\\circ$ antiferro quadrupole orders\non a distorted kagom\\'e lattice, predicting various chirality-related responses\nin the nonmagnetic ordered phase of URhSn. Furthermore, as a phonon analog,\nchiral phonons can emerge in achiral crystals through coupling with the pEC\norder. Our results provide a distinct origin of chirality and a fundamental\nbasis for exploring the interplay between electronic and structural chirality.",
    "pdf_url": "http://arxiv.org/pdf/2502.13977v1",
    "published": "2025-02-17T07:51:57+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11522v1",
    "title": "Fan's condition for completely independent spanning trees",
    "authors": [
      "Jie Ma",
      "Junqing Cai"
    ],
    "abstract": "Spanning trees $T_1,T_2, \\dots,T_k$ of $G$ are $k$ completely independent\nspanning trees if, for any two vertices $u,v\\in V(G)$, the paths from $u$ to\n$v$ in these $k$ trees are pairwise edge-disjoint and internal vertex-disjoint.\nHasunuma proved that determining whether a graph contains $k$ completely\nindependent spanning trees is NP-complete, even for $k = 2$. Araki posed the\nquestion of whether certain known sufficient conditions for hamiltonian cycles\nare also also guarantee two completely independent spanning trees? In this\npaper, we affirmatively answer this question for the Fan-type condition.\nPrecisely, we proved that if $G$ is a connected graph such that each pair of\nvertices at distance 2 has degree sum at least $|V(G)|$, then $G$ has two\ncompletely independent spanning trees.",
    "pdf_url": "http://arxiv.org/pdf/2502.11522v1",
    "published": "2025-02-17T07:51:46+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11521v1",
    "title": "DeFiScope: Detecting Various DeFi Price Manipulations with LLM Reasoning",
    "authors": [
      "Juantao Zhong",
      "Daoyuan Wu",
      "Ye Liu",
      "Maoyi Xie",
      "Yang Liu",
      "Yi Li",
      "Ning Liu"
    ],
    "abstract": "DeFi (Decentralized Finance) is one of the most important applications of\ntoday's cryptocurrencies and smart contracts. It manages hundreds of billions\nin Total Value Locked (TVL) on-chain, yet it remains susceptible to common DeFi\nprice manipulation attacks. Despite state-of-the-art (SOTA) systems like\nDeFiRanger and DeFort, we found that they are less effective to non-standard\nprice models in custom DeFi protocols, which account for 44.2% of the 95 DeFi\nprice manipulation attacks reported over the past three years.\n  In this paper, we introduce the first LLM-based approach, DeFiScope, for\ndetecting DeFi price manipulation attacks in both standard and custom price\nmodels. Our insight is that large language models (LLMs) have certain\nintelligence to abstract price calculation from code and infer the trend of\ntoken price changes based on the extracted price models. To further strengthen\nLLMs in this aspect, we leverage Foundry to synthesize on-chain data and use it\nto fine-tune a DeFi price-specific LLM. Together with the high-level DeFi\noperations recovered from low-level transaction data, DeFiScope detects various\nDeFi price manipulations according to systematically mined patterns.\nExperimental results show that DeFiScope achieves a high precision of 96% and a\nrecall rate of 80%, significantly outperforming SOTA approaches. Moreover, we\nevaluate DeFiScope's cost-effectiveness and demonstrate its practicality by\nhelping our industry partner confirm 147 real-world price manipulation attacks,\nincluding discovering 81 previously unknown historical incidents.",
    "pdf_url": "http://arxiv.org/pdf/2502.11521v1",
    "published": "2025-02-17T07:45:03+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11520v1",
    "title": "AURORA:Automated Training Framework of Universal Process Reward Models via Ensemble Prompting and Reverse Verification",
    "authors": [
      "Xiaoyu Tan",
      "Tianchu Yao",
      "Chao Qu",
      "Bin Li",
      "Minghao Yang",
      "Dakuan Lu",
      "Haozhe Wang",
      "Xihe Qiu",
      "Wei Chu",
      "Yinghui Xu",
      "Yuan Qi"
    ],
    "abstract": "The reasoning capabilities of advanced large language models (LLMs) like o1\nhave revolutionized artificial intelligence applications. Nevertheless,\nevaluating and optimizing complex reasoning processes remain significant\nchallenges due to diverse policy distributions and the inherent limitations of\nhuman effort and accuracy. In this paper, we present AURORA, a novel automated\nframework for training universal process reward models (PRMs) using ensemble\nprompting and reverse verification. The framework employs a two-phase approach:\nFirst, it uses diverse prompting strategies and ensemble methods to perform\nautomated annotation and evaluation of processes, ensuring robust assessments\nfor reward learning. Second, it leverages practical reference answers for\nreverse verification, enhancing the model's ability to validate outputs and\nimproving training accuracy. To assess the framework's performance, we extend\nbeyond the existing ProcessBench benchmark by introducing UniversalBench, which\nevaluates reward predictions across full trajectories under diverse policy\ndistribtion with long Chain-of-Thought (CoT) outputs. Experimental results\ndemonstrate that AURORA enhances process evaluation accuracy, improves PRMs'\naccuracy for diverse policy distributions and long-CoT responses. The project\nwill be open-sourced at https://auroraprm.github.io/. The Universal-PRM-7B is\navailable at https://huggingface.co/infly/Universal-PRM-7B.",
    "pdf_url": "http://arxiv.org/pdf/2502.11520v1",
    "published": "2025-02-17T07:41:27+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11519v1",
    "title": "UniGO: A Unified Graph Neural Network for Modeling Opinion Dynamics on Graphs",
    "authors": [
      "Hao Li",
      "Hao Jiang",
      "Yuke Zheng",
      "Hao Sun",
      "Wenying Gong"
    ],
    "abstract": "Polarization and fragmentation in social media amplify user biases, making it\nincreasingly important to understand the evolution of opinions. Opinion\ndynamics provide interpretability for studying opinion evolution, yet\nincorporating these insights into predictive models remains challenging. This\nchallenge arises due to the inherent complexity of the diversity of opinion\nfusion rules and the difficulty in capturing equilibrium states while avoiding\nover-smoothing. This paper constructs a unified opinion dynamics model to\nintegrate different opinion fusion rules and generates corresponding synthetic\ndatasets. To fully leverage the advantages of unified opinion dynamics, we\nintroduces UniGO, a framework for modeling opinion evolution on graphs. Using a\ncoarsen-refine mechanism, UniGO efficiently models opinion dynamics through a\ngraph neural network, mitigating over-smoothing while preserving equilibrium\nphenomena. UniGO leverages pretraining on synthetic datasets, which enhances\nits ability to generalize to real-world scenarios, providing a viable paradigm\nfor applications of opinion dynamics. Experimental results on both synthetic\nand real-world datasets demonstrate UniGO's effectiveness in capturing complex\nopinion formation processes and predicting future evolution. The pretrained\nmodel also shows strong generalization capability, validating the benefits of\nusing synthetic data to boost real-world performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11519v1",
    "published": "2025-02-17T07:40:32+00:00",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11518v1",
    "title": "Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review",
    "authors": [
      "Di Wu",
      "Xian Wei",
      "Guang Chen",
      "Hao Shen",
      "Xiangfeng Wang",
      "Wenhao Li",
      "Bo Jin"
    ],
    "abstract": "Embodied multi-agent systems (EMAS) have attracted growing attention for\ntheir potential to address complex, real-world challenges in areas such as\nlogistics and robotics. Recent advances in foundation models pave the way for\ngenerative agents capable of richer communication and adaptive problem-solving.\nThis survey provides a systematic examination of how EMAS can benefit from\nthese generative capabilities. We propose a taxonomy that categorizes EMAS by\nsystem architectures and embodiment modalities, emphasizing how collaboration\nspans both physical and virtual contexts. Central building blocks, perception,\nplanning, communication, and feedback, are then analyzed to illustrate how\ngenerative techniques bolster system robustness and flexibility. Through\nconcrete examples, we demonstrate the transformative effects of integrating\nfoundation models into embodied, multi-agent frameworks. Finally, we discuss\nchallenges and future directions, underlining the significant promise of EMAS\nto reshape the landscape of AI-driven collaboration.",
    "pdf_url": "http://arxiv.org/pdf/2502.11518v1",
    "published": "2025-02-17T07:39:34+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11517v2",
    "title": "Learning to Keep a Promise: Scaling Language Model Decoding Parallelism with Learned Asynchronous Decoding",
    "authors": [
      "Tian Jin",
      "Ellie Y. Cheng",
      "Zack Ankner",
      "Nikunj Saunshi",
      "Blake M. Elias",
      "Amir Yazdanbakhsh",
      "Jonathan Ragan-Kelley",
      "Suvinay Subramanian",
      "Michael Carbin"
    ],
    "abstract": "Decoding with autoregressive large language models (LLMs) traditionally\noccurs sequentially, generating one token after another. An emerging line of\nwork explored parallel decoding by identifying and simultaneously generating\nsemantically independent chunks of LLM responses. However, these techniques\nrely on hand-crafted heuristics tied to syntactic structures like lists and\nparagraphs, making them rigid and imprecise. We present PASTA, a learning-based\nsystem that teaches LLMs to identify semantic independence and express parallel\ndecoding opportunities in their own responses. At its core are PASTA-LANG and\nits interpreter: PASTA-LANG is an annotation language that enables LLMs to\nexpress semantic independence in their own responses; the language interpreter\nacts on these annotations to orchestrate parallel decoding on-the-fly at\ninference time. Through a two-stage finetuning process, we train LLMs to\ngenerate PASTA-LANG annotations that optimize both response quality and\ndecoding speed. Evaluation on AlpacaEval, an instruction following benchmark,\nshows that our approach Pareto-dominates existing methods in terms of decoding\nspeed and response quality; our results demonstrate geometric mean speedups\nranging from 1.21x to 1.93x with corresponding quality changes of +2.2% to\n-7.1%, measured by length-controlled win rates against sequential decoding\nbaseline.",
    "pdf_url": "http://arxiv.org/pdf/2502.11517v2",
    "published": "2025-02-17T07:39:16+00:00",
    "categories": [
      "cs.CL",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11516v1",
    "title": "CRB-Rate Tradeoff in RSMA-enabled Near-Field Integrated Multi-Target Sensing and Multi-User Communications",
    "authors": [
      "Jiasi Zhou",
      "Cong Zhou",
      "Yanjing Sun",
      "Chintha Tellambura"
    ],
    "abstract": "Extremely large-scale antenna arrays enhance spectral efficiency and spatial\nresolution in integrated sensing and communication (ISAC) networks while\nexpanding the Rayleigh distance, triggering a shift from conventional far-field\nplane waves to near-field (NF) spherical waves. However, full-digital\nbeamforming is infeasible due to the need for dedicated radio frequency (RF)\nchains. To address this, NF-ISAC with a rate-splitting multiple access (RSMA)\nscheme is developed for advanced interference management, considering\nfully-connected and partially-connected hybrid analog and digital (HAD)\nbeamforming architectures. Specifically, the Cram\\'{e}r-Rao bound (CRB) for\njoint distance and angle sensing is derived, and the achievable performance\nregion between the max-min communication rate and the multi-target CRB is\ndefined. To fully characterize the Pareto boundary of the CRB-rate region, a\nsensing-centric minimization problem is formulated under communication rate\nconstraints for two HAD beamforming architectures. A penalty dual decomposition\n(PDD)-based double-loop algorithm is developed to optimize fully-connected HAD\nbeamformers. To reduce computational complexity, a two-stage design algorithm\nfor fully connected HAD beamforming is also proposed. Additionally, the\nPDD-based double-loop algorithm is extended to the partially-connected HAD\narchitecture. Simulations demonstrate the proposed schemes and algorithms: 1)\nachieve performance comparable to a fully digital beamformer with fewer RF\nchains, 2) outperform space division multiple access and far-field ISAC, and 3)\nyield enhanced CRB-rate trade-off performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11516v1",
    "published": "2025-02-17T07:32:38+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11515v1",
    "title": "SayAnything: Audio-Driven Lip Synchronization with Conditional Video Diffusion",
    "authors": [
      "Junxian Ma",
      "Shiwen Wang",
      "Jian Yang",
      "Junyi Hu",
      "Jian Liang",
      "Guosheng Lin",
      "Jingbo chen",
      "Kai Li",
      "Yu Meng"
    ],
    "abstract": "Recent advances in diffusion models have led to significant progress in\naudio-driven lip synchronization. However, existing methods typically rely on\nconstrained audio-visual alignment priors or multi-stage learning of\nintermediate representations to force lip motion synthesis. This leads to\ncomplex training pipelines and limited motion naturalness. In this paper, we\npresent SayAnything, a conditional video diffusion framework that directly\nsynthesizes lip movements from audio input while preserving speaker identity.\nSpecifically, we propose three specialized modules including identity\npreservation module, audio guidance module, and editing control module. Our\nnovel design effectively balances different condition signals in the latent\nspace, enabling precise control over appearance, motion, and region-specific\ngeneration without requiring additional supervision signals or intermediate\nrepresentations. Extensive experiments demonstrate that SayAnything generates\nhighly realistic videos with improved lip-teeth coherence, enabling unseen\ncharacters to say anything, while effectively generalizing to animated\ncharacters.",
    "pdf_url": "http://arxiv.org/pdf/2502.11515v1",
    "published": "2025-02-17T07:29:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11514v2",
    "title": "Investigating Inference-time Scaling for Chain of Multi-modal Thought: A Preliminary Study",
    "authors": [
      "Yujie Lin",
      "Ante Wang",
      "Moye Chen",
      "Jingyao Liu",
      "Hao Liu",
      "Jinsong Su",
      "Xinyan Xiao"
    ],
    "abstract": "Recently, inference-time scaling of chain-of-thought (CoT) has been\ndemonstrated as a promising approach for addressing multi-modal reasoning\ntasks. While existing studies have predominantly centered on text-based\nthinking, the integration of both visual and textual modalities within the\nreasoning process remains unexplored. In this study, we pioneer the exploration\nof inference-time scaling with multi-modal thought, aiming to bridge this gap.\nTo provide a comprehensive analysis, we systematically investigate popular\nsampling-based and tree search-based inference-time scaling methods on 10\nchallenging tasks spanning various domains. Besides, we uniformly adopt a\nconsistency-enhanced verifier to ensure effective guidance for both methods\nacross different thought paradigms. Results show that multi-modal thought\npromotes better performance against conventional text-only thought, and\nblending the two types of thought fosters more diverse thinking. Despite these\nadvantages, multi-modal thoughts necessitate higher token consumption for\nprocessing richer visual inputs, which raises concerns in practical\napplications. We hope that our findings on the merits and drawbacks of this\nresearch line will inspire future works in the field.",
    "pdf_url": "http://arxiv.org/pdf/2502.11514v2",
    "published": "2025-02-17T07:29:01+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11513v1",
    "title": "MaZO: Masked Zeroth-Order Optimization for Multi-Task Fine-Tuning of Large Language Models",
    "authors": [
      "Zhen Zhang",
      "Yifan Yang",
      "Kai Zhen",
      "Nathan Susanj",
      "Athanasios Mouchtaris",
      "Siegfried Kunzmann",
      "Zheng Zhang"
    ],
    "abstract": "Large language models have demonstrated exceptional capabilities across\ndiverse tasks, but their fine-tuning demands significant memory, posing\nchallenges for resource-constrained environments. Zeroth-order (ZO)\noptimization provides a memory-efficient alternative by eliminating the need\nfor backpropagation. However, ZO optimization suffers from high gradient\nvariance, and prior research has largely focused on single-task learning,\nleaving its application to multi-task learning unexplored. Multi-task learning\nis crucial for leveraging shared knowledge across tasks to improve\ngeneralization, yet it introduces unique challenges under ZO settings, such as\namplified gradient variance and collinearity. In this paper, we present MaZO,\nthe first framework specifically designed for multi-task LLM fine-tuning under\nZO optimization. MaZO tackles these challenges at the parameter level through\ntwo key innovations: a weight importance metric to identify critical parameters\nand a multi-task weight update mask to selectively update these parameters,\nreducing the dimensionality of the parameter space and mitigating task\nconflicts. Experiments demonstrate that MaZO achieves state-of-the-art\nperformance, surpassing even multi-task learning methods designed for\nfirst-order optimization.",
    "pdf_url": "http://arxiv.org/pdf/2502.11513v1",
    "published": "2025-02-17T07:28:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11512v1",
    "title": "Triaxial Alignment Magnetometer Utilizing Free-Spin Precession in the Geomagnetic Range",
    "authors": [
      "Ge Jin",
      "Tao Shi",
      "Sheng Zou"
    ],
    "abstract": "In this paper, we present a triaxial alignment magnetometer based on\nfree-spin precession deployed in the geomagnetic range. Existing vector\nmeasurement methods often require complex optical setups, heating structures,\nand laser modulation. This study addresses this challenge by employing a\nlinearly polarized probe beam to induce atomic alignment and subsequently\ndetecting the optical polarization rotation caused by the pulsed radio\nfrequency field. The experiment is conducted in a paraffin-coated cell without\nbuffer gas at room temperature, containing rubidium with natural abundance. We\nreport triaxial measurements with a static magnetic field amplitude of\napproximately 50 $\\mu{\\text{T}}$ (close to Earth's magnetic field), where the\nnoise levels for each axis are approximately 5.3\n${\\text{pT/}}\\sqrt{{\\text{Hz}}}$, 4.7 ${\\text{pT/}}\\sqrt{{\\text{Hz}}}$, and 9.3\n${\\text{pT/}}\\sqrt{{\\text{Hz}}}$ respectively. The proposed method demonstrates\na simple structure suitable for cost-effective and versatile applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11512v1",
    "published": "2025-02-17T07:28:04+00:00",
    "categories": [
      "physics.atom-ph",
      "physics.app-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.13168v3",
    "title": "What defines stationarity in space plasmas",
    "authors": [
      "George Livadiotis",
      "David J. McComas"
    ],
    "abstract": "Starting from the concept of entropy defect in thermodynamics, we construct\nthe entropy formulation of space plasmas, and then use it to develop a measure\nof their stationarity. In particular, we show that statistics of this entropy\nresults in two findings that improve our understanding of stationary and\nnonstationary systems: (i) variations of the Boltzmann-Gibbs (BG) entropy do\nnot exceed twice the value of the thermodynamic kappa, the parameter that\nprovides a measure of the entropy defect in both stationary and nonstationary\nstates, while becomes the shape parameter that labels the kappa distributions\nin stationary states; and (ii) the ratio of the deviation of the BG entropy\nwith kappa scales with the kappa deviation via a power-law, while the\nrespective exponent provides a stationarity deviation index (SDI), which\nmeasures the natural tendency of the system to depart from stationarity. We\nconfirm the validity of these findings in three different heliospheric plasma\ndatasets observed from three missions: (1) A solar energetic particle event,\nrecorded by the Integrated Science Investigation of the Sun instrument onboard\nParker Solar Probe; (2) Near Earth solar wind protons recorded by the Solar\nWind Experiment instrument onboard WIND; and (3) Plasma protons in the\nheliosheath, source of energetic neutral atoms recorded by IBEX. The full\nstrength and capability of the entropic deviation ratio and SDI can now be used\nby the space physics community for analyzing and characterizing the\nstationarity of space plasmas, as well as other researchers for analyzing any\nother correlated systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.13168v3",
    "published": "2025-02-17T07:27:49+00:00",
    "categories": [
      "physics.space-ph",
      "astro-ph.SR",
      "physics.plasm-ph"
    ],
    "primary_category": "physics.space-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11511v1",
    "title": "Signature of strange star as the central engine of GRB 240529A",
    "authors": [
      "Xiao Tian",
      "HouJun LÃ¼",
      "WenJun Tan",
      "ShaoLin Xiong",
      "HaoYu Yuan",
      "WenYuan Yu",
      "ShuQing Zhong",
      "WenLong Zhang",
      "EnWei Liang"
    ],
    "abstract": "GRB 240529A is a long-duration gamma-ray burst (GRB) whose light curve of\nprompt emission is composed of a triple-episode structure, separated by\nquiescent gaps of tens to hundreds of seconds. More interestingly, its X-ray\nlight curve of afterglow exhibits two-plateau emissions, namely, an internal\nplateau emission that is smoothly connected with a $\\sim t^{-0.1}$ segment and\nfollowed by a $\\sim t^{-2}$ power-law decay. The three episodes in the prompt\nemission, together with two plateau emissions in X-ray, are unique in the Swift\nera. They are very difficult to explain with the standard internal/external\nshock model by invoking a black hole central engine. However, it could be\nconsistent with the prediction of a supramassive magnetar as the central\nengine, the physical process of phase transition from magnetar to strange star,\nas well as the cooling and spin-down of the strange star. In this paper, we\npropose that the first- and second-episode emissions in the prompt $\\gamma-$ray\nof GRB 240529A are from the jet emission of a massive star collapsing into a\nsupramassive magnetar and the re-activity of central engine, respectively.\nThen, the third-episode emission of prompt is attributed to the phase\ntransition from a magnetar to a strange star. Finally, the first- and\nsecond-plateau emissions of the X-ray afterglow are powered by the cooling and\nspin-down of the strange star, respectively. The observational data of each\ncomponent of GRB 240529A are roughly coincident with the estimations of the\nabove physical picture.",
    "pdf_url": "http://arxiv.org/pdf/2502.11511v1",
    "published": "2025-02-17T07:26:22+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11510v2",
    "title": "Here Be Dragons: Bimodal posteriors arise from numerical integration error in longitudinal models",
    "authors": [
      "Tess O'Brien",
      "Matt Moores",
      "David Warton",
      "Daniel Falster"
    ],
    "abstract": "Longitudinal models with dynamics governed by differential equations may\nrequire numerical integration alongside parameter estimation. We have\nidentified a situation where the numerical integration introduces error in such\na way that it becomes a novel source of non-uniqueness in estimation. We obtain\ntwo very different sets of parameters, one of which is a good estimate of the\ntrue values and the other a very poor one. The two estimates have forward\nnumerical projections statistically indistinguishable from each other because\nof numerical error. In such cases, the posterior distribution for parameters is\nbimodal, with a dominant mode closer to the true parameter value, and a second\ncluster around the errant value. We demonstrate that multi-modality exists both\ntheoretically and empirically for an affine first order differential equation,\nthat a simulation workflow can test for evidence of the issue more generally,\nand that Markov Chain Monte Carlo sampling with a suitable solution can avoid\nbimodality. The issue of multi-modal posteriors arising from numerical error\nhas consequences for Bayesian inverse methods that rely on numerical\nintegration more broadly.",
    "pdf_url": "http://arxiv.org/pdf/2502.11510v2",
    "published": "2025-02-17T07:26:15+00:00",
    "categories": [
      "stat.OT",
      "stat.CO",
      "62-02"
    ],
    "primary_category": "stat.OT"
  },
  {
    "id": "http://arxiv.org/abs/2502.12215v2",
    "title": "Revisiting the Test-Time Scaling of o1-like Models: Do they Truly Possess Test-Time Scaling Capabilities?",
    "authors": [
      "Zhiyuan Zeng",
      "Qinyuan Cheng",
      "Zhangyue Yin",
      "Yunhua Zhou",
      "Xipeng Qiu"
    ],
    "abstract": "The advent of test-time scaling in large language models (LLMs), exemplified\nby OpenAI's o1 series, has advanced reasoning capabilities by scaling\ncomputational resource allocation during inference. While successors like QwQ,\nDeepseek-R1 (R1) and LIMO replicate these advancements, whether these models\ntruly possess test-time scaling capabilities remains underexplored. This study\nfound that longer CoTs of these o1-like models do not consistently enhance\naccuracy; in fact, correct solutions are often shorter than incorrect ones for\nthe same questions. Further investigation shows this phenomenon is closely\nrelated to models' self-revision capabilities - longer CoTs contain more\nself-revisions, which often lead to performance degradation. We then compare\nsequential and parallel scaling strategies on QwQ, R1 and LIMO, finding that\nparallel scaling achieves better coverage and scalability. Based on these\ninsights, we propose Shortest Majority Vote, a method that combines parallel\nscaling strategies with CoT length characteristics, significantly improving\nmodels' test-time scalability compared to conventional majority voting\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.12215v2",
    "published": "2025-02-17T07:21:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2503.05718v1",
    "title": "zScore: A Universal Decentralised Reputation System for the Blockchain Economy",
    "authors": [
      "Himanshu Udupi",
      "Ashutosh Sahoo",
      "Akshay S. P.",
      "Gurukiran S.",
      "Parag Paul",
      "Petrus C. Martens"
    ],
    "abstract": "Modern society functions on trust. The onchain economy, however, is built on\nthe founding principles of trustless peer-to-peer interactions in an\nadversarial environment without a centralised body of trust and needs a\nverifiable system to quantify credibility to minimise bad economic activity. We\nprovide a robust framework titled zScore, a core primitive for reputation\nderived from a wallet's onchain behaviour using state-of-the-art AI neural\nnetwork models combined with real-world credentials ported onchain through\nzkTLS. The initial results tested on retroactive data from lending protocols\nestablish a strong correlation between a good zScore and healthy borrowing and\nrepayment behaviour, making it a robust and decentralised alibi for\ncreditworthiness; we highlight significant improvements from previous attempts\nby protocols like Cred showcasing its robustness. We also present a list of\npossible applications of our system in Section 5, thereby establishing its\nutility in rewarding actual value creation while filtering noise and suspicious\nactivity and flagging malicious behaviour by bad actors.",
    "pdf_url": "http://arxiv.org/pdf/2503.05718v1",
    "published": "2025-02-17T07:19:04+00:00",
    "categories": [
      "cs.CY",
      "cs.CE",
      "cs.DC",
      "cs.LG",
      "K.4.4; I.2.11; C.2.4; K.4.2; H.3.5"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11509v1",
    "title": "DifCluE: Generating Counterfactual Explanations with Diffusion Autoencoders and modal clustering",
    "authors": [
      "Suparshva Jain",
      "Amit Sangroya",
      "Lovekesh Vig"
    ],
    "abstract": "Generating multiple counterfactual explanations for different modes within a\nclass presents a significant challenge, as these modes are distinct yet\nconverge under the same classification. Diffusion probabilistic models (DPMs)\nhave demonstrated a strong ability to capture the underlying modes of data\ndistributions. In this paper, we harness the power of a Diffusion Autoencoder\nto generate multiple distinct counterfactual explanations. By clustering in the\nlatent space, we uncover the directions corresponding to the different modes\nwithin a class, enabling the generation of diverse and meaningful\ncounterfactuals. We introduce a novel methodology, DifCluE, which consistently\nidentifies these modes and produces more reliable counterfactual explanations.\nOur experimental results demonstrate that DifCluE outperforms the current\nstate-of-the-art in generating multiple counterfactual explanations, offering a\nsignificant advancement in model interpretability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11509v1",
    "published": "2025-02-17T07:17:37+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11508v1",
    "title": "Chinese Spelling Correction: A Comprehensive Survey of Progress, Challenges, and Opportunities",
    "authors": [
      "Changchun Liu",
      "Kai Zhang",
      "Junzhe Jiang",
      "Zixiao Kong",
      "Qi Liu",
      "Enhong Chen"
    ],
    "abstract": "Chinese Spelling Correction (CSC) is a critical task in natural language\nprocessing, aimed at detecting and correcting spelling errors in Chinese text.\nThis survey provides a comprehensive overview of CSC, tracing its evolution\nfrom pre-trained language models to large language models, and critically\nanalyzing their respective strengths and weaknesses in this domain. Moreover,\nwe further present a detailed examination of existing benchmark datasets,\nhighlighting their inherent challenges and limitations. Finally, we propose\npromising future research directions, particularly focusing on leveraging the\npotential of LLMs and their reasoning capabilities for improved CSC\nperformance. To the best of our knowledge, this is the first comprehensive\nsurvey dedicated to the field of CSC. We believe this work will serve as a\nvaluable resource for researchers, fostering a deeper understanding of the\nfield and inspiring future advancements.",
    "pdf_url": "http://arxiv.org/pdf/2502.11508v1",
    "published": "2025-02-17T07:17:27+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11507v2",
    "title": "A Bi-failure Mode Model for Competing Risk Modeling with HMC-Driven Bayesian Framework",
    "authors": [
      "Badamasi Abba",
      "Mustapha Muhammad",
      "Muhammad Salihu Isa",
      "Jinbiao Wu"
    ],
    "abstract": "Bathtub failure rate (BFR) and roller-coaster failure rate (RCFR - a sequence\nof BFR and inverted BFR (IBFR)) shapes are among the non-monotone failure rate\nfunction (FRF) behaviors often observed in complex or competing risks (CR)\ndatasets. Recent studies have introduced varied bathtub failure rate models for\nreliability modeling of such datasets. However, limited attention is paid to\nthe reliability study of CR datasets characterized by RCFR. Motivated by this\ndrawback, this paper proposes the so-called Bi-Failure Modes (BFM) model for\nrobust reliability analysis of CR data exhibiting BFR, RCFR, and several other\nFRF shapes. The mean residual life function (MRLF) and cause-specific failure\nprobabilities are studied in detail. The fundamental reciprocal relationships\nbetween the MRLF and FRF are established. We propose the Hamiltonian Monte\nCarlo (HMC)-based Bayesian framework for estimating the BFM parameters and its\nreliability attributes to offer greater computational efficiency and faster\ninference. Two CR datasets from electrode voltage endurance life and electrical\nappliance tests, respectively, characterized by BFR and RCFR behaviors, are\nemployed to demonstrate the BFM adequacy. The recently introduced Bridge\nCriterion (BC) metric and other metrics are used to evaluate the BFM modeling\nperformance against five recent methodologies under the maximum likelihood\ntechnique. The BFM compatibility with the two datasets is also examined. The\nfindings portrayed the BFM's advantage over other competing candidates.",
    "pdf_url": "http://arxiv.org/pdf/2502.11507v2",
    "published": "2025-02-17T07:14:42+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.11506v1",
    "title": "Learning Surrogate Potential Mean Field Games via Gaussian Processes: A Data-Driven Approach to Ill-Posed Inverse Problems",
    "authors": [
      "Jingguo Zhang",
      "Xianjin Yang",
      "Chenchen Mou",
      "Chao Zhou"
    ],
    "abstract": "Mean field games (MFGs) describe the collective behavior of large populations\nof interacting agents. In this work, we tackle ill-posed inverse problems in\npotential MFGs, aiming to recover the agents' population, momentum, and\nenvironmental setup from limited, noisy measurements and partial observations.\nThese problems are ill-posed because multiple MFG configurations can explain\nthe same data, or different parameters can yield nearly identical observations.\nNonetheless, they remain crucial in practice for real-world scenarios where\ndata are inherently sparse or noisy, or where the MFG structure is not fully\ndetermined. Our focus is on finding surrogate MFGs that accurately reproduce\nthe observed data despite these challenges. We propose two Gaussian process\n(GP)-based frameworks: an inf-sup formulation and a bilevel approach. The\nchoice between them depends on whether the unknown parameters introduce\nconcavity in the objective. In the inf-sup framework, we use the linearity of\nGPs and their parameterization structure to maintain convex-concave properties,\nallowing us to apply standard convex optimization algorithms. In the bilevel\nframework, we employ a gradient-descent-based algorithm and introduce two\nmethods for computing the outer gradient. The first method leverages an\nexisting solver for the inner potential MFG and applies automatic\ndifferentiation, while the second adopts an adjoint-based strategy that\ncomputes the outer gradient independently of the inner solver. Our numerical\nexperiments show that when sufficient prior information is available, the\nunknown parameters can be accurately recovered. Otherwise, if prior information\nis limited, the inverse problem is ill-posed, but our frameworks can still\nproduce surrogate MFG models that closely match observed data.",
    "pdf_url": "http://arxiv.org/pdf/2502.11506v1",
    "published": "2025-02-17T07:14:30+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11505v2",
    "title": "Graph Neural Network-based Spectral Filtering Mechanism for Imbalance Classification in Network Digital Twin",
    "authors": [
      "Abubakar Isah",
      "Ibrahim Aliyu",
      "Sulaiman Muhammad Rashid",
      "Jaehyung Park",
      "Minsoo Hahn",
      "Jinsul Kim"
    ],
    "abstract": "Graph neural networks are gaining attention in fifth-generation (5G) core\nnetwork digital twins, which are data-driven complex systems with numerous\ncomponents. Analyzing these data can be challenging due to rare failure types,\nleading to imbalanced classification in multiclass settings. Digital twins of\n5G networks increasingly employ graph classification as the main method for\nidentifying failure types. However, the skewed distribution of failure\noccurrences is a significant class-imbalance problem that prevents practical\ngraph data mining. Previous studies have not sufficiently addressed this\ncomplex problem. This paper, proposes class-Fourier GNN (CF-GNN) that\nintroduces a class-oriented spectral filtering mechanism to ensure precise\nclassification by estimating a unique spectral filter for each class. This work\nemploys eigenvalue and eigenvector spectral filtering to capture and adapt to\nvariations in minority classes, ensuring accurate class-specific feature\ndiscrimination, and adept at graph representation learning for complex local\nstructures among neighbors in an end-to-end setting. The extensive experiments\ndemonstrate that the proposed CF-GNN could help create new techniques for\nenhancing classifiers and investigate the characteristics of the multiclass\nimbalanced data in a network digital twin system.",
    "pdf_url": "http://arxiv.org/pdf/2502.11505v2",
    "published": "2025-02-17T07:12:39+00:00",
    "categories": [
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11504v1",
    "title": "Accelerated Gradient-based Design Optimization Via Differentiable Physics-Informed Neural Operator: A Composites Autoclave Processing Case Study",
    "authors": [
      "Janak M. Patel",
      "Milad Ramezankhani",
      "Anirudh Deodhar",
      "Dagnachew Birru"
    ],
    "abstract": "Simulation and optimization are crucial for advancing the engineering design\nof complex systems and processes. Traditional optimization methods require\nsubstantial computational time and effort due to their reliance on\nresource-intensive simulations, such as finite element analysis, and the\ncomplexity of rigorous optimization algorithms. Data-agnostic AI-based\nsurrogate models, such as Physics-Informed Neural Operators (PINOs), offer a\npromising alternative to these conventional simulations, providing drastically\nreduced inference time, unparalleled data efficiency, and zero-shot\nsuper-resolution capability. However, the predictive accuracy of these models\nis often constrained to small, low-dimensional design spaces or systems with\nrelatively simple dynamics. To address this, we introduce a novel\nPhysics-Informed DeepONet (PIDON) architecture, which extends the capabilities\nof conventional neural operators to effectively model the nonlinear behavior of\ncomplex engineering systems across high-dimensional design spaces and a wide\nrange of dynamic design configurations. This new architecture outperforms\nexisting SOTA models, enabling better predictions across broader design spaces.\nLeveraging PIDON's differentiability, we integrate a gradient-based\noptimization approach using the Adam optimizer to efficiently determine optimal\ndesign variables. This forms an end-to-end gradient-based optimization\nframework that accelerates the design process while enhancing scalability and\nefficiency. We demonstrate the effectiveness of this framework in the\noptimization of aerospace-grade composites curing processes achieving a 3x\nspeedup in obtaining optimal design variables compared to gradient-free\nmethods. Beyond composites processing, the proposed model has the potential to\nbe used as a scalable and efficient optimization tool for broader applications\nin advanced engineering and digital twin systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11504v1",
    "published": "2025-02-17T07:11:46+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11503v2",
    "title": "Self-Homotopy Equivalence Group of an Elliptic Space and Its Embedding in general Linear Groups",
    "authors": [
      "Mahmoud Benkhalifa"
    ],
    "abstract": "For a rational elliptic space, this paper examines the relationship between\nits homotopy groups and its self-homotopy equivalence group. Moreover, we\ninvestigate how this group is embedded in general linear groups.",
    "pdf_url": "http://arxiv.org/pdf/2502.11503v2",
    "published": "2025-02-17T07:07:56+00:00",
    "categories": [
      "math.AT",
      "Group of homotopy self-equivalences, Whitehead exact sequence,\n  Sullivan model, Elliptic Spaces, Linear Groups"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11502v1",
    "title": "A non-trivial conservation law with a trivial characteristic",
    "authors": [
      "Kostya Druzhkov"
    ],
    "abstract": "We show that the conservation law of the overdetermined system $u_t - 4u_x^3\n- u_{xxx} = 0$, $u_y = 0$, associated with the characteristic $(u_{xy}, 0)$, is\nnon-trivial despite the characteristic vanishing on the system.",
    "pdf_url": "http://arxiv.org/pdf/2502.11502v1",
    "published": "2025-02-17T07:06:15+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.DG",
      "math.MP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11501v2",
    "title": "Token Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?",
    "authors": [
      "Zichen Wen",
      "Yifeng Gao",
      "Weijia Li",
      "Conghui He",
      "Linfeng Zhang"
    ],
    "abstract": "Multimodal large language models (MLLMs) have shown remarkable performance\nfor cross-modal understanding and generation, yet still suffer from severe\ninference costs. Recently, abundant works have been proposed to solve this\nproblem with token pruning, which identifies the redundant tokens in MLLMs and\nthen prunes them to reduce the computation and KV storage costs, leading to\nsignificant acceleration without training. While these methods claim efficiency\ngains, critical questions about their fundamental design and evaluation remain\nunanswered: Why do many existing approaches underperform even compared to naive\nrandom token selection? Are attention-based scoring sufficient for reliably\nidentifying redundant tokens? Is language information really helpful during\ntoken pruning? What makes a good trade-off between token importance and\nduplication? Are current evaluation protocols comprehensive and unbiased? The\nignorance of previous research on these problems hinders the long-term\ndevelopment of token pruning. In this paper, we answer these questions one by\none, providing insights into the design of future token pruning methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.11501v2",
    "published": "2025-02-17T07:05:36+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11500v1",
    "title": "California Earthquake Dataset for Machine Learning and Cloud Computing",
    "authors": [
      "Weiqiang Zhu",
      "Haoyu Wang",
      "Bo Rong",
      "Ellen Yu",
      "Stephane Zuzlewski",
      "Gabrielle Tepp",
      "Taka'aki Taira",
      "Julien Marty",
      "Allen Husker",
      "Richard M Allen"
    ],
    "abstract": "The San Andreas Fault system, known for its frequent seismic activity,\nprovides an extensive dataset for earthquake studies. The region's\nwell-instrumented seismic networks have been crucial in advancing research on\nearthquake statistics, physics, and subsurface Earth structures. In recent\nyears, earthquake data from California has become increasingly valuable for\ndeep learning applications, such as Generalized Phase Detection (GPD) for phase\ndetection and polarity determination, and PhaseNet for phase arrival-time\npicking. The continuous accumulation of data, particularly those manually\nlabeled by human analysts, serves as an essential resource for advancing both\nregional and global deep learning models. To support the continued development\nof machine learning and data mining studies, we have compiled a unified\nCalifornia Earthquake Event Dataset (CEED) that integrates seismic records from\nthe Northern California Earthquake Data Center (NCEDC) and the Southern\nCalifornia Earthquake Data Center (SCEDC). The dataset includes both\nautomatically and manually determined parameters such as earthquake origin\ntime, source location, P/S phase arrivals, first-motion polarities, and ground\nmotion intensity measurements. The dataset is organized in an event-based\nformat organized by year spanning from 2000 to 2024, facilitating\ncross-referencing with event catalogs and enabling continuous updates in future\nyears. This comprehensive open-access dataset is designed to support diverse\napplications including developing deep learning models, creating enhanced\ncatalog products, and research into earthquake processes, fault zone\nstructures, and seismic risks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11500v1",
    "published": "2025-02-17T07:03:59+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.18489v1",
    "title": "LLM4EFFI: Leveraging Large Language Models to Enhance Code Efficiency and Correctness",
    "authors": [
      "Tong Ye",
      "Weigang Huang",
      "Xuhong Zhang",
      "Tengfei Ma",
      "Peiyu Liu",
      "Jianwei Yin",
      "Wenhai Wang"
    ],
    "abstract": "Large Language Models (LLMs), particularly Code LLMs, have demonstrated\nimpressive performance in code generation. Current research primarily focuses\non the correctness of generated code, while efficiency remains less explored.\nRecent works have focused on modifying the initial version of the code to\nimprove its efficiency. However, such refinements are limited by the\nalgorithmic design and overall logic of the initial code, resulting in only\nincremental improvements. In contrast, when human developers write high-quality\ncode, they typically begin by designing several potential solutions at the\nlogical level, evaluating various algorithms and their complexities, and then\nproceeding to implement and optimize the solution. In this study, we introduce\n\\tool: \\uline{L}arge \\uline{L}anguage \\uline{M}odel for Code\n\\uline{Effi}ciency, a novel framework that enables LLMs to generate code that\nbalances both efficiency and correctness. Specifically, \\tool divides the\nefficiency optimization process into two domains: algorithmic exploration in\nthe logic domain and implementation optimization in the code domain. The\ncorrectness of the code is then guaranteed through a synthetic test case\nrefinement process. This approach, which prioritizes efficiency before ensuring\ncorrectness, offers a new paradigm for efficient code generation. Experiments\ndemonstrate that \\tool consistently improves both efficiency and correctness,\nachieving new state-of-the-art performance in code efficiency benchmarks across\nvarious LLM backbones.",
    "pdf_url": "http://arxiv.org/pdf/2502.18489v1",
    "published": "2025-02-17T07:01:18+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11499v1",
    "title": "Analysis of the data on differential cross sections and spin density matrix elements for $Î³p \\to Ï^0 p$",
    "authors": [
      "Ai-Chao Wang",
      "Neng-Chang Wei",
      "Fei Huang"
    ],
    "abstract": "The newly published data on spin density matrix elements from the GlueX\nCollaboration, along with the previously released differential cross-section\ndata from the CLAS Collaboration and the other two experiments for the $\\gamma\np \\to \\rho^0 p$ reaction, are systematically investigated using an effective\nLagrangian approach within the tree-level Born approximation. The model\ncombines contributions from $t$-channel meson exchanges ($\\pi$, $\\eta$, and\n$f_2$), $s$-channel nucleon ($N$) and nucleon resonance ($N^\\ast$) exchanges,\n$u$-channel $N$ exchange, and a generalized contact term to construct the\nscattering amplitudes. Regge propagators are employed for $t$-channel\namplitudes to incorporate the contributions from mesons with various spins\nlying on the same trajectories. The analysis shows that the background\ncontributions, dominated by the $f_2$-trajectory exchange, provide a\nsatisfactory description of the data in the high-energy and forward-angle\nregions. The inclusion of specific nucleon resonances, such as\n$N(2100)1/2^{+}$, $N(2060)5/2^{-}$, or $\\Delta(2000)5/2^{+}$, significantly\nimproves the description of the differential cross-section data at\nnear-perpendicular scattering angles in the low-energy region. Predictions of\nphoton beam and target nucleon asymmetries are provided, offering valuable\ninsights to discriminate reaction mechanisms when corresponding data become\navailable in the future.",
    "pdf_url": "http://arxiv.org/pdf/2502.11499v1",
    "published": "2025-02-17T07:00:28+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11498v1",
    "title": "Direct and inverse problems for a third-order self-adjoint differential operator with non-local potential functions",
    "authors": [
      "Yixuan Liu",
      "Mingming Zhang"
    ],
    "abstract": "The direct and inverse problems for a third-order self-adjoint differential\noperator with non-local potential functions are considered. Firstly, the\nmultiplicity for eigenvalues of the operator is analyzed, and it is proved that\nthe differential operator has simple eigenvalues, except for finitely many\neigenvalues of multiplicity two or three. Then the expressions of\neigenfunctions and resolvent are obtained. Finally, the inverse problem for\nrecovering non-local potential functions is solved.",
    "pdf_url": "http://arxiv.org/pdf/2502.11498v1",
    "published": "2025-02-17T07:00:09+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11497v2",
    "title": "Geometry Aware Passthrough Mitigates Cybersickness",
    "authors": [
      "Trishia El Chemaly",
      "Mohit Goyal",
      "Tinglin Duan",
      "Vrushank Phadnis",
      "Sakar Khattar",
      "Bjorn Vlaskamp",
      "Achin Kulshrestha",
      "Eric Lee Turner",
      "Aveek Purohit",
      "Gregory Neiswander",
      "Konstantine Tsotsos"
    ],
    "abstract": "Virtual Reality headsets isolate users from the real-world by restricting\ntheir perception to the virtual-world. Video See-Through (VST) headsets address\nthis by utilizing world-facing cameras to create Augmented Reality experiences.\nHowever, directly displaying camera feeds causes visual discomfort and\ncybersickness due to the inaccurate perception of scale and exaggerated motion\nparallax. This paper demonstrates the potential of geometry aware passthrough\nsystems in mitigating cybersickness through accurate depth perception. We first\npresent a methodology to benchmark and compare passthrough algorithms.\nFurthermore, we design a protocol to quantitatively measure cybersickness\nexperienced by users in VST headsets. Using this protocol, we conduct a user\nstudy to compare direct passthrough and geometry aware passthrough systems. To\nthe best of our knowledge, our study is the first one to reveal significantly\nreduced nausea, disorientation, and total scores of cybersickness with geometry\naware passthrough. It also uncovers several potential avenues to further\nmitigate visually-induced discomfort.",
    "pdf_url": "http://arxiv.org/pdf/2502.11497v2",
    "published": "2025-02-17T06:58:59+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11496v1",
    "title": "New Red Supergiant Stars in the other side of our Galaxy",
    "authors": [
      "Lin Zhang",
      "Bingqiu Chen",
      "Yi Ren",
      "Zehao Zhang",
      "Jian Gao",
      "Biwei Jiang"
    ],
    "abstract": "Red supergiant stars (RSGs) are massive stars in a late stage of evolution,\ncrucial for understanding stellar life cycles and Galactic structure. However,\nRSGs on the far side of our Galaxy have been underexplored due to observational\nchallenges. In this study, we introduce a novel method and present a new\ncatalogue comprising 474 RSGs situated on the far side of the Milky Way,\nsourced from the OGLE-III catalogue of Variable Stars (OIII-CVS). The\nidentification of these RSGs was made possible by analyzing the granulation\nparameters extracted from OGLE I-band time-series data and the stellar\nparameters from Gaia DR3. Additionally, we estimate the distances to these RSGs\nusing an empirical relation between their characteristic amplitude, absolute\nmagnitude, and intrinsic color, achieving a distance uncertainty of 13%. These\nnewly identified RSGs are distributed at Galactocentric distances between 0 and\n30kpc, and reside roughly 1 to 4kpc above and below the Galactic plane. This\ndistribution provides new insights into the structure of the Milky Way,\nparticularly at its outer boundaries. Our results reveal that the vertical\ndistribution of these RSGs is consistent with the flare structure of the\nGalactic disk, confirming that the far side of the Milky Way exhibits a similar\nflaring pattern to the near side. This catalogue offers a valuable resource for\nfuture detailed studies of RSGs and contributes to a more comprehensive\nunderstanding of the Galactic structure and stellar evolution.",
    "pdf_url": "http://arxiv.org/pdf/2502.11496v1",
    "published": "2025-02-17T06:56:52+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11495v1",
    "title": "Balanced Multi-Factor In-Context Learning for Multilingual Large Language Models",
    "authors": [
      "Masahiro Kaneko",
      "Alham Fikri Aji",
      "Timothy Baldwin"
    ],
    "abstract": "Multilingual large language models (MLLMs) are able to leverage in-context\nlearning (ICL) to achieve high performance by leveraging cross-lingual\nknowledge transfer without parameter updates. However, their effectiveness is\nhighly sensitive to example selection, particularly in multilingual settings.\nBased on the findings of existing work, three key factors influence\nmultilingual ICL: (1) semantic similarity, (2) linguistic alignment, and (3)\nlanguage-specific performance. However, existing approaches address these\nfactors independently, without explicitly disentangling their combined impact,\nleaving optimal example selection underexplored. To address this gap, we\npropose balanced multi-factor ICL (\\textbf{BMF-ICL}), a method that quantifies\nand optimally balances these factors for improved example selection.\nExperiments on mCSQA and TYDI across four MLLMs demonstrate that BMF-ICL\noutperforms existing methods. Further analysis highlights the importance of\nincorporating all three factors and the importance of selecting examples from\nmultiple languages.",
    "pdf_url": "http://arxiv.org/pdf/2502.11495v1",
    "published": "2025-02-17T06:56:33+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11494v2",
    "title": "Stop Looking for Important Tokens in Multimodal Language Models: Duplication Matters More",
    "authors": [
      "Zichen Wen",
      "Yifeng Gao",
      "Shaobo Wang",
      "Junyuan Zhang",
      "Qintong Zhang",
      "Weijia Li",
      "Conghui He",
      "Linfeng Zhang"
    ],
    "abstract": "Vision tokens in multimodal large language models often dominate huge\ncomputational overhead due to their excessive length compared to linguistic\nmodality. Abundant recent methods aim to solve this problem with token pruning,\nwhich first defines an importance criterion for tokens and then prunes the\nunimportant vision tokens during inference. However, in this paper, we show\nthat the importance is not an ideal indicator to decide whether a token should\nbe pruned. Surprisingly, it usually results in inferior performance than random\ntoken pruning and leading to incompatibility to efficient attention computation\noperators.Instead, we propose DART (Duplication-Aware Reduction of Tokens),\nwhich prunes tokens based on its duplication with other tokens, leading to\nsignificant and training-free acceleration. Concretely, DART selects a small\nsubset of pivot tokens and then retains the tokens with low duplication to the\npivots, ensuring minimal information loss during token pruning. Experiments\ndemonstrate that DART can prune 88.9% vision tokens while maintaining\ncomparable performance, leading to a 1.99$\\times$ and 2.99$\\times$ speed-up in\ntotal time and prefilling stage, respectively, with good compatibility to\nefficient attention operators. Our codes are available at\nhttps://github.com/ZichenWen1/DART.",
    "pdf_url": "http://arxiv.org/pdf/2502.11494v2",
    "published": "2025-02-17T06:56:28+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11493v1",
    "title": "DAST: Context-Aware Compression in LLMs via Dynamic Allocation of Soft Tokens",
    "authors": [
      "Shaoshen Chen",
      "Yangning Li",
      "Zishan Xu",
      "Yinghui Li",
      "Xin Su",
      "Zifei Shan",
      "Hai-tao Zheng"
    ],
    "abstract": "Large Language Models (LLMs) face computational inefficiencies and redundant\nprocessing when handling long context inputs, prompting a focus on compression\ntechniques. While existing semantic vector-based compression methods achieve\npromising performance, these methods fail to account for the intrinsic\ninformation density variations between context chunks, instead allocating soft\ntokens uniformly across context chunks. This uniform distribution inevitably\ndiminishes allocation to information-critical regions. To address this, we\npropose Dynamic Allocation of Soft Tokens (DAST), a simple yet effective method\nthat leverages the LLM's intrinsic understanding of contextual relevance to\nguide compression. DAST combines perplexity-based local information with\nattention-driven global information to dynamically allocate soft tokens to the\ninformative-rich chunks, enabling effective, context-aware compression.\nExperimental results across multiple benchmarks demonstrate that DAST surpasses\nstate-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.11493v1",
    "published": "2025-02-17T06:55:13+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11492v3",
    "title": "Why Vision Language Models Struggle with Visual Arithmetic? Towards Enhanced Chart and Geometry Understanding",
    "authors": [
      "Kung-Hsiang Huang",
      "Can Qin",
      "Haoyi Qiu",
      "Philippe Laban",
      "Shafiq Joty",
      "Caiming Xiong",
      "Chien-Sheng Wu"
    ],
    "abstract": "Vision Language Models (VLMs) have achieved remarkable progress in multimodal\ntasks, yet they often struggle with visual arithmetic, seemingly simple\ncapabilities like object counting or length comparison, which are essential for\nrelevant complex tasks like chart understanding and geometric reasoning. In\nthis work, we first investigate the root causes of this deficiency through a\nsuite of probing tasks focusing on basic visual arithmetic. Our analysis\nreveals that while pre-trained vision encoders typically capture sufficient\ninformation, the text decoder often fails to decode it correctly for arithmetic\nreasoning. To address this, we propose CogAlign, a novel post-training strategy\ninspired by Piaget's theory of cognitive development. CogAlign trains VLMs to\nrecognize invariant properties under visual transformations. We demonstrate\nthat this approach significantly improves the performance of three diverse VLMs\non our proposed probing tasks. Furthermore, CogAlign enhances performance by an\naverage of 4.6% on CHOCOLATE and 2.9% on MATH-VISION, outperforming or matching\nsupervised fine-tuning methods while requiring only 60% less training data.\nThese results highlight the effectiveness and generalizability of CogAlign in\nimproving fundamental visual arithmetic capabilities and their transfer to\ndownstream tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11492v3",
    "published": "2025-02-17T06:54:49+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11491v2",
    "title": "Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering",
    "authors": [
      "Runxuan Liu",
      "Bei Luo",
      "Jiaqi Li",
      "Baoxin Wang",
      "Ming Liu",
      "Dayong Wu",
      "Shijin Wang",
      "Bing Qin"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in natural\nlanguage processing. However, in knowledge graph question answering tasks\n(KGQA), there remains the issue of answering questions that require multi-hop\nreasoning. Existing methods rely on entity vector matching, but the purpose of\nthe question is abstract and difficult to match with specific entities. As a\nresult, it is difficult to establish reasoning paths to the purpose, which\nleads to information loss and redundancy. To address this issue, inspired by\nhuman reverse thinking, we propose Ontology-Guided Reverse Thinking (ORT), a\nnovel framework that constructs reasoning paths from purposes back to\nconditions. ORT operates in three key phases: (1) using LLM to extract purpose\nlabels and condition labels, (2) constructing label reasoning paths based on\nthe KG ontology, and (3) using the label reasoning paths to guide knowledge\nretrieval. Experiments on the WebQSP and CWQ datasets show that ORT achieves\nstate-of-the-art performance and significantly enhances the capability of LLMs\nfor KGQA.",
    "pdf_url": "http://arxiv.org/pdf/2502.11491v2",
    "published": "2025-02-17T06:53:15+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11490v1",
    "title": "GPU-accelerated Multi-relational Parallel Graph Retrieval for Web-scale Recommendations",
    "authors": [
      "Zhuoning Guo",
      "Guangxing Chen",
      "Qian Gao",
      "Xiaochao Liao",
      "Jianjia Zheng",
      "Lu Shen",
      "Hao Liu"
    ],
    "abstract": "Web recommendations provide personalized items from massive catalogs for\nusers, which rely heavily on retrieval stages to trade off the effectiveness\nand efficiency of selecting a small relevant set from billion-scale candidates\nin online digital platforms. As one of the largest Chinese search engine and\nnews feed providers, Baidu resorts to Deep Neural Network (DNN) and graph-based\nApproximate Nearest Neighbor Search (ANNS) algorithms for accurate relevance\nestimation and efficient search for relevant items. However, current retrieval\nat Baidu fails in comprehensive user-item relational understanding due to\ndissected interaction modeling, and performs inefficiently in large-scale\ngraph-based ANNS because of suboptimal traversal navigation and the GPU\ncomputational bottleneck under high concurrency. To this end, we propose a\nGPU-accelerated Multi-relational Parallel Graph Retrieval (GMP-GR) framework to\nachieve effective yet efficient retrieval in web-scale recommendations. First,\nwe propose a multi-relational user-item relevance metric learning method that\nunifies diverse user behaviors through multi-objective optimization and employs\na self-covariant loss to enhance pathfinding performance. Second, we develop a\nhierarchical parallel graph-based ANNS to boost graph retrieval throughput,\nwhich conducts breadth-depth-balanced searches on a large-scale item graph and\ncost-effectively handles irregular neural computation via adaptive aggregation\non GPUs. In addition, we integrate system optimization strategies in the\ndeployment of GMP-GR in Baidu. Extensive experiments demonstrate the\nsuperiority of GMP-GR in retrieval accuracy and efficiency. Deployed across\nmore than twenty applications at Baidu, GMP-GR serves hundreds of millions of\nusers with a throughput exceeding one hundred million requests per second.",
    "pdf_url": "http://arxiv.org/pdf/2502.11490v1",
    "published": "2025-02-17T06:49:34+00:00",
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.IR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.15778v1",
    "title": "One for All: A General Framework of LLMs-based Multi-Criteria Decision Making on Human Expert Level",
    "authors": [
      "Hui Wang",
      "Fafa Zhang",
      "Chaoxu Mu"
    ],
    "abstract": "Multi-Criteria Decision Making~(MCDM) is widely applied in various fields,\nusing quantitative and qualitative analyses of multiple levels and attributes\nto support decision makers in making scientific and rational decisions in\ncomplex scenarios. However, traditional MCDM methods face bottlenecks in\nhigh-dimensional problems. Given the fact that Large Language Models~(LLMs)\nachieve impressive performance in various complex tasks, but limited work\nevaluates LLMs in specific MCDM problems with the help of human domain experts,\nwe further explore the capability of LLMs by proposing an LLM-based evaluation\nframework to automatically deal with general complex MCDM problems. Within the\nframework, we assess the performance of various typical open-source models, as\nwell as commercial models such as Claude and ChatGPT, on 3 important\napplications, these models can only achieve around 60\\% accuracy rate compared\nto the evaluation ground truth. Upon incorporation of Chain-of-Thought or\nfew-shot prompting, the accuracy rates rise to around 70\\%, and highly depend\non the model. In order to further improve the performance, a LoRA-based\nfine-tuning technique is employed. The experimental results show that the\naccuracy rates for different applications improve significantly to around 95\\%,\nand the performance difference is trivial between different models, indicating\nthat LoRA-based fine-tuned LLMs exhibit significant and stable advantages in\naddressing MCDM tasks and can provide human-expert-level solutions to a wide\nrange of MCDM challenges.",
    "pdf_url": "http://arxiv.org/pdf/2502.15778v1",
    "published": "2025-02-17T06:47:20+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11489v2",
    "title": "The Nature of Gravitational Wave Events with Host Environment Escape Velocities",
    "authors": [
      "Guo-Peng Li",
      "Xi-Long Fan"
    ],
    "abstract": "We propose a novel method to probe the parameters and origin channels of\ngravitational wave events using the escape velocities of their host\nenvironments. This method could lead to more convergent posterior distributions\noffering additional insights into the physical properties, formation, and\nevolution of the sources. The method provides more accurate parameter\nestimation for events that represent previous mergers in the hierarchical\ntriple merger scenario and is valuable for the search for such mergers with\nthird-generation ground-based detectors. To demonstrate this approach, we take\nsix recently identified events in LIGO-Virgo-KAGRA data, considered as\npotential previous mergers in hierarchical triple mergers, as examples. The use\nof escape velocities results in posterior spin distributions that are\nconcentrated near zero, aligning with the expected birth spins of\nfirst-generation black holes formed from the collapse of stars. The uncertainty\nin the posterior primary mass distribution is significantly reduced comparing\nwith the LIGO-Virgo-KAGRA distributions, especially for events modeled under\nthe assumption of a globular cluster origin scenario. We rule out the\npossibility that GW190512, GW170729, and GW190708 originates from globular\nclusters as previous mergers in the hierarchical triple merger scenario.",
    "pdf_url": "http://arxiv.org/pdf/2502.11489v2",
    "published": "2025-02-17T06:46:40+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA",
      "astro-ph.SR",
      "gr-qc"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11488v1",
    "title": "Interference patterns for simple lens models in wave-optics regime",
    "authors": [
      "Ashish Kumar Meena"
    ],
    "abstract": "This work studies interference patterns created by simple lens models (point\nmass, Chang-Refsdal, and binary lens) in the wave optics regime, primarily in\nthe context of lensing of gravitational waves (GWs) in the LIGO band at\nfrequencies around 100 Hz. We study how the interference patterns behave close\nto the caustic curves which mark the high magnification regions in conventional\ngeometric optics. In addition, we also look at the formation of highly\nde-amplified regions in the amplification maps close to caustics and how they\ndiffer under wave and geometric optics. We see that for a source close to\ncaustics, the oscillations in the amplification factor (their amplitude and\nlocation of crests and troughs) can differ significantly in wave optics\ncompared to geometric optics. As we move away from caustics, the wave optics\namplification factor starts to converge towards geometric optics one,\nespecially the frequencies at which crests and through occur in the\namplification factor, although the amplitude of these oscillations can still be\nconsiderably different. For Chang-Refsdal and binary lens with ${\\sim}100\\:{\\rm\nM_\\odot}-200\\:{\\rm M_\\odot}$ can introduce significant de-amplification at\nfrequencies ${\\sim}100$ Hz when the source is close to caustics which may help\nus distinguish such lenses from the point mass lens.",
    "pdf_url": "http://arxiv.org/pdf/2502.11488v1",
    "published": "2025-02-17T06:45:02+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11487v1",
    "title": "Non-Binary LDPC Arithmetic Error Correction For Processing-in-Memory",
    "authors": [
      "Daijing Shi",
      "Yihang Zhu",
      "Anjunyi Fan",
      "Yaoyu Tao",
      "Yuchao Yang",
      "Bonan Yan"
    ],
    "abstract": "Processing-in-memory (PIM) based on emerging devices such as memristors is\nmore vulnerable to noise than traditional memories, due to the physical\nnon-idealities and complex operations in analog domains. To ensure high\nreliability, efficient error-correcting code (ECC) is highly desired. However,\nstate-of-the-art ECC schemes for PIM suffer drawbacks including dataflow\ninterruptions, low code rates, and limited error correction patterns. In this\nwork, we propose non-binary low-density parity-check (NB-LDPC) error correction\nrunning over the Galois field. Such NB-LDPC scheme with a long word length of\n1024 bits can correct up to 8-bit errors with a code rate over 88%. Nonbinary\nGF operations can support both memory mode and PIM mode even with multi-level\nmemory cells. We fabricate a 40nm prototype PIM chip equipped with our proposed\nNB-LDPC scheme for validation purposes. Experiments show that PIM with NB-LDPC\nerror correction demonstrates up to 59.65 times bit error rate (BER)\nimprovement over the original PIM without such error correction. The test chip\ndelivers 2.978 times power efficiency enhancement over prior works.",
    "pdf_url": "http://arxiv.org/pdf/2502.11487v1",
    "published": "2025-02-17T06:44:21+00:00",
    "categories": [
      "cs.AR",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11486v2",
    "title": "Anti-Degeneracy Scheme for Lidar SLAM based on Particle Filter in Geometry Feature-Less Environments",
    "authors": [
      "Yanbin Li",
      "Wei Zhang",
      "Zhiguo Zhang",
      "Xiaogang Shi",
      "Ziruo Li",
      "Mingming Zhang",
      "Hongping Xie",
      "Wenzheng Chi"
    ],
    "abstract": "Simultaneous localization and mapping (SLAM) based on particle filtering has\nbeen extensively employed in indoor scenarios due to its high efficiency.\nHowever, in geometry feature-less scenes, the accuracy is severely reduced due\nto lack of constraints. In this article, we propose an anti-degeneracy system\nbased on deep learning. Firstly, we design a scale-invariant linear mapping to\nconvert coordinates in continuous space into discrete indexes, in which a data\naugmentation method based on Gaussian model is proposed to ensure the model\nperformance by effectively mitigating the impact of changes in the number of\nparticles on the feature distribution. Secondly, we develop a degeneracy\ndetection model using residual neural networks (ResNet) and transformer which\nis able to identify degeneracy by scrutinizing the distribution of the particle\npopulation. Thirdly, an adaptive anti-degeneracy strategy is designed, which\nfirst performs fusion and perturbation on the resample process to provide rich\nand accurate initial values for the pose optimization, and use a hierarchical\npose optimization combining coarse and fine matching, which is able to\nadaptively adjust the optimization frequency and the sensor trustworthiness\naccording to the degree of degeneracy, in order to enhance the ability of\nsearching the global optimal pose. Finally, we demonstrate the optimality of\nthe model, as well as the improvement of the image matrix method and GPU on the\ncomputation time through ablation experiments, and verify the performance of\nthe anti-degeneracy system in different scenarios through simulation\nexperiments and real experiments. This work has been submitted to IEEE for\npublication. Copyright may be transferred without notice, after which this\nversion may no longer be available.",
    "pdf_url": "http://arxiv.org/pdf/2502.11486v2",
    "published": "2025-02-17T06:42:28+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11485v1",
    "title": "Non-uniqueness of Regular Solutions for Incompressible Static Euler Equations with Given Boundary Conditions and Turbulent Global Solutions of Incompressible Navier-Stokes Equations",
    "authors": [
      "Yongqian Han"
    ],
    "abstract": "The incompressible Navier-Stokes equations and static Euler equations are\nconsidered. We find that there exist infinite non-trivial regular solutions of\nincompressible static Euler equations with given boundary conditions. Moreover\nthere exist random solutions of incompressible static Euler equations. Provided\nReynolds number is large enough and time variable $t$ goes to infinity, these\nrandom solutions of static Euler equations are the path limits of corresponding\nNavier-Stokes flows. But the double limits of these Navier-Stokes flows do not\nexist. These phenomena reveal randomness and turbulence of incompressible\nfluids. Therefore these solutions are called turbulent solutions. Here some\ntyping models without Prandtl layer are given.",
    "pdf_url": "http://arxiv.org/pdf/2502.11485v1",
    "published": "2025-02-17T06:39:46+00:00",
    "categories": [
      "math.AP",
      "35Q30, 76D05, 76F02, 37L20"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11484v2",
    "title": "Dictionary-Learning-Based Data Pruning for System Identification",
    "authors": [
      "Tingna Wang",
      "Sikai Zhang",
      "Mingming Song",
      "Limin Sun"
    ],
    "abstract": "System identification is normally involved in augmenting time series data by\ntime shifting and nonlinearisation (e.g., polynomial basis), both of which\nintroduce redundancy in features and samples. Many research works focus on\nreducing redundancy feature-wise, while less attention is paid to sample-wise\nredundancy. This paper proposes a novel data pruning method, called mini-batch\nFastCan, to reduce sample-wise redundancy based on dictionary learning. Time\nseries data is represented by some representative samples, called atoms, via\ndictionary learning. The useful samples are selected based on their correlation\nwith the atoms. The method is tested on one simulated dataset and two benchmark\ndatasets. The R-squared between the coefficients of models trained on the full\ndatasets and the coefficients of models trained on pruned datasets is adopted\nto evaluate the performance of data pruning methods. It is found that the\nproposed method significantly outperforms the random pruning method.",
    "pdf_url": "http://arxiv.org/pdf/2502.11484v2",
    "published": "2025-02-17T06:38:43+00:00",
    "categories": [
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11483v1",
    "title": "No-regret incentive-compatible online learning under exact truthfulness with non-myopic experts",
    "authors": [
      "Junpei Komiyama",
      "Nishant A. Mehta",
      "Ali Mortazavi"
    ],
    "abstract": "We study an online forecasting setting in which, over $T$ rounds, $N$\nstrategic experts each report a forecast to a mechanism, the mechanism selects\none forecast, and then the outcome is revealed. In any given round, each expert\nhas a belief about the outcome, but the expert wishes to select its report so\nas to maximize the total number of times it is selected. The goal of the\nmechanism is to obtain low belief regret: the difference between its cumulative\nloss (based on its selected forecasts) and the cumulative loss of the best\nexpert in hindsight (as measured by the experts' beliefs). We consider exactly\ntruthful mechanisms for non-myopic experts, meaning that truthfully reporting\nits belief strictly maximizes the expert's subjective probability of being\nselected in any future round. Even in the full-information setting, it is an\nopen problem to obtain the first no-regret exactly truthful mechanism in this\nsetting. We develop the first no-regret mechanism for this setting via an\nonline extension of the Independent-Event Lotteries Forecasting Competition\nMechanism (I-ELF). By viewing this online I-ELF as a novel instance of Follow\nthe Perturbed Leader (FPL) with noise based on random walks with loss-dependent\nperturbations, we obtain $\\tilde{O}(\\sqrt{T N})$ regret. Our results are fueled\nby new tail bounds for Poisson binomial random variables that we develop. We\nextend our results to the bandit setting, where we give an exactly truthful\nmechanism obtaining $\\tilde{O}(T^{2/3} N^{1/3})$ regret; this is the first\nno-regret result even among approximately truthful mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11483v1",
    "published": "2025-02-17T06:36:45+00:00",
    "categories": [
      "cs.LG",
      "cs.GT",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11482v1",
    "title": "DATA: Decomposed Attention-based Task Adaptation for Rehearsal-Free Continual Learning",
    "authors": [
      "Huanxuan Liao",
      "Shizhu He",
      "Yupu Hao",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Continual learning (CL) is essential for Large Language Models (LLMs) to\nadapt to evolving real-world demands, yet they are susceptible to catastrophic\nforgetting (CF). While traditional CF solutions rely on expensive data\nrehearsal, recent rehearsal-free methods employ model-based and\nregularization-based strategies to address this issue. However, these\napproaches often neglect the model's plasticity, which is crucial to achieving\noptimal performance on newly learned tasks. Consequently, a key challenge in CL\nis striking a balance between preserving plasticity and mitigating CF. To\ntackle this challenge, we propose the $\\textbf{D}$ecomposed\n$\\textbf{A}$ttention-based $\\textbf{T}$ask $\\textbf{A}$daptation (DATA), which\nexplicitly decouples and learns both task-specific and task-shared knowledge\nusing high-rank and low-rank task adapters (e.g., LoRAs). For new tasks, DATA\ndynamically adjusts the weights of adapters of different ranks based on their\nrelevance and distinction from previous tasks, allowing the model to acquire\nnew task-specific skills while effectively retaining previously learned\nknowledge. Specifically, we implement a decomposed component weighting strategy\ncomprising learnable components that collectively generate attention-based\nweights, allowing the model to integrate and utilize diverse knowledge from\neach DATA. Extensive experiments on three widely used benchmarks demonstrate\nthat our proposed method achieves state-of-the-art performance. Notably, our\napproach significantly enhances model plasticity and mitigates CF by extending\nlearnable components and employing stochastic restoration during training\niterations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11482v1",
    "published": "2025-02-17T06:35:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11481v1",
    "title": "Variable-frame CNNLSTM for Breast Nodule Classification using Ultrasound Videos",
    "authors": [
      "Xiangxiang Cui",
      "Zhongyu Li",
      "Xiayue Fan",
      "Peng Huang",
      "Ying Wang",
      "Meng Yang",
      "Shi Chang",
      "Jihua Zhu"
    ],
    "abstract": "The intersection of medical imaging and artificial intelligence has become an\nimportant research direction in intelligent medical treatment, particularly in\nthe analysis of medical images using deep learning for clinical diagnosis.\nDespite the advances, existing keyframe classification methods lack extraction\nof time series features, while ultrasonic video classification based on\nthree-dimensional convolution requires uniform frame numbers across patients,\nresulting in poor feature extraction efficiency and model classification\nperformance. This study proposes a novel video classification method based on\nCNN and LSTM, introducing NLP's long and short sentence processing scheme into\nvideo classification for the first time. The method reduces CNN-extracted image\nfeatures to 1x512 dimension, followed by sorting and compressing feature\nvectors for LSTM training. Specifically, feature vectors are sorted by patient\nvideo frame numbers and populated with padding value 0 to form variable\nbatches, with invalid padding values compressed before LSTM training to\nconserve computing resources. Experimental results demonstrate that our\nvariable-frame CNNLSTM method outperforms other approaches across all metrics,\nshowing improvements of 3-6% in F1 score and 1.5% in specificity compared to\nkeyframe methods. The variable-frame CNNLSTM also achieves better accuracy and\nprecision than equal-frame CNNLSTM. These findings validate the effectiveness\nof our approach in classifying variable-frame ultrasound videos and suggest\npotential applications in other medical imaging modalities.",
    "pdf_url": "http://arxiv.org/pdf/2502.11481v1",
    "published": "2025-02-17T06:35:37+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11480v1",
    "title": "Enhancing Offline Model-Based RL via Active Model Selection: A Bayesian Optimization Perspective",
    "authors": [
      "Yu-Wei Yang",
      "Yun-Ming Chan",
      "Wei Hung",
      "Xi Liu",
      "Ping-Chun Hsieh"
    ],
    "abstract": "Offline model-based reinforcement learning (MBRL) serves as a competitive\nframework that can learn well-performing policies solely from pre-collected\ndata with the help of learned dynamics models. To fully unleash the power of\noffline MBRL, model selection plays a pivotal role in determining the dynamics\nmodel utilized for downstream policy learning. However, offline MBRL\nconventionally relies on validation or off-policy evaluation, which are rather\ninaccurate due to the inherent distribution shift in offline RL. To tackle\nthis, we propose BOMS, an active model selection framework that enhances model\nselection in offline MBRL with only a small online interaction budget, through\nthe lens of Bayesian optimization (BO). Specifically, we recast model selection\nas BO and enable probabilistic inference in BOMS by proposing a novel\nmodel-induced kernel, which is theoretically grounded and computationally\nefficient. Through extensive experiments, we show that BOMS improves over the\nbaseline methods with a small amount of online interaction comparable to only\n$1\\%$-$2.5\\%$ of offline training data on various RL tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11480v1",
    "published": "2025-02-17T06:34:58+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11479v1",
    "title": "High Quality Single Crystal of Kitaev Spin Liquid Candidate Material RuBr3 Synthesized under High Pressure",
    "authors": [
      "Bowen Zhang",
      "Xiangjun Li",
      "Limin Yan",
      "Wenbo Li",
      "Nana Li",
      "Jianfa Zhao",
      "Xiaobing Liu",
      "Shun-Li Yu",
      "Zhiwei Hu",
      "Wenge Yang",
      "Runze Yu"
    ],
    "abstract": "Kitaev quantum spin liquids have attracted significant attention in condensed\nmatter physics over the past decade. To understand their emergent quantum\nphenomena, high-quality single crystals of substantial size are essential.\nHere, we report the synthesis of single crystals of the Kitaev quantum spin\nliquid candidate RuBr3, achieving millimeter-sized crystals through a self-flux\nmethod under high pressure and high temperature conditions. The crystals\nexhibit well-defined cleavage planes with a lustrous appearance. Transport\ncharacterizations exhibit a narrow band-gap semiconducting behavior with 0.13\neV and 0.11 eV band-gap in ab plane and along c axis, respectively. Magnetic\nmeasurement shows a transition to antiferromagnetic (AFM) state at\napproximately 29 K both in ab plane and along c axis. Notably, the N\\'eel\ntemperature increases to 34 K with an applied magnetic field of up to 7 T in\nthe ab plane, but without any change along c axis. The large size and high\nquality of RuBr3 single crystals provide a valuable platform for investigating\nvarious interactions, particularly the Kitaev interaction, and for elucidating\nthe intrinsic physical properties of Kitaev quantum spin liquids.",
    "pdf_url": "http://arxiv.org/pdf/2502.11479v1",
    "published": "2025-02-17T06:30:30+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11478v2",
    "title": "TAPS: Throat and Acoustic Paired Speech Dataset for Deep Learning-Based Speech Enhancement",
    "authors": [
      "Yunsik Kim",
      "Yonghun Song",
      "Yoonyoung Chung"
    ],
    "abstract": "In high-noise environments such as factories, subways, and busy streets,\ncapturing clear speech is challenging. Throat microphones can offer a solution\nbecause of their inherent noise-suppression capabilities; however, the passage\nof sound waves through skin and tissue attenuates high-frequency information,\nreducing speech clarity. Recent deep learning approaches have shown promise in\nenhancing throat microphone recordings, but further progress is constrained by\nthe lack of a standard dataset. Here, we introduce the Throat and Acoustic\nPaired Speech (TAPS) dataset, a collection of paired utterances recorded from\n60 native Korean speakers using throat and acoustic microphones. Furthermore,\nan optimal alignment approach was developed and applied to address the inherent\nsignal mismatch between the two microphones. We tested three baseline deep\nlearning models on the TAPS dataset and found mapping-based approaches to be\nsuperior for improving speech quality and restoring content. These findings\ndemonstrate the TAPS dataset's utility for speech enhancement tasks and support\nits potential as a standard resource for advancing research in throat\nmicrophone-based applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11478v2",
    "published": "2025-02-17T06:29:11+00:00",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2502.11477v1",
    "title": "Learning to Sample Effective and Diverse Prompts for Text-to-Image Generation",
    "authors": [
      "Taeyoung Yun",
      "Dinghuai Zhang",
      "Jinkyoo Park",
      "Ling Pan"
    ],
    "abstract": "Recent advances in text-to-image diffusion models have achieved impressive\nimage generation capabilities. However, it remains challenging to control the\ngeneration process with desired properties (e.g., aesthetic quality, user\nintention), which can be expressed as black-box reward functions. In this\npaper, we focus on prompt adaptation, which refines the original prompt into\nmodel-preferred prompts to generate desired images. While prior work uses\nreinforcement learning (RL) to optimize prompts, we observe that applying RL\noften results in generating similar postfixes and deterministic behaviors. To\nthis end, we introduce \\textbf{P}rompt \\textbf{A}daptation with\n\\textbf{G}FlowNets (\\textbf{PAG}), a novel approach that frames prompt\nadaptation as a probabilistic inference problem. Our key insight is that\nleveraging Generative Flow Networks (GFlowNets) allows us to shift from reward\nmaximization to sampling from an unnormalized density function, enabling both\nhigh-quality and diverse prompt generation. However, we identify that a naive\napplication of GFlowNets suffers from mode collapse and uncovers a previously\noverlooked phenomenon: the progressive loss of neural plasticity in the model,\nwhich is compounded by inefficient credit assignment in sequential prompt\ngeneration. To address this critical challenge, we develop a systematic\napproach in PAG with flow reactivation, reward-prioritized sampling, and reward\ndecomposition for prompt adaptation. Extensive experiments validate that PAG\nsuccessfully learns to sample effective and diverse prompts for text-to-image\ngeneration. We also show that PAG exhibits strong robustness across various\nreward functions and transferability to different text-to-image models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11477v1",
    "published": "2025-02-17T06:28:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11476v2",
    "title": "FastMCTS: A Simple Sampling Strategy for Data Synthesis",
    "authors": [
      "Peiji Li",
      "Kai Lv",
      "Yunfan Shao",
      "Yichuan Ma",
      "Linyang Li",
      "Xiaoqing Zheng",
      "Xipeng Qiu",
      "Qipeng Guo"
    ],
    "abstract": "Synthetic high-quality multi-step reasoning data can significantly enhance\nthe performance of large language models on various tasks. However, most\nexisting methods rely on rejection sampling, which generates trajectories\nindependently and suffers from inefficiency and imbalanced sampling across\nproblems of varying difficulty. In this work, we introduce FastMCTS, an\ninnovative data synthesis strategy inspired by Monte Carlo Tree Search.\nFastMCTS provides a more efficient sampling method for multi-step reasoning\ndata, offering step-level evaluation signals and promoting balanced sampling\nacross problems of different difficulty levels. Experiments on both English and\nChinese reasoning datasets demonstrate that FastMCTS generates over 30\\% more\ncorrect reasoning paths compared to rejection sampling as the number of\ngenerated tokens scales up. Furthermore, under comparable synthetic data\nbudgets, models trained on FastMCTS-generated data outperform those trained on\nrejection sampling data by 3.9\\% across multiple benchmarks. As a lightweight\nsampling strategy, FastMCTS offers a practical and efficient alternative for\nsynthesizing high-quality reasoning data. Our code will be released soon.",
    "pdf_url": "http://arxiv.org/pdf/2502.11476v2",
    "published": "2025-02-17T06:27:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.13167v1",
    "title": "SmartLLM: Smart Contract Auditing using Custom Generative AI",
    "authors": [
      "Jun Kevin",
      "Pujianto Yugopuspito"
    ],
    "abstract": "Smart contracts are essential to decentralized finance (DeFi) and blockchain\necosystems but are increasingly vulnerable to exploits due to coding errors and\ncomplex attack vectors. Traditional static analysis tools and existing\nvulnerability detection methods often fail to address these challenges\ncomprehensively, leading to high false-positive rates and an inability to\ndetect dynamic vulnerabilities. This paper introduces SmartLLM, a novel\napproach leveraging fine-tuned LLaMA 3.1 models with Retrieval-Augmented\nGeneration (RAG) to enhance the accuracy and efficiency of smart contract\nauditing. By integrating domain-specific knowledge from ERC standards and\nemploying advanced techniques such as QLoRA for efficient fine-tuning, SmartLLM\nachieves superior performance compared to static analysis tools like Mythril\nand Slither, as well as zero-shot large language model (LLM) prompting methods\nsuch as GPT-3.5 and GPT-4. Experimental results demonstrate a perfect recall of\n100% and an accuracy score of 70%, highlighting the model's robustness in\nidentifying vulnerabilities, including reentrancy and access control issues.\nThis research advances smart contract security by offering a scalable and\neffective auditing solution, supporting the secure adoption of decentralized\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2502.13167v1",
    "published": "2025-02-17T06:22:05+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11475v2",
    "title": "Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points",
    "authors": [
      "Kechi Zhang",
      "Ge Li",
      "Jia Li",
      "Yihong Dong",
      "Jia Li",
      "Zhi Jin"
    ],
    "abstract": "Code generation models have shown significant potential for automating\nprogramming tasks. However, the challenge of generating accurate and reliable\ncode persists due to the highly complex and long-reasoning nature of the task.\nEven state-of-the-art models often fail in code generation due to small errors,\nwhich can drastically affect the overall functionality of code. Our study\nidentifies that current models tend to produce errors concentrated at specific\nerror-prone points, which significantly impacts the accuracy of the generated\ncode. To address this issue, we introduce Focused-DPO, a framework that\nenhances code generation by directing preference optimization towards these\ncritical error-prone areas. This approach builds on Direct Preference\nOptimization, emphasizing accuracy in parts prone to errors. Additionally, we\ndevelop a method called Error-Point Identification, which constructs a dataset\nthat targets these problematic points without requiring costly human\nannotations. Our experiments on benchmarks such as HumanEval(+), MBPP(+), and\nLiveCodeBench demonstrate that Focused-DPO significantly improves the precision\nand reliability of code generation, reducing common errors and enhancing\noverall code quality. By focusing on error-prone points, Focused-DPO advances\nthe accuracy and functionality of model-generated code.",
    "pdf_url": "http://arxiv.org/pdf/2502.11475v2",
    "published": "2025-02-17T06:16:02+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11474v1",
    "title": "A refinement of Cauchys theorem on the zeros of quaternion polynomial",
    "authors": [
      "Nisar Ahmad Rather",
      "Danish Rashid Bhat",
      "Tanveer Bhat"
    ],
    "abstract": "In this paper, we shall present an interesting and significant refinement of\na classical result of Cauchy about the moduli of the zeros of a quaternionic\npolynomial. As an application of this result we shall obtain zero-free regions\nof polynomials having quaternionic coefficients.",
    "pdf_url": "http://arxiv.org/pdf/2502.11474v1",
    "published": "2025-02-17T06:12:39+00:00",
    "categories": [
      "math.CV",
      "Gm",
      "F.2"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2503.01849v1",
    "title": "Towards Environment-Sensitive Molecular Inference via Mixed Integer Linear Programming",
    "authors": [
      "Jianshen Zhu",
      "Mao Takekida",
      "Naveed Ahmed Azam",
      "Kazuya Haraguchi",
      "Liang Zhao",
      "Tatsuya Akutsu"
    ],
    "abstract": "Traditional QSAR/QSPR and inverse QSAR/QSPR methods often assume that\nchemical properties are dictated by single molecules, overlooking the influence\nof molecular interactions and environmental factors. In this paper, we\nintroduce a novel QSAR/QSPR framework that can capture the combined effects of\nmultiple molecules (e.g., small molecules or polymers) and experimental\nconditions on property values. We design a feature function to integrate the\ninformation of multiple molecules and the environment. Specifically, for the\nproperty Flory-Huggins $\\chi$-parameter, which characterizes the thermodynamic\nproperties between the solute and the solvent, and varies in temperatures, we\ndemonstrate through computational experimental results that our approach can\nachieve a competitively high learning performance compared to existing works on\npredicting $\\chi$-parameter values, while inferring the solute polymers with up\nto 50 non-hydrogen atoms in their monomer forms in a relatively short time. A\ncomparison study with the simulation software J-OCTA demonstrates that the\npolymers inferred by our methods are of high quality.",
    "pdf_url": "http://arxiv.org/pdf/2503.01849v1",
    "published": "2025-02-17T06:07:12+00:00",
    "categories": [
      "physics.chem-ph",
      "cs.LG"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11473v1",
    "title": "For a New Department of Energy lab to examine laser fusion for energy",
    "authors": [
      "Wallace Manheimer"
    ],
    "abstract": "This paper gives a summary of a talk by the author at the mini-conference\nentitled Progress in Making IFE-based Concepts a Reality at the APS-DPP meeting\nin Atlanta in October, 2024. It argues principally for a new DoE lab to examine\nthe potential opportunity of laser fusion for civilian energy, by direct drive,\nwith an excimer laser. This work is motivated mostly by the demonstration of a\nburning plasma in an indirect drive configuration, by the Lawrence Livermore\nNational laboratory with its NIF laser. Also, it briefly gives some impressions\nof the mini conference.",
    "pdf_url": "http://arxiv.org/pdf/2502.11473v1",
    "published": "2025-02-17T06:06:39+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11472v1",
    "title": "Multiplicity result for a mass supercritical NLS with a partial confinement",
    "authors": [
      "Louis Jeanjean",
      "Linjie Song"
    ],
    "abstract": "We consider an NLS equation in $\\mathbb{R}^3$ with partial confinement and\nmass supercritical nonlinearity. In Bellazzini, Boussaid, Jeanjean and\nVisciglia (Comm. Math. Phys. 353, 2017, 229-251) for such a problem, a solution\nwith a prescribed $L^2$ norm was obtained, as a local minima, and the existence\nof a second solution, at a mountain pass energy level, was proposed as an open\nproblem. We give here a positive, non-perturbative, answer to this problem. Our\nsolution is obtained as a limit of a sequence of solutions of corresponding\nproblems on bounded domains of $\\mathbb{R}^3$. The symmetry of solutions on\nbounded domains is used centrally in the convergence process.",
    "pdf_url": "http://arxiv.org/pdf/2502.11472v1",
    "published": "2025-02-17T06:03:29+00:00",
    "categories": [
      "math.AP",
      "35A15, 35J60"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11471v4",
    "title": "GLTW: Joint Improved Graph Transformer and LLM via Three-Word Language for Knowledge Graph Completion",
    "authors": [
      "Kangyang Luo",
      "Yuzhuo Bai",
      "Cheng Gao",
      "Shuzheng Si",
      "Yingli Shen",
      "Zhu Liu",
      "Zhitong Wang",
      "Cunliang Kong",
      "Wenhao Li",
      "Yufei Huang",
      "Ye Tian",
      "Xuantang Xiong",
      "Lei Han",
      "Maosong Sun"
    ],
    "abstract": "Knowledge Graph Completion (KGC), which aims to infer missing or incomplete\nfacts, is a crucial task for KGs. However, integrating the vital structural\ninformation of KGs into Large Language Models (LLMs) and outputting predictions\ndeterministically remains challenging. To address this, we propose a new method\ncalled GLTW, which encodes the structural information of KGs and merges it with\nLLMs to enhance KGC performance. Specifically, we introduce an improved Graph\nTransformer (iGT) that effectively encodes subgraphs with both local and global\nstructural information and inherits the characteristics of language model,\nbypassing training from scratch. Also, we develop a subgraph-based\nmulti-classification training objective, using all entities within KG as\nclassification objects, to boost learning efficiency.Importantly, we combine\niGT with an LLM that takes KG language prompts as input.Our extensive\nexperiments on various KG datasets show that GLTW achieves significant\nperformance gains compared to SOTA baselines.",
    "pdf_url": "http://arxiv.org/pdf/2502.11471v4",
    "published": "2025-02-17T06:02:59+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11470v1",
    "title": "Optimized detection of cyber-attacks on IoT networks via hybrid deep learning models",
    "authors": [
      "Ahmed Bensaoud",
      "Jugal Kalita"
    ],
    "abstract": "The rapid expansion of Internet of Things (IoT) devices has increased the\nrisk of cyber-attacks, making effective detection essential for securing IoT\nnetworks. This work introduces a novel approach combining Self-Organizing Maps\n(SOMs), Deep Belief Networks (DBNs), and Autoencoders to detect known and\npreviously unseen attack patterns. A comprehensive evaluation using simulated\nand real-world traffic data is conducted, with models optimized via Particle\nSwarm Optimization (PSO). The system achieves an accuracy of up to 99.99% and\nMatthews Correlation Coefficient (MCC) values exceeding 99.50%. Experiments on\nNSL-KDD, UNSW-NB15, and CICIoT2023 confirm the model's strong performance\nacross diverse attack types. These findings suggest that the proposed method\nenhances IoT security by identifying emerging threats and adapting to evolving\nattack strategies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11470v1",
    "published": "2025-02-17T06:01:06+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11469v2",
    "title": "If Attention Serves as a Cognitive Model of Human Memory Retrieval, What is the Plausible Memory Representation?",
    "authors": [
      "Ryo Yoshida",
      "Shinnosuke Isono",
      "Kohei Kajikawa",
      "Taiga Someya",
      "Yushi Sugimoto",
      "Yohei Oseki"
    ],
    "abstract": "Recent work in computational psycholinguistics has revealed intriguing\nparallels between attention mechanisms and human memory retrieval, focusing\nprimarily on vanilla Transformers that operate on token-level representations.\nHowever, computational psycholinguistic research has also established that\nsyntactic structures provide compelling explanations for human sentence\nprocessing that token-level factors cannot fully account for. In this paper, we\ninvestigate whether the attention mechanism of Transformer Grammar (TG), which\nuniquely operates on syntactic structures as representational units, can serve\nas a cognitive model of human memory retrieval, using Normalized Attention\nEntropy (NAE) as a linking hypothesis between models and humans. Our\nexperiments demonstrate that TG's attention achieves superior predictive power\nfor self-paced reading times compared to vanilla Transformer's, with further\nanalyses revealing independent contributions from both models. These findings\nsuggest that human sentence processing involves dual memory representations --\none based on syntactic structures and another on token sequences -- with\nattention serving as the general memory retrieval algorithm, while highlighting\nthe importance of incorporating syntactic structures as representational units.",
    "pdf_url": "http://arxiv.org/pdf/2502.11469v2",
    "published": "2025-02-17T05:58:25+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11468v1",
    "title": "Semantically Robust Unsupervised Image Translation for Paired Remote Sensing Images",
    "authors": [
      "Sheng Fang",
      "Kaiyu Li",
      "Zhe Li",
      "Jianli Zhao",
      "Xingli Zhang"
    ],
    "abstract": "Image translation for change detection or classification in bi-temporal\nremote sensing images is unique. Although it can acquire paired images, it is\nstill unsupervised. Moreover, strict semantic preservation in translation is\nalways needed instead of multimodal outputs. In response to these problems,\nthis paper proposes a new method, SRUIT (Semantically Robust Unsupervised\nImage-to-image Translation), which ensures semantically robust translation and\nproduces deterministic output. Inspired by previous works, the method explores\nthe underlying characteristics of bi-temporal Remote Sensing images and designs\nthe corresponding networks. Firstly, we assume that bi-temporal Remote Sensing\nimages share the same latent space, for they are always acquired from the same\nland location. So SRUIT makes the generators share their high-level layers, and\nthis constraint will compel two domain mapping to fall into the same latent\nspace. Secondly, considering land covers of bi-temporal images could evolve\ninto each other, SRUIT exploits the cross-cycle-consistent adversarial networks\nto translate from one to the other and recover them. Experimental results show\nthat constraints of sharing weights and cross-cycle consistency enable\ntranslated images with both good perceptual image quality and semantic\npreservation for significant differences.",
    "pdf_url": "http://arxiv.org/pdf/2502.11468v1",
    "published": "2025-02-17T05:57:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.13166v1",
    "title": "Large Language Models Can Help Mitigate Barren Plateaus",
    "authors": [
      "Jun Zhuang",
      "Chaowen Guan"
    ],
    "abstract": "In the era of noisy intermediate-scale quantum (NISQ) computing, Quantum\nNeural Networks (QNNs) have emerged as a promising approach for various\napplications, yet their training is often hindered by barren plateaus (BPs),\nwhere gradient variance vanishes exponentially as the model size increases. To\naddress this challenge, we propose a new Large Language Model (LLM)-driven\nsearch framework, AdaInit, that iteratively searches for optimal initial\nparameters of QNNs to maximize gradient variance and therefore mitigate BPs.\nUnlike conventional one-time initialization methods, AdaInit dynamically\nrefines QNN's initialization using LLMs with adaptive prompting. Theoretical\nanalysis of the Expected Improvement (EI) proves a supremum for the search,\nensuring this process can eventually identify the optimal initial parameter of\nthe QNN. Extensive experiments across four public datasets demonstrate that\nAdaInit significantly enhances QNN's trainability compared to classic\ninitialization methods, validating its effectiveness in mitigating BPs.",
    "pdf_url": "http://arxiv.org/pdf/2502.13166v1",
    "published": "2025-02-17T05:57:15+00:00",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11467v1",
    "title": "Approximation of Permutation Invariant Polynomials by Transformers: Efficient Construction in Column-Size",
    "authors": [
      "Naoki Takeshita",
      "Masaaki Imaizumi"
    ],
    "abstract": "Transformers are a type of neural network that have demonstrated remarkable\nperformance across various domains, particularly in natural language processing\ntasks. Motivated by this success, research on the theoretical understanding of\ntransformers has garnered significant attention. A notable example is the\nmathematical analysis of their approximation power, which validates the\nempirical expressive capability of transformers. In this study, we investigate\nthe ability of transformers to approximate column-symmetric polynomials, an\nextension of symmetric polynomials that take matrices as input. Consequently,\nwe establish an explicit relationship between the size of the transformer\nnetwork and its approximation capability, leveraging the parameter efficiency\nof transformers and their compatibility with symmetry by focusing on the\nalgebraic properties of symmetric polynomials.",
    "pdf_url": "http://arxiv.org/pdf/2502.11467v1",
    "published": "2025-02-17T05:56:11+00:00",
    "categories": [
      "cs.LG",
      "math.FA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11466v2",
    "title": "GiFT: Gibbs Fine-Tuning for Code Generation",
    "authors": [
      "Haochen Li",
      "Wanjin Feng",
      "Xin Zhou",
      "Zhiqi Shen"
    ],
    "abstract": "Training Large Language Models (LLMs) with synthetic data is a prevalent\npractice in code generation. A key approach is self-training, where LLMs are\niteratively trained on self-generated correct code snippets. In this case, the\nself-generated codes are drawn from a conditional distribution, conditioned on\na specific seed description. However, the seed description is not the only\nvalid representation that aligns with its intended meaning. With all valid\ndescriptions and codes forming a joint space, codes drawn from the conditional\ndistribution would lead to an underrepresentation of the full description-code\nspace. As such, we propose Gibbs Fine-Tuning (GiFT), a novel self-training\nmethod inspired by Gibbs sampling. GiFT allows self-generated data to be drawn\nfrom the marginal distribution of the joint space, thereby mitigating the\nbiases inherent in conditional sampling. We provide a theoretical analysis\ndemonstrating the potential benefits of fine-tuning LLMs with code derived from\nthe marginal distribution. Furthermore, we propose a perplexity-based code\nselection method to mitigate the imbalanced long-tail distribution of the\nself-generated codes. Empirical evaluation of two LLMs across four datasets\ndemonstrates that GiFT achieves superior performance, particularly on more\nchallenging benchmarks. Source code is available at\nhttps://github.com/Alex-HaochenLi/GiFT.",
    "pdf_url": "http://arxiv.org/pdf/2502.11466v2",
    "published": "2025-02-17T05:52:44+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11465v1",
    "title": "All Models Are Miscalibrated, But Some Less So: Comparing Calibration with Conditional Mean Operators",
    "authors": [
      "Peter Moskvichev",
      "Dino Sejdinovic"
    ],
    "abstract": "When working in a high-risk setting, having well calibrated probabilistic\npredictive models is a crucial requirement. However, estimators for calibration\nerror are not always able to correctly distinguish which model is better\ncalibrated. We propose the \\emph{conditional kernel calibration error} (CKCE)\nwhich is based on the Hilbert-Schmidt norm of the difference between\nconditional mean operators. By working directly with the definition of strong\ncalibration as the distance between conditional distributions, which we\nrepresent by their embeddings in reproducing kernel Hilbert spaces, the CKCE is\nless sensitive to the marginal distribution of predictive models. This makes it\nmore effective for relative comparisons than previously proposed calibration\nmetrics. Our experiments, using both synthetic and real data, show that CKCE\nprovides a more consistent ranking of models by their calibration error and is\nmore robust against distribution shift.",
    "pdf_url": "http://arxiv.org/pdf/2502.11465v1",
    "published": "2025-02-17T05:52:09+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.11464v3",
    "title": "BagChain: A Dual-functional Blockchain Leveraging Bagging-based Distributed Learning",
    "authors": [
      "Zixiang Cui",
      "Xintong Ling",
      "Xingyu Zhou",
      "Jiaheng Wang",
      "Zhi Ding",
      "Xiqi Gao"
    ],
    "abstract": "This work proposes a dual-functional blockchain framework named BagChain for\nbagging-based decentralized learning. BagChain integrates blockchain with\ndistributed machine learning by replacing the computationally costly hash\noperations in proof-of-work with machine-learning model training. BagChain\nutilizes individual miners' private data samples and limited computing\nresources to train potentially weak base models, which may be very weak, and\nfurther aggregates them into strong ensemble models. Specifically, we design a\nthree-layer blockchain structure associated with the corresponding generation\nand validation mechanisms to enable distributed machine learning among\nuncoordinated miners in a permissionless and open setting. To reduce\ncomputational waste due to blockchain forking, we further propose the cross\nfork sharing mechanism for practical networks with lengthy delays. Extensive\nexperiments illustrate the superiority and efficacy of BagChain when handling\nvarious machine learning tasks on both independently and identically\ndistributed (IID) and non-IID datasets. BagChain remains robust and effective\neven when facing constrained local computing capability, heterogeneous private\nuser data, and sparse network connectivity.",
    "pdf_url": "http://arxiv.org/pdf/2502.11464v3",
    "published": "2025-02-17T05:49:45+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11463v2",
    "title": "BIG-AOME: Designing Bodily Interaction Gamification towards Anti-sedentary Online Meeting Environments",
    "authors": [
      "Jiaqi Jiang",
      "Shanghao Li",
      "Xian Li",
      "Yingxin Xu",
      "Jian Zhao",
      "Pengcheng An"
    ],
    "abstract": "Online meetings have become an integral part of daily life, but prolonged\nscreen time poses significant health risks. While various interventions address\nsedentary lifestyles, few focus on mitigating sedentary behavior during online\nmeetings. Design opportunities in this context remain underexplored. This study\ninvestigates the design of gamified bodily interactions as anti-sedentary\nmeasures during online meetings using a research through design approach. In\ncollaboration with 11 users, we co-designed and iterated three prototypes,\nresulting in the BIG-AOME (Bodily Interaction Gamification towards\nAnti-sedentary Online Meeting Environments) framework. User studies with 15\nparticipants across three groups evaluated these prototypes through\nsemi-structured interviews analyzed using Hsieh's qualitative content analysis.\nFindings show that gamified bodily interactions encourage physical movement\nwhile reducing awkwardness during online meetings. Participants valued the\nsocial engagement fostered by cooperative and competitive elements in these\ngames, enhancing social dynamics while encouraging physical movement. Such\ngames can also serve as online icebreakers or playful decision-making tools.\nThis study offers a comprehensive analysis of design dimensions within the\nBIG-AOME framework, including body engagement, attention, bodily interplay,\ntimeliness, and virtual/physical environments, highlighting the potential of\nanti-sedentary bodily interactions to mitigate sedentary behavior and enhance\nsocial connections in online meetings.",
    "pdf_url": "http://arxiv.org/pdf/2502.11463v2",
    "published": "2025-02-17T05:46:53+00:00",
    "categories": [
      "cs.HC",
      "H.5.2; K.8.0"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11462v1",
    "title": "LMFCA-Net: A Lightweight Model for Multi-Channel Speech Enhancement with Efficient Narrow-Band and Cross-Band Attention",
    "authors": [
      "Yaokai Zhang",
      "Hanchen Pei",
      "Wanqi Wang",
      "Gongping Huang"
    ],
    "abstract": "Deep learning based end-to-end multi-channel speech enhancement methods have\nachieved impressive performance by leveraging sub-band, cross-band, and spatial\ninformation. However, these methods often demand substantial computational\nresources, limiting their practicality on terminal devices. This paper presents\na lightweight multi-channel speech enhancement network with decoupled fully\nconnected attention (LMFCA-Net). The proposed LMFCA-Net introduces time-axis\ndecoupled fully-connected attention (T-FCA) and frequency-axis decoupled\nfully-connected attention (F-FCA) mechanisms to effectively capture long-range\nnarrow-band and cross-band information without recurrent units. Experimental\nresults show that LMFCA-Net performs comparably to state-of-the-art methods\nwhile significantly reducing computational complexity and latency, making it a\npromising solution for practical applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11462v1",
    "published": "2025-02-17T05:42:03+00:00",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11461v2",
    "title": "Doppler Correspondence: Non-Iterative Scan Matching With Doppler Velocity-Based Correspondence",
    "authors": [
      "Jiwoo Kim",
      "Geunsik Bae",
      "Changseung Kim",
      "Jinwoo Lee",
      "Woojae Shin",
      "Hyondong Oh"
    ],
    "abstract": "Achieving successful scan matching is essential for LiDAR odometry. However,\nin challenging environments with adverse weather conditions or repetitive\ngeometric patterns, LiDAR odometry performance is degraded due to incorrect\nscan matching. Recently, the emergence of frequency-modulated continuous wave\n4D LiDAR and 4D radar technologies has provided the potential to address these\nunfavorable conditions. The term 4D refers to point cloud data characterized by\nrange, azimuth, and elevation along with Doppler velocity. Although 4D data is\navailable, most scan matching methods for 4D LiDAR and 4D radar still establish\ncorrespondence by repeatedly identifying the closest points between consecutive\nscans, overlooking the Doppler information. This paper introduces, for the\nfirst time, a simple Doppler velocity-based correspondence -- Doppler\nCorrespondence -- that is invariant to translation and small rotation of the\nsensor, with its geometric and kinematic foundations. Extensive experiments\ndemonstrate that the proposed method enables the direct matching of consecutive\npoint clouds without an iterative process, making it computationally efficient.\nAdditionally, it provides a more robust correspondence estimation in\nenvironments with repetitive geometric patterns.The implementation of our\nproposed method is publicly available at https://github.com/Tars0523/Doppler\nCorrespondence.",
    "pdf_url": "http://arxiv.org/pdf/2502.11461v2",
    "published": "2025-02-17T05:37:07+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11460v1",
    "title": "UnitCoder: Scalable Iterative Code Synthesis with Unit Test Guidance",
    "authors": [
      "Yichuan Ma",
      "Yunfan Shao",
      "Peiji Li",
      "Demin Song",
      "Qipeng Guo",
      "Linyang Li",
      "Xipeng Qiu",
      "Kai Chen"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious tasks, yet code generation remains a major challenge. Current\napproaches for obtaining high-quality code data primarily focus on (i)\ncollecting large-scale pre-training data and (ii) synthesizing instruction data\nthrough prompt engineering with powerful models. While pre-training data faces\nquality consistency issues, instruction-based synthesis suffers from limited\ninstruction diversity and inherent biases of LLMs. To address this gap, we\nintroduce UnitCoder, a systematic pipeline leveraging model-generated unit\ntests to both guide and validate the code generation process. Combined with\nlarge-scale package-based retrieval from pre-training corpus, we generate a\ndataset of 500K+ verifiable programs containing diverse API calls. Evaluations\non multiple Python benchmarks (BigCodeBench, HumanEval, MBPP) demonstrate that\nmodels fine-tuned on our synthetic data exhibit consistent performance\nimprovements. Notably, Llama3.1-8B and InternLM2.5-7B improve from 31\\% and\n28\\% to 40\\% and 39\\% success rates on BigCodeBench, respectively. Our work\npresents a scalable approach that leverages model-generated unit tests to guide\nthe synthesis of high-quality code data from pre-training corpora,\ndemonstrating the potential for producing diverse and high-quality\npost-training data at scale. All code and data will be released\n(https://github.com).",
    "pdf_url": "http://arxiv.org/pdf/2502.11460v1",
    "published": "2025-02-17T05:37:02+00:00",
    "categories": [
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11459v1",
    "title": "Towards Responsible and Fair Data Science: Resource Allocation for Inclusive and Sustainable Analytics",
    "authors": [
      "Genoveva Vargas-Solar"
    ],
    "abstract": "This project addresses the challenges of responsible and fair resource\nallocation in data science (DS), focusing on DS queries evaluation. Current DS\npractices often overlook the broader socio-economic, environmental, and ethical\nimplications, including data sovereignty, fairness, and inclusivity. By\nintegrating a decolonial perspective, the project aims to establish innovative\nfairness metrics that respect cultural and contextual diversity, optimise\ncomputational and energy efficiency, and ensure equitable participation of\nunderrepresented communities. The research includes developing algorithms to\nalign resource allocation with fairness constraints, incorporating ethical and\nsustainability considerations, and fostering interdisciplinary collaborations\nto bridge technical advancements and societal impact gaps. This work aims to\nreshape into an equitable, transparent, and community-empowering practice\nchallenging the technological power developed by the Big Tech.",
    "pdf_url": "http://arxiv.org/pdf/2502.11459v1",
    "published": "2025-02-17T05:33:50+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2502.11458v1",
    "title": "Towards Efficient Pre-training: Exploring FP4 Precision in Large Language Models",
    "authors": [
      "Jiecheng Zhou",
      "Ding Tang",
      "Rong Fu",
      "Boni Hu",
      "Haoran Xu",
      "Yi Wang",
      "Zhilin Pei",
      "Zhongling Su",
      "Liang Liu",
      "Xingcheng Zhang",
      "Weiming Zhang"
    ],
    "abstract": "The burgeoning computational demands for training large language models\n(LLMs) necessitate efficient methods, including quantized training, which\nleverages low-bit arithmetic operations to reduce costs. While FP8 precision\nhas shown potential, leveraging FP4 remains challenging due to inherent\nquantization errors and limited representation capability. Based on the\nTransformer architecture, we present an FP4 training scheme for LLMs,\novercoming these obstacles through mixed-precision quantization strategies\ntailed for different modules and training stages. This allows us to apply the\nprecision level suitable to distinct components within the model, ensuring that\nmulti-head attention and linear layers are handled appropriately. Our\npretraining recipe ensures stability in backpropagation by incorporating\nfine-grained quantization methods with a target precision training schedule.\nExperimental results demonstrate that our FP4 training scheme achieves accuracy\ncomparable to BF16 and FP8, with smaller theoretical computational cost. With\nthe advent of next-generation hardware supporting FP4, our method sets the\nfoundation for efficient ultra-low precision training.",
    "pdf_url": "http://arxiv.org/pdf/2502.11458v1",
    "published": "2025-02-17T05:33:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11457v1",
    "title": "Aligning Sentence Simplification with ESL Learner's Proficiency for Language Acquisition",
    "authors": [
      "Guanlin Li",
      "Yuki Arase",
      "Noel Crespi"
    ],
    "abstract": "Text simplification is crucial for improving accessibility and comprehension\nfor English as a Second Language (ESL) learners. This study goes a step further\nand aims to facilitate ESL learners' language acquisition by simplification.\nSpecifically, we propose simplifying complex sentences to appropriate levels\nfor learners while also increasing vocabulary coverage of the target level in\nthe simplifications. We achieve this without a parallel corpus by conducting\nreinforcement learning on a large language model. Our method employs\ntoken-level and sentence-level rewards, and iteratively trains the model on its\nself-generated outputs to guide the model to search for simplification\nhypotheses that satisfy the target attributes. Experiment results on CEFR-SP\nand TurkCorpus datasets show that the proposed method can effectively increase\nthe frequency and diversity of vocabulary of the target level by more than\n$20\\%$ compared to baseline models, while maintaining high simplification\nquality.",
    "pdf_url": "http://arxiv.org/pdf/2502.11457v1",
    "published": "2025-02-17T05:32:56+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11456v1",
    "title": "Leveraging Labelled Data Knowledge: A Cooperative Rectification Learning Network for Semi-supervised 3D Medical Image Segmentation",
    "authors": [
      "Yanyan Wang",
      "Kechen Song",
      "Yuyuan Liu",
      "Shuai Ma",
      "Yunhui Yan",
      "Gustavo Carneiro"
    ],
    "abstract": "Semi-supervised 3D medical image segmentation aims to achieve accurate\nsegmentation using few labelled data and numerous unlabelled data. The main\nchallenge in the design of semi-supervised learning methods consists in the\neffective use of the unlabelled data for training. A promising solution\nconsists of ensuring consistent predictions across different views of the data,\nwhere the efficacy of this strategy depends on the accuracy of the\npseudo-labels generated by the model for this consistency learning strategy. In\nthis paper, we introduce a new methodology to produce high-quality\npseudo-labels for a consistency learning strategy to address semi-supervised 3D\nmedical image segmentation. The methodology has three important contributions.\nThe first contribution is the Cooperative Rectification Learning Network (CRLN)\nthat learns multiple prototypes per class to be used as external knowledge\npriors to adaptively rectify pseudo-labels at the voxel level. The second\ncontribution consists of the Dynamic Interaction Module (DIM) to facilitate\npairwise and cross-class interactions between prototypes and multi-resolution\nimage features, enabling the production of accurate voxel-level clues for\npseudo-label rectification. The third contribution is the Cooperative Positive\nSupervision (CPS), which optimises uncertain representations to align with\nunassertive representations of their class distributions, improving the model's\naccuracy in classifying uncertain regions. Extensive experiments on three\npublic 3D medical segmentation datasets demonstrate the effectiveness and\nsuperiority of our semi-supervised learning method.",
    "pdf_url": "http://arxiv.org/pdf/2502.11456v1",
    "published": "2025-02-17T05:29:50+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11455v1",
    "title": "Adversary-Aware DPO: Enhancing Safety Alignment in Vision Language Models via Adversarial Training",
    "authors": [
      "Fenghua Weng",
      "Jian Lou",
      "Jun Feng",
      "Minlie Huang",
      "Wenjie Wang"
    ],
    "abstract": "Safety alignment is critical in pre-training large language models (LLMs) to\ngenerate responses aligned with human values and refuse harmful queries. Unlike\nLLM, the current safety alignment of VLMs is often achieved with post-hoc\nsafety fine-tuning. However, these methods are less effective to white-box\nattacks. To address this, we propose $\\textit{Adversary-aware DPO (ADPO)}$, a\nnovel training framework that explicitly considers adversarial.\n$\\textit{Adversary-aware DPO (ADPO)}$ integrates adversarial training into DPO\nto enhance the safety alignment of VLMs under worst-case adversarial\nperturbations. $\\textit{ADPO}$ introduces two key components: (1) an\nadversarial-trained reference model that generates human-preferred responses\nunder worst-case perturbations, and (2) an adversarial-aware DPO loss that\ngenerates winner-loser pairs accounting for adversarial distortions. By\ncombining these innovations, $\\textit{ADPO}$ ensures that VLMs remain robust\nand reliable even in the presence of sophisticated jailbreak attacks. Extensive\nexperiments demonstrate that $\\textit{ADPO}$ outperforms baselines in the\nsafety alignment and general utility of VLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11455v1",
    "published": "2025-02-17T05:28:47+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11454v1",
    "title": "UniCBE: An Uniformity-driven Comparing Based Evaluation Framework with Unified Multi-Objective Optimization",
    "authors": [
      "Peiwen Yuan",
      "Shaoxiong Feng",
      "Yiwei Li",
      "Xinglin Wang",
      "Yueqi Zhang",
      "Jiayi Shi",
      "Chuyi Tan",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "Human preference plays a significant role in measuring large language models\nand guiding them to align with human values. Unfortunately, current\ncomparing-based evaluation (CBE) methods typically focus on a single\noptimization objective, failing to effectively utilize scarce yet valuable\npreference signals. To address this, we delve into key factors that can enhance\nthe accuracy, convergence, and scalability of CBE: suppressing sampling bias,\nbalancing descending process of uncertainty, and mitigating updating\nuncertainty. Following the derived guidelines, we propose UniCBE, a unified\nuniformity-driven CBE framework which simultaneously optimize these core\nobjectives by constructing and integrating three decoupled sampling probability\nmatrices, each designed to ensure uniformity in specific aspects. We further\nablate the optimal tuple sampling and preference aggregation strategies to\nachieve efficient CBE. On the AlpacaEval benchmark, UniCBE saves over 17% of\nevaluation budgets while achieving a Pearson correlation with ground truth\nexceeding 0.995, demonstrating excellent accuracy and convergence. In scenarios\nwhere new models are continuously introduced, UniCBE can even save over 50% of\nevaluation costs, highlighting its improved scalability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11454v1",
    "published": "2025-02-17T05:28:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11453v1",
    "title": "Connector-S: A Survey of Connectors in Multi-modal Large Language Models",
    "authors": [
      "Xun Zhu",
      "Zheng Zhang",
      "Xi Chen",
      "Yiming Shi",
      "Miao Li",
      "Ji Wu"
    ],
    "abstract": "With the rapid advancements in multi-modal large language models (MLLMs),\nconnectors play a pivotal role in bridging diverse modalities and enhancing\nmodel performance. However, the design and evolution of connectors have not\nbeen comprehensively analyzed, leaving gaps in understanding how these\ncomponents function and hindering the development of more powerful connectors.\nIn this survey, we systematically review the current progress of connectors in\nMLLMs and present a structured taxonomy that categorizes connectors into atomic\noperations (mapping, compression, mixture of experts) and holistic designs\n(multi-layer, multi-encoder, multi-modal scenarios), highlighting their\ntechnical contributions and advancements. Furthermore, we discuss several\npromising research frontiers and challenges, including high-resolution input,\ndynamic compression, guide information selection, combination strategy, and\ninterpretability. This survey is intended to serve as a foundational reference\nand a clear roadmap for researchers, providing valuable insights into the\ndesign and optimization of next-generation connectors to enhance the\nperformance and adaptability of MLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11453v1",
    "published": "2025-02-17T05:28:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11452v1",
    "title": "Photoinduced twist and untwist of moirÃ© superlattices in TMDC heterobilayers",
    "authors": [
      "C. J. R. Duncan",
      "A. C. Johnson",
      "I. Maity",
      "A. Rubio",
      "M. Gordon",
      "A. C. Bartnik",
      "M. Kaemingk",
      "W. H. Li",
      "M. B. Andorf",
      "C. A. Pennington",
      "I. V. Bazarov",
      "M. W. Tate",
      "D. A. Muller",
      "J. Thom-Levy",
      "S. M. Gruner",
      "A . M. Lindenberg",
      "F. Liu",
      "J. M. Maxson"
    ],
    "abstract": "Two-dimensional twisted bilayer moir\\'e structures provide a versatile\nmaterial platform for realizing a rich variety of strongly correlated\nelectronic quantum phases intricately coupled with the periodically modulated\nlattice structures. In this work, we use ultrafast electron diffraction to\ndirectly reveal the photoinduced dynamic evolution of the moir\\'e superlattice\nin $2^\\circ$ and $57^\\circ$ twisted WSe$_2$/MoSe$_2$ heterobilayers. Upon\nabove-band-gap photoexcitation, the moir\\'e superlattice diffraction features\nare enhanced within 1 ps and subsequently suppressed several picoseconds after,\naccompanied by a collective lattice excitation of a moir\\'e phonon mode with\nsub-THz frequency. This unique response deviates markedly from typical\nphotoinduced lattice heating, and suggests dynamic twisting and untwisting of\nthe local moir\\'e chiral structure. We infer large oscillations in the local\ntwist angle, approaching $1^\\circ$ peak to trough, that are driven by ultrafast\ncharge carrier excitation and relaxation -- a phenomenon further supported by\nmolecular dynamics simulations. Our findings suggest a novel approach for\nreal-time dynamic reconfiguration of moire superlattices to achieve ultrafast\nmodulation of their strongly correlated behaviors.",
    "pdf_url": "http://arxiv.org/pdf/2502.11452v1",
    "published": "2025-02-17T05:26:23+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11451v1",
    "title": "From Personas to Talks: Revisiting the Impact of Personas on LLM-Synthesized Emotional Support Conversations",
    "authors": [
      "Shenghan Wu",
      "Yang Deng",
      "Yimo Zhu",
      "Wynne Hsu",
      "Mong Li Lee"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has revolutionized the\ngeneration of emotional support conversations (ESC), offering scalable\nsolutions with reduced costs and enhanced data privacy. This paper explores the\nrole of personas in the creation of ESC by LLMs. Our research utilizes\nestablished psychological frameworks to measure and infuse persona traits into\nLLMs, which then generate dialogues in the emotional support scenario. We\nconduct extensive evaluations to understand the stability of persona traits in\ndialogues, examining shifts in traits post-generation and their impact on\ndialogue quality and strategy distribution. Experimental results reveal several\nnotable findings: 1) LLMs can infer core persona traits, 2) subtle shifts in\nemotionality and extraversion occur, influencing the dialogue dynamics, and 3)\nthe application of persona traits modifies the distribution of emotional\nsupport strategies, enhancing the relevance and empathetic quality of the\nresponses. These findings highlight the potential of persona-driven LLMs in\ncrafting more personalized, empathetic, and effective emotional support\ndialogues, which has significant implications for the future design of\nAI-driven emotional support systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11451v1",
    "published": "2025-02-17T05:24:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11450v1",
    "title": "Fishing For Cheap And Efficient Pruners At Initialization",
    "authors": [
      "Ivo Gollini Navarrete",
      "Nicolas Mauricio Cuadrado",
      "Jose Renato Restom",
      "Martin TakÃ¡Ä",
      "Samuel HorvÃ¡th"
    ],
    "abstract": "Pruning offers a promising solution to mitigate the associated costs and\nenvironmental impact of deploying large deep neural networks (DNNs).\nTraditional approaches rely on computationally expensive trained models or\ntime-consuming iterative prune-retrain cycles, undermining their utility in\nresource-constrained settings. To address this issue, we build upon the\nestablished principles of saliency (LeCun et al., 1989) and connection\nsensitivity (Lee et al., 2018) to tackle the challenging problem of one-shot\npruning neural networks (NNs) before training (PBT) at initialization. We\nintroduce Fisher-Taylor Sensitivity (FTS), a computationally cheap and\nefficient pruning criterion based on the empirical Fisher Information Matrix\n(FIM) diagonal, offering a viable alternative for integrating first- and\nsecond-order information to identify a model's structurally important\nparameters. Although the FIM-Hessian equivalency only holds for convergent\nmodels that maximize the likelihood, recent studies (Karakida et al., 2019)\nsuggest that, even at initialization, the FIM captures essential geometric\ninformation of parameters in overparameterized NNs, providing the basis for our\nmethod. Finally, we demonstrate empirically that layer collapse, a critical\nlimitation of data-dependent pruning methodologies, is easily overcome by\npruning within a single training epoch after initialization. We perform\nexperiments on ResNet18 and VGG19 with CIFAR-10 and CIFAR-100, widely used\nbenchmarks in pruning research. Our method achieves competitive performance\nagainst state-of-the-art techniques for one-shot PBT, even under extreme\nsparsity conditions. Our code is made available to the public.",
    "pdf_url": "http://arxiv.org/pdf/2502.11450v1",
    "published": "2025-02-17T05:22:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05",
      "I.2.6; C.1.3"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11449v3",
    "title": "Tractable General Equilibrium",
    "authors": [
      "Denizalp Goktas",
      "Amy Greenwald"
    ],
    "abstract": "We study Walrasian economies (or general equilibrium models) and their\nsolution concept, the Walrasian equilibrium. A key challenge in this domain is\nidentifying price-adjustment processes that converge to equilibrium. One such\nprocess, t\\^atonnement, is an auction-like algorithm first proposed in 1874 by\nL\\'eon Walras. While continuous-time variants of t\\^atonnement are known to\nconverge to equilibrium in economies satisfying the Weak Axiom of Revealed\nPreferences (WARP), the process fails to converge in a pathological Walrasian\neconomy known as the Scarf economy. To address these issues, we analyze\nWalrasian economies using variational inequalities (VIs), an optimization\nframework. We introduce the class of mirror extragradient algorithms, which,\nunder suitable Lipschitz-continuity-like assumptions, converge to a solution of\nany VI satisfying the Minty condition in polynomial time. We show that the set\nof Walrasian equilibria of any balanced economy-which includes among others\nArrow-Debreu economies-corresponds to the solution set of an associated VI that\nsatisfies the Minty condition but is generally discontinuous. Applying the\nmirror extragradient algorithm to this VI we obtain a class of\nt\\^atonnement-like processes, which we call the mirror extrat\\^atonnement\nprocess. While our VI formulation is generally discontinuous, it is\nLipschitz-continuous in variationally stable Walrasian economies with bounded\nelasticity-including those satisfying WARP and the Scarf economy-thus\nestablishing the polynomial-time convergence of mirror extrat\\^atonnement in\nthese economies. We validate our approach through experiments on large\nArrow-Debreu economies with Cobb-Douglas, Leontief, and CES consumers, as well\nas the Scarf economy, demonstrating fast convergence in all cases without\nfailure.",
    "pdf_url": "http://arxiv.org/pdf/2502.11449v3",
    "published": "2025-02-17T05:14:14+00:00",
    "categories": [
      "cs.GT",
      "cs.CE",
      "econ.TH"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11448v2",
    "title": "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection",
    "authors": [
      "Weidi Luo",
      "Shenghong Dai",
      "Xiaogeng Liu",
      "Suman Banerjee",
      "Huan Sun",
      "Muhao Chen",
      "Chaowei Xiao"
    ],
    "abstract": "The rapid advancements in Large Language Models (LLMs) have enabled their\ndeployment as autonomous agents for handling complex tasks in dynamic\nenvironments. These LLMs demonstrate strong problem-solving capabilities and\nadaptability to multifaceted scenarios. However, their use as agents also\nintroduces significant risks, including task-specific risks, which are\nidentified by the agent administrator based on the specific task requirements\nand constraints, and systemic risks, which stem from vulnerabilities in their\ndesign or interactions, potentially compromising confidentiality, integrity, or\navailability (CIA) of information and triggering security risks. Existing\ndefense agencies fail to adaptively and effectively mitigate these risks. In\nthis paper, we propose AGrail, a lifelong agent guardrail to enhance LLM agent\nsafety, which features adaptive safety check generation, effective safety check\noptimization, and tool compatibility and flexibility. Extensive experiments\ndemonstrate that AGrail not only achieves strong performance against\ntask-specific and system risks but also exhibits transferability across\ndifferent LLM agents' tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11448v2",
    "published": "2025-02-17T05:12:33+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11447v2",
    "title": "Does Editing Provide Evidence for Localization?",
    "authors": [
      "Zihao Wang",
      "Victor Veitch"
    ],
    "abstract": "A basic aspiration for interpretability research in large language models is\nto \"localize\" semantically meaningful behaviors to particular components within\nthe LLM. There are various heuristics for finding candidate locations within\nthe LLM. Once a candidate localization is found, it can be assessed by editing\nthe internal representations at the corresponding localization and checking\nwhether this induces model behavior that is consistent with the semantic\ninterpretation of the localization. The question we address here is: how strong\nis the evidence provided by such edits? To evaluate the localization claim, we\nwant to assess the effect of the optimal intervention at a particular location.\nThe key new technical tool is a way of adapting LLM alignment techniques to\nfind such optimal localized edits. With this tool in hand, we give an example\nwhere the edit-based evidence for localization appears strong, but where\nlocalization clearly fails. Indeed, we find that optimal edits at random\nlocalizations can be as effective as aligning the full model. In aggregate, our\nresults suggest that merely observing that localized edits induce targeted\nchanges in behavior provides little to no evidence that these locations\nactually encode the target behavior.",
    "pdf_url": "http://arxiv.org/pdf/2502.11447v2",
    "published": "2025-02-17T05:09:46+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T50",
      "I.2.7; I.2.6; F.1.1"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11446v1",
    "title": "Hybrid Beamforming Design for Bistatic Integrated Sensing and Communication Systems",
    "authors": [
      "Tianhao Mao",
      "Jie Yang",
      "Le Liang",
      "Shi Jin"
    ],
    "abstract": "Integrated sensing and communication (ISAC) in millimeter wave is a key\nenabler for next-generation networks, which leverages large bandwidth and\nextensive antenna arrays, benefiting both communication and sensing\nfunctionalities. The associated high costs can be mitigated by adopting a\nhybrid beamforming structure. However, the well-studied monostatic ISAC systems\nface challenges related to full-duplex operation. To address this issue, this\npaper focuses on a three-dimensional bistatic configuration that requires only\nhalf-duplex base stations. To intuitively evaluate the error bound of bistatic\nsensing using orthogonal frequency division multiplexing waveforms, we propose\na positioning scheme that combines angle-of-arrival and time-of-arrival\nestimation, deriving the closed-form expression of the position error bound\n(PEB). Using this PEB, we develop two hybrid beamforming algorithms for joint\nwaveform design, aimed at maximizing achievable spectral efficiency (SE) while\nensuring a predefined PEB threshold. The first algorithm leverages a Riemannian\ntrust-region approach, achieving superior performance in terms of global optima\nand convergence speed compared to conventional gradient-based methods, but with\nhigher complexity. In contrast, the second algorithm, which employs orthogonal\nmatching pursuit, offers a more computationally efficient solution, delivering\nreasonable SE while maintaining the PEB constraint. Numerical results are\nprovided to validate the effectiveness of the proposed designs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11446v1",
    "published": "2025-02-17T05:07:29+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11445v1",
    "title": "Semiclassical scar on tori in high dimension",
    "authors": [
      "Huanhuan Yuan",
      "Yong Li"
    ],
    "abstract": "We show that the eigenfunctions of the self-adjoint elliptic $h-$differential\noperator $P_{h}(t)$ exhibits semiclassical scar phenomena on the\n$d-$dimensional torus, under the $\\sigma$-Bruno-R\\\"{u}ssmann condition, instead\nof the Diophantine one. Its equivalence is described as: for almost all\nperturbed Hamiltonian's KAM Lagrangian tori $\\Lambda_{\\omega}$, there exists a\nsemiclassical measure with positive mass on $\\Lambda_{\\omega}$. The premise is\nthat we can obatain a family of quasimodes for the $h-$differential operator\n$P_{h}(t)$ in the semiclassical limit as $h\\rightarrow0$, under the\n$\\sigma$-Bruno-R\\\"{u}ssmann condition.",
    "pdf_url": "http://arxiv.org/pdf/2502.11445v1",
    "published": "2025-02-17T05:07:01+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11444v1",
    "title": "Does RAG Really Perform Bad For Long-Context Processing?",
    "authors": [
      "Kun Luo",
      "Zheng Liu",
      "Peitian Zhang",
      "Hongjin Qian",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "The efficient processing of long context poses a serious challenge for large\nlanguage models (LLMs). Recently, retrieval-augmented generation (RAG) has\nemerged as a promising strategy for this problem, as it enables LLMs to make\nselective use of the long context for efficient computation. However, existing\nRAG approaches lag behind other long-context processing methods due to inherent\nlimitations on inaccurate retrieval and fragmented contexts. To address these\nchallenges, we introduce RetroLM, a novel RAG framework for long-context\nprocessing. Unlike traditional methods, RetroLM employs KV-level retrieval\naugmentation, where it partitions the LLM's KV cache into contiguous pages and\nretrieves the most crucial ones for efficient computation. This approach\nenhances robustness to retrieval inaccuracy, facilitates effective utilization\nof fragmented contexts, and saves the cost from repeated computation. Building\non this framework, we further develop a specialized retriever for precise\nretrieval of critical pages and conduct unsupervised post-training to optimize\nthe model's ability to leverage retrieved information. We conduct comprehensive\nevaluations with a variety of benchmarks, including LongBench, InfiniteBench,\nand RULER, where RetroLM significantly outperforms existing long-context LLMs\nand efficient long-context processing methods, particularly in tasks requiring\nintensive reasoning or extremely long-context comprehension.",
    "pdf_url": "http://arxiv.org/pdf/2502.11444v1",
    "published": "2025-02-17T05:02:25+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11443v1",
    "title": "Constraining the Hubble Constant with a Simulated Full Covariance Matrix Using Neural Networks",
    "authors": [
      "Jing Niu",
      "Peng He",
      "Tong-Jie Zhang"
    ],
    "abstract": "The Hubble parameter, $H(z)$, plays a crucial role in understanding the\nexpansion history of the universe and constraining the Hubble constant,\n$\\mathrm{H}_0$. The Cosmic Chronometers (CC) method provides an independent\napproach to measuring $H(z)$, but existing studies either neglect off-diagonal\nelements in the covariance matrix or use an incomplete covariance matrix,\nlimiting the accuracy of $\\mathrm{H}_0$ constraints. To address this, we use a\nFully Connected Neural Network (FCNN) to simulate the full $33 \\times 33$\ncovariance matrix based on a previously proposed $15 \\times 15$ covariance\nmatrix. We find that two key hyperparameters, epochs and batch size,\nsignificantly affect the simulation and introduce two criteria for selecting\noptimal values. Using the simulated covariance matrix, we constrain\n$\\mathrm{H}_0$ via two independent methods: EMCEE and Gaussian Process. Our\nresults show that different hyperparameter selection criteria lead to\nvariations in the chosen combinations but have little impact on the final\nconstrained $\\mathrm{H}_0$. However, different epochs and batch size settings\ndo affect the results. Incorporating the simulated covariance matrix increases\nthe uncertainty in $\\mathrm{H}_0$ compared to using no covariance matrix or\nonly the proposed $15 \\times 15$ covariance matrix. The comparison between\nEMCEE and GP suggests that the constraint method itself also influences the\nfinal $\\mathrm{H}_0$. These findings highlight the importance of properly\nmodeling covariance in CC-based $\\mathrm{H}_0$ constraints.",
    "pdf_url": "http://arxiv.org/pdf/2502.11443v1",
    "published": "2025-02-17T05:00:10+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11442v1",
    "title": "Multi-Turn Multi-Modal Question Clarification for Enhanced Conversational Understanding",
    "authors": [
      "Kimia Ramezan",
      "Alireza Amiri Bavandpour",
      "Yifei Yuan",
      "Clemencia Siro",
      "Mohammad Aliannejadi"
    ],
    "abstract": "Conversational query clarification enables users to refine their search\nqueries through interactive dialogue, improving search effectiveness.\nTraditional approaches rely on text-based clarifying questions, which often\nfail to capture complex user preferences, particularly those involving visual\nattributes. While recent work has explored single-turn multi-modal\nclarification with images alongside text, such methods do not fully support the\nprogressive nature of user intent refinement over multiple turns. Motivated by\nthis, we introduce the Multi-turn Multi-modal Clarifying Questions (MMCQ) task,\nwhich combines text and visual modalities to refine user queries in a\nmulti-turn conversation. To facilitate this task, we create a large-scale\ndataset named ClariMM comprising over 13k multi-turn interactions and 33k\nquestion-answer pairs containing multi-modal clarifying questions. We propose\nMario, a retrieval framework that employs a two-phase ranking strategy: initial\nretrieval with BM25, followed by a multi-modal generative re-ranking model that\nintegrates textual and visual information from conversational history. Our\nexperiments show that multi-turn multi-modal clarification outperforms\nuni-modal and single-turn approaches, improving MRR by 12.88%. The gains are\nmost significant in longer interactions, demonstrating the value of progressive\nrefinement for complex queries.",
    "pdf_url": "http://arxiv.org/pdf/2502.11442v1",
    "published": "2025-02-17T04:58:14+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11441v3",
    "title": "Which Retain Set Matters for LLM Unlearning? A Case Study on Entity Unlearning",
    "authors": [
      "Hwan Chang",
      "Hwanhee Lee"
    ],
    "abstract": "Large language models (LLMs) risk retaining unauthorized or sensitive\ninformation from their training data, which raises privacy concerns. LLM\nunlearning seeks to mitigate these risks by selectively removing specified data\nwhile maintaining overall model performance. However, most existing work focus\non methods to achieve effective forgetting and does not provide a detailed\nanalysis of the retain set, the portion of training data that is not targeted\nfor removal. In this paper, we investigate the effects of unlearning on various\nsubsets of the retain set through a case study on entity unlearning. We\nintroduce the Syntactically Similar Neighbor Set, a group of queries that share\nsimilar syntactic structures with the data targeted for removal, and show that\nthis subset suffers the greatest performance drop during unlearning. Moreover,\nwhen used for regularization, this set not only preserves performance on\nsyntactically similar queries but also delivers comparable or improved results\nacross other data subsets. Our results highlight that syntactic similarity is a\ncritical factor, potentially more so than domain or entity relationships, in\nachieving effective and practical LLM unlearning.",
    "pdf_url": "http://arxiv.org/pdf/2502.11441v3",
    "published": "2025-02-17T04:55:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11440v1",
    "title": "Medical Image Registration Meets Vision Foundation Model: Prototype Learning and Contour Awareness",
    "authors": [
      "Hao Xu",
      "Tengfei Xue",
      "Jianan Fan",
      "Dongnan Liu",
      "Yuqian Chen",
      "Fan Zhang",
      "Carl-Fredrik Westin",
      "Ron Kikinis",
      "Lauren J. O'Donnell",
      "Weidong Cai"
    ],
    "abstract": "Medical image registration is a fundamental task in medical image analysis,\naiming to establish spatial correspondences between paired images. However,\nexisting unsupervised deformable registration methods rely solely on\nintensity-based similarity metrics, lacking explicit anatomical knowledge,\nwhich limits their accuracy and robustness. Vision foundation models, such as\nthe Segment Anything Model (SAM), can generate high-quality segmentation masks\nthat provide explicit anatomical structure knowledge, addressing the\nlimitations of traditional methods that depend only on intensity similarity.\nBased on this, we propose a novel SAM-assisted registration framework\nincorporating prototype learning and contour awareness. The framework includes:\n(1) Explicit anatomical information injection, where SAM-generated segmentation\nmasks are used as auxiliary inputs throughout training and testing to ensure\nthe consistency of anatomical information; (2) Prototype learning, which\nleverages segmentation masks to extract prototype features and aligns\nprototypes to optimize semantic correspondences between images; and (3)\nContour-aware loss, a contour-aware loss is designed that leverages the edges\nof segmentation masks to improve the model's performance in fine-grained\ndeformation fields. Extensive experiments demonstrate that the proposed\nframework significantly outperforms existing methods across multiple datasets,\nparticularly in challenging scenarios with complex anatomical structures and\nambiguous boundaries. Our code is available at\nhttps://github.com/HaoXu0507/IPMI25-SAM-Assisted-Registration.",
    "pdf_url": "http://arxiv.org/pdf/2502.11440v1",
    "published": "2025-02-17T04:54:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11439v2",
    "title": "An Efficient Sparse Fine-Tuning with Low Quantization Error via Neural Network Pruning",
    "authors": [
      "Cen-Jhih Li",
      "Aditya Bhaskara"
    ],
    "abstract": "Fine-tuning is an important step in adapting foundation models such as large\nlanguage models to downstream tasks. To make this step more accessible to users\nwith limited computational budgets, it is crucial to develop fine-tuning\nmethods that are memory and computationally efficient. Sparse Fine-tuning\n(SpFT) and Low-rank adaptation (LoRA) are two frameworks that have emerged for\naddressing this problem and have been adopted widely in practice. In this work,\nwe develop a new SpFT framework, based on ideas from neural network pruning. At\na high level, we first identify ``important'' neurons/nodes using feature\nimportance metrics from network pruning (specifically, we use the structural\npruning method), and then perform fine-tuning by restricting to weights\ninvolving these neurons. Experiments on common language tasks show our method\nimproves SpFT's memory efficiency by 20-50\\% while matching the accuracy of\nstate-of-the-art methods like LoRA's variants.",
    "pdf_url": "http://arxiv.org/pdf/2502.11439v2",
    "published": "2025-02-17T04:54:42+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11438v2",
    "title": "SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL",
    "authors": [
      "Jimin Lee",
      "Ingeol Baek",
      "Byeongjeong Kim",
      "Hyunkyung Bae",
      "Hwanhee Lee"
    ],
    "abstract": "Text-to-SQL aims to convert natural language questions into executable SQL\nqueries. While previous approaches, such as skeleton-masked selection, have\ndemonstrated strong performance by retrieving similar training examples to\nguide large language models (LLMs), they struggle in real-world scenarios where\nsuch examples are unavailable. To overcome this limitation, we propose\nSelf-Augmentation in-context learning with Fine-grained Example selection for\nText-to-SQL (SAFE-SQL), a novel framework that improves SQL generation by\ngenerating and filtering self-augmented examples. SAFE-SQL first prompts an LLM\nto generate multiple Text-to-SQL examples relevant to the test input. Then\nSAFE-SQL filters these examples through three relevance assessments,\nconstructing high-quality in-context learning examples. Using self-generated\nexamples, SAFE-SQL surpasses the previous zero-shot, and few-shot Text-to-SQL\nframeworks, achieving higher execution accuracy. Notably, our approach provides\nadditional performance gains in extra hard and unseen scenarios, where\nconventional methods often fail.",
    "pdf_url": "http://arxiv.org/pdf/2502.11438v2",
    "published": "2025-02-17T04:52:24+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.17476v1",
    "title": "Fusion of ECG Foundation Model Embeddings to Improve Early Detection of Acute Coronary Syndromes",
    "authors": [
      "Zeyuan Meng",
      "Lovely Yeswanth Panchumarthi",
      "Saurabh Kataria",
      "Alex Fedorov",
      "Jessica ZÃ¨gre-Hemsey",
      "Xiao Hu",
      "Ran Xiao"
    ],
    "abstract": "Acute Coronary Syndrome (ACS) is a life-threatening cardiovascular condition\nwhere early and accurate diagnosis is critical for effective treatment and\nimproved patient outcomes. This study explores the use of ECG foundation\nmodels, specifically ST-MEM and ECG-FM, to enhance ACS risk assessment using\nprehospital ECG data collected in ambulances. Both models leverage\nself-supervised learning (SSL), with ST-MEM using a reconstruction-based\napproach and ECG-FM employing contrastive learning, capturing unique spatial\nand temporal ECG features. We evaluate the performance of these models\nindividually and through a fusion approach, where their embeddings are combined\nfor enhanced prediction. Results demonstrate that both foundation models\noutperform a baseline ResNet-50 model, with the fusion-based approach achieving\nthe highest performance (AUROC: 0.843 +/- 0.006, AUCPR: 0.674 +/- 0.012). These\nfindings highlight the potential of ECG foundation models for early ACS\ndetection and motivate further exploration of advanced fusion strategies to\nmaximize complementary feature utilization.",
    "pdf_url": "http://arxiv.org/pdf/2502.17476v1",
    "published": "2025-02-17T04:50:56+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11437v1",
    "title": "Learning Dexterous Bimanual Catch Skills through Adversarial-Cooperative Heterogeneous-Agent Reinforcement Learning",
    "authors": [
      "Taewoo Kim",
      "Youngwoo Yoon",
      "Jaehong Kim"
    ],
    "abstract": "Robotic catching has traditionally focused on single-handed systems, which\nare limited in their ability to handle larger or more complex objects. In\ncontrast, bimanual catching offers significant potential for improved dexterity\nand object handling but introduces new challenges in coordination and control.\nIn this paper, we propose a novel framework for learning dexterous bimanual\ncatching skills using Heterogeneous-Agent Reinforcement Learning (HARL). Our\napproach introduces an adversarial reward scheme, where a throw agent increases\nthe difficulty of throws-adjusting speed-while a catch agent learns to\ncoordinate both hands to catch objects under these evolving conditions. We\nevaluate the framework in simulated environments using 15 different objects,\ndemonstrating robustness and versatility in handling diverse objects. Our\nmethod achieved approximately a 2x increase in catching reward compared to\nsingle-agent baselines across 15 diverse objects.",
    "pdf_url": "http://arxiv.org/pdf/2502.11437v1",
    "published": "2025-02-17T04:50:45+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11436v1",
    "title": "ADO: Automatic Data Optimization for Inputs in LLM Prompts",
    "authors": [
      "Sam Lin",
      "Wenyue Hua",
      "Lingyao Li",
      "Zhenting Wang",
      "Yongfeng Zhang"
    ],
    "abstract": "This study explores a novel approach to enhance the performance of Large\nLanguage Models (LLMs) through the optimization of input data within prompts.\nWhile previous research has primarily focused on refining instruction\ncomponents and augmenting input data with in-context examples, our work\ninvestigates the potential benefits of optimizing the input data itself. We\nintroduce a two-pronged strategy for input data optimization: content\nengineering and structural reformulation. Content engineering involves imputing\nmissing values, removing irrelevant attributes, and enriching profiles by\ngenerating additional information inferred from existing attributes. Subsequent\nto content engineering, structural reformulation is applied to optimize the\npresentation of the modified content to LLMs, given their sensitivity to input\nformat. Our findings suggest that these optimizations can significantly improve\nthe performance of LLMs in various tasks, offering a promising avenue for\nfuture research in prompt engineering. The source code is available at\nhttps://anonymous.4open.science/r/ADO-6BC5/",
    "pdf_url": "http://arxiv.org/pdf/2502.11436v1",
    "published": "2025-02-17T04:50:41+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11435v2",
    "title": "SMART: Self-Aware Agent for Tool Overuse Mitigation",
    "authors": [
      "Cheng Qian",
      "Emre Can Acikgoz",
      "Hongru Wang",
      "Xiusi Chen",
      "Avirup Sil",
      "Dilek Hakkani-TÃ¼r",
      "Gokhan Tur",
      "Heng Ji"
    ],
    "abstract": "Current Large Language Model (LLM) agents demonstrate strong reasoning and\ntool use capabilities, but often lack self-awareness, failing to balance these\napproaches effectively. This imbalance leads to Tool Overuse, where models\nunnecessarily rely on external tools for tasks solvable with parametric\nknowledge, increasing computational overhead. Inspired by human metacognition,\nwe introduce SMART (Strategic Model-Aware Reasoning with Tools), a paradigm\nthat enhances an agent's self-awareness to optimize task handling and reduce\ntool overuse. To support this paradigm, we introduce SMART-ER, a dataset\nspanning three domains, where reasoning alternates between parametric knowledge\nand tool-dependent steps, with each step enriched by rationales explaining when\ntools are necessary. Through supervised training, we develop SMARTAgent, a\nfamily of models that dynamically balance parametric knowledge and tool use.\nEvaluations show that SMARTAgent reduces tool use by 24% while improving\nperformance by over 37%, enabling 7B-scale models to match its 70B counterpart\nand GPT-4o. Additionally, SMARTAgent generalizes to out-of-distribution test\ndata like GSM8K and MINTQA, maintaining accuracy with just one-fifth the tool\ncalls. These highlight the potential of strategic tool use to enhance\nreasoning, mitigate overuse, and bridge the gap between model size and\nperformance, advancing intelligent and resource-efficient agent designs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11435v2",
    "published": "2025-02-17T04:50:37+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.15777v1",
    "title": "TSS GAZ PTP: Towards Improving Gumbel AlphaZero with Two-stage Self-play for Multi-constrained Electric Vehicle Routing Problems",
    "authors": [
      "Hui Wang",
      "Xufeng Zhang",
      "Xiaoyu Zhang",
      "Zhenhuan Ding",
      "Chaoxu Mu"
    ],
    "abstract": "Recently, Gumbel AlphaZero~(GAZ) was proposed to solve classic combinatorial\noptimization problems such as TSP and JSSP by creating a carefully designed\ncompetition model~(consisting of a learning player and a competitor player),\nwhich leverages the idea of self-play. However, if the competitor is too strong\nor too weak, the effectiveness of self-play training can be reduced,\nparticularly in complex CO problems. To address this problem, we further\npropose a two-stage self-play strategy to improve the GAZ method~(named TSS GAZ\nPTP). In the first stage, the learning player uses the enhanced policy network\nbased on the Gumbel Monte Carlo Tree Search~(MCTS), and the competitor uses the\nhistorical best trained policy network~(acts as a greedy player). In the second\nstage, we employ Gumbel MCTS for both players, which makes the competition\nfiercer so that both players can continuously learn smarter trajectories. We\nfirst investigate the performance of our proposed TSS GAZ PTP method on TSP\nsince it is also used as a test problem by the original GAZ. The results show\nthe superior performance of TSS GAZ PTP. Then we extend TSS GAZ PTP to deal\nwith multi-constrained Electric Vehicle Routing Problems~(EVRP), which is a\nrecently well-known real application research topic and remains challenging as\na complex CO problem. Impressively, the experimental results show that the TSS\nGAZ PTP outperforms the state-of-the-art Deep Reinforcement Learning methods in\nall types of instances tested and outperforms the optimization solver in tested\nlarge-scale instances, indicating the importance and promising of employing\nmore dynamic self-play strategies for complex CO problems.",
    "pdf_url": "http://arxiv.org/pdf/2502.15777v1",
    "published": "2025-02-17T04:47:36+00:00",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11434v1",
    "title": "The blazar PKS 0605-085 as the origin of the KM3-230213A ultra high energy neutrino event",
    "authors": [
      "T. A. Dzhatdoev"
    ],
    "abstract": "The KM3Net Collaboration has recently reported on the observation of a\nremarkable event KM3-230213A that could have been produced by an ultra high\nenergy cosmic neutrino. The origin of this event is still unclear. In\nparticular, the cosmogenic neutrino scenario is not favoured due to the\nnon-observation of a similar event by the IceCube detector, and most galactic\nscenarios are disfavoured as well. We show that the blazar PKS 0605-085 is a\nviable source of the KM3-230213A event. In particular, even though this blazar\nis located at 2.4$^{\\circ}$ from the KM3-230213A event, the association between\nthe blazar and the event is not unlikely due to a sizable direction systematic\nuncertainty of $\\approx 1.5^{\\circ}$ reported by the KM3Net Collaboration.\nFurthermore, we show that the observation of a $\\approx$72 PeV neutrino from\nPKS 0605-085 is entirely possible given that a $\\approx$7.5 PeV neutrino could\nhave been observed from another blazar TXS 0506+056. Finally, we consider\n$\\gamma$-ray constraints on the number of observable neutrino events and show\nthat for the case of the external photon field production mechanism these\nconstraints could be relaxed due to the often-neglected effect of the\nisotropisation of the hadronically-produced electrons in the magnetic field of\nthe blob. We encourage further multi-wavelength observations of the blazar PKS\n0605-085.",
    "pdf_url": "http://arxiv.org/pdf/2502.11434v1",
    "published": "2025-02-17T04:47:20+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.14892v1",
    "title": "EgoSpeak: Learning When to Speak for Egocentric Conversational Agents in the Wild",
    "authors": [
      "Junhyeok Kim",
      "Min Soo Kim",
      "Jiwan Chung",
      "Jungbin Cho",
      "Jisoo Kim",
      "Sungwoong Kim",
      "Gyeongbo Sim",
      "Youngjae Yu"
    ],
    "abstract": "Predicting when to initiate speech in real-world environments remains a\nfundamental challenge for conversational agents. We introduce EgoSpeak, a novel\nframework for real-time speech initiation prediction in egocentric streaming\nvideo. By modeling the conversation from the speaker's first-person viewpoint,\nEgoSpeak is tailored for human-like interactions in which a conversational\nagent must continuously observe its environment and dynamically decide when to\ntalk. Our approach bridges the gap between simplified experimental setups and\ncomplex natural conversations by integrating four key capabilities: (1)\nfirst-person perspective, (2) RGB processing, (3) online processing, and (4)\nuntrimmed video processing. We also present YT-Conversation, a diverse\ncollection of in-the-wild conversational videos from YouTube, as a resource for\nlarge-scale pretraining. Experiments on EasyCom and Ego4D demonstrate that\nEgoSpeak outperforms random and silence-based baselines in real time. Our\nresults also highlight the importance of multimodal input and context length in\neffectively deciding when to speak.",
    "pdf_url": "http://arxiv.org/pdf/2502.14892v1",
    "published": "2025-02-17T04:47:12+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11433v3",
    "title": "FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading",
    "authors": [
      "Guojun Xiong",
      "Zhiyang Deng",
      "Keyi Wang",
      "Yupeng Cao",
      "Haohang Li",
      "Yangyang Yu",
      "Xueqing Peng",
      "Mingquan Lin",
      "Kaleb E Smith",
      "Xiao-Yang Liu",
      "Jimin Huang",
      "Sophia Ananiadou",
      "Qianqian Xie"
    ],
    "abstract": "Large language models (LLMs) fine-tuned on multimodal financial data have\ndemonstrated impressive reasoning capabilities in various financial tasks.\nHowever, they often struggle with multi-step, goal-oriented scenarios in\ninteractive financial markets, such as trading, where complex agentic\napproaches are required to improve decision-making. To address this, we propose\n\\textsc{FLAG-Trader}, a unified architecture integrating linguistic processing\n(via LLMs) with gradient-driven reinforcement learning (RL) policy\noptimization, in which a partially fine-tuned LLM acts as the policy network,\nleveraging pre-trained knowledge while adapting to the financial domain through\nparameter-efficient fine-tuning. Through policy gradient optimization driven by\ntrading rewards, our framework not only enhances LLM performance in trading but\nalso improves results on other financial-domain tasks. We present extensive\nempirical evidence to validate these enhancements.",
    "pdf_url": "http://arxiv.org/pdf/2502.11433v3",
    "published": "2025-02-17T04:45:53+00:00",
    "categories": [
      "cs.AI",
      "cs.CE",
      "q-fin.TR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11432v2",
    "title": "Maximal Inequalities for Separately Exchangeable Empirical Processes",
    "authors": [
      "Harold D. Chiang"
    ],
    "abstract": "This paper derives new maximal inequalities for empirical processes\nassociated with separately exchangeable random arrays. For fixed index\ndimension $K\\ge 1$, we establish a global maximal inequality bounding the\n$q$-th moment ($q\\in[1,\\infty)$) of the supremum of these processes. We also\nobtain a refined local maximal inequality controlling the first absolute moment\nof the supremum. Both results are proved for a general pointwise measurable\nfunction class. Our approach uses a new technique partitioning the index set\ninto transversal groups, decoupling dependencies and enabling more\nsophisticated higher moment bounds.",
    "pdf_url": "http://arxiv.org/pdf/2502.11432v2",
    "published": "2025-02-17T04:40:56+00:00",
    "categories": [
      "econ.EM",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2502.11431v1",
    "title": "Any Information Is Just Worth One Single Screenshot: Unifying Search With Visualized Information Retrieval",
    "authors": [
      "Ze Liu",
      "Zhengyang Liang",
      "Junjie Zhou",
      "Zheng Liu",
      "Defu Lian"
    ],
    "abstract": "With the popularity of multimodal techniques, it receives growing interests\nto acquire useful information in visual forms. In this work, we formally define\nan emerging IR paradigm called \\textit{Visualized Information Retrieval}, or\n\\textbf{Vis-IR}, where multimodal information, such as texts, images, tables\nand charts, is jointly represented by a unified visual format called\n\\textbf{Screenshots}, for various retrieval applications. We further make three\nkey contributions for Vis-IR. First, we create \\textbf{VIRA} (Vis-IR\nAggregation), a large-scale dataset comprising a vast collection of screenshots\nfrom diverse sources, carefully curated into captioned and question-answer\nformats. Second, we develop \\textbf{UniSE} (Universal Screenshot Embeddings), a\nfamily of retrieval models that enable screenshots to query or be queried\nacross arbitrary data modalities. Finally, we construct \\textbf{MVRB} (Massive\nVisualized IR Benchmark), a comprehensive benchmark covering a variety of task\nforms and application scenarios. Through extensive evaluations on MVRB, we\nhighlight the deficiency from existing multimodal retrievers and the\nsubstantial improvements made by UniSE. Our work will be shared with the\ncommunity, laying a solid foundation for this emerging field.",
    "pdf_url": "http://arxiv.org/pdf/2502.11431v1",
    "published": "2025-02-17T04:40:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11430v1",
    "title": "\"An Image of Ourselves in Our Minds\": How College-educated Online Dating Users Construct Profiles for Effective Self Presentation",
    "authors": [
      "Fan Zhang",
      "Yun Chen",
      "Xiaoke Zeng",
      "Tianqi Wang",
      "Long Ling",
      "RAY LC"
    ],
    "abstract": "Online dating is frequently used by individuals looking for potential\nrelationships and intimate connections. Central to dating apps is the creation\nand refinement of a dating profile, which represents the way individuals desire\nto present themselves to potential mates, while hiding information they do not\ncare to share. To investigate the way frequent users of dating apps construct\ntheir online profiles and perceive the effectiveness of strategies taken in\nmaking profiles, we conducted semi-structured interviews with 20 experienced\nusers who are Chinese college-educated young adults and uncovered the processes\nand rationales by which they make profiles for online dating, particularly in\nselecting images for inclusion. We found that participants used idealized\nphotos that exaggerated their positive personality traits, sometimes traits\nthat they do not possess but perceive others to desire, and sometimes even\ntraits they wish they had possessed. Users also strategically used photos that\nshow personality and habits without showing themselves, and often hid certain\nidentifying information to reduce privacy risks. This analysis signals\npotential factors that are key in building online dating profiles, providing\ndesign implications for systems that limit the use of inaccurate information\nwhile still promoting self-expression in relationship platforms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11430v1",
    "published": "2025-02-17T04:39:47+00:00",
    "categories": [
      "cs.HC",
      "J.4"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11429v1",
    "title": "What's in a Query: Polarity-Aware Distribution-Based Fair Ranking",
    "authors": [
      "Aparna Balagopalan",
      "Kai Wang",
      "Olawale Salaudeen",
      "Asia Biega",
      "Marzyeh Ghassemi"
    ],
    "abstract": "Machine learning-driven rankings, where individuals (or items) are ranked in\nresponse to a query, mediate search exposure or attention in a variety of\nsafety-critical settings. Thus, it is important to ensure that such rankings\nare fair. Under the goal of equal opportunity, attention allocated to an\nindividual on a ranking interface should be proportional to their relevance\nacross search queries. In this work, we examine amortized fair ranking -- where\nrelevance and attention are cumulated over a sequence of user queries to make\nfair ranking more feasible in practice. Unlike prior methods that operate on\nexpected amortized attention for each individual, we define new\ndivergence-based measures for attention distribution-based fairness in ranking\n(DistFaiR), characterizing unfairness as the divergence between the\ndistribution of attention and relevance corresponding to an individual over\ntime. This allows us to propose new definitions of unfairness, which are more\nreliable at test time. Second, we prove that group fairness is upper-bounded by\nindividual fairness under this definition for a useful class of divergence\nmeasures, and experimentally show that maximizing individual fairness through\nan integer linear programming-based optimization is often beneficial to group\nfairness. Lastly, we find that prior research in amortized fair ranking ignores\ncritical information about queries, potentially leading to a fairwashing risk\nin practice by making rankings appear more fair than they actually are.",
    "pdf_url": "http://arxiv.org/pdf/2502.11429v1",
    "published": "2025-02-17T04:38:36+00:00",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11428v1",
    "title": "Higher-Dimensional Vacuum Einstein Equations: Symmetry, New Solutions, and Ricci Solitons",
    "authors": [
      "M. M. Akbar",
      "M. Self"
    ],
    "abstract": "We show that the system of vacuum Einstein equations (i.e., Ricci-flat\nmetrics) with two hypersurface-orthogonal, commuting Killing vector fields in\n$d \\ge 5$ dimensions is invariant under the action of a one-parameter Lie\ngroup, and the group action on any metric can be expressed in a closed,\nuniversal form. This enables the generation of a one-parameter family of\nsolutions from any given ``seed\" solution of the system without solving\nadditional equations, as well as one-parameter families of local steady Ricci\nsolitons. This extends the Lie point symmetry in four dimensions, found earlier\nfor axisymmetric static vacuum systems, and provides the first example of\nsolution generation in higher-dimensional vacuum Einstein equations that can be\nrealized purely algebraically.",
    "pdf_url": "http://arxiv.org/pdf/2502.11428v1",
    "published": "2025-02-17T04:38:34+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11427v1",
    "title": "Do we Really Need Visual Instructions? Towards Visual Instruction-Free Fine-tuning for Large Vision-Language Models",
    "authors": [
      "Zikang Liu",
      "Kun Zhou",
      "Wayne Xin Zhao",
      "Dawei Gao",
      "Yaliang Li",
      "Ji-Rong Wen"
    ],
    "abstract": "Visual instruction tuning has become the predominant technology in eliciting\nthe multimodal task-solving capabilities of large vision-language models\n(LVLMs). Despite the success, as visual instructions require images as the\ninput, it would leave the gap in inheriting the task-solving capabilities from\nthe backbone LLMs, and make it costly to collect a large-scale dataset. To\naddress it, we propose ViFT, a visual instruction-free fine-tuning framework\nfor LVLMs. In ViFT, we only require the text-only instructions and image\ncaption data during training, to separately learn the task-solving and visual\nperception abilities. During inference, we extract and combine the\nrepresentations of the text and image inputs, for fusing the two abilities to\nfulfill multimodal tasks. Experimental results demonstrate that ViFT can\nachieve state-of-the-art performance on several visual reasoning and visual\ninstruction following benchmarks, with rather less training data. Our code and\ndata will be publicly released.",
    "pdf_url": "http://arxiv.org/pdf/2502.11427v1",
    "published": "2025-02-17T04:38:12+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12214v1",
    "title": "Zero Token-Driven Deep Thinking in LLMs: Unlocking the Full Potential of Existing Parameters via Cyclic Refinement",
    "authors": [
      "Guanghao Li",
      "Wenhao Jiang",
      "Li Shen",
      "Ming Tang",
      "Chun Yuan"
    ],
    "abstract": "Resource limitations often constrain the parameter counts of Large Language\nModels (LLMs), hindering their performance. While existing methods employ\nparameter sharing to reuse the same parameter set under fixed budgets, such\napproaches typically force each layer to assume multiple roles with a\npredetermined number of iterations, restricting efficiency and adaptability. In\nthis work, we propose the Zero Token Transformer (ZTT), which features a\nhead-tail decoupled parameter cycling method. We disentangle the first (head)\nand last (tail) layers from parameter cycling and iteratively refine only the\nintermediate layers. Furthermore, we introduce a Zero-Token Mechanism, an\ninternal architectural component rather than an input token, to guide\nlayer-specific computation. At each cycle, the model retrieves a zero token\n(with trainable key values) from a Zero-Token Pool, integrating it alongside\nregular tokens in the attention mechanism. The corresponding attention scores\nnot only reflect each layer's computational importance but also enable dynamic\nearly exits without sacrificing overall model accuracy. Our approach achieves\nsuperior performance under tight parameter budgets, effectively reduces\ncomputational overhead via early exits, and can be readily applied to fine-tune\nexisting pre-trained models for enhanced efficiency and adaptability.",
    "pdf_url": "http://arxiv.org/pdf/2502.12214v1",
    "published": "2025-02-17T04:37:22+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11426v2",
    "title": "Verti-Bench: A General and Scalable Off-Road Mobility Benchmark for Vertically Challenging Terrain",
    "authors": [
      "Tong Xu",
      "Chenhui Pan",
      "Madhan B. Rao",
      "Aniket Datar",
      "Anuj Pokhrel",
      "Yuanjie Lu",
      "Xuesu Xiao"
    ],
    "abstract": "Recent advancement in off-road autonomy has shown promises in deploying\nautonomous mobile robots in outdoor off-road environments. Encouraging results\nhave been reported from both simulated and real-world experiments. However,\nunlike evaluating off-road perception tasks on static datasets, benchmarking\noff-road mobility still faces significant challenges due to a variety of\nfactors, including variations in vehicle platforms and terrain properties.\nFurthermore, different vehicle-terrain interactions need to be unfolded during\nmobility evaluation, which requires the mobility systems to interact with the\nenvironments instead of comparing against a pre-collected dataset. In this\npaper, we present Verti-Bench, a mobility benchmark that focuses on extremely\nrugged, vertically challenging off-road environments. 100 unique off-road\nenvironments and 1000 distinct navigation tasks with millions of off-road\nterrain properties, including a variety of geometry and semantics, rigid and\ndeformable surfaces, and large natural obstacles, provide standardized and\nobjective evaluation in high-fidelity multi-physics simulation. Verti-Bench is\nalso scalable to various vehicle platforms with different scales and actuation\nmechanisms. We also provide datasets from expert demonstration, random\nexploration, failure cases (rolling over and getting stuck), as well as a\ngym-like interface for reinforcement learning. We use Verti-Bench to benchmark\nten off-road mobility systems, present our findings, and identify future\noff-road mobility research directions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11426v2",
    "published": "2025-02-17T04:37:19+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11425v2",
    "title": "Counterfactual-Consistency Prompting for Relative Temporal Understanding in Large Language Models",
    "authors": [
      "Jongho Kim",
      "Seung-won Hwang"
    ],
    "abstract": "Despite the advanced capabilities of large language models (LLMs), their\ntemporal reasoning ability remains underdeveloped. Prior works have highlighted\nthis limitation, particularly in maintaining temporal consistency when\nunderstanding events. For example, models often confuse mutually exclusive\ntemporal relations like ``before'' and ``after'' between events and make\ninconsistent predictions. In this work, we tackle the issue of temporal\ninconsistency in LLMs by proposing a novel counterfactual prompting approach.\nOur method generates counterfactual questions and enforces collective\nconstraints, enhancing the model's consistency. We evaluate our method on\nmultiple datasets, demonstrating significant improvements in event ordering for\nexplicit and implicit events and temporal commonsense understanding by\neffectively addressing temporal inconsistencies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11425v2",
    "published": "2025-02-17T04:37:07+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11424v1",
    "title": "Bounds for weighted Chebyshev and residual polynomials on subsets of $\\mathbb{R}$",
    "authors": [
      "Jacob S. Christiansen",
      "Barry Simon",
      "Maxim Zinchenko"
    ],
    "abstract": "We give upper and lower bounds for weighted Chebyshev and residual\npolynomials on subsets of the real line. As an application, we prove a\nSzeg\\H{o}-type theorem in the setting of Parreau--Widom sets.",
    "pdf_url": "http://arxiv.org/pdf/2502.11424v1",
    "published": "2025-02-17T04:36:55+00:00",
    "categories": [
      "math.CA",
      "41A50, 41A17, 41A44, 30C10"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11423v2",
    "title": "Exploring Persona Sentiment Sensitivity in Personalized Dialogue Generation",
    "authors": [
      "Yonghyun Jun",
      "Hwanhee Lee"
    ],
    "abstract": "Personalized dialogue systems have advanced considerably with the integration\nof user-specific personas into large language models (LLMs). However, while\nLLMs can effectively generate personalized responses, the influence of persona\nsentiment on dialogue quality remains underexplored. In this work, we conduct a\nlarge-scale analysis of dialogues generated using a range of polarized user\nprofiles. Our experiments reveal that dialogues involving negatively polarized\nusers tend to overemphasize persona attributes. In contrast, positively\npolarized profiles yield dialogues that selectively incorporate persona\ninformation, resulting in smoother interactions. Furthermore, we find that\npersonas with weak or neutral sentiment generally produce lower-quality\ndialogues. Motivated by these findings, we propose a dialogue generation\napproach that explicitly accounts for persona polarity by combining a\nturn-based generation strategy with a profile ordering mechanism and\nsentiment-aware prompting. Our study provides new insights into the sensitivity\nof LLMs to persona sentiment and offers guidance for developing more robust and\nnuanced personalized dialogue systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11423v2",
    "published": "2025-02-17T04:36:53+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11422v3",
    "title": "Planning of Heuristics: Strategic Planning on Large Language Models with Monte Carlo Tree Search for Automating Heuristic Optimization",
    "authors": [
      "Hui Wang",
      "Xufeng Zhang",
      "Chaoxu Mu"
    ],
    "abstract": "Heuristics have achieved great success in solving combinatorial optimization\nproblems~(COPs). However, heuristics designed by humans require too much domain\nknowledge and testing time. Since Large Language Models~(LLMs) possess strong\ncapabilities to understand and generate content with a knowledge base that\ncovers various domains, they offer potential ways to automatically optimize\nheuristics. To this end, we propose Planning of Heuristics~(PoH), an\noptimization method that integrates LLM self-reflection with Monte Carlo Tree\nSearch, a well-known planning algorithm. PoH iteratively refines generated\nheuristics by evaluating their performance and providing improvement\nsuggestions. Our method enables to iteratively evaluate the generated\nheuristics~(states) and improve them based on the improvement\nsuggestions~(actions) and evaluation results~(rewards), by effectively\nsimulating future states to search for paths with higher rewards. In this\npaper, we apply PoH to solve the Traveling Salesman Problem and the Flow Shop\nScheduling Problem. The experimental results show that PoH outperforms\nhand-crafted heuristics and other Automatic Heuristic Design methods based on\nLLMs, and achieves the state-of-the-art performance in automating heuristic\noptimization with LLMs to solve tested COPs, especially with large sizes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11422v3",
    "published": "2025-02-17T04:35:01+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11421v1",
    "title": "On rigid regular graphs and a problem of Babai and Pultr",
    "authors": [
      "Kolja Knauer",
      "Gil Puig i Surroca"
    ],
    "abstract": "A graph is \\textit{rigid} if it only admits the identity endomorphism. We\nshow that for every $d\\ge 3$ there exist infinitely many mutually rigid\n$d$-regular graphs of arbitrary odd girth $g\\geq 7$. Moreover, we determine the\nminimum order of a rigid $d$-regular graph for every $d\\ge 3$. This provides\nstrong positive answers to a question of van der Zypen\n[https://mathoverflow.net/q/296483, https://mathoverflow.net/q/321108].\nFurther, we use our construction to show that every finite monoid is isomorphic\nto the endomorphism monoid of a regular graph. This solves a problem of Babai\nand Pultr [J. Comb.~Theory, Ser.~B, 1980].",
    "pdf_url": "http://arxiv.org/pdf/2502.11421v1",
    "published": "2025-02-17T04:21:03+00:00",
    "categories": [
      "math.CO",
      "cs.DM"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11420v3",
    "title": "Training-Free Guidance Beyond Differentiability: Scalable Path Steering with Tree Search in Diffusion and Flow Models",
    "authors": [
      "Yingqing Guo",
      "Yukang Yang",
      "Hui Yuan",
      "Mengdi Wang"
    ],
    "abstract": "Training-free guidance enables controlled generation in diffusion and flow\nmodels, but most methods rely on gradients and assume differentiable\nobjectives. This work focuses on training-free guidance addressing challenges\nfrom non-differentiable objectives and discrete data distributions. We propose\nTreeG: Tree Search-Based Path Steering Guidance, applicable to both continuous\nand discrete settings in diffusion and flow models. TreeG offers a unified\nframework for training-free guidance by proposing, evaluating, and selecting\ncandidates at each step, enhanced with tree search over active paths and\nparallel exploration. We comprehensively investigate the design space of TreeG\nover the candidate proposal module and the evaluation function, instantiating\nTreeG into three novel algorithms. Our experiments show that TreeG consistently\noutperforms top guidance baselines in symbolic music generation, small molecule\ndesign, and enhancer DNA design with improvements of 29.01%, 16.6%, and 18.43%.\nAdditionally, we identify an inference-time scaling law showing TreeG's\nscalability in inference-time computation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11420v3",
    "published": "2025-02-17T04:20:39+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11419v2",
    "title": "InsBank: Evolving Instruction Subset for Ongoing Alignment",
    "authors": [
      "Jiayi Shi",
      "Yiwei Li",
      "Shaoxiong Feng",
      "Peiwen Yuan",
      "Xinglin Wang",
      "Yueqi Zhang",
      "Chuyi Tan",
      "Boyuan Pan",
      "Huan Ren",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "Large language models (LLMs) typically undergo instruction tuning to enhance\nalignment. Recent studies emphasize that quality and diversity of instruction\ndata are more crucial than quantity, highlighting the need to select diverse,\nhigh-quality subsets to reduce training costs. However, how to evolve these\nselected subsets alongside the development of new instruction data remains\ninsufficiently explored. To achieve LLMs' ongoing alignment, we introduce\nInstruction Bank (\\textbf{InsBank}), a continuously updated repository that\nintegrates the latest valuable instruction data. We further propose Progressive\nInstruction Bank Evolution (\\textbf{PIBE}), a novel framework designed to\nevolve InsBank effectively and efficiently over time. PIBE employs a gradual\ndata selection strategy to maintain long-term efficiency, leveraging a\nrepresentation-based diversity score to capture relationships between data\npoints and retain historical information for comprehensive diversity\nevaluation. This also allows for flexible combination of diversity and quality\nscores during data selection and ranking. Extensive experiments demonstrate\nthat PIBE significantly outperforms baselines in InsBank evolution and is able\nto extract budget-specific subsets, demonstrating its effectiveness and\nadaptability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11419v2",
    "published": "2025-02-17T04:17:53+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11418v2",
    "title": "TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents",
    "authors": [
      "Geon Lee",
      "Wenchao Yu",
      "Kijung Shin",
      "Wei Cheng",
      "Haifeng Chen"
    ],
    "abstract": "Time series data is essential in various applications, including climate\nmodeling, healthcare monitoring, and financial analytics. Understanding the\ncontextual information associated with real-world time series data is often\nessential for accurate and reliable event predictions. In this paper, we\nintroduce TimeCAP, a time-series processing framework that creatively employs\nLarge Language Models (LLMs) as contextualizers of time series data, extending\ntheir typical usage as predictors. TimeCAP incorporates two independent LLM\nagents: one generates a textual summary capturing the context of the time\nseries, while the other uses this enriched summary to make more informed\npredictions. In addition, TimeCAP employs a multi-modal encoder that synergizes\nwith the LLM agents, enhancing predictive performance through mutual\naugmentation of inputs with in-context examples. Experimental results on\nreal-world datasets demonstrate that TimeCAP outperforms state-of-the-art\nmethods for time series event prediction, including those utilizing LLMs as\npredictors, achieving an average improvement of 28.75% in F1 score.",
    "pdf_url": "http://arxiv.org/pdf/2502.11418v2",
    "published": "2025-02-17T04:17:27+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11417v2",
    "title": "DiSCo: Device-Server Collaborative LLM-Based Text Streaming Services",
    "authors": [
      "Ting Sun",
      "Penghan Wang",
      "Fan Lai"
    ],
    "abstract": "The rapid rise of large language models (LLMs) in text streaming services has\nintroduced significant cost and Quality of Experience (QoE) challenges in\nserving millions of daily requests, especially in meeting Time-To-First-Token\n(TTFT) and Time-Between-Token (TBT) requirements for real-time interactions.\nOur real-world measurements show that both server-based and on-device\ndeployments struggle to meet diverse QoE demands: server deployments face high\ncosts and last-hop issues (e.g., Internet latency and dynamics), while\non-device LLM inference is constrained by resources.\n  We introduce DiSCo, a device-server cooperative scheduler designed to\noptimize users' QoE by adaptively routing requests and migrating response\ngeneration between endpoints while maintaining cost constraints. DiSCo employs\ncost-aware scheduling, leveraging the predictable speed of on-device LLM\ninference with the flexible capacity of server-based inference to dispatch\nrequests on the fly, while introducing a token-level migration mechanism to\nensure consistent token delivery during migration. Evaluations on real-world\nworkloads -- including commercial services like OpenAI GPT and DeepSeek, and\nopen-source deployments such as LLaMA3 -- show that DiSCo can improve users'\nQoE by reducing tail TTFT (11-52\\%) and mean TTFT (6-78\\%) across different\nmodel-device configurations, while dramatically reducing serving costs by up to\n84\\% through its migration mechanism while maintaining comparable QoE levels.",
    "pdf_url": "http://arxiv.org/pdf/2502.11417v2",
    "published": "2025-02-17T04:15:45+00:00",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.13165v1",
    "title": "HedgeAgents: A Balanced-aware Multi-agent Financial Trading System",
    "authors": [
      "Xiangyu Li",
      "Yawen Zeng",
      "Xiaofen Xing",
      "Jin Xu",
      "Xiangmin Xu"
    ],
    "abstract": "As automated trading gains traction in the financial market, algorithmic\ninvestment strategies are increasingly prominent. While Large Language Models\n(LLMs) and Agent-based models exhibit promising potential in real-time market\nanalysis and trading decisions, they still experience a significant -20% loss\nwhen confronted with rapid declines or frequent fluctuations, impeding their\npractical application. Hence, there is an imperative to explore a more robust\nand resilient framework. This paper introduces an innovative multi-agent\nsystem, HedgeAgents, aimed at bolstering system robustness via ``hedging''\nstrategies. In this well-balanced system, an array of hedging agents has been\ntailored, where HedgeAgents consist of a central fund manager and multiple\nhedging experts specializing in various financial asset classes. These agents\nleverage LLMs' cognitive capabilities to make decisions and coordinate through\nthree types of conferences. Benefiting from the powerful understanding of LLMs,\nour HedgeAgents attained a 70% annualized return and a 400% total return over a\nperiod of 3 years. Moreover, we have observed with delight that HedgeAgents can\neven formulate investment experience comparable to those of human experts\n(https://hedgeagents.github.io/).",
    "pdf_url": "http://arxiv.org/pdf/2502.13165v1",
    "published": "2025-02-17T04:13:19+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "q-fin.TR"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11416v1",
    "title": "Generalized quantum two level model and its application in astrophysics",
    "authors": [
      "Orkash Amat",
      "Nurimangul Nurmamat",
      "Yong-Feng Huang",
      "Cheng-Ming Li",
      "Jin-Jun Geng",
      "Chen-RanHu",
      "Ze-Cheng Zou",
      "Xiao-Fei Dong",
      "Chen Deng",
      "Fan Xu",
      "Xiao-li Zhang",
      "Chen Du"
    ],
    "abstract": "Complicated time-dependent curved spacetime and electric field are involved\nin many astrophysical situations, including the early universe, Hawking\nradiation, the Schwinger effect, and gravitational pair production. In this\nLetter, a generalized quantum two-level model (GQTLM) is developed, which is\napplicable to arbitrary time-dependent curved spacetime and electric field. The\nmodel is found to be consistent with quantum kinetic theory, and is\ncharacterized by its simplicity and versatility. The momentum distribution of\nparticles and the effects of gravitational distortions can be correctly\ndescribed. Quantum properties concerning vortex structures, such as the\nintrinsic orbital angular momentum of particles and antiparticles can also be\nconveniently calculated. The model is expected to significantly advance the\nquantum exploration of the universe. It could refine the prediction of\nprimordial gravitational waves and relevant non-Gaussian signals, extend the\ncalculation of Hawking radiation to general black hole configurations, help to\ndistinguish neutron stars from strange quark stars, and elucidate the\ngravitational pair production mechanism.",
    "pdf_url": "http://arxiv.org/pdf/2502.11416v1",
    "published": "2025-02-17T04:05:16+00:00",
    "categories": [
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.13164v1",
    "title": "Multi-Agent Actor-Critic Generative AI for Query Resolution and Analysis",
    "authors": [
      "Mohammad Wali Ur Rahman",
      "Ric Nevarez",
      "Lamia Tasnim Mim",
      "Salim Hariri"
    ],
    "abstract": "In this paper, we introduce MASQRAD (Multi-Agent Strategic Query Resolution\nand Diagnostic tool), a transformative framework for query resolution based on\nthe actor-critic model, which utilizes multiple generative AI agents. MASQRAD\nis excellent at translating imprecise or ambiguous user inquiries into precise\nand actionable requests. This framework generates pertinent visualizations and\nresponses to these focused queries, as well as thorough analyses and insightful\ninterpretations for users. MASQRAD addresses the common shortcomings of\nexisting solutions in domains that demand fast and precise data interpretation,\nsuch as their incapacity to successfully apply AI for generating actionable\ninsights and their challenges with the inherent ambiguity of user queries.\nMASQRAD functions as a sophisticated multi-agent system but \"masquerades\" to\nusers as a single AI entity, which lowers errors and enhances data interaction.\nThis approach makes use of three primary AI agents: Actor Generative AI, Critic\nGenerative AI, and Expert Analysis Generative AI. Each is crucial for creating,\nenhancing, and evaluating data interactions. The Actor AI generates Python\nscripts to generate data visualizations from large datasets within operational\nconstraints, and the Critic AI rigorously refines these scripts through\nmulti-agent debate. Finally, the Expert Analysis AI contextualizes the outcomes\nto aid in decision-making. With an accuracy rate of 87\\% when handling tasks\nrelated to natural language visualization, MASQRAD establishes new benchmarks\nfor automated data interpretation and showcases a noteworthy advancement that\nhas the potential to revolutionize AI-driven applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.13164v1",
    "published": "2025-02-17T04:03:15+00:00",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11415v1",
    "title": "Weak Closed-loop Solvability for Discrete-time Linear-Quadratic Optimal Control",
    "authors": [
      "Yue Sun",
      "Xianping Wu",
      "Xun Li"
    ],
    "abstract": "In this paper, the open-loop, closed-loop, and weak closed-loop solvability\nfor discrete-time linear-quadratic (LQ) control problem is considered due to\nthe fact that it is always open-loop optimal solvable if the LQ control problem\nis closed-loop optimal solvable but not vice versa. The contributions are\ntwo-fold. On the one hand, the equivalent relationship between the closed-loop\noptimal solvability and the solution of the generalized Riccati equation is\ngiven. On the other hand, when the system is merely open-loop solvable, we have\nfound the equivalent existence form of the optimal solution by perturbation\nmethod, which is said to be a weak closed-loop solution. Moreover, it obtains\nthat there is an open-loop optimal control with a linear feedback form of the\nstate. The essential technique is to solve the forward and backward difference\nequations by iteration. An example sheds light on the theoretical results\nestablished.",
    "pdf_url": "http://arxiv.org/pdf/2502.11415v1",
    "published": "2025-02-17T04:02:18+00:00",
    "categories": [
      "math.OC",
      "org"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11414v2",
    "title": "Unbiased Learning to Rank with Query-Level Click Propensity Estimation: Beyond Pointwise Observation and Relevance",
    "authors": [
      "Lulu Yu",
      "Keping Bi",
      "Jiafeng Guo",
      "Shihao Liu",
      "Dawei Yin",
      "Xueqi Cheng"
    ],
    "abstract": "Most existing unbiased learning-to-rank (ULTR) approaches are based on the\nuser examination hypothesis, which assumes that users will click a result only\nif it is both relevant and observed (typically modeled by position). However,\nin real-world scenarios, users often click only one or two results after\nexamining multiple relevant options, due to limited patience or because their\ninformation needs have already been satisfied. Motivated by this, we propose a\nquery-level click propensity model to capture the probability that users will\nclick on different result lists, allowing for non-zero probabilities that users\nmay not click on an observed relevant result. We hypothesize that this\npropensity increases when more potentially relevant results are present, and\nrefer to this user behavior as relevance saturation bias. Our method introduces\na Dual Inverse Propensity Weighting (DualIPW) mechanism -- combining\nquery-level and position-level IPW -- to address both relevance saturation and\nposition bias. Through theoretical derivation, we prove that DualIPW can learn\nan unbiased ranking model. Experiments on the real-world Baidu-ULTR dataset\ndemonstrate that our approach significantly outperforms state-of-the-art ULTR\nbaselines. The code and dataset information can be found at\nhttps://github.com/Trustworthy-Information-Access/DualIPW.",
    "pdf_url": "http://arxiv.org/pdf/2502.11414v2",
    "published": "2025-02-17T03:55:51+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11413v1",
    "title": "Statistical Query Hardness of Multiclass Linear Classification with Random Classification Noise",
    "authors": [
      "Ilias Diakonikolas",
      "Mingchen Ma",
      "Lisheng Ren",
      "Christos Tzamos"
    ],
    "abstract": "We study the task of Multiclass Linear Classification (MLC) in the\ndistribution-free PAC model with Random Classification Noise (RCN).\nSpecifically, the learner is given a set of labeled examples $(x, y)$, where\n$x$ is drawn from an unknown distribution on $R^d$ and the labels are generated\nby a multiclass linear classifier corrupted with RCN. That is, the label $y$ is\nflipped from $i$ to $j$ with probability $H_{ij}$ according to a known noise\nmatrix $H$ with non-negative separation $\\sigma: = \\min_{i \\neq j}\nH_{ii}-H_{ij}$. The goal is to compute a hypothesis with small 0-1 error. For\nthe special case of two labels, prior work has given polynomial-time algorithms\nachieving the optimal error. Surprisingly, little is known about the complexity\nof this task even for three labels. As our main contribution, we show that the\ncomplexity of MLC with RCN becomes drastically different in the presence of\nthree or more labels. Specifically, we prove super-polynomial Statistical Query\n(SQ) lower bounds for this problem. In more detail, even for three labels and\nconstant separation, we give a super-polynomial lower bound on the complexity\nof any SQ algorithm achieving optimal error. For a larger number of labels and\nsmaller separation, we show a super-polynomial SQ lower bound even for the\nweaker goal of achieving any constant factor approximation to the optimal loss\nor even beating the trivial hypothesis.",
    "pdf_url": "http://arxiv.org/pdf/2502.11413v1",
    "published": "2025-02-17T03:54:38+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11412v3",
    "title": "Quantum decision trees with information entropy",
    "authors": [
      "Zhelun Li",
      "Koji Terashi"
    ],
    "abstract": "We present a classification algorithm for quantum states, inspired by\ndecision-tree methods. To adapt the decision-tree framework to the\nprobabilistic nature of quantum measurements, we utilize conditional\nprobabilities to compute information gain, thereby optimizing the measurement\nscheme. For each measurement shot on an unknown quantum state, the algorithm\nselects the observable with the highest expected information gain, continuing\nuntil convergence. We demonstrate using the simulations that this algorithm\neffectively identifies quantum states sampled from the Haar random\ndistribution. However, despite not relying on circuit-based quantum neural\nnetworks, the algorithm still encounters challenges akin to the barren plateau\nproblem. In the leading order, we show that the information gain is\nproportional to the variance of the observable's expectation values over\ncandidate states. As the system size increases, this variance, and consequently\nthe information gain, are exponentially suppressed, which poses significant\nchallenges for classifying general Haar-random quantum states. Finally, we\napply the quantum decision tree to classify the ground states of various\nHamiltonians using physically-motivated observables. On both simulators and\nquantum computers, the quantum decision tree yields better performances when\ncompared to methods that are not information-optimized. This indicates that the\nmeasurement of physically-motivated observables can significantly improve the\nclassification performance, guiding towards the future direction of this\napproach.",
    "pdf_url": "http://arxiv.org/pdf/2502.11412v3",
    "published": "2025-02-17T03:51:40+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11411v1",
    "title": "Detecting and Filtering Unsafe Training Data via Data Attribution",
    "authors": [
      "Yijun Pan",
      "Taiwei Shi",
      "Jieyu Zhao",
      "Jiaqi W. Ma"
    ],
    "abstract": "Large language models (LLMs) are vulnerable to unsafe training data that even\nsmall amounts of unsafe data can lead to harmful model behaviors. Detecting and\nfiltering such unsafe training data is essential for trustworthy model\ndevelopment. Current state-of-the-art (SOTA) approaches typically rely on\ntraining moderation classifiers which requires significant computational\noverhead and are limited to predefined taxonomies, making them less adaptable\nto evolving safety concerns. Moreover, these classifiers lack insight into the\ntraining process, limiting their effectiveness in filtering unsafe data. To\naddress these limitations, we propose DABUF, leveraging data attribution to\ndetect and filter unsafe training data by attributing harmful model outputs to\ninfluential training data points. DABUF enables flexible identification of\nvarious unsafe data types without predefined taxonomies. However, in practice,\nmodel outputs can be complex with combined safe linguistic features and unsafe\ncontent, leading to reduced attribution accuracy. In such cases, DABUF will\nintegrate moderation classifiers to identify a minimal subset of unsafe\ntraining data for targeted attribution (such as jailbreak). When model outputs\nare relatively straightforward, DABUF uses model outputs directly as the\nattribution targets. We evaluate the performance on two different tasks: in\nfiltering jailbreaking training data and in identifying and mitigating gender\nbias. DABUF outperforms SOTA approaches by up to 7.5\\% in detection AUPRC in\njailbreaking scenarios, and 44.1\\% in detecting gender bias. Moreover,\nretraining on DABUF-filtered data leads to higher model safety across\nexperiments, underscoring its versatility in addressing a broad spectrum of\nunsafe data issues.",
    "pdf_url": "http://arxiv.org/pdf/2502.11411v1",
    "published": "2025-02-17T03:50:58+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11410v1",
    "title": "Structure based SAT dataset for analysing GNN generalisation",
    "authors": [
      "Yi Fu",
      "Anthony Tompkins",
      "Yang Song",
      "Maurice Pagnucco"
    ],
    "abstract": "Satisfiability (SAT) solvers based on techniques such as conflict driven\nclause learning (CDCL) have produced excellent performance on both synthetic\nand real world industrial problems. While these CDCL solvers only operate on a\nper-problem basis, graph neural network (GNN) based solvers bring new benefits\nto the field by allowing practitioners to exploit knowledge gained from solved\nproblems to expedite solving of new SAT problems. However, one specific area\nthat is often studied in the context of CDCL solvers, but largely overlooked in\nGNN solvers, is the relationship between graph theoretic measure of structure\nin SAT problems and the generalisation ability of GNN solvers. To bridge the\ngap between structural graph properties (e.g., modularity, self-similarity) and\nthe generalisability (or lack thereof) of GNN based SAT solvers, we present\nStructureSAT: a curated dataset, along with code to further generate novel\nexamples, containing a diverse set of SAT problems from well known problem\ndomains. Furthermore, we utilise a novel splitting method that focuses on\ndeconstructing the families into more detailed hierarchies based on their\nstructural properties. With the new dataset, we aim to help explain problematic\ngeneralisation in existing GNN SAT solvers by exploiting knowledge of\nstructural graph properties. We conclude with multiple future directions that\ncan help researchers in GNN based SAT solving develop more effective and\ngeneralisable SAT solvers.",
    "pdf_url": "http://arxiv.org/pdf/2502.11410v1",
    "published": "2025-02-17T03:49:25+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11409v1",
    "title": "Electroweak baryogenesis and electron EDM in the TNMSSM",
    "authors": [
      "Xiang Yang",
      "Ming-Hui Guo",
      "Jin-Lei Yang",
      "Qing-Hua Li",
      "Tai-Fu Feng"
    ],
    "abstract": "We have studied the impact of CP-violating (CPV) effects on electroweak\nbaryogenesis (EWBG) and the electric dipole moment (EDM) of electron ($d_e$),\nthe electric dipole moment (EDM) of mercury neutron ($d_n$) and the electric\ndipole moment (EDM) of ($d_{Hg}$) in an extension of the Minimal Supersymmetric\nStandard Model (MSSM). The model incorporating a $SU(2)$ triplet with\nhypercharges of $\\pm1$ and a gauge singlet from the standard model that is\nmutually coupled, is collectively referred to as the next-to-minimal\nsupersymmetric standard model with triplets (TNMSSM). Furthermore, we discuss\nthe strong first-order phase transition (PT) achieved by this model via\ntree-level effects. The numerical results indicate that the TNMSSM can account\nfor the observed baryon asymmetry. Additionally, the regions favored by EWBG\ncan be compatible with the corresponding electron EDM bounds when different\ncontributions to the $d_e$ cancel each other out.",
    "pdf_url": "http://arxiv.org/pdf/2502.11409v1",
    "published": "2025-02-17T03:49:23+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11408v1",
    "title": "Precise GPS-Denied UAV Self-Positioning via Context-Enhanced Cross-View Geo-Localization",
    "authors": [
      "Yuanze Xu",
      "Ming Dai",
      "Wenxiao Cai",
      "Wankou Yang"
    ],
    "abstract": "Image retrieval has been employed as a robust complementary technique to\naddress the challenge of Unmanned Aerial Vehicles (UAVs) self-positioning.\nHowever, most existing methods primarily focus on localizing objects captured\nby UAVs through complex part-based representations, often overlooking the\nunique challenges associated with UAV self-positioning, such as fine-grained\nspatial discrimination requirements and dynamic scene variations. To address\nthe above issues, we propose the Context-Enhanced method for precise UAV\nSelf-Positioning (CEUSP), specifically designed for UAV self-positioning tasks.\nCEUSP integrates a Dynamic Sampling Strategy (DSS) to efficiently select\noptimal negative samples, while the Rubik's Cube Attention (RCA) module,\ncombined with the Context-Aware Channel Integration (CACI) module, enhances\nfeature representation and discrimination by exploiting interdimensional\ninteractions, inspired by the rotational mechanics of a Rubik's Cube. Extensive\nexperimental validate the effectiveness of the proposed method, demonstrating\nnotable improvements in feature representation and UAV self-positioning\naccuracy within complex urban environments. Our approach achieves\nstate-of-the-art performance on the DenseUAV dataset, which is specifically\ndesigned for dense urban contexts, and also delivers competitive results on the\nwidely recognized University-1652 benchmark.",
    "pdf_url": "http://arxiv.org/pdf/2502.11408v1",
    "published": "2025-02-17T03:49:18+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11407v1",
    "title": "Gensor: A Graph-based Construction Tensor Compilation Method for Deep Learning",
    "authors": [
      "Hangda Liu",
      "Boyu Diao",
      "Yu Yang",
      "Wenxin Chen",
      "Xiaohui Peng",
      "Yongjun Xu"
    ],
    "abstract": "High-performance deep learning depends on efficient tensor programs. In\nrecent years, automatic tensor program optimization, also known as tensor\ncompilation, has emerged as the primary approach to generating efficient tensor\nprograms. However, how to generate kernels with higher performance in a shorter\ntime is still the key challenge. In this paper, we present Gensor, a\ngraph-based construction tensor compilation method for deep learning, to\nfurther improve the performance of construction tensor compilation. Unlike\nexisting tree-based methods, Gensor abstracts construction space into a graph\nstructure. Gensor then explores the construction space with Markov analysis.\nGensor takes tensor programs as states and models scheduling primitives as\ntransition actions between these states. Therefore, the process of tensor\nprogram construction optimization is abstracted as a graph traversal process.\nThis approach expands the optimization space, improving operator performance\nwhile ensuring rapid optimization. Extensive experiments with typical operators\ndemonstrate that Gensor significantly outperforms the state-of-the-art methods\non GPUs for both cloud servers and edge devices. As a result, Gensor can\ngenerate operator kernels in seconds, with performance increasing by 18\\% on\naverage, reaching a maximum of 30\\%. It also achieves high speedup for\nend-to-end models like ResNet-50 and GPT-2, with an average acceleration of\n20\\%.",
    "pdf_url": "http://arxiv.org/pdf/2502.11407v1",
    "published": "2025-02-17T03:47:15+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11406v2",
    "title": "Flavor dependence of Energy-energy correlators",
    "authors": [
      "Liliana ApolinÃ¡rio",
      "Raghav Kunnawalkam Elayavalli",
      "Nuno Olavo Madureira",
      "Jun-Xing Sheng",
      "Xin-Nian Wang",
      "Zhong Yang"
    ],
    "abstract": "Energy-energy correlators (EECs) within high energy jets serve as a key\nexperimentally accessible quantity to probe the scale and structure of the\nquark-gluon plasma (QGP) in relativistic heavy-ion collisions. The CMS\nCollaboration's first measurement of the modification to the EEC within single\ninclusive jets in Pb+Pb collisions relative to p+p collisions reveals a\nsignificant enhancement at small angles, which may arise from jet transverse\nmomentum $p_T$ selection biases due to jet energy loss. We investigate the\ndependence of jet EECs on the flavor of the initiating parton. The EEC\ndistribution of a gluon jet is broader and the peak of transition from\nperturbative to non-perturbative regime occurs at a larger angle than a quark\njet. Such flavor dependence leads to the different EECs for $\\gamma$-jets and\nsingle inclusive jets due to their different flavor composition. It is also\nresponsible for a colliding energy dependence of EECs of single inclusive jets\nat fixed jet energy. We also investigate the impact of flavor composition\nvariation on the $p_T$ dependence of the jet EEC. We further propose that a\nchange in the gluon jet fraction in A+A collisions compared to p+p can also\ncontribute to a non-negligible enhancement of the medium modified EEC at small\nangles. Using the \\textsc{Jewel} model, we predict the reduction of the gluon\njet fraction in A+A collisions and estimate its impact on the EEC.",
    "pdf_url": "http://arxiv.org/pdf/2502.11406v2",
    "published": "2025-02-17T03:46:15+00:00",
    "categories": [
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11405v1",
    "title": "LayAlign: Enhancing Multilingual Reasoning in Large Language Models via Layer-Wise Adaptive Fusion and Alignment Strategy",
    "authors": [
      "Zhiwen Ruan",
      "Yixia Li",
      "He Zhu",
      "Longyue Wang",
      "Weihua Luo",
      "Kaifu Zhang",
      "Yun Chen",
      "Guanhua Chen"
    ],
    "abstract": "Despite being pretrained on multilingual corpora, large language models\n(LLMs) exhibit suboptimal performance on low-resource languages. Recent\napproaches have leveraged multilingual encoders alongside LLMs by introducing\ntrainable parameters connecting the two models. However, these methods\ntypically focus on the encoder's output, overlooking valuable information from\nother layers. We propose \\aname (\\mname), a framework that integrates\nrepresentations from all encoder layers, coupled with the \\attaname mechanism\nto enable layer-wise interaction between the LLM and the multilingual encoder.\nExtensive experiments on multilingual reasoning tasks, along with analyses of\nlearned representations, show that our approach consistently outperforms\nexisting baselines.",
    "pdf_url": "http://arxiv.org/pdf/2502.11405v1",
    "published": "2025-02-17T03:45:03+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11404v2",
    "title": "ToolCoder: A Systematic Code-Empowered Tool Learning Framework for Large Language Models",
    "authors": [
      "Hanxing Ding",
      "Shuchang Tao",
      "Liang Pang",
      "Zihao Wei",
      "Jinyang Gao",
      "Bolin Ding",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "Tool learning has emerged as a crucial capability for large language models\n(LLMs) to solve complex real-world tasks through interaction with external\ntools. Existing approaches face significant challenges, including reliance on\nhand-crafted prompts, difficulty in multi-step planning, and lack of precise\nerror diagnosis and reflection mechanisms. We propose ToolCoder, a novel\nframework that reformulates tool learning as a code generation task. Inspired\nby software engineering principles, ToolCoder transforms natural language\nqueries into structured Python function scaffold and systematically breaks down\ntasks with descriptive comments, enabling LLMs to leverage coding paradigms for\ncomplex reasoning and planning. It then generates and executes function\nimplementations to obtain final responses. Additionally, ToolCoder stores\nsuccessfully executed functions in a repository to promote code reuse, while\nleveraging error traceback mechanisms for systematic debugging, optimizing both\nexecution efficiency and robustness. Experiments demonstrate that ToolCoder\nachieves superior performance in task completion accuracy and execution\nreliability compared to existing approaches, establishing the effectiveness of\ncode-centric approaches in tool learning.",
    "pdf_url": "http://arxiv.org/pdf/2502.11404v2",
    "published": "2025-02-17T03:42:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11403v2",
    "title": "AdS gravastar and bulk-cone singularities",
    "authors": [
      "Heng-Yu Chen",
      "Yasuaki Hikida",
      "Yasutaka Koga"
    ],
    "abstract": "The horizon of black hole is surrounded by the photon sphere and an outside\nobserver cannot easily examine the geometry inside the photon sphere. In this\nnote, we propose a way to investigate the region from dual conformal field\ntheory by making use of AdS/CFT correspondence. We first construct gravastar\ngeometry as an asymptotic anti-de Sitter spacetime, where the region inside the\nphoton sphere is replaced by a horizon-less geometry. It is known that\nbulk-cone singularities in the retarded Green function in dual conformal field\ntheory can encode the bulk null geodesics. We then compute numerically the\nretarded Green function from the bulk theory and observe bulk-cone\nsingularities corresponding to null geodesics traveling into the interior\nregion. In this way, we show that it is possible to examine the region inside\nthe photon sphere from bulk-cone singularities of dual conformal field theory.",
    "pdf_url": "http://arxiv.org/pdf/2502.11403v2",
    "published": "2025-02-17T03:41:46+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.11402v2",
    "title": "Enhanced Algorithms for the Representation of integers by Binary Quadratic forms: Reduction to Subset Sum",
    "authors": [
      "Maher Mamah"
    ],
    "abstract": "In this paper, we present efficient algorithms for solving the Diophantine\nequation $f(x, y) = m$ for an arbitrary definite binary quadratic form $f$,\ngiven the factorization of $m$. While Cornacchia's algorithm to solve $x^2 +\ndy^2 = m$ is efficient in many cases, its runtime becomes exponentially large\nwhen $m$ is highly composite and encounters subtleties when generalized to\narbitrary forms $f$. To address these issues, we give a reduction from our\nproblem to an instance of the Subset sum, a weakly NP complete problem,\nallowing for more efficient solutions. Leveraging this approach, we develop\ndeterministic algorithms that adapt to different cases based on\n$\\mathrm{disc}(f)$ and $ m $. In particular, when $|\\mathrm{disc}(f)| =\n\\mathrm{polylog}(m) $, we provide a polynomial time solution that remains\nefficient regardless of the structure of $ m $. For more general cases, we\npresent an algorithm that improves upon Cornacchia's method, achieving a\nquadratic speedup. Recently, the problem of representing integers by a form $ f\n$ found important applications in elliptic curves and isogeny based\ncryptography, where these algorithms are central to solving norm form\nequations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11402v2",
    "published": "2025-02-17T03:41:40+00:00",
    "categories": [
      "math.NT",
      "math.CO",
      "11Y16 (primary), 11Y40 (secondary)"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11401v2",
    "title": "Following the Autoregressive Nature of LLM Embeddings via Compression and Alignment",
    "authors": [
      "Jingcheng Deng",
      "Zhongtao Jiang",
      "Liang Pang",
      "Liwei Chen",
      "Kun Xu",
      "Zihao Wei",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "A new trend uses LLMs as dense text encoders via contrastive learning.\nHowever, since LLM embeddings predict the probability distribution of the next\ntoken, they are inherently generative and distributive, conflicting with\ncontrastive learning, which requires embeddings to capture full-text semantics\nand align via cosine similarity. This discrepancy hinders the full utilization\nof LLMs' pre-training capabilities, resulting in inefficient learning. In\nresponse to this issue, we propose AutoRegEmbed, a new contrastive learning\nmethod built on embedding conditional probability distributions, which\nintegrates two core tasks: information compression and conditional distribution\nalignment. The information compression task encodes text into the embedding\nspace, ensuring that the embedding vectors capture global semantics. The\nconditional distribution alignment task focuses on aligning text embeddings\nwith positive samples embeddings by leveraging the conditional distribution of\nembeddings while simultaneously reducing the likelihood of generating negative\nsamples from text embeddings, thereby achieving embedding alignment and\nuniformity. Experimental results demonstrate that our method significantly\noutperforms traditional contrastive learning approaches and achieves\nperformance comparable to state-of-the-art models when using the same amount of\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2502.11401v2",
    "published": "2025-02-17T03:36:25+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11400v1",
    "title": "Revisiting Robust RAG: Do We Still Need Complex Robust Training in the Era of Powerful LLMs?",
    "authors": [
      "Hanxing Ding",
      "Shuchang Tao",
      "Liang Pang",
      "Zihao Wei",
      "Liwei Chen",
      "Kun Xu",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "Retrieval-augmented generation (RAG) systems often suffer from performance\ndegradation when encountering noisy or irrelevant documents, driving\nresearchers to develop sophisticated training strategies to enhance their\nrobustness against such retrieval noise. However, as large language models\n(LLMs) continue to advance, the necessity of these complex training methods is\nincreasingly questioned. In this paper, we systematically investigate whether\ncomplex robust training strategies remain necessary as model capacity grows.\nThrough comprehensive experiments spanning multiple model architectures and\nparameter scales, we evaluate various document selection methods and\nadversarial training techniques across diverse datasets. Our extensive\nexperiments consistently demonstrate that as models become more powerful, the\nperformance gains brought by complex robust training methods drop off\ndramatically. We delve into the rationale and find that more powerful models\ninherently exhibit superior confidence calibration, better generalization\nacross datasets (even when trained with randomly selected documents), and\noptimal attention mechanisms learned with simpler strategies. Our findings\nsuggest that RAG systems can benefit from simpler architectures and training\nstrategies as models become more powerful, enabling more scalable applications\nwith minimal complexity.",
    "pdf_url": "http://arxiv.org/pdf/2502.11400v1",
    "published": "2025-02-17T03:34:31+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11399v1",
    "title": "FontCraft: Multimodal Font Design Using Interactive Bayesian Optimization",
    "authors": [
      "Yuki Tatsukawa",
      "I-Chao Shen",
      "Mustafa Doga Dogan",
      "Anran Qi",
      "Yuki Koyama",
      "Ariel Shamir",
      "Takeo Igarashi"
    ],
    "abstract": "Creating new fonts requires a lot of human effort and professional\ntypographic knowledge. Despite the rapid advancements of automatic font\ngeneration models, existing methods require users to prepare pre-designed\ncharacters with target styles using font-editing software, which poses a\nproblem for non-expert users. To address this limitation, we propose FontCraft,\na system that enables font generation without relying on pre-designed\ncharacters. Our approach integrates the exploration of a font-style latent\nspace with human-in-the-loop preferential Bayesian optimization and multimodal\nreferences, facilitating efficient exploration and enhancing user control.\nMoreover, FontCraft allows users to revisit previous designs, retracting their\nearlier choices in the preferential Bayesian optimization process. Once users\nfinish editing the style of a selected character, they can propagate it to the\nremaining characters and further refine them as needed. The system then\ngenerates a complete outline font in OpenType format. We evaluated the\neffectiveness of FontCraft through a user study comparing it to a baseline\ninterface. Results from both quantitative and qualitative evaluations\ndemonstrate that FontCraft enables non-expert users to design fonts\nefficiently.",
    "pdf_url": "http://arxiv.org/pdf/2502.11399v1",
    "published": "2025-02-17T03:33:23+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.12213v1",
    "title": "Spatiotemporal-aware Trend-Seasonality Decomposition Network for Traffic Flow Forecasting",
    "authors": [
      "Lingxiao Cao",
      "Bin Wang",
      "Guiyuan Jiang",
      "Yanwei Yu",
      "Junyu Dong"
    ],
    "abstract": "Traffic prediction is critical for optimizing travel scheduling and enhancing\npublic safety, yet the complex spatial and temporal dynamics within traffic\ndata present significant challenges for accurate forecasting. In this paper, we\nintroduce a novel model, the Spatiotemporal-aware Trend-Seasonality\nDecomposition Network (STDN). This model begins by constructing a dynamic graph\nstructure to represent traffic flow and incorporates novel spatio-temporal\nembeddings to jointly capture global traffic dynamics. The representations\nlearned are further refined by a specially designed trend-seasonality\ndecomposition module, which disentangles the trend-cyclical component and\nseasonal component for each traffic node at different times within the graph.\nThese components are subsequently processed through an encoder-decoder network\nto generate the final predictions. Extensive experiments conducted on\nreal-world traffic datasets demonstrate that STDN achieves superior performance\nwith remarkable computation cost. Furthermore, we have released a new traffic\ndataset named JiNan, which features unique inner-city dynamics, thereby\nenriching the scenario comprehensiveness in traffic prediction evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2502.12213v1",
    "published": "2025-02-17T03:29:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2503.03755v1",
    "title": "Research on evolution and early warning model of network public opinion based on online Latent Dirichlet distribution model and BP neural network",
    "authors": [
      "Qiaozhi Bao",
      "Yanlin Chen",
      "Xusheng Ji"
    ],
    "abstract": "Online public opinion is increasingly becoming a significant factor affecting\nthe stability of the internet and society, particularly as the frequency of\nonline public opinion crises has risen in recent years. Enhancing the\ncapability for early warning of online public opinion crises is urgent. The\nmost effective approach is to identify potential crises in their early stages\nand implement corresponding management measures. This study establishes a\npreliminary indicator system for online public opinion early warning, based on\nthe principles of indicator system construction and the characteristics and\nevolution patterns of online public opinion. Subsequently, data-driven\nmethodologies were employed to collect and preprocess public opinion indicator\ndata. Utilizing grey relational analysis and the K-Means clustering algorithm,\nwe classified online public opinion events into three levels: slight, warning,\nand severe. Furthermore, we constructed an online topic evolution model using\nthe online Hierarchical Dirichlet Process model to analyze the thematic changes\nof online public opinion events across different warning levels. Finally, we\ndeveloped an online public opinion early warning model using a Backpropagation\n(BP) neural network. The test results of early warning samples show that the\nmodel achieves high accuracy. Thus, in practical early warning applications,\nthe BP neural network can be effectively utilized for predicting online public\nopinion events.",
    "pdf_url": "http://arxiv.org/pdf/2503.03755v1",
    "published": "2025-02-17T03:28:59+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11398v1",
    "title": "Comprehensive scaling laws across animals, microorganisms and plants",
    "authors": [
      "Huan Liu",
      "Shashank Priya",
      "Richard D. James"
    ],
    "abstract": "Scaling laws illuminate Nature's fundamental biological principles and guide\nbioinspired materials and structural designs. In simple cases they are based on\nthe fundamental principle that all laws of nature remain unchanged (i.e.,\ninvariant) under a change of units. A more general framework is a change of\nvariables for the governing laws that takes all equations, boundary, and\ninteraction conditions into themselves. We consider an accepted macroscale\nsystem of partial differential equations including coupled fluid dynamics,\nnonlinear elasticity, and rigid body mechanics for a complex organism. We show\nthat there is a set of scaling laws where length, time, density, elastic\nmodulus, viscosity, and gravitational constant undergo nontrivial scaling\n(Table 1). We compare these results to extensive data sets mined from the\nliterature on beating frequency of flying, swimming, and running animals, speed\nof bacteria, insects, fish, mammals and reptiles, leg stiffness of mammals, and\nmodulus of elasticity of plants. The uniform agreement of the scaling laws with\nthe dynamics of fauna, flora, and microorganisms supports the dominating role\nof coupled nonlinear elasticity and fluid dynamics in evolutionary development.\nWe conclude with predictions for some prehistoric cases for which observations\nare unavailable.",
    "pdf_url": "http://arxiv.org/pdf/2502.11398v1",
    "published": "2025-02-17T03:27:31+00:00",
    "categories": [
      "physics.bio-ph"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11397v1",
    "title": "Angle structures on pseudo 3-manifolds",
    "authors": [
      "Huabin Ge",
      "Longsong Jia",
      "Faze Zhang"
    ],
    "abstract": "It is still not known whether a hyperbolic 3-manifold admits an angle\nstructure or not. We consider angle structures with area-curvature on\ntriangulated pseudo 3-manifolds M in this article. A suficient and necessary\ncondition for the existence of such angle structures is established. As a\nconsequence, any compact hyperbolic 3-manifold with totally geodesic boundary\nadmits an angle structure. We also derive certain topological information of M\nfrom the existence of such angle structures.",
    "pdf_url": "http://arxiv.org/pdf/2502.11397v1",
    "published": "2025-02-17T03:27:28+00:00",
    "categories": [
      "math.GT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11396v1",
    "title": "Maintenance of Structural Hole Spanners in Dynamic Networks",
    "authors": [
      "Diksha Goel",
      "Hong Shen",
      "Hui Tian",
      "Mingyu Guo"
    ],
    "abstract": "Structural Hole (SH) spanners are the set of users who bridge different\ngroups of users and are vital in numerous applications. Despite their\nimportance, existing work for identifying SH spanners focuses only on static\nnetworks. However, real-world networks are highly dynamic where the underlying\nstructure of the network evolves continuously. Consequently, we study SH\nspanner problem for dynamic networks. We propose an efficient solution for\nupdating SH spanners in dynamic networks. Our solution reuses the information\nobtained during the initial runs of the static algorithm and avoids the\nrecomputations for the nodes unaffected by the updates. Experimental results\nshow that the proposed solution achieves a minimum speedup of 3.24 over\nrecomputation. To the best of our knowledge, this is the first attempt to\naddress the problem of maintaining SH spanners in dynamic networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11396v1",
    "published": "2025-02-17T03:26:05+00:00",
    "categories": [
      "cs.SI",
      "68R10 (Graph Theory)"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11395v3",
    "title": "beta Hydroxybutyrate Targets C99 Driven Organelle Disruption in a Drosophila Model of Alzheimers Disease",
    "authors": [
      "Hao Huang",
      "Kaijing Xu",
      "Michael Lardelli"
    ],
    "abstract": "The amyloid precursor protein (APP)-derived fragment C99 has emerged as a\ncentral driver of subcellular dysfunction in Alzheimers disease (AD), yet its\nprecise interactome and contribution to mitochondrial and autophagy-lysosomal\ndisruption remain incompletely defined. Here, we performed quantitative\nproteomic mapping of C99 associated proteins in a Drosophila AD model and\nidentified three major functional modules nuclear gene expression,\nmitochondrial metabolism, and autophagy regulation frequently disrupted in AD.\nAmong these, several C99 interactors showed altered association upon treatment\nwith beta-hydroxybutyrate (BHB), a metabolic ketone body with emerging\nneuroprotective properties. Ultrastructural analysis revealed that C99\nexpression induced severe mitochondrial fragmentation, cristae loss, and the\naccumulation of dense vesicles with fibrillar contents, indicative of impaired\norganelle integrity and degradative failure. These abnormalities were\nsubstantially reversed by BHB treatment, which restored mitochondrial\narchitecture, improved lysosomal acidification, and reduced the burden of\naberrant vesicles. Functional assays confirmed that BHB also rescued lifespan\nand memory deficits in C99-expressing flies. Further, expression of selected\nC99 interactors such as PPME1 and VPS35 was sufficient to ameliorate\nneurodegenerative phenotypes in vivo, underscoring their functional relevance.\nTogether, our findings define a multi-axis cellular pathology driven by C99\naccumulation and demonstrate that metabolic intervention via BHB can reprogram\ndisrupted proteomic networks and organelle homeostasis. These results establish\na mechanistic link between ketone signaling and early subcellular dysfunction\nin AD, offering potential new targets for therapeutic intervention.",
    "pdf_url": "http://arxiv.org/pdf/2502.11395v3",
    "published": "2025-02-17T03:25:46+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11394v2",
    "title": "A Signed Graph Approach to Understanding and Mitigating Oversmoothing in GNNs",
    "authors": [
      "Jiaqi Wang",
      "Xinyi Wu",
      "James Cheng",
      "Yifei Wang"
    ],
    "abstract": "Deep graph neural networks (GNNs) often suffer from oversmoothing, where node\nrepresentations become overly homogeneous with increasing depth. While\ntechniques like normalization, residual connections, and edge dropout have been\nproposed to mitigate oversmoothing, they are typically developed independently,\nwith limited theoretical understanding of their underlying mechanisms. In this\nwork, we present a unified theoretical perspective based on the framework of\nsigned graphs, showing that many existing strategies implicitly introduce\nnegative edges that alter message-passing to resist oversmoothing. However, we\nshow that merely adding negative edges in an unstructured manner is\ninsufficient-the asymptotic behavior of signed propagation depends critically\non the strength and organization of positive and negative edges. To address\nthis limitation, we leverage the theory of structural balance, which promotes\nstable, cluster-preserving dynamics by connecting similar nodes with positive\nedges and dissimilar ones with negative edges. We propose Structural Balanced\nPropagation (SBP), a plug-and-play method that assigns signed edges based on\neither labels or feature similarity to explicitly enhance structural balance in\nthe constructed signed graphs. Experiments on nine benchmarks across both\nhomophilic and heterophilic settings demonstrate that SBP consistently improves\nclassification accuracy and mitigates oversmoothing, even at depths of up to\n300 layers. Our results provide a principled explanation for prior\noversmoothing remedies and introduce a new direction for signed message-passing\ndesign in deep GNNs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11394v2",
    "published": "2025-02-17T03:25:36+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11393v2",
    "title": "HellaSwag-Pro: A Large-Scale Bilingual Benchmark for Evaluating the Robustness of LLMs in Commonsense Reasoning",
    "authors": [
      "Xiaoyuan Li",
      "Moxin Li",
      "Rui Men",
      "Yichang Zhang",
      "Keqin Bao",
      "Wenjie Wang",
      "Fuli Feng",
      "Dayiheng Liu",
      "Junyang Lin"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in\ncommonsense reasoning; however, some variations in questions can trigger\nincorrect responses. Do these models truly understand commonsense knowledge, or\njust memorize expression patterns? To investigate this question, we present the\nfirst extensive robustness evaluation of LLMs in commonsense reasoning. We\nintroduce HellaSwag-Pro, a large-scale bilingual benchmark consisting of 11,200\ncases, by designing and compiling seven types of question variants. To\nconstruct this benchmark, we propose a two-stage method to develop Chinese\nHellaSwag, a finely annotated dataset comprising 12,000 instances across 56\ncategories. We conduct extensive experiments on 41 representative LLMs,\nrevealing that these LLMs are far from robust in commonsense reasoning.\nFurthermore, this robustness varies depending on the language in which the LLM\nis tested. This work establishes a high-quality evaluation benchmark, with\nextensive experiments offering valuable insights to the community in\ncommonsense reasoning for LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11393v2",
    "published": "2025-02-17T03:24:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11392v1",
    "title": "Uniform-in-time asymptotic limits of generalized Kuramoto models",
    "authors": [
      "Hangjun Cho",
      "Seung-Yeal Ha",
      "Myeongju Kang",
      "Chan Ho Min"
    ],
    "abstract": "We study two uniform-in-time asymptotic limits for generalized Kuramoto (GK)\nmodels. For these GK type models, we first derive the uniform stability\nestimates with respect to initial data, natural frequency and communication\nnetwork under a suitable framework, and then as direct applications of this\nuniform stability estimate, we establish two asymptotic limits which are valid\nin the whole time interval, namely uniform-in-time continuum and mean-filed\nlimit to the continuum and kinetic GK models, respectively. In the mean-field\nlimit setting (the number of particles tends to infinity), we show\nglobal-in-time existence of measure-valued solutions to the corresponding\nkinetic equation. On the other hand, in a continuum limit setting (the lattice\nsize tends to zero), we show that the lattice GKM solutions converge to a\nclassical solution to the continuum GK model in supremum norm. Two asymptotic\nlimits improve earlier results for the generalized GK type models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11392v1",
    "published": "2025-02-17T03:22:20+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "34D05, 45J05, 82C20"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.14891v3",
    "title": "CoDiff: Conditional Diffusion Model for Collaborative 3D Object Detection",
    "authors": [
      "Zhe Huang",
      "Shuo Wang",
      "Yongcai Wang",
      "Lei Wang"
    ],
    "abstract": "Collaborative 3D object detection holds significant importance in the field\nof autonomous driving, as it greatly enhances the perception capabilities of\neach individual agent by facilitating information exchange among multiple\nagents. However, in practice, due to pose estimation errors and time delays,\nthe fusion of information across agents often results in feature\nrepresentations with spatial and temporal noise, leading to detection errors.\nDiffusion models naturally have the ability to denoise noisy samples to the\nideal data, which motivates us to explore the use of diffusion models to\naddress the noise problem between multi-agent systems. In this work, we propose\nCoDiff, a novel robust collaborative perception framework that leverages the\npotential of diffusion models to generate more comprehensive and clearer\nfeature representations. To the best of our knowledge, this is the first work\nto apply diffusion models to multi-agent collaborative perception.\nSpecifically, we project high-dimensional feature map into the latent space of\na powerful pre-trained autoencoder. Within this space, individual agent\ninformation serves as a condition to guide the diffusion model's sampling. This\nprocess denoises coarse feature maps and progressively refines the fused\nfeatures. Experimental study on both simulated and real-world datasets\ndemonstrates that the proposed framework CoDiff consistently outperforms\nexisting relevant methods in terms of the collaborative object detection\nperformance, and exhibits highly desired robustness when the pose and delay\ninformation of agents is with high-level noise. The code is released at\nhttps://github.com/HuangZhe885/CoDiff",
    "pdf_url": "http://arxiv.org/pdf/2502.14891v3",
    "published": "2025-02-17T03:20:52+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11391v1",
    "title": "Excluded conformal minors of Birkhoff-von Neumann graphs with equal global forcing number and maximum anti-forcing number",
    "authors": [
      "Yaxian Zhang",
      "Yan Wu",
      "Heping Zhang"
    ],
    "abstract": "Global forcing number and maximum anti-forcing number of matchable graphs\n(graphs with a perfect matching) were proposed in completely different\nsituations with applications in theoretical chemistry. Surprisingly for\nbipartite graphs and some nonbipartite graphs as solid bricks (or Birkhoff-von\nNeumann graphs) G, the global forcing number gf(G) is at least the maximum\nanti-forcing number Af(G). It is natural to consider when gf(G) = Af(G) holds.\nFor convenience, we call a matchable graph G strongly uniform if each conformal\nmatchable subgraph G' always satisfies gf(G') = Af(G'). In this article, by\napplying the ear decomposition theorem and discussing the existence of a\nHamilton cycle with positions of chords, we give \"excluded conformal minors\"\nand \"structural\" characterizations of matchable bipartite graphs and\nBirkhoff-von Neumann graphs that are strongly uniform respectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.11391v1",
    "published": "2025-02-17T03:16:16+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11390v1",
    "title": "MARS: Mesh AutoRegressive Model for 3D Shape Detailization",
    "authors": [
      "Jingnan Gao",
      "Weizhe Liu",
      "Weixuan Sun",
      "Senbo Wang",
      "Xibin Song",
      "Taizhang Shang",
      "Shenzhou Chen",
      "Hongdong Li",
      "Xiaokang Yang",
      "Yichao Yan",
      "Pan Ji"
    ],
    "abstract": "State-of-the-art methods for mesh detailization predominantly utilize\nGenerative Adversarial Networks (GANs) to generate detailed meshes from coarse\nones. These methods typically learn a specific style code for each category or\nsimilar categories without enforcing geometry supervision across different\nLevels of Detail (LODs). Consequently, such methods often fail to generalize\nacross a broader range of categories and cannot ensure shape consistency\nthroughout the detailization process. In this paper, we introduce MARS, a novel\napproach for 3D shape detailization. Our method capitalizes on a novel\nmulti-LOD, multi-category mesh representation to learn shape-consistent mesh\nrepresentations in latent space across different LODs. We further propose a\nmesh autoregressive model capable of generating such latent representations\nthrough next-LOD token prediction. This approach significantly enhances the\nrealism of the generated shapes. Extensive experiments conducted on the\nchallenging 3D Shape Detailization benchmark demonstrate that our proposed MARS\nmodel achieves state-of-the-art performance, surpassing existing methods in\nboth qualitative and quantitative assessments. Notably, the model's capability\nto generate fine-grained details while preserving the overall shape integrity\nis particularly commendable.",
    "pdf_url": "http://arxiv.org/pdf/2502.11390v1",
    "published": "2025-02-17T03:12:16+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11389v1",
    "title": "TEMPO: A Python Package for Time Evolution of Pulse Sequences in QuTiP",
    "authors": [
      "Jner Tzern Oon",
      "Sonja A. Hakala",
      "George A. Witt",
      "Ronald Walsworth"
    ],
    "abstract": "TEMPO (Time-dependent Evolution of Multiple Pulse Operations) offers\naccessible and efficient simulations of pulse sequences in Python, using the\nsuite of master equation solvers available in the Quantum Toolbox in Python\n(QuTiP). It enables straightforward definition of pulse sequence structures,\nincluding any underlying time-dependent Hamiltonians and pulse timing\ninformation, and faster simulations of pulse sequence dynamics (compared to\nnaive implementations using QuTiP) while remaining compatible with the existing\ncollection of QuTiP subpackages. Given the ubiquitous use of pulse sequences\nthroughout quantum information/computing sciences, magnetic resonance studies,\nand quantum metrology, this work has immediate relevance to a wide array of\nresearch applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11389v1",
    "published": "2025-02-17T03:10:51+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11388v1",
    "title": "Hyperelliptic curves, minitwistors, and spacelike Zoll spaces",
    "authors": [
      "Nobuhiro Honda"
    ],
    "abstract": "We construct a compact minitwistor space from a hyperelliptic curve with real\nstructure and show that it yields a lot of new Lorentzian Einstein-Weyl spaces\nall of which are diffeomorphic to the 3-dimensional deSitter space. These\nstructures are real analytic, admit a circle symmetry and moreover, all their\nspacelike geodesics are closed and simple. The number of the nodes of\nminitwistor lines on the minitwistor space is equal to the genus of the\nhyperelliptic curve and is taken arbitrarily. These Einstein-Weyl structures\ndeform as the hyperelliptic curves deform, and so have $(2g-1)$-dimensional\nmoduli space, where $g$ is the genus of the hyperelliptic curve. A relationship\nbetween the minitwistor spaces recently obtained by Hitchin from ALE\ngravitational instantons is also given for A$_{\\rm odd}$-type.",
    "pdf_url": "http://arxiv.org/pdf/2502.11388v1",
    "published": "2025-02-17T03:10:36+00:00",
    "categories": [
      "math.DG",
      "math.AG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11387v1",
    "title": "RoleMRC: A Fine-Grained Composite Benchmark for Role-Playing and Instruction-Following",
    "authors": [
      "Junru Lu",
      "Jiazheng Li",
      "Guodong Shen",
      "Lin Gui",
      "Siyu An",
      "Yulan He",
      "Di Yin",
      "Xing Sun"
    ],
    "abstract": "Role-playing is important for Large Language Models (LLMs) to follow diverse\ninstructions while maintaining role identity and the role's pre-defined ability\nlimits. Existing role-playing datasets mostly contribute to controlling role\nstyle and knowledge boundaries, but overlook role-playing in\ninstruction-following scenarios. We introduce a fine-grained role-playing and\ninstruction-following composite benchmark, named RoleMRC, including: (1)\nMulti-turn dialogues between ideal roles and humans, including free chats or\ndiscussions upon given passages; (2) Role-playing machine reading\ncomprehension, involving response, refusal, and attempts according to passage\nanswerability and role ability; (3) More complex scenarios with nested,\nmulti-turn and prioritized instructions. The final RoleMRC features a 10.2k\nrole profile meta-pool, 37.9k well-synthesized role-playing instructions, and\n1.4k testing samples. We develop a pipeline to quantitatively evaluate the\nfine-grained role-playing and instruction-following capabilities of several\nmainstream LLMs, as well as models that are fine-tuned on our data. Moreover,\ncross-evaluation on external role-playing datasets confirms that models\nfine-tuned on RoleMRC enhances instruction-following without compromising\ngeneral role-playing and reasoning capabilities. We also probe the neural-level\nactivation maps of different capabilities over post-tuned LLMs. Access to our\nRoleMRC, RoleMRC-mix and Codes: https://github.com/LuJunru/RoleMRC.",
    "pdf_url": "http://arxiv.org/pdf/2502.11387v1",
    "published": "2025-02-17T03:08:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11386v1",
    "title": "Intelligent Mobile AI-Generated Content Services via Interactive Prompt Engineering and Dynamic Service Provisioning",
    "authors": [
      "Yinqiu Liu",
      "Ruichen Zhang",
      "Jiacheng Wang",
      "Dusit Niyato",
      "Xianbin Wang",
      "Dong In Kim",
      "Hongyang Du"
    ],
    "abstract": "Due to massive computational demands of large generative models, AI-Generated\nContent (AIGC) can organize collaborative Mobile AIGC Service Providers (MASPs)\nat network edges to provide ubiquitous and customized content generation for\nresource-constrained users. However, such a paradigm faces two significant\nchallenges: 1) raw prompts (i.e., the task description from users) often lead\nto poor generation quality due to users' lack of experience with specific AIGC\nmodels, and 2) static service provisioning fails to efficiently utilize\ncomputational and communication resources given the heterogeneity of AIGC\ntasks. To address these challenges, we propose an intelligent mobile AIGC\nservice scheme. Firstly, we develop an interactive prompt engineering mechanism\nthat leverages a Large Language Model (LLM) to generate customized prompt\ncorpora and employs Inverse Reinforcement Learning (IRL) for policy imitation\nthrough small-scale expert demonstrations. Secondly, we formulate a dynamic\nmobile AIGC service provisioning problem that jointly optimizes the number of\ninference trials and transmission power allocation. Then, we propose the\nDiffusion-Enhanced Deep Deterministic Policy Gradient (D3PG) algorithm to solve\nthe problem. By incorporating the diffusion process into Deep Reinforcement\nLearning (DRL) architecture, the environment exploration capability can be\nimproved, thus adapting to varying mobile AIGC scenarios. Extensive\nexperimental results demonstrate that our prompt engineering approach improves\nsingle-round generation success probability by 6.3 times, while D3PG increases\nthe user service experience by 67.8% compared to baseline DRL approaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.11386v1",
    "published": "2025-02-17T03:05:20+00:00",
    "categories": [
      "cs.NI",
      "cs.LG"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11385v1",
    "title": "Circuit Partitioning and Full Circuit Execution: A Comparative Study of GPU-Based Quantum Circuit Simulation",
    "authors": [
      "Kartikey Sarode",
      "Daniel E. Huang",
      "E. Wes Bethel"
    ],
    "abstract": "Executing large quantum circuits is not feasible using the currently\navailable NISQ (noisy intermediate-scale quantum) devices. The high costs of\nusing real quantum devices make it further challenging to research and develop\nquantum algorithms. As a result, performing classical simulations is usually\nthe preferred method for researching and validating large-scale quantum\nalgorithms. However, these simulations require a huge amount of resources, as\neach additional qubit exponentially increases the computational space required.\n  Distributed Quantum Computing (DQC) is a promising alternative to reduce the\nresources required for simulating large quantum algorithms at the cost of\nincreased runtime. This study presents a comparative analysis of two simulation\nmethods: circuit-splitting and full-circuit execution using distributed memory,\neach having a different type of overhead.\n  The first method, using CutQC, cuts the circuit into smaller subcircuits and\nallows us to simulate a large quantum circuit on smaller machines. The second\nmethod, using Qiskit-Aer-GPU, distributes the computational space across a\ndistributed memory system to simulate the entire quantum circuit. Results\nindicate that full-circuit executions are faster than circuit-splitting for\nsimulations performed on a single node. However, circuit-splitting simulations\nshow promising results in specific scenarios as the number of qubits is scaled.",
    "pdf_url": "http://arxiv.org/pdf/2502.11385v1",
    "published": "2025-02-17T03:04:43+00:00",
    "categories": [
      "quant-ph",
      "cs.ET"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11384v1",
    "title": "Beyond Cortisol! Physiological Indicators of Welfare for Dogs: Deficits, Misunderstandings and Opportunities",
    "authors": [
      "ML Cobb",
      "AG Jimenez",
      "NA Dreschel"
    ],
    "abstract": "This paper aims to initiate new conversations about the use of physiological\nindicators when assessing the welfare of dogs. There are significant concerns\nabout construct validity - whether the measures used accurately reflect\nwelfare. The goal is to provide recommendations for future inquiry and\nencourage debate. We acknowledge that the scientific understanding of animal\nwelfare has evolved and bring attention to the shortcomings of commonly used\nbiomarkers like cortisol. These indicators are frequently used in isolation and\nwith limited salient dog descriptors, so fail to reflect the canine experience\nadequately. Using a systems approach, we explore various physiological systems\nand alternative indicators, such as heart rate variability and oxidative\nstress, to address this limitation. It is essential to consider factors like\nage, body weight, breed, and sex when interpreting these biomarkers correctly,\nand researchers should report on these in their studies. This discussion\nidentifies possible indicators for both positive and negative experiences. In\nconclusion, we advocate for a practical, evidence-based approach to assessing\nindicators of canine welfare, including non-invasive collection methods. We\nacknowledge the complexity of evaluating experiential responses in dogs across\ndifferent situations and the need for continued work to improve practices and\nrefine terminology. This will enhance our ability to accurately understand\nwelfare and improve the wellbeing of dogs, serving to inform standards of\nanimal welfare assessment. We hope this will promote more fundamental research\nin canine physiology to improve construct validity, leading to better\npractices, ultimately improving the lives of dogs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11384v1",
    "published": "2025-02-17T03:03:39+00:00",
    "categories": [
      "q-bio.QM"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2502.12212v1",
    "title": "Asymptotic Behavior of Resonant Frequencies in Cylindrical Samples for Resonant Ultrasound Spectroscopy",
    "authors": [
      "Jake E. Akins",
      "Casey M. Holycross",
      "Farhad Farzbod"
    ],
    "abstract": "Resonant ultrasound spectroscopy (RUS) is a non-destructive technique for\nassessing the elastic and anelastic properties of materials by analyzing the\nfrequencies of free vibrations in samples with known geometry. This paper\nexplores the asymptotic behavior of eigenfrequencies in samples with\ncylindrical geometry. Extending prior research on cuboid samples, our study\nrepresents another step toward characterizing asymptotic behavior in\narbitrarily shaped samples. While our findings are specific to cylindrical\ngeometries, they are particularly relevant since many RUS samples adopt this\nshape. Furthermore, we present results on computing derivatives of Zernike\npolynomials, which may enhance the efficiency of resonant frequency\ncalculations in the RUS method.",
    "pdf_url": "http://arxiv.org/pdf/2502.12212v1",
    "published": "2025-02-17T03:03:39+00:00",
    "categories": [
      "physics.gen-ph"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11383v3",
    "title": "When Homogeneous Systems Meet Dissipation and Disorder",
    "authors": [
      "Xixi Feng",
      "Ao Zhou",
      "Feng Lu",
      "Gao Xianlong",
      "Shujie Cheng"
    ],
    "abstract": "We investigate the localization and topological properties of the\nnon-equilibrium steady state (NESS) in a one-dimensional homogeneous system.\nOur results demonstrate that, despite the absence of disorder in the initial\nsystem, the NESS can exhibit localization under bond dissipation. These\ndissipation-driven localization and delocalization phenomena are clearly\ndistinguished using Wigner distributions. Furthermore, we find that the initial\nlocalization characteristics of the system significantly influence the\nlocalization properties of the NESS. Drawing upon the concept of Bose-Einstein\ncondensate broadening in cold-atom experiments, along with experimental data,\nwe systematically characterize the impact of bond dissipation and disorder on\nthe localization and topological properties of the NESS. The phase diagram\nreveals that the NESS can be topologically non-trivial even when the initial\nsystem is topologically trivial, and that the topological triviality of the\ninitial system strengthens the topological non-triviality of the NESS. This\nwork provides new insights into the localization and topological phase\ntransitions in homogeneous systems induced by bond dissipation and disorder.",
    "pdf_url": "http://arxiv.org/pdf/2502.11383v3",
    "published": "2025-02-17T02:59:34+00:00",
    "categories": [
      "cond-mat.dis-nn"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11382v1",
    "title": "A Physics-Informed Blur Learning Framework for Imaging Systems",
    "authors": [
      "Liqun Chen",
      "Yuxuan Li",
      "Jun Dai",
      "Jinwei Gu",
      "Tianfan Xue"
    ],
    "abstract": "Accurate blur estimation is essential for high-performance imaging across\nvarious applications. Blur is typically represented by the point spread\nfunction (PSF). In this paper, we propose a physics-informed PSF learning\nframework for imaging systems, consisting of a simple calibration followed by a\nlearning process. Our framework could achieve both high accuracy and universal\napplicability. Inspired by the Seidel PSF model for representing spatially\nvarying PSF, we identify its limitations in optimization and introduce a novel\nwavefront-based PSF model accompanied by an optimization strategy, both\nreducing optimization complexity and improving estimation accuracy. Moreover,\nour wavefront-based PSF model is independent of lens parameters, eliminate the\nneed for prior knowledge of the lens. To validate our approach, we compare it\nwith recent PSF estimation methods (Degradation Transfer and Fast Two-step)\nthrough a deblurring task, where all the estimated PSFs are used to train\nstate-of-the-art deblurring algorithms. Our approach demonstrates improvements\nin image quality in simulation and also showcases noticeable visual quality\nimprovements on real captured images.",
    "pdf_url": "http://arxiv.org/pdf/2502.11382v1",
    "published": "2025-02-17T02:54:14+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11381v3",
    "title": "Without Paired Labeled Data: End-to-End Self-Supervised Learning for Drone-view Geo-Localization",
    "authors": [
      "Zhongwei Chen",
      "Zhao-Xu Yang",
      "Hai-Jun Rong"
    ],
    "abstract": "Drone-view Geo-Localization (DVGL) aims to achieve accurate localization of\ndrones by retrieving the most relevant GPS-tagged satellite images. However,\nmost existing methods heavily rely on strictly pre-paired drone-satellite\nimages for supervised learning. When the target region shifts, new paired\nsamples are typically required to adapt to the distribution changes. The high\ncost of annotation and the limited transferability of these methods\nsignificantly hinder the practical deployment of DVGL in open-world scenarios.\nTo address these limitations, we propose an end-to-end self-supervised learning\nmethod with a shallow backbone network. It employs a clustering algorithm to\ngenerate pseudo-labels and adopts a dual-path contrastive learning framework to\nlearn discriminative intra-view representations. Furthermore, our method\nincorporates two core modules, including the dynamic hierarchical memory\nlearning module (DHML) and the information consistency evolution learning\nmodule (ICEL). The DHML combines short-term and long-term memory to enhance\nintra-view feature consistency and discriminability. Meanwhile, the ICEL module\nutilizes a neighborhood-driven dynamic constraint mechanism to systematically\ncapture implicit cross-view semantic correlations, consequently improving\ncross-view feature alignment. To further stabilize and strengthen the\nself-supervised training process, a pseudo-label enhancement strategy is\nintroduced to enhance the quality of pseudo supervision. Extensive experiments\non three public benchmark datasets demonstrate that the proposed method\nconsistently outperforms existing self-supervised methods and even surpasses\nseveral state-of-the-art supervised methods. {Our code is available at\nhttps://github.com/ISChenawei/DMNIL.",
    "pdf_url": "http://arxiv.org/pdf/2502.11381v3",
    "published": "2025-02-17T02:53:08+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.13163v2",
    "title": "A Survey of Fuzzing Open-Source Operating Systems",
    "authors": [
      "Kun Hu",
      "Qicai Chen",
      "Zilong Lu",
      "Wenzhuo Zhang",
      "Bihuan Chen",
      "You Lu",
      "Haowen Jiang",
      "Bingkun Sun",
      "Xin Peng",
      "Wenyun Zhao"
    ],
    "abstract": "Vulnerabilities in open-source operating systems (OSs) pose substantial\nsecurity risks to software systems, making their detection crucial. While\nfuzzing has been an effective vulnerability detection technique in various\ndomains, OS fuzzing (OSF) faces unique challenges due to OS complexity and\nmulti-layered interaction, and has not been comprehensively reviewed.\nTherefore, this work systematically surveys the state-of-the-art OSF\ntechniques, categorizes them based on the general fuzzing process, and\ninvestigates challenges specific to kernel, file system, driver, and hypervisor\nfuzzing. Finally, future research directions for OSF are discussed. GitHub:\nhttps://github.com/pghk13/Survey-OSF.",
    "pdf_url": "http://arxiv.org/pdf/2502.13163v2",
    "published": "2025-02-17T02:53:02+00:00",
    "categories": [
      "cs.OS",
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.OS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11380v2",
    "title": "From the New World of Word Embeddings: A Comparative Study of Small-World Lexico-Semantic Networks in LLMs",
    "authors": [
      "Zhu Liu",
      "Ying Liu",
      "KangYang Luo",
      "Cunliang Kong",
      "Maosong Sun"
    ],
    "abstract": "Lexico-semantic networks represent words as nodes and their semantic\nrelatedness as edges. While such networks are traditionally constructed using\nembeddings from encoder-based models or static vectors, embeddings from\ndecoder-only large language models (LLMs) remain underexplored. Unlike encoder\nmodels, LLMs are trained with a next-token prediction objective, which does not\ndirectly encode the meaning of the current token. In this paper, we construct\nlexico-semantic networks from the input embeddings of LLMs with varying\nparameter scales and conduct a comparative analysis of their global and local\nstructures. Our results show that these networks exhibit small-world\nproperties, characterized by high clustering and short path lengths. Moreover,\nlarger LLMs yield more intricate networks with less small-world effects and\nlonger paths, reflecting richer semantic structures and relations. We further\nvalidate our approach through analyses of common conceptual pairs, structured\nlexical relations derived from WordNet, and a cross-lingual semantic network\nfor qualitative words.",
    "pdf_url": "http://arxiv.org/pdf/2502.11380v2",
    "published": "2025-02-17T02:52:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2503.00010v1",
    "title": "Wakamatsu-tilting subcategories in extriangulated categories",
    "authors": [
      "Zhiwei Zhu",
      "Jiaqun Wei"
    ],
    "abstract": "Let $\\mathscr{C}$ be an extriangulated category with enough projectives and\ninjectives. We give the definitions of Wakamatsu-tilting subcategories and\nWakamatsu-cotilting subcategories of $\\mathscr{C}$ and show that they coincide\nwith each other. Moreover, the definitions of $\\infty$-tilting subcategories\nand $\\infty$-cotilting subcategories given by Zhang, Wei and Wang also coincide\nwith them. As a result, Wakamatsu-tilting subcategories success all properties\nof $\\infty$-tilting subcategories and $\\infty$-cotilting subcategories. On the\nother hand, we glue the Wakamatsu-tilting subcategories in a special\nrecollement and show that the converse of the gluing holds under certain\nconditions.",
    "pdf_url": "http://arxiv.org/pdf/2503.00010v1",
    "published": "2025-02-17T02:49:47+00:00",
    "categories": [
      "math.RT",
      "math.CT"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11379v1",
    "title": "CCJA: Context-Coherent Jailbreak Attack for Aligned Large Language Models",
    "authors": [
      "Guanghao Zhou",
      "Panjia Qiu",
      "Mingyuan Fan",
      "Cen Chen",
      "Mingyuan Chu",
      "Xin Zhang",
      "Jun Zhou"
    ],
    "abstract": "Despite explicit alignment efforts for large language models (LLMs), they can\nstill be exploited to trigger unintended behaviors, a phenomenon known as\n\"jailbreaking.\" Current jailbreak attack methods mainly focus on discrete\nprompt manipulations targeting closed-source LLMs, relying on manually crafted\nprompt templates and persuasion rules. However, as the capabilities of\nopen-source LLMs improve, ensuring their safety becomes increasingly crucial.\nIn such an environment, the accessibility of model parameters and gradient\ninformation by potential attackers exacerbates the severity of jailbreak\nthreats. To address this research gap, we propose a novel\n\\underline{C}ontext-\\underline{C}oherent \\underline{J}ailbreak\n\\underline{A}ttack (CCJA). We define jailbreak attacks as an optimization\nproblem within the embedding space of masked language models. Through\ncombinatorial optimization, we effectively balance the jailbreak attack success\nrate with semantic coherence. Extensive evaluations show that our method not\nonly maintains semantic consistency but also surpasses state-of-the-art\nbaselines in attack effectiveness. Additionally, by integrating semantically\ncoherent jailbreak prompts generated by our method into widely used black-box\nmethodologies, we observe a notable enhancement in their success rates when\ntargeting closed-source commercial LLMs. This highlights the security threat\nposed by open-source LLMs to commercial counterparts. We will open-source our\ncode if the paper is accepted.",
    "pdf_url": "http://arxiv.org/pdf/2502.11379v1",
    "published": "2025-02-17T02:49:26+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11378v1",
    "title": "Numerical Differentiation-based Electrophysiology-Aware Adaptive ResNet for Inverse ECG Modeling",
    "authors": [
      "Lingzhen Zhu",
      "Kenneth Bilchick",
      "Jianxin Xie"
    ],
    "abstract": "Electrocardiographic imaging aims to noninvasively reconstruct the electrical\ndynamic patterns on the heart surface from body-surface ECG measurements,\naiding the mechanistic study of cardiac function. At the core of ECGI lies the\ninverse ECG problem, a mathematically ill-conditioned challenge where small\nbody measurement errors or noise can lead to significant inaccuracies in the\nreconstructed heart-surface potentials. %Leveraging a well-developed\nelectrophysiological (EP) model, our previous study developed an EP-informed\ndeep learning framework, demonstrating promising effectiveness in improving\ncardiac map predictions. To improve the accuracy of ECGI and ensure that\ncardiac predictions adhere to established physical principles, recent advances\nhave incorporated well-established electrophysiology (EP) laws into their model\nformulations. However, traditional EP-informed models encounter significant\nchallenges, including overfitting to EP constraints, limitations in network\nscalability, and suboptimal initialization. These issues compromise prediction\naccuracy and stability, hindering their effectiveness in practical\napplications. This highlights the need for an advanced data analytic and\npredictive tool to achieve reliable cardiac electrodynamic restoration. Here,\nwe present a Numerical Differentiation-based Electrophysiology-Aware Adaptive\nResidual neural Network (EAND-ARN) for robust inverse ECG modeling. Our method\nemploys numerical differentiation to compute the spatiotemporal derivative,\nenabling EP constraints to be applied across a local spatiotemporal region,\nthereby strengthening the overall EP enforcement. Additionally, we design an\nadaptive residual network to improve gradient flow, enhancing predictive\naccuracy and mitigating issues with poor initialization. Experimental results\nshow that EAND-ARN significantly outperforms existing methods in current\npractice.",
    "pdf_url": "http://arxiv.org/pdf/2502.11378v1",
    "published": "2025-02-17T02:49:09+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11377v1",
    "title": "PrivilegedDreamer: Explicit Imagination of Privileged Information for Rapid Adaptation of Learned Policies",
    "authors": [
      "Morgan Byrd",
      "Jackson Crandell",
      "Mili Das",
      "Jessica Inman",
      "Robert Wright",
      "Sehoon Ha"
    ],
    "abstract": "Numerous real-world control problems involve dynamics and objectives affected\nby unobservable hidden parameters, ranging from autonomous driving to robotic\nmanipulation, which cause performance degradation during sim-to-real transfer.\nTo represent these kinds of domains, we adopt hidden-parameter Markov decision\nprocesses (HIP-MDPs), which model sequential decision problems where hidden\nvariables parameterize transition and reward functions. Existing approaches,\nsuch as domain randomization, domain adaptation, and meta-learning, simply\ntreat the effect of hidden parameters as additional variance and often struggle\nto effectively handle HIP-MDP problems, especially when the rewards are\nparameterized by hidden variables. We introduce Privileged-Dreamer, a\nmodel-based reinforcement learning framework that extends the existing\nmodel-based approach by incorporating an explicit parameter estimation module.\nPrivilegedDreamer features its novel dual recurrent architecture that\nexplicitly estimates hidden parameters from limited historical data and enables\nus to condition the model, actor, and critic networks on these estimated\nparameters. Our empirical analysis on five diverse HIP-MDP tasks demonstrates\nthat PrivilegedDreamer outperforms state-of-the-art model-based, model-free,\nand domain adaptation learning algorithms. Additionally, we conduct ablation\nstudies to justify the inclusion of each component in the proposed\narchitecture.",
    "pdf_url": "http://arxiv.org/pdf/2502.11377v1",
    "published": "2025-02-17T02:46:02+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11376v1",
    "title": "Deterministic Single-Photon Adder and Subtractor",
    "authors": [
      "Si-Qi Jiang",
      "Hai-Jun Xing",
      "Li-Ping Yang"
    ],
    "abstract": "Single-photon addition and subtraction are fundamental operations in quantum\ninformation processing. Traditionally, the behavior of a single-photon adder\n(SPA) and single-photon subtractor (SPS) has been theoretically described using\ncreation and annihilation operators, respectively. However, we demonstrate that\nthis ladder-operator-based description contains significant theoretical flaws.\nTo address these issues, we develop a theoretical framework based on Kraus\noperators, applicable to both coherent and incoherent SPAs and SPSs.\nFurthermore, we propose a method for realizing deterministic SPAs and SPSs of a\ncavity mode using three-level atoms. We analyze the effects of these operations\non various quantum states. Additionally, we demonstrate that the use of a\ncontrol pulse could enhance the performance of SPAs and SPSs, effectively\npreserving the quantum coherence of the resulting photon state.",
    "pdf_url": "http://arxiv.org/pdf/2502.11376v1",
    "published": "2025-02-17T02:45:22+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11375v1",
    "title": "Robot Deformable Object Manipulation via NMPC-generated Demonstrations in Deep Reinforcement Learning",
    "authors": [
      "Haoyuan Wang",
      "Zihao Dong",
      "Hongliang Lei",
      "Zejia Zhang",
      "Weizhuang Shi",
      "Wei Luo",
      "Weiwei Wan",
      "Jian Huang"
    ],
    "abstract": "In this work, we conducted research on deformable object manipulation by\nrobots based on demonstration-enhanced reinforcement learning (RL). To improve\nthe learning efficiency of RL, we enhanced the utilization of demonstration\ndata from multiple aspects and proposed the HGCR-DDPG algorithm. It uses a\nnovel high-dimensional fuzzy approach for grasping-point selection, a refined\nbehavior-cloning method to enhance data-driven learning in Rainbow-DDPG, and a\nsequential policy-learning strategy. Compared to the baseline algorithm\n(Rainbow-DDPG), our proposed HGCR-DDPG achieved 2.01 times the global average\nreward and reduced the global average standard deviation to 45% of that of the\nbaseline algorithm. To reduce the human labor cost of demonstration collection,\nwe proposed a low-cost demonstration collection method based on Nonlinear Model\nPredictive Control (NMPC). Simulation experiment results show that\ndemonstrations collected through NMPC can be used to train HGCR-DDPG, achieving\ncomparable results to those obtained with human demonstrations. To validate the\nfeasibility of our proposed methods in real-world environments, we conducted\nphysical experiments involving deformable object manipulation. We manipulated\nfabric to perform three tasks: diagonal folding, central axis folding, and\nflattening. The experimental results demonstrate that our proposed method\nachieved success rates of 83.3%, 80%, and 100% for these three tasks,\nrespectively, validating the effectiveness of our approach. Compared to current\nlarge-model approaches for robot manipulation, the proposed algorithm is\nlightweight, requires fewer computational resources, and offers task-specific\ncustomization and efficient adaptability for specific tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11375v1",
    "published": "2025-02-17T02:41:46+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11374v2",
    "title": "Leave No One Behind: Enhancing Diversity While Maintaining Accuracy in Social Recommendation",
    "authors": [
      "Lei Li",
      "Xiao Zhou"
    ],
    "abstract": "Social recommendation, which incorporates social connections into recommender\nsystems, has proven effective in improving recommendation accuracy. However,\nbeyond accuracy, diversity is also crucial for enhancing user engagement.\nDespite its importance, the impact of social recommendation models on diversity\nremains largely unexplored. In this study, we systematically examine the dual\nperformance of existing social recommendation algorithms in terms of both\naccuracy and diversity. Our empirical analysis reveals a concerning trend:\nwhile social recommendation models enhance accuracy, they often reduce\ndiversity. To address this issue, we propose Diversified Social Recommendation\n(DivSR), a novel approach that employs relational knowledge distillation to\ntransfer high-diversity structured knowledge from non-social recommendation\nmodels to social recommendation models. DivSR is a lightweight, model-agnostic\nframework that seamlessly integrates with existing social recommendation\narchitectures. Experiments on three benchmark datasets demonstrate that DivSR\nsignificantly enhances diversity while maintaining competitive accuracy,\nachieving a superior accuracy-diversity trade-off. Our code and data are\npublicly available at: https://github.com/ll0ruc/DivSR.",
    "pdf_url": "http://arxiv.org/pdf/2502.11374v2",
    "published": "2025-02-17T02:41:11+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11373v1",
    "title": "Solutions for a critical elliptic system with periodic boundary condition",
    "authors": [
      "Qingfang Wang",
      "Wenju Wu",
      "Mingxue Zhai"
    ],
    "abstract": "In this paper, we consider the following nonlinear critical Schr\\\"odinger\nsystem: \\begin{eqnarray*}\\begin{cases} -\\Delta u=K_1(y)u^{2^*-1}+\\frac{1}{2}\nu^{\\frac{2^*}{2}-1}v^\\frac{2^*}{2}, \\,\\,\\,\\,\\,y\\in\\Omega,\\,\\,\\,\\,\\,u>0,\\cr\n-\\Delta v=K_2(y)v^{2^*-1}+\\frac{1}{2} v^{\\frac{2^*}{2}-1}u^\\frac{2^*}{2},\n\\,\\,\\,\\,\\,y\\in\\Omega,\\,\\,\\,\\,\\,v>0,\\cr u(y'+Le_j,y'')=u(y),\n\\,\\,\\,\\,\\,\\frac{\\partial u(y'+Le_j,y'')}{\\partial y_j}=\\frac{\\partial\nu(y)}{\\partial y_j}, \\,\\,\\,\\,\\,if\\,\\, y'=-\\frac{L}{2}e_j,\\,\\,\\,j=1, \\ldots,\nk,\\cr v(y'+Le_j,y'')=v(y), \\,\\,\\,\\,\\,\\frac{\\partial v(y'+Le_j,y'')}{\\partial\ny_j}=\\frac{\\partial v(y)}{\\partial y_j}, \\,\\,\\,\\,\\,if\\,\\,\ny'=-\\frac{L}{2}e_j,\\,\\,\\,j=1, \\ldots, k,\\cr u,v \\to 0 \\,\\,as \\,\\,|y''|\\to\n\\infty, \\end{cases} \\end{eqnarray*} where $K_1(y),\\,K_2(y)$ satisfy some\nperiodic conditions and $\\Omega$ is a strip. Under some conditions which are\nweaker than Li, Wei and Xu(J. Reine Angew. Math. 743: 163-211, 2018), we prove\nthat there exists a single bubbling solution for the above system. Moreover, as\nthe appearance of the coupling terms, we construct different forms of\nsolutions, which makes it more interesting. Since there are periodic boundary\nconditions, this expansion for the difference between the standard bubbles and\nthe approximate bubble can not be obtained by using the comparison theorem as\none usually does for Dirichlet boundary condition. To overcome this difficulty,\nwe will use the Green's function of $-\\Delta$ in $\\Omega$ with periodic\nboundary conditions which helps us find the approximate bubble. Due to the lack\nof the Sobolev inequality, we will introduce a suitable weighted space to carry\nout the reduction.",
    "pdf_url": "http://arxiv.org/pdf/2502.11373v1",
    "published": "2025-02-17T02:39:27+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11372v1",
    "title": "Weibull Processes in Network Degree Distributions",
    "authors": [
      "Peter R Williams",
      "Zhan Chen"
    ],
    "abstract": "This study examines degree distributions in two large collaboration networks:\nthe Microsoft Academic Graph (1800-2020) and Internet Movie Database\n(1900-2020), comprising $2.72 \\times 10^8$ and $1.88 \\times 10^6$ nodes\nrespectively. Statistical comparison using $\\chi^2$ measures showed that\nWeibull distributions fit the degree distributions better than power-law or\nlog-normal models, especially at later stages in the network evolution. The\nWeibull shape parameters exhibit notable stability ($k \\approx 0.8$-$1.0$ for\nacademic, $k \\approx 0.9$-$1.1$ for entertainment collaborations) despite\norders of magnitude growth in network size. While early-stage networks display\napproximate power-law scaling, mature networks develop characteristic\nflattening in the low-degree region that Weibull distributions appear to\ncapture better. In the academic network, the cutoff between the flattened\nregion and power-law tail shows a gradual increase from $5$ to $9$ edges over\ntime, while the entertainment network maintains a distinctive degree structure\nthat may reflect storytelling and cast-size constraints. These patterns suggest\nthe possibility that collaboration network evolution might be influenced more\nby constraint-based growth than by pure preferential attachment or\nmultiplicative processes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11372v1",
    "published": "2025-02-17T02:38:57+00:00",
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12211v1",
    "title": "Techno-Economic Analysis of Hydrogen Production: Costs, Policies, and Scalability in the Transition to Net-Zero",
    "authors": [
      "Eliseo Curcio"
    ],
    "abstract": "This study presents a comprehensive techno-economic analysis of gray, blue,\nand green hydrogen production pathways, evaluating their cost structures,\ninvestment feasibility, infrastructure challenges, and policy-driven cost\nreductions. The findings confirm that gray hydrogen (1.50-2.50/kg) remains the\nmost cost-effective today but is increasingly constrained by carbon pricing.\nBlue hydrogen (2.00-3.50/kg) offers a transitional pathway but depends on CCS\ncosts, natural gas price volatility, and regulatory support. Green hydrogen\n(3.50-6.00/kg) is currently the most expensive but benefits from declining\nrenewable electricity costs, electrolyzer efficiency improvements, and\ngovernment incentives such as the Inflation Reduction Act (IRA), which provides\ntax credits of up to 3.00/kg. The analysis shows that renewable electricity\ncosts below 20-30/MWh are essential for green hydrogen to achieve cost parity\nwith fossil-based hydrogen. The DOE's Hydrogen Shot Initiative aims to lower\ngreen hydrogen costs to 1.00/kg by 2031, emphasizing the need for CAPEX\nreductions, economies of scale, and improved electrolyzer efficiency.\nInfrastructure remains a critical challenge, with pipeline retrofitting\nreducing transport costs by 50-70%, though liquefied hydrogen and chemical\ncarriers remain costly due to energy losses and reconversion expenses.\nInvestment trends indicate a shift toward green hydrogen, with over 250 billion\nprojected by 2035, surpassing blue hydrogen's expected 100 billion. Carbon\npricing above $100/ton CO2 will likely make gray hydrogen uncompetitive by\n2030, accelerating the shift to low-carbon hydrogen. Hydrogen's long-term\nviability depends on continued cost reductions, policy incentives, and\ninfrastructure expansion, with green hydrogen positioned as a cornerstone of\nthe net-zero energy transition by 2035.",
    "pdf_url": "http://arxiv.org/pdf/2502.12211v1",
    "published": "2025-02-17T02:37:56+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2502.11371v1",
    "title": "RAG vs. GraphRAG: A Systematic Evaluation and Key Insights",
    "authors": [
      "Haoyu Han",
      "Harry Shomer",
      "Yu Wang",
      "Yongjia Lei",
      "Kai Guo",
      "Zhigang Hua",
      "Bo Long",
      "Hui Liu",
      "Jiliang Tang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) enhances the performance of LLMs across\nvarious tasks by retrieving relevant information from external sources,\nparticularly on text-based data. For structured data, such as knowledge graphs,\nGraphRAG has been widely used to retrieve relevant information. However, recent\nstudies have revealed that structuring implicit knowledge from text into graphs\ncan benefit certain tasks, extending the application of GraphRAG from graph\ndata to general text-based data. Despite their successful extensions, most\napplications of GraphRAG for text data have been designed for specific tasks\nand datasets, lacking a systematic evaluation and comparison between RAG and\nGraphRAG on widely used text-based benchmarks. In this paper, we systematically\nevaluate RAG and GraphRAG on well-established benchmark tasks, such as Question\nAnswering and Query-based Summarization. Our results highlight the distinct\nstrengths of RAG and GraphRAG across different tasks and evaluation\nperspectives. Inspired by these observations, we investigate strategies to\nintegrate their strengths to improve downstream tasks. Additionally, we provide\nan in-depth discussion of the shortcomings of current GraphRAG approaches and\noutline directions for future research.",
    "pdf_url": "http://arxiv.org/pdf/2502.11371v1",
    "published": "2025-02-17T02:36:30+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.12210v1",
    "title": "Enhancing Frame Detection with Retrieval Augmented Generation",
    "authors": [
      "Papa Abdou Karim Karou Diallo",
      "Amal Zouaq"
    ],
    "abstract": "Recent advancements in Natural Language Processing have significantly\nimproved the extraction of structured semantic representations from\nunstructured text, especially through Frame Semantic Role Labeling (FSRL).\nDespite this progress, the potential of Retrieval-Augmented Generation (RAG)\nmodels for frame detection remains under-explored. In this paper, we present\nthe first RAG-based approach for frame detection called RCIF (Retrieve\nCandidates and Identify Frames). RCIF is also the first approach to operate\nwithout the need for explicit target span and comprises three main stages: (1)\ngeneration of frame embeddings from various representations ; (2) retrieval of\ncandidate frames given an input text; and (3) identification of the most\nsuitable frames. We conducted extensive experiments across multiple\nconfigurations, including zero-shot, few-shot, and fine-tuning settings. Our\nresults show that our retrieval component significantly reduces the complexity\nof the task by narrowing the search space thus allowing the frame identifier to\nrefine and complete the set of candidates. Our approach achieves\nstate-of-the-art performance on FrameNet 1.5 and 1.7, demonstrating its\nrobustness in scenarios where only raw text is provided. Furthermore, we\nleverage the structured representation obtained through this method as a proxy\nto enhance generalization across lexical variations in the task of translating\nnatural language questions into SPARQL queries.",
    "pdf_url": "http://arxiv.org/pdf/2502.12210v1",
    "published": "2025-02-17T02:34:02+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11370v1",
    "title": "HI-GVF: Shared Control based on Human-Influenced Guiding Vector Fields for Human-multi-robot Cooperation",
    "authors": [
      "Pengming Zhu",
      "Zongtan Zhou",
      "Weijia Yao",
      "Wei Dai",
      "Zhiwen Zeng",
      "Huimin Lu"
    ],
    "abstract": "Human-multi-robot shared control leverages human decision-making and robotic\nautonomy to enhance human-robot collaboration. While widely studied, existing\nsystems often adopt a leader-follower model, limiting robot autonomy to some\nextent. Besides, a human is required to directly participate in the motion\ncontrol of robots through teleoperation, which significantly burdens the\noperator. To alleviate these two issues, we propose a layered shared control\ncomputing framework using human-influenced guiding vector fields (HI-GVF) for\nhuman-robot collaboration. HI-GVF guides the multi-robot system along a desired\npath specified by the human. Then, an intention field is designed to merge the\nhuman and robot intentions, accelerating the propagation of the human intention\nwithin the multi-robot system. Moreover, we give the stability analysis of the\nproposed model and use collision avoidance based on safety barrier certificates\nto fine-tune the velocity. Eventually, considering the firefighting task as an\nexample scenario, we conduct simulations and experiments using multiple\nhuman-robot interfaces (brain-computer interface, myoelectric wristband,\neye-tracking), and the results demonstrate that our proposed approach boosts\nthe effectiveness and performance of the task.",
    "pdf_url": "http://arxiv.org/pdf/2502.11370v1",
    "published": "2025-02-17T02:33:09+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11369v1",
    "title": "Physics-Informed Gaussian Process Classification for Constraint-Aware Alloy Design",
    "authors": [
      "Christofer Hardcastle",
      "Ryan O Mullan",
      "Raymundo Arroyave",
      "Brent Vela"
    ],
    "abstract": "Alloy design can be framed as a constraint-satisfaction problem. Building on\nprevious methodologies, we propose equipping Gaussian Process Classifiers\n(GPCs) with physics-informed prior mean functions to model the boundaries of\nfeasible design spaces. Through three case studies, we highlight the utility of\ninformative priors for handling constraints on continuous and categorical\nproperties. (1) Phase Stability: By incorporating CALPHAD predictions as priors\nfor solid-solution phase stability, we enhance model validation using a\npublicly available XRD dataset. (2) Phase Stability Prediction Refinement: We\ndemonstrate an in silico active learning approach to efficiently correct phase\ndiagrams. (3) Continuous Property Thresholds: By embedding priors into\ncontinuous property models, we accelerate the discovery of alloys meeting\nspecific property thresholds via active learning. In each case, integrating\nphysics-based insights into the classification framework substantially improved\nmodel performance, demonstrating an efficient strategy for constraint-aware\nalloy design.",
    "pdf_url": "http://arxiv.org/pdf/2502.11369v1",
    "published": "2025-02-17T02:33:07+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11368v2",
    "title": "LLMs can Perform Multi-Dimensional Analytic Writing Assessments: A Case Study of L2 Graduate-Level Academic English Writing",
    "authors": [
      "Zhengxiang Wang",
      "Veronika Makarova",
      "Zhi Li",
      "Jordan Kodner",
      "Owen Rambow"
    ],
    "abstract": "The paper explores the performance of LLMs in the context of\nmulti-dimensional analytic writing assessments, i.e. their ability to provide\nboth scores and comments based on multiple assessment criteria. Using a corpus\nof literature reviews written by L2 graduate students and assessed by human\nexperts against 9 analytic criteria, we prompt several popular LLMs to perform\nthe same task under various conditions. To evaluate the quality of feedback\ncomments, we apply a novel feedback comment quality evaluation framework. This\nframework is interpretable, cost-efficient, scalable, and reproducible,\ncompared to existing methods that rely on manual judgments. We find that LLMs\ncan generate reasonably good and generally reliable multi-dimensional analytic\nassessments. We release our corpus and code for reproducibility.",
    "pdf_url": "http://arxiv.org/pdf/2502.11368v2",
    "published": "2025-02-17T02:31:56+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11367v1",
    "title": "Sparse Autoencoder Features for Classifications and Transferability",
    "authors": [
      "Jack Gallifant",
      "Shan Chen",
      "Kuleen Sasse",
      "Hugo Aerts",
      "Thomas Hartvigsen",
      "Danielle S. Bitterman"
    ],
    "abstract": "Sparse Autoencoders (SAEs) provide potentials for uncovering structured,\nhuman-interpretable representations in Large Language Models (LLMs), making\nthem a crucial tool for transparent and controllable AI systems. We\nsystematically analyze SAE for interpretable feature extraction from LLMs in\nsafety-critical classification tasks. Our framework evaluates (1) model-layer\nselection and scaling properties, (2) SAE architectural configurations,\nincluding width and pooling strategies, and (3) the effect of binarizing\ncontinuous SAE activations. SAE-derived features achieve macro F1 > 0.8,\noutperforming hidden-state and BoW baselines while demonstrating cross-model\ntransfer from Gemma 2 2B to 9B-IT models. These features generalize in a\nzero-shot manner to cross-lingual toxicity detection and visual classification\ntasks. Our analysis highlights the significant impact of pooling strategies and\nbinarization thresholds, showing that binarization offers an efficient\nalternative to traditional feature selection while maintaining or improving\nperformance. These findings establish new best practices for SAE-based\ninterpretability and enable scalable, transparent deployment of LLMs in\nreal-world applications. Full repo: https://github.com/shan23chen/MOSAIC.",
    "pdf_url": "http://arxiv.org/pdf/2502.11367v1",
    "published": "2025-02-17T02:30:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11366v1",
    "title": "Moment Monotonicity of Weibull, Gamma and Log-normal Distributions",
    "authors": [
      "Kang Liu"
    ],
    "abstract": "This paper investigates the moment monotonicity property of Weibull, Gamma,\nand Log-normal distributions. We provide the first complete mathematical proofs\nfor the monotonicity of the function $E(X^n)^{\\frac{1}{n}}$ specific to these\ndistributions. Through the derivations, we identify a key property: in many\ncases, one of the two parameters defining each distribution can be effectively\ncanceled out. This finding opens up opportunities for improved parameter\nestimation of these random variables. Our results contribute to a deeper\nunderstanding of the behavior of these widely used distributions and offer\nvaluable insights for applications in fields such as reliability engineering,\neconometrics, and machine learning.",
    "pdf_url": "http://arxiv.org/pdf/2502.11366v1",
    "published": "2025-02-17T02:30:44+00:00",
    "categories": [
      "math.ST",
      "math.PR",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2502.11365v3",
    "title": "Machine Learning for Detecting Steering in Qutrit-Pair States",
    "authors": [
      "Pu Wang",
      "Zhongyan Li",
      "Huixian Meng"
    ],
    "abstract": "Only a few states in high-dimensional systems can be identified as\n(un)steerable using existing theoretical or experimental methods. We utilize\nsemidefinite programming (SDP) to construct a dataset for steerability\ndetection in qutrit-qutrit systems. For the full-information feature $F_1$,\nartificial neural networks achieve high classification accuracy and\ngeneralization, and preform better than the support vector machine. As feature\nengineering playing a pivotal role, we introduce a steering ellipsoid-like\nfeature $F_2$, which significantly enhances the performance of each of our\nmodels. Given the SDP method provides only a sufficient condition for\nsteerability detection, we establish the first rigorously constructed,\naccurately labeled dataset based on theoretical foundations. This dataset\nenables models to exhibit outstanding accuracy and generalization capabilities,\nindependent of the choice of features. As applications, we investigate the\nsteerability boundaries of isotropic states and partially entangled states, and\nfind new steerable states. This work not only advances the application of\nmachine learning for probing quantum steerability in high-dimensional systems\nbut also deepens the theoretical understanding of quantum steerability itself.",
    "pdf_url": "http://arxiv.org/pdf/2502.11365v3",
    "published": "2025-02-17T02:28:05+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11364v2",
    "title": "Blessing of Multilinguality: A Systematic Analysis of Multilingual In-Context Learning",
    "authors": [
      "Yilei Tu",
      "Andrew Xue",
      "Freda Shi"
    ],
    "abstract": "While multilingual large language models generally perform adequately, and\nsometimes even rival English performance on high-resource languages (HRLs),\nthey often significantly underperform on low-resource languages (LRLs). Among\nseveral prompting strategies aiming at bridging the gap, multilingual\nin-context learning (ICL) has been particularly effective when demonstration in\ntarget languages is unavailable. However, there lacks a systematic\nunderstanding of when and why it works well.\n  In this work, we systematically analyze multilingual ICL, using\ndemonstrations in HRLs to enhance cross-lingual transfer. We show that\ndemonstrations in mixed HRLs consistently outperform English-only ones across\nthe board, particularly for tasks written in LRLs. Surprisingly, our ablation\nstudy shows that the presence of irrelevant non-English sentences in the prompt\nyields measurable gains, suggesting the effectiveness of multilingual exposure\nitself. Our results highlight the potential of strategically leveraging\nmultilingual resources to bridge the performance gap for underrepresented\nlanguages.",
    "pdf_url": "http://arxiv.org/pdf/2502.11364v2",
    "published": "2025-02-17T02:27:35+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11363v1",
    "title": "A Kernel Ridge Regression Combining Nonlinear ROMs for Accurate Flow Field Reconstruction with Discontinuities",
    "authors": [
      "Weiji Wang",
      "Chunlin Gong",
      "Xuyi Jia",
      "Chunna Li"
    ],
    "abstract": "Nonlinear reduced-order models (ROMs), represented by manifold learning (ML),\ncan effectively improve the modeling accuracy of nonlinear flow fields with\ndiscontinuities. However, the inverse mapping from low-dimensional manifold\ncoordinates to high-dimensional flow fields often introduces considerable\nreconstruction errors, leading to inaccuracy in the locations of\ndiscontinuities. To address this challenge, a novel reconstruction method is\nproposed to enhance the accuracy of reconstructing flow fields with\ndiscontinuities. The method employs kernel ridge regression (KRR) to construct\na set of nonlinear modes rich in discontinuity information, sequentially these\nmodes are nonlinearly combined with manifold coordinates to achieve accurate\nflow field reconstruction. The proposed reconstruction method is validated to\nreconstruct the transonic flow fields over RAE2822 airfoil. Comparison results\ndemonstrate that the method achieves superior reconstruction accuracy compared\nto existing approaches, especially in reconstructing flow fields' discontinuous\nregions and precisely capturing discontinuities. This work provides an\neffective and highly interpretable solution for improving the accuracy of\nnonlinear ROMs in discontinuous flow fields modeling.",
    "pdf_url": "http://arxiv.org/pdf/2502.11363v1",
    "published": "2025-02-17T02:27:26+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11362v1",
    "title": "Teleportation With Null Space Gradient Projection for Optimization Acceleration",
    "authors": [
      "Zihao Wu",
      "Juncheng Dong",
      "Ahmed Aloui",
      "Vahid Tarokh"
    ],
    "abstract": "Optimization techniques have become increasingly critical due to the\never-growing model complexity and data scale. In particular, teleportation has\nemerged as a promising approach, which accelerates convergence of gradient\ndescent-based methods by navigating within the loss invariant level set to\nidentify parameters with advantageous geometric properties. Existing\nteleportation algorithms have primarily demonstrated their effectiveness in\noptimizing Multi-Layer Perceptrons (MLPs), but their extension to more advanced\narchitectures, such as Convolutional Neural Networks (CNNs) and Transformers,\nremains challenging. Moreover, they often impose significant computational\ndemands, limiting their applicability to complex architectures. To this end, we\nintroduce an algorithm that projects the gradient of the teleportation\nobjective function onto the input null space, effectively preserving the\nteleportation within the loss invariant level set and reducing computational\ncost. Our approach is readily generalizable from MLPs to CNNs, transformers,\nand potentially other advanced architectures. We validate the effectiveness of\nour algorithm across various benchmark datasets and optimizers, demonstrating\nits broad applicability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11362v1",
    "published": "2025-02-17T02:27:16+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11361v3",
    "title": "VLDBench Evaluating Multimodal Disinformation with Regulatory Alignment",
    "authors": [
      "Shaina Raza",
      "Ashmal Vayani",
      "Aditya Jain",
      "Aravind Narayanan",
      "Vahid Reza Khazaie",
      "Syed Raza Bashir",
      "Elham Dolatabadi",
      "Gias Uddin",
      "Christos Emmanouilidis",
      "Rizwan Qureshi",
      "Mubarak Shah"
    ],
    "abstract": "Detecting disinformation that blends manipulated text and images has become\nincreasingly challenging, as AI tools make synthetic content easy to generate\nand disseminate. While most existing AI safety benchmarks focus on single\nmodality misinformation (i.e., false content shared without intent to deceive),\nintentional multimodal disinformation, such as propaganda or conspiracy\ntheories that imitate credible news, remains largely unaddressed. We introduce\nthe Vision-Language Disinformation Detection Benchmark (VLDBench), the first\nlarge-scale resource supporting both unimodal (text-only) and multimodal (text\n+ image) disinformation detection. VLDBench comprises approximately 62,000\nlabeled text-image pairs across 13 categories, curated from 58 news outlets.\nUsing a semi-automated pipeline followed by expert review, 22 domain experts\ninvested over 500 hours to produce high-quality annotations with substantial\ninter-annotator agreement. Evaluations of state-of-the-art Large Language\nModels (LLMs) and Vision-Language Models (VLMs) on VLDBench show that\nincorporating visual cues improves detection accuracy by 5 to 35 percentage\npoints over text-only models. VLDBench provides data and code for evaluation,\nfine-tuning, and robustness testing to support disinformation analysis.\nDeveloped in alignment with AI governance frameworks (e.g., the MIT AI Risk\nRepository), VLDBench offers a principled foundation for advancing trustworthy\ndisinformation detection in multimodal media.\n  Project: https://vectorinstitute.github.io/VLDBench/ Dataset:\nhttps://huggingface.co/datasets/vector-institute/VLDBench Code:\nhttps://github.com/VectorInstitute/VLDBench",
    "pdf_url": "http://arxiv.org/pdf/2502.11361v3",
    "published": "2025-02-17T02:18:47+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11360v1",
    "title": "GeoDANO: Geometric VLM with Domain Agnostic Vision Encoder",
    "authors": [
      "Seunghyuk Cho",
      "Zhenyue Qin",
      "Yang Liu",
      "Youngbin Choi",
      "Seungbeom Lee",
      "Dongwoo Kim"
    ],
    "abstract": "We introduce GeoDANO, a geometric vision-language model (VLM) with a\ndomain-agnostic vision encoder, for solving plane geometry problems. Although\nVLMs have been employed for solving geometry problems, their ability to\nrecognize geometric features remains insufficiently analyzed. To address this\ngap, we propose a benchmark that evaluates the recognition of visual geometric\nfeatures, including primitives such as dots and lines, and relations such as\northogonality. Our preliminary study shows that vision encoders often used in\ngeneral-purpose VLMs, e.g., OpenCLIP, fail to detect these features and\nstruggle to generalize across domains. We develop GeoCLIP, a CLIP based model\ntrained on synthetic geometric diagram-caption pairs to overcome the\nlimitation. Benchmark results show that GeoCLIP outperforms existing vision\nencoders in recognizing geometric features. We then propose our VLM, GeoDANO,\nwhich augments GeoCLIP with a domain adaptation strategy for unseen diagram\nstyles. GeoDANO outperforms specialized methods for plane geometry problems and\nGPT-4o on MathVerse.",
    "pdf_url": "http://arxiv.org/pdf/2502.11360v1",
    "published": "2025-02-17T02:18:33+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11359v1",
    "title": "Simulation-Based Optimization for Policy Incentives and Planning of Hybrid Microgrids",
    "authors": [
      "Nanrui Gong",
      "James C. Spall"
    ],
    "abstract": "Transitioning to renewable power generation is often difficult for remote or\nisolated communities, due to generation intermittency and high cost barriers.\nOur paper presents a simulation-based optimization approach for the design of\npolicy incentives and planning of microgrids with renewable energy sources,\ntargeting isolated communities. We propose a novel framework that integrates\nstochastic simulation to account for weather uncertainty and system\navailability while optimizing microgrid configurations and policy incentives.\nUtilizing the mixed-variable Simultaneous Perturbation Stochastic Approximation\n(MSPSA) algorithm, our method demonstrates a significant reduction in Net\nPresent Cost (NPC) for microgrids, achieving a 68.1% reduction in total costs\nin a case study conducted on Popova Island. The results indicate the\neffectiveness of our approach in enhancing the economic viability of microgrids\nwhile promoting cleaner energy solutions. Future research directions include\nrefining uncertainty models and exploring applications in grid-connected\nmicrogrids.",
    "pdf_url": "http://arxiv.org/pdf/2502.11359v1",
    "published": "2025-02-17T02:16:45+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11358v1",
    "title": "Mimicking the Familiar: Dynamic Command Generation for Information Theft Attacks in LLM Tool-Learning System",
    "authors": [
      "Ziyou Jiang",
      "Mingyang Li",
      "Guowei Yang",
      "Junjie Wang",
      "Yuekai Huang",
      "Zhiyuan Chang",
      "Qing Wang"
    ],
    "abstract": "Information theft attacks pose a significant risk to Large Language Model\n(LLM) tool-learning systems. Adversaries can inject malicious commands through\ncompromised tools, manipulating LLMs to send sensitive information to these\ntools, which leads to potential privacy breaches. However, existing attack\napproaches are black-box oriented and rely on static commands that cannot adapt\nflexibly to the changes in user queries and the invocation chain of tools. It\nmakes malicious commands more likely to be detected by LLM and leads to attack\nfailure. In this paper, we propose AutoCMD, a dynamic attack comment generation\napproach for information theft attacks in LLM tool-learning systems. Inspired\nby the concept of mimicking the familiar, AutoCMD is capable of inferring the\ninformation utilized by upstream tools in the toolchain through learning on\nopen-source systems and reinforcement with target system examples, thereby\ngenerating more targeted commands for information theft. The evaluation results\nshow that AutoCMD outperforms the baselines with +13.2% $ASR_{Theft}$, and can\nbe generalized to new tool-learning systems to expose their information leakage\nrisks. We also design four defense methods to effectively protect tool-learning\nsystems from the attack.",
    "pdf_url": "http://arxiv.org/pdf/2502.11358v1",
    "published": "2025-02-17T02:15:46+00:00",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11357v4",
    "title": "Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents",
    "authors": [
      "Vardaan Pahuja",
      "Yadong Lu",
      "Corby Rosset",
      "Boyu Gou",
      "Arindam Mitra",
      "Spencer Whitehead",
      "Yu Su",
      "Ahmed Awadallah"
    ],
    "abstract": "Recent success in large multimodal models (LMMs) has sparked promising\napplications of agents capable of autonomously completing complex web tasks.\nWhile open-source LMM agents have made significant advances in offline\nevaluation benchmarks, their performance still falls substantially short of\nhuman-level capabilities in more realistic online settings. A key bottleneck is\nthe lack of diverse and large-scale trajectory-level datasets across various\ndomains, which are expensive to collect. In this paper, we address this\nchallenge by developing a scalable recipe to synthesize the largest and most\ndiverse trajectory-level dataset to date, containing over 94K successful\nmultimodal web trajectories, spanning 49K unique URLs, 720K screenshots, and\n33M web elements. In particular, we leverage extensive web exploration and\nrefinement to obtain diverse task intents. The average cost is 28 cents per\nsuccessful trajectory, making it affordable to a wide range of users in the\ncommunity. Leveraging this dataset, we train Explorer, a multimodal web agent,\nand demonstrate strong performance on both offline and online web agent\nbenchmarks such as Mind2Web-Live, Multimodal-Mind2Web, and MiniWob++.\nAdditionally, our experiments highlight data scaling as a key driver for\nimproving web agent capabilities. We hope this study makes state-of-the-art\nLMM-based agent research at a larger scale more accessible.",
    "pdf_url": "http://arxiv.org/pdf/2502.11357v4",
    "published": "2025-02-17T02:13:48+00:00",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11355v3",
    "title": "Nuclear Deployed: Analyzing Catastrophic Risks in Decision-making of Autonomous LLM Agents",
    "authors": [
      "Rongwu Xu",
      "Xiaojian Li",
      "Shuo Chen",
      "Wei Xu"
    ],
    "abstract": "Large language models (LLMs) are evolving into autonomous decision-makers,\nraising concerns about catastrophic risks in high-stakes scenarios,\nparticularly in Chemical, Biological, Radiological and Nuclear (CBRN) domains.\nBased on the insight that such risks can originate from trade-offs between the\nagent's Helpful, Harmlessness and Honest (HHH) goals, we build a novel\nthree-stage evaluation framework, which is carefully constructed to effectively\nand naturally expose such risks. We conduct 14,400 agentic simulations across\n12 advanced LLMs, with extensive experiments and analysis. Results reveal that\nLLM agents can autonomously engage in catastrophic behaviors and deception,\nwithout being deliberately induced. Furthermore, stronger reasoning abilities\noften increase, rather than mitigate, these risks. We also show that these\nagents can violate instructions and superior commands. On the whole, we\nempirically prove the existence of catastrophic risks in autonomous LLM agents.\nWe release our code to foster further research.",
    "pdf_url": "http://arxiv.org/pdf/2502.11355v3",
    "published": "2025-02-17T02:11:17+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11356v1",
    "title": "SAIF: A Sparse Autoencoder Framework for Interpreting and Steering Instruction Following of Language Models",
    "authors": [
      "Zirui He",
      "Haiyan Zhao",
      "Yiran Qiao",
      "Fan Yang",
      "Ali Payani",
      "Jing Ma",
      "Mengnan Du"
    ],
    "abstract": "The ability of large language models (LLMs) to follow instructions is crucial\nfor their practical applications, yet the underlying mechanisms remain poorly\nunderstood. This paper presents a novel framework that leverages sparse\nautoencoders (SAE) to interpret how instruction following works in these\nmodels. We demonstrate how the features we identify can effectively steer model\noutputs to align with given instructions. Through analysis of SAE latent\nactivations, we identify specific latents responsible for instruction following\nbehavior. Our findings reveal that instruction following capabilities are\nencoded by a distinct set of instruction-relevant SAE latents. These latents\nboth show semantic proximity to relevant instructions and demonstrate causal\neffects on model behavior. Our research highlights several crucial factors for\nachieving effective steering performance: precise feature identification, the\nrole of final layer, and optimal instruction positioning. Additionally, we\ndemonstrate that our methodology scales effectively across SAEs and LLMs of\nvarying sizes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11356v1",
    "published": "2025-02-17T02:11:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11354v1",
    "title": "On the relevance of GIKS instability of charged N=4 SYM plasma",
    "authors": [
      "Alex Buchel"
    ],
    "abstract": "Recently Gladden, Ivo, Kovtun, and Starinets (GIKS) identified a novel\ninstability of ${\\cal N}=4$ supersymmetric Yang-Mills plasma with a diagonal\n$U(1)$ $R$-symmetry chemical potential. Since ${\\cal N}=4$ SYM plasma has\n$R$-charged matter fields, it might suffer from the standard superconducting\ninstability. We show that while the superconducting instability is indeed\npresent, it happens at a lower critical temperature compare to that of the GIKS\ninstability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11354v1",
    "published": "2025-02-17T02:10:48+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.11353v1",
    "title": "SparseZipper: Enhancing Matrix Extensions to Accelerate SpGEMM on CPUs",
    "authors": [
      "Tuan Ta",
      "Joshua Randall",
      "Christopher Batten"
    ],
    "abstract": "The importance of general matrix multiplication (GEMM) is motivating new\ninstruction set extensions for multiplying dense matrices in almost all\ncontemporary ISAs, and these extensions are often implemented using\nhigh-performance systolic arrays. However, matrices in emerging workloads are\nnot always dense, and sparse matrices where the vast majority of values are\nzeros are becoming more common. Existing matrix extensions and\nmicro-architectures cannot efficiently process highly sparse matrices due to\ntwo reasons: (1) wasted work when one or both input values are zero; and (2)\nincompatibility with sparse matrix formats. This work proposes SparseZipper\nthat minimally modifies existing matrix extensions and systolic-array-based\nmicro-architectures specialized for dense-dense GEMM to accelerate\nsparse-sparse GEMM operating on highly sparse matrices with unstructured\nsparsity structures. Our performance evaluation shows SparseZipper achieves\n5.98x and 2.61x speedup over a scalar hash-based implementation of SpGEMM and a\nstate-of-the-art vectorized SpGEMM version, respectively. Our component-level\narea evaluation shows SparseZipper increases the area of a baseline 16x16\nsystolic array by only 12.7% resulting in an area overhead for an entire\nsystem-on-chip of just a few percent.",
    "pdf_url": "http://arxiv.org/pdf/2502.11353v1",
    "published": "2025-02-17T02:09:46+00:00",
    "categories": [
      "cs.AR",
      "C.1.2"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11352v1",
    "title": "A Framework for Learning Scoring Rules in Autonomous Driving Planning Systems",
    "authors": [
      "Zikang Xiong",
      "Joe Kurian Eappen",
      "Suresh Jagannathan"
    ],
    "abstract": "In autonomous driving systems, motion planning is commonly implemented as a\ntwo-stage process: first, a trajectory proposer generates multiple candidate\ntrajectories, then a scoring mechanism selects the most suitable trajectory for\nexecution. For this critical selection stage, rule-based scoring mechanisms are\nparticularly appealing as they can explicitly encode driving preferences,\nsafety constraints, and traffic regulations in a formalized,\nhuman-understandable format. However, manually crafting these scoring rules\npresents significant challenges: the rules often contain complex\ninterdependencies, require careful parameter tuning, and may not fully capture\nthe nuances present in real-world driving data. This work introduces FLoRA, a\nnovel framework that bridges this gap by learning interpretable scoring rules\nrepresented in temporal logic. Our method features a learnable logic structure\nthat captures nuanced relationships across diverse driving scenarios,\noptimizing both rules and parameters directly from real-world driving\ndemonstrations collected in NuPlan. Our approach effectively learns to evaluate\ndriving behavior even though the training data only contains positive examples\n(successful driving demonstrations). Evaluations in closed-loop planning\nsimulations demonstrate that our learned scoring rules outperform existing\ntechniques, including expert-designed rules and neural network scoring models,\nwhile maintaining interpretability. This work introduces a data-driven approach\nto enhance the scoring mechanism in autonomous driving systems, designed as a\nplug-in module to seamlessly integrate with various trajectory proposers. Our\nvideo and code are available on xiong.zikang.me/FLoRA.",
    "pdf_url": "http://arxiv.org/pdf/2502.11352v1",
    "published": "2025-02-17T02:06:57+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11351v6",
    "title": "Review of the QCD sum rules for exotic states",
    "authors": [
      "Zhi-Gang Wang"
    ],
    "abstract": "We review the exotic states, such as the $X$, $Y$, $Z$, $T$ and $P$ states,\nand present their possible assignments based on the QCD sum rules. We present\nmany predictions which can be confronted to the experimental data in the future\nto diagnose the exotic states. Furthermore, we also mention other theoretical\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2502.11351v6",
    "published": "2025-02-17T02:05:01+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11350v2",
    "title": "Planar 3$Ï$ and 2$Ï$ Method for Increased Sensitivity to Through-Plane Thermal Properties",
    "authors": [
      "Darshan Chalise",
      "Brinthan Kanesalingam",
      "Divya Chalise"
    ],
    "abstract": "Accurately measuring the thermal properties of buried interfaces is crucial\nfor understanding heat transport in multilayered materials, particularly in\napplications such as batteries and integrated circuits. The conventional\n3$\\omega$ method, which uses a line heater, has limited sensitivity to\nthrough-plane thermal properties due to lateral heat spreading, especially when\na highly conductive layer overlays a resistive one. Additionally, when using a\nline heater, there is a lower limit to the frequency of heating, below which\nthe analytical solution assuming infinite lateral dimension is not valid. This\nlimits analytical interpretation of 2$\\omega$ temperature oscillation at lower\nfrequencies where the sensitivity to the conductivity of a buried layer is\ngreater. To overcome these limitations, we propose a planar 3$\\omega$ and\n2$\\omega$ method that enhances the sensitivity to buried layers by ensuring\nplanar heat flow. We implement this technique using a planar metallic heater\nacross the entire sample and validate it experimentally against the analytical\nsolution using Feldman's algorithm. We also discuss the practical\nimplementation details of the approach, including ensuring uniform current\ndistribution and the required sensor layout. Our results demonstrate improved\nmeasurement sensitivity for polymer layers in silicon stacks and buried\ninterfaces in battery electrodes, with sensitivity improvements by factors of\n2-5 compared to conventional technique using a line heater.",
    "pdf_url": "http://arxiv.org/pdf/2502.11350v2",
    "published": "2025-02-17T02:04:48+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11349v1",
    "title": "Biases in Edge Language Models: Detection, Analysis, and Mitigation",
    "authors": [
      "Vinamra Sharma",
      "Danilo Pietro Pau",
      "JosÃ© Cano"
    ],
    "abstract": "The integration of large language models (LLMs) on low-power edge devices\nsuch as Raspberry Pi, known as edge language models (ELMs), has introduced\nopportunities for more personalized, secure, and low-latency language\nintelligence that is accessible to all. However, the resource constraints\ninherent in edge devices and the lack of robust ethical safeguards in language\nmodels raise significant concerns about fairness, accountability, and\ntransparency in model output generation. This paper conducts a comparative\nanalysis of text-based bias across language model deployments on edge, cloud,\nand desktop environments, aiming to evaluate how deployment settings influence\nmodel fairness. Specifically, we examined an optimized Llama-2 model running on\na Raspberry Pi 4; GPT 4o-mini, Gemini-1.5-flash, and Grok-beta models running\non cloud servers; and Gemma2 and Mistral models running on a MacOS desktop\nmachine. Our results demonstrate that Llama-2 running on Raspberry Pi 4 is\n43.23% and 21.89% more prone to showing bias over time compared to models\nrunning on the desktop and cloud-based environments. We also propose the\nimplementation of a feedback loop, a mechanism that iteratively adjusts model\nbehavior based on previous outputs, where predefined constraint weights are\napplied layer-by-layer during inference, allowing the model to correct bias\npatterns, resulting in 79.28% reduction in model bias.",
    "pdf_url": "http://arxiv.org/pdf/2502.11349v1",
    "published": "2025-02-17T01:57:31+00:00",
    "categories": [
      "cs.LG",
      "cs.PF",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11348v2",
    "title": "Global dynamics of a two-species competition patch model in a Y-shaped river network",
    "authors": [
      "Weifang Yan",
      "Shanshan Chen"
    ],
    "abstract": "In this paper, we investigate a two-species Lotka-Volterra competition patch\nmodel in a Y-shaped river network, where the two species are assumed to be\nidentical except for their random and directed movements. We show that\ncompetition exclusion can occur under certain conditions, i.e., one of the\nsemi-trivial equilibrium is globally asymptotically stable. Especially, if the\nrandom dispersal rates of the two species are equal, the species with a smaller\ndrift rate will drive the other species to extinction, which suggests that\nsmall drift rates are favored.",
    "pdf_url": "http://arxiv.org/pdf/2502.11348v2",
    "published": "2025-02-17T01:55:56+00:00",
    "categories": [
      "math.DS",
      "34D23, 34C12, 37C65, 92D25, 92D40"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11347v1",
    "title": "Evaluating the Performance of the DeepSeek Model in Confidential Computing Environment",
    "authors": [
      "Ben Dong",
      "Qian Wang"
    ],
    "abstract": "The increasing adoption of Large Language Models (LLMs) in cloud environments\nraises critical security concerns, particularly regarding model confidentiality\nand data privacy. Confidential computing, enabled by Trusted Execution\nEnvironments (TEEs), offers a promising solution to mitigate these risks.\nHowever, existing TEE implementations, primarily CPU-based, struggle to\nefficiently support the resource-intensive nature of LLM inference and\ntraining. In this work, we present the first evaluation of the DeepSeek model\nwithin a TEE-enabled confidential computing environment, specifically utilizing\nIntel Trust Domain Extensions (TDX). Our study benchmarks DeepSeek's\nperformance across CPU-only, CPU-GPU hybrid, and TEE-based implementations. For\nsmaller parameter sets, such as DeepSeek-R1-1.5B, the TDX implementation\noutperforms the CPU version in executing computations within a secure\nenvironment. It highlights the potential for efficiently deploying LLM models\non resource-constrained systems while ensuring security. The overall GPU-to-CPU\nperformance ratio averages 12 across different model sizes, with smaller models\nexhibiting a lower ratio. Additionally, we provide foundational insights and\nguidance on optimizing CPU-GPU confidential computing solutions for scalable\nand secure AI deployments. Our findings contribute to the advancement of\nprivacy-preserving AI, paving the way for efficient and secure LLM inference in\nconfidential computing environments.",
    "pdf_url": "http://arxiv.org/pdf/2502.11347v1",
    "published": "2025-02-17T01:55:38+00:00",
    "categories": [
      "cs.PF"
    ],
    "primary_category": "cs.PF"
  },
  {
    "id": "http://arxiv.org/abs/2502.11346v1",
    "title": "Power-Measurement-Based Channel Autocorrelation Estimation for IRS-Assisted Wideband Communications",
    "authors": [
      "He Sun",
      "Lipeng Zhu",
      "Weidong Mei",
      "Rui Zhang"
    ],
    "abstract": "Channel state information (CSI) is essential to the performance optimization\nof intelligent reflecting surface (IRS)-aided wireless communication systems.\nHowever, the passive and frequency-flat reflection of IRS, as well as the\nhigh-dimensional IRS-reflected channels, have posed practical challenges for\nefficient IRS channel estimation, especially in wideband communication systems\nwith significant multi-path channel delay spread. To tackle the above\nchallenge, we propose a novel neural network (NN)-empowered IRS channel\nestimation and passive reflection design framework for the wideband orthogonal\nfrequency division multiplexing (OFDM) communication system based only on the\nuser's reference signal received power (RSRP) measurements with time-varying\nrandom IRS training reflections. In particular, we show that the average\nreceived signal power over all OFDM subcarriers at the user terminal can be\nrepresented as the prediction of a single-layer NN composed of multiple\nsubnetworks with the same structure, such that the autocorrelation matrix of\nthe wideband IRS channel can be recovered as their weights via supervised\nlearning. To exploit the potential sparsity of the channel autocorrelation\nmatrix, a progressive training method is proposed by gradually increasing the\nnumber of subnetworks until a desired accuracy is achieved, thus reducing the\ntraining complexity. Based on the estimates of IRS channel autocorrelation\nmatrix, the IRS passive reflection is then optimized to maximize the average\nchannel power gain over all subcarriers. Numerical results indicate the\neffectiveness of the proposed IRS channel autocorrelation matrix estimation and\npassive reflection design under wideband channels, which can achieve\nsignificant performance improvement compared to the existing IRS reflection\ndesigns based on user power measurements.",
    "pdf_url": "http://arxiv.org/pdf/2502.11346v1",
    "published": "2025-02-17T01:55:36+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11345v1",
    "title": "Hierarchical Graph Topic Modeling with Topic Tree-based Transformer",
    "authors": [
      "Delvin Ce Zhang",
      "Menglin Yang",
      "Xiaobao Wu",
      "Jiasheng Zhang",
      "Hady W. Lauw"
    ],
    "abstract": "Textual documents are commonly connected in a hierarchical graph structure\nwhere a central document links to others with an exponentially growing\nconnectivity. Though Hyperbolic Graph Neural Networks (HGNNs) excel at\ncapturing such graph hierarchy, they cannot model the rich textual semantics\nwithin documents. Moreover, text contents in documents usually discuss topics\nof different specificity. Hierarchical Topic Models (HTMs) discover such latent\ntopic hierarchy within text corpora. However, most of them focus on the textual\ncontent within documents, and ignore the graph adjacency across interlinked\ndocuments. We thus propose a Hierarchical Graph Topic Modeling Transformer to\nintegrate both topic hierarchy within documents and graph hierarchy across\ndocuments into a unified Transformer. Specifically, to incorporate topic\nhierarchy within documents, we design a topic tree and infer a hierarchical\ntree embedding for hierarchical topic modeling. To preserve both topic and\ngraph hierarchies, we design our model in hyperbolic space and propose\nHyperbolic Doubly Recurrent Neural Network, which models ancestral and\nfraternal tree structure. Both hierarchies are inserted into each Transformer\nlayer to learn unified representations. Both supervised and unsupervised\nexperiments verify the effectiveness of our model.",
    "pdf_url": "http://arxiv.org/pdf/2502.11345v1",
    "published": "2025-02-17T01:55:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11344v1",
    "title": "A Coq implementation of a Theory of Tagged Objects",
    "authors": [
      "Matthew Gates",
      "Alex Potanin"
    ],
    "abstract": "We present a first step towards the Coq implementation of the Theory of\nTagged Objects formalism. The concept of tagged types is encoded, and the\nsoundness proofs are discussed with some future work suggestions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11344v1",
    "published": "2025-02-17T01:54:30+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11343v2",
    "title": "SPLD polynomial optimization and bounded degree SOS hierarchies",
    "authors": [
      "Liguo Jiao",
      "Jae Hyoung Lee",
      "Nguyen Bui Nguyen Thao"
    ],
    "abstract": "In this paper, we introduce a new class of structured polynomials, called\nseparable plus lower degree (SPLD) polynomials. The formal definition of an\nSPLD polynomial, which extends the concept of SPQ polynomials (Ahmadi et al. in\nMath Oper Res 48:1316--1343, 2023), is provided. A type of bounded degree SOS\nhierarchy, referred to as BSOS-SPLD, is proposed to efficiently solve\noptimization problems involving SPLD polynomials. Numerical experiments on\nseveral benchmark problems indicate that the proposed method yields better\nperformance than the standard bounded degree SOS hierarchy (Lasserre et al. in\nEURO J Comput Optim 5:87--117, 2017). An exact SOS relaxation for a class of\nconvex SPLD polynomial optimization problems is proposed. Finally, we present\nan application of SPLD polynomials to convex polynomial regression problems\narising in statistics.",
    "pdf_url": "http://arxiv.org/pdf/2502.11343v2",
    "published": "2025-02-17T01:52:40+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11342v1",
    "title": "Revisiting the charge-density-wave superlattice of 1$T$-TiSe$_2$",
    "authors": [
      "Wei Wang",
      "Patrick Liu",
      "Lijun Wu",
      "Jing Tao",
      "Genda Gu",
      "Alfred Zong",
      "Yimei Zhu"
    ],
    "abstract": "A number of intriguing phenomena, including exciton condensation, orbital\nordering, and emergence of chirality, have been proposed to accompany\ncharge-density-wave (CDW) formation in the layered transition metal\ndichalcogenide 1$T$-TiSe$_2$. Explaining these effects relies on knowledge of\nthe atomic displacement pattern underlying the CDW, yet structural proposals\nbased on spatially-averaging bulk crystal diffraction and surface-dependent\nscanning tunneling microscopy have remained inconsistent. Here, we revisit the\nCDW superlattice structure with selected-area electron diffraction, a\nbulk-sensitive probe capable of capturing sub-micrometer spatial variations\nwhile maintaining high momentum resolution. We resolved two distinct, spatially\nseparated CDW phases characterized by different interlayer ordering. In both\nphases, previously reported atomic displacement patterns fail to account for\nthe observed extinction rules. Instead, our analysis reveals a new superlattice\nstructure, which features a large number of nearly degenerate CDW domains.\nThese findings not only provide a new basis for understanding the gyrotropic\nelectronic order and metastability in 1$T$-TiSe$_2$, they also underscore the\nimportance of bulk-sensitive mesoscopic techniques in investigating materials\nthat host unconventional superlattices.",
    "pdf_url": "http://arxiv.org/pdf/2502.11342v1",
    "published": "2025-02-17T01:46:09+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11341v1",
    "title": "Interaction-driven losses for atoms in a dark-state lattice",
    "authors": [
      "Piotr Kubala",
      "Mateusz ÅÄcki"
    ],
    "abstract": "In this work we estimate the collisional loss rate of ultracold bosons in the\noptical potential featuring subwavelength-width peaks. This is established by\nusing $\\Lambda$ arrangement of three atomic states coupled (almost) resonantly\nby lasers. Using Fermi's Golden Rule, we find that the loss rate is influenced\nby the overall strength of the lasers, with the largest losses occurring when\nthe two-photon transition is blue-detuned from the excited state of the\n$\\Lambda$ system. Overall, the predicted loss rates are low, which may allow\nthe use of ultracold bosons in the construction of dark-state potentials in the\n$\\Lambda$-type many-level system.",
    "pdf_url": "http://arxiv.org/pdf/2502.11341v1",
    "published": "2025-02-17T01:42:01+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2502.11340v1",
    "title": "S2TX: Cross-Attention Multi-Scale State-Space Transformer for Time Series Forecasting",
    "authors": [
      "Zihao Wu",
      "Juncheng Dong",
      "Haoming Yang",
      "Vahid Tarokh"
    ],
    "abstract": "Time series forecasting has recently achieved significant progress with\nmulti-scale models to address the heterogeneity between long and short range\npatterns. Despite their state-of-the-art performance, we identify two potential\nareas for improvement. First, the variates of the multivariate time series are\nprocessed independently. Moreover, the multi-scale (long and short range)\nrepresentations are learned separately by two independent models without\ncommunication. In light of these concerns, we propose State Space Transformer\nwith cross-attention (S2TX). S2TX employs a cross-attention mechanism to\nintegrate a Mamba model for extracting long-range cross-variate context and a\nTransformer model with local window attention to capture short-range\nrepresentations. By cross-attending to the global context, the Transformer\nmodel further facilitates variate-level interactions as well as local/global\ncommunications. Comprehensive experiments on seven classic long-short range\ntime-series forecasting benchmark datasets demonstrate that S2TX can achieve\nhighly robust SOTA results while maintaining a low memory footprint.",
    "pdf_url": "http://arxiv.org/pdf/2502.11340v1",
    "published": "2025-02-17T01:40:45+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11339v1",
    "title": "Why is the strength of a polymer network so low?",
    "authors": [
      "Shaswat Mohanty",
      "Jose Blanchet",
      "Zhigang Suo",
      "Wei Cai"
    ],
    "abstract": "Experiments have long shown that a polymer network of covalent bonds commonly\nruptures at a stress that is orders of magnitude lower than the strength of the\ncovalent bonds. Here we investigate this large reduction in strength by\ncoarse-grained molecular dynamics simulations. We show that the network\nruptures by sequentially breaking a small fraction of bonds, and that each\nbroken bond lies on the minimum \"shortest path\". The shortest path is the path\nof the fewest bonds that connect two monomers at the opposite ends of the\nnetwork. As the network is stretched, the minimum shortest path straightens and\nbears high tension set by covalent bonds, while most strands off the path\ndeform by entropic elasticity. After a bond on the minimum shortest path\nbreaks, the process repeats for the next minimum shortest path. As the network\nis stretched and bonds are broken, the scatter in lengths of the shortest paths\nfirst narrows, causing stress to rise, and then broadens, causing stress to\ndecline. This sequential breaking of a small fraction of bonds causes the\nnetwork to rupture at a stress that is orders of magnitude below the strength\nof the covalent bonds.",
    "pdf_url": "http://arxiv.org/pdf/2502.11339v1",
    "published": "2025-02-17T01:33:56+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.mtrl-sci",
      "cond-mat.stat-mech",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2502.11338v1",
    "title": "WRT-SAM: Foundation Model-Driven Segmentation for Generalized Weld Radiographic Testing",
    "authors": [
      "Yunyi Zhou",
      "Kun Shi",
      "Gang Hao"
    ],
    "abstract": "Radiographic testing is a fundamental non-destructive evaluation technique\nfor identifying weld defects and assessing quality in industrial applications\ndue to its high-resolution imaging capabilities. Over the past decade, deep\nlearning techniques have significantly advanced weld defect identification in\nradiographic images. However, conventional approaches, which rely on training\nsmall-scale, task-specific models on single-scenario datasets, exhibit poor\ncross-scenario generalization. Recently, the Segment Anything Model (SAM), a\npre-trained visual foundation model trained on large-scale datasets, has\ndemonstrated exceptional zero-shot generalization capabilities. Fine-tuning SAM\nwith limited domain-specific data has yielded promising results in fields such\nas medical image segmentation and anomaly detection. To the best of our\nknowledge, this work is the first to introduce SAM-based segmentation for\ngeneral weld radiographic testing images. We propose WRT-SAM, a novel weld\nradiographic defect segmentation model that leverages SAM through an\nadapter-based integration with a specialized prompt generator architecture. To\nimprove adaptability to grayscale weld radiographic images, we introduce a\nfrequency prompt generator module, which enhances the model's sensitivity to\nfrequency-domain information. Furthermore, to address the multi-scale nature of\nweld defects, we incorporate a multi-scale prompt generator module, enabling\nthe model to effectively extract and encode defect information across varying\nscales. Extensive experimental evaluations demonstrate that WRT-SAM achieves a\nrecall of 78.87%, a precision of 84.04%, and an AUC of 0.9746, setting a new\nstate-of-the-art (SOTA) benchmark. Moreover, the model exhibits superior\nzero-shot generalization performance, highlighting its potential for practical\ndeployment in diverse radiographic testing scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.11338v1",
    "published": "2025-02-17T01:31:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11337v1",
    "title": "A Comparison of Human and Machine Learning Errors in Face Recognition",
    "authors": [
      "Marina EstÃ©vez-Almenzar",
      "Ricardo Baeza-Yates",
      "Carlos Castillo"
    ],
    "abstract": "Machine learning applications in high-stakes scenarios should always operate\nunder human oversight. Developing an optimal combination of human and machine\nintelligence requires an understanding of their complementarities, particularly\nregarding the similarities and differences in the way they make mistakes. We\nperform extensive experiments in the area of face recognition and compare two\nautomated face recognition systems against human annotators through a\ndemographically balanced user study. Our research uncovers important ways in\nwhich machine learning errors and human errors differ from each other, and\nsuggests potential strategies in which human-machine collaboration can improve\naccuracy in face recognition.",
    "pdf_url": "http://arxiv.org/pdf/2502.11337v1",
    "published": "2025-02-17T01:27:35+00:00",
    "categories": [
      "cs.HC",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2503.05717v1",
    "title": "A computational model for crack-tip fields in a 3-D porous elastic solid with material moduli dependent on density",
    "authors": [
      "Kun Gou",
      "S. M. Mallikarjunaiah"
    ],
    "abstract": "A mathematical model for crack-tip fields is proposed in this paper for the\nresponse of a three-dimensional (3-D) porous elastic solid whose material\nmoduli are dependent on the density. Such a description wherein the generalized\nLam\\`e coefficients are nonlinear functions of material stiffness is more\nrealistic because most engineering materials are porous, and their material\nproperties depend on porosity and density. The governing boundary value problem\nfor the static equilibrium state in a 3-D, homogeneous, isotropic material is\nobtained as a second-order, quasilinear partial-differential-equation system\nwith a classical traction-free crack-surface boundary condition. The numerical\nsolution is obtained from a continuous trilinear Galerkin-type finite element\ndiscretization. A Picard-type linearization is utilized to handle the\nnonlinearities in the discrete problem. The proposed model can describe the\nstate of stress and strain in various materials, including recovering the\nclassical singularities in the linearized model. The role of \\textit{tensile\nstress}, \\textit{stress intensity factor} (SIF), and \\textit{strain energy\ndensity} are examined. The results indicate that the maximum values of all\nthese quantities occur directly before the crack-tip, consistent with the\nobservation made in the canonical problem for the linearized elastic fracture\nmechanics. One can use the same classical local fracture criterion, like the\nmaximum of SIF, to study crack tips' quasi-static and dynamic evolution within\nthe framework described in this article.",
    "pdf_url": "http://arxiv.org/pdf/2503.05717v1",
    "published": "2025-02-17T01:23:19+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12209v1",
    "title": "Suboptimal Shapley Value Explanations",
    "authors": [
      "Xiaolei Lu"
    ],
    "abstract": "Deep Neural Networks (DNNs) have demonstrated strong capacity in supporting a\nwide variety of applications. Shapley value has emerged as a prominent tool to\nanalyze feature importance to help people understand the inference process of\ndeep neural models. Computing Shapley value function requires choosing a\nbaseline to represent feature's missingness. However, existing random and\nconditional baselines could negatively influence the explanation. In this\npaper, by analyzing the suboptimality of different baselines, we identify the\nproblematic baseline where the asymmetric interaction between $\\bm{x}'_i$ (the\nreplacement of the faithful influential feature) and other features has\nsignificant directional bias toward the model's output, and conclude that\n$p(y|\\bm{x}'_i) = p(y)$ potentially minimizes the asymmetric interaction\ninvolving $\\bm{x}'_i$. We further generalize the uninformativeness of\n$\\bm{x}'_i$ toward the label space $L$ to avoid estimating $p(y)$ and design a\nsimple uncertainty-based reweighting mechanism to accelerate the computation\nprocess. We conduct experiments on various NLP tasks and our quantitative\nanalysis demonstrates the effectiveness of the proposed uncertainty-based\nreweighting mechanism. Furthermore, by measuring the consistency of\nexplanations generated by explainable methods and human, we highlight the\ndisparity between model inference and human understanding.",
    "pdf_url": "http://arxiv.org/pdf/2502.12209v1",
    "published": "2025-02-17T01:17:12+00:00",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.11336v1",
    "title": "ExaGPT: Example-Based Machine-Generated Text Detection for Human Interpretability",
    "authors": [
      "Ryuto Koike",
      "Masahiro Kaneko",
      "Ayana Niwa",
      "Preslav Nakov",
      "Naoaki Okazaki"
    ],
    "abstract": "Detecting texts generated by Large Language Models (LLMs) could cause grave\nmistakes due to incorrect decisions, such as undermining student's academic\ndignity. LLM text detection thus needs to ensure the interpretability of the\ndecision, which can help users judge how reliably correct its prediction is.\nWhen humans verify whether a text is human-written or LLM-generated, they\nintuitively investigate with which of them it shares more similar spans.\nHowever, existing interpretable detectors are not aligned with the human\ndecision-making process and fail to offer evidence that users easily\nunderstand. To bridge this gap, we introduce ExaGPT, an interpretable detection\napproach grounded in the human decision-making process for verifying the origin\nof a text. ExaGPT identifies a text by checking whether it shares more similar\nspans with human-written vs. with LLM-generated texts from a datastore. This\napproach can provide similar span examples that contribute to the decision for\neach span in the text as evidence. Our human evaluation demonstrates that\nproviding similar span examples contributes more effectively to judging the\ncorrectness of the decision than existing interpretable methods. Moreover,\nextensive experiments in four domains and three generators show that ExaGPT\nmassively outperforms prior powerful detectors by up to +40.9 points of\naccuracy at a false positive rate of 1%.",
    "pdf_url": "http://arxiv.org/pdf/2502.11336v1",
    "published": "2025-02-17T01:15:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11335v1",
    "title": "Personalized Ranking on Cascading Behavior Graphs for Accurate Multi-Behavior Recommendation",
    "authors": [
      "Geonwoo Ko",
      "Minseo Jeon",
      "Jinhong Jung"
    ],
    "abstract": "Multi-behavior recommendation predicts items a user may purchase by analyzing\ndiverse behaviors like viewing, adding to a cart, and purchasing. Existing\nmethods fall into two categories: representation learning and graph ranking.\nRepresentation learning generates user and item embeddings to capture latent\ninteraction patterns, leveraging multi-behavior properties for better\ngeneralization. However, these methods often suffer from over-smoothing and\nbias toward frequent interactions, limiting their expressiveness. Graph ranking\nmethods, on the other hand, directly compute personalized ranking scores,\ncapturing user preferences more effectively. Despite their potential, graph\nranking approaches have been primarily explored in single-behavior settings and\nremain underutilized for multi-behavior recommendation. In this paper, we\npropose CascadingRank, a novel graph ranking method for multi-behavior\nrecommendation. It models the natural sequence of user behaviors (e.g.,\nviewing, adding to cart, and purchasing) through a cascading behavior graph. An\niterative algorithm computes ranking scores, ensuring smoothness, query\nfitting, and cascading alignment. Experiments on three real-world datasets\ndemonstrate that CascadingRank outperforms state-of-the-art methods, with up to\n9.56% and 7.16% improvements in HR@10 and NDCG@10, respectively. Furthermore,\nwe provide theoretical analysis highlighting its effectiveness, convergence,\nand scalability, showcasing the advantages of graph ranking in multi-behavior\nrecommendation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11335v1",
    "published": "2025-02-17T01:13:45+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11334v2",
    "title": "Three-dimensional imaging of biological cells using surface plasmon coupled emission",
    "authors": [
      "Anik Mazumder",
      "Mohammad Mozammal",
      "Muhammad Anisuzzaman Talukder"
    ],
    "abstract": "Biological cell imaging has become one of the most crucial research interests\ndue to its wide-ranging applications in biomedical and microbiology studies.\nHowever, three-dimensional (3D) imaging of biological cells remains critically\nchallenging and often requires prohibitively expensive and complex equipment.\nTherefore, a low-cost imaging technique with a simpler optical arrangement is\nhighly desirable. We propose an approach to obtain accurate 3D cell images\nusing surface plasmon coupled emission (SPCE) patterns from a fluorescently\nlabeled biological cell, eliminating the need for conventional microscopes or\nextensive data processing. An imaging methodology has been developed and\ntheoretically demonstrated to reconstruct 3D cell structures from detected SPCE\npatterns. The reconstructed 3D images closely match the actual cell geometries.\nThe technique has been applied to both regular and irregular cell shapes. In\neach case, the root-mean-square error (RMSE) between the reconstructed images\nand the actual structures remains within a few percent. For a circular-shaped\ncell base, the RMSE is $\\lesssim 1.4\\%$, while for irregular cell bases, the\nRMSE is $\\lesssim 2.8\\%$. Finally, a 3D image of a random cellular structure is\nobtained with an RMSE of $\\lesssim 6.5\\%$. Despite being in its initial stages\nof development, the proposed technique demonstrates promising results\nconsidering its simplicity and low cost.",
    "pdf_url": "http://arxiv.org/pdf/2502.11334v2",
    "published": "2025-02-17T01:12:29+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.11333v1",
    "title": "Inverse Flow and Consistency Models",
    "authors": [
      "Yuchen Zhang",
      "Jian Zhou"
    ],
    "abstract": "Inverse generation problems, such as denoising without ground truth\nobservations, is a critical challenge in many scientific inquiries and\nreal-world applications. While recent advances in generative models like\ndiffusion models, conditional flow matching, and consistency models achieved\nimpressive results by casting generation as denoising problems, they cannot be\ndirectly used for inverse generation without access to clean data. Here we\nintroduce Inverse Flow (IF), a novel framework that enables using these\ngenerative models for inverse generation problems including denoising without\nground truth. Inverse Flow can be flexibly applied to nearly any continuous\nnoise distribution and allows complex dependencies. We propose two algorithms\nfor learning Inverse Flows, Inverse Flow Matching (IFM) and Inverse Consistency\nModel (ICM). Notably, to derive the computationally efficient, simulation-free\ninverse consistency model objective, we generalized consistency training to any\nforward diffusion processes or conditional flows, which have applications\nbeyond denoising. We demonstrate the effectiveness of IF on synthetic and real\ndatasets, outperforming prior approaches while enabling noise distributions\nthat previous methods cannot support. Finally, we showcase applications of our\ntechniques to fluorescence microscopy and single-cell genomics data,\nhighlighting IF's utility in scientific problems. Overall, this work expands\nthe applications of powerful generative models to inversion generation\nproblems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11333v1",
    "published": "2025-02-17T01:11:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11332v2",
    "title": "Stochastic Block Covariance Matrix Estimation",
    "authors": [
      "Yunran Chen",
      "Surya T Tokdar",
      "Jennifer M Groh"
    ],
    "abstract": "Motivated by a neuroscience application we study the problem of statistical\nestimation of a high-dimensional covariance matrix with a block structure. The\nblock model embeds a structural assumption: the population of items (neurons)\ncan be divided into latent sub-populations with shared associative covariation\nwithin blocks and shared associative or dis-associative covariation across\nblocks. Unlike the block diagonal assumption, our block structure incorporates\npositive or negative pairwise correlation between blocks. In addition to\noffering reasonable modeling choices in neuroscience and economics, the block\ncovariance matrix assumption is interesting purely from the perspective of\nstatistical estimation theory: (a) it offers in-built dimension reduction and\n(b) it resembles a regularized factor model without the need of choosing the\nnumber of factors. We discuss a hierarchical Bayesian estimation method to\nsimultaneously recover the latent blocks and estimate the overall covariance\nmatrix. We show with numerical experiments that a hierarchical structure and a\nshrinkage prior are essential to accurate recovery when several blocks are\npresent.",
    "pdf_url": "http://arxiv.org/pdf/2502.11332v2",
    "published": "2025-02-17T01:08:40+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.11331v3",
    "title": "Transfer Learning of CATE with Kernel Ridge Regression",
    "authors": [
      "Seok-Jin Kim",
      "Hongjie Liu",
      "Molei Liu",
      "Kaizheng Wang"
    ],
    "abstract": "The proliferation of data has sparked significant interest in leveraging\nfindings from one study to estimate treatment effects in a different target\npopulation without direct outcome observations. However, the transfer learning\nprocess is frequently hindered by substantial covariate shift and limited\noverlap between (i) the source and target populations, as well as (ii) the\ntreatment and control groups within the source. We propose a novel method for\noverlap-adaptive transfer learning of conditional average treatment effect\n(CATE) using kernel ridge regression (KRR). Our approach involves partitioning\nthe labeled source data into two subsets. The first one is used to train\ncandidate CATE models based on regression adjustment and pseudo-outcomes. An\noptimal model is then selected using the second subset and unlabeled target\ndata, employing another pseudo-outcome-based strategy. We provide a theoretical\njustification for our method through sharp non-asymptotic MSE bounds,\nhighlighting its adaptivity to both weak overlaps and the complexity of CATE\nfunction. Extensive numerical studies confirm that our method achieves superior\nfinite-sample efficiency and adaptability. We conclude by demonstrating the\neffectiveness of our approach using a 401(k) eligibility dataset.",
    "pdf_url": "http://arxiv.org/pdf/2502.11331v3",
    "published": "2025-02-17T01:07:45+00:00",
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.11330v2",
    "title": "System Message Generation for User Preferences using Open-Source Models",
    "authors": [
      "Minbyul Jeong",
      "Jungho Cho",
      "Minsoo Khang",
      "Dawoon Jung",
      "Teakgyu Hong"
    ],
    "abstract": "System messages play a crucial role in interactions with large language\nmodels (LLMs), often serving as prompts to initiate conversations. Through\nsystem messages, users can assign specific roles, perform intended tasks,\nincorporate background information, and specify various output formats and\ncommunication styles. Despite such versatility, publicly available datasets\noften lack system messages and are subject to strict license constraints in\nindustrial applications. Moreover, manually annotating system messages that\nalign with user instructions is resource-intensive. In light of these\nchallenges, we introduce SysGen, a pipeline for generating system messages that\nbetter align assistant responses with user instructions using existing\nsupervised fine-tuning datasets that lack system messages. Training open-source\nmodels on SysGen data yields substantial improvements in both single-turn\n(Multifacet) and multi-turn (SysBench) conversation benchmarks. Notably, our\nmethod shows strong gains in shorter conversations, suggesting that it enhances\nearly-stage interaction effectiveness. Our qualitative analysis further\nemphasizes the value of diverse and structured system messages in improving LLM\nadaptability across varied user scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2502.11330v2",
    "published": "2025-02-17T01:05:31+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11329v1",
    "title": "Differentially private fine-tuned NF-Net to predict GI cancer type",
    "authors": [
      "Sai Venkatesh Chilukoti",
      "Imran Hossen Md",
      "Liqun Shan",
      "Vijay Srinivas Tida",
      "Xiali Hei"
    ],
    "abstract": "Based on global genomic status, the cancer tumor is classified as\nMicrosatellite Instable (MSI) and Microsatellite Stable (MSS). Immunotherapy is\nused to diagnose MSI, whereas radiation and chemotherapy are used for MSS.\nTherefore, it is significant to classify a gastro-intestinal (GI) cancer tumor\ninto MSI vs. MSS to provide appropriate treatment. The existing literature\nshowed that deep learning could directly predict the class of GI cancer tumors\nfrom histological images. However, deep learning (DL) models are susceptible to\nvarious threats, including membership inference attacks, model extraction\nattacks, etc. These attacks render the use of DL models impractical in\nreal-world scenarios. To make the DL models useful and maintain privacy, we\nintegrate differential privacy (DP) with DL. In particular, this paper aims to\npredict the state of GI cancer while preserving the privacy of sensitive data.\nWe fine-tuned the Normalizer Free Net (NF-Net) model. We obtained an accuracy\nof 88.98\\% without DP to predict (GI) cancer status. When we fine-tuned the\nNF-Net using DP-AdamW and adaptive DP-AdamW, we got accuracies of 74.58% and\n76.48%, respectively. Moreover, we investigate the Weighted Random Sampler\n(WRS) and Class weighting (CW) to solve the data imbalance. We also evaluated\nand analyzed the DP algorithms in different settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.11329v1",
    "published": "2025-02-17T01:04:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11328v1",
    "title": "Progress of the TianQin project",
    "authors": [
      "Jun Luo",
      "Shaojun Bai",
      "Yan-Zheng Bai",
      "Lin Cai",
      "Hao Dang",
      "Qijia Dong",
      "Hui-Zong Duan",
      "Yuanbo Du",
      "Lei Fan",
      "Xinju Fu",
      "Yong Gao",
      "Xingyu Gou",
      "Changlei Guo",
      "Wei Hong",
      "Bin Hu",
      "Heran Hu",
      "Ming Hu",
      "Yi-Ming Hu",
      "Fa Peng Huang",
      "Defeng Gu",
      "Xin Ji",
      "Yuan-Ze Jiang",
      "En-Kun Li",
      "Hongyin Li",
      "Ming Li",
      "Ming Li",
      "Yong Li",
      "Zhu Li",
      "Zizheng Li",
      "JunXiang Lian",
      "Yu-Rong Liang",
      "Xudong Lin",
      "Jianping Liu",
      "Lin-Xia Liu",
      "Kui Liu",
      "Li Liu",
      "Minghe Liu",
      "Qi Liu",
      "Yan-Chong Liu",
      "Yue Liu",
      "Peng-Shun Luo",
      "Yingxin Luo",
      "Yi-Qiu Ma",
      "Yun Ma",
      "Yunhe Meng",
      "Vadim Milyukov",
      "Jian-Guo Peng",
      "Konstantin Postnov",
      "Shao-Bo Qu",
      "Tilei Shan",
      "Cheng-Gang Shao",
      "Changfu Shi",
      "Pei-Yi Song",
      "Yunfei Song",
      "Wei Su",
      "Ding Yin Tan",
      "Shuping Tan",
      "Yu-Jie Tan",
      "Wenhai Tan",
      "Liangcheng Tu",
      "Cheng-Rui Wang",
      "Guoyong Wang",
      "Lijiao Wang",
      "Pan-Pan Wang",
      "Shun Wang",
      "Xiaoyong Wang",
      "Xudong Wang",
      "Yan Wang",
      "Ran Wei",
      "Shu-Chao Wu",
      "Jie Xu",
      "Zhi-Lin Xu",
      "Chao Xue",
      "Hao Yan",
      "Yong Yan",
      "Changpeng Yang",
      "Shanqing Yang",
      "Hsien-Chi Yeh",
      "Hang Yin",
      "Yelong Tong",
      "Jian-Bo Yu",
      "Wen-Hao Yuan",
      "Bu-Tian Zhang",
      "Dexuan Zhang",
      "Jian-dong Zhang",
      "Jie Zhang",
      "Lihua Zhang",
      "Xuefeng Zhang",
      "Guoying Zhao",
      "Liqian Zhao",
      "Xin Zhao",
      "An-Nan Zhou",
      "Hao Zhou",
      "Peng Zhou",
      "Yupeng Zhou",
      "Ze-Bing Zhou",
      "Fan Zhu",
      "Liang-Gui Zhu",
      "Lin Zhu",
      "Kui Zou",
      "Jianwei Mei"
    ],
    "abstract": "TianQin is a future space-based gravitational wave observatory targeting the\nfrequency window of $10^{-4}$ Hz $\\sim 1$ Hz. A large variety of gravitational\nwave sources are expected in this frequency band, including the merger of\nmassive black hole binaries, the inspiral of extreme/intermediate mass ratio\nsystems, stellar-mass black hole binaries, Galactic compact binaries, and so\non. TianQin will consist of three Earth orbiting satellites on nearly identical\norbits with orbital radii of about $10^5$ km. The satellites will form a normal\ntriangle constellation whose plane is nearly perpendicular to the ecliptic\nplane. The TianQin project has been progressing smoothly following the ``0123\"\ntechnology roadmap. In step ``0\", the TianQin laser ranging station has been\nconstructed and it has successfully ranged to all the five retro-reflectors on\nthe Moon. In step ``1\", the drag-free control technology has been tested and\ndemonstrated using the TianQin-1 satellite. In step ``2\", the inter-satellite\nlaser interferometry technology will be tested using the pair of TianQin-2\nsatellites. The TianQin-2 mission has been officially approved and the\nsatellites will be launched around 2026. In step ``3\", i.e., the TianQin-3\nmission, three identical satellites will be launched around 2035 to form the\nspace-based gravitational wave detector, TianQin, and to start gravitational\nwave detection in space.",
    "pdf_url": "http://arxiv.org/pdf/2502.11328v1",
    "published": "2025-02-17T00:50:16+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.IM"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.15776v1",
    "title": "Logic.py: Bridging the Gap between LLMs and Constraint Solvers",
    "authors": [
      "Pascal Kesseli",
      "Peter O'Hearn",
      "Ricardo Silveira Cabral"
    ],
    "abstract": "We present a novel approach to formalise and solve search-based problems\nusing large language models, which significantly improves upon previous\nstate-of-the-art results. We demonstrate the efficacy of this approach on the\nlogic puzzles benchmark ZebraLogicBench. Instead of letting the LLM attempt to\ndirectly solve the puzzles, our method prompts the model to formalise the\nproblem in a logic-focused domain-specific language (DSL) called Logic.py. This\nformalised representation is then solved using a constraint solver, leveraging\nthe strengths of both the language model and the solver. Our approach achieves\na remarkable 65% absolute improvement over the baseline performance of Llama\n3.1 70B on ZebraLogicBench, setting a new state-of-the-art with an accuracy of\nover 90%. This significant advancement demonstrates the potential of combining\nlanguage models with domain-specific languages and auxiliary tools on\ntraditionally challenging tasks for LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.15776v1",
    "published": "2025-02-17T00:36:54+00:00",
    "categories": [
      "cs.AI",
      "cs.LO",
      "68T27",
      "F.4.1; I.2.3; I.2.8"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11327v1",
    "title": "Valency, charge-transfer, and orbital-dependent correlation in bilayer nickelates Nd3Ni2O7",
    "authors": [
      "Daisuke Takegami",
      "Takaki Okauchi",
      "Edgar Abarca Morales",
      "Kouto Fujinuma",
      "Mizuki Furo",
      "Masato Yoshimura",
      "Ku-Ding Tsuei",
      "Grace A. Pan",
      "Dan Ferenc Segedin",
      "Qi Song",
      "Hanjong Paik",
      "Charles M. Brooks",
      "Julia A. Mundy",
      "Takashi Mizokawa",
      "Liu Hao Tjeng",
      "Berit H. Goodge",
      "Atsushi Hariki"
    ],
    "abstract": "We examine the bulk electronic structure of Nd3Ni2O7 using Ni 2p core-level\nhard x-ray photoemission spectroscopy combined with density functional theory +\ndynamical mean-field theory. Our results reveal a large deviation of the Ni 3d\noccupation from the formal Ni2.5+ valency, highlighting the importance of the\ncharge-transfer from oxygen ligands. We find that the dominant d8 configuration\nis accompanied by nearly equal contributions from d7 and d9 states, exhibiting\nan unusual valence state among Ni-based oxides. Finally, we discuss the Ni\ndx2-y2 and dz2 orbital-dependent hybridization, correlation and local spin\ndynamics.",
    "pdf_url": "http://arxiv.org/pdf/2502.11327v1",
    "published": "2025-02-17T00:34:53+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11326v2",
    "title": "Deep Learning of Proteins with Local and Global Regions of Disorder",
    "authors": [
      "Oufan Zhang",
      "Zi Hao Liu",
      "Julie D Forman-Kay",
      "Teresa Head-Gordon"
    ],
    "abstract": "Although machine learning has transformed protein structure prediction of\nfolded protein ground states with remarkable accuracy, intrinsically disordered\nproteins and regions (IDPs/IDRs) are defined by diverse and dynamical\nstructural ensembles that are predicted with low confidence by algorithms such\nas AlphaFold. We present a new machine learning method, IDPForge (Intrinsically\nDisordered Protein, FOlded and disordered Region GEnerator), that exploits a\ntransformer protein language diffusion model to create all-atom IDP ensembles\nand IDR disordered ensembles that maintains the folded domains. IDPForge does\nnot require sequence-specific training, back transformations from\ncoarse-grained representations, nor ensemble reweighting, as in general the\ncreated IDP/IDR conformational ensembles show good agreement with solution\nexperimental data, and options for biasing with experimental restraints are\nprovided if desired. We envision that IDPForge with these diverse capabilities\nwill facilitate integrative and structural studies for proteins that contain\nintrinsic disorder.",
    "pdf_url": "http://arxiv.org/pdf/2502.11326v2",
    "published": "2025-02-17T00:33:00+00:00",
    "categories": [
      "q-bio.BM"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2503.21783v1",
    "title": "On the additivity of n-multiplicative isomorphisms, derivations, and related maps in axial algebras",
    "authors": [
      "Daniel Eiti Nishida Kawai",
      "Henrique Guzzo Jr.",
      "Bruno Leonardo Macedo Ferreira"
    ],
    "abstract": "In this paper, we demonstrate that several classes of functions, specifically\nn-multiplicative isomorphisms, derivations, elementary maps, and Jordan\nelementary maps on a class of algebras that includes Jordan algebras with\nidempotents, J(a)-axial algebras and M(a,b)-axial algebras, are additive under\nappropriate conditions, which may be referred to as Martindale-type conditions.\nFurthermore, we answer the question left open in the recent article titled\n\"Multiplicative isomorphisms and derivations on axial algebra.\"",
    "pdf_url": "http://arxiv.org/pdf/2503.21783v1",
    "published": "2025-02-17T00:32:41+00:00",
    "categories": [
      "math.RA",
      "Primary: 17A36, 17C27, Secondary: 17A01, 17D99"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11325v2",
    "title": "The impact of wind accretion in Evolving Symbiotic Systems",
    "authors": [
      "R. F. Maldonado",
      "J. A. ToalÃ¡",
      "J. B. RodrÃ­guez-GonzÃ¡lez",
      "E. Tejeda"
    ],
    "abstract": "We investigate the impact of geometric corrections to the\nBondi-Hoyle-Lyttleton (BHL) accretion scheme applied to evolving symbiotic\nsystems. We model systems where 0.7 and 1 M$_\\odot$ white dwarfs accrete\nmaterial from Solar-like stars with initial masses of 1, 2, and 3 M$_\\odot$.\nThe primary star is evolved using the MESA stellar evolution code, while the\norbital dynamics of the system are calculated using REBOUND. The analysis\nfocuses on systems evolving through the red giant branch and the\nthermally-pulsating asymptotic giant branch phases that do not experience a\nWind Roche Lobe Overflow phase. We compare three scenarios: no accretion,\nstandard BHL accretion, and the improved wind accretion. The choice of\naccretion prescription critically influences the evolution of symbiotic\nsystems. Simulations using the modified model did not reach the Chandrasekhar\nlimit, suggesting that type Ia supernova progenitors require accretors\noriginating from ultra-massive WDs. In contrast, the standard BHL model\npredicts WD growth to this limit in compact systems. This discrepancy suggests\nthat population synthesis studies adopting the traditional BHL approach may\nyield inaccurate results. The revised model successfully reproduces the\naccretion properties of observed symbiotic systems and predicts transitions\nbetween different accretion regimes driven by donor mass-loss variability.\nThese results emphasize the need for updated wind accretion models to\naccurately describe the evolution of symbiotic binaries.",
    "pdf_url": "http://arxiv.org/pdf/2502.11325v2",
    "published": "2025-02-17T00:25:32+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11324v1",
    "title": "Robust High-Dimensional Mean Estimation With Low Data Size, an Empirical Study",
    "authors": [
      "Cullen Anderson",
      "Jeff M. Phillips"
    ],
    "abstract": "Robust statistics aims to compute quantities to represent data where a\nfraction of it may be arbitrarily corrupted. The most essential statistic is\nthe mean, and in recent years, there has been a flurry of theoretical\nadvancement for efficiently estimating the mean in high dimensions on corrupted\ndata. While several algorithms have been proposed that achieve near-optimal\nerror, they all rely on large data size requirements as a function of\ndimension. In this paper, we perform an extensive experimentation over various\nmean estimation techniques where data size might not meet this requirement due\nto the high-dimensional setting.",
    "pdf_url": "http://arxiv.org/pdf/2502.11324v1",
    "published": "2025-02-17T00:21:34+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.11323v1",
    "title": "A statistical theory of overfitting for imbalanced classification",
    "authors": [
      "Jingyang Lyu",
      "Kangjie Zhou",
      "Yiqiao Zhong"
    ],
    "abstract": "Classification with imbalanced data is a common challenge in data analysis,\nwhere certain classes (minority classes) account for a small fraction of the\ntraining data compared with other classes (majority classes). Classical\nstatistical theory based on large-sample asymptotics and finite-sample\ncorrections is often ineffective for high-dimensional data, leaving many\noverfitting phenomena in empirical machine learning unexplained.\n  In this paper, we develop a statistical theory for high-dimensional\nimbalanced classification by investigating support vector machines and logistic\nregression. We find that dimensionality induces truncation or skewing effects\non the logit distribution, which we characterize via a variational problem\nunder high-dimensional asymptotics. In particular, for linearly separable data\ngenerated from a two-component Gaussian mixture model, the logits from each\nclass follow a normal distribution $\\mathsf{N}(0,1)$ on the testing set, but\nasymptotically follow a rectified normal distribution $\\max\\{\\kappa,\n\\mathsf{N}(0,1)\\}$ on the training set -- which is a pervasive phenomenon we\nverified on tabular data, image data, and text data. This phenomenon explains\nwhy the minority class is more severely affected by overfitting. Further, we\nshow that margin rebalancing, which incorporates class sizes into the loss\nfunction, is crucial for mitigating the accuracy drop for the minority class.\nOur theory also provides insights into the effects of overfitting on\ncalibration and other uncertain quantification measures.",
    "pdf_url": "http://arxiv.org/pdf/2502.11323v1",
    "published": "2025-02-17T00:21:33+00:00",
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.ML",
      "stat.TH",
      "62J12"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2502.11322v3",
    "title": "Intersection of holonomy varieties of $CP^1$-structures",
    "authors": [
      "Shinpei Baba"
    ],
    "abstract": "Let $\\Sigma$ be a closed orientable surface of genus at least two, and let\n$X, Y$ be distinct marked Riemann surface structures on $\\Sigma$, possibly with\nopposite orientations.\n  In this paper, we show that there are (exactly) countably infinite pairs of\n${\\rm CP}^1$-structures on $X$ and on $Y$ sharing holonomy $\\pi_1(\\Sigma) \\to\n{\\rm PSL}_2 {\\rm C}$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11322v3",
    "published": "2025-02-17T00:21:27+00:00",
    "categories": [
      "math.GT",
      "math.CV",
      "math.DG"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11321v1",
    "title": "Advances in Bayesian Modeling: Applications and Methods",
    "authors": [
      "Yifei Yan",
      "Juan Sosa",
      "Carlos A. MartÃ­nez"
    ],
    "abstract": "This paper explores the versatility and depth of Bayesian modeling by\npresenting a comprehensive range of applications and methods, combining Markov\nchain Monte Carlo (MCMC) techniques and variational approximations. Covering\ntopics such as hierarchical modeling, spatial modeling, higher-order Markov\nchains, and Bayesian nonparametrics, the study emphasizes practical\nimplementations across diverse fields, including oceanography, climatology,\nepidemiology, astronomy, and financial analysis. The aim is to bridge\ntheoretical underpinnings with real-world applications, illustrating the\nformulation of Bayesian models, elicitation of priors, computational\nstrategies, and posterior and predictive analyses. By leveraging different\ncomputational methods, this paper provides insights into model fitting,\ngoodness-of-fit evaluation, and predictive accuracy, addressing computational\nefficiency and methodological challenges across various datasets and domains.",
    "pdf_url": "http://arxiv.org/pdf/2502.11321v1",
    "published": "2025-02-17T00:11:21+00:00",
    "categories": [
      "stat.AP",
      "stat.CO",
      "stat.ME"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11320v2",
    "title": "Heat kernels and Green functions for fractional SchrÃ¶dinger operators with confining potentials",
    "authors": [
      "Xin Chen",
      "Kamil Kaleta",
      "Jian Wang"
    ],
    "abstract": "We give two-sided, global (in all variables) estimates of the heat kernel and\nthe Green function of the fractional Schr\\\"odinger operator with a non-negative\nand locally bounded potential $V$ such that $V(x) \\to \\infty$ as $|x| \\to\n\\infty$. We assume that $V$ is comparable to a radial profile with the doubling\nproperty. Our bounds are sharp with respect to spatial variables and\nqualitatively sharp with respect to time. The methods we use combine\nprobabilistic and analytic arguments. They are based on the strong Markov\nproperty and the Feynman--Kac formula.",
    "pdf_url": "http://arxiv.org/pdf/2502.11320v2",
    "published": "2025-02-17T00:10:18+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11319v1",
    "title": "Diffuse-charge dynamics across a capacitive interface in a DC electric field",
    "authors": [
      "Shuozhen Zhao",
      "Bhavya Balu",
      "Zongxin Yu",
      "Michael J. Miksis",
      "Petia M. Vlahovska"
    ],
    "abstract": "Cells and cellular organelles are encapsulated by nanometrically thin\nmembranes whose main component is a lipid bilayer. In the presence of electric\nfields, the ion-impermeable lipid bilayer acts as a capacitor and supports a\npotential difference across the membrane. We analyze the charging dynamics of a\nplanar membrane separating bulk solutions with different electrolyte\nconcentrations upon the application of an applied uniform DC electric field.\nThe membrane is modeled as a zero-thickness capacitive interface. The evolution\nof the electric potential and ions distributions in the bulk are solved for\nusing the Poisson-Nernst-Planck (PNP) equations. Asymptotic solutions are\nderived in the limit of thin Debye layers and weak fields (compared to the\nthermal electric potential).",
    "pdf_url": "http://arxiv.org/pdf/2502.11319v1",
    "published": "2025-02-17T00:06:09+00:00",
    "categories": [
      "cond-mat.soft",
      "physics.bio-ph"
    ],
    "primary_category": "cond-mat.soft"
  }
]