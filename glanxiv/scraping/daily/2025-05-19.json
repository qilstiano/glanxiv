[
  {
    "id": "http://arxiv.org/abs/2505.13781v2",
    "title": "Rainbow triangles and the Erd≈ës-Hajnal problem in projective geometries",
    "authors": [
      "Carolyn Chun",
      "James Dylan Douthitt",
      "Wayne Ge",
      "Tony Huynh",
      "Matthew E. Kroeker",
      "Peter Nelson"
    ],
    "abstract": "We formulate a geometric version of the Erd\\H{o}s-Hajnal conjecture that\napplies to finite projective geometries rather than graphs, in both its usual\n'induced' form and the multicoloured form. The multicoloured conjecture states,\nroughly, that a colouring $c$ of the points of $\\mathsf{PG}(n-1,q)$ containing\nno copy of a fixed colouring $c_0$ of $\\mathsf{PG}(k-1,q)$ for small $k$ must\ncontain a subspace of dimension polynomial in $n$ that avoids some colour.\n  If $(k,q) = (2,2)$, then $c_0$ is a colouring of a three-element 'triangle',\nand there are three essentially different cases, all of which we resolve. We\nderive both the cases where $c_0$ assigns the same colour to two different\nelements from a recent breakthrough result in additive combinatorics due to\nKelley and Meka. We handle the case that $c_0$ is a 'rainbow' colouring by\nproving that rainbow-triangle-free colourings of projective geometries are\nexactly those that admit a certain decomposition into two-coloured pieces. This\nis closely analogous to a theorem of Gallai on rainbow-triangle-free coloured\ncomplete graphs. We also show that existing structure theorems resolve certain\ntwo-coloured cases where $(k,q) = (2,3)$, and $(k,q) = (3,2)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.13781v2",
    "published": "2025-05-19T23:57:20+00:00",
    "categories": [
      "math.CO",
      "05B35, 05C15"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13780v1",
    "title": "Extensions of Brown Hamiltonian-I. A high-accuracy model for von Zeipel-Lidov-Kozai oscillations",
    "authors": [
      "Hanlun Lei",
      "Evgeni Grishin"
    ],
    "abstract": "Triple systems with low hierarchical structure are common throughout the\nUniverse, including examples such as high-altitude lunar satellites influenced\nby the Earth, planetary satellites perturbed by the Sun, and stellar binaries\naffected by a supermassive black hole. In these systems, nonlinear\nperturbations are significant, making classical double-averaged models (even\nthose incorporating the Brown Hamiltonian correction) insufficient for\naccurately capturing long-term dynamics. To overcome this limitation, the\ncurrent study develops a high-precision dynamical model that incorporates the\nnonlinear effects of the quadrupole-order potential arising from both the inner\nand outer bodies, referred to as the extended Brown Hamiltonian model. This\nframework specifically expresses the Hamiltonian function and the\ntransformation between mean and osculating orbital elements in elegant, closed\nforms with respect to the eccentricities of the inner and outer orbits.\nPractical applications to Jupiter's irregular satellites show that the\nlong-term evolutions predicted by the extended Brown Hamiltonian model align\nwell with the results of direct N-body simulations. The developed Hamiltonian\noffers a fundamental dynamical model, which is particularly well suited for\ndescribing von Zeipel-Lidov-Kozai oscillations in low-hierarchy three-body\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13780v1",
    "published": "2025-05-19T23:55:19+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13779v1",
    "title": "Singularities in Calogero--Moser Varieties",
    "authors": [
      "Gwyn Bellamy",
      "Ruslan Maksimau",
      "Travis Schedler"
    ],
    "abstract": "In this article we describe completely the singularities appearing in\nCalogero--Moser varieties associated (at any parameter) to the wreath product\nsymplectic reflection groups. We do so by parameterizing the symplectic leaves\nin the variety, describing combinatorially the resulting closure relation and\ncomputing a transverse slice to each leaf. We also show that the normalization\nof the closure of each symplectic leaf is isomorphic to a Calogero--Moser\nvariety for an associated (explicit) subquotient of the symplectic reflection\ngroup. This confirms a conjecture of Bonnaf\\'e for these groups. We use the\nfact that the Calogero--Moser varieties associated to wreath products can be\nidentified with certain Nakajima quiver varieties. In particular, our result\nidentifying the normalization of the closure of each symplectic leaf with\nanother quiver variety holds for arbitrary quiver varieties.",
    "pdf_url": "http://arxiv.org/pdf/2505.13779v1",
    "published": "2025-05-19T23:42:36+00:00",
    "categories": [
      "math.AG",
      "math.RT",
      "math.SG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13778v1",
    "title": "CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs",
    "authors": [
      "Guoheng Sun",
      "Ziyao Wang",
      "Bowei Tian",
      "Meng Liu",
      "Zheyu Shen",
      "Shwai He",
      "Yexiao He",
      "Wanghao Ye",
      "Yiting Wang",
      "Ang Li"
    ],
    "abstract": "As post-training techniques evolve, large language models (LLMs) are\nincreasingly augmented with structured multi-step reasoning abilities, often\noptimized through reinforcement learning. These reasoning-enhanced models\noutperform standard LLMs on complex tasks and now underpin many commercial LLM\nAPIs. However, to protect proprietary behavior and reduce verbosity, providers\ntypically conceal the reasoning traces while returning only the final answer.\nThis opacity introduces a critical transparency gap: users are billed for\ninvisible reasoning tokens, which often account for the majority of the cost,\nyet have no means to verify their authenticity. This opens the door to token\ncount inflation, where providers may overreport token usage or inject\nsynthetic, low-effort tokens to inflate charges. To address this issue, we\npropose CoIn, a verification framework that audits both the quantity and\nsemantic validity of hidden tokens. CoIn constructs a verifiable hash tree from\ntoken embedding fingerprints to check token counts, and uses embedding-based\nrelevance matching to detect fabricated reasoning content. Experiments\ndemonstrate that CoIn, when deployed as a trusted third-party auditor, can\neffectively detect token count inflation with a success rate reaching up to\n94.7%, showing the strong ability to restore billing transparency in opaque LLM\nservices. The dataset and code are available at\nhttps://github.com/CASE-Lab-UMD/LLM-Auditing-CoIn.",
    "pdf_url": "http://arxiv.org/pdf/2505.13778v1",
    "published": "2025-05-19T23:39:23+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13777v1",
    "title": "Sat2Sound: A Unified Framework for Zero-Shot Soundscape Mapping",
    "authors": [
      "Subash Khanal",
      "Srikumar Sastry",
      "Aayush Dhakal",
      "Adeel Ahmad",
      "Nathan Jacobs"
    ],
    "abstract": "We present Sat2Sound, a multimodal representation learning framework for\nsoundscape mapping, designed to predict the distribution of sounds at any\nlocation on Earth. Existing methods for this task rely on satellite image and\npaired geotagged audio samples, which often fail to capture the diversity of\nsound sources at a given location. To address this limitation, we enhance\nexisting datasets by leveraging a Vision-Language Model (VLM) to generate\nsemantically rich soundscape descriptions for locations depicted in satellite\nimages. Our approach incorporates contrastive learning across audio, audio\ncaptions, satellite images, and satellite image captions. We hypothesize that\nthere is a fixed set of soundscape concepts shared across modalities. To this\nend, we learn a shared codebook of soundscape concepts and represent each\nsample as a weighted average of these concepts. Sat2Sound achieves\nstate-of-the-art performance in cross-modal retrieval between satellite image\nand audio on two datasets: GeoSound and SoundingEarth. Additionally, building\non Sat2Sound's ability to retrieve detailed soundscape captions, we introduce a\nnovel application: location-based soundscape synthesis, which enables immersive\nacoustic experiences. Our code and models will be publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.13777v1",
    "published": "2025-05-19T23:36:04+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13776v1",
    "title": "Convergence Analysis of an Adaptive Nonconforming FEM for Phase-Field Dependent Topology Optimization in Stokes Flow",
    "authors": [
      "Bangti Jin",
      "Jing Li",
      "Yifeng Xu",
      "Shengfeng Zhu"
    ],
    "abstract": "In this work, we develop an adaptive nonconforming finite element algorithm\nfor the numerical approximation of phase-field parameterized topology\noptimization governed by the Stokes system. We employ the conforming linear\nfinite element space to approximate the phase field, and the nonconforming\nlinear finite elements (Crouzeix-Raviart elements) and piecewise constants to\napproximate the velocity field and the pressure field, respectively. We\nestablish the convergence of the adaptive method, i.e., the sequence of\nminimizers contains a subsequence that converges to a solution of the\nfirst-order optimality system, and the associated subsequence of discrete\npressure fields also converges. The analysis relies crucially on a new discrete\ncompactness result of nonconforming linear finite elements over a sequence of\nadaptively generated meshes. We present numerical results for several examples\nto illustrate the performance of the algorithm, including a comparison with the\nuniform refinement strategy.",
    "pdf_url": "http://arxiv.org/pdf/2505.13776v1",
    "published": "2025-05-19T23:29:25+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.OC"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13775v2",
    "title": "Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens",
    "authors": [
      "Kaya Stechly",
      "Karthik Valmeekam",
      "Atharva Gundawar",
      "Vardhan Palod",
      "Subbarao Kambhampati"
    ],
    "abstract": "Recent impressive results from large reasoning models have been interpreted\nas a triumph of Chain of Thought (CoT), and especially of the process of\ntraining on CoTs sampled from base LLMs in order to help find new reasoning\npatterns. In this paper, we critically examine that interpretation by\ninvestigating how the semantics of intermediate tokens-often anthropomorphized\nas \"thoughts\" or reasoning traces and which are claimed to display behaviors\nlike backtracking, self-verification etc.-actually influence model performance.\nWe train transformer models on formally verifiable reasoning traces and\nsolutions, constraining both intermediate steps and final outputs to align with\nthose of a formal solver (in our case, A* search). By constructing a formal\ninterpreter of the semantics of our problems and intended algorithm, we\nsystematically evaluate not only solution accuracy but also the correctness of\nintermediate traces, thus allowing us to evaluate whether the latter causally\ninfluences the former. We notice that, despite significant improvements on the\nsolution-only baseline, models trained on entirely correct traces still produce\ninvalid reasoning traces when arriving at correct solutions. To further show\nthat trace accuracy is only loosely connected to solution accuracy, we then\ntrain models on noisy, corrupted traces which have no relation to the specific\nproblem each is paired with, and find that not only does performance remain\nlargely consistent with models trained on correct data, but in some cases can\nimprove upon it and generalize more robustly on out-of-distribution tasks.\nThese results challenge the assumption that intermediate tokens or \"Chains of\nThought\" induce predictable reasoning behaviors and caution against\nanthropomorphizing such outputs or over-interpreting them (despite their mostly\ncorrect forms) as evidence of human-like or algorithmic behaviors in language\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2505.13775v2",
    "published": "2025-05-19T23:29:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13774v2",
    "title": "Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models",
    "authors": [
      "Zidi Xiong",
      "Shan Chen",
      "Zhenting Qi",
      "Himabindu Lakkaraju"
    ],
    "abstract": "Large Reasoning Models (LRMs) have significantly enhanced their capabilities\nin complex problem-solving by introducing a thinking draft that enables\nmulti-path Chain-of-Thought explorations before producing final answers.\nEnsuring the faithfulness of these intermediate reasoning processes is crucial\nfor reliable monitoring, interpretation, and effective control. In this paper,\nwe propose a systematic counterfactual intervention framework to rigorously\nevaluate thinking draft faithfulness. Our approach focuses on two complementary\ndimensions: (1) Intra-Draft Faithfulness, which assesses whether individual\nreasoning steps causally influence subsequent steps and the final draft\nconclusion through counterfactual step insertions; and (2) Draft-to-Answer\nFaithfulness, which evaluates whether final answers are logically consistent\nwith and dependent on the thinking draft, by perturbing the draft's concluding\nlogic. We conduct extensive experiments across six state-of-the-art LRMs. Our\nfindings show that current LRMs demonstrate selective faithfulness to\nintermediate reasoning steps and frequently fail to faithfully align with the\ndraft conclusions. These results underscore the need for more faithful and\ninterpretable reasoning in advanced LRMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13774v2",
    "published": "2025-05-19T23:20:24+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13773v1",
    "title": "Model Cards for AI Teammates: Comparing Human-AI Team Familiarization Methods for High-Stakes Environments",
    "authors": [
      "Ryan Bowers",
      "Richard Agbeyibor",
      "Jack Kolb",
      "Karen Feigh"
    ],
    "abstract": "We compare three methods of familiarizing a human with an artificial\nintelligence (AI) teammate (\"agent\") prior to operation in a collaborative,\nfast-paced intelligence, surveillance, and reconnaissance (ISR) environment. In\na between-subjects user study (n=60), participants either read documentation\nabout the agent, trained alongside the agent prior to the mission, or were\ngiven no familiarization. Results showed that the most valuable information\nabout the agent included details of its decision-making algorithms and its\nrelative strengths and weaknesses compared to the human. This information\nallowed the familiarization groups to form sophisticated team strategies more\nquickly than the control group. Documentation-based familiarization led to the\nfastest adoption of these strategies, but also biased participants towards\nrisk-averse behavior that prevented high scores. Participants familiarized\nthrough direct interaction were able to infer much of the same information\nthrough observation, and were more willing to take risks and experiment with\ndifferent control modes, but reported weaker understanding of the agent's\ninternal processes. Significant differences were seen between individual\nparticipants' risk tolerance and methods of AI interaction, which should be\nconsidered when designing human-AI control interfaces. Based on our findings,\nwe recommend a human-AI team familiarization method that combines AI\ndocumentation, structured in-situ training, and exploratory interaction.",
    "pdf_url": "http://arxiv.org/pdf/2505.13773v1",
    "published": "2025-05-19T23:19:16+00:00",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13772v2",
    "title": "Krikri: Advancing Open Large Language Models for Greek",
    "authors": [
      "Dimitris Roussis",
      "Leon Voukoutis",
      "Georgios Paraskevopoulos",
      "Sokratis Sofianopoulos",
      "Prokopis Prokopidis",
      "Vassilis Papavasileiou",
      "Athanasios Katsamanis",
      "Stelios Piperidis",
      "Vassilis Katsouros"
    ],
    "abstract": "We introduce Llama-Krikri-8B, a cutting-edge Large Language Model tailored\nfor the Greek language, built on Meta's Llama 3.1-8B. Llama-Krikri-8B has been\nextensively trained on high-quality Greek data to ensure superior adaptation to\nlinguistic nuances. With 8 billion parameters, it offers advanced capabilities\nwhile maintaining efficient computational performance. Llama-Krikri-8B supports\nboth Modern Greek and English, and is also equipped to handle polytonic text\nand Ancient Greek. The chat version of Llama-Krikri-8B features a multi-stage\npost-training pipeline, utilizing both human and synthetic instruction and\npreference data, by applying techniques such as MAGPIE. In addition, for\nevaluation, we propose three novel public benchmarks for Greek. Our evaluation\non existing as well as the proposed benchmarks shows notable improvements over\ncomparable Greek and multilingual LLMs in both natural language understanding\nand generation as well as code generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13772v2",
    "published": "2025-05-19T23:18:27+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13771v1",
    "title": "Score-Based Training for Energy-Based TTS Models",
    "authors": [
      "Wanli Sun",
      "Anton Ragni"
    ],
    "abstract": "Noise contrastive estimation (NCE) is a popular method for training\nenergy-based models (EBM) with intractable normalisation terms. The key idea of\nNCE is to learn by comparing unnormalised log-likelihoods of the reference and\nnoisy samples, thus avoiding explicitly computing normalisation terms. However,\nNCE critically relies on the quality of noisy samples. Recently, sliced score\nmatching (SSM) has been popularised by closely related diffusion models (DM).\nUnlike NCE, SSM learns a gradient of log-likelihood, or score, by learning\ndistribution of its projections on randomly chosen directions. However, both\nNCE and SSM disregard the form of log-likelihood function, which is problematic\ngiven that EBMs and DMs make use of first-order optimisation during inference.\nThis paper proposes a new criterion that learns scores more suitable for\nfirst-order schemes. Experiments contrasts these approaches for training EBMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13771v1",
    "published": "2025-05-19T23:12:25+00:00",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.13770v1",
    "title": "Ice Cream Doesn't Cause Drowning: Benchmarking LLMs Against Statistical Pitfalls in Causal Inference",
    "authors": [
      "Jin Du",
      "Li Chen",
      "Xun Xian",
      "An Luo",
      "Fangqiao Tian",
      "Ganghua Wang",
      "Charles Doss",
      "Xiaotong Shen",
      "Jie Ding"
    ],
    "abstract": "Reliable causal inference is essential for making decisions in high-stakes\nareas like medicine, economics, and public policy. However, it remains unclear\nwhether large language models (LLMs) can handle rigorous and trustworthy\nstatistical causal inference. Current benchmarks usually involve simplified\ntasks. For example, these tasks might only ask LLMs to identify semantic causal\nrelationships or draw conclusions directly from raw data. As a result, models\nmay overlook important statistical pitfalls, such as Simpson's paradox or\nselection bias. This oversight limits the applicability of LLMs in the real\nworld. To address these limitations, we propose CausalPitfalls, a comprehensive\nbenchmark designed to rigorously evaluate the capability of LLMs in overcoming\ncommon causal inference pitfalls. Our benchmark features structured challenges\nacross multiple difficulty levels, each paired with grading rubrics. This\napproach allows us to quantitatively measure both causal reasoning capabilities\nand the reliability of LLMs' responses. We evaluate models using two protocols:\n(1) direct prompting, which assesses intrinsic causal reasoning, and (2)\ncode-assisted prompting, where models generate executable code for explicit\nstatistical analysis. Additionally, we validate the effectiveness of this judge\nby comparing its scoring with assessments from human experts. Our results\nreveal significant limitations in current LLMs when performing statistical\ncausal inference. The CausalPitfalls benchmark provides essential guidance and\nquantitative metrics to advance the development of trustworthy causal reasoning\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13770v1",
    "published": "2025-05-19T23:06:00+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ME",
      "stat.ML",
      "62-08, 68T50, 68T05, 68T01, 68T07, 62-07, 68U35, 62C99",
      "I.2.7; I.2.6; I.2.0; I.5.1; I.5.4; F.2.2; H.2.8; G.3"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13769v2",
    "title": "Finding Distributions that Differ, with False Discovery Rate Control",
    "authors": [
      "Yonghoon Lee",
      "Edgar Dobriban",
      "Eric Tchetgen Tchetgen"
    ],
    "abstract": "We consider the problem of comparing a reference distribution with several\nother distributions. Given a sample from both the reference and the comparison\ngroups, we aim to identify the comparison groups whose distributions differ\nfrom that of the reference group. Viewing this as a multiple testing problem,\nwe introduce a methodology that provides exact, distribution-free control of\nthe false discovery rate. To do so, we introduce the concept of batch conformal\np-values and demonstrate that they satisfy positive regression dependence\nacross the groups [Benjamini and Yekutieli, 2001], thereby enabling control of\nthe false discovery rate through the Benjamini-Hochberg procedure. The proof of\npositive regression dependence introduces a novel technique for the inductive\nconstruction of rank vectors with almost sure dominance under exchangeability.\nWe evaluate the performance of the proposed procedure through simulations,\nwhere, despite being distribution-free, in some cases they show performance\ncomparable to methods with knowledge of the data-generating normal\ndistribution; and further have more power than direct approaches based on\nconformal out-of-distribution detection. Further, we illustrate our methods on\na Hepatitis C treatment dataset, where they can identify patient groups with\nlarge treatment effects; and on the Current Population Survey dataset, where\nthey can identify sub-population with long work hours.",
    "pdf_url": "http://arxiv.org/pdf/2505.13769v2",
    "published": "2025-05-19T23:03:52+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.13768v3",
    "title": "Augmenting Online RL with Offline Data is All You Need: A Unified Hybrid RL Algorithm Design and Analysis",
    "authors": [
      "Ruiquan Huang",
      "Donghao Li",
      "Chengshuai Shi",
      "Cong Shen",
      "Jing Yang"
    ],
    "abstract": "This paper investigates a hybrid learning framework for reinforcement\nlearning (RL) in which the agent can leverage both an offline dataset and\nonline interactions to learn the optimal policy. We present a unified algorithm\nand analysis and show that augmenting confidence-based online RL algorithms\nwith the offline dataset outperforms any pure online or offline algorithm alone\nand achieves state-of-the-art results under two learning metrics, i.e.,\nsub-optimality gap and online learning regret. Specifically, we show that our\nalgorithm achieves a sub-optimality gap\n$\\tilde{O}(\\sqrt{1/(N_0/\\mathtt{C}(\\pi^*|\\rho)+N_1}) )$, where\n$\\mathtt{C}(\\pi^*|\\rho)$ is a new concentrability coefficient, $N_0$ and $N_1$\nare the numbers of offline and online samples, respectively. For regret\nminimization, we show that it achieves a constant $\\tilde{O}(\n\\sqrt{N_1/(N_0/\\mathtt{C}(\\pi^{-}|\\rho)+N_1)} )$ speed-up compared to pure\nonline learning, where $\\mathtt{C}(\\pi^-|\\rho)$ is the concentrability\ncoefficient over all sub-optimal policies. Our results also reveal an\ninteresting separation on the desired coverage properties of the offline\ndataset for sub-optimality gap minimization and regret minimization. We further\nvalidate our theoretical findings in several experiments in special RL models\nsuch as linear contextual bandits and Markov decision processes (MDPs).",
    "pdf_url": "http://arxiv.org/pdf/2505.13768v3",
    "published": "2025-05-19T22:58:54+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.11022v1",
    "title": "Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox",
    "authors": [
      "Shivani Shukla",
      "Himanshu Joshi",
      "Romilla Syed"
    ],
    "abstract": "The rapid adoption of Large Language Models(LLMs) for code generation has\ntransformed software development, yet little attention has been given to how\nsecurity vulnerabilities evolve through iterative LLM feedback. This paper\nanalyzes security degradation in AI-generated code through a controlled\nexperiment with 400 code samples across 40 rounds of \"improvements\" using four\ndistinct prompting strategies. Our findings show a 37.6% increase in critical\nvulnerabilities after just five iterations, with distinct vulnerability\npatterns emerging across different prompting approaches. This evidence\nchallenges the assumption that iterative LLM refinement improves code security\nand highlights the essential role of human expertise in the loop. We propose\npractical guidelines for developers to mitigate these risks, emphasizing the\nneed for robust human validation between LLM iterations to prevent the\nparadoxical introduction of new security issues during supposedly beneficial\ncode \"improvements\".",
    "pdf_url": "http://arxiv.org/pdf/2506.11022v1",
    "published": "2025-05-19T22:55:51+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13767v2",
    "title": "Dark States of Light and the Hidden Energy in Thermal Radiation Detection",
    "authors": [
      "Celso Jorge Villas-Boas",
      "Ciro Micheletti Diniz"
    ],
    "abstract": "We develop a quantum-optical framework demonstrating that thermal radiation\ncan confine a significant portion of its energy in dark collective modes --\nhighly entangled photon states that, despite their photonic nature, remain\ndecoupled from matter through standard electromagnetic interactions. In a\nsystem comprising $M$ thermal field modes, we show that only a fraction $1/M$\nof the total energy is accessible to matter, while the remaining $(M-1)/M$ is\nstored in dark states, rendering it undetectable by conventional\nelectromagnetic means. We also demonstrate that intensity measurements,\ncommonly used to estimate field energy, can be misleading due to collective\neffects that suppress or enhance light-matter coupling. To explore further this\nphenomenon, we analyze a cavity QED model enclosing a single dissipative atom\nand show that symmetry breaking in the atom-field interaction enables access to\nthe hidden energy stored in dark modes. While inconclusive, these findings\nsuggest that dark states of light may underlie certain unexplained energy\nphenomena, pointing to a possible microscopic mechanism based on the collective\nstructure of thermal radiation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13767v2",
    "published": "2025-05-19T22:52:50+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.03154v1",
    "title": "Modular Diffusion Policy Training: Decoupling and Recombining Guidance and Diffusion for Offline RL",
    "authors": [
      "Zhaoyang Chen",
      "Cody Fleming"
    ],
    "abstract": "Classifier free guidance has shown strong potential in diffusion-based\nreinforcement learning. However, existing methods rely on joint training of the\nguidance module and the diffusion model, which can be suboptimal during the\nearly stages when the guidance is inaccurate and provides noisy learning\nsignals. In offline RL, guidance depends solely on offline data: observations,\nactions, and rewards, and is independent of the policy module's behavior,\nsuggesting that joint training is not required. This paper proposes modular\ntraining methods that decouple the guidance module from the diffusion model,\nbased on three key findings:\n  Guidance Necessity: We explore how the effectiveness of guidance varies with\nthe training stage and algorithm choice, uncovering the roles of guidance and\ndiffusion. A lack of good guidance in the early stage presents an opportunity\nfor optimization.\n  Guidance-First Diffusion Training: We introduce a method where the guidance\nmodule is first trained independently as a value estimator, then frozen to\nguide the diffusion model using classifier-free reward guidance. This\nmodularization reduces memory usage, improves computational efficiency, and\nenhances both sample efficiency and final performance.\n  Cross-Module Transferability: Applying two independently trained guidance\nmodels, one during training and the other during inference, can significantly\nreduce normalized score variance (e.g., reducing IQR by 86%). We show that\nguidance modules trained with one algorithm (e.g., IDQL) can be directly reused\nwith another (e.g., DQL), with no additional training required, demonstrating\nbaseline-level performance as well as strong modularity and transferability.\n  We provide theoretical justification and empirical validation on bullet D4RL\nbenchmarks. Our findings suggest a new paradigm for offline RL: modular,\nreusable, and composable training pipelines.",
    "pdf_url": "http://arxiv.org/pdf/2506.03154v1",
    "published": "2025-05-19T22:51:58+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13766v1",
    "title": "Advancing Software Quality: A Standards-Focused Review of LLM-Based Assurance Techniques",
    "authors": [
      "Avinash Patil"
    ],
    "abstract": "Software Quality Assurance (SQA) is critical for delivering reliable, secure,\nand efficient software products. The Software Quality Assurance Process aims to\nprovide assurance that work products and processes comply with predefined\nprovisions and plans. Recent advancements in Large Language Models (LLMs)\npresent new opportunities to enhance existing SQA processes by automating tasks\nlike requirement analysis, code review, test generation, and compliance checks.\nSimultaneously, established standards such as ISO/IEC 12207, ISO/IEC 25010,\nISO/IEC 5055, ISO 9001/ISO/IEC 90003, CMMI, and TMM provide structured\nframeworks for ensuring robust quality practices. This paper surveys the\nintersection of LLM-based SQA methods and these recognized standards,\nhighlighting how AI-driven solutions can augment traditional approaches while\nmaintaining compliance and process maturity. We first review the foundational\nsoftware quality standards and the technical fundamentals of LLMs in software\nengineering. Next, we explore various LLM-based SQA applications, including\nrequirement validation, defect detection, test generation, and documentation\nmaintenance. We then map these applications to key software quality frameworks,\nillustrating how LLMs can address specific requirements and metrics within each\nstandard. Empirical case studies and open-source initiatives demonstrate the\npractical viability of these methods. At the same time, discussions on\nchallenges (e.g., data privacy, model bias, explainability) underscore the need\nfor deliberate governance and auditing. Finally, we propose future directions\nencompassing adaptive learning, privacy-focused deployments, multimodal\nanalysis, and evolving standards for AI-driven software quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.13766v1",
    "published": "2025-05-19T22:49:30+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13765v1",
    "title": "WIND: Accelerated RNN-T Decoding with Windowed Inference for Non-blank Detection",
    "authors": [
      "Hainan Xu",
      "Vladimir Bataev",
      "Lilit Grigoryan",
      "Boris Ginsburg"
    ],
    "abstract": "We propose Windowed Inference for Non-blank Detection (WIND), a novel\nstrategy that significantly accelerates RNN-T inference without compromising\nmodel accuracy. During model inference, instead of processing frames\nsequentially, WIND processes multiple frames simultaneously within a window in\nparallel, allowing the model to quickly locate non-blank predictions during\ndecoding, resulting in significant speed-ups. We implement WIND for greedy\ndecoding, batched greedy decoding with label-looping techniques, and also\npropose a novel beam-search decoding method. Experiments on multiple datasets\nwith different conditions show that our method, when operating in greedy modes,\nspeeds up as much as 2.4X compared to the baseline sequential approach while\nmaintaining identical Word Error Rate (WER) performance. Our beam-search\nalgorithm achieves slightly better accuracy than alternative methods, with\nsignificantly improved speed. We will open-source our WIND implementation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13765v1",
    "published": "2025-05-19T22:48:01+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13764v2",
    "title": "Incremental Firmware Update Over-the-Air for Low-Power IoT Devices over LoRaWAN",
    "authors": [
      "Andrea De Simone",
      "Giovanna Turvani",
      "Fabrizio Riente"
    ],
    "abstract": "Efficiently supporting remote firmware updates in Internet of Things (IoT)\ndevices remains a significant challenge due to the limitations of many IoT\ncommunication protocols, which often make it impractical to transmit full\nfirmware images. Techniques such as firmware partitioning have been introduced\nto mitigate this issue, but they frequently fall short, especially in\nbattery-powered systems where time and energy constraints are critical. As a\nresult, physical maintenance interventions are still commonly required, which\nis costly and inconvenient in large-scale deployments. In this work, we present\na lightweight and innovative method that addresses this challenge by generating\nhighly compact delta patches, enabling firmware reconstruction directly on the\ndevice. Our algorithm is specifically optimized for low-power devices,\nminimizing both memory usage and computational overhead. Compared to existing\nsolutions, our approach significantly reduces the data volume needed for\nupdates while maintaining performance comparable to more complex alternatives.\nExperimental evaluations confirm that our method yields substantial time and\nenergy savings, making it particularly well-suited for battery-powered IoT\nnodes. Although our implementation targets the LoRaWAN protocol, the approach\nis flexible and can be adapted to other IoT communication technologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.13764v2",
    "published": "2025-05-19T22:34:05+00:00",
    "categories": [
      "eess.SY",
      "cs.NI",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13763v1",
    "title": "Language Models Are Capable of Metacognitive Monitoring and Control of Their Internal Activations",
    "authors": [
      "Li Ji-An",
      "Hua-Dong Xiong",
      "Robert C. Wilson",
      "Marcelo G. Mattar",
      "Marcus K. Benna"
    ],
    "abstract": "Large language models (LLMs) can sometimes report the strategies they\nactually use to solve tasks, but they can also fail to do so. This suggests\nsome degree of metacognition -- the capacity to monitor one's own cognitive\nprocesses for subsequent reporting and self-control. Metacognitive abilities\nenhance AI capabilities but raise safety concerns, as models might obscure\ntheir internal processes to evade neural-activation-based oversight mechanisms\ndesigned to detect harmful behaviors. Given society's increased reliance on\nthese models, it is critical that we understand the limits of their\nmetacognitive abilities, particularly their ability to monitor their internal\nactivations. To address this, we introduce a neuroscience-inspired\nneurofeedback paradigm designed to quantify the ability of LLMs to explicitly\nreport and control their activation patterns. By presenting models with\nsentence-label pairs where labels correspond to sentence-elicited internal\nactivations along specific directions in the neural representation space, we\ndemonstrate that LLMs can learn to report and control these activations. The\nperformance varies with several factors: the number of example pairs provided,\nthe semantic interpretability of the target neural direction, and the variance\nexplained by that direction. These results reveal a \"metacognitive space\" with\ndimensionality much lower than the model's neural space, suggesting LLMs can\nmonitor only a subset of their neural mechanisms. Our findings provide\nempirical evidence quantifying metacognitive capabilities in LLMs, with\nsignificant implications for AI safety.",
    "pdf_url": "http://arxiv.org/pdf/2505.13763v1",
    "published": "2025-05-19T22:32:25+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13762v2",
    "title": "From Structural Design to Dynamics Modeling: Control-Oriented Development of a 3-RRR Parallel Ankle Rehabilitation Robot",
    "authors": [
      "Siyuan Zhang",
      "Yufei Zhang",
      "Junlin Lyu",
      "Sunil K. Agrawal"
    ],
    "abstract": "This paper presents the development of a wearable ankle rehabilitation robot\nbased on a 3-RRR spherical parallel mechanism (SPM) to support multi-DOF\nrecovery through pitch, roll, and yaw motions. The system features a compact,\nergonomic structure designed for comfort, safety, and compatibility with ankle\nbiomechanics. A complete design-to-dynamics pipeline has been implemented,\nincluding structural design, kinematic modeling for motion planning, and\nLagrangian-based dynamic modeling for torque estimation and simulation\nanalysis. Preliminary simulations verify stable joint coordination and smooth\nmotion tracking under representative rehabilitation trajectories. The control\nframework is currently being developed to enhance responsiveness across the\nworkspace. Future work will focus on integrating personalized modeling and\nadaptive strategies to address kinematic singularities through model based\ncontrol. This work establishes a foundational platform for intelligent,\npersonalized ankle rehabilitation, enabling both static training and potential\nextension to gait-phase-timed assistance.",
    "pdf_url": "http://arxiv.org/pdf/2505.13762v2",
    "published": "2025-05-19T22:28:05+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13761v2",
    "title": "Simulation Agent: A Framework for Integrating Simulation and Large Language Models for Enhanced Decision-Making",
    "authors": [
      "Jacob Kleiman",
      "Kevin Frank",
      "Joseph Voyles",
      "Sindy Campagna"
    ],
    "abstract": "Simulations, although powerful in accurately replicating real-world systems,\noften remain inaccessible to non-technical users due to their complexity.\nConversely, large language models (LLMs) provide intuitive, language-based\ninteractions but can lack the structured, causal understanding required to\nreliably model complex real-world dynamics. We introduce our simulation agent\nframework, a novel approach that integrates the strengths of both simulation\nmodels and LLMs. This framework helps empower users by leveraging the\nconversational capabilities of LLMs to interact seamlessly with sophisticated\nsimulation systems, while simultaneously utilizing the simulations to ground\nthe LLMs in accurate and structured representations of real-world phenomena.\nThis integrated approach helps provide a robust and generalizable foundation\nfor empirical validation and offers broad applicability across diverse domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.13761v2",
    "published": "2025-05-19T22:27:18+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13760v1",
    "title": "Consistency Conditions for Differentiable Surrogate Losses",
    "authors": [
      "Drona Khurana",
      "Anish Thilagar",
      "Dhamma Kimpara",
      "Rafael Frongillo"
    ],
    "abstract": "The statistical consistency of surrogate losses for discrete prediction tasks\nis often checked via the condition of calibration. However, directly verifying\ncalibration can be arduous. Recent work shows that for polyhedral surrogates, a\nless arduous condition, indirect elicitation (IE), is still equivalent to\ncalibration. We give the first results of this type for non-polyhedral\nsurrogates, specifically the class of convex differentiable losses. We first\nprove that under mild conditions, IE and calibration are equivalent for\none-dimensional losses in this class. We construct a counter-example that shows\nthat this equivalence fails in higher dimensions. This motivates the\nintroduction of strong IE, a strengthened form of IE that is equally easy to\nverify. We establish that strong IE implies calibration for differentiable\nsurrogates and is both necessary and sufficient for strongly convex,\ndifferentiable surrogates. Finally, we apply these results to a range of\nproblems to demonstrate the power of IE and strong IE for designing and\nanalyzing consistent differentiable surrogates.",
    "pdf_url": "http://arxiv.org/pdf/2505.13760v1",
    "published": "2025-05-19T22:17:36+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13759v1",
    "title": "Enhanced ammonia electro-oxidation reaction on platinum-iron oxide catalyst assisted by MagnetoElectroCatalysis",
    "authors": [
      "Caio Machado Fernandes",
      "Eduardo M. Rodrigues",
      "Odivaldo C. Alves",
      "Flavio Garcia",
      "Yutao Xing",
      "Mauro C. Santos",
      "Julio Cesar M. Silva"
    ],
    "abstract": "Ammonia poses significant environmental challenges due to its role in water\npollution, contributing to eutrophication and several detrimental environmental\nand ecological issues. Addressing the efficient removal or conversion of\nammonia is, therefore, critical. Among various methods, the ammonia\nelectro-oxidation reaction stands out due to its potential for direct energy\nconversion and environment remediation. Here, we synthesize platinum-iron oxide\nmagnetic nanoparticles (Pt-MNP) as electrocatalysts and apply an alternating\nmagnetic field (AMF) to enhance their activity.. The AMF generates localized\nheat via N\\'eel relaxation, accelerating ammonia oxidation kinetics at the\ncatalytic surface.. Compared to conventional electro-oxidation methods, this\ntechnique demonstrates superior efficiency and stability, offering a promising\nalternative for ammonia treatment. This work uses the concept of\nMagnetoElectroCatalysis, showcasing the synergy between magnetic fields and the\nelectrochemical process, leveraging the AMF to induce localized heating within\nthe nanocatalyst, thereby improving its catalytic activity as shown in cyclic\nvoltammetry and chronoamperometry experiments. By combining nanocatalyst design\nwith innovative AMF application, this study provides a new avenue for enhancing\nelectrochemical reactions, with broad implications for environmental\nremediation and sustainable energy solutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13759v1",
    "published": "2025-05-19T22:16:00+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13758v1",
    "title": "BeamClean: Language Aware Embedding Reconstruction",
    "authors": [
      "Kaan Kale",
      "Kyle Mylonakis",
      "Jay Roberts",
      "Sidhartha Roy"
    ],
    "abstract": "In this work, we consider an inversion attack on the obfuscated input\nembeddings sent to a language model on a server, where the adversary has no\naccess to the language model or the obfuscation mechanism and sees only the\nobfuscated embeddings along with the model's embedding table. We propose\nBeamClean, an inversion attack that jointly estimates the noise parameters and\ndecodes token sequences by integrating a language-model prior. Against\nLaplacian and Gaussian obfuscation mechanisms, BeamClean always surpasses naive\ndistance-based attacks. This work highlights the necessity for and robustness\nof more advanced learned, input-dependent methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13758v1",
    "published": "2025-05-19T22:14:22+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13757v2",
    "title": "CoRank: LLM-Based Compact Reranking with Document Features for Scientific Retrieval",
    "authors": [
      "Runchu Tian",
      "Xueqiang Xu",
      "Bowen Jin",
      "SeongKu Kang",
      "Jiawei Han"
    ],
    "abstract": "Scientific retrieval is essential for advancing scientific knowledge\ndiscovery. Within this process, document reranking plays a critical role in\nrefining first-stage retrieval results. However, standard LLM listwise\nreranking faces challenges in the scientific domain. First-stage retrieval is\noften suboptimal in the scientific domain, so relevant documents are ranked\nlower. Meanwhile, conventional listwise reranking places the full text of\ncandidates into the context window, limiting the number of candidates that can\nbe considered. As a result, many relevant documents are excluded before\nreranking, constraining overall retrieval performance. To address these\nchallenges, we explore semantic-feature-based compact document representations\n(e.g., categories, sections, and keywords) and propose CoRank, a training-free,\nmodel-agnostic reranking framework for scientific retrieval. It presents a\nthree-stage solution: (i) offline extraction of document features, (ii)\ncoarse-grained reranking using these compact representations, and (iii)\nfine-grained reranking on full texts of the top candidates from (ii). This\nintegrated process addresses suboptimal first-stage retrieval: Compact\nrepresentations allow more documents to fit within the context window,\nimproving candidate set coverage, while the final fine-grained ranking ensures\na more accurate ordering. Experiments on 5 academic retrieval datasets show\nthat CoRank significantly improves reranking performance across different LLM\nbackbones (average nDCG@10 from 50.6 to 55.5). Overall, these results\nunderscore the synergistic interaction between information extraction and\ninformation retrieval, demonstrating how structured semantic features can\nenhance reranking in the scientific domain.",
    "pdf_url": "http://arxiv.org/pdf/2505.13757v2",
    "published": "2025-05-19T22:10:27+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13756v1",
    "title": "OGHReS: Star formation in the Outer Galaxy II ($\\ell = 180^\\circ$-$280^\\circ$)",
    "authors": [
      "J. S. Urquhart",
      "C. Koenig",
      "D. Colombo",
      "A. Karska",
      "A. Giannetti",
      "T. J. T. Moore",
      "A. Y. Yang",
      "F. Wyrowski",
      "Y. Sun",
      "Z. Jiang",
      "K. R. Neralwar",
      "D. Eden",
      "I. Grozdanova",
      "S. Neupane",
      "M. Figueira",
      "E. Dann",
      "V.",
      "S. Veena",
      "W. -J. Kim",
      "S. Leurini",
      "J. Brand",
      "M. -Y. Lee"
    ],
    "abstract": "The Outer Galaxy High-Resolution Survey (OGHReS) covers 100 square degrees\n($180^\\circ < \\ell < 280^\\circ$) in the (2--1) transitions of three\nCO-isotopologues. We use the spectra to refine the velocities and physical\nproperties to 6706 \\higal\\ clumps located in the OGHReS region. In a previous\npaper, we analysed 3584 clumps between $\\ell = 250^\\circ$ and $280^\\circ$.\nHere, we cover a further 3122 clumps ($180^\\circ < \\ell < 250^\\circ$) and\ndetermine reliable velocities for \\withVLSR\\ of these, finding good agreement\nwith the previously assigned velocities ($\\sim$80 percent within 5 \\kms). We\nupdate velocities for 288 clumps and provide new values for an additional 411.\nCombining these with the previous results, we have velocities and physical\nproperties for 6193 clumps (92.3 percent). The \\allnonDetections\\\nnon-detections are low surface density clumps or likely contamination by\nevolved stars and galaxies. Key findings: i) improved correlation between\nclumps and spiral arm loci, and the discovery of clumps beyond the outer arm\nsupports the existence of a new spiral structure; ii) decreasing trend in the\n$L/M$-ratio consistent with less high-mass star formation in the outer Galaxy;\niii) increase in the star formation fraction (SFF) in the outer Galaxy,\nsuggesting that more clumps are forming stars despite their lower mass; iv)\ndiscrepancies in velocity assignments across different surveys that could\naffect $\\sim$10000 clumps, especially in the fourth quadrant.",
    "pdf_url": "http://arxiv.org/pdf/2505.13756v1",
    "published": "2025-05-19T22:03:43+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13755v1",
    "title": "Panda: A pretrained forecast model for universal representation of chaotic dynamics",
    "authors": [
      "Jeffrey Lai",
      "Anthony Bao",
      "William Gilpin"
    ],
    "abstract": "Chaotic systems are intrinsically sensitive to small errors, challenging\nefforts to construct predictive data-driven models of real-world dynamical\nsystems such as fluid flows or neuronal activity. Prior efforts comprise either\nspecialized models trained separately on individual time series, or foundation\nmodels trained on vast time series databases with little underlying dynamical\nstructure. Motivated by dynamical systems theory, we present Panda, Patched\nAttention for Nonlinear DynAmics. We train Panda on a novel synthetic,\nextensible dataset of $2 \\times 10^4$ chaotic dynamical systems that we\ndiscover using an evolutionary algorithm. Trained purely on simulated data,\nPanda exhibits emergent properties: zero-shot forecasting of unseen real world\nchaotic systems, and nonlinear resonance patterns in cross-channel attention\nheads. Despite having been trained only on low-dimensional ordinary\ndifferential equations, Panda spontaneously develops the ability to predict\npartial differential equations without retraining. We demonstrate a neural\nscaling law for differential equations, underscoring the potential of\npretrained models for probing abstract mathematical domains like nonlinear\ndynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.13755v1",
    "published": "2025-05-19T21:59:19+00:00",
    "categories": [
      "cs.LG",
      "cs.NE",
      "nlin.CD",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13754v2",
    "title": "Unsupervised Learning of Local Updates for Maximum Independent Set in Dynamic Graphs",
    "authors": [
      "Devendra Parkar",
      "Anya Chaturvedi",
      "Joshua J. Daymude"
    ],
    "abstract": "We present the first unsupervised learning model for finding Maximum\nIndependent Sets (MaxIS) in dynamic graphs where edges change over time. Our\nmethod combines structural learning from graph neural networks (GNNs) with a\nlearned distributed update mechanism that, given an edge addition or deletion\nevent, modifies nodes' internal memories and infers their MaxIS membership in a\nsingle, parallel step. We parameterize our model by the update mechanism's\nradius and investigate the resulting performance-runtime tradeoffs for various\ndynamic graph topologies. We evaluate our model against a mixed integer\nprogramming solver and the state-of-the-art learning-based methods for MaxIS on\nstatic graphs (ICML 2020; NeurIPS 2020, 2023). Across synthetic and empirical\ndynamic graphs of 50-1,000 nodes, our model achieves competitive approximation\nratios with excellent scalability; on large graphs, it significantly\noutperforms the state-of-the-art learning methods in solution quality, runtime,\nand memory usage. When generalizing to graphs of 10,000 nodes (100x larger than\nthe ones used for training), our model produces MaxIS solutions 1.05-1.18x\nlarger than any other learning method, even while maintaining competitive\nruntimes.",
    "pdf_url": "http://arxiv.org/pdf/2505.13754v2",
    "published": "2025-05-19T21:58:22+00:00",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13753v1",
    "title": "Analysis of COVID-19 Infection Dynamics: Extended SIR Model Approach",
    "authors": [
      "Caleb Traxler",
      "Minh Ton",
      "Nameer Ahmed",
      "Sasha Prostota",
      "Annie Cheng"
    ],
    "abstract": "This paper presents a detailed mathematical investigation into the dynamics\nof COVID-19 infections through extended Susceptible-Infected-Recovered (SIR)\nand Susceptible-Exposed-Infected-Recovered (SEIR) epidemiological models. By\nincorporating demographic factors such as birth and death rates, we enhance the\nclassical Kermack-McKendrick framework to realistically represent long-term\ndisease progression. Using empirical data from four COVID-19 epidemic waves in\nOrange County, California, between January 2020 and March 2022, we estimate key\nparameters and perform stability and bifurcation analyses. Our results\nconsistently indicate endemic states characterized by stable spiral equilibria\ndue to reproduction numbers (R0) exceeding unity across all waves.\nAdditionally, the inclusion of vaccination demonstrates the potential to reduce\nthe effective reproduction number below one, shifting the system towards a\nstable disease-free equilibrium. Our analysis underscores the critical role of\nlatency periods in shaping epidemic dynamics and highlights actionable insights\nfor public health interventions aimed at COVID-19 control and eventual\neradication.",
    "pdf_url": "http://arxiv.org/pdf/2505.13753v1",
    "published": "2025-05-19T21:56:32+00:00",
    "categories": [
      "q-bio.PE",
      "math.DS",
      "physics.soc-ph"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13752v1",
    "title": "Tracking Reentries of Starlink Satellites During the Rising Phase of Solar Cycle 25",
    "authors": [
      "Denny M. Oliveira",
      "Eftyhia Zesta",
      "Katherine Garcia-Sage"
    ],
    "abstract": "The exponential increase of low-Earth orbit (LEO) satellites in the past 5\nyears has brought into intense focus the need for reliable monitoring and\nreentry prediction to safeguard from space collisions and ground debris\nimpacts. However, LEO satellites fly within the upper atmosphere region that\nexerts significant drag forces to their orbits, reducing their lifetimes, and\nincreasing collision risks during dynamic events, like geomagnetic storms. Such\nconditions can become more severe during geomagnetic storms, particularly\nduring extreme events. In this work, we use two-line element (TLE) satellite\ntracking data to investigate geomagnetic activity effects on the reentries of\n523 Starlink satellites from 2020 to 2024. This period coincides with the\nrising phase of solar cycle 25, which has shown itself to be more intense than\nthe previous solar cycle. We derive satellite altitudes and velocities from TLE\nfiles and perform a superposed epoch analysis, the first with hundreds of\nsimilar satellites. Even with limitedly accurate TLE data, our results\nindisputably show that satellites reenter faster with higher geomagnetic\nactivity. This is explained by the fastest orbital decay rates (in km/day) of\nthe satellites caused by increased drag forces. We also find that prediction\nerrors, defined as the difference between the epochs of actual reentries and\npredicted reentries at reference altitudes, increase with geomagnetic activity.\nAs a result, we clearly show that the intense solar activity of the current\nsolar cycle has already had significant impacts on Starlink reentries. This is\na very exciting time in satellite orbital drag research, since the number of\nsatellites in LEO and solar activity are the highest ever observed in human\nhistory.",
    "pdf_url": "http://arxiv.org/pdf/2505.13752v1",
    "published": "2025-05-19T21:56:20+00:00",
    "categories": [
      "physics.space-ph",
      "astro-ph.EP",
      "astro-ph.IM"
    ],
    "primary_category": "physics.space-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13751v1",
    "title": "Multiple Proposer Transaction Fee Mechanism Design: Robust Incentives Against Censorship and Bribery",
    "authors": [
      "Aikaterini-Panagiota Stouka",
      "Julian Ma",
      "Thomas Thiery"
    ],
    "abstract": "Censorship resistance is one of the core value proposition of blockchains. A\nrecurring design pattern aimed at providing censorship resistance is enabling\nmultiple proposers to contribute inputs into block construction. Notably,\nFork-Choice Enforced Inclusion Lists (FOCIL) is proposed to be included in\nEthereum. However, the current proposal relies on altruistic behavior, without\na Transaction Fee Mechanism (TFM). This study aims to address this gap by\nexploring how multiple proposers should be rewarded to incentivize censorship\nresistance. The main contribution of this work is the identification of TFMs\nthat ensure censorship resistance under bribery attacks, while also satisfying\nthe incentive compatibility properties of EIP-1559. We provide a concrete\npayment mechanism for FOCIL, along with generalizable contributions to the\nliterature by analyzing 1) incentive compatibility of TFMs in the presence of a\nbribing adversary, 2) TFMs in protocols with multiple phases of transaction\ninclusion, and 3) TFMs of protocols in which parties are uncertain about the\nbehavior and the possible bribe of others.",
    "pdf_url": "http://arxiv.org/pdf/2505.13751v1",
    "published": "2025-05-19T21:53:58+00:00",
    "categories": [
      "cs.GT",
      "cs.CR"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.21511v1",
    "title": "Geological CO$_2$ Storage in Poland: Review of Sequestration Potential, Policy Development, and Socio-Economic Factors",
    "authors": [
      "Mohammad Nooraiepour",
      "Karol M. DƒÖbrowski",
      "Mohammad Masoudi",
      "Szymon Kuczy≈Ñski",
      "Zezhang Song",
      "Ane Elisabet Lothe",
      "Helge Hellevang"
    ],
    "abstract": "Poland's coal-reliant economy faces challenges in meeting European Union\nclimate mandates. Carbon Capture and Storage (CCS) is pivotal for decarbonizing\nhigh-emission sectors (e.g., cement, chemicals, refineries, and steel),\nenabling substantial CO$_2$ emission reductions while sustaining industrial\ncompetitiveness. This multidisciplinary review assesses Poland's CO$_2$ storage\npotential, integrating geological, regulatory, and socio-economic analyses to\nevaluate large-scale CCS feasibility. Onshore saline aquifers alongside\ndepleted hydrocarbon fields offer significant storage potential, with offshore\nBaltic Basin sites constrained by logistical and environmental regulations,\nincluding the Helsinki Convention. Evolving policy and regulatory framework is\nevaluated, including recent amendments to the Geological and Mining Law that\nmay facilitate onshore CO$_2$ storage near industrial hubs. We analyze regional\nand data compilation constraints, infrastructure readiness, and the integration\nof the CCUS value chain. It was found that current storage assessments face\nchallenges, including sparse data, restricted research access, and limited\nindustry-academia collaboration, which impede maturing basin-scale and\nsite-specific analyses to higher storage readiness levels. These gaps introduce\nsignificant uncertainty and undermine reliability, which limits informed\nbusiness decisions. Socio-economic barriers, including public skepticism,\nfinancial uncertainties, and regulatory gaps, hinder large-scale CCS\ndeployment, necessitating transparent engagement. A framework for building\npublic trust through transparent governance, inclusive community engagement,\nand proactive risk communication was suggested to build trust and foster CCS\nacceptance in Poland. Proactive stakeholder involvement and transparent risk\ncommunication, particularly in coal-dependent communities, are critical.",
    "pdf_url": "http://arxiv.org/pdf/2505.21511v1",
    "published": "2025-05-19T21:53:29+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13750v1",
    "title": "Eudoxia: a FaaS scheduling simulator for the composable lakehouse",
    "authors": [
      "Tapan Srivastava",
      "Jacopo Tagliabue",
      "Ciro Greco"
    ],
    "abstract": "Due to the variety of its target use cases and the large API surface area to\ncover, a data lakehouse (DLH) is a natural candidate for a composable data\nsystem. Bauplan is a composable DLH built on \"spare data parts\" and a unified\nFunction-as-a-Service (FaaS) runtime for SQL queries and Python pipelines.\nWhile FaaS simplifies both building and using the system, it introduces novel\nchallenges in scheduling and optimization of data workloads. In this work,\nstarting from the programming model of the composable DLH, we characterize the\nunderlying scheduling problem and motivate simulations as an effective tools to\niterate on the DLH. We then introduce and release to the community Eudoxia, a\ndeterministic simulator for scheduling data workloads as cloud functions. We\nshow that Eudoxia can simulate a wide range of workloads and enables highly\ncustomizable user implementations of scheduling algorithms, providing a cheap\nmechanism for developers to evaluate different scheduling algorithms against\ntheir infrastructure.",
    "pdf_url": "http://arxiv.org/pdf/2505.13750v1",
    "published": "2025-05-19T21:53:13+00:00",
    "categories": [
      "cs.DB",
      "cs.DC"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.13749v1",
    "title": "A Complexity Dichotomy for Semilinear Target Sets in Automata with One Counter",
    "authors": [
      "Yousef Shakiba",
      "Henry Sinclair-Banks",
      "Georg Zetzsche"
    ],
    "abstract": "In many kinds of infinite-state systems, the coverability problem has\nsignificantly lower complexity than the reachability problem. In order to\ndelineate the border of computational hardness between coverability and\nreachability, we propose to place these problems in a more general context,\nwhich makes it possible to prove complexity dichotomies.\n  The more general setting arises as follows. We note that for coverability, we\nare given a vector $t$ and are asked if there is a reachable vector $x$\nsatisfying the relation $x\\ge t$. For reachability, we want to satisfy the\nrelation $x=t$. In the more general setting, there is a Presburger formula\n$\\varphi(t,x)$, and we are given $t$ and are asked if there is a reachable $x$\nwith $\\varphi(t,x)$.\n  We study this setting for systems with one counter and binary updates: (i)\ninteger VASS, (ii) Parikh automata, and (i) standard (non-negative) VASS. In\neach of these cases, reachability is NP-complete, but coverability is known to\nbe in polynomial time. Our main results are three dichotomy theorems, one for\neach of the cases (i)--(iii). In each case, we show that for every $\\varphi$,\nthe problem is either NP-complete or belongs to $\\mathsf{AC}^1$, a circuit\ncomplexity class within polynomial time. We also show that it is decidable on\nwhich side of the dichotomy a given formula falls.",
    "pdf_url": "http://arxiv.org/pdf/2505.13749v1",
    "published": "2025-05-19T21:52:56+00:00",
    "categories": [
      "cs.FL",
      "cs.CC",
      "cs.LO"
    ],
    "primary_category": "cs.FL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13748v1",
    "title": "ReBaCCA-ss: Relevance-Balanced Continuum Correlation Analysis with Smoothing and Surrogating for Quantifying Similarity Between Population Spiking Activities",
    "authors": [
      "Xiang Zhang",
      "Chenlin Xu",
      "Zhouxiao Lu",
      "Haonan Wang",
      "Dong Song"
    ],
    "abstract": "Quantifying similarity between population spike patterns is essential for\nunderstanding how neural dynamics encode information. Traditional approaches,\nwhich combine kernel smoothing, PCA, and CCA, have limitations: smoothing\nkernel bandwidths are often empirically chosen, CCA maximizes alignment between\npatterns without considering the variance explained within patterns, and\nbaseline correlations from stochastic spiking are rarely corrected. We\nintroduce ReBaCCA-ss (Relevance-Balanced Continuum Correlation Analysis with\nsmoothing and surrogating), a novel framework that addresses these challenges\nthrough three innovations: (1) balancing alignment and variance explanation via\ncontinuum canonical correlation; (2) correcting for noise using surrogate spike\ntrains; and (3) selecting the optimal kernel bandwidth by maximizing the\ndifference between true and surrogate correlations. ReBaCCA-ss is validated on\nboth simulated data and hippocampal recordings from rats performing a Delayed\nNonmatch-to-Sample task. It reliably identifies spatio-temporal similarities\nbetween spike patterns. Combined with Multidimensional Scaling, ReBaCCA-ss\nreveals structured neural representations across trials, events, sessions, and\nanimals, offering a powerful tool for neural population analysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.13748v1",
    "published": "2025-05-19T21:51:56+00:00",
    "categories": [
      "q-bio.NC",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.16601v1",
    "title": "Resistive Plate Chamber Detector Construction and Certification: State-of-the-Art Facilities at the Max Planck Institute for Physics, in Partnership with Industrial Partners",
    "authors": [
      "Davide Costa",
      "Francesco Fallavollita",
      "Hubert Kroha",
      "Oliver Kortner",
      "Pavel Maly",
      "Giorgia Proto",
      "Daniel Soyk",
      "Elena Voevodina",
      "Jorg Zimmermann"
    ],
    "abstract": "Resistive Plate Chambers (RPCs) featuring 1 mm gas volumes combined with\nhigh-pressure phenolic laminate (HPL) electrodes provide excellent timing\nresolution down to a few hundred picoseconds, along with spatial resolution on\nthe order of a few millimeters. Thanks to their relatively low production cost\nand robust performance in high-background environments, RPCs have become\nessential components for instrumenting large detection areas in high-energy\nphysics experiments. The growing demand for these advanced RPC detectors,\nparticularly for the High-Luminosity upgrade of the Large Hadron Collider\n(HL-LHC), necessitates the establishment of new production facilities capable\nof delivering high-quality detectors at an industrial scale. To address this\nrequirement, a dedicated RPC assembly and certification facility has been\ndeveloped at the Max Planck Institute for Physics in Munich, leveraging\nstrategic collaborations with industrial partners MIRION and PTS. This\npartnership facilitated the transfer of advanced, research-level assembly\nmethodologies into robust, scalable industrial processes. Through a structured,\nphased prototyping and certification approach, initial tests on small-scale\n($40 \\times 50 \\, cm^2$) prototypes validated the scalability and applicability\nof optimized production procedures to large-scale ($1.0 \\times 2.0 \\, m^2$) RPC\ndetectors. Currently, the project has entered its final certification phase,\ninvolving extensive performance and longevity testing, including a year-long\nirradiation campaign at CERN's Gamma Irradiation Facility (GIF++). This article\ndetails the development and successful industrial implementation of novel\nassembly techniques, highlighting the enhanced capabilities and reliability of\nRPC detectors prepared through this industrial-academic collaboration, ensuring\nreadiness for upcoming challenges in high-energy physics detector\ninstrumentation.",
    "pdf_url": "http://arxiv.org/pdf/2505.16601v1",
    "published": "2025-05-19T21:51:36+00:00",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2506.06301v1",
    "title": "Large Language Models and Their Applications in Roadway Safety and Mobility Enhancement: A Comprehensive Review",
    "authors": [
      "Muhammad Monjurul Karim",
      "Yan Shi",
      "Shucheng Zhang",
      "Bingzhang Wang",
      "Mehrdad Nasri",
      "Yinhai Wang"
    ],
    "abstract": "Roadway safety and mobility remain critical challenges for modern\ntransportation systems, demanding innovative analytical frameworks capable of\naddressing complex, dynamic, and heterogeneous environments. While traditional\nengineering methods have made progress, the complexity and dynamism of\nreal-world traffic necessitate more advanced analytical frameworks. Large\nLanguage Models (LLMs), with their unprecedented capabilities in natural\nlanguage understanding, knowledge integration, and reasoning, represent a\npromising paradigm shift. This paper comprehensively reviews the application\nand customization of LLMs for enhancing roadway safety and mobility. A key\nfocus is how LLMs are adapted -- via architectural, training, prompting, and\nmultimodal strategies -- to bridge the \"modality gap\" with transportation's\nunique spatio-temporal and physical data. The review systematically analyzes\ndiverse LLM applications in mobility (e.g., traffic flow prediction, signal\ncontrol) and safety (e.g., crash analysis, driver behavior assessment,).\nEnabling technologies such as V2X integration, domain-specific foundation\nmodels, explainability frameworks, and edge computing are also examined.\nDespite significant potential, challenges persist regarding inherent LLM\nlimitations (hallucinations, reasoning deficits), data governance (privacy,\nbias), deployment complexities (sim-to-real, latency), and rigorous safety\nassurance. Promising future research directions are highlighted, including\nadvanced multimodal fusion, enhanced spatio-temporal reasoning, human-AI\ncollaboration, continuous learning, and the development of efficient,\nverifiable systems. This review provides a structured roadmap of current\ncapabilities, limitations, and opportunities, underscoring LLMs' transformative\npotential while emphasizing the need for responsible innovation to realize\nsafer, more intelligent transportation systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.06301v1",
    "published": "2025-05-19T21:51:18+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13747v1",
    "title": "Two-photon microscopy through scattering media harnessing speckle autocorrelation",
    "authors": [
      "Lei Zhu",
      "Bernhard Rauer",
      "Hilton B. De Aguiar",
      "Sylvain Gigan"
    ],
    "abstract": "Two-photon (2P) microscopy is a powerful technique for deep-tissue\nfluorescence imaging; however, tissue scattering limits its effectiveness for\ndepth imaging using conventional approaches. Despite typical strategies having\nbeen put forward to extend depth imaging capabilities based on wave-front\nshaping (WFS), computationally recovering images remains a significant\nchallenge using 2P signal. In this work, we demonstrate the successful\nreconstruction of fluorescent objects behind scattering layers using 2P\nmicroscopy, utilizing the optical memory effect (ME) along with the speckle\nautocorrelation technique and a phase retrieval algorithm. Our results\nhighlight the effectiveness of this method, offering significant potential for\nimproving depth imaging capabilities in 2P microscopy through scattering media.",
    "pdf_url": "http://arxiv.org/pdf/2505.13747v1",
    "published": "2025-05-19T21:46:54+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.13746v1",
    "title": "ReSW-VL: Representation Learning for Surgical Workflow Analysis Using Vision-Language Model",
    "authors": [
      "Satoshi Kondo"
    ],
    "abstract": "Surgical phase recognition from video is a technology that automatically\nclassifies the progress of a surgical procedure and has a wide range of\npotential applications, including real-time surgical support, optimization of\nmedical resources, training and skill assessment, and safety improvement.\nRecent advances in surgical phase recognition technology have focused primarily\non Transform-based methods, although methods that extract spatial features from\nindividual frames using a CNN and video features from the resulting time series\nof spatial features using time series modeling have shown high performance.\nHowever, there remains a paucity of research on training methods for CNNs\nemployed for feature extraction or representation learning in surgical phase\nrecognition. In this study, we propose a method for representation learning in\nsurgical workflow analysis using a vision-language model (ReSW-VL). Our\nproposed method involves fine-tuning the image encoder of a CLIP (Convolutional\nLanguage Image Model) vision-language model using prompt learning for surgical\nphase recognition. The experimental results on three surgical phase recognition\ndatasets demonstrate the effectiveness of the proposed method in comparison to\nconventional methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13746v1",
    "published": "2025-05-19T21:44:37+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13745v1",
    "title": "Synthetic Non-stationary Data Streams for Recognition of the Unknown",
    "authors": [
      "Joanna Komorniczak"
    ],
    "abstract": "The problem of data non-stationarity is commonly addressed in data stream\nprocessing. In a dynamic environment, methods should continuously be ready to\nanalyze time-varying data -- hence, they should enable incremental training and\nrespond to concept drifts. An equally important variability typical for\nnon-stationary data stream environments is the emergence of new, previously\nunknown classes. Often, methods focus on one of these two phenomena --\ndetection of concept drifts or detection of novel classes -- while both\ndifficulties can be observed in data streams. Additionally, concerning\npreviously unknown observations, the topic of open set of classes has become\nparticularly important in recent years, where the goal of methods is to\nefficiently classify within known classes and recognize objects outside the\nmodel competence. This article presents a strategy for synthetic data stream\ngeneration in which both concept drifts and the emergence of new classes\nrepresenting unknown objects occur. The presented research shows how\nunsupervised drift detectors address the task of detecting novelty and concept\ndrifts and demonstrates how the generated data streams can be utilized in the\nopen set recognition task.",
    "pdf_url": "http://arxiv.org/pdf/2505.13745v1",
    "published": "2025-05-19T21:44:32+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13744v2",
    "title": "Early Stages of Self-Healing at Tungsten Grain Boundaries from Ab Initio Machine Learning Simulations",
    "authors": [
      "Jorge Su√°rez-Recio",
      "Pablo M. Piaggi",
      "Francisco J. Dom√≠nguez-Guti√©rrez",
      "Raquel Gonzalez-Arrabal",
      "Roberto Iglesias"
    ],
    "abstract": "Nanostructured tungsten has been reported as a possible alternative\nplasma-facing material due to its potential ability to self-heal\nradiation-induced defects, a property that is attributed to its high density of\ngrain boundaries (GB). Here, we study the initial stages of self-healing at\ntungsten interfaces with molecular dynamics simulations driven by a\nmachine-learning interatomic potential tailored to one of the most common GBs\nfound in experiments. Our model accurately reproduces the ab initio potential\nenergy surface derived from density functional theory (DFT) calculations and\noutperforms previously reported empirical and machine learning interatomic\npotentials in predicting defect energetics. The simulations reveal\nlow-temperature defect migration to GBs driven by rapid dumbbell-like ordering\nand subsequent accommodation along GB grooves. In contrast to empirical\npotentials, which predict unexpected GB degradation at high temperatures after\ndefect migration, our model maintains stable GB motifs over the investigated\ntemperature range. The temperature-dependent defect counts, evaluated using an\nArrhenius-like fit, yield an average interstitial migration energy of 0.048 eV,\nin agreement with experiment.\n  This work underscores the capabilities of ab initio machine learning\nsimulations in accurately modeling defect-GB interactions and highlights their\npotential to contribute to the development of radiation tolerant materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.13744v2",
    "published": "2025-05-19T21:41:31+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.13743v1",
    "title": "Error estimates for a multiobjective optimal control of a pointwise tracking problem",
    "authors": [
      "Francisco Fuica",
      "Stefan Volkwein"
    ],
    "abstract": "We analyze a pointwise tracking multiobjective optimal control problem\nsubject to the Poisson problem and bilateral control constraints. To\napproximate Pareto optimal points and the Pareto front numerically, we consider\ntwo different finite element-based scalarization techniques, namely the\nweighted-sum method and the reference point method, where in both methods many\nscalar-constrained optimization problems have to be solved. We prove a priori\nerror estimates for both scalarizations. The underlying subproblems of either\nmethod are solved with a Barzilai-Borwein gradient method. Numerical\nexperiments illustrate the accuracy of the proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2505.13743v1",
    "published": "2025-05-19T21:39:11+00:00",
    "categories": [
      "math.OC",
      "cs.NA",
      "math.NA",
      "49M25, 58E17, 65N15, 65N30, 90C29"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13742v1",
    "title": "Understanding Task Representations in Neural Networks via Bayesian Ablation",
    "authors": [
      "Andrew Nam",
      "Declan Campbell",
      "Thomas Griffiths",
      "Jonathan Cohen",
      "Sarah-Jane Leslie"
    ],
    "abstract": "Neural networks are powerful tools for cognitive modeling due to their\nflexibility and emergent properties. However, interpreting their learned\nrepresentations remains challenging due to their sub-symbolic semantics. In\nthis work, we introduce a novel probabilistic framework for interpreting latent\ntask representations in neural networks. Inspired by Bayesian inference, our\napproach defines a distribution over representational units to infer their\ncausal contributions to task performance. Using ideas from information theory,\nwe propose a suite of tools and metrics to illuminate key model properties,\nincluding representational distributedness, manifold complexity, and\npolysemanticity.",
    "pdf_url": "http://arxiv.org/pdf/2505.13742v1",
    "published": "2025-05-19T21:36:09+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13741v1",
    "title": "Frozen Backpropagation: Relaxing Weight Symmetry in Temporally-Coded Deep Spiking Neural Networks",
    "authors": [
      "Gaspard Goupy",
      "Pierre Tirilly",
      "Ioan Marius Bilasco"
    ],
    "abstract": "Direct training of Spiking Neural Networks (SNNs) on neuromorphic hardware\ncan greatly reduce energy costs compared to GPU-based training. However,\nimplementing Backpropagation (BP) on such hardware is challenging because\nforward and backward passes are typically performed by separate networks with\ndistinct weights. To compute correct gradients, forward and feedback weights\nmust remain symmetric during training, necessitating weight transport between\nthe two networks. This symmetry requirement imposes hardware overhead and\nincreases energy costs. To address this issue, we introduce Frozen\nBackpropagation (fBP), a BP-based training algorithm relaxing weight symmetry\nin settings with separate networks. fBP updates forward weights by computing\ngradients with periodically frozen feedback weights, reducing weight transports\nduring training and minimizing synchronization overhead. To further improve\ntransport efficiency, we propose three partial weight transport schemes of\nvarying computational complexity, where only a subset of weights is transported\nat a time. We evaluate our methods on image recognition tasks and compare them\nto existing approaches addressing the weight symmetry requirement. Our results\nshow that fBP outperforms these methods and achieves accuracy comparable to BP.\nWith partial weight transport, fBP can substantially lower transport costs by\n1,000x with an accuracy drop of only 0.5pp on CIFAR-10 and 1.1pp on CIFAR-100,\nor by up to 10,000x at the expense of moderated accuracy loss. This work\nprovides insights for guiding the design of neuromorphic hardware incorporating\nBP-based on-chip learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.13741v1",
    "published": "2025-05-19T21:35:20+00:00",
    "categories": [
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13740v2",
    "title": "Improving Compositional Generation with Diffusion Models Using Lift Scores",
    "authors": [
      "Chenning Yu",
      "Sicun Gao"
    ],
    "abstract": "We introduce a novel resampling criterion using lift scores, for improving\ncompositional generation in diffusion models. By leveraging the lift scores, we\nevaluate whether generated samples align with each single condition and then\ncompose the results to determine whether the composed prompt is satisfied. Our\nkey insight is that lift scores can be efficiently approximated using only the\noriginal diffusion model, requiring no additional training or external modules.\nWe develop an optimized variant that achieves relatively lower computational\noverhead during inference while maintaining effectiveness. Through extensive\nexperiments, we demonstrate that lift scores significantly improved the\ncondition alignment for compositional generation across 2D synthetic data,\nCLEVR position tasks, and text-to-image synthesis. Our code is available at\nhttp://rainorangelemon.github.io/complift.",
    "pdf_url": "http://arxiv.org/pdf/2505.13740v2",
    "published": "2025-05-19T21:34:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13739v1",
    "title": "Magnetic field-enhanced two-electron oxygen reduction reaction using CeMnCo nanoparticles supported on different carbonaceous matrices",
    "authors": [
      "Caio Machado Fernandes",
      "Joao Paulo C. Moura",
      "Aline B. Trench",
      "Odivaldo C. Alves",
      "Yutao Xing",
      "Marcos R. V. Lanza",
      "Julio Cesar M. Silva",
      "Mauro C. Santos"
    ],
    "abstract": "The current study illustrates the successful synthesis of\nCe$_{1.0}$Mn$_{0.9}$Co$_{0.1}$ nanoparticles, characterized through XRD, EPR,\nmagnetization curves, and TEM/HRTEM/EDX analyses. These nanoparticles were then\nloaded into the carbon Vulcan XC72 and the carbon Printex L6 matrices in\nvarying amounts (1, 3, 5, and 10% w/w) via wet impregnation method to fabricate\nelectrocatalysts for the 2-electron ORR. Before experimentation, the material\nwas characterized via XPS and contact angle measurements. The electrochemical\nresults produced significant findings, indicating that the electrocatalysts\nwith the nanostructures modifying both carbon blacks notably augmented currents\nin rotating ring-disk electrode measurements, signifying enhanced selectivity\nfor H$_2$O$_2$ production. Moreover, our research underscored the significant\nimpact of Magnetic Field-Enhanced Electrochemistry, employing a constant\nmagnetic field strength of 2000 Oe, on 2-electron ORR experiments. Particularly\nnoteworthy were the observed results surpassing the ones without the magnetic\nfield, demonstrating heightened currents and improved selectivity for\nH$_2$O$_2$ production (more than 90 %) facilitated by CeMnCo nanoparticles.\nThese significant findings in electrocatalytic efficiency have practical\nimplications, suggesting the potential for developing more efficient and\nselective catalysts for the 2-electron ORR.",
    "pdf_url": "http://arxiv.org/pdf/2505.13739v1",
    "published": "2025-05-19T21:28:51+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13738v1",
    "title": "Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training",
    "authors": [
      "Shane Bergsma",
      "Nolan Dey",
      "Gurpreet Gosal",
      "Gavia Gray",
      "Daria Soboleva",
      "Joel Hestness"
    ],
    "abstract": "Efficient LLM pre-training requires well-tuned hyperparameters (HPs),\nincluding learning rate {\\eta} and weight decay {\\lambda}. We study scaling\nlaws for HPs: formulas for how to scale HPs as we scale model size N, dataset\nsize D, and batch size B. Recent work suggests the AdamW timescale,\nB/({\\eta}{\\lambda}D), should remain constant across training settings, and we\nverify the implication that optimal {\\lambda} scales linearly with B, for a\nfixed N,D. However, as N,D scale, we show the optimal timescale obeys a precise\npower law in the tokens-per-parameter ratio, D/N. This law thus provides a\nmethod to accurately predict {\\lambda}opt in advance of large-scale training.\nWe also study scaling laws for optimal batch size Bopt (the B enabling lowest\nloss at a given N,D) and critical batch size Bcrit (the B beyond which further\ndata parallelism becomes ineffective). In contrast with prior work, we find\nboth Bopt and Bcrit scale as power laws in D, independent of model size, N.\nFinally, we analyze how these findings inform the real-world selection of\nPareto-optimal N and D under dual training time and compute objectives.",
    "pdf_url": "http://arxiv.org/pdf/2505.13738v1",
    "published": "2025-05-19T21:27:33+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13737v1",
    "title": "Causal Head Gating: A Framework for Interpreting Roles of Attention Heads in Transformers",
    "authors": [
      "Andrew Nam",
      "Henry Conklin",
      "Yukang Yang",
      "Thomas Griffiths",
      "Jonathan Cohen",
      "Sarah-Jane Leslie"
    ],
    "abstract": "We present causal head gating (CHG), a scalable method for interpreting the\nfunctional roles of attention heads in transformer models. CHG learns soft\ngates over heads and assigns them a causal taxonomy - facilitating,\ninterfering, or irrelevant - based on their impact on task performance. Unlike\nprior approaches in mechanistic interpretability, which are hypothesis-driven\nand require prompt templates or target labels, CHG applies directly to any\ndataset using standard next-token prediction. We evaluate CHG across multiple\nlarge language models (LLMs) in the Llama 3 model family and diverse tasks,\nincluding syntax, commonsense, and mathematical reasoning, and show that CHG\nscores yield causal - not merely correlational - insight, validated via\nablation and causal mediation analyses. We also introduce contrastive CHG, a\nvariant that isolates sub-circuits for specific task components. Our findings\nreveal that LLMs contain multiple sparse, sufficient sub-circuits, that\nindividual head roles depend on interactions with others (low modularity), and\nthat instruction following and in-context learning rely on separable\nmechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.13737v1",
    "published": "2025-05-19T21:24:13+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13736v1",
    "title": "Response of Kaluza-Klein mass spectrum to deformations of rugby-ball compact space",
    "authors": [
      "Hajime Otsuka",
      "Yutaka Sakamura"
    ],
    "abstract": "We investigate the response of the Kaluza-Klein (KK) mass spectrum to various\ndeformations of the rugby-ball background in 6-dimensional supergravity. We\nderived the mode equations that contain the 3-dimensional scale factor and the\nlapse function. By solving these, we numerically evaluate the KK masses for a\nbulk scalar and a spinor when the background has a nontrivial dependence on the\nposition in the compact space. We clarify some qualitative features of the\nspectrum deformation for some perturbations of the rugby-ball background. For\nperturbations of a supersymmetric background, we find that the mass-splitting\nbetween bosonic and fermionic modes is much smaller than the deviation from the\nvalues of the supersymmetric mass eigenvalues.",
    "pdf_url": "http://arxiv.org/pdf/2505.13736v1",
    "published": "2025-05-19T21:19:14+00:00",
    "categories": [
      "hep-th",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13735v2",
    "title": "Numerical Calculation of Coulomb Corrections in Forward Elastic $p^\\uparrow\\!\\!\\;{p}$ and ${p}^\\uparrow\\!{A}$ Scattering",
    "authors": [
      "Andrei Poblaguev"
    ],
    "abstract": "The analysis of RHIC hydrogen gas jet target polarimeter measurements of\ntransverse analyzing powers $A_\\text{N}(t)$ in proton-nucleus scattering\nrequires accurate Coulomb corrections to both spin-flip and non-flip\namplitudes. These corrections must cover a wide range of nuclear charges $Z$\nand form factor slopes, with flexibility to vary form factors during data\nfitting. To avoid technically challenging calculations involving a small but\nfinite fictitious photon mass, the Coulomb correction to the non-flip\nelectromagnetic amplitude with an exponential form factor was related to the\ncorresponding correction for the spin-flip amplitude. This approach allows soft\nphoton contributions to all amplitudes, including those with non-exponential\nform factors, to be calculated in the massless photon limit using only\nanalytical expressions and numerically stable integrals with nonsingular\nintegrands and finite integration limits. In addition, an absorptive correction\nto the spin-flip electromagnetic amplitude, which plays a critical role in spin\neffects in forward polarized proton-nucleus scattering, was accurately\nevaluated.",
    "pdf_url": "http://arxiv.org/pdf/2505.13735v2",
    "published": "2025-05-19T21:17:57+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13734v2",
    "title": "Euler-Poincare characteristic pair of orientable supermanifolds",
    "authors": [
      "Mehdi Ghorbani",
      "Fatemeh Alikhani",
      "Saad Varsaie"
    ],
    "abstract": "The Euler-Poincare characteristic, or Euler characteristic in short, is a\nfundamental topological invariant of compact manifolds that plays a crucial\nrole in a variety of geometric and topological situations. From this point of\nview, we tried to expand on this important concept in supergeometry. In this\narticle, we introduce the Euler-Poincare characteristic pair in the\nsupergeometry. In the final section, we examine transversality in the category\nof $\\Pi$-symmetric supermanifolds.",
    "pdf_url": "http://arxiv.org/pdf/2505.13734v2",
    "published": "2025-05-19T21:16:10+00:00",
    "categories": [
      "math.DG",
      "58A50, 58C50"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13733v1",
    "title": "Liquid combs: broadband light with equidistance and without stability",
    "authors": [
      "Mithun Roy",
      "Tianyi Zeng",
      "Zhenyang Xiao",
      "Chao Dong",
      "Sadhvikas Addamane",
      "Qing Hu",
      "David Burghoff"
    ],
    "abstract": "Broadband light sources with well-defined spectral structures are vital for\nscience and technology. However, the evenly spaced lines of frequency combs\nrepresent only a small subset of all possible structured white-light sources.\nWe demonstrate liquid combs: optical states that preserve spectral equidistance\nbut lack temporal stability. By engineering the gain and dispersion of\nsemiconductor laser cavities, we produce light that possesses rapid phase\nfluctuations but maintains relative phase differences between modes that vary\nidentically. We show experimentally that this phenomenon occurs in multiple\nlaser platforms -- across multiple octaves -- through the creation of a\nmetrological technique that determines the phase differences. We also show\ntheoretically that this is a general phenomenon that can be described using a\nmean-field theory. These liquid combs are attractive for many applications due\nto having wider bandwidths than frequency combs, and more generally, they\nrepresent the long-sought realization of structured white-light sources that\nare not combs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13733v1",
    "published": "2025-05-19T21:09:00+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.13732v1",
    "title": "Backward Conformal Prediction",
    "authors": [
      "Etienne Gauthier",
      "Francis Bach",
      "Michael I. Jordan"
    ],
    "abstract": "We introduce $\\textit{Backward Conformal Prediction}$, a method that\nguarantees conformal coverage while providing flexible control over the size of\nprediction sets. Unlike standard conformal prediction, which fixes the coverage\nlevel and allows the conformal set size to vary, our approach defines a rule\nthat constrains how prediction set sizes behave based on the observed data, and\nadapts the coverage level accordingly. Our method builds on two key\nfoundations: (i) recent results by Gauthier et al. [2025] on post-hoc validity\nusing e-values, which ensure marginal coverage of the form $\\mathbb{P}(Y_{\\rm\ntest} \\in \\hat C_n^{\\tilde{\\alpha}}(X_{\\rm test})) \\ge 1 -\n\\mathbb{E}[\\tilde{\\alpha}]$ up to a first-order Taylor approximation for any\ndata-dependent miscoverage $\\tilde{\\alpha}$, and (ii) a novel leave-one-out\nestimator $\\hat{\\alpha}^{\\rm LOO}$ of the marginal miscoverage\n$\\mathbb{E}[\\tilde{\\alpha}]$ based on the calibration set, ensuring that the\ntheoretical guarantees remain computable in practice. This approach is\nparticularly useful in applications where large prediction sets are impractical\nsuch as medical diagnosis. We provide theoretical results and empirical\nevidence supporting the validity of our method, demonstrating that it maintains\ncomputable coverage guarantees while ensuring interpretable, well-controlled\nprediction set sizes.",
    "pdf_url": "http://arxiv.org/pdf/2505.13732v1",
    "published": "2025-05-19T21:08:14+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.13731v1",
    "title": "GeoRanker: Distance-Aware Ranking for Worldwide Image Geolocalization",
    "authors": [
      "Pengyue Jia",
      "Seongheon Park",
      "Song Gao",
      "Xiangyu Zhao",
      "Yixuan Li"
    ],
    "abstract": "Worldwide image geolocalization-the task of predicting GPS coordinates from\nimages taken anywhere on Earth-poses a fundamental challenge due to the vast\ndiversity in visual content across regions. While recent approaches adopt a\ntwo-stage pipeline of retrieving candidates and selecting the best match, they\ntypically rely on simplistic similarity heuristics and point-wise supervision,\nfailing to model spatial relationships among candidates. In this paper, we\npropose GeoRanker, a distance-aware ranking framework that leverages large\nvision-language models to jointly encode query-candidate interactions and\npredict geographic proximity. In addition, we introduce a multi-order distance\nloss that ranks both absolute and relative distances, enabling the model to\nreason over structured spatial relationships. To support this, we curate\nGeoRanking, the first dataset explicitly designed for geographic ranking tasks\nwith multimodal candidate information. GeoRanker achieves state-of-the-art\nresults on two well-established benchmarks (IM2GPS3K and YFCC4K), significantly\noutperforming current best methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13731v1",
    "published": "2025-05-19T21:04:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13730v1",
    "title": "XRISM Reveals a Remnant Torus in the Low-Luminosity AGN M81*",
    "authors": [
      "Jon M. Miller",
      "Ehud Behar",
      "Hisamitsu Awaki",
      "Ann Hornschemeier",
      "Jesse Bluem",
      "Luigi Gallo",
      "Shogo B. Kobayashi",
      "Richard Mushotzky",
      "Masanori Ohno",
      "Robert Petre",
      "Kosuke Sato",
      "Yuichi Terashima",
      "Mihoko Yukita"
    ],
    "abstract": "Up to 40% of galaxies in the local universe host a low-luminosity active\ngalactic nucleus (LLAGN), making it vital to understand this mode of black hole\naccretion. However, the presence or absence of Seyfert-like geometries - an\naccretion disk close to the black hole, an optical broad line region (BLR), and\na molecular torus - remains uncertain owing to the low flux levels of sources\nwithin this class. Herein, we present an analysis of a XRISM/Resolve spectrum\nof M81*, the LLAGN in the heart of the nearby spiral galaxy M81. A weak,\nneutral Fe K emission line is detected and resolved into K$_{\\alpha,1}$ and\nK$_{\\alpha,2}$ components. It shows a negligible velocity shift, and weak\nbroadening (FWHM$=460^{+260}_{-160}~{\\rm km}~{\\rm s}^{-1}$) that corresponds to\nan inner emission radius of ${\\rm r} \\geq 2.7\\times 10^{4}~GM/c^{2}$ for likely\ninclinations. The Fe K$_{\\alpha}$ line likely traces a torus. The upper limit\non additional splitting of the Fe K$_{\\alpha}$ line components translates to a\nlimit on the local magnetic field of ${\\rm B} \\leq 3.5\\times 10^{8}$ Gauss,\nassuming Zeeman splitting. The spectra also reveal ionized plasma(s) through\nHe-like Fe XXV and H-like Fe XXVI emission lines. These can be fit equally well\nassuming photoionization and collisional excitation. The H-like Fe XXVI line is\nbetter described when a second component is included with a red-shift of ${\\rm\nv} = 1600~{\\rm km}~{\\rm s}^{-1}$, but this addition is of marginal statistical\nsignificance. We discuss these results in the context of radiatively\ninefficient accretion flow models, magnetically arrested disks, and possible\nlinks to the Fermi bubbles in the Milky Way.",
    "pdf_url": "http://arxiv.org/pdf/2505.13730v1",
    "published": "2025-05-19T20:59:21+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15850v1",
    "title": "Machine Learning-Based Prediction of Mortality in Geriatric Traumatic Brain Injury Patients",
    "authors": [
      "Yong Si",
      "Junyi Fan",
      "Li Sun",
      "Shuheng Chen",
      "Elham Pishgar",
      "Kamiar Alaei",
      "Greg Placencia",
      "Maryam Pishgar"
    ],
    "abstract": "Traumatic Brain Injury (TBI) is a major contributor to mortality among older\nadults, with geriatric patients facing disproportionately high risk due to\nage-related physiological vulnerability and comorbidities. Early and accurate\nprediction of mortality is essential for guiding clinical decision-making and\noptimizing ICU resource allocation. In this study, we utilized the MIMIC-III\ndatabase to identify geriatric TBI patients and applied a machine learning\nframework to develop a 30-day mortality prediction model. A rigorous\npreprocessing pipeline-including Random Forest-based imputation, feature\nengineering, and hybrid selection-was implemented to refine predictors from 69\nto 9 clinically meaningful variables. CatBoost emerged as the top-performing\nmodel, achieving an AUROC of 0.867 (95% CI: 0.809-0.922), surpassing\ntraditional scoring systems. SHAP analysis confirmed the importance of GCS\nscore, oxygen saturation, and prothrombin time as dominant predictors. These\nfindings highlight the value of interpretable machine learning tools for early\nmortality risk stratification in elderly TBI patients and provide a foundation\nfor future clinical integration to support high-stakes decision-making in\ncritical care.",
    "pdf_url": "http://arxiv.org/pdf/2505.15850v1",
    "published": "2025-05-19T20:58:58+00:00",
    "categories": [
      "q-bio.QM"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.13729v1",
    "title": "SayCoNav: Utilizing Large Language Models for Adaptive Collaboration in Decentralized Multi-Robot Navigation",
    "authors": [
      "Abhinav Rajvanshi",
      "Pritish Sahu",
      "Tixiao Shan",
      "Karan Sikka",
      "Han-Pang Chiu"
    ],
    "abstract": "Adaptive collaboration is critical to a team of autonomous robots to perform\ncomplicated navigation tasks in large-scale unknown environments. An effective\ncollaboration strategy should be determined and adapted according to each\nrobot's skills and current status to successfully achieve the shared goal. We\npresent SayCoNav, a new approach that leverages large language models (LLMs)\nfor automatically generating this collaboration strategy among a team of\nrobots. Building on the collaboration strategy, each robot uses the LLM to\ngenerate its plans and actions in a decentralized way. By sharing information\nto each other during navigation, each robot also continuously updates its\nstep-by-step plans accordingly. We evaluate SayCoNav on Multi-Object Navigation\n(MultiON) tasks, that require the team of the robots to utilize their\ncomplementary strengths to efficiently search multiple different objects in\nunknown environments. By validating SayCoNav with varied team compositions and\nconditions against baseline methods, our experimental results show that\nSayCoNav can improve search efficiency by at most 44.28% through effective\ncollaboration among heterogeneous robots. It can also dynamically adapt to the\nchanging conditions during task execution.",
    "pdf_url": "http://arxiv.org/pdf/2505.13729v1",
    "published": "2025-05-19T20:58:06+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13728v1",
    "title": "Quantifying Chromosphere Response to Flare Energy Release Using AIA Observations in 1600~√Ö and 304~√Ö Passbands",
    "authors": [
      "Jiong Qiu",
      "Rhiannon Fleming"
    ],
    "abstract": "Imaging observations of the solar lower atmosphere by the Atmosphere Imaging\nAssembly (AIA) have been mostly used as the context, and their quantitative\ninformation has been much less explored. The chromosphere responds rapidly to\nenergy release by magnetic reconnection during flares. Furthermore, a flare is\na collection of multiple energy release events that can be identified in\nspatially resolved chromosphere observations. In this paper, we conduct a\nstatistical and semi-quantitative study of the relative photometry in the UV\n1600~\\AA\\ and EUV 304~\\AA\\ passbands for 18 flares observed by AIA. In each\nflare, we have identified thousands of flare ribbon pixels in the UV 1600~\\AA\\\nimages, and measured their brightness (counts per second) and the rise and\ndecay timescales, which are indicative of heating properties in flare loops.\nThe analysis shows that bright flare pixels, characterized by peak brightness\nlarger than ten times the quiescent brightness, exhibit sharp light curves with\nthe half rise time below 2 min, followed by a two-phase decay with a rapid\ndecay on timescales comparable to the rise time and then a more gradual decay.\nFlare ribbon pixels identified in both UV 1600 ~\\AA\\ and EUV 304~\\AA\\ images\nexhibit similar time profiles during the rise, and their peak brightness appear\nto be related by a power law. Our analysis shows that AIA observed flare\nbrightness in UV 1600~\\AA\\ relative to the quiescent brightness is a meaningful\nmeasurement of the flare chromosphere photometry, and AIA observations for over\na decade thus provide a unique and extensive database for systematic and\nsemi-quantitative study of flaring chromosphere, either in the context of the\nSun as a star, or in spatially resolved manner that helps to probe the nature\nof flare energy release on elementary scales.",
    "pdf_url": "http://arxiv.org/pdf/2505.13728v1",
    "published": "2025-05-19T20:57:04+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13727v2",
    "title": "Kummer Surfaces, Isogenies and Theta Functions",
    "authors": [
      "Adrian Clingher",
      "Andreas Malmendier",
      "Tony Shaska"
    ],
    "abstract": "The paper discusses geometric and computational aspects associated with\n$(n,n)$-isogenies for principally polarized Abelian surfaces and related Kummer\nsurfaces. We start by reviewing the comprehensive Theta function framework for\nclassifying genus-two curves, their principally polarized Jacobians, as well as\nfor establishing explicit quartic normal forms for associated Kummer surfaces.\nThis framework is then used for practical isogeny computations. A particular\nfocus of the discussion is the $(n,n)$-Split isogeny case. We also explore\npossible extensions of Richelot's $(2,2)$-isogenies to higher order cases, with\na view towards developing efficient isogeny computation algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.13727v2",
    "published": "2025-05-19T20:55:16+00:00",
    "categories": [
      "math.AG",
      "14J28, 14K02, 14K25"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13726v1",
    "title": "Benchmarking MOEAs for solving continuous multi-objective RL problems",
    "authors": [
      "Carlos Hern√°ndez",
      "Roberto Santana"
    ],
    "abstract": "Multi-objective reinforcement learning (MORL) addresses the challenge of\nsimultaneously optimizing multiple, often conflicting, rewards, moving beyond\nthe single-reward focus of conventional reinforcement learning (RL). This\napproach is essential for applications where agents must balance trade-offs\nbetween diverse goals, such as speed, energy efficiency, or stability, as a\nseries of sequential decisions. This paper investigates the applicability and\nlimitations of multi-objective evolutionary algorithms (MOEAs) in solving\ncomplex MORL problems. We assess whether these algorithms can effectively\naddress the unique challenges posed by MORL and how MORL instances can serve as\nbenchmarks to evaluate and improve MOEA performance. In particular, we propose\na framework to characterize the features influencing MORL instance complexity,\nselect representative MORL problems from the literature, and benchmark a suite\nof MOEAs alongside single-objective EAs using scalarized MORL formulations.\nAdditionally, we evaluate the utility of existing multi-objective quality\nindicators in MORL scenarios, such as hypervolume conducting a comparison of\nthe algorithms supported by statistical analysis. Our findings provide insights\ninto the interplay between MORL problem characteristics and algorithmic\neffectiveness, highlighting opportunities for advancing both MORL research and\nthe design of evolutionary algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.13726v1",
    "published": "2025-05-19T20:54:20+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13725v1",
    "title": "SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs",
    "authors": [
      "Yu Guo",
      "Dong Jin",
      "Shenghao Ye",
      "Shuangwu Chen",
      "Jian Yang",
      "Xiaobin Tan"
    ],
    "abstract": "Large Language models (LLMs) have demonstrated significant potential in\ntext-to-SQL reasoning tasks, yet a substantial performance gap persists between\nexisting open-source models and their closed-source counterparts. In this\npaper, we introduce SQLForge, a novel approach for synthesizing reliable and\ndiverse data to enhance text-to-SQL reasoning in LLMs. We improve data\nreliability through SQL syntax constraints and SQL-to-question reverse\ntranslation, ensuring data logic at both structural and semantic levels. We\nalso propose an SQL template enrichment and iterative data domain exploration\nmechanism to boost data diversity. Building on the augmented data, we fine-tune\na variety of open-source models with different architectures and parameter\nsizes, resulting in a family of models termed SQLForge-LM. SQLForge-LM achieves\nthe state-of-the-art performance on the widely recognized Spider and BIRD\nbenchmarks among the open-source models. Specifically, SQLForge-LM achieves EX\naccuracy of 85.7% on Spider Dev and 59.8% on BIRD Dev, significantly narrowing\nthe performance gap with closed-source methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13725v1",
    "published": "2025-05-19T20:51:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13724v1",
    "title": "Experimental demonstration of a tomographic 5D phase-space reconstruction",
    "authors": [
      "S. Jaster-Merz",
      "R. W. Assmann",
      "J. Beinortaitƒó",
      "J. Bj√∂rklund Svensson",
      "R. Brinkmann",
      "F. Burkart",
      "P. Craievich",
      "H. Dinter",
      "P. Gonz√°lez Caminal",
      "W. Hillert",
      "A. L. Kanekar",
      "M. Kellermeier",
      "W. Kuropka",
      "F. Mayet",
      "J. Osterhoff",
      "B. Stacey",
      "M. Stanitzki",
      "T. Vinatier",
      "S. Wesch",
      "R. D'Arcy"
    ],
    "abstract": "Detailed knowledge of particle-beam properties is of great importance to\nunderstand and push the performance of existing and next-generation particle\naccelerators. We recently proposed a new phase-space tomography method to\nreconstruct the five-dimensional (5D) phase space, i.e., the charge density\ndistribution in all three spatial directions and the two transverse momenta.\nHere, we present the first experimental demonstration of the method at the\nFLASHForward facility at DESY. This includes the reconstruction of the 5D\nphase-space distribution of a GeV-class electron bunch, the use of this\nmeasured phase space to create a particle distribution for simulations, and the\nextraction of the transverse 4D slice emittance.",
    "pdf_url": "http://arxiv.org/pdf/2505.13724v1",
    "published": "2025-05-19T20:47:18+00:00",
    "categories": [
      "physics.acc-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13723v1",
    "title": "Turbocharging Gaussian Process Inference with Approximate Sketch-and-Project",
    "authors": [
      "Pratik Rathore",
      "Zachary Frangella",
      "Sachin Garg",
      "Shaghayegh Fazliani",
      "Micha≈Ç Derezi≈Ñski",
      "Madeleine Udell"
    ],
    "abstract": "Gaussian processes (GPs) play an essential role in biostatistics, scientific\nmachine learning, and Bayesian optimization for their ability to provide\nprobabilistic predictions and model uncertainty. However, GP inference\nstruggles to scale to large datasets (which are common in modern applications),\nsince it requires the solution of a linear system whose size scales\nquadratically with the number of samples in the dataset. We propose an\napproximate, distributed, accelerated sketch-and-project algorithm\n($\\texttt{ADASAP}$) for solving these linear systems, which improves\nscalability. We use the theory of determinantal point processes to show that\nthe posterior mean induced by sketch-and-project rapidly converges to the true\nposterior mean. In particular, this yields the first efficient, condition\nnumber-free algorithm for estimating the posterior mean along the top spectral\nbasis functions, showing that our approach is principled for GP inference.\n$\\texttt{ADASAP}$ outperforms state-of-the-art solvers based on conjugate\ngradient and coordinate descent across several benchmark datasets and a\nlarge-scale Bayesian optimization task. Moreover, $\\texttt{ADASAP}$ scales to a\ndataset with $> 3 \\cdot 10^8$ samples, a feat which has not been accomplished\nin the literature.",
    "pdf_url": "http://arxiv.org/pdf/2505.13723v1",
    "published": "2025-05-19T20:46:26+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13722v1",
    "title": "Practice Makes Perfect: A Study of Digital Twin Technology for Assembly and Problem-solving using Lunar Surface Telerobotics",
    "authors": [
      "Xavier O'Keefe",
      "Katy McCutchan",
      "Alexis Muniz",
      "Jack Burns",
      "Daniel Szafir"
    ],
    "abstract": "Robotic systems that can traverse planetary or lunar surfaces to collect\nenvironmental data and perform physical manipulation tasks, such as assembling\nequipment or conducting mining operations, are envisioned to form the backbone\nof future human activities in space. However, the environmental conditions in\nwhich these robots, or \"rovers,\" operate present challenges toward achieving\nfully autonomous solutions, meaning that rover missions will require some\ndegree of human teleoperation or supervision for the foreseeable future. As a\nresult, human operators require training to successfully direct rovers and\navoid costly errors or mission failures, as well as the ability to recover from\nany issues that arise on the fly during mission activities. While analog\nenvironments, such as JPL's Mars Yard, can help with such training by\nsimulating surface environments in the real world, access to such resources may\nbe rare and expensive. As an alternative or supplement to such physical\nanalogs, we explore the design and evaluation of a virtual reality digital twin\nsystem to train human teleoperation of robotic rovers with mechanical arms for\nspace mission activities. We conducted an experiment with 24 human operators to\ninvestigate how our digital twin system can support human teleoperation of\nrovers in both pre-mission training and in real-time problem solving in a mock\nlunar mission in which users directed a physical rover in the context of\ndeploying dipole radio antennas. We found that operators who first trained with\nthe digital twin showed a 28% decrease in mission completion time, an 85%\ndecrease in unrecoverable errors, as well as improved mental markers, including\ndecreased cognitive load and increased situation awareness.",
    "pdf_url": "http://arxiv.org/pdf/2505.13722v1",
    "published": "2025-05-19T20:40:52+00:00",
    "categories": [
      "cs.RO",
      "astro-ph.EP",
      "astro-ph.IM"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.17072v2",
    "title": "Safety Alignment Can Be Not Superficial With Explicit Safety Signals",
    "authors": [
      "Jianwei Li",
      "Jung-Eun Kim"
    ],
    "abstract": "Recent studies on the safety alignment of large language models (LLMs) have\nrevealed that existing approaches often operate superficially, leaving models\nvulnerable to various adversarial attacks. Despite their significance, these\nstudies generally fail to offer actionable solutions beyond data augmentation\nfor achieving more robust safety mechanisms. This paper identifies a\nfundamental cause of this superficiality: existing alignment approaches often\npresume that models can implicitly learn a safety-related reasoning task during\nthe alignment process, enabling them to refuse harmful requests. However, the\nlearned safety signals are often diluted by other competing objectives, leading\nmodels to struggle with drawing a firm safety-conscious decision boundary when\nconfronted with adversarial attacks. Based on this observation, by explicitly\nintroducing a safety-related binary classification task and integrating its\nsignals with our attention and decoding strategies, we eliminate this ambiguity\nand allow models to respond more responsibly to malicious queries. We emphasize\nthat, with less than 0.2x overhead cost, our approach enables LLMs to assess\nthe safety of both the query and the previously generated tokens at each\nnecessary generating step. Extensive experiments demonstrate that our method\nsignificantly improves the resilience of LLMs against various adversarial\nattacks, offering a promising pathway toward more robust generative AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17072v2",
    "published": "2025-05-19T20:40:46+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13721v1",
    "title": "Non-degenerate SPDC photon-pair source for UV-A illumination",
    "authors": [
      "Preetisha Goswami",
      "Marta Gilaberte Basset",
      "Jorge Fuenzalida",
      "Markus Gr√§fe",
      "Valerio Flavio Gili"
    ],
    "abstract": "We present a frequency-correlated non-degenerate photon-pair source\nconsisting of a second-order nonlinear crystal that generates ultraviolet UV-A\nand infrared light via spontaneous parametric down-conversion. Quantum imaging\nand sensing techniques like quantum imaging with undetected light and quantum\nghost imaging leverage on wavelength correlations between down-converted photon\npairs to decouple sensing and detection wavelengths, thereby exploiting\nestablished camera technology within the visible spectrum. Our results open up\nnovel quantum sensing application scenarios in the ultraviolet domain, with\npotential implications for advancements in biomedical and non-destructive\ntesting fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.13721v1",
    "published": "2025-05-19T20:40:41+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13720v1",
    "title": "Solving Lyapunov equations for electrically driven ternary electrolytes -- application to long-range van der Waals interactions",
    "authors": [
      "Guangle Du",
      "Bing Miao",
      "David S. Dean"
    ],
    "abstract": "Stochastic density functional theory (SDFT) has been widely used to study the\nout of equilibrium properties of electrolyte solutions. Examples include\ninvestigations of electrical conductivity -- both within and beyond linear\nresponse -- and modifications of thermal van der Waals interactions in driven\nelectrolytes. Within the approximation scheme derived from linearizing SDFT for\nfluctuations around mean densities, the steady state correlation functions\nbetween the $N$ ionic species are governed by linear Lyapunov equations of\ndegree $N(N+1)/2$. Consequently, the system's complexity increases\nsignificantly when transitioning from binary to ternary electrolytes, and few\nanalytical results exist for the latter. In this paper, we demonstrate how --\nfor the specific case of electrolytes -- the Lyapunov equations can be reduced\nto a system of $N$ linear equations. We apply this reduction to compute the\nlong-range component of the van der Waals interaction between two slabs\ncontaining a ternary electrolyte under an applied electric field parallel to\nthe slabs. Unlike the binary electrolyte case, we show that the resulting van\nder Waals interaction for a ternary electrolyte depends on the ionic species'\ndiffusion coefficients, highlighting its inherently out of equilibrium nature.",
    "pdf_url": "http://arxiv.org/pdf/2505.13720v1",
    "published": "2025-05-19T20:32:08+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.13719v1",
    "title": "cuHALLaR: A GPU Accelerated Low-Rank Augmented Lagrangian Method for Large-Scale Semidefinite Programming",
    "authors": [
      "Jacob M. Aguirre",
      "Diego Cifuentes",
      "Vincent Guigues",
      "Renato D. C. Monteiro",
      "Victor Hugo Nascimento",
      "Arnesh Sujanani"
    ],
    "abstract": "This paper introduces cuHALLaR, a GPU-accelerated implementation of the\nHALLaR method proposed in Monteiro et al. 2024 for solving large-scale\nsemidefinite programming (SDP) problems. We demonstrate how our Julia-based\nimplementation efficiently uses GPU parallelism through optimization of simple,\nbut key, operations, including linear maps, adjoints, and gradient evaluations.\nExtensive numerical experiments across three SDP problem classes, i.e., maximum\nstable set, matrix completion, and phase retrieval show significant performance\nimprovements over both CPU implementations and existing GPU-based solvers. For\nthe largest instances, cuHALLaR achieves speedups of 30-140x on matrix\ncompletion problems, up to 135x on maximum stable set problems for Hamming\ngraphs with 8.4 million vertices, and 15-47x on phase retrieval problems with\ndimensions up to 3.2 million. Our approach efficiently handles massive problems\nwith dimensions up to (n,m) equal to (8 million, 300 million) with high\nprecision, solving matrix completion instances with over 8 million rows and\ncolumns in just 142 seconds. These results establish cuHALLaR as a very\npromising GPU-based method for solving large-scale semidefinite programs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13719v1",
    "published": "2025-05-19T20:30:56+00:00",
    "categories": [
      "math.OC",
      "90C30, 65K10, 90C26, 90C60, 90C25"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13718v2",
    "title": "Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings",
    "authors": [
      "Safal Shrestha",
      "Minwu Kim",
      "Aadim Nepal",
      "Anubhav Shrestha",
      "Keith Ross"
    ],
    "abstract": "Designing effective reasoning-capable LLMs typically requires training using\nReinforcement Learning with Verifiable Rewards (RLVR) or distillation with\ncarefully curated Long Chain of Thoughts (CoT), both of which depend heavily on\nextensive training data. This creates a major challenge when the amount of\nquality training data is scarce. We propose a sample-efficient, two-stage\ntraining strategy to develop reasoning LLMs under limited supervision. In the\nfirst stage, we \"warm up\" the model by distilling Long CoTs from a toy domain,\nnamely, Knights \\& Knaves (K\\&K) logic puzzles to acquire general reasoning\nskills. In the second stage, we apply RLVR to the warmed-up model using a\nlimited set of target-domain examples. Our experiments demonstrate that this\ntwo-phase approach offers several benefits: $(i)$ the warmup phase alone\nfacilitates generalized reasoning, leading to performance improvements across a\nrange of tasks, including MATH, HumanEval$^{+}$, and MMLU-Pro; $(ii)$ When both\nthe base model and the warmed-up model are RLVR trained on the same small\ndataset ($\\leq100$ examples), the warmed-up model consistently outperforms the\nbase model; $(iii)$ Warming up before RLVR training allows a model to maintain\ncross-domain generalizability even after training on a specific domain; $(iv)$\nIntroducing warmup in the pipeline improves not only accuracy but also overall\nsample efficiency during RLVR training. The results in this paper highlight the\npromise of warmup for building robust reasoning LLMs in data-scarce\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.13718v2",
    "published": "2025-05-19T20:29:15+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13717v1",
    "title": "Quantum state preparation with polynomial resources: Branched-Subspaces Adiabatic Preparation (B-SAP)",
    "authors": [
      "Davide Cugini",
      "Giacomo Guarnieri",
      "Mario Motta",
      "Dario Gerace"
    ],
    "abstract": "Quantum state preparation lies at the heart of quantum computation and\nquantum simulations, enabling the investigation of complex systems of many\nbodies across physics, chemistry, and data science. Although methods such as\nVariational Quantum Algorithms (VQAs) and Adiabatic Preparation (AP) offer\npromising routes, each faces significant challenges. In this work, we introduce\na hybrid algorithm that integrates the conceptual strengths of VQAs and AP,\nenhanced through the use of group-theoretic structures, to efficiently\napproximate ground and excited states of arbitrary many-body Hamiltonians. Our\napproach is validated on the one-dimensional XYZ Heisenberg model with periodic\nboundary conditions across a broad parameters range and system sizes. Given the\nsystem size $L$, we successfully prepare up to $L^2-L+2$ of its lowest\neigenstates with high fidelity, employing quantum circuit depths that scale\nonly polynomially with L. These results highlight the accuracy, efficiency, and\nrobustness of the proposed algorithm, which offers a compelling pathway for the\nactual preparation of targeted quantum states on near-term quantum devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.13717v1",
    "published": "2025-05-19T20:26:35+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13716v1",
    "title": "Orbital Phase-resolved Analysis of X-ray and Gamma-ray Observations of the High-Mass Gamma-ray Binary 4FGL J1405.1-6119",
    "authors": [
      "Alexander Lange",
      "Robin H. D. Corbet",
      "Joel B. Coley",
      "Guillaume Dubus",
      "Jeremy Hare",
      "Nazma Islam",
      "Jonathan Barnes"
    ],
    "abstract": "We present the results of multi-wavelength observations of the High-Mass\nGamma-Ray Binary 4FGL J1405.1-6119. A pair of joint XMM-Newton and NuSTAR\nobservations taken in 2019 (sampling the gamma-ray maximum and X-ray maximum)\ncharacterize the emission of soft and hard X-rays. We find variability of the\nhydrogen column density along our line of sight, $N_{\\rm H}$, and photon index,\n$\\Gamma$, and find no evidence of pulsations in X-rays. We also refine a new\nbest-fit orbital period to $P=13.7157\\pm0.0014$ days, the first orbital\nphase-resolved analysis based on nearly 16 years of Fermi--LAT observations of\n4FGL J1405.1-6119 and the evolution of the spectral shape as a function of\norbital phase. Finally, the X-ray and $\\gamma$-ray spectra for the phases\nsampled in the new X-ray observations can be interpreted in the framework of\nthe intrabinary shock model, previously applied to High-Mass Gamma-Ray binaries\nsuch as LS 5039.",
    "pdf_url": "http://arxiv.org/pdf/2505.13716v1",
    "published": "2025-05-19T20:24:45+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13715v1",
    "title": "Dynamic Bipedal MPC with Foot-level Obstacle Avoidance and Adjustable Step Timing",
    "authors": [
      "Tianze Wang",
      "Christian Hubicki"
    ],
    "abstract": "Collision-free planning is essential for bipedal robots operating within\nunstructured environments. This paper presents a real-time Model Predictive\nControl (MPC) framework that addresses both body and foot avoidance for dynamic\nbipedal robots. Our contribution is two-fold: we introduce (1) a novel\nformulation for adjusting step timing to facilitate faster body avoidance and\n(2) a novel 3D foot-avoidance formulation that implicitly selects swing\ntrajectories and footholds that either steps over or navigate around obstacles\nwith awareness of Center of Mass (COM) dynamics. We achieve body avoidance by\napplying a half-space relaxation of the safe region but introduce a switching\nheuristic based on tracking error to detect a need to change foot-timing\nschedules. To enable foot avoidance and viable landing footholds on all sides\nof foot-level obstacles, we decompose the non-convex safe region on the ground\ninto several convex polygons and use Mixed-Integer Quadratic Programming to\ndetermine the optimal candidate. We found that introducing a soft\nminimum-travel-distance constraint is effective in preventing the MPC from\nbeing trapped in local minima that can stall half-space relaxation methods\nbehind obstacles. We demonstrated the proposed algorithms on multibody\nsimulations on the bipedal robot platforms, Cassie and Digit, as well as\nhardware experiments on Digit.",
    "pdf_url": "http://arxiv.org/pdf/2505.13715v1",
    "published": "2025-05-19T20:24:43+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13714v1",
    "title": "Detection of Hydrocarbons in the Disk around an Actively-Accreting Planetary-Mass Object",
    "authors": [
      "Laura Flagg",
      "Aleks Scholz",
      "V. Almendros-Abad",
      "Ray Jayawardhana",
      "Belinda Damian",
      "Koraljka Muzic",
      "Antonella Natta",
      "Paola Pinilla",
      "Leonardo Testi"
    ],
    "abstract": "We present the 0.6--12-micron spectrum of Cha\\,1107-7626, a 6-10 Jupiter-mass\nfree-floating object in the $\\sim$2\\,Myr-old Chamaeleon-I star-forming region,\nfrom observations with the NIRSpec and MIRI instruments onboard the James Webb\nSpace Telescope. We confirm that Cha\\,1107-7626 is one of the lowest-mass\nobjects known to harbor a dusty disk with infrared excess emission at\nwavelengths beyond 4 microns. Our NIRSpec data, and prior ground-based\nobservations, provide strong evidence for ongoing accretion through Hydrogen\nrecombination lines. In the mid-infrared spectrum, we detect unambiguously\nemission lines caused by methane (CH$_\\mathrm{4}$) and ethylene\n(C$_\\mathrm{2}$H$_\\mathrm{4}$) in its circum-substellar disk. Our findings mean\nthat Cha 1107-7626 is by far the lowest-mass object with hydrocarbons observed\nin its disk. The spectrum of the disk looks remarkably similar to that of\nISO-ChaI 147, a very low mass star with a carbon-rich disk that is 10 to 20\ntimes more massive than Cha\\,1107-7626. The hydrocarbon lines can be accounted\nfor with a model assuming gas temperatures of a few hundred Kelvin in the inner\ndisk. The obvious similarities between the spectra of a low-mass star and a\nplanetary-mass object indicate that the conditions in the inner disks can be\nsimilar across a wide range of central object masses.",
    "pdf_url": "http://arxiv.org/pdf/2505.13714v1",
    "published": "2025-05-19T20:24:33+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13713v1",
    "title": "CHANG-ES: XXXVI. The thin and thick radio discs",
    "authors": [
      "V. Heesen",
      "M. Stein",
      "N. Pourjafari",
      "M. Br√ºggen",
      "J. Stil",
      "J. -T. Li",
      "T. Wiegert",
      "J. Irwin",
      "R. -J. Dettmar",
      "T. A. Porter",
      "Y. Stein"
    ],
    "abstract": "Context. Edge-on spiral galaxies give us an outsiders' view of the radio\nhalo, which envelops these galaxies. The radio halos are caused by extra-planar\ncosmic-ray electrons that emit synchrotron emission in magnetic fields. Aims.\nWe aim to study the origin of radio halos around galaxies and infer the role of\ncosmic-rays in supporting the gaseous discs. We would like to test the\ninfluence of star formation as the main source of cosmic rays as well as other\nfundamental galaxy properties such as mass and size. Methods. We present a\nstudy of radio continuum scale heights in 22 nearby edge-on galaxies from the\nCHANG-ES survey. We employ deep observations with the Jansky Very Large Array\nin the S-band (2-4 GHz), imaging at 7\" angular resolution. We measure scale\nheights in three strips within the effective radio continuum radius, correcting\nfor the influence of angular resolution and inclination angle. We include only\ngalaxies where a distinction between the two disc components can be made in at\nleast one of the strips, providing us with robust measurements of both scale\nheights. Results. We find a strong positive correlation between scale heights\nof the thin and thick discs and star-forming radius as well as star-formation\nrate (SFR); moderately strong correlations are found for the mass surface\ndensity and the ratio of SFR-to-mass surface density; no correlation is found\nwith SFR surface density alone. Yet the SFR surface density plays a role as\nwell: galaxies with high SFR surface densities have a rather roundish shape,\nwhereas galaxies with little star formation show only a relatively small\nvertical extent in comparison to their size. Conclusions. Thick gaseous discs\nare partially supported by cosmic-ray pressure. Our results are a useful\nbenchmark for simulations of galaxy evolution that include cosmic rays.",
    "pdf_url": "http://arxiv.org/pdf/2505.13713v1",
    "published": "2025-05-19T20:23:09+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13712v1",
    "title": "A new scale anomaly in Dirac matter",
    "authors": [
      "Matteo Baggioli",
      "Maxim N. Chernodub",
      "Karl Landsteiner",
      "Alessandro Principi",
      "Mar√≠a A. H. Vozmediano"
    ],
    "abstract": "The dynamics of Dirac semimetals is modeled at low energies by the massless\nDirac Hamiltonian with the Fermi velocity replacing the velocity of light. The\nclassical action is scale invariant. In 3D materials, Coulomb interactions\ninduce a conformal anomaly associated to the charge renormalization already\nknown in quantum field theory. In this work, we describe a new conformal\nanomaly induced by the running of the Fermi velocity that applies to Dirac\nsemimetals in two and three dimensions. The case of graphene is particularly\ninteresting. We analyze the anomaly and explore its thermodynamic and\nhydrodynamic consequences. The anomaly modifies the propagation speed of\nhydrodynamic sound waves, alters the thermodynamic equation of state, and\ninduces a non-vanishing bulk viscosity proportional to the beta function of the\nFermi velocity.",
    "pdf_url": "http://arxiv.org/pdf/2505.13712v1",
    "published": "2025-05-19T20:22:25+00:00",
    "categories": [
      "hep-th",
      "cond-mat.other"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13711v1",
    "title": "An extension of the $r^p$ method for wave equations with scale-critical potentials and first-order terms",
    "authors": [
      "Maxime Van de Moortel"
    ],
    "abstract": "The $r^p$ method, first introduced in [DR10], has become a robust strategy to\nprove decay for wave equations in the context of black holes and beyond. In\nthis note, we propose an extension of this method, which is particularly\nsuitable for proving decay for a general class of wave equations featuring a\nscale-critical time-dependent potential and/or first-order terms of small\namplitude. Our approach consists of absorbing error terms in the $r^p$-weighted\nenergy using a novel Gr\\\"{o}nwall argument, which allows a larger range of $p$\nthan the standard method. A spherically symmetric version of our strategy first\nappeared in [VdM22] in the context of a weakly charged scalar field on a black\nhole whose equations also involve a scale-critical potential.",
    "pdf_url": "http://arxiv.org/pdf/2505.13711v1",
    "published": "2025-05-19T20:22:06+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13710v2",
    "title": "Quantum Computational Unpredictability Entropy and Quantum Leakage Resilience",
    "authors": [
      "Noam Avidan",
      "Rotem Arnon"
    ],
    "abstract": "Computational entropies provide a framework for quantifying uncertainty and\nrandomness under computational constraints. They play a central role in\nclassical cryptography, underpinning the analysis and construction of\nprimitives such as pseudo-random generators, leakage-resilient cryptography,\nand randomness extractors. In the quantum setting, however, computational\nanalogues of entropy remain largely unexplored. In this work, we initiate the\nstudy of quantum computational entropy by defining quantum computational\nunpredictability entropy, a natural generalization of classical\nunpredictability entropy to the quantum setting. Our definition builds on the\noperational interpretation of quantum min-entropy as the optimal guessing\nprobability, while restricting the adversary to efficient guessing strategies.\nWe prove that this entropy satisfies several fundamental properties, including\na leakage chain rule that holds even in the presence of unbounded prior quantum\nside-information. We also show that unpredictability entropy enables\npseudo-randomness extraction against quantum adversaries with bounded\ncomputational power. Together, these results lay a foundation for developing\ncryptographic tools that rely on min-entropy in the quantum computational\nsetting.",
    "pdf_url": "http://arxiv.org/pdf/2505.13710v2",
    "published": "2025-05-19T20:20:30+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.15849v2",
    "title": "What Lives? A meta-analysis of diverse opinions on the definition of life",
    "authors": [
      "Reed Bender",
      "Karina Kofman",
      "Blaise Ag√ºera y Arcas",
      "Michael Levin"
    ],
    "abstract": "The question of \"what is life?\" has challenged scientists and philosophers\nfor centuries, producing an array of definitions that reflect both the mystery\nof its emergence and the diversity of disciplinary perspectives brought to bear\non the question. Despite significant progress in our understanding of\nbiological systems, psychology, computation, and information theory, no single\ndefinition for life has yet achieved universal acceptance. This challenge\nbecomes increasingly urgent as advances in synthetic biology, artificial\nintelligence, and astrobiology challenge our traditional conceptions of what it\nmeans to be alive. We undertook a methodological approach that leverages large\nlanguage models (LLMs) to analyze a set of definitions of life provided by a\ncurated set of cross-disciplinary experts. We used a novel pairwise correlation\nanalysis to map the definitions into distinct feature vectors, followed by\nagglomerative clustering, intra-cluster semantic analysis, and t-SNE projection\nto reveal underlying conceptual archetypes. This methodology revealed a\ncontinuous landscape of the themes relating to the definition of life,\nsuggesting that what has historically been approached as a binary taxonomic\nproblem should be instead conceived as differentiated perspectives within a\nunified conceptual latent space. We offer a new methodological bridge between\nreductionist and holistic approaches to fundamental questions in science and\nphilosophy, demonstrating how computational semantic analysis can reveal\nconceptual patterns across disciplinary boundaries, and opening similar\npathways for addressing other contested definitional territories across the\nsciences.",
    "pdf_url": "http://arxiv.org/pdf/2505.15849v2",
    "published": "2025-05-19T20:17:37+00:00",
    "categories": [
      "q-bio.OT",
      "cs.AI",
      "cs.CY",
      "q-bio.BM",
      "q-bio.CB",
      "q-bio.SC",
      "stat.AP"
    ],
    "primary_category": "q-bio.OT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13709v1",
    "title": "Policy-Driven World Model Adaptation for Robust Offline Model-based Reinforcement Learning",
    "authors": [
      "Jiayu Chen",
      "Aravind Venugopal",
      "Jeff Schneider"
    ],
    "abstract": "Offline reinforcement learning (RL) offers a powerful paradigm for\ndata-driven control. Compared to model-free approaches, offline model-based RL\n(MBRL) explicitly learns a world model from a static dataset and uses it as a\nsurrogate simulator, improving data efficiency and enabling potential\ngeneralization beyond the dataset support. However, most existing offline MBRL\nmethods follow a two-stage training procedure: first learning a world model by\nmaximizing the likelihood of the observed transitions, then optimizing a policy\nto maximize its expected return under the learned model. This objective\nmismatch results in a world model that is not necessarily optimized for\neffective policy learning. Moreover, we observe that policies learned via\noffline MBRL often lack robustness during deployment, and small adversarial\nnoise in the environment can lead to significant performance degradation. To\naddress these, we propose a framework that dynamically adapts the world model\nalongside the policy under a unified learning objective aimed at improving\nrobustness. At the core of our method is a maximin optimization problem, which\nwe solve by innovatively utilizing Stackelberg learning dynamics. We provide\ntheoretical analysis to support our design and introduce computationally\nefficient implementations. We benchmark our algorithm on twelve noisy D4RL\nMuJoCo tasks and three stochastic Tokamak Control tasks, demonstrating its\nstate-of-the-art performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.13709v1",
    "published": "2025-05-19T20:14:33+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13708v1",
    "title": "Robust learning of halfspaces under log-concave marginals",
    "authors": [
      "Jane Lange",
      "Arsen Vasilyan"
    ],
    "abstract": "We say that a classifier is \\emph{adversarially robust} to perturbations of\nnorm $r$ if, with high probability over a point $x$ drawn from the input\ndistribution, there is no point within distance $\\le r$ from $x$ that is\nclassified differently. The \\emph{boundary volume} is the probability that a\npoint falls within distance $r$ of a point with a different label. This work\nstudies the task of computationally efficient learning of hypotheses with small\nboundary volume, where the input is distributed as a subgaussian isotropic\nlog-concave distribution over $\\mathbb{R}^d$.\n  Linear threshold functions are adversarially robust; they have boundary\nvolume proportional to $r$. Such concept classes are efficiently learnable by\npolynomial regression, which produces a polynomial threshold function (PTF),\nbut PTFs in general may have boundary volume $\\Omega(1)$, even for $r \\ll 1$.\n  We give an algorithm that agnostically learns linear threshold functions and\nreturns a classifier with boundary volume $O(r+\\varepsilon)$ at radius of\nperturbation $r$. The time and sample complexity of\n$d^{\\tilde{O}(1/\\varepsilon^2)}$ matches the complexity of polynomial\nregression.\n  Our algorithm augments the classic approach of polynomial regression with\nthree additional steps: a) performing the $\\ell_1$-error regression under noise\nsensitivity constraints, b) a structured partitioning and rounding step that\nreturns a Boolean classifier with error $\\textsf{opt} + O(\\varepsilon)$ and\nnoise sensitivity $O(r+\\varepsilon)$ simultaneously, and c) a local corrector\nthat ``smooths'' a function with low noise sensitivity into a function that is\nadversarially robust.",
    "pdf_url": "http://arxiv.org/pdf/2505.13708v1",
    "published": "2025-05-19T20:12:16+00:00",
    "categories": [
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13707v1",
    "title": "Real-time dynamics with bead-Fourier path integrals I: Bead-Fourier CMD",
    "authors": [
      "Nathan London",
      "Mohammad R. Momeni"
    ],
    "abstract": "Developing new methods for the accurate and efficient calculations of\nreal-time quantum correlation functions is deemed one of the most challenging\nproblems of modern condensed matter theory. Many popular methods, such as\ncentroid molecular dynamics (CMD), make use of Feynman path integrals (PIs) to\nefficiently introduce nuclear quantum effects into classical dynamical\nsimulations. Conventional CMD methods use the discretized form of the PI\nformalism to represent a quantum particle using a series of replicas, or\n\"beads\", connected with harmonic springs to create an imaginary time ring\npolymer. The alternative Fourier PI methodology, instead, represents the\nimaginary time path using a Fourier sine series. Presented as an intermediary\nbetween the two formalisms, bead-Fourier PIs (BF-PIs) have been shown to reduce\nthe number of beads needed to converge equilibrium properties by including a\nfew terms of the Fourier series. Here, a new CMD method is presented where the\neffective potential is calculated using BF-PIs as opposed to the typical\ndiscretized PIs. We demonstrate the accuracy and efficiency of this new BF-CMD\nmethod for a series of 1D model systems and show that at low temperatures, one\ncan achieve a 4-fold reduction in the number of beads with the addition of a\nsingle Fourier component. The developed methodology is general and can be\nextended to other closely related methods, such as ring polymer molecular\ndynamics (RPMD), as well as non-adiabatic PI methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13707v1",
    "published": "2025-05-19T20:12:05+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.other"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13706v1",
    "title": "Are Large Language Models Good at Detecting Propaganda?",
    "authors": [
      "Julia Jose",
      "Rachel Greenstadt"
    ],
    "abstract": "Propagandists use rhetorical devices that rely on logical fallacies and\nemotional appeals to advance their agendas. Recognizing these techniques is key\nto making informed decisions. Recent advances in Natural Language Processing\n(NLP) have enabled the development of systems capable of detecting manipulative\ncontent. In this study, we look at several Large Language Models and their\nperformance in detecting propaganda techniques in news articles. We compare the\nperformance of these LLMs with transformer-based models. We find that, while\nGPT-4 demonstrates superior F1 scores (F1=0.16) compared to GPT-3.5 and Claude\n3 Opus, it does not outperform a RoBERTa-CRF baseline (F1=0.67). Additionally,\nwe find that all three LLMs outperform a MultiGranularity Network (MGN)\nbaseline in detecting instances of one out of six propaganda techniques\n(name-calling), with GPT-3.5 and GPT-4 also outperforming the MGN baseline in\ndetecting instances of appeal to fear and flag-waving.",
    "pdf_url": "http://arxiv.org/pdf/2505.13706v1",
    "published": "2025-05-19T20:11:13+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13705v1",
    "title": "Can thermodynamic equilibrium be established in planet-forming disks?",
    "authors": [
      "Jayatee Kanwar",
      "Peter Woitke",
      "Inga Kamp",
      "Paul Rimmer",
      "Christiane Helling"
    ],
    "abstract": "The inner regions of planet-forming disks are warm and dense. The chemical\nnetworks used for disk modelling so far were developed for a cold and dilute\nmedium and do not include a complete set of pressure-dependent reactions. The\nchemical networks developed for planetary atmospheres include such reactions\nalong with the inverse reactions related to the Gibb's free energies of the\nmolecules. The chemical networks used for disk modelling are thus incomplete in\nthis respect. We want to study whether thermodynamic equilibrium can be\nestablished in a planet-forming disk. We identify the regions in the disk most\nlikely to reach thermodynamic equilibrium and determine the timescale over\nwhich this occurs. We employ the theoretical concepts used in exoplanet\natmosphere chemistry for the disk modelling with PROtoplanetary DIsk MOdel\n({\\sc ProDiMo}). We develop a chemical network called CHemistry Assembled from\nexoplanets and dIsks for Thermodynamic EquilibriA ({\\sc ChaiTea}) that is based\non the UMIST 2022, STAND, and large DIscANAlysis (DIANA) chemical networks. It\nconsists of 239 species. From the STAND network, we adopt the concept of\nreversing all gas-phase reactions based on thermodynamic data. We use\nsingle-point models for a range of gas densities and gas temperatures to verify\nthat the implemented concepts work and thermodynamic equilibrium is achieved in\nthe absence of cosmic rays and photoreactions including radiative associations\nand direct recombinations. We then study the impact of photoreactions and\ncosmic rays that lead to deviations from thermodynamic equilibrium. We explore\nthe chemical relaxation timescales towards thermodynamic equilibrium. Lastly,\nwe study the predicted 2D chemical structure of a typical T\\,Tauri disk when\nusing the new {\\sc ChaiTea} network instead of the large DIANA standard\nnetwork, including photorates, cosmic rays, X-rays, and ice....",
    "pdf_url": "http://arxiv.org/pdf/2505.13705v1",
    "published": "2025-05-19T20:07:07+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13704v1",
    "title": "Nonlinear Nonlocal: Comparing A. O. Barut's Theory to Mine with special emphasis on That Dot on the Screen",
    "authors": [
      "W. David Wick"
    ],
    "abstract": "In the 1980's and 90's, A. O Barut and colleagues developed a nonperturbative\napproach to electrodynamics eschewing so-called ``second-quantization\". Based\non incorporation of self-energy terms, the resulting nonlinear and nonlocal\ntheory explained many well-known phenomena of atomic and radiation physics. In\n2017, this author introduced a nonlinear, nonlocal theory with the intent of\nresolving the Measurement Problem. Barut also suggested that his theory\nresolved such paradoxes. Here I compare the two theories with special attention\nto That Dot on the Screen.",
    "pdf_url": "http://arxiv.org/pdf/2505.13704v1",
    "published": "2025-05-19T20:06:58+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13703v1",
    "title": "A novel model class for bowtie biological networks with universal classification properties",
    "authors": [
      "Charles A. Johnson",
      "Keon Ho",
      "Park",
      "Enoch Yeung"
    ],
    "abstract": "Cell sensory transcription networks are the intracellular computation\nstructure that regulates and drives cellular activity. Activity in these\nnetworks determines the the cell's ability to adapt to changes in its\nenvironment. Resilient cells successfully identify (classify) and appropriately\nrespond to environmental shifts. We present a model for identification and\nresponse to environmental changes in resilient bacteria. This model combines\ntwo known motifs in transcription networks: dense overlapping regulons (DORs)\nand single input modules (SIMs). DORs have the ability to perform cellular\ndecision making and have a network structure similar to that of a shallow\nneural network, with a number of input transcription factors (TFs) mapping to a\ndistinct set of genes. SIMs contain a master TF that simultaneously activates a\nnumber of target genes. Within most observed cell sensory transcription\nnetworks, the master transcription factor of SIMs are output genes of a DOR\ncreating a fan-in-fan-out (bowtie) structure in the transcriptional network. We\nmodel this hybrid network motif (which we call the DOR2SIM motif) with a\nsuperposition of modular nonlinear functions to describe protein signaling in\nthe network and basic mass action kinetics to describe the other chemical\nreactions in this process. We analyze this model's biological feasibility and\ncapacity to perform classification, the first step in adaptation. We provide\nsufficient conditions for models of the DOR2SIM motif to classify constant\n(environmental) inputs. These conditions suggest that generally low monomer\ndegradation rates as well as low expression of source node genes at equilibrium\nin the DOR component enable classification.",
    "pdf_url": "http://arxiv.org/pdf/2505.13703v1",
    "published": "2025-05-19T20:05:26+00:00",
    "categories": [
      "q-bio.MN"
    ],
    "primary_category": "q-bio.MN"
  },
  {
    "id": "http://arxiv.org/abs/2505.13702v1",
    "title": "Unsupervised anomaly detection in MeV ultrafast electron diffraction",
    "authors": [
      "Mariana A. Fazio",
      "Salvador Sosa G√ºitron",
      "Marcus Babzien",
      "Mikhail Fedurin",
      "Junjie Li",
      "Mark Palmer",
      "Sandra S. Biedron",
      "Manel Martinez-Ramon"
    ],
    "abstract": "This study focus in the construction of an unsupervised anomaly detection\nmethodology to detect faulty images in MUED. We believe that unsupervised\ntechniques are the best choice for our purposes because the data used to train\nthe detector does not need to be manually labeled, and instead, the machine is\nintended to detect by itself the anomalies in the dataset, which liberates the\nuser of tedious, time-consuming initial image examination. The structure must,\nadditionally, provide the user with some measure of uncertainty in the\ndetection, so the user can take decisions based on this measure.",
    "pdf_url": "http://arxiv.org/pdf/2505.13702v1",
    "published": "2025-05-19T20:05:24+00:00",
    "categories": [
      "cs.LG",
      "physics.ins-det"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13701v1",
    "title": "The plunging region of a thin accretion disc around a Schwarzschild black hole",
    "authors": [
      "Jake Rule",
      "Andrew Mummery",
      "Steven Balbus",
      "James Stone",
      "Lizhong Zhang"
    ],
    "abstract": "A set of analytic solutions for the plunging region thermodynamics have been\ndeveloped recently under the assumption that the fluid undergoes a\ngravity-dominated geodesic plunge into the black hole. We test this model\nagainst a dedicated 3D global GRMHD simulation of a thin accretion disc around\na Schwarzschild black hole using the code AthenaK. Provided that we account for\nnon-adiabatic heating in the energetics, plausibly from grid-scale magnetic\ndissipation, we find an excellent agreement between the analytic model and the\nsimulated quantities. These results are particularly important for existing and\nfuture electromagnetic black hole spin measurements, many of which do not to\ninclude the plunging fluid in their emission modelling. This exclusion\ntypically stems from the assumption of a zero-stress boundary condition at the\nISCO, forcing all thermodynamic quantities to vanish. Instead, we find a\nnon-zero $\\delta_\\mathcal{J}\\approx 5.3 \\%$ drop in the angular momentum over\nthe plunging region, which is consistent with both prior simulations and\nobservations. We demonstrate that this stress is small enough for the dynamics\nof the fluid in the plunging region to be well-described by geodesic\ntrajectories, yet large enough to cause measurable dissipation near to the ISCO\n- keeping thermodynamic quantities from vanishing. In the plunging region,\nconstant $\\alpha$-disc models are a physically inappropriate framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.13701v1",
    "published": "2025-05-19T20:03:53+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13700v1",
    "title": "New insight into the variability of the Be star $œÄ$ Aquarii: Determination of stellar and disk parameters",
    "authors": [
      "D. Concha",
      "C. Arcos",
      "D. Turis-Gallo",
      "T. B. Souza",
      "M. Cur√©",
      "R. S. Levenhagen",
      "I. Araya"
    ],
    "abstract": "The Be star $\\pi$ Aquarii shows peculiar $\\gamma$ Cas-type X-ray emission,\nlikely caused by its outer disk interacting with a low-mass companion, probably\na white dwarf. We study the long-term variability of its optical spectra to\nderive stellar and disk parameters during major changes. We identify and\nanalyze Balmer, helium, silicon, and iron emission lines at selected epochs.\nStellar parameters were derived using atmosphere models, considering oblate\ngeometry due to fast rotation. Disk properties were constrained through\nH$\\alpha$ line modeling using a viscous decretion disk model. The H$\\alpha$\nline evolved from shell to double-, triple-peaked, and flat-topped profiles. On\nDec 22, 2001, the disk showed a low-intensity shell profile and fast density\ndecay, indicating a small disk. From 2011 to 2014, the disk decayed slowly,\nthen grew significantly until Nov 2022, increasing its H$\\alpha$ equivalent\nwidth 18-fold and reaching an emitting region of ~65 solar radii. The\ninclination changed by ~10 degrees over 20 years, suggesting a precessing disk.\nThe FeII 5018 A line traces a larger region than H$\\alpha$ and is the only FeII\nline with a distinct profile. We conclude $\\pi$ Aquarii is part of a misaligned\nbinary system, with the white dwarf crossing the disk twice per orbit,\ncapturing material, and enhancing X-ray emission.",
    "pdf_url": "http://arxiv.org/pdf/2505.13700v1",
    "published": "2025-05-19T20:02:39+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13699v1",
    "title": "A 2-torsion invariant of 2-knots",
    "authors": [
      "Ryan Budney"
    ],
    "abstract": "In this paper we describe what should perhaps be called a `type-2' Vassiliev\ninvariant of knots S^2 -> S^4. We give a formula for an invariant of 2-knots,\ntaking values in Z_2 that can be computed in terms of the double-point diagram\nof the knot. The double-point diagram is a collection of curves and\ndiffeomorphisms of curves, in the domain S^2, that describe the crossing data\nwith respect to a projection, analogous to a chord diagram for a projection of\na classical knot S^1 -> S^3. Our formula turns the computation of the invariant\ninto a planar geometry problem. More generally, we describe a numerical\ninvariant of families of knots S^j -> S^n, for all n >= j+2 and j >= 1. In the\nco-dimension two case n=j+2 the invariant is an isotopy invariant, and either\ntakes values in Z or Z_2 depending on a parity issue.",
    "pdf_url": "http://arxiv.org/pdf/2505.13699v1",
    "published": "2025-05-19T20:02:16+00:00",
    "categories": [
      "math.GT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13698v1",
    "title": "Finiteness of Free Algebras of Modular Forms on Unitary Groups",
    "authors": [
      "Yota Maeda",
      "Kazuma Ohara"
    ],
    "abstract": "Classical results on the classification of reflections in an arithmetic\nsubgroup $\\Gamma$ imply that if the graded algebra of modular forms\n$M_*(\\Gamma)$ is freely generated, then $\\Gamma$ must be an arithmetic subgroup\nof either the orthogonal group $\\operatorname{O}^+(2,n)$ or the unitary group\n$\\operatorname{U}(1,n)$. Vinberg and Schwarzman showed that in the orthogonal\ncase, if $n>10$, then it is never free. In this paper, we investigate the\nremaining unitary case and prove that, up to scaling, there are only finitely\nmany isometry classes of Hermitian lattices of signature $(1, n)$ with $n > 2$\nover imaginary quadratic fields with odd discriminant that admit a free algebra\nof modular forms. In particular, when $n>99$ (except over\n$\\mathbb{Q}(\\sqrt{-3})$, where we require $n > 154$), the graded algebra\n$M_*(\\Gamma)$ is never free for any arithmetic subgroup\n$\\Gamma<\\operatorname{U}(1,n)$, thereby partially confirming a conjecture by\nWang and Williams. As a byproduct, we also establish a finiteness result for\nreflective modular forms. In the course of this proof, we derive a formula for\nthe covolume of an arithmetic subgroup of a special unitary group, presented as\nthe stabiliser of a Hermitian lattice, which generalises Prasad's volume\nformula for principal arithmetic subgroups in the case of special unitary\ngroups.",
    "pdf_url": "http://arxiv.org/pdf/2505.13698v1",
    "published": "2025-05-19T20:00:16+00:00",
    "categories": [
      "math.NT",
      "math.AG",
      "11F55, 22E40, 20G25, 11E39, 11G18"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13697v2",
    "title": "RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs",
    "authors": [
      "Soumya Rani Samineni",
      "Durgesh Kalwar",
      "Karthik Valmeekam",
      "Kaya Stechly",
      "Subbarao Kambhampati"
    ],
    "abstract": "Reinforcement learning-based post-training of large language models (LLMs)\nhas recently gained attention, particularly following the release of DeepSeek\nR1, which applied GRPO for fine-tuning. Amid the growing hype around improved\nreasoning abilities attributed to RL post-training, we critically examine the\nformulation and assumptions underlying these methods. We start by highlighting\nthe popular structural assumptions made in modeling LLM training as a Markov\nDecision Process (MDP), and show how they lead to a degenerate MDP that doesn't\nquite need the RL/GRPO apparatus. The two critical structural assumptions\ninclude (1) making the MDP states be just a concatenation of the actions-with\nstates becoming the context window and the actions becoming the tokens in LLMs\nand (2) splitting the reward of a state-action trajectory uniformly across the\ntrajectory. Through a comprehensive analysis, we demonstrate that these\nsimplifying assumptions make the approach effectively equivalent to an\noutcome-driven supervised learning. Our experiments on benchmarks including\nGSM8K and Countdown using Qwen-2.5 base models show that iterative supervised\nfine-tuning, incorporating both positive and negative samples, achieves\nperformance comparable to GRPO-based training. We will also argue that the\nstructural assumptions indirectly incentivize the RL to generate longer\nsequences of intermediate tokens-which in turn feeds into the narrative of \"RL\ngenerating longer thinking traces.\" While RL may well be a very useful\ntechnique for improving the reasoning abilities of LLMs, our analysis shows\nthat the simplistic structural assumptions made in modeling the underlying MDP\nrender the popular LLM RL frameworks and their interpretations questionable.",
    "pdf_url": "http://arxiv.org/pdf/2505.13697v2",
    "published": "2025-05-19T19:57:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13696v1",
    "title": "Building spatial world models from sparse transitional episodic memories",
    "authors": [
      "Zizhan He",
      "Maxime Daigle",
      "Pouya Bashivan"
    ],
    "abstract": "Many animals possess a remarkable capacity to rapidly construct flexible\nmental models of their environments. These world models are crucial for\nethologically relevant behaviors such as navigation, exploration, and planning.\nThe ability to form episodic memories and make inferences based on these sparse\nexperiences is believed to underpin the efficiency and adaptability of these\nmodels in the brain. Here, we ask: Can a neural network learn to construct a\nspatial model of its surroundings from sparse and disjoint episodic memories?\nWe formulate the problem in a simulated world and propose a novel framework,\nthe Episodic Spatial World Model (ESWM), as a potential answer. We show that\nESWM is highly sample-efficient, requiring minimal observations to construct a\nrobust representation of the environment. It is also inherently adaptive,\nallowing for rapid updates when the environment changes. In addition, we\ndemonstrate that ESWM readily enables near-optimal strategies for exploring\nnovel environments and navigating between arbitrary points, all without the\nneed for additional training.",
    "pdf_url": "http://arxiv.org/pdf/2505.13696v1",
    "published": "2025-05-19T19:56:24+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13695v1",
    "title": "Large-scale quantum reservoir computing using a Gaussian Boson Sampler",
    "authors": [
      "Valeria Cimini",
      "Mandar M. Sohoni",
      "Federico Presutti",
      "Benjamin K. Malia",
      "Shi-Yuan Ma",
      "Ryotatsu Yanagimoto",
      "Tianyu Wang",
      "Tatsuhiro Onodera",
      "Logan G. Wright",
      "Peter L. McMahon"
    ],
    "abstract": "A Gaussian boson sampler (GBS) is a special-purpose quantum computer that can\nbe practically realized at large scale in optics. Here we report on experiments\nin which we used a frequency-multiplexed GBS with $>400$ modes as the reservoir\nin the quantum-machine-learning approach of quantum reservoir computing. We\nevaluated the accuracy of our GBS-based reservoir computer on a variety of\nbenchmark tasks, including spoken-vowels classification and MNIST\nhandwritten-digit classification. We found that when the reservoir computer was\ngiven access to the correlations between measured modes of the GBS, the\nachieved accuracies were the same or higher than when it was only given access\nto the mean photon number in each mode -- and in several cases the advantage in\naccuracy from using the correlations was greater than 20 percentage points.\nThis provides experimental evidence in support of theoretical predictions that\naccess to correlations enhances the power of quantum reservoir computers. We\nalso tested our reservoir computer when operating the reservoir with various\nsources of classical rather than squeezed (quantum) light and found that using\nsqueezed light consistently resulted in the highest (or tied highest, for\nsimple tasks) accuracies. Our work experimentally establishes that a GBS can be\nan effective reservoir for quantum reservoir computing and provides a practical\nplatform for experimentally exploring the role of quantumness and correlations\nin quantum machine learning at very large system sizes.",
    "pdf_url": "http://arxiv.org/pdf/2505.13695v1",
    "published": "2025-05-19T19:55:44+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13694v1",
    "title": "A Systematic Review and Taxonomy for Privacy Breach Classification: Trends, Gaps, and Future Directions",
    "authors": [
      "Clint Fuchs",
      "John D. Hastings"
    ],
    "abstract": "In response to the rising frequency and complexity of data breaches and\nevolving global privacy regulations, this study presents a comprehensive\nexamination of academic literature on the classification of privacy breaches\nand violations between 2010-2024. Through a systematic literature review, a\ncorpus of screened studies was assembled and analyzed to identify primary\nresearch themes, emerging trends, and gaps in the field. A novel taxonomy is\nintroduced to guide efforts by categorizing research efforts into seven\ndomains: breach classification, report classification, breach detection, threat\ndetection, breach prediction, risk analysis, and threat classification. An\nanalysis reveals that breach classification and detection dominate the\nliterature, while breach prediction and risk analysis have only recently\nemerged in the literature, suggesting opportunities for potential research\nimpacts. Keyword and phrase frequency analysis reveal potentially underexplored\nareas, including location privacy, prediction models, and healthcare data\nbreaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.13694v1",
    "published": "2025-05-19T19:52:21+00:00",
    "categories": [
      "cs.CR",
      "C.2.0; D.4.6; K.6.5; K.4.1; H.3.3"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13693v1",
    "title": "HarmonE: A Self-Adaptive Approach to Architecting Sustainable MLOps",
    "authors": [
      "Hiya Bhatt",
      "Shaunak Biswas",
      "Srinivasan Rakhunathan",
      "Karthik Vaidhyanathan"
    ],
    "abstract": "Machine Learning Enabled Systems (MLS) are becoming integral to real-world\napplications, but ensuring their sustainable performance over time remains a\nsignificant challenge. These systems operate in dynamic environments and face\nruntime uncertainties like data drift and model degradation, which affect the\nsustainability of MLS across multiple dimensions: technical, economical,\nenvironmental, and social. While Machine Learning Operations (MLOps) addresses\nthe technical dimension by streamlining the ML model lifecycle, it overlooks\nother dimensions. Furthermore, some traditional practices, such as frequent\nretraining, incur substantial energy and computational overhead, thus\namplifying sustainability concerns. To address them, we introduce HarmonE, an\narchitectural approach that enables self-adaptive capabilities in MLOps\npipelines using the MAPE-K loop. HarmonE allows system architects to define\nexplicit sustainability goals and adaptation thresholds at design time, and\nperforms runtime monitoring of key metrics, such as prediction accuracy, energy\nconsumption, and data distribution shifts, to trigger appropriate adaptation\nstrategies. We validate our approach using a Digital Twin (DT) of an\nIntelligent Transportation System (ITS), focusing on traffic flow prediction as\nour primary use case. The DT employs time series ML models to simulate\nreal-time traffic and assess various flow scenarios. Our results show that\nHarmonE adapts effectively to evolving conditions while maintaining accuracy\nand meeting sustainability goals.",
    "pdf_url": "http://arxiv.org/pdf/2505.13693v1",
    "published": "2025-05-19T19:51:30+00:00",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13692v1",
    "title": "Effects of Ultraviolet Radiation on Sub-Neptune Exoplanet Hazes Through Laboratory Experiments",
    "authors": [
      "Lori Huseby",
      "Sarah E. Moran",
      "Neil Pearson",
      "Tiffany Kataria",
      "Chao He",
      "Cara Pesciotta",
      "Sarah M. H√∂rst",
      "Pierre Haenecour",
      "Travis Barman",
      "Vishnu Reddy",
      "Nikole K. Lewis",
      "V√©ronique Vuitton"
    ],
    "abstract": "Temperate sub-Neptune exoplanets could contain large inventories of water in\nvarious phases, such as water-worlds with water-rich atmospheres or even\noceans. Both space-based and ground-based observations have shown that many\nexoplanets likely also contain photochemically-generated hazes. Haze particles\nare a key source of organic matter and may impact the evolution or origin of\nlife. In addition, haze layers could provide a mechanism for lower-atmospheric\nshielding and ultimately atmospheric retention. Often orbiting close to M-dwarf\nstars, these planets receive large amounts of radiation, especially during\nflaring events, which may strip away their atmospheres. M-dwarf stars are known\nto have higher stellar activity than other types of stars, and stellar flares\nhave the potential to accelerate atmospheric escape. In this work, we present\nresults on laboratory investigations of UV radiation effects simulating two\ndifferent stellar flare energies on laboratory-produced exoplanet hazes made\nunder conditions analogous to water-world atmospheres. We find that both\nsimulated flares altered the overall transmittance and reflectance of the\nhazes, and higher energy \"flares\" make those alterations more pronounced. On a\nlarger scale, these laboratory-made hazes show potential signs of degradation\nover the simulated flaring period. Our results provide insight into the effects\nthat stellar flaring events have on potential exoplanet haze composition and\nthe ability for water-world-like exoplanets to retain their atmospheres.",
    "pdf_url": "http://arxiv.org/pdf/2505.13692v1",
    "published": "2025-05-19T19:51:01+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13691v1",
    "title": "Unified nonparametric equation-of-state inference from the neutron-star crust to perturbative-QCD densities",
    "authors": [
      "Eliot Finch",
      "Isaac Legred",
      "Katerina Chatziioannou",
      "Reed Essick",
      "Sophia Han",
      "Phillippe Landry"
    ],
    "abstract": "Perturbative quantum chromodynamics (pQCD), while valid only at densities\nexceeding those found in the cores of neutron stars, could provide constraints\non the dense-matter equation of state (EOS). In this work, we examine the\nimpact of pQCD information on the inference of the EOS using a nonparametric\nframework based on Gaussian processes (GPs). We examine the application of pQCD\nconstraints through a \"pQCD likelihood,\" and verify the findings of previous\nworks; namely, a softening of the EOS at the central densities of the most\nmassive neutron stars and a reduction in the maximum neutron-star mass.\nAlthough the pQCD likelihood can be easily integrated into existing EOS\ninference frameworks, this approach requires an arbitrary selection of the\ndensity at which the constraints are applied. The EOS behavior is also treated\ndifferently either side of the chosen density. To mitigate these issues, we\nextend the EOS model to higher densities, thereby constructing a \"unified\"\ndescription of the EOS from the neutron-star crust to densities relevant for\npQCD. In this approach the pQCD constraints effectively become part of the\nprior. Since the EOS is unconstrained by any calculation or data between the\ndensities applicable to neutron stars and pQCD, we argue for maximum modeling\nflexibility in that regime. We compare the unified EOS with the traditional\npQCD likelihood, and although we confirm the EOS softening, we do not see a\nreduction in the maximum neutron-star mass or any impact on macroscopic\nobservables. Though residual model dependence cannot be ruled out, we find that\npQCD suggests the speed of sound in the densest neutron-star cores has already\nstarted decreasing toward the asymptotic limit; we find that the speed of sound\nsquared at the center of the most massive neutron star has an upper bound of\n$\\sim 0.5$ at the $90\\%$ level.",
    "pdf_url": "http://arxiv.org/pdf/2505.13691v1",
    "published": "2025-05-19T19:48:17+00:00",
    "categories": [
      "nucl-th",
      "astro-ph.HE",
      "gr-qc"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13690v1",
    "title": "Reduced Muscle Fatigue Using Continuous Subthreshold Kilohertz Stimulation of Peripheral Nerves",
    "authors": [
      "Long Meng",
      "Paola Terolli",
      "Xiaogang Hu"
    ],
    "abstract": "Functional electrical stimulation (FES) is a prevalent technique commonly\nused to activate muscles in individuals with neurological disorders.\nTraditional FES strategies predominantly utilize low-frequency (LF)\nstimulation, which evokes synchronous action potentials, leading to rapid\nmuscle fatigue. To address these limitations, we introduced a subthreshold\nhigh-frequency (HF) stimulation method that employed continuous,\ncharge-balanced subthreshold current pulses at kilohertz frequencies, designed\nto evoke motor unit (MU) activation similar to voluntary activation. We\nevaluated the effectiveness of HF stimulation on the reduction of muscle\nfatigue across different force levels (10 %, 25 %, and 40 % of maximum force).\nThe HF stimulation utilized continuous charge-balanced, short pulses of 80\n{\\mu}s (at a 10 kHz frequency) targeted the ulnar/median nerve bundles. We\ncompared the fatigue effects with conventional LF stimulation and voluntary\nmuscle contractions. Our results indicated that HF stimulation maintained more\nsustained force outputs and muscle activation over a prolonged time compared\nwith LF stimulation. The HF stimulation also evoked a more dispersed muscle\nactivation pattern, similar to voluntary muscle contractions. These findings\nsuggest that HF stimulation can significantly enhance the sustainability of\nmuscle contractions and reduce muscle fatigue, potentially improving the\nefficacy and applicability of FES in clinical and home-based settings for\nindividuals with neurological impairments.",
    "pdf_url": "http://arxiv.org/pdf/2505.13690v1",
    "published": "2025-05-19T19:45:38+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13689v1",
    "title": "Piecewise linear circle maps and conjugation to rigid rational rotations",
    "authors": [
      "Paul Glendinning",
      "Siyuan Ma",
      "James Montaldi"
    ],
    "abstract": "Criteria for piecewise linear circle homeomorphisms to be conjugate to a\nrigid rotation, $x\\to x+\\omega~({\\rm mod}~1)$, with rational rotation number\n$\\omega$ are given. The consequences of the existence of such maps in families\nof maps is considered and the results are illustrated using two examples:\nHerman's classic family of piecewise linear maps with two linear components,\nand a map derived from geometric optics which has four components. These\nresults show how results for piecewise smooth circle homeomorphisms with\nirrational rotation numbers have natural correspondences with the case of\nrational rotation numbers for piecewise linear maps. In natural families of\nmaps the existence of a parameter value at which the map is conjugate to a\nrigid rotation implies linear scaling of the rotation number in a neighbourhood\nof the critical parameter value and no mode-locked intervals, in contrast to\nthe behaviour of generic families of circle maps.",
    "pdf_url": "http://arxiv.org/pdf/2505.13689v1",
    "published": "2025-05-19T19:45:27+00:00",
    "categories": [
      "math.DS",
      "37E45, 39A23"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13688v3",
    "title": "Gaze-Enhanced Multimodal Turn-Taking Prediction in Triadic Conversations",
    "authors": [
      "Seongsil Heo",
      "Calvin Murdock",
      "Michael Proulx",
      "Christi Miller"
    ],
    "abstract": "Turn-taking prediction is crucial for seamless interactions. This study\nintroduces a novel, lightweight framework for accurate turn-taking prediction\nin triadic conversations without relying on computationally intensive methods.\nUnlike prior approaches that either disregard gaze or treat it as a passive\nsignal, our model integrates gaze with speaker localization, structuring it\nwithin a spatial constraint to transform it into a reliable predictive cue.\nLeveraging egocentric behavioral cues, our experiments demonstrate that\nincorporating gaze data from a single-user significantly improves prediction\nperformance, while gaze data from multiple-users further enhances it by\ncapturing richer conversational dynamics. This study presents a lightweight and\nprivacy-conscious approach to support adaptive, directional sound control,\nenhancing speech intelligibility in noisy environments, particularly for\nhearing assistance in smart glasses.",
    "pdf_url": "http://arxiv.org/pdf/2505.13688v3",
    "published": "2025-05-19T19:43:58+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13687v1",
    "title": "Revenue-Optimal Efficient Mechanism Design with General Type Spaces",
    "authors": [
      "Siddharth Prasad",
      "Maria-Florina Balcan",
      "Tuomas Sandholm"
    ],
    "abstract": "We derive the revenue-optimal efficient (welfare-maximizing) mechanism in a\ngeneral multidimensional mechanism design setting when type spaces -- that is,\nthe underlying domains from which agents' values come from -- can capture\narbitrarily complex informational constraints about the agents. Type spaces can\nencode information about agents representing, for example, machine learning\npredictions of agent behavior, institutional knowledge about feasible market\noutcomes (such as item substitutability or complementarity in auctions), and\ncorrelations between multiple agents. Prior work has only dealt with connected\ntype spaces, which are not expressive enough to capture many natural kinds of\nconstraints such as disjunctive constraints. We provide two characterizations\nof the optimal mechanism based on allocations and connected components; both\nmake use of an underlying network flow structure to the mechanism design. Our\nresults significantly generalize and improve the prior state of the art in\nrevenue-optimal efficient mechanism design. They also considerably expand the\nscope of what forms of agent information can be expressed and used to improve\nrevenue.",
    "pdf_url": "http://arxiv.org/pdf/2505.13687v1",
    "published": "2025-05-19T19:40:23+00:00",
    "categories": [
      "cs.GT",
      "econ.TH"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13686v1",
    "title": "An Open Quantum System of Coupled Rotors",
    "authors": [
      "V V Sreedhar",
      "Ankit Yadav"
    ],
    "abstract": "A quantum mechanical system of two coupled rotors (particles constrained to\nmove on a circle) is studied from an open quantum systems point of view. One of\nthe rotors is integrated out and the reduced density operator of the other\nrotor is studied. It's eigenvalues are worked out explicitly using the\nproperties of Mathieu functions, and the von Neumann entropy, which is a\nstandard measure of entanglement, is computed in terms of the Fourier\ncoefficients defining the Mathieu functions. Furthermore, upon introducing a\ntime-periodic delta kick and making one of the rotors much heavier than the\nother, the two-rotor system can be interpreted as a system-bath model, allowing\nus to introduce a series of approximations to derive a master equation of the\nLindblad type describing the time-evolution of the reduced density operator.",
    "pdf_url": "http://arxiv.org/pdf/2505.13686v1",
    "published": "2025-05-19T19:39:15+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13685v1",
    "title": "Effect of Plasma Treatment on the Spontaneous Formation and Morphology of Surface Nanobubbles on Silicon",
    "authors": [
      "Anayet Ullah Siddique",
      "Roseanne Warren"
    ],
    "abstract": "The formation of gaseous, spherical cap-shaped domains (so-called \"surface\nnanobubbles\") at the solid-liquid interface is a topic of fundamental interest\ndue to the possible effects of nanobubbles on surface cleaning, wetting, and\nnanoscale patterning. This work investigates the spontaneous formation of\nsurface nanobubbles on oxygen plasma-treated Si by PeakForce quantitative\nnanomechanics (PFQNM) imaging, X-ray photoelectron spectroscopy, and water\ncontact angle measurements. Large quantities of surface nanobubbles with sub-10\nnm height and sub-100 nm base width are observed on oxygen plasma-treated Si\nsurfaces that have been \"aged\" in atmospheric conditions (stored in a plastic\nwafer container). Several days of aging time are required for surface\nnanobubbles to form on oxygen plasma-treated Si, at which point the bubbles are\nremarkably consistent in their properties across samples aged 5-12 days. The\npresence of surface nanobubbles on plasma-treated aged Si surfaces runs\ncontrary to prior reports of infrequent nanobubble formation on Si/SiOx.\nSurface characterization supports a theory of post-plasma atmospheric\nhydrocarbon adsorption inducing changes in Si-wetting behavior to a sufficient\nextent that nanobubble formation can occur. The results are of importance in\nSi-based fabrication processes employing oxygen plasma treatment with\nsubsequent DI water immersion.",
    "pdf_url": "http://arxiv.org/pdf/2505.13685v1",
    "published": "2025-05-19T19:39:13+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.14725v1",
    "title": "HR-VILAGE-3K3M: A Human Respiratory Viral Immunization Longitudinal Gene Expression Dataset for Systems Immunity",
    "authors": [
      "Xuejun Sun",
      "Yiran Song",
      "Xiaochen Zhou",
      "Ruilie Cai",
      "Yu Zhang",
      "Xinyi Li",
      "Rui Peng",
      "Jialiu Xie",
      "Yuanyuan Yan",
      "Muyao Tang",
      "Prem Lakshmanane",
      "Baiming Zou",
      "James S. Hagood",
      "Raymond J. Pickles",
      "Didong Li",
      "Fei Zou",
      "Xiaojing Zheng"
    ],
    "abstract": "Respiratory viral infections pose a global health burden, yet the cellular\nimmune responses driving protection or pathology remain unclear. Natural\ninfection cohorts often lack pre-exposure baseline data and structured temporal\nsampling. In contrast, inoculation and vaccination trials generate insightful\nlongitudinal transcriptomic data. However, the scattering of these datasets\nacross platforms, along with inconsistent metadata and preprocessing procedure,\nhinders AI-driven discovery. To address these challenges, we developed the\nHuman Respiratory Viral Immunization LongitudinAl Gene Expression\n(HR-VILAGE-3K3M) repository: an AI-ready, rigorously curated dataset that\nintegrates 14,136 RNA-seq profiles from 3,178 subjects across 66 studies\nencompassing over 2.56 million cells. Spanning vaccination, inoculation, and\nmixed exposures, the dataset includes microarray, bulk RNA-seq, and single-cell\nRNA-seq from whole blood, PBMCs, and nasal swabs, sourced from GEO, ImmPort,\nand ArrayExpress. We harmonized subject-level metadata, standardized outcome\nmeasures, applied unified preprocessing pipelines with rigorous quality\ncontrol, and aligned all data to official gene symbols. To demonstrate the\nutility of HR-VILAGE-3K3M, we performed predictive modeling of vaccine\nresponders and evaluated batch-effect correction methods. Beyond these initial\ndemonstrations, it supports diverse systems immunology applications and\nbenchmarking of feature selection and transfer learning algorithms. Its scale\nand heterogeneity also make it ideal for pretraining foundation models of the\nhuman immune response and for advancing multimodal learning frameworks. As the\nlargest longitudinal transcriptomic resource for human respiratory viral\nimmunization, it provides an accessible platform for reproducible AI-driven\nresearch, accelerating systems immunology and vaccine development against\nemerging viral threats.",
    "pdf_url": "http://arxiv.org/pdf/2505.14725v1",
    "published": "2025-05-19T19:37:49+00:00",
    "categories": [
      "q-bio.GN",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.13684v1",
    "title": "Smooth Fano 3-folds satisfying Condition (A)",
    "authors": [
      "Hamid Abban",
      "Ivan Cheltsov",
      "Takashi Kishimoto",
      "Frederic Mangolte"
    ],
    "abstract": "A smooth variety is said to satisfy Condition (A) if every finite abelian\nsubgroup of its automorphism group has a fixed point. We classify smooth Fano\n3-folds that satisfy Condition (A).",
    "pdf_url": "http://arxiv.org/pdf/2505.13684v1",
    "published": "2025-05-19T19:32:56+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13683v1",
    "title": "Genesis: A Compiler Framework for Hamiltonian Simulation on Hybrid CV-DV Quantum Computers",
    "authors": [
      "Zihan Chen",
      "Jiakang Li",
      "Minghao Guo",
      "Henry Chen",
      "Zirui Li",
      "Joel Bierman",
      "Yipeng Huang",
      "Huiyang Zhou",
      "Yuan Liu",
      "Eddy Z. Zhang"
    ],
    "abstract": "This paper introduces Genesis, the first compiler designed to support\nHamiltonian Simulation on hybrid continuous-variable (CV) and discrete-variable\n(DV) quantum computing systems. Genesis is a two-level compilation system. At\nthe first level, it decomposes an input Hamiltonian into basis gates using the\nnative instruction set of the target hybrid CV-DV quantum computer. At the\nsecond level, it tackles the mapping and routing of qumodes/qubits to implement\nlong-range interactions for the gates decomposed from the first level. Rather\nthan a typical implementation that relies on SWAP primitives similar to\nqubit-based (or DV-only) systems, we propose an integrated design of\nconnectivity-aware gate synthesis and beamsplitter SWAP insertion tailored for\nhybrid CV-DV systems. We also introduce an OpenQASM-like domain-specific\nlanguage (DSL) named CVDV-QASM to represent Hamiltonian in terms of\nPauli-exponentials and basic gate sequences from the hybrid CV-DV gate set.\nGenesis has successfully compiled several important Hamiltonians, including the\nBose-Hubbard model, $\\mathbb{Z}_2-$Higgs model, Hubbard-Holstein model,\nHeisenberg model and Electron-vibration coupling Hamiltonians, which are\ncritical in domains like quantum field theory, condensed matter physics, and\nquantum chemistry. Our implementation is available at\nGenesis-CVDV-Compiler(https://github.com/ruadapt/Genesis-CVDV-Compiler).",
    "pdf_url": "http://arxiv.org/pdf/2505.13683v1",
    "published": "2025-05-19T19:32:06+00:00",
    "categories": [
      "quant-ph",
      "cs.AR",
      "cs.PL"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13682v2",
    "title": "On the Sign of the Casimir Force Between Two Bodies Coupled to a Dirac field",
    "authors": [
      "Aitor Fern√°ndez",
      "C√©sar D. Fosco",
      "Guillermo Hansen"
    ],
    "abstract": "We apply the result of Kenneth and I. Klich, Phys. Rev. Lett.97, 160401\n(2006) to derive a theorem for two objects coupled to a Dirac field. We\ndemonstrate that a sufficient condition for the Casimir interaction to be\nrepulsive, is for their geometric configuration to be odd under the same\nreflection operation considered in that work.",
    "pdf_url": "http://arxiv.org/pdf/2505.13682v2",
    "published": "2025-05-19T19:31:39+00:00",
    "categories": [
      "hep-th",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13681v1",
    "title": "Entropic limitations on fixed causal order",
    "authors": [
      "Matheus Capela",
      "Kaumudibikash Goswami"
    ],
    "abstract": "Quantum processes can exhibit scenarios beyond a fixed order of events. We\npropose information inequalities that, when violated, constitute sufficient\nconditions to certify quantum processes without a fixed causal order --\ncausally separable or indefinite causal ordered processes. The inequalities\nhold valid for a vast class of information measures. Nevertheless, we take\nunder scrutiny the von Neumann, $\\alpha-$R\\'enyi entropies with parameter\n$\\alpha \\in [1/2,1) \\cup (1,\\infty)$, and max- and min-entropies. We also\ndiscuss how the strong subadditivity of quantum (von Neumann) entropy, used\nalong with the information inequality developed here, implies relevant\nwitnesses of causally separable and indefinite causal ordered processes in\nmarginal scenarios. Importantly, we show the violation of these inequalities\nfor the quantum switch, a paradigmatic example of a process with indefinite\ncausal order. Our approach contributes to the important research direction of\ninformation-theoretic characterization of quantum processes beyond fixed causal\norders.",
    "pdf_url": "http://arxiv.org/pdf/2505.13681v1",
    "published": "2025-05-19T19:31:18+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13680v1",
    "title": "Weakest Bidder Types and New Core-Selecting Combinatorial Auctions",
    "authors": [
      "Siddharth Prasad",
      "Maria-Florina Balcan",
      "Tuomas Sandholm"
    ],
    "abstract": "Core-selecting combinatorial auctions are popular auction designs that\nconstrain prices to eliminate the incentive for any group of bidders -- with\nthe seller -- to renegotiate for a better deal. They help overcome the\nlow-revenue issues of classical combinatorial auctions. We introduce a new\nclass of core-selecting combinatorial auctions that leverage bidder information\navailable to the auction designer. We model such information through\nconstraints on the joint type space of the bidders -- these are constraints on\nbidders' private valuations that are known to hold by the auction designer\nbefore bids are elicited. First, we show that type space information can\novercome the well-known impossibility of incentive-compatible core-selecting\ncombinatorial auctions. We present a revised and generalized version of that\nimpossibility result that depends on how much information is conveyed by the\ntype spaces. We then devise a new family of core-selecting combinatorial\nauctions and show that they minimize the sum of bidders' incentives to deviate\nfrom truthful bidding. We develop new constraint generation techniques -- and\nbuild upon existing quadratic programming techniques -- to compute core prices,\nand conduct experiments to evaluate the incentive, revenue, fairness, and\ncomputational merits of our new auctions. Our new core-selecting auctions\ndirectly improve upon existing designs that have been used in many high-stakes\nauctions around the world. We envision that they will be a useful addition to\nany auction designer's toolkit.",
    "pdf_url": "http://arxiv.org/pdf/2505.13680v1",
    "published": "2025-05-19T19:30:46+00:00",
    "categories": [
      "cs.GT",
      "econ.TH",
      "math.OC"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13679v2",
    "title": "Demystifying the Balanced Product Code: A Review",
    "authors": [
      "Heather Leitch",
      "Alastair Kay"
    ],
    "abstract": "The discovery of the family of balanced product codes was pivotal in the\nsubsequent development of 'good' low density quantum error correcting codes\nthat have optimal scaling of the key parameters of distance and storage\ndensity. We review this family, giving a completely different presentation to\nthe original, minimising the abstraction and technicalities wherever possible.\nThe target audience is anyone familiar with the stabilizer formalism for error\ncorrection wanting to understand how parity-check matrices can be constructed\nfor high storage density quantum codes.",
    "pdf_url": "http://arxiv.org/pdf/2505.13679v2",
    "published": "2025-05-19T19:26:53+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13678v1",
    "title": "Noncommutative effective field theories and the large $N$ correspondence",
    "authors": [
      "Alastair Hamilton"
    ],
    "abstract": "We integrate the notion of an effective field theory, as described by\nCostello, with the framework of noncommutative symplectic geometry introduced\nby Kontsevich; providing a definition for the renormalization group flow in\nnoncommutative geometry that is defined through the use of ribbon graphs. As in\nthe commutative case, the resulting noncommutative effective field theories are\nin one-to-one correspondence with local interaction functionals. We explain how\nin this setting, the large $N$ correspondence discovered by 't Hooft appears as\na relation between noncommutative and commutative effective field theories. As\nan example, we apply this framework to study a noncommutative analogue of\nChern-Simons theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.13678v1",
    "published": "2025-05-19T19:26:50+00:00",
    "categories": [
      "math.QA",
      "hep-th",
      "81T12, 81T15, 81T18, 81T30, 81T35, 81T75"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13677v1",
    "title": "Unveiling Electron Density Profile in Nearby Galaxies using SDSS MaNGA",
    "authors": [
      "Shivam Burman",
      "Sunil Malik",
      "Suprit Singh",
      "Yogesh Wadadekar"
    ],
    "abstract": "Most observational studies of galactic-scale magnetic fields using Faraday\nrotation rely on estimates of thermal electron densities in galaxies and their\nradial variations. However, the spatial distribution of electrons in the\ninterstellar medium (ISM) is not clearly known. In this study, we propose and\nutilize collision-excited doublet emission line ratios of [S\\,\\textsc{ii}]\n$\\lambda\\lambda$ 6716, 6731 \\AA~and [O\\,\\textsc{ii}] $\\lambda\\lambda$ 3726,\n3729 \\AA \\ to estimate the electron densities ($n_e$). To map their\ndistribution in the galaxies, we employ Integral Field Unit (IFU) spectroscopic\nobservations from the SDSS Mapping Nearby Galaxies at Apache Point Observatory\n(MaNGA) survey, utilising data products from both the \\texttt{Pipe3D} and MaNGA\nData Analysis Pipeline (DAP). We present a spatially resolved analysis of $13$\nface-on galaxies (inclination, $i \\leq 10^\\circ$), including $9$ star-forming\ngalaxies (SFGs) and $4$ Non-SFGs. Azimuthally averaged radial profiles of $n_e$\nare obtained using two different binning schemes: linear and non-linear. For\nthe \\texttt{Pipe3D} case, both SFGs and non-SFGs exhibit $n_e$ gradients, with\nhigher densities of $n_e$(S\\,\\textsc{ii}) = $165.6 \\pm 20.8$ cm$^{-3}$ in the\ninner disk region (r/R$_e$ $\\leq$ 1.5), which decrease to $31 \\pm 4.5$\ncm$^{-3}$ in the outer disk region (r/R$_e$ $>$ 1.5). We also translate $n_e$\nto the electron column density $N_e$ assuming an evenly distributed thin disk\nprofile, fairly excluding the central bulge regions. These electron density\nestimates at different radii provide valuable insights for resolving\nambiguities in current and future studies of magnetic fields in galaxies.",
    "pdf_url": "http://arxiv.org/pdf/2505.13677v1",
    "published": "2025-05-19T19:26:40+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13676v1",
    "title": "The Dirichlet-to-Neumann map for Lorentzian Calder√≥n problems with data on disjoint sets",
    "authors": [
      "Yuchao Yi",
      "Yang Zhang"
    ],
    "abstract": "We consider the restricted Dirichlet-to-Neumann map $\\Lambda^{U,V}_{g,A,q}$\nfor the wave equation with magnetic potential $A$ and scalar potential $q$, on\nan admissible Lorentzian manifold $(M, g)$ of dimension $n \\geq 3$ with\nboundary. Here $U$ and $V$ are disjoint open subsets of $\\partial M$, where we\nimpose the Dirichlet data on $U$ and measure the Neumann-type data on $V$. We\nuse the gliding rays and microlocal analysis to show that, without any a priori\ninformation, one can reconstruct the conformal class of the boundary metric\n$g|_{T\\partial M \\times T\\partial M}$ and the magnetic potential $A|_{T\\partial\nM}$ at recoverable boundary points from $\\Lambda^{U,V}_{g,A,q}$. In particular,\nthe conformal factor and the jet of the metric at those points are determined\nup to gauge transformations. Moreover, if the metric and the time orientation\nare known on $U$ (or $V$), then the metric on a larger portion of $V$ (or $U$)\ncan be reconstructed, up to gauge.",
    "pdf_url": "http://arxiv.org/pdf/2505.13676v1",
    "published": "2025-05-19T19:24:22+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13675v1",
    "title": "Temperature dependence of coercivity for isolated Ni nanowires unraveled by high-sensitivity micromagnetometry",
    "authors": [
      "Evelyn A. Escudero Bruna",
      "Federico Rom√°",
      "Fernando Meneses",
      "Paula. G. Bercoff",
      "Moira I. Dolz"
    ],
    "abstract": "Magnetic nanowires are critical components in fields such as data storage and\nspintronics, where precise control of their magnetic properties is essential\nfor device optimization. In particular, the behavior of isolated nanowires is\noften different from that of an ensemble, offering an opportunity to explore\nthe role that dipolar and magnetoelastic interactions play in the latter\nsystem. Unfortunately, the comparison between a collection of nanowires and\nsingle ones is often poorly characterized, as measuring individual nanowires\nwith weak magnetic signals is a challenging task. In this work, we employ a\nhighly-sensitive micromechanical torsional oscillator to measure the magnetic\nresponse of few individual Ni nanowires with 72 +/- 5 nm average diameter,\nfabricated by electrodeposition in anodic aluminum oxide templates as an array\nand subsequently released from this membrane. When comparing the magnetic\nproperties as a function of temperature between single nanowires and the array,\nwe show that coercivity values of individual nanowires are at least twice as\nlarge as for the array in the range 5 K - 200 K. Also, we characterize the\ndifferences in the hysteresis loops, which are more squared for isolated\nnanowires, with a high magnetic remanence close to 80 % of the saturation\nvalue. Our results highlight the crucial role of dipolar and mechanical\ninteractions in modifying the magnetic behavior of nanowires arrays, providing\nvaluable insights for the design and application of nanowires-based magnetic\ndevices.",
    "pdf_url": "http://arxiv.org/pdf/2505.13675v1",
    "published": "2025-05-19T19:24:04+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.13674v1",
    "title": "Risk-Averse Traversal of Graphs with Stochastic and Correlated Edge Costs for Safe Global Planetary Mobility",
    "authors": [
      "Olivier Lamarre",
      "Jonathan Kelly"
    ],
    "abstract": "In robotic planetary surface exploration, strategic mobility planning is an\nimportant task that involves finding candidate long-distance routes on orbital\nmaps and identifying segments with uncertain traversability. Then, expert human\noperators establish safe, adaptive traverse plans based on the actual\nnavigation difficulties encountered in these uncertain areas. In this paper, we\nformalize this challenge as a new, risk-averse variant of the Canadian\nTraveller Problem (CTP) tailored to global planetary mobility. The objective is\nto find a traverse policy minimizing a conditional value-at-risk (CVaR)\ncriterion, which is a risk measure with an intuitive interpretation. We propose\na novel search algorithm that finds exact CVaR-optimal policies. Our approach\nleverages well-established optimal AND-OR search techniques intended for\n(risk-agnostic) expectation minimization and extends these methods to the\nrisk-averse domain. We validate our approach through simulated long-distance\nplanetary surface traverses; we employ real orbital maps of the Martian surface\nto construct problem instances and use terrain maps to express traversal\nprobabilities in uncertain regions. Our results illustrate different adaptive\ndecision-making schemes depending on the level of risk aversion. Additionally,\nour problem setup allows accounting for traversability correlations between\nsimilar areas of the environment. In such a case, we empirically demonstrate\nhow information-seeking detours can mitigate risk.",
    "pdf_url": "http://arxiv.org/pdf/2505.13674v1",
    "published": "2025-05-19T19:23:47+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13673v1",
    "title": "Comparing Apples to Oranges: A Taxonomy for Navigating the Global Landscape of AI Regulation",
    "authors": [
      "Sacha Alanoca",
      "Shira Gur-Arieh",
      "Tom Zick",
      "Kevin Klyman"
    ],
    "abstract": "AI governance has transitioned from soft law-such as national AI strategies\nand voluntary guidelines-to binding regulation at an unprecedented pace. This\nevolution has produced a complex legislative landscape: blurred definitions of\n\"AI regulation\" mislead the public and create a false sense of safety;\ndivergent regulatory frameworks risk fragmenting international cooperation; and\nuneven access to key information heightens the danger of regulatory capture.\nClarifying the scope and substance of AI regulation is vital to uphold\ndemocratic rights and align international AI efforts. We present a taxonomy to\nmap the global landscape of AI regulation. Our framework targets essential\nmetrics-technology or application-focused rules, horizontal or sectoral\nregulatory coverage, ex ante or ex post interventions, maturity of the digital\nlegal landscape, enforcement mechanisms, and level of stakeholder\nparticipation-to classify the breadth and depth of AI regulation. We apply this\nframework to five early movers: the European Union's AI Act, the United States'\nExecutive Order 14110, Canada's AI and Data Act, China's Interim Measures for\nGenerative AI Services, and Brazil's AI Bill 2338/2023. We further offer an\ninteractive visualization that distills these dense legal texts into accessible\ninsights, highlighting both commonalities and differences. By delineating what\nqualifies as AI regulation and clarifying each jurisdiction's approach, our\ntaxonomy reduces legal uncertainty, supports evidence-based policymaking, and\nlays the groundwork for more inclusive, globally coordinated AI governance.",
    "pdf_url": "http://arxiv.org/pdf/2505.13673v1",
    "published": "2025-05-19T19:23:41+00:00",
    "categories": [
      "cs.CY",
      "K.4.1; I.2.0; K.5.0"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13672v1",
    "title": "A*-Decoding: Token-Efficient Inference Scaling",
    "authors": [
      "Giannis Chatziveroglou"
    ],
    "abstract": "Inference-time scaling has emerged as a powerful alternative to parameter\nscaling for improving language model performance on complex reasoning tasks.\nWhile existing methods have shown strong performance gains under fixed compute\nbudgets, there has been little focus on optimally utilizing that budget during\ninference. In this work, we introduce A*-decoding, a search-based\ninference-time strategy that builds on the A* search algorithm to optimally\nutilize a fixed compute budget by prioritizing high-quality reasoning paths\nduring generation. We frame language model decoding as a structured search in a\nstate space of partial solutions, applying the A* transition model to identify\npromising continuations guided by an external process supervision signal. In\nour experiments, A*-decoding reaches the performance levels of strong inference\nscaling baselines like best-of-N and particle filtering while using up to 3x\nfewer tokens and 30% fewer PRM passes under equivalent compute budgets. On the\nMATH500 and AIME 2024 benchmarks, A*-decoding enables Llama-3.2-1B-Instruct to\nmatch the performance of the 70x larger Llama-3.1-70B-Instruct, and allows\nQwen3-1.7B to reach o1-like reasoning accuracy. These results highlight the\npower of structured search in decoding, offering an alternative to brute-force\nsampling or scale-driven gains. Our work demonstrates how thoughtful\ninference-time strategies can enhance reasoning in SLMs, pointing toward future\nadvances in more efficient and scalable language model deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.13672v1",
    "published": "2025-05-19T19:19:48+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13671v1",
    "title": "Multipole Analysis and Application to Supernova Remnant X-ray Images",
    "authors": [
      "Denis A. Leahy",
      "S. Ranasinghe",
      "J. Hansen",
      "M. D. Filipoviƒá",
      "Z. Smeaton"
    ],
    "abstract": "We develop a multipole analysis method for images with a circular boundary,\nthen apply it to supernova remnant (SNR) images. The morphology of SNR images\nis related to several factors, including the inhomogeneities of the supernova\nejecta and of the circumstellar medium in which the ejecta and shock wave\ntravel. The current multipole method corrects some errors in a previously\npresented method, and applies the new analysis to test for differences in X-ray\nimage morphology between Type Ia and core-collapse type SNRs. We find there is\nno clear difference between the two SNR types in morphology as measured by\nmultipole moments.",
    "pdf_url": "http://arxiv.org/pdf/2505.13671v1",
    "published": "2025-05-19T19:19:11+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13670v1",
    "title": "ResQue Greedy: Rewiring Sequential Greedy for Improved Submodular Maximization",
    "authors": [
      "Joan Vendrell Gallart",
      "Alan Kuhnle",
      "Solmaz Kia"
    ],
    "abstract": "This paper introduces Rewired Sequential Greedy (ResQue Greedy), an enhanced\napproach for submodular maximization under cardinality constraints. By\nintegrating a novel set curvature metric within a lattice-based framework,\nResQue Greedy identifies and corrects suboptimal decisions made by the standard\nsequential greedy algorithm. Specifically, a curvature-aware rewiring strategy\nis employed to dynamically redirect the solution path, leading to improved\napproximation performance over the conventional sequential greedy algorithm\nwithout significantly increasing computational complexity. Numerical\nexperiments demonstrate that ResQue Greedy achieves tighter near-optimality\nbounds compared to the traditional sequential greedy method.",
    "pdf_url": "http://arxiv.org/pdf/2505.13670v1",
    "published": "2025-05-19T19:17:25+00:00",
    "categories": [
      "cs.DM",
      "cs.DS",
      "math.OC"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2505.13669v1",
    "title": "GeoVLM: Improving Automated Vehicle Geolocalisation Using Vision-Language Matching",
    "authors": [
      "Barkin Dagda",
      "Muhammad Awais",
      "Saber Fallah"
    ],
    "abstract": "Cross-view geo-localisation identifies coarse geographical position of an\nautomated vehicle by matching a ground-level image to a geo-tagged satellite\nimage from a database. Despite the advancements in Cross-view geo-localisation,\nsignificant challenges still persist such as similar looking scenes which makes\nit challenging to find the correct match as the top match. Existing approaches\nreach high recall rates but they still fail to rank the correct image as the\ntop match. To address this challenge, this paper proposes GeoVLM, a novel\napproach which uses the zero-shot capabilities of vision language models to\nenable cross-view geo-localisation using interpretable cross-view language\ndescriptions. GeoVLM is a trainable reranking approach which improves the best\nmatch accuracy of cross-view geo-localisation. GeoVLM is evaluated on standard\nbenchmark VIGOR and University-1652 and also through real-life driving\nenvironments using Cross-View United Kingdom, a new benchmark dataset\nintroduced in this paper. The results of the paper show that GeoVLM improves\nretrieval performance of cross-view geo-localisation compared to the\nstate-of-the-art methods with the help of explainable natural language\ndescriptions. The code is available at\nhttps://github.com/CAV-Research-Lab/GeoVLM",
    "pdf_url": "http://arxiv.org/pdf/2505.13669v1",
    "published": "2025-05-19T19:17:06+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13668v1",
    "title": "MAFA: A multi-agent framework for annotation",
    "authors": [
      "Mahmood Hegazy",
      "Aaron Rodrigues",
      "Azzam Naeem"
    ],
    "abstract": "Modern applications require accurate and efficient retrieval of information\nin response to user queries. Mapping user utterances to the most relevant\nFrequently Asked Questions (FAQs) is a crucial component of these systems.\nTraditional approaches often rely on a single model or technique, which may not\ncapture the nuances of diverse user inquiries. In this paper, we introduce a\nmulti-agent framework for FAQ annotation that combines multiple specialized\nagents with different approaches and a judge agent that reranks candidates to\nproduce optimal results. Our agents utilize a structured reasoning approach\ninspired by Attentive Reasoning Queries (ARQs), which guides them through\nsystematic reasoning steps using targeted, task-specific JSON queries. Our\nframework features a specialized few-shot example strategy, where each agent\nreceives different few-shots, enhancing ensemble diversity and coverage of the\nquery space. We evaluate our framework on a real-world banking dataset as well\nas public benchmark datasets (LCQMC and FiQA), demonstrating significant\nimprovements over single-agent approaches across multiple metrics, including a\n14% increase in Top-1 accuracy, an 18% increase in Top-5 accuracy, and a 12%\nimprovement in Mean Reciprocal Rank on our dataset, and similar gains on public\nbenchmarks when compared with traditional single agent annotation techniques.\nOur framework is particularly effective at handling ambiguous queries, making\nit well-suited for deployment in production applications while showing strong\ngeneralization capabilities across different domains and languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.13668v1",
    "published": "2025-05-19T19:16:37+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.14724v3",
    "title": "On biquandle-based invariant of immersed surface-links, Yoshikawa oriented fifth move, and ribbon 2-knots",
    "authors": [
      "Michal Jablonowski"
    ],
    "abstract": "We resolve an open problem by showing that the Yoshikawa's fifth oriented\nmove in his list cannot be reproduced by any finite sequence of the other nine\nmoves and planar isotopies. Our proof introduces a link-type semi-invariant\nthat remains unchanged under all moves except the fifth, highlighting its\nnecessity in generating the full move set. Second, we extend the algebraic\ntoolkit for immersed surface-links. After revisiting the banded-unlink\ndescription of immersed surfaces and the twelve local moves that relate their\ndiagrams, we develop a biquandle-based coloring theory. By assigning elements\nof a biquandle to diagram arcs according to local rules, we obtain a counting\ninvariant of immersed surfaces up to isotopy. Third, we show that there are\ninfinitely many pairs of ribbon $2$-knots with isomorphic groups but different\nknot quandles.",
    "pdf_url": "http://arxiv.org/pdf/2505.14724v3",
    "published": "2025-05-19T19:15:56+00:00",
    "categories": [
      "math.GT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.00018v1",
    "title": "On the Impact of Monte Carlo Statistical Uncertainty on Surrogate-based Design Optimization",
    "authors": [
      "Omer F. Erdem",
      "David P. Broughton",
      "Josef Svoboda",
      "Chengkun Huang",
      "Majdi I. Radaideh"
    ],
    "abstract": "In multi-objective design tasks, the computational cost increases rapidly\nwhen high-fidelity simulations are used to evaluate objective functions.\nSurrogate models help mitigate this cost by approximating the simulation\noutput, simplifying the design process. However, under high uncertainty,\nsurrogate models trained on noisy data can produce inaccurate predictions, as\ntheir performance depends heavily on the quality of training data. This study\ninvestigates the impact of data uncertainty on two multi-objective design\nproblems modelled using Monte Carlo transport simulations: a neutron moderator\nand an ion-to-neutron converter. For each, a grid search was performed using\nfive different tally uncertainty levels to generate training data for neural\nnetwork surrogate models. These models were then optimized using NSGA-III. The\nrecovered Pareto-fronts were analyzed across uncertainty levels, and the impact\nof training data quality on optimization outcomes was quantified. Average\nsimulation times were also compared to evaluate the trade-off between accuracy\nand computational cost. Results show that the influence of simulation\nuncertainty is strongly problem-dependent. In the neutron moderator case,\nhigher uncertainties led to exaggerated objective sensitivities and distorted\nPareto-fronts, reducing normalized hypervolume. In contrast, the ion-to-neutron\nconverter task was less affected--low-fidelity simulations produced results\nsimilar to those from high-fidelity data. These findings suggest that a\nfixed-fidelity approach is not optimal. Surrogate models can still recover the\nPareto-front under noisy conditions, and multi-fidelity studies can help\nidentify the appropriate uncertainty level for each problem, enabling better\ntrade-offs between computational efficiency and optimization accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2506.00018v1",
    "published": "2025-05-19T19:12:48+00:00",
    "categories": [
      "stat.AP",
      "physics.comp-ph"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13667v2",
    "title": "Adaptive Diffusion Constrained Sampling for Bimanual Robot Manipulation",
    "authors": [
      "Haolei Tong",
      "Yuezhe Zhang",
      "Sophie Lueth",
      "Georgia Chalvatzaki"
    ],
    "abstract": "Coordinated multi-arm manipulation requires satisfying multiple simultaneous\ngeometric constraints across high-dimensional configuration spaces, which poses\na significant challenge for traditional planning and control methods. In this\nwork, we propose Adaptive Diffusion Constrained Sampling (ADCS), a generative\nframework that flexibly integrates both equality (e.g., relative and absolute\npose constraints) and structured inequality constraints (e.g., proximity to\nobject surfaces) into an energy-based diffusion model. Equality constraints are\nmodeled using dedicated energy networks trained on pose differences in Lie\nalgebra space, while inequality constraints are represented via Signed Distance\nFunctions (SDFs) and encoded into learned constraint embeddings, allowing the\nmodel to reason about complex spatial regions. A key innovation of our method\nis a Transformer-based architecture that learns to weight constraint-specific\nenergy functions at inference time, enabling flexible and context-aware\nconstraint integration. Moreover, we adopt a two-phase sampling strategy that\nimproves precision and sample diversity by combining Langevin dynamics with\nresampling and density-aware re-weighting. Experimental results on dual-arm\nmanipulation tasks show that ADCS significantly improves sample diversity and\ngeneralization across settings demanding precise coordination and adaptive\nconstraint handling.",
    "pdf_url": "http://arxiv.org/pdf/2505.13667v2",
    "published": "2025-05-19T19:12:29+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13666v1",
    "title": "Oort Cloud Ecology. III. The Sun left the parent star cluster shortly after the giant planets formed",
    "authors": [
      "Simon Portegies Zwart",
      "Shuo Huang"
    ],
    "abstract": "The Sun was born in a clustered environment with 10,000 other stars. Being an\nisolated star today, the Sun must have left the nest. We do not directly know\nwhen that happened, how violent the ejection was, or how far the Solar siblings\nhave drifted apart. The mass of the fragile outer Opic-Oort cloud, (between\n$r_{\\rm inner} \\sim 30,000$\\,au and $200\\,000$au from the Sun) and the orbital\ndistribution of planetesimals in the inner Hills-Oort cloud (between $\\sim\n1000$\\,au and $\\sim 30\\,000$ au) are sensitive to the dynamical processes\ninvolving the Sun in the parent cluster. We aim at understanding the extend to\nwhich observing the Oort cloud constrains the Sun's birth environment. This is\nachieved by a combination of theoretical arguments and N-body simulations. We\nshow that the current mass of the Opic-Oort cloud (between 0.2 and $2.0$ Earth\nmasses) is best explained if the Sun left the nest within $\\sim 20$\\,Myr after\nthe giant planets formed and migrated. As a consequence, the possible dynamical\nencounter with another star carving the Kuiper belt, the Sun's abduction of\nSedna, and other perturbations induced by nearby stars then must have happened\nshortly after the giant planets in the Solar system formed, but before the Sun\nleft the parent cluster. Signatures of the time spend in the parent cluster\nmust still be visible in the outer parts of the Solar system today. The\nstrongest constraints will be the discovery of a population of relatively\nlow-eccentricity ($e < 0.9$) inner Oort-cloud (but $500 < a < 10^4$\\,au)\nobjects.",
    "pdf_url": "http://arxiv.org/pdf/2505.13666v1",
    "published": "2025-05-19T19:11:06+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13665v1",
    "title": "Magnetic field-enhanced oxygen reduction reaction for electrochemical hydrogen peroxide production with different cerium oxide nanostructures",
    "authors": [
      "Caio Machado Fernandes",
      "Aila O. Santos",
      "Vanessa S. Antonin",
      "Joao Paulo C. Moura",
      "Aline B. Trench",
      "Odivaldo C. Alves",
      "Yutao Xing",
      "Julio Cesar M. Silva",
      "Mauro C. Santos"
    ],
    "abstract": "We investigated cerium oxide nanoparticles of various morphologies\n(nanosheets, nanocubes, and nanoparticles) supported on carbon Vulcan XC-72 for\nthe two-electron oxygen reduction reaction (ORR). It was used a continuous\nmagnetic field (2000 Oe) for the first time in the literature. The best results\nwere for 5% (w/w) CeO2 for all three different morphologies, more than doubling\nthe ring current, enhancing the hydrogen peroxide selectivity from 51% (Vulcan\nXC-72) to 84-89%, and modifying the onset potential to lesser negative values.\nThe presence of the magnetic field led to even higher ring currents with 5%\n(w/w) CeO$_2$, H$_2$O$_2$ selectivity from 54% (Vulcan XC-72) to 88-96% and\nchanging even more the onset potential. Those results were correlated with the\nZeeman effect, the Lorentz force, generating magnetohydrodynamic effects, the\nKelvin force, and the formation of Bound Magnetic Polarons. This pioneering\nresearch introduces an innovative approach, highlighting the potential of an\nexternal continuous magnetic field.",
    "pdf_url": "http://arxiv.org/pdf/2505.13665v1",
    "published": "2025-05-19T19:06:54+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13664v1",
    "title": "Assessing GPT Performance in a Proof-Based University-Level Course Under Blind Grading",
    "authors": [
      "Ming Ding",
      "Rasmus Kyng",
      "Federico Solda",
      "Weixuan Yuan"
    ],
    "abstract": "As large language models (LLMs) advance, their role in higher education,\nparticularly in free-response problem-solving, requires careful examination.\nThis study assesses the performance of GPT-4o and o1-preview under realistic\neducational conditions in an undergraduate algorithms course. Anonymous\nGPT-generated solutions to take-home exams were graded by teaching assistants\nunaware of their origin. Our analysis examines both coarse-grained performance\n(scores) and fine-grained reasoning quality (error patterns). Results show that\nGPT-4o consistently struggles, failing to reach the passing threshold, while\no1-preview performs significantly better, surpassing the passing score and even\nexceeding the student median in certain exercises. However, both models exhibit\nissues with unjustified claims and misleading arguments. These findings\nhighlight the need for robust assessment strategies and AI-aware grading\npolicies in education.",
    "pdf_url": "http://arxiv.org/pdf/2505.13664v1",
    "published": "2025-05-19T19:05:48+00:00",
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13663v1",
    "title": "Non-Invasive Arterial Pulse Detection with Millimeter-wave Radar and Comparison With Photoplethysmography",
    "authors": [
      "Nima Bahmani",
      "Dariush Salami",
      "H√ºseyin Yiƒüitler",
      "Juhapekka Hietala",
      "Tuukka Panula",
      "Stephan Sigg"
    ],
    "abstract": "Cardiovascular diseases remain a leading cause of mortality and disability.\nThe convenient measurement of cardiovascular health using smart systems is\ntherefore a key enabler to foster accurate and early detection and diagnosis of\ncardiovascular diseases and it require accessing a correct pulse morphology\nsimilar to arterial pressure wave. This paper investigates the comparison\nbetween different sensor modalities, such as mmWave and photoplethysmography\nfrom the same physiological site and reference continuous non-invasive blood\npressure devide. We have developed a hardware prototype and established an\nexperiment consist of 23 test participants. Both mmWave and PPG are capable of\ndetecting inter-beat intervals. mmWave is providing more accurate arterial\npulse waveform than green photoplethysmography.",
    "pdf_url": "http://arxiv.org/pdf/2505.13663v1",
    "published": "2025-05-19T19:05:06+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13662v1",
    "title": "Differentially Private Quantiles with Smaller Error",
    "authors": [
      "Jacob Imola",
      "Fabrizio Boninsegna",
      "Hannah Keller",
      "Anders Aamand",
      "Amrita Roy Chowdhury",
      "Rasmus Pagh"
    ],
    "abstract": "In the approximate quantiles problem, the goal is to output $m$ quantile\nestimates, the ranks of which are as close as possible to $m$ given quantiles\n$q_1,\\dots,q_m$. We present a mechanism for approximate quantiles that\nsatisfies $\\varepsilon$-differential privacy for a dataset of $n$ real numbers\nwhere the ratio between the closest pair of points and the size of the domain\nis bounded by $b$. As long as the minimum gap between quantiles is large\nenough, $|q_i-q_{i-1}|\\geq\n\\Omega\\left(\\frac{m\\log(m)\\log(b)}{n\\varepsilon}\\right)$ for all $i$, the\nmaximum rank error of our mechanism is $O\\left(\\frac{\\log(b) +\n\\log^2(m)}{\\varepsilon}\\right)$ with high probability. Previously, the best\nknown algorithm under pure DP was due to Kaplan, Schnapp, and Stemmer~(ICML\n'22), who achieve a bound of $O\\left(\\log(b)\\log^2(m)/\\varepsilon\\right)$, so\nwe save a factor $\\Omega(\\min(\\log(b),\\log^2(m)))$. Our improvement stems from\nthe use of continual counting techniques to randomize the quantiles in a\ncorrelated way. We also present an $(\\varepsilon,\\delta)$-differentially\nprivate mechanism that relaxes the gap assumption without affecting the error\nbound, improving on existing methods when $\\delta$ is sufficiently close to\nzero. We provide experimental evaluation which confirms that our mechanism\nperforms favorably compared to prior work in practice, in particular when the\nnumber of quantiles $m$ is large.",
    "pdf_url": "http://arxiv.org/pdf/2505.13662v1",
    "published": "2025-05-19T19:05:03+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13661v2",
    "title": "Combined tight-binding and configuration interaction study of unfolded electronic structure of G-color center in Si",
    "authors": [
      "Jakub Valdhans",
      "Petr Klenovsk√Ω"
    ],
    "abstract": "We have theoretically studied the G-center in bulk silicon material using the\nempirical tight-binding model for calculations of unfolded band structures with\nconfiguration interaction correction for the exciton at $\\Gamma$ point of the\nBrillouin zone. The G-center in B configuration (emissive) being a candidate\nstructure as the telecom single- and entangled-photon source has two\nsubstitutional carbons and one interstitial atom embedded into the bulk in six\nequally possible configurations. Taking the advantage of the low computation\neffort of the tight-binding and unfolding approach, it is possible to calculate\nand analyze the behavior of a variety of the electronic configurations. Our\ntight-binding model is able to describe not only the behavior of the G-center\nin the silicon bulk but using the unfolding approach it can also pinpoint the\ncontributions of different elements of the supercell on the final pseudo-band\nstructure. Moreover, the configuration interaction correction with\nsingle-particle basis states computed by our unfolded tight-binding model\npredicts a very small fine-structure splitting of the ground state exciton both\nfor bright and dark doublet in the studied system. That underscores the\npossibility of the silicon G-center to become a very good emitter of single and\nentangled photons for quantum communication and computation applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.13661v2",
    "published": "2025-05-19T19:00:42+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.13660v1",
    "title": "Sobolev Gradient Ascent for Optimal Transport: Barycenter Optimization and Convergence Analysis",
    "authors": [
      "Kaheon Kim",
      "Bohan Zhou",
      "Changbo Zhu",
      "Xiaohui Chen"
    ],
    "abstract": "This paper introduces a new constraint-free concave dual formulation for the\nWasserstein barycenter. Tailoring the vanilla dual gradient ascent algorithm to\nthe Sobolev geometry, we derive a scalable Sobolev gradient ascent (SGA)\nalgorithm to compute the barycenter for input distributions supported on a\nregular grid. Despite the algorithmic simplicity, we provide a global\nconvergence analysis that achieves the same rate as the classical subgradient\ndescent methods for minimizing nonsmooth convex functions in the Euclidean\nspace. A central feature of our SGA algorithm is that the computationally\nexpensive $c$-concavity projection operator enforced on the Kantorovich dual\npotentials is unnecessary to guarantee convergence, leading to significant\nalgorithmic and theoretical simplifications over all existing primal and dual\nmethods for computing the exact barycenter. Our numerical experiments\ndemonstrate the superior empirical performance of SGA over the existing optimal\ntransport barycenter solvers.",
    "pdf_url": "http://arxiv.org/pdf/2505.13660v1",
    "published": "2025-05-19T18:59:24+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13659v1",
    "title": "Symmetry-Driven Trimer Formation in Kagome Correlated Electron Materials",
    "authors": [
      "Varsha Kumari",
      "Julia Bauer",
      "Alexandru B. Georgescu"
    ],
    "abstract": "Correlated electron materials with molecular orbital states extending over\ntransition metal clusters can host multiferroicity, spin frustration, and\nunconventional insulating phases. However, the fundamental criteria that govern\ncluster formation and stability remain unclear. Here, we identify a symmetry,\ncorrelation, and electron filling driven criteria that stabilize triangular\nmetal trimers in materials displaying transition metal kagome patterns. Using\ndensity functional theory and chemical bonding analysis, we show that trimer\nformation emerges when 6 to 8 electrons occupy molecular orbitals derived from\ntransition metal d-states, achieving near complete filling of bonding states\nwhile avoiding antibonding occupation, and correlations are of intermediate\nstrength. This principle explains the stability of Nb$_3$X$_8$ (X = Cl, Br, I),\nand more broadly, our findings offer a general design rule to obtain quantum\nmaterials with quantum states extended across transition metal clusters.",
    "pdf_url": "http://arxiv.org/pdf/2505.13659v1",
    "published": "2025-05-19T18:59:07+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.13658v1",
    "title": "Boundary-condition-assisted chiral-symmetry protection of the zeroth Landau level on a two-dimensional lattice",
    "authors": [
      "A. Don√≠s Vela",
      "C. W. J. Beenakker"
    ],
    "abstract": "The massless two-dimensional Dirac equation in a perpendicular magnetic field\nB supports a B-independent \"zeroth Landau level\", a dispersionless\nzero-energy-mode protected by chiral symmetry. On a lattice the zero-mode\nbecomes doubly degenerate with states of opposite chirality, which removes the\nprotection and allows for a broadening when the magnetic field is non-uniform.\nIt is known that this fundamental obstruction can be avoided by spatially\nseparating the doubly degenerate states, adjoining +B and -B regions in a\nsystem of twice the size. Here we show that the same objective can be achieved\nwithout doubling the system size. The key ingredients are 1) a\nchirality-preserving \"tangent fermion\" discretization of the Dirac equation;\nand 2) a boundary condition that ensures the zero-mode contains only states of\na single chirality.",
    "pdf_url": "http://arxiv.org/pdf/2505.13658v1",
    "published": "2025-05-19T18:57:24+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.13657v1",
    "title": "Clarifying orthography: Orthographic transparency as compressibility",
    "authors": [
      "Charles J. Torres",
      "Richard Futrell"
    ],
    "abstract": "Orthographic transparency -- how directly spelling is related to sound --\nlacks a unified, script-agnostic metric. Using ideas from algorithmic\ninformation theory, we quantify orthographic transparency in terms of the\nmutual compressibility between orthographic and phonological strings. Our\nmeasure provides a principled way to combine two factors that decrease\northographic transparency, capturing both irregular spellings and rule\ncomplexity in one quantity. We estimate our transparency measure using\nprequential code-lengths derived from neural sequence models. Evaluating 22\nlanguages across a broad range of script types (alphabetic, abjad, abugida,\nsyllabic, logographic) confirms common intuitions about relative transparency\nof scripts. Mutual compressibility offers a simple, principled, and general\nyardstick for orthographic transparency.",
    "pdf_url": "http://arxiv.org/pdf/2505.13657v1",
    "published": "2025-05-19T18:56:15+00:00",
    "categories": [
      "cs.CL",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13656v1",
    "title": "Carving Nature/Conceptual Models at Joints Using Thinging Machines",
    "authors": [
      "Sabah Al-Fedaghi"
    ],
    "abstract": "To handle the complexity of our world, the carving metaphor has been used to\nbuild a conceptual system of reality. In such an endeavor, we can choose\nvarious joints to carve at; that is, we can conceptualize various aspects of\nreality. Conceptual modeling concerns carving (e.g., categorization) and\nspecifying a conceptual picture of a subject domain. This paper concerns with\napplying the notion of carving to conceptual models. Specifically, it concerns\nmodeling based on the so-called thinging machine (TM). The central problem is\nhow to carve events when building a TM model. In TMs, an event is defined as a\nthimac (thing/machine) with a time feature that infuses dynamism into the\nstatic thimac, called a region. A region is a diagrammatic description based on\nfive generic actions: create, process, release, transfer, and receive. The\npaper contains new material about TM modeling and generalization and focuses on\nthe carving problem to include structural carving and dynamic events. The study\ns results provide a foundation for establishing a new type of reality carving\nbased on the TM model diagrams.",
    "pdf_url": "http://arxiv.org/pdf/2505.13656v1",
    "published": "2025-05-19T18:55:56+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13655v2",
    "title": "Optimal Client Sampling in Federated Learning with Client-Level Heterogeneous Differential Privacy",
    "authors": [
      "Jiahao Xu",
      "Rui Hu",
      "Olivera Kotevska"
    ],
    "abstract": "Federated Learning with client-level differential privacy (DP) provides a\npromising framework for collaboratively training models while rigorously\nprotecting clients' privacy. However, classic approaches like DP-FedAvg\nstruggle when clients have heterogeneous privacy requirements, as they must\nuniformly enforce the strictest privacy level across clients, leading to\nexcessive DP noise and significant model utility degradation. Existing methods\nto improve the model utility in such heterogeneous privacy settings often\nassume a trusted server and are largely heuristic, resulting in suboptimal\nperformance and lacking strong theoretical underpinnings. In this work, we\naddress these challenges under a practical attack model where both clients and\nthe server are honest-but-curious. We propose GDPFed, which partitions clients\ninto groups based on their privacy budgets and achieves client-level DP within\neach group to reduce the privacy budget waste and hence improve the model\nutility. Based on the privacy and convergence analysis of GDPFed, we find that\nthe magnitude of DP noise depends on both model dimensionality and the\nper-group client sampling ratios. To further improve the performance of GDPFed,\nwe introduce GDPFed$^+$, which integrates model sparsification to eliminate\nunnecessary noise and optimizes per-group client sampling ratios to minimize\nconvergence error. Extensive empirical evaluations on multiple benchmark\ndatasets demonstrate the effectiveness of GDPFed$^+$, showing substantial\nperformance gains compared with state-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13655v2",
    "published": "2025-05-19T18:55:34+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13654v1",
    "title": "Chaos Engineering in the Wild: Findings from GitHub",
    "authors": [
      "Joshua Owotogbe",
      "Indika Kumara",
      "Dario Di Nucci",
      "Damian Andrew Tamburri",
      "Willem-Jan van den Heuvel"
    ],
    "abstract": "Chaos engineering aims to improve the resilience of software systems by\nintentionally injecting faults to identify and address system weaknesses that\ncause outages in production environments. Although many tools for chaos\nengineering exist, their practical adoption is not yet explored. This study\nexamines 971 GitHub repositories that incorporate 10 popular chaos engineering\ntools to identify patterns and trends in their use. The analysis reveals that\nToxiproxy and Chaos Mesh are the most frequently used, showing consistent\ngrowth since 2016 and reflecting increasing adoption in cloud-native\ndevelopment. The release of new chaos engineering tools peaked in 2018,\nfollowed by a shift toward refinement and integration, with Chaos Mesh and\nLitmusChaos leading in ongoing development activity. Software development is\nthe most frequent application (58.0%), followed by unclassified purposes\n(16.2%), teaching (10.3%), learning (9.9%), and research (5.7%).\nDevelopment-focused repositories tend to have higher activity, particularly for\nToxiproxy and Chaos Mesh, highlighting their industrial relevance. Fault\ninjection scenarios mainly address network disruptions (40.9%) and instance\ntermination (32.7%), while application-level faults remain underrepresented\n(3.0%), highlighting for future exploration.",
    "pdf_url": "http://arxiv.org/pdf/2505.13654v1",
    "published": "2025-05-19T18:53:25+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13653v2",
    "title": "UGC 10043 in Depth: Dissecting the Polar Bulge and Subtle LSB Features",
    "authors": [
      "S. K. H. Bahr",
      "A. V. Mosenkov"
    ],
    "abstract": "Galaxies with polar structures -- of which polar-ring galaxies (PRGs) are a\nprominent subclass -- contain components that are kinematically decoupled and\nhighly inclined relative to the host galaxy's major axis. Modern deep optical\nsurveys provide a powerful means of detecting low surface brightness (LSB)\nfeatures around galaxies, offering critical insights into the formation and\nevolution of galaxies with polar structures. UGC 10043 is an edge-on galaxy\nnotable for its prominent bulge, which extends orthogonally to the disk plane.\nIn addition, the galaxy displays a well-defined integral-shaped disk warp and\nmultiple dust features crossing the bulge along the minor galaxy axis. In this\nwork, we present new deep optical photometry of UGC 10043 down to 29.5 mag\narcsec$^{-2}$ and perform a detailed analysis of its LSB and polar structures.\nThe observations reveal a stellar stream aligned along the polar axis,\nalongside other signatures of tidal interaction, including a flat, tilted LSB\nenvelope that extends toward the neighboring galaxy MCG +04-37-035, with which\nUGC 10043 is connected by an HI bridge. Our results suggest that the polar\ncomponent of UGC 10043 comprises and older, triaxial polar bulge and a younger,\nforming polar structure, likely originating from the ongoing disruption of a\ndwarf satellite galaxy, while also participating in active interaction with MCG\n+04-37-035.",
    "pdf_url": "http://arxiv.org/pdf/2505.13653v2",
    "published": "2025-05-19T18:52:11+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13652v1",
    "title": "Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents",
    "authors": [
      "Karina Zainullina",
      "Alexander Golubev",
      "Maria Trofimova",
      "Sergei Polezhaev",
      "Ibragim Badertdinov",
      "Daria Litvintseva",
      "Simon Karasik",
      "Filipp Fisin",
      "Sergei Skvortsov",
      "Maksim Nekrashevich",
      "Anton Shevtsov",
      "Boris Yangel"
    ],
    "abstract": "Large language models (LLMs) have recently achieved remarkable results in\ncomplex multi-step tasks, such as mathematical reasoning and agentic software\nengineering. However, they often struggle to maintain consistent performance\nacross multiple solution attempts. One effective approach to narrow the gap\nbetween average-case and best-case performance is guided test-time search,\nwhich explores multiple solution paths to identify the most promising one.\nUnfortunately, effective search techniques (e.g. MCTS) are often unsuitable for\nnon-serializable RL environments, such as Docker containers, where intermediate\nenvironment states cannot be easily saved and restored. We investigate two\ncomplementary search strategies applicable to such environments: 1-step\nlookahead and trajectory selection, both guided by a learned action-value\nfunction estimator. On the SWE-bench Verified benchmark, a key testbed for\nagentic software engineering, we find these methods to double the average\nsuccess rate of a fine-tuned Qwen-72B model, achieving 40.8%, the new\nstate-of-the-art for open-weights models. Additionally, we show that these\ntechniques are transferable to more advanced closed models, yielding similar\nimprovements with GPT-4o.",
    "pdf_url": "http://arxiv.org/pdf/2505.13652v1",
    "published": "2025-05-19T18:50:15+00:00",
    "categories": [
      "cs.SE",
      "cs.CL"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13651v3",
    "title": "Traceable Black-box Watermarks for Federated Learning",
    "authors": [
      "Jiahao Xu",
      "Rui Hu",
      "Olivera Kotevska",
      "Zikai Zhang"
    ],
    "abstract": "Due to the distributed nature of Federated Learning (FL) systems, each local\nclient has access to the global model, posing a critical risk of model leakage.\nExisting works have explored injecting watermarks into local models to enable\nintellectual property protection. However, these methods either focus on\nnon-traceable watermarks or traceable but white-box watermarks. We identify a\ngap in the literature regarding the formal definition of traceable black-box\nwatermarking and the formulation of the problem of injecting such watermarks\ninto FL systems. In this work, we first formalize the problem of injecting\ntraceable black-box watermarks into FL. Based on the problem, we propose a\nnovel server-side watermarking method, $\\mathbf{TraMark}$, which creates a\ntraceable watermarked model for each client, enabling verification of model\nleakage in black-box settings. To achieve this, $\\mathbf{TraMark}$ partitions\nthe model parameter space into two distinct regions: the main task region and\nthe watermarking region. Subsequently, a personalized global model is\nconstructed for each client by aggregating only the main task region while\npreserving the watermarking region. Each model then learns a unique watermark\nexclusively within the watermarking region using a distinct watermark dataset\nbefore being sent back to the local client. Extensive results across various FL\nsystems demonstrate that $\\mathbf{TraMark}$ ensures the traceability of all\nwatermarked models while preserving their main task performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.13651v3",
    "published": "2025-05-19T18:49:31+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13650v1",
    "title": "Self-Reinforced Graph Contrastive Learning",
    "authors": [
      "Chou-Ying Hsieh",
      "Chun-Fu Jang",
      "Cheng-En Hsieh",
      "Qian-Hui Chen",
      "Sy-Yen Kuo"
    ],
    "abstract": "Graphs serve as versatile data structures in numerous real-world\ndomains-including social networks, molecular biology, and knowledge graphs-by\ncapturing intricate relational information among entities. Among graph-based\nlearning techniques, Graph Contrastive Learning (GCL) has gained significant\nattention for its ability to derive robust, self-supervised graph\nrepresentations through the contrasting of positive and negative sample pairs.\nHowever, a critical challenge lies in ensuring high-quality positive pairs so\nthat the intrinsic semantic and structural properties of the original graph are\npreserved rather than distorted. To address this issue, we propose SRGCL\n(Self-Reinforced Graph Contrastive Learning), a novel framework that leverages\nthe model's own encoder to dynamically evaluate and select high-quality\npositive pairs. We designed a unified positive pair generator employing\nmultiple augmentation strategies, and a selector guided by the manifold\nhypothesis to maintain the underlying geometry of the latent space. By adopting\na probabilistic mechanism for selecting positive pairs, SRGCL iteratively\nrefines its assessment of pair quality as the encoder's representational power\nimproves. Extensive experiments on diverse graph-level classification tasks\ndemonstrate that SRGCL, as a plug-in module, consistently outperforms\nstate-of-the-art GCL methods, underscoring its adaptability and efficacy across\nvarious domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.13650v1",
    "published": "2025-05-19T18:45:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13649v1",
    "title": "Proton Structure Functions from Holographic Einstein-Dilaton Models",
    "authors": [
      "Ayrton da Cruz Pereira do Nascimento",
      "Henrique Boschi-Filho",
      "Jorge Noronha"
    ],
    "abstract": "We study the proton structure functions $F_1$ and $F_2$ in the context of\nholography. We develop a general framework that extends previous holographic\ncalculations of $F_1$ and $F_2$ to the case where the bulk geometry stems from\nbottom-up Einstein-Dilaton models, which are commonly used in the literature to\ndescribe some properties of QCD in the strong coupling regime. We focus on a\nchoice of the dilaton potential that leads to a holographic model able to\nreproduce known lattice QCD results for the glueball masses at zero temperature\nand pure Yang-Mills thermodynamics above deconfinement. Once the parameters of\nthe background holographic model are fixed, we introduce probe fermionic and\ngauge fields in the bulk {\\it a la} Polchinski and Strassler to determine the\ncorresponding structure functions. This particular realization of the model can\nsuccessfully describe the proton mass and provide results for $F_2$ at large\n$x$ that are in qualitative agreement with experimental data.",
    "pdf_url": "http://arxiv.org/pdf/2505.13649v1",
    "published": "2025-05-19T18:42:29+00:00",
    "categories": [
      "hep-th",
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13648v1",
    "title": "Conceptual Modeling: Topics, Themes, and Technology Trends",
    "authors": [
      "V. C. Storey",
      "R. Lukyanenko",
      "A. Castellanos"
    ],
    "abstract": "Conceptual modeling is an important part of information systems development\nand use that involves identifying and representing relevant aspects of reality.\nAlthough the past decades have experienced continuous digitalization of\nservices and products that impact business and society, conceptual modeling\nefforts are still required to support new technologies as they emerge. This\npaper surveys research on conceptual modeling over the past five decades and\nshows how its topics and trends continue to evolve to accommodate emerging\ntechnologies, while remaining grounded in basic constructs. We survey over\n5,300 papers that address conceptual modeling topics from the 1970s to the\npresent, which are collected from 35 multidisciplinary journals and\nconferences, and use them as the basis from which to analyze the progression of\nconceptual modeling. The important role that conceptual modeling should play in\nour evolving digital world is discussed, and future research directions\nproposed.",
    "pdf_url": "http://arxiv.org/pdf/2505.13648v1",
    "published": "2025-05-19T18:42:01+00:00",
    "categories": [
      "cs.HC",
      "cs.DB"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13647v2",
    "title": "On $z^\\circ$-ideals and annihilator ideals",
    "authors": [
      "A. Taherifar"
    ],
    "abstract": "For $a\\in R$, let $P_a$ denote the intersection of all minimal prime ideals\nof $R$ containing $a$. An ideal $I$ of a ring $R$ is called a $z^{\\circ}$-ideal\nif $P_a\\subseteq I$ for all $a\\in I$. In this paper, we first investigate the\nclass of $z^{\\circ}$-ideals in non-commutative rings. We provide\ncharacterizations of $z^{\\circ}$-ideals in 2-by-2 generalized triangular matrix\nrings, full and upper triangular matrix rings, and semiprime rings. Next, we\nexplore new properties of the lattice $rAnn(id(R))$, the set of right\nannihilator ideals of $R$. We prove that $rAnn(id(R))$ forms a frame when $R$\nis semiprime and a coherent frame when $R$ is a reduced ring. Furthermore, we\ncharacterize the smallest (resp., largest) right annihilator ideal contained in\nan ideal $I$ of an $SA$-ring $R$.",
    "pdf_url": "http://arxiv.org/pdf/2505.13647v2",
    "published": "2025-05-19T18:41:31+00:00",
    "categories": [
      "math.GN",
      "16D25, 16D70, 06D22"
    ],
    "primary_category": "math.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.13646v2",
    "title": "On the Present Status of Inflationary Cosmology",
    "authors": [
      "Renata Kallosh",
      "Andrei Linde"
    ],
    "abstract": "We give a brief review of the basic principles of inflationary theory and\ndiscuss the present status of the simplest inflationary models that can\ndescribe Planck/BICEP/Keck observational data by choice of a single model\nparameter. In particular, we discuss the Starobinsky model, Higgs inflation,\nand $\\alpha$-attractors, including the recently developed $\\alpha$-attractor\nmodels with $SL(2,\\mathbb{Z})$ invariant potentials. We also describe\ninflationary models providing a good fit to the recent ACT data, as well as the\npolynomial chaotic inflation models with three parameters, which can account\nfor any values of the three main CMB-related inflationary parameters $A_{s}$,\n$n_{s}$ and $r$.",
    "pdf_url": "http://arxiv.org/pdf/2505.13646v2",
    "published": "2025-05-19T18:32:21+00:00",
    "categories": [
      "hep-th",
      "astro-ph.CO",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13645v1",
    "title": "The evolution of CME sheath turbulence from L1 to Earth: Wind and MMS observations of the 2023-04-23 CME",
    "authors": [
      "Matthew R. Argall",
      "Li-Jen Chen",
      "No√© Lugaz",
      "Norberto Romanelli",
      "Jaye L. Verniero",
      "Charles W. Smith",
      "Brandon Burkholder",
      "Victoria Wilder"
    ],
    "abstract": "An interplanetary shock driven by a coronal mass ejection (CME) containing an\ninterval of sub-Alfv\\'enic flow impacted Earth on April 23, 2024. In this\narticle, we analyze the turbulence in the sheath region between the shock and\nCME to determine how it evolves from L1 (as observed by Wind) to Earth (as\nobserved by MMS, upstream of the bow shock). Wind and MMS were separated by\n$55\\,\\mathrm{R_{E}}$ in the dawn-dusk direction, but the shock normals differ\nby only $2.8^{\\circ}$ and the Pearson correlation coefficient between\ntime-shifted magnetic field components is $\\rho=0.93$. We observe a shift in\nthe break point of the magnetic power spectral density between inertial and ion\nkinetic scales toward the ion inertial length and a steepening of the spectral\nslope, indicating more active energy cascade closer to Earth. The distribution\nof increments becomes more non-Gaussian near Earth, particularly at ion kinetic\nscales, indicating the turbulence becomes more intermittent. Finally, the\ncorrelation length at Earth is 25\\% longer than at L1, indicating that the\nturbulence is smoothing out the magnetic field. The results present an example\nof substantial evolution of CME sheath turbulence from L1 to Earth.",
    "pdf_url": "http://arxiv.org/pdf/2505.13645v1",
    "published": "2025-05-19T18:31:51+00:00",
    "categories": [
      "physics.space-ph"
    ],
    "primary_category": "physics.space-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13644v1",
    "title": "Collapsing Taylor Mode Automatic Differentiation",
    "authors": [
      "Felix Dangel",
      "Tim Siebert",
      "Marius Zeinhofer",
      "Andrea Walther"
    ],
    "abstract": "Computing partial differential equation (PDE) operators via nested\nbackpropagation is expensive, yet popular, and severely restricts their utility\nfor scientific machine learning. Recent advances, like the forward Laplacian\nand randomizing Taylor mode automatic differentiation (AD), propose forward\nschemes to address this. We introduce an optimization technique for Taylor mode\nthat 'collapses' derivatives by rewriting the computational graph, and\ndemonstrate how to apply it to general linear PDE operators, and randomized\nTaylor mode. The modifications simply require propagating a sum up the\ncomputational graph, which could -- or should -- be done by a machine learning\ncompiler, without exposing complexity to users. We implement our collapsing\nprocedure and evaluate it on popular PDE operators, confirming it accelerates\nTaylor mode and outperforms nested backpropagation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13644v1",
    "published": "2025-05-19T18:31:31+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13643v1",
    "title": "FedCTTA: A Collaborative Approach to Continual Test-Time Adaptation in Federated Learning",
    "authors": [
      "Rakibul Hasan Rajib",
      "Md Akil Raihan Iftee",
      "Mir Sazzat Hossain",
      "A. K. M. Mahbubur Rahman",
      "Sajib Mistry",
      "M Ashraful Amin",
      "Amin Ahsan Ali"
    ],
    "abstract": "Federated Learning (FL) enables collaborative model training across\ndistributed clients without sharing raw data, making it ideal for\nprivacy-sensitive applications. However, FL models often suffer performance\ndegradation due to distribution shifts between training and deployment.\nTest-Time Adaptation (TTA) offers a promising solution by allowing models to\nadapt using only test samples. However, existing TTA methods in FL face\nchallenges such as computational overhead, privacy risks from feature sharing,\nand scalability concerns due to memory constraints. To address these\nlimitations, we propose Federated Continual Test-Time Adaptation (FedCTTA), a\nprivacy-preserving and computationally efficient framework for federated\nadaptation. Unlike prior methods that rely on sharing local feature statistics,\nFedCTTA avoids direct feature exchange by leveraging similarity-aware\naggregation based on model output distributions over randomly generated noise\nsamples. This approach ensures adaptive knowledge sharing while preserving data\nprivacy. Furthermore, FedCTTA minimizes the entropy at each client for\ncontinual adaptation, enhancing the model's confidence in evolving target\ndistributions. Our method eliminates the need for server-side training during\nadaptation and maintains a constant memory footprint, making it scalable even\nas the number of clients or training rounds increases. Extensive experiments\nshow that FedCTTA surpasses existing methods across diverse temporal and\nspatial heterogeneity scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.13643v1",
    "published": "2025-05-19T18:29:51+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13642v1",
    "title": "Non-Obvious Manipulability in Additively Separable and Fractional Hedonic Games",
    "authors": [
      "Diodato Ferraioli",
      "Giovanna Varricchio"
    ],
    "abstract": "In this work, we consider the design of Non-Obviously Manipulable (NOM)\nmechanisms, mechanisms that bounded rational agents may fail to recognize as\nmanipulable, for two relevant classes of succinctly representable Hedonic\nGames: Additively Separable and Fractional Hedonic Games. In these classes,\nagents have cardinal scores towards other agents, and their preferences over\ncoalitions are determined by aggregating such scores. This aggregation results\nin a utility function for each agent, which enables the evaluation of outcomes\nvia the utilitarian social welfare. We first prove that, when scores can be\narbitrary, every optimal mechanism is NOM; moreover, when scores are limited in\na continuous interval, there exists an optimal mechanism that is NOM. Given the\nhardness of computing optimal outcomes in these settings, we turn our attention\nto efficient and NOM mechanisms. To this aim, we first prove a characterization\nof NOM mechanisms that simplifies the class of mechanisms of interest. Then, we\ndesign a NOM mechanism returning approximations that asymptotically match the\nbest-known approximation achievable in polynomial time. Finally, we focus on\ndiscrete scores, where the compatibility of NOM with optimality depends on the\nspecific values. Therefore, we initiate a systematic analysis to identify which\ndiscrete values support this compatibility and which do not.",
    "pdf_url": "http://arxiv.org/pdf/2505.13642v1",
    "published": "2025-05-19T18:29:09+00:00",
    "categories": [
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13641v1",
    "title": "An Alignment Between the CRA's Essential Requirements and the ATT&CK's Mitigations",
    "authors": [
      "Jukka Ruohonen",
      "Eun-Young Kang",
      "Qusai Ramadan"
    ],
    "abstract": "The paper presents an alignment evaluation between the mitigations present in\nthe MITRE's ATT&CK framework and the essential cyber security requirements of\nthe recently introduced Cyber Resilience Act (CRA) in the European Union. In\noverall, the two align well with each other. With respect to the CRA, there are\nnotable gaps only in terms of data minimization, data erasure, and\nvulnerability coordination. In terms of the ATT&CK framework, gaps are present\nonly in terms of threat intelligence, training, out-of-band communication\nchannels, and residual risks. The evaluation presented contributes to narrowing\nof a common disparity between law and technical frameworks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13641v1",
    "published": "2025-05-19T18:29:00+00:00",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13640v1",
    "title": "Maximal 2-dimensional binary words of bounded degree",
    "authors": [
      "Alexandre Blondin Mass√©",
      "Alain Goupil",
      "Ralphael L'Heureux",
      "Louis Marin"
    ],
    "abstract": "Let d be an integer between 0 and 4, and W be a 2-dimensional word of\ndimensions h x w on the binary alphabet {0, 1}, where h, w in Z > 0. Assume\nthat each occurrence of the letter 1 in W is adjacent to at most d letters 1.\nWe provide an exact formula for the maximum number of letters 1 that can occur\nin W for fixed (h, w). As a byproduct, we deduce an upper bound on the length\nof maximum snake polyominoes contained in a h x w rectangle.",
    "pdf_url": "http://arxiv.org/pdf/2505.13640v1",
    "published": "2025-05-19T18:28:30+00:00",
    "categories": [
      "math.CO",
      "cs.FL"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13639v1",
    "title": "Ping-pong in the projective plane over a nonarchimedean field",
    "authors": [
      "Sami Douba",
      "Dmitry Kubrak",
      "Konstantinos Tsouvalas"
    ],
    "abstract": "We show that any lattice in $\\mathrm{SL}_3(k)$, where $k$ is a nonarchimedean\nlocal field, contains an undistorted subgroup isomorphic to the free product\n$\\mathbb{Z}^2*\\mathbb{Z}$. To our knowledge, the subgroups we construct give\nthe first examples in the literature of finitely generated Zariski-dense\ninfinite-covolume discrete subgroups of an almost simple group over a\nnonarchimedean local field that are not virtually free. Our result is in\ncontrast to the case of $\\mathrm{SL}_3(\\mathbb{Z})$, in which the existence of\na $\\mathbb{Z}^2*\\mathbb{Z}$ subgroup remains open.",
    "pdf_url": "http://arxiv.org/pdf/2505.13639v1",
    "published": "2025-05-19T18:24:11+00:00",
    "categories": [
      "math.GR",
      "math.NT"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.18743v1",
    "title": "From Representation to Mediation: A New Agenda for Conceptual Modeling Research in A Digital World",
    "authors": [
      "J. Recker",
      "R. Lukyanenko",
      "M. A. Jabbari",
      "B. M. Samuel",
      "A. Castellanos"
    ],
    "abstract": "The role of information systems (IS) as representations of real-world systems\nis changing in an increasingly digitalized world, suggesting that conceptual\nmodeling is losing its relevance to the IS field. We argue the opposite:\nConceptual modeling research is more relevant to the IS field than ever, but it\nrequires an update with current theory. We develop a new theoretical framework\nof conceptual modeling that delivers a fundamental shift in the assumptions\nthat govern research in this area. This move can make traditional knowledge\nabout conceptual modeling consistent with the emerging requirements of a\ndigital world. Our framework draws attention to the role of conceptual modeling\nscripts as mediators between physical and digital realities. We identify new\nresearch questions about grammars, methods, scripts, agents, and contexts that\nare situated in intertwined physical and digital realities. We discuss several\nimplications for conceptual modeling scholarship that relate to the necessity\nof developing new methods and grammars for conceptual modeling, broadening the\nmethodological array of conceptual modeling scholarship, and considering new\ndependent variables.",
    "pdf_url": "http://arxiv.org/pdf/2506.18743v1",
    "published": "2025-05-19T18:19:23+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13638v1",
    "title": "4Hammer: a board-game reinforcement learning environment for the hour long time frame",
    "authors": [
      "Massimo Fioravanti",
      "Giovanni Agosta"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong performance on tasks\nwith short time frames, but struggle with tasks requiring longer durations.\nWhile datasets covering extended-duration tasks, such as software engineering\ntasks or video games, do exist, there are currently few implementations of\ncomplex board games specifically designed for reinforcement learning and LLM\nevaluation. To address this gap, we propose the 4Hammer reinforcement learning\nenvironment, a digital twin simulation of a subset of Warhammer 40,000-a\ncomplex, zero-sum board game. Warhammer 40,000 features intricate rules,\nrequiring human players to thoroughly read and understand over 50 pages of\ndetailed natural language rules, grasp the interactions between their game\npieces and those of their opponents, and independently track and communicate\nthe evolving game state.",
    "pdf_url": "http://arxiv.org/pdf/2505.13638v1",
    "published": "2025-05-19T18:19:22+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13637v1",
    "title": "Single-photon detection enabled by negative differential conductivity in moir√© superlattices",
    "authors": [
      "Krystian Nowakowski",
      "Hitesh Agarwal",
      "Sergey Slizovskiy",
      "Robin Smeyers",
      "Xueqiao Wang",
      "Zhiren Zheng",
      "Julien Barrier",
      "David Barcons Ruiz",
      "Geng Li",
      "Riccardo Bertini",
      "Matteo Ceccanti",
      "Iacopo Torre",
      "Bert Jorissen",
      "Antoine Reserbat-Plantey",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Lucian Covaci",
      "Milorad V. Milo≈°eviƒá",
      "Vladimir Fal'ko",
      "Pablo Jarillo-Herrero",
      "Roshan Krishna Kumar",
      "Frank H. L. Koppens"
    ],
    "abstract": "Detecting individual light quanta is essential for quantum information, space\nexploration, advanced machine vision, and fundamental science. Here, we\nintroduce a novel single photon detection mechanism using highly photosensitive\nnon-equilibrium electron phases in moir\\'e materials. Using tunable bands in\nbilayer graphene/hexagonal-boron nitride superlattices, we engineer negative\ndifferential conductance and a sensitive bistable state capable of detecting\nsingle photons. Operating in this regime, we demonstrate single-photon counting\nat mid-infrared (11.3 microns) and visible wavelengths (675 nanometres) and\ntemperatures up to 25 K. This detector offers new prospects for broadband,\nhigh-temperature quantum technologies with CMOS compatibility and seamless\nintegration into photonic integrated circuits (PICs). Our analysis suggests the\nmechanism underlying our device operation originates from negative differential\nvelocity, and represents an important milestone in the field of high-bias\ntransport in two-dimensional moir\\'e quantum materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.13637v1",
    "published": "2025-05-19T18:19:15+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "physics.app-ph",
      "physics.optics"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.13636v1",
    "title": "Incentivizing Truthful Language Models via Peer Elicitation Games",
    "authors": [
      "Baiting Chen",
      "Tong Zhu",
      "Jiale Han",
      "Lexin Li",
      "Gang Li",
      "Xiaowu Dai"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong generative capabilities\nbut remain prone to inconsistencies and hallucinations. We introduce Peer\nElicitation Games (PEG), a training-free, game-theoretic framework for aligning\nLLMs through a peer elicitation mechanism involving a generator and multiple\ndiscriminators instantiated from distinct base models. Discriminators interact\nin a peer evaluation setting, where rewards are computed using a\ndeterminant-based mutual information score that provably incentivizes truthful\nreporting without requiring ground-truth labels. We establish theoretical\nguarantees showing that each agent, via online learning, achieves sublinear\nregret in the sense their cumulative performance approaches that of the best\nfixed truthful strategy in hindsight. Moreover, we prove last-iterate\nconvergence to a truthful Nash equilibrium, ensuring that the actual policies\nused by agents converge to stable and truthful behavior over time. Empirical\nevaluations across multiple benchmarks demonstrate significant improvements in\nfactual accuracy. These results position PEG as a practical approach for\neliciting truthful behavior from LLMs without supervision or fine-tuning.",
    "pdf_url": "http://arxiv.org/pdf/2505.13636v1",
    "published": "2025-05-19T18:16:58+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13635v1",
    "title": "Unsplittable Multicommodity Flows in Outerplanar Graphs",
    "authors": [
      "David Alem√°n-Espinosa",
      "Nikhil Kumar"
    ],
    "abstract": "We consider the problem of multicommodity flows in outerplanar graphs.\nOkamura and Seymour showed that the cut-condition is sufficient for routing\ndemands in outerplanar graphs. We consider the unsplittable version of the\nproblem and prove that if the cut-condition is satisfied, then we can route\neach demand along a single path by exceeding the capacity of an edge by no more\nthan $\\frac{18}{5} \\cdot d_{max}$, where $d_{max}$ is the value of the maximum\ndemand.",
    "pdf_url": "http://arxiv.org/pdf/2505.13635v1",
    "published": "2025-05-19T18:15:26+00:00",
    "categories": [
      "cs.DS",
      "F.2.2; G.1.6; G.2.1"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13634v1",
    "title": "OH molecule as a quantum probe to jointly estimate electric and magnetic fields",
    "authors": [
      "Luca Previdi",
      "Francesco Albarelli",
      "Matteo G. A. Paris"
    ],
    "abstract": "The OH molecule (OHM) carries both electric and magnetic dipole moments and\nit is characterized by a diatomic structure that simplifies its modeling. Thus,\nit naturally emerges as a quantum probe for joint estimation of electric and\nmagnetic fields. In this paper, we address optimal strategies to jointly\nestimate the two fields and to overcome the additional quantum noise due to\ntheir incompatibility. We study and optimize stationary and dynamical\nestimation strategies, and devise a sequential control scheme to beat the\nlimitations imposed by non commutativity in specific configurations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13634v1",
    "published": "2025-05-19T18:15:03+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13633v1",
    "title": "IPENS:Interactive Unsupervised Framework for Rapid Plant Phenotyping Extraction via NeRF-SAM2 Fusion",
    "authors": [
      "Wentao Song",
      "He Huang",
      "Youqiang Sun",
      "Fang Qu",
      "Jiaqi Zhang",
      "Longhui Fang",
      "Yuwei Hao",
      "Chenyang Peng"
    ],
    "abstract": "Advanced plant phenotyping technologies play a crucial role in targeted trait\nimprovement and accelerating intelligent breeding. Due to the species diversity\nof plants, existing methods heavily rely on large-scale high-precision manually\nannotated data. For self-occluded objects at the grain level, unsupervised\nmethods often prove ineffective. This study proposes IPENS, an interactive\nunsupervised multi-target point cloud extraction method. The method utilizes\nradiance field information to lift 2D masks, which are segmented by SAM2\n(Segment Anything Model 2), into 3D space for target point cloud extraction. A\nmulti-target collaborative optimization strategy is designed to effectively\nresolve the single-interaction multi-target segmentation challenge.\nExperimental validation demonstrates that IPENS achieves a grain-level\nsegmentation accuracy (mIoU) of 63.72% on a rice dataset, with strong\nphenotypic estimation capabilities: grain volume prediction yields R2 = 0.7697\n(RMSE = 0.0025), leaf surface area R2 = 0.84 (RMSE = 18.93), and leaf length\nand width predictions achieve R2 = 0.97 and 0.87 (RMSE = 1.49 and 0.21). On a\nwheat dataset,IPENS further improves segmentation accuracy to 89.68% (mIoU),\nwith equally outstanding phenotypic estimation performance: spike volume\nprediction achieves R2 = 0.9956 (RMSE = 0.0055), leaf surface area R2 = 1.00\n(RMSE = 0.67), and leaf length and width predictions reach R2 = 0.99 and 0.92\n(RMSE = 0.23 and 0.15). This method provides a non-invasive, high-quality\nphenotyping extraction solution for rice and wheat. Without requiring annotated\ndata, it rapidly extracts grain-level point clouds within 3 minutes through\nsimple single-round interactions on images for multiple targets, demonstrating\nsignificant potential to accelerate intelligent breeding efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.13633v1",
    "published": "2025-05-19T18:13:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13632v1",
    "title": "Well-posedness and mean-field limit estimate of a consensus-based algorithm for multiplayer games",
    "authors": [
      "Hui Huang",
      "Jethro Warnett"
    ],
    "abstract": "Recently, the paper [12] introduces a derivative-free consensus-based\nparticle method that finds the Nash equilibrium of non-convex multiplayer\ngames, where it proves the global exponential convergence in the sense of\nmean-field law. This paper aims to address theoretical gaps in [12],\nspecifically by providing a quantitative estimate of the mean-field limit with\nrespect to the number of particles, as well as establishing the well-posedness\nof both the finite particle model and the corresponding mean-field dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.13632v1",
    "published": "2025-05-19T18:09:10+00:00",
    "categories": [
      "math.OC",
      "math.CA",
      "math.PR"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13631v1",
    "title": "Learning (Approximately) Equivariant Networks via Constrained Optimization",
    "authors": [
      "Andrei Manolache",
      "Luiz F. O. Chamon",
      "Mathias Niepert"
    ],
    "abstract": "Equivariant neural networks are designed to respect symmetries through their\narchitecture, boosting generalization and sample efficiency when those\nsymmetries are present in the data distribution. Real-world data, however,\noften departs from perfect symmetry because of noise, structural variation,\nmeasurement bias, or other symmetry-breaking effects. Strictly equivariant\nmodels may struggle to fit the data, while unconstrained models lack a\nprincipled way to leverage partial symmetries. Even when the data is fully\nsymmetric, enforcing equivariance can hurt training by limiting the model to a\nrestricted region of the parameter space. Guided by homotopy principles, where\nan optimization problem is solved by gradually transforming a simpler problem\ninto a complex one, we introduce Adaptive Constrained Equivariance (ACE), a\nconstrained optimization approach that starts with a flexible, non-equivariant\nmodel and gradually reduces its deviation from equivariance. This gradual\ntightening smooths training early on and settles the model at a data-driven\nequilibrium, balancing between equivariance and non-equivariance. Across\nmultiple architectures and tasks, our method consistently improves performance\nmetrics, sample efficiency, and robustness to input perturbations compared with\nstrictly equivariant models and heuristic equivariance relaxations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13631v1",
    "published": "2025-05-19T18:08:09+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13630v1",
    "title": "Metric Distortion for Tournament Voting and Beyond",
    "authors": [
      "Moses Charikar",
      "Prasanna Ramakrishnan",
      "Zihan Tan",
      "Kangning Wang"
    ],
    "abstract": "In the well-studied metric distortion problem in social choice, we have\nvoters and candidates located in a shared metric space, and the objective is to\ndesign a voting rule that selects a candidate with minimal total distance to\nthe voters. However, the voting rule has limited information about the\ndistances in the metric, such as each voter's ordinal rankings of the\ncandidates in order of distances. The central question is whether we can design\nrules that, for any election and underlying metric space, select a candidate\nwhose total cost deviates from the optimal by only a small factor, referred to\nas the distortion.\n  A long line of work resolved the optimal distortion of deterministic rules,\nand recent work resolved the optimal distortion of randomized (weighted)\ntournament rules, which only use the aggregate preferences between pairs of\ncandidates. In both cases, simple rules achieve the optimal distortion of $3$.\nCan we achieve the best of both worlds: a deterministic tournament rule\nmatching the lower bound of $3$? Prior to our work, the best rules have\ndistortion $2 + \\sqrt{5} \\approx 4.2361$.\n  In this work, we establish a lower bound of $3.1128$ on the distortion of any\ndeterministic tournament rule, even when there are only 5 candidates, and\nimprove the upper bound with a novel rule guaranteeing distortion $3.9312$. We\nthen generalize tournament rules to the class of $k$-tournament rules which\nobtain the aggregate preferences between $k$-tuples of candidates. We show that\nthere is a family of deterministic $k$-tournament rules that achieves\ndistortion approaching $3$ as $k$ grows. Finally, we show that even with $k =\n3$, a randomized $k$-tournament rule can achieve distortion less than $3$,\nwhich had been a longstanding barrier even for the larger class of ranked\nvoting rules.",
    "pdf_url": "http://arxiv.org/pdf/2505.13630v1",
    "published": "2025-05-19T18:06:52+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13629v1",
    "title": "Can local White Dwarfs constrain Dark Matter interactions?",
    "authors": [
      "Pooja Bhattacharjee",
      "Sandra Robles",
      "Stephan A. Meighen-Berger",
      "Francesca Calore"
    ],
    "abstract": "We investigate whether nearby white dwarfs (WDs) can constrain dark matter\n(DM) interactions with ordinary matter. As experimental sensitivity improves,\ndriven by the Gaia mission, the sample volume of nearby WDs has been increasing\nover recent years. We carefully select a sample of ten cold, isolated,\nnon-magnetic WDs within 13~pc of the Sun. We model their carbon-oxygen interior\nusing a finite temperature relativistic equation of state and model atmospheres\nto infer their core temperatures. This enables us to perform a thorough\nestimation of the DM capture rate and evaporation mass using actual\nastrophysical observations. Given the low local DM density, we focus on DM that\nannihilates into long-lived mediators, which escape the WD and later decay into\nphotons. While \\textit{Fermi}-LAT data shows no significant gamma-ray excess,\nfuture telescopes, CTA North \\& South, LHAASO, SWGO, could probe DM-nucleon\ncross sections down to $\\sim 10^{-41}~\\text{cm}^2$ for DM masses above the TeV\nscale. Our results are competitive with current direct detection bounds (e.g.,\nLZ) in the multi-TeV regime. This work underscores the importance of systematic\nWD studies in the broader landscape of DM detection and demonstrates the\nsynergy between astrophysical and terrestrial searches in exploring DM\ninteractions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13629v1",
    "published": "2025-05-19T18:06:50+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "astro-ph.HE",
      "astro-ph.SR"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13628v1",
    "title": "Cross-Lingual Representation Alignment Through Contrastive Image-Caption Tuning",
    "authors": [
      "Nathaniel Krasner",
      "Nicholas Lanuzo",
      "Antonios Anastasopoulos"
    ],
    "abstract": "Multilingual alignment of sentence representations has mostly required\nbitexts to bridge the gap between languages. We investigate whether visual\ninformation can bridge this gap instead. Image caption datasets are very easy\nto create without requiring multilingual expertise, so this offers a more\nefficient alternative for low-resource languages. We find that multilingual\nimage-caption alignment can implicitly align the text representations between\nlanguages, languages unseen by the encoder in pretraining can be incorporated\ninto this alignment post-hoc, and these aligned representations are usable for\ncross-lingual Natural Language Understanding (NLU) and bitext retrieval.",
    "pdf_url": "http://arxiv.org/pdf/2505.13628v1",
    "published": "2025-05-19T18:06:45+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13627v1",
    "title": "Mass of Cepheid V350 Sgr Incorporating Interferometry and the Companion Mass",
    "authors": [
      "Nancy Remage Evans",
      "Alexandre Gallenne",
      "Pierre Kervella",
      "H. Moritz Guenther",
      "Joanna Kuraszkiewicz",
      "Richard I. Anderson",
      "Charles Proffitt",
      "Antoine Merand",
      "Boris Trahin",
      "Giordano Viviani",
      "Shreeya Shetye"
    ],
    "abstract": "The system V350 Sgr has a classical Cepheid for the primary. Interferometry\nis presented for the system and the full orbit is determined. The mass of the\ncompanion has been determined from an {\\it IUE} spectrum and comparison with\nthe mass-temperature relation from Detached Eclipsing Binaries. Combined with\nthe mass of the companion (2.6 $\\pm$ 0.2 M$_\\odot$), the mass of the Cepheid is\ndetermined to be 4.7 $\\pm$ 0.8 M$_\\odot$. For systems with less complete\ninformation, Cepheid masses can be determined from a single-lined spectroscopic\norbit, {\\it Gaia} proper motion anomalies, and the mass of the companion from\nthe ultraviolet. Uncertainties resulting from different approaches to mass\ndetermination are discussed, and are expected to be reduced after the {\\it\nGaia} DR4 release. Temperatures for Morgan Keenan (MK) standard stars from the\nultraviolet are also provided.",
    "pdf_url": "http://arxiv.org/pdf/2505.13627v1",
    "published": "2025-05-19T18:06:22+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13626v3",
    "title": "Methods to Test the Source of the Extreme Gas Motions in WS 35",
    "authors": [
      "Sean J. Gunderson",
      "Richard Ignace",
      "Walter W. Golay"
    ],
    "abstract": "We present theoretical arguments toward the plausibility of a stellar wind to\nexplain the 16000 km s$^{-1}$ line broadening in the optical spectra of WS 35,\nthe central star in the Pa 30 nebula. The wind model is discussed in the\ncontext of super-Eddington flows. We argue that WS 35 potentially occupies a\nnew regime of wind driving theory as the first metal-only wind. While this\nframework provides a promising avenue for explaining the high speed flow,\nquestions remain about the source's true nature. We further describe how future\nradio observations can provide an independent test of the spherical wind\nscenario. A magnetically channeled wind would likely produce a relatively flat\nand bright radio spectral energy distributions. By contrast a spherical wind\nshould result in a thermal radio spectrum with a canonical continuum slope of\n$\\nu^{0.6}$, and a brightness level consistent with the currently predicted\nmass-loss rate.",
    "pdf_url": "http://arxiv.org/pdf/2505.13626v3",
    "published": "2025-05-19T18:05:43+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13625v1",
    "title": "Classical Criticality via Quantum Annealing",
    "authors": [
      "Pratik Sathe",
      "Andrew D. King",
      "Susan M. Mniszewski",
      "Carleton Coffrin",
      "Cristiano Nisoli",
      "Francesco Caravelli"
    ],
    "abstract": "Quantum annealing provides a powerful platform for simulating magnetic\nmaterials and realizing statistical physics models, presenting a compelling\nalternative to classical Monte Carlo methods. We demonstrate that quantum\nannealers can accurately reproduce phase diagrams and simulate critical\nphenomena without suffering from the critical slowing down that often affects\nclassical algorithms. To illustrate this, we study the piled-up dominoes model,\nwhich interpolates between the ferromagnetic 2D Ising model and Villain's fully\nfrustrated ``odd model''. We map out its phase diagram and for the first time,\nemploy finite-size scaling and Binder cumulants on a quantum annealer to study\ncritical exponents for thermal phase transitions. Our method achieves\nsystematic temperature control by tuning the energy scale of the Hamiltonian,\neliminating the need to adjust the physical temperature of the quantum\nhardware. This work demonstrates how, through fine-tuning and calibration, a\nquantum annealer can be employed to apply sophisticated finite-size scaling\ntechniques from statistical mechanics. Our results establish quantum annealers\nas robust statistical physics simulators, offering a novel pathway for studying\nphase transitions and critical behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.13625v1",
    "published": "2025-05-19T18:04:27+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.dis-nn",
      "quant-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.13624v1",
    "title": "Viability of post-inflationary freeze-in with precision cosmology",
    "authors": [
      "Anirban Biswas",
      "Sougata Ganguly",
      "Dibyendu Nanda",
      "Sujit Kumar Sahoo"
    ],
    "abstract": "Prediction of inflationary observables from the temperature fluctuation of\nCosmic Microwave Background (CMB) can play a pivotal role in predicting the\nreheating dynamics in the early universe. In this work, we highlight how the\ninflationary observables, in particular the spectral index $n_s$, can play a\npotential role in constraining the post-inflationary dark matter (DM)\nproduction. We demonstrate a novel way of constraining the non-thermal\nproduction of DM via UV freeze-in which is otherwise elusive in terrestrial\nexperiments. We consider a scenario in which DM is produced from this thermal\nplasma via a dimension-five operator. The mutual connection between $n_s$ and\nrelic density of DM via the reheating temperature, $T_{\\rm RH}$, enables us to\nput constraints on the DM parameter space. For the minimal choice of the\ninflationary model parameters and DM mass between $1\\,\\rm MeV$ to $1\\,\\rm TeV$,\nwe found that Planck alone can exclude the cut-off scale of the dimension-five\noperator $\\Lambda \\lesssim 10^{12}\\,\\rm GeV$ which is significantly stronger\nthan any other existing constraints on such minimal scenario. If we impose the\ncombined prediction form Planck and recently released data by ACT, the\nexclusion limit can reach up to the Planck scale for TeV-scale dark matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.13624v1",
    "published": "2025-05-19T18:04:25+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13623v1",
    "title": "Probing Reheating Phase via Non-Helical Magnetogenesis and Secondary Gravitational Waves",
    "authors": [
      "Subhasis Maiti",
      "Debaprasad Maity",
      "Rohan Srikanth"
    ],
    "abstract": "In the past two decades, significant advancements have been made in\nobservational techniques to enhance our understanding of the universe and its\nevolutionary processes. However, our knowledge of the post-inflation reheating\nphase remains limited due to its small-scale dynamics. Traditional\nobservations, such as those of the Cosmic Microwave Background (CMB), primarily\nprovide insights into large-scale dynamics, making it challenging to glean\ninformation about the reheating era. In this paper, our primary aim is to\nexplore how the generation of Gravitational Waves (GWs) spectra, resulting from\nelectromagnetic fields in the early universe, can offer valuable insights into\nthe Reheating dynamics. We investigate how the spectral shape of GWs varies\nacross different frequency ranges, depending on the initial magnetic profile\nand reheating dynamics. For this, we consider a well-known non-helical\nmagnetogenesis model, where the usual electromagnetic kinetic term is coupled\nwith a background scalar. Notably, for such a scenario, we observe distinct\nspectral shapes with sufficiently high amplitudes for different reheating\nhistories with the equation of state parametrized by ($w_{\\rm re}$). We\nidentify spectral breaks in the GW spectra for both $w_{\\rm re}<1/3$ and\n$w_{\\rm re}>1/3$ scenarios. We find that future GW experiments such as BBO,\nLISA, SKA, and DECIGO are well within the reach of observing those distinct\nspectral shapes and can potentially shed light on the underlying mechanism of\nthe reheating phase.",
    "pdf_url": "http://arxiv.org/pdf/2505.13623v1",
    "published": "2025-05-19T18:03:56+00:00",
    "categories": [
      "astro-ph.CO",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13622v1",
    "title": "Spiking Neural Networks with Random Network Architecture",
    "authors": [
      "Zihan Dai",
      "Huanfei Ma"
    ],
    "abstract": "The spiking neural network, known as the third generation neural network, is\nan important network paradigm. Due to its mode of information propagation that\nfollows biological rationality, the spiking neural network has strong energy\nefficiency and has advantages in complex high-energy application scenarios.\nHowever, unlike the artificial neural network (ANN) which has a mature and\nunified framework, the SNN models and training methods have not yet been widely\nunified due to the discontinuous and non-differentiable property of the firing\nmechanism. Although several algorithms for training spiking neural networks\nhave been proposed in the subsequent development process, some fundamental\nissues remain unsolved. Inspired by random network design, this work proposes a\nnew architecture for spiking neural networks, RanSNN, where only part of the\nnetwork weights need training and all the classic training methods can be\nadopted. Compared with traditional training methods for spiking neural\nnetworks, it greatly improves the training efficiency while ensuring the\ntraining performance, and also has good versatility and stability as validated\nby benchmark tests.",
    "pdf_url": "http://arxiv.org/pdf/2505.13622v1",
    "published": "2025-05-19T18:03:55+00:00",
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13621v3",
    "title": "Bayesian Hierarchical Models for Quantitative Estimates for Performance metrics applied to Saddle Search Algorithms",
    "authors": [
      "Rohit Goswami"
    ],
    "abstract": "Rigorous performance evaluation is essential for developing robust algorithms\nfor high-throughput computational chemistry. Traditional benchmarking, however,\noften struggles to account for system-specific variability, making it difficult\nto form actionable conclusions. We present a Bayesian hierarchical modeling\nframework that rigorously quantifies performance metrics and their uncertainty,\nenabling a nuanced comparison of algorithmic strategies. We apply this\nframework to analyze the Dimer method, comparing Conjugate Gradient (CG) and\nL-BFGS rotation optimizers, with and without the removal of external rotations,\nacross a benchmark of 500 molecular systems. Our analysis confirms that CG\noffers higher overall robustness than L-BFGS in this context. While the\ntheoretically-motivated removal of external rotations led to higher\ncomputational cost (>40% more energy and force calls) for most systems in this\nset, our models also reveal a subtle interplay, hinting that this feature may\nimprove the reliability of the L-BFGS optimizer. Rather than identifying a\nsingle superior method, our findings support the design of adaptive \"chain of\nmethods\" workflows. This work showcases how a robust statistical paradigm can\nmove beyond simple performance rankings to inform the intelligent,\ncontext-dependent application of computational chemistry methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13621v3",
    "published": "2025-05-19T18:03:26+00:00",
    "categories": [
      "physics.chem-ph",
      "cs.PF"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13619v2",
    "title": "SALT spectroscopic follow-up of the G4Jy Sample",
    "authors": [
      "Sarah V. White",
      "Kshitij Thorat",
      "Moses Mogotsi",
      "Rosalind E. Skelton",
      "Solohery M. Randriamampandry",
      "Encarni Romero-Colmenero",
      "Precious K. Sejake",
      "Francesco Massaro",
      "Abigail Garcia-Perez",
      "Ana Jimenez-Gallardo",
      "Harold A. Pena-Herazo",
      "Edward N. Taylor"
    ],
    "abstract": "The GLEAM 4-Jy (G4Jy) Sample is a thorough compilation of the 'brightest'\nradio sources in the southern sky (Declination < 30 deg), as measured at 151\nMHz (S > 4.0 Jy) with the Murchison Widefield Array (MWA), through the GaLactic\nand Extragalactic All-sky MWA (GLEAM) Survey. In addition to flux-density\nmeasurements, the G4Jy catalogue provides host-galaxy identifications (through\ncareful visual-inspection) and four sets of spectral indices. Despite their\nbrightness in the radio, many of these sources are poorly-studied, with the\nvast majority lacking a spectroscopic redshift in published work. This is\ncrucial for studying the intrinsic properties of the sources, and so we conduct\na multi-semester observing campaign on the Southern African Large Telescope\n(SALT), with optical spectroscopy enabling us to provide new redshifts to the\nastronomical community. Initial results show that not all of the host galaxies\nexhibit emission-line spectra in the optical (~4500-7500 Ang), which\nillustrates the importance of radio-frequency selection (rather than optical\nselection) for creating an unbiased sample of active galactic nuclei. By\ncombining SALT redshifts with those from the 6-degree Field Galaxy Survey\n(6dFGS) and the Sloan Digital Sky Survey (SDSS), we calculate radio\nluminosities and linear sizes for 299 G4Jy sources (which includes one\nnewly-discovered giant radio-galaxy, G4Jy 604). Furthermore, with the highest\nredshift acquired (so far) being z ~ 2.2 from SDSS, we look forward to\nevolution studies of this complete sample, as well as breaking degeneracies in\nradio properties with respect to, for example, the galaxy environment.",
    "pdf_url": "http://arxiv.org/pdf/2505.13619v2",
    "published": "2025-05-19T18:02:44+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13620v2",
    "title": "Field-Level Comparison and Robustness Analysis of Cosmological N-body Simulations",
    "authors": [
      "Adrian E. Bayer",
      "Francisco Villaescusa-Navarro",
      "Sammy Sharief",
      "Romain Teyssier",
      "Lehman H. Garrison",
      "Laurence Perreault-Levasseur",
      "Greg L. Bryan",
      "Marco Gatti",
      "Eli Visbal"
    ],
    "abstract": "We present the first field-level comparison of cosmological N-body\nsimulations, considering various widely used codes: Abacus, CUBEP$^3$M, Enzo,\nGadget, Gizmo, PKDGrav, and Ramses. Unlike previous comparisons focused on\nsummary statistics, we conduct a comprehensive field-level analysis: evaluating\nstatistical similarity, quantifying implications for cosmological parameter\ninference, and identifying the regimes in which simulations are consistent. We\nbegin with a traditional comparison using the power spectrum, cross-correlation\ncoefficient, and visual inspection of the matter field. We follow this with a\nstatistical out-of-distribution (OOD) analysis to quantify distributional\ndifferences between simulations, revealing insights not captured by the\ntraditional metrics. We then perform field-level simulation-based inference\n(SBI) using convolutional neural networks (CNNs), training on one simulation\nand testing on others, including a full hydrodynamic simulation for comparison.\nWe identify several causes of OOD behavior and biased inference, finding that\nresolution effects, such as those arising from adaptive mesh refinement (AMR),\nhave a significant impact. Models trained on non-AMR simulations fail\ncatastrophically when evaluated on AMR simulations, introducing larger biases\nthan those from hydrodynamic effects. Differences in resolution, even when\nusing the same N-body code, likewise lead to biased inference. We attribute\nthese failures to a CNN's sensitivity to small-scale fluctuations, particularly\nin voids and filaments, and demonstrate that appropriate smoothing brings the\nsimulations into statistical agreement. Our findings motivate the need for\ncareful data filtering and the use of field-level OOD metrics, such as PQMass,\nto ensure robust inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.13620v2",
    "published": "2025-05-19T18:02:44+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13618v1",
    "title": "Spectrum of BPS black holes in $AdS_3 \\times S^3 \\times S^3 \\times S^1$",
    "authors": [
      "Matthew Heydeman",
      "Xiaoyi Shi",
      "Gustavo J. Turiaci"
    ],
    "abstract": "We uncover novel features in the spectrum of BPS and near-BPS states in\nasymptotically $AdS_3 \\times S^3 \\times S^3 \\times S^1$ spacetimes. This\nfollows from a careful analysis of semiclassical and quantum black holes in\nthis theory, which have peculiarities due to the nonlinear large\n$\\mathcal{N}=4$ superconformal symmetry. Notably, we find that the $S^3 \\times\nS^3$ angular momentum spectrum of BPS states in the Ramond sector exhibits\ndiscrete jumps as a function of the ratio between the radii of the two\nthree-spheres. This phenomenon is a quantum gravity effect for which no\nmicroscopic derivation is currently known. In addition, we construct a family\nof non-extremal supersymmetric black holes that contribute to a supersymmetric\nindex yet possess a temperature-dependent free energy. Analogous results apply\nto six-dimensional black holes with $AdS_2 \\times S^2 \\times S^2$ near-horizon\ngeometries constructed in M-theory compactifications.",
    "pdf_url": "http://arxiv.org/pdf/2505.13618v1",
    "published": "2025-05-19T18:02:10+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.22438v1",
    "title": "Counting with Confidence: Accurate Pest Monitoring in Water Traps",
    "authors": [
      "Xumin Gao",
      "Mark Stevens",
      "Grzegorz Cielniak"
    ],
    "abstract": "Accurate pest population monitoring and tracking their dynamic changes are\ncrucial for precision agriculture decision-making. A common limitation in\nexisting vision-based automatic pest counting research is that models are\ntypically evaluated on datasets with ground truth but deployed in real-world\nscenarios without assessing the reliability of counting results due to the lack\nof ground truth. To this end, this paper proposed a method for comprehensively\nevaluating pest counting confidence in the image, based on information related\nto counting results and external environmental conditions. First, a pest\ndetection network is used for pest detection and counting, extracting counting\nresult-related information. Then, the pest images undergo image quality\nassessment, image complexity assessment, and pest distribution uniformity\nassessment. And the changes in image clarity caused by stirring during image\nacquisition are quantified by calculating the average gradient magnitude.\nNotably, we designed a hypothesis-driven multi-factor sensitivity analysis\nmethod to select the optimal image quality assessment and image complexity\nassessment methods. And we proposed an adaptive DBSCAN clustering algorithm for\npest distribution uniformity assessment. Finally, the obtained information\nrelated to counting results and external environmental conditions is input into\na regression model for prediction, resulting in the final pest counting\nconfidence. To the best of our knowledge, this is the first study dedicated to\ncomprehensively evaluating counting confidence in counting tasks, and\nquantifying the relationship between influencing factors and counting\nconfidence through a model. Experimental results show our method reduces MSE by\n31.7% and improves R2 by 15.2% on the pest counting confidence test set,\ncompared to the baseline built primarily on information related to counting\nresults.",
    "pdf_url": "http://arxiv.org/pdf/2506.22438v1",
    "published": "2025-05-19T18:01:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13617v1",
    "title": "Direction-Aware Neural Acoustic Fields for Few-Shot Interpolation of Ambisonic Impulse Responses",
    "authors": [
      "Christopher Ick",
      "Gordon Wichern",
      "Yoshiki Masuyama",
      "Fran√ßois Germain",
      "Jonathan Le Roux"
    ],
    "abstract": "The characteristics of a sound field are intrinsically linked to the\ngeometric and spatial properties of the environment surrounding a sound source\nand a listener. The physics of sound propagation is captured in a time-domain\nsignal known as a room impulse response (RIR). Prior work using neural fields\n(NFs) has allowed learning spatially-continuous representations of RIRs from\nfinite RIR measurements. However, previous NF-based methods have focused on\nmonaural omnidirectional or at most binaural listeners, which does not\nprecisely capture the directional characteristics of a real sound field at a\nsingle point. We propose a direction-aware neural field (DANF) that more\nexplicitly incorporates the directional information by Ambisonic-format RIRs.\nWhile DANF inherently captures spatial relations between sources and listeners,\nwe further propose a direction-aware loss. In addition, we investigate the\nability of DANF to adapt to new rooms in various ways including low-rank\nadaptation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13617v1",
    "published": "2025-05-19T18:01:53+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13616v1",
    "title": "FIRES: Fluid Integrated Reflecting and Emitting Surfaces",
    "authors": [
      "Farshad Rostami Ghadi",
      "Kai-Kit Wong",
      "Masoud Kaveh",
      "F. Javier Lopez-Martinez",
      "Chan-Byoung Chae",
      "George C. Alexandropoulos"
    ],
    "abstract": "This letter introduces the concept of fluid integrated reflecting and\nemitting surface (FIRES), which constitutes a new paradigm seamlessly\nintegrating the flexibility of fluid-antenna systems (FASs) with the dual\nfunctionality of simultaneous transmitting and reflecting reconfigurable\nintelligent surfaces (STAR-RISs). The potential of the proposed metasurface\nstructure is studied though an FIRES-enabled multicast system based on the\nenergy splitting protocol. In this model, the FIRES is divided into\nnon-overlapping subareas, each functioning as a 'fluid' element capable of\nconcurrent reflection and transmission and changing its position of radiation\nwithin the subarea. In particular, we formulate an optimization problem for the\ndesign of the triple tunable features of the surface unit elements, which is\nsolved via a tailored particle swarm optimization approach. Our results\nshowcase that the proposed FIRES architecture significantly outperforms its\nconventional STAR-RIS counterpart.",
    "pdf_url": "http://arxiv.org/pdf/2505.13616v1",
    "published": "2025-05-19T18:01:35+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13615v2",
    "title": "Predicting mosquito flight behavior using Bayesian dynamical systems learning",
    "authors": [
      "Christopher Zuo",
      "Chenyi Fei",
      "Alexander E. Cohen",
      "Soohwan Kim",
      "Ring T. Carde",
      "J√∂rn Dunkel",
      "David L. Hu"
    ],
    "abstract": "Mosquito-borne diseases cause several hundred thousand deaths every year.\nDeciphering mosquito host-seeking behavior is essential to prevent disease\ntransmission through mosquito capture and surveillance. Despite recent\nsubstantial progress, we currently lack a comprehensive quantitative\nunderstanding of how visual and other sensory cues guide mosquitoes to their\ntargets. Here, we combined 3D infrared tracking of Aedes aegypti mosquitoes\nwith Bayesian dynamical systems inference to learn a quantitative biophysical\nmodel of mosquito host-seeking behavior. Trained on more than 20,000,000 data\npoints from mosquito free-flight trajectories recorded in the presence of\nvisual and carbon dioxide cues, the model accurately predicts how mosquitoes\nrespond to human targets. Our results provide a quantitative foundation for\noptimizing mosquito capture and control strategies, a key step towards\nmitigating the impact of mosquito-borne diseases.",
    "pdf_url": "http://arxiv.org/pdf/2505.13615v2",
    "published": "2025-05-19T18:01:25+00:00",
    "categories": [
      "physics.bio-ph"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13614v1",
    "title": "Deterministic Bounds and Random Estimates of Metric Tensors on Neuromanifolds",
    "authors": [
      "Ke Sun"
    ],
    "abstract": "The high dimensional parameter space of modern deep neural networks -- the\nneuromanifold -- is endowed with a unique metric tensor defined by the Fisher\ninformation, estimating which is crucial for both theory and practical methods\nin deep learning. To analyze this tensor for classification networks, we return\nto a low dimensional space of probability distributions -- the core space --\nand carefully analyze the spectrum of its Riemannian metric. We extend our\ndiscoveries there into deterministic bounds of the metric tensor on the\nneuromanifold. We introduce an unbiased random estimate of the metric tensor\nand its bounds based on Hutchinson's trace estimator. It can be evaluated\nefficiently through a single backward pass and can be used to estimate the\ndiagonal, or block diagonal, or the full tensor. Its quality is guaranteed with\na standard deviation bounded by the true value up to scaling.",
    "pdf_url": "http://arxiv.org/pdf/2505.13614v1",
    "published": "2025-05-19T18:01:08+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13613v1",
    "title": "Distinguishing Distance Duality breaking models using electromagnetic and gravitational waves measurements",
    "authors": [
      "Chiara De Leo",
      "Matteo Martinelli",
      "Rocco D'Agostino",
      "Giulia Gianfagna",
      "Carlos J. A. P. Martins"
    ],
    "abstract": "Several assumptions at the foundation of the standard cosmological model have\nas a direct consequence a specific relation between cosmological distances,\nknown as the distance duality relation, whose violation would be a smoking gun\nof deviations from standard cosmology. We explore the role of upcoming\ngravitational wave observations in investigating possible deviations from the\ndistance duality relation, alongside the more commonly used supernovae. We find\nthat, when combined with baryon acoustic oscillations, gravitational waves will\nprovide similar constraining power to the combination of baryon acoustic\noscillations and supernovae. Moreover, the combination of observables with\ndifferent sensitivities to electromagnetic and gravitational physics provides a\npromising way to discriminate among different physical mechanisms that could\nlead to violations of the distance duality relation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13613v1",
    "published": "2025-05-19T18:01:03+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13612v1",
    "title": "Sight, Sound and Smell in Immersive Experiences of Urban History: Virtual Vauxhall Gardens Case Study",
    "authors": [
      "Tim Pearce",
      "David Souto",
      "Douglas Barrett",
      "Benjamin Lok",
      "Mateusz Bocian",
      "Artur Soczawa-Stronczyk",
      "Giasemi Vavoula",
      "Paul Long",
      "Avinash Bhangaonkar",
      "Stephanie Bowry",
      "Michaela Butter",
      "David Coke",
      "Kate Loveman",
      "Rosemary Sweet",
      "Lars Tharp",
      "Jeremy Webster",
      "Hongji Yang",
      "Robin Green",
      "Andrew Hugill"
    ],
    "abstract": "We explore the integration of multisensory elements in virtual reality\nreconstructions of historical spaces through a case study of the Virtual\nVauxhall Gardens project. While visual and auditory components have become\nstandard in digital heritage experiences, the addition of olfactory stimuli\nremains underexplored, despite its powerful connection to memory and emotional\nengagement. This research investigates how multisensory experiences involving\nolfaction can be effectively integrated into VR reconstructions of historical\nspaces to enhance presence and engagement with cultural heritage. In the\ncontext of a VR reconstruction of London's eighteenth-century Vauxhall Pleasure\nGardens, we developed a networked portable olfactory display capable of\nsynchronizing specific scents with visual and auditory elements at pivotal\nmoments in the virtual experience. Our evaluation methodology assesses both\ntechnical implementation and user experience, measuring presence, and usability\nmetrics across diverse participant groups. Our results show that integrating\nsynchronized olfactory stimuli into the VR experience can enhance user\nengagement and be perceived positively, contributing to a unique and immersive\nencounter with historical settings. While presence questionnaires indicated a\nstrong sense of auditory presence and control, with other sensory factors rated\nmoderately, user experience of attractiveness was exceptionally high;\nqualitative feedback suggested heightened sensory awareness and engagement\ninfluenced by the inclusion and anticipation of smell. Our results suggest that\nevaluating multisensory VR heritage experiences requires a nuanced approach, as\nstandard usability metrics may be ill-suited and 'realism' might be less\ncritical than creating an evocative, historically informed, and emotionally\nresonant experience......",
    "pdf_url": "http://arxiv.org/pdf/2505.13612v1",
    "published": "2025-05-19T18:00:42+00:00",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13611v1",
    "title": "INSPIRE: INvestigating Stellar Populations In RElics. IX. KiDS J0842+0059: the first fully confirmed relic beyond the local Universe",
    "authors": [
      "C. Tortora",
      "G. Tozzi",
      "G. Agapito",
      "F. La Barbera",
      "C. Spiniello",
      "R. Li",
      "G. Carl√†",
      "G. D'Ago",
      "E. Ghose",
      "F. Mannucci",
      "N. R. Napolitano",
      "E. Pinna",
      "M. Arnaboldi",
      "D. Bevacqua",
      "A. Ferr√©-Mateu",
      "A. Gallazzi",
      "J. Hartke",
      "L. K. Hunt",
      "M. Maksymowicz-Maciata",
      "C. Pulsoni",
      "P. Saracco",
      "D. Scognamiglio",
      "M. Spavone"
    ],
    "abstract": "Relics are massive, compact and quiescent galaxies that assembled the\nmajority of their stars in the early Universe and lived untouched until today,\ncompletely missing any subsequent size-growth caused by mergers and\ninteractions. They provide the unique opportunity to put constraints on the\nfirst phase of mass assembly in the Universe with the ease of being nearby.\nWhile only a few relics have been found in the local Universe, the {\\tt\nINSPIRE} project has confirmed 38 relics at higher redshifts ($z \\sim\n0.2-0.4$), fully characterising their integrated kinematics and stellar\npopulations. However, given the very small sizes of these objects and the\nlimitations imposed by the atmosphere, structural parameters inferred from\nground-based optical imaging are possibly affected by systematic effects that\nare difficult to quantify. In this paper, we present the first high-resolution\nimage obtained with Adaptive Optics Ks-band observations on SOUL-LUCI@LBT of\none of the most extreme {\\tt INSPIRE} relics, KiDS~J0842+0059 at $z \\sim 0.3$.\nWe confirm the disky morphology of this galaxy (axis ratio of $0.24$) and its\ncompact nature (circularized effective radius of $\\sim 1$ kpc) by modelling its\n2D surface brightness profile with a PSF-convolved S\\'ersic model. We\ndemonstrate that the surface mass density profile of KiDS~J0842+0059 closely\nresembles that of the most extreme local relic, NGC~1277, as well as of\nhigh-redshift red nuggets. We unambiguously conclude that this object is a\nremnant of a high-redshift compact and massive galaxy, which assembled all of\nits mass at $z>2$, and completely missed the merger phase of the galaxy\nevolution.",
    "pdf_url": "http://arxiv.org/pdf/2505.13611v1",
    "published": "2025-05-19T18:00:11+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13610v1",
    "title": "Computation of the knot Floer complex of knots of thickness one",
    "authors": [
      "Patricia Sorya"
    ],
    "abstract": "We develop and implement an algorithm that computes the full knot Floer\ncomplex of knots of thickness one. As an application, by extending this\nalgorithm to certain knots of thickness two, we show that all but finitely many\nnon-integral Dehn surgery slopes are characterizing for most knots with up to\n17 crossings.",
    "pdf_url": "http://arxiv.org/pdf/2505.13610v1",
    "published": "2025-05-19T18:00:09+00:00",
    "categories": [
      "math.GT"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13607v1",
    "title": "Large databases of metal-poor stars corrected for three-dimensional and/or non-local thermodynamic equilibrium effects",
    "authors": [
      "I. Koutsouridou",
      "√Å. Sk√∫lad√≥ttir",
      "S. Salvadori"
    ],
    "abstract": "Early chemical enrichment processes can be revealed by the careful study of\nmetal-poor stars. In our Local Group, we can obtain spectra of individual stars\nto measure their precise, but not always accurate, chemical abundances.\nUnfortunately, stellar abundances are typically estimated under the simplistic\nassumption of local thermodynamic equilibrium (LTE). This can systematically\nalter both the abundance patterns of individual stars and global trends of\nchemical enrichment. The SAGA database compiles the largest catalogue of\nmetal-poor stars in the Milky Way. For the first time, we provide the community\nwith the SAGA catalogue fully corrected for non-LTE (NLTE) effects, using\nstate-of-the-art publicly available grids. In addition, we present an\neasy-to-use online tool NLiTE that quickly provides NLTE corrections for large\nstellar samples. For further scientific exploration, NLiTE facilitates the\ncomparison of different NLTE grids to investigate their intrinsic\nuncertainties. Finally, we compare the NLTE-SAGA catalogue with our\ncosmological galaxy formation and chemical evolution model, NEFERTITI. By\naccounting for NLTE effects, we can solve the long-standing discrepancy between\nmodels and observations in the abundance ratio of [C/Fe], the best tracer of\nthe first stellar populations. At low [Fe/H]<-3.5, models are unable to\nreproduce the high measured [C/Fe] in LTE, which are lowered in NLTE, aligning\nwith simulations. Other elements are a mixed bag: some show improved agreement\nwith models (e.g. Na) and others worse (e.g. Co). Few elemental ratios do not\nchange significantly (e.g. [Mg/Fe], [Ca/Fe]). Properly accounting for NLTE\neffects is fundamental for interpreting the chemical abundances of metal-poor\nstars. Our NLiTE tool thus enables a meaningful comparison of stellar samples\nwith stellar and chemical evolution models and low-metallicity gaseous\nenvironments at higher redshift.",
    "pdf_url": "http://arxiv.org/pdf/2505.13607v1",
    "published": "2025-05-19T18:00:07+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13608v1",
    "title": "Sampling NNLO QCD phase space with normalizing flows",
    "authors": [
      "Timo Jan√üen",
      "Rene Poncelet",
      "Steffen Schumann"
    ],
    "abstract": "We showcase the application of neural importance sampling for the evaluation\nof NNLO QCD scattering cross sections. We consider Normalizing Flows in the\nform of discrete Coupling Layers and time continuous flows for the integration\nof the various cross-section contributions when using the sector-improved\nresidue subtraction scheme. We thereby consider the stratification of the\nintegrands into their positive and negative contributions, and separately\noptimize the phase-space sampler. We exemplify the novel methods for the case\nof gluonic top-quark pair production at the LHC at NNLO QCD accuracy. We find\nsignificant gains with respect to the current default methods used in STRIPPER\nin terms of reduced cross-section variances and increased unweighting\nefficiencies. In turn, the computational costs for evaluations of the integrand\nneeded to achieve a certain statistical uncertainty for the cross section can\nbe reduced by a factor 8.",
    "pdf_url": "http://arxiv.org/pdf/2505.13608v1",
    "published": "2025-05-19T18:00:07+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13609v3",
    "title": "Bootstrapping Nonequilibrium Stochastic Processes",
    "authors": [
      "Minjae Cho"
    ],
    "abstract": "We show that bootstrap methods based on the positivity of probability\nmeasures provide a systematic framework for studying both synchronous and\nasynchronous nonequilibrium stochastic processes on infinite lattices. First,\nwe formulate linear programming problems that use positivity and invariance\nproperty of invariant measures to derive rigorous bounds on their expectation\nvalues. Second, for time evolution in asynchronous processes, we exploit the\nmaster equation along with positivity and initial conditions to construct\nlinear and semidefinite programming problems that yield bounds on expectation\nvalues at both short and late times. We illustrate both approaches using two\ncanonical examples: the contact process in 1+1 and 2+1 dimensions, and the\nDomany-Kinzel model in both synchronous and asynchronous forms in 1+1\ndimensions. Our bounds on invariant measures yield rigorous lower bounds on\ncritical rates, while those on time evolutions provide two-sided bounds on the\nhalf-life of the infection density and the temporal correlation length in the\nsubcritical phase.",
    "pdf_url": "http://arxiv.org/pdf/2505.13609v3",
    "published": "2025-05-19T18:00:07+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "hep-th",
      "math.OC",
      "math.PR"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.13605v1",
    "title": "Deep galaxy stellar mass functions as a function of star formation rate in the Virgo cluster environment",
    "authors": [
      "Cameron R. Morgan",
      "Elizaveta Sazonova",
      "Ian D. Roberts",
      "Michael L. Balogh",
      "Joel Roediger",
      "Laura Ferrarese",
      "Patrick C√¥t√©",
      "Alessandro Boselli",
      "Matteo Fossati",
      "Jean-Charles Cuillandre",
      "Stephen Gwyn"
    ],
    "abstract": "We analyze deep ($M_*\\gtrsim10^7~{M}_{\\odot}$) galaxy stellar mass functions\n(SMFs) of the Virgo cluster using stellar masses derived as part of the Next\nGeneration Virgo Survey (NGVS). The total SMF has a slope of\n$\\alpha=-1.35^{+0.02}_{-0.02}$ which is similar to or steeper than typical\nfield values. Using deep \\ha{} data from the Virgo Environmental Survey Tracing\nIonised Gas Emission (VESTIGE) we separate out star-forming galaxies, quiescent\ngalaxies with no ongoing star formation, and low-SFR galaxies that are\nintermediate between these two populations. For each of these populations, the\nshape of the SMF is found to be universal throughout the cluster, from the core\nto the outskirts. The star-forming and quiescent SMFs show stark differences\nwith values seen in field galaxies. The relative fraction of quiescent galaxies\nis highest in the core of the cluster, with low-SFR and star-forming galaxies\nmore significant in the outer regions of the cluster. At low stellar masses\n($M_*\\lesssim10^9~{M}_{\\odot}$), the quiescent fraction in the main cluster is\nsignificantly higher than that of the field and even satellites of massive\ngroups. At high stellar masses, the quiescent fraction is similar to other\nstudies of cluster galaxies. We model the quiescent population in the infall\nregion of the cluster as a combination of backsplash and field quiescent\ngalaxies, and find that the backsplash fractions needed to explain the observed\npopulation are unrealistically high. This suggests the existence of a third\npopulation of low-mass galaxies that are pre-processed outside the virial\nradius of the cluster, possibly in groups prior to infall.",
    "pdf_url": "http://arxiv.org/pdf/2505.13605v1",
    "published": "2025-05-19T18:00:05+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13606v1",
    "title": "Quasiparticles and optical conductivity in the mixed state of Weyl superconductors with unconventional pairing",
    "authors": [
      "Zhihai Liu",
      "Luyang Wang"
    ],
    "abstract": "Previous investigations have revealed that the Weyl superconductor (WeylSC)\nand the two-dimensional (2D) nodal superconductor, realized through a\ntopological insulator-superconductor heterostructure, can exhibit a Dirac-like\nLandau level (LL) structure that scales with $\\sqrt{n}$ in the presence of a\nvortex lattice, where $n$ is the index of the LLs. Here, we investigate the\nexcitation spectrum in the mixed state of WeylSCs with unconventional pairing\nand find that, unlike in the spin-singlet case, QP bands for the spin-triplet\npairing show surprising dispersion, except for the chiral symmetry-protected,\ndispersionless zeroth Landau level (ZLL). Different pairing symmetries in\nWeylSCs also result in distinct magneto-optical responses, manifested as\ncharacterized magneto-optical conductivity curves. We also reveal that,\ncompared to the topologically protected, charge-neutral, localized Majorana\nzero mode (MZM), the chiral symmetry-protected ZLL is non-charge-neutral and\ndelocalized. Both of these zero modes may be observed in the vortex of a\nsuperconductor heterostructure.",
    "pdf_url": "http://arxiv.org/pdf/2505.13606v1",
    "published": "2025-05-19T18:00:05+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.13603v2",
    "title": "Determining the origin of the X-ray emission in blazars through multiwavelength polarization",
    "authors": [
      "Ioannis Liodakis",
      "Haocheng Zhang",
      "Stella Boula",
      "Riccardo Middei",
      "Jorge Otero-Santos",
      "Dmitry Blinov",
      "Iv√°n Agudo",
      "Markus B√∂ttcher",
      "Chien-Ting Chen",
      "Steven R. Ehlert",
      "Svetlana G. Jorstad",
      "Philip Kaaret",
      "Henric Krawczynski",
      "Abel L. Peirson",
      "Roger W. Romani",
      "Fabrizio Tavecchio",
      "Martin C. Weisskopf",
      "Pouya M. Kouch",
      "Elina Lindfors",
      "Kari Nilsson",
      "Callum McCall",
      "Helen E. Jermak",
      "Iain A. Steele",
      "Ioannis Myserlis",
      "Mark Gurwell",
      "Garrett K. Keating",
      "Ramprasad Rao",
      "Sincheol Kang",
      "Sang-Sung Lee",
      "Sanghyun Kim",
      "Whee Yeon Cheong",
      "Hyeon-Woo Jeong",
      "Emmanouil Angelakis",
      "Alexander Kraus",
      "Francisco Jos√© Aceituno",
      "Giacomo Bonnoli",
      "V√≠ctor Casanova",
      "Juan Escudero",
      "Beatriz Ag√≠s-Gonz√°lez",
      "Daniel Morcuende",
      "Alfredo Sota",
      "Rumen Bachev",
      "Tatiana S. Grishina",
      "Evgenia N. Kopatskaya",
      "Elena G. Larionova",
      "Daria A. Morozova",
      "Sergey S. Savchenko",
      "Ekaterina V. Shishkina",
      "Ivan S. Troitskiy",
      "Yulia V. Troitskaya",
      "Andrey A. Vasilyev"
    ],
    "abstract": "The origin of the high-energy emission in astrophysical jets from black holes\nis a highly debated issue. This is particularly true for jets from supermassive\nblack holes that are among the most powerful particle accelerators in the\nUniverse. So far, the addition of new observations and new messengers have only\nmanaged to create more questions than answers. However, the newly available\nX-ray polarization observations promise to finally distinguish between emission\nmodels. We use extensive multiwavelength and polarization campaigns as well as\nstate-of-the-art polarized spectral energy distribution models to attack this\nproblem by focusing on two X-ray polarization observations of blazar BL\nLacertae in flaring and quiescent $\\gamma$-ray states. We find that regardless\nof the jet composition and underlying emission model, inverse-Compton\nscattering from relativistic electrons dominates at X-ray energies.",
    "pdf_url": "http://arxiv.org/pdf/2505.13603v2",
    "published": "2025-05-19T18:00:04+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13604v1",
    "title": "String-Membrane-Nets from Higher-Form Gauging: An Alternate Route to $p$-String Condensation",
    "authors": [
      "Pranay Gorantla",
      "Abhinav Prem",
      "Nathanan Tantivasadakarn",
      "Dominic J. Williamson"
    ],
    "abstract": "We present a new perspective on the $p$-string condensation procedure for\nconstructing 3+1D fracton phases by implementing this process via the gauging\nof higher-form symmetries. Specifically, we show that gauging a 1-form symmetry\nin 3+1D that is generated by Abelian anyons in isotropic stacks of 2+1D\ntopological orders naturally results in a 3+1D $p$-string condensed phase,\nproviding a controlled non-perturbative construction that realizes fracton\norders. This approach clarifies the symmetry principles underlying $p$-string\ncondensation and generalizes the familiar connection between anyon condensation\nand one-form gauging in two spatial dimensions. We demonstrate this\ncorrespondence explicitly in both field theories and lattice models: in field\ntheory, we derive the foliated field theory description of the $\\mathbb{Z}_N$\nX-Cube model by gauging a higher-form symmetry in stacks of 2+1D $\\mathbb{Z}_N$\ngauge theories; on the lattice, we show how gauging a diagonal 1-form symmetry\nin isotropic stacks of $G$-graded string-net models leads to\nstring-membrane-nets hosting restricted mobility excitations. This perspective\nnaturally generalizes to spatial dimensions $d \\geq 2$ and provides a step\ntowards building an algebraic theory of $p$-string condensation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13604v1",
    "published": "2025-05-19T18:00:04+00:00",
    "categories": [
      "cond-mat.str-el",
      "hep-th",
      "quant-ph"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.13600v3",
    "title": "Constraints are not enough",
    "authors": [
      "Gary T. Horowitz",
      "Donald Marolf",
      "Jorge E. Santos"
    ],
    "abstract": "The Euclidean Einstein-Hilbert action is well-known to be unbounded below and\nthus to raise many questions regarding the definition of the gravitational path\nintegral. A variety of works since the late 1980's have suggested that this\nproblem disappears when one fixes a foliation of the spacetime and imposes the\ncorresponding gravitational constraints. However, we show here that this\napproach fails with various classes of boundary conditions imposed on the\nfoliation: compact slices without boundary, asymptotically flat, or\nasymptotically locally anti-de Sitter slices. We also discuss the idea of\nfixing the scalar curvature and Wick-rotating the conformal factor, and show\nthat it also fails to produce an action bounded from below.",
    "pdf_url": "http://arxiv.org/pdf/2505.13600v3",
    "published": "2025-05-19T18:00:03+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13601v2",
    "title": "Dark Matter in an Evanescent Three-Brane Randall-Sundrum Scenario",
    "authors": [
      "Andrea Donini",
      "Miguel G. Folgado",
      "Juan Herrero-Garc√≠a",
      "Giacomo Landini",
      "Alejandro Mu√±oz-Ovalle",
      "Nuria Rius"
    ],
    "abstract": "Apart from its gravitational interactions, dark matter (DM) has remained so\nfar elusive in laboratory searches. One possible explanation is that the\nrelevant interactions to explain its relic abundance are mainly gravitational.\nIn this work we consider an extradimensional Randall-Sundrum scenario with a\nTeV-PeV IR brane, where the Standard Model is located, and a GeV-TeV deep IR\n(DIR) one, where the DM lies. When the curvatures of the bulk to the left and\nright of the IR brane are very similar, the tension of the IR brane is\nsignificantly smaller than that of the other two branes, and therefore we term\nit \\evanescent\". In this setup, the relic abundance of DM arises from the\nfreezeout mechanism, thanks to DM annihilations into radions and gravitons.\nFocusing on a scalar singlet DM candidate, we compute and apply current and\nfuture constraints from direct, indirect and collider-based searches. Our\nfindings demonstrate the viability of this scenario and highlight its potential\ntestability in upcoming experiments. We also discuss the possibility of\ninferring the number of branes if the radion and several Kaluza-Klein graviton\nresonances are detected at a future collider.",
    "pdf_url": "http://arxiv.org/pdf/2505.13601v2",
    "published": "2025-05-19T18:00:03+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13602v1",
    "title": "A Panchromatic Characterization of the Evening and Morning Atmosphere of WASP-107 b: Composition and Cloud Variations, and Insight into the Effect of Stellar Contamination",
    "authors": [
      "Matthew M. Murphy",
      "Thomas G. Beatty",
      "Everett Schlawin",
      "Taylor J. Bell",
      "Michael Radica",
      "Thomas D. Kennedy",
      "Nishil Mehta",
      "Luis Welbanks",
      "Michael R. Line",
      "Vivien Parmentier",
      "Thomas P. Greene",
      "Sagnick Mukherjee",
      "Jonathan J. Fortney",
      "Kazumasa Ohno",
      "Lindsey Wiser",
      "Kenneth Arnold",
      "Emily Rauscher",
      "Isaac R. Edelman",
      "Marcia J. Rieke"
    ],
    "abstract": "Limb-resolved transmission spectroscopy has the potential to transform our\nunderstanding of exoplanetary atmospheres. By separately measuring the\ntransmission spectra of the evening and morning limbs, these atmospheric\nregions can be individually characterized, shedding light into the global\ndistribution and transport of key atmospheric properties from transit\nobservations alone. In this work, we follow up the recent detection of limb\nasymmetry on the exoplanet WASP-107 b (Murphy et al. 2024) by reanalyzing\nliterature observations of WASP-107 b using all of JWST's science intruments\n(NIRISS, NIRCam, NIRSpec, and MIRI) to measure its limb transmission spectra\nfrom $\\sim$1-12 $\\mu$m. We confirm the evening--morning temperature difference\ninferred previously and find that it is qualitatively consistent with\npredictions from global circulation models. We find evidence for\nevening--morning variation in SO$_2$ and CO$_2$ abundance, and significant\ncloud coverage only on WASP-107 b's morning limb. We find that the NIRISS and\nNIRSpec observations are potentially contaminated by occulted starspots, which\nwe leverage to investigate stellar contamination's impact on limb asymmetry\nmeasurements. We find that starspot crossings can significantly bias the\ninferred evening and morning transmission spectra depending on when they occur\nduring the transit, and develop a simple correction model which successfully\nbrings these instruments' spectra into agreement with the uncontaminated\nobservations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13602v1",
    "published": "2025-05-19T18:00:03+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13595v1",
    "title": "Revealing the intricacies of radio galaxies and filaments in the merging galaxy cluster Abell 2255. I. Insights from deep LOFAR-VLBI sub-arcsecond resolution images",
    "authors": [
      "E. De Rubeis",
      "M. Bondi",
      "A. Botteon",
      "R. J. van Weeren",
      "J. M. G. H. J. de Jong",
      "L. Rudnick",
      "G. Brunetti",
      "K. Rajpurohit",
      "C. Gheller",
      "H. J. A. R√∂ttgering"
    ],
    "abstract": "High sensitivity of modern interferometers is revealing a plethora of\nfilaments surrounding radio galaxies, especially in galaxy cluster\nenvironments. The morphology and spectral characteristics of these thin\nstructures require the combination of high-resolution and low frequency\nobservations, which is best obtained using the LOw Frequency ARray (LOFAR)\ninternational stations. In this paper, we aim to detect and characterize\nnon-thermal filaments observed close or as part of the radio galaxies in Abell\n2255 using deep, LOFAR-VLBI observations at 144 MHz. These structures can be\nused to disentangle possible scenarios for the origin of the non-thermal\nfilaments and connection to the motion of the host galaxy within the dense and\nturbulent intracluster medium (ICM), and consequent interaction between the ICM\nand radio jets. Combining multiple observations, we produced the deepest images\never obtained with LOFAR-VLBI targeting a galaxy cluster, using 56 hours of\nobservations, reaching $0.3-0.5\"$ resolution. We detailed throughout the paper\nthe calibration and imaging strategy for the different targets, as well as the\nmultitude of morphological features discovered. Thanks to the high-sensitivity\nof LOFAR-VLBI, we revealed unprecedented details for the main cluster radio\ngalaxies, recovering in most cases also their more extended structure observed\nonly at such low frequencies. In particular, we focused on the Original Tailed\nRadio Galaxy (Original TRG) where we distinguished many filaments constituting\nits tail with varying lengths ($80-110$ kpc) and widths ($3-10$ kpc). The final\nradio images showcase the potential of deep, high-resolution observations for\ngalaxy clusters. With such approach, we enabled the study of these thin,\nelongated radio filaments: after being discovered, these filaments now require\nspectral studies to determine their formation mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.13595v1",
    "published": "2025-05-19T18:00:02+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13596v1",
    "title": "FAUST XXIV. Large dust grains in the protostellar outflow cavity walls of the Class I binary L1551 IRS5",
    "authors": [
      "G. Sabatini",
      "E. Bianchi",
      "C. J. Chandler",
      "L. Cacciapuoti",
      "L. Podio",
      "M. J. Maureira",
      "C. Codella",
      "C. Ceccarelli",
      "N. Sakai",
      "L. Testi",
      "C. Toci",
      "B. Svoboda",
      "T. Sakai",
      "M. Bouvier",
      "P. Caselli",
      "N. Cuello",
      "M. De Simone",
      "I. J√≠menez-Serra",
      "D. Johnstone",
      "L. Loinard",
      "Z. E. Zhang",
      "S. Yamamoto"
    ],
    "abstract": "Planet formation around young stars requires the growth of interstellar dust\ngrains from mm-sized particles to km-sized planetesimals. Numerical simulations\nhave shown that large ($\\sim$mm-sized) grains found in the inner envelope of\nyoung protostars could be lifted from the disc via winds. However we are still\nlacking unambiguous evidence for large grains in protostellar winds/outflows.\nWe investigate dust continuum emission in the envelope of the Class I binary\nL1551 IRS5 in the Taurus molecular cloud, aiming to identify observational\nsignatures of grain growth, such as variations in the dust emissivity index\n($\\beta_{\\rm mm}$). In this context, we present new, high-angular resolution\n(50 au), observations of thermal dust continuum emission at 1.3 mm and 3 mm in\nthe envelope ($\\sim$3000 au) of L1551 IRS5 , obtained as part of the ALMA-FAUST\nLarge Program. We analyse dust emission along the cavity walls of the CO\noutflow, extended up to $\\sim$1800 au. We find an H$_2$ volume density\n$>2\\times10^5$ cm$^{-3}$, a dust mass of $\\sim$58 M$_\\oplus$, and $\\beta_{\\rm\nmm}$<1, implying the presence of grains $\\sim$10$^3$ times larger than the\ntypical ISM sizes. We provide the first spatially resolved observational\nevidence of large grains within an outflow cavity wall. Our results suggest\nthat these grains have been transported from the inner disc to the envelope by\nprotostellar winds and may subsequently fall back into the outer disc by\ngravity and/or via accretion streamers. This cycle provides longer time for\ngrains to grow, playing a crucial role in the formation of planetesimals.",
    "pdf_url": "http://arxiv.org/pdf/2505.13596v1",
    "published": "2025-05-19T18:00:02+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13597v1",
    "title": "Constraining cosmic ray transport models using circumgalactic medium properties and observables",
    "authors": [
      "Yue Samuel Lu",
      "Du≈°an Kere≈°",
      "Philip F. Hopkins",
      "Sam B. Ponnada",
      "Claude-Andr√© Faucher-Gigu√©re",
      "Cameron B. Hummels"
    ],
    "abstract": "Cosmic rays (CRs) are a pivotal non-thermal component of galaxy formation and\nevolution. However, the intricacies of CR physics, particularly how they\npropagate in the circumgalactic medium (CGM), remain largely unconstrained. In\nthis work, we study CGM properties in FIRE-2 (Feedback In Realistic\nEnvironments) simulations of the same Milky Way (MW)-mass halo at $z=0$ with\ndifferent CR transport models that produce similar diffuse $\\sim$ GeV\n$\\gamma$-ray emission. We study the gas morphology and thermal properties, and\ngenerate synthetic observations of rest-frame UV ion absorption columns and\nX-ray emission. CRs lower galaxy masses and star formation rates (SFRs) while\nsupporting more cool CGM gas, which boosts the HI and OVI column densities in\nthe CGM, bringing simulations more in line with observations, but there can be\nlarge differences between CR transport models and resolution levels. X-ray\nemission within and close to galaxies is consistent with thermal (free-free and\nmetal-line) emission plus X-ray binaries, while more extended ($\\sim 100\\,$kpc)\nCGM emission is potentially dominated by inverse Compton (IC) scattering,\nmotivating future work on the spatially resolved X-ray profiles. Although\ncomparisons with observations are sensitive to sample selection and mimicking\nthe details of observations, and our analysis did not result in strong\nconstraints on CR models, the differences between simulations are significant\nand could be used as a framework for future studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.13597v1",
    "published": "2025-05-19T18:00:02+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13598v1",
    "title": "Interplay of magnetic textures with spin-orbit coupled substrates",
    "authors": [
      "Zachary Llewellyn",
      "Eric Mascot",
      "Oleg A. Tretiakov",
      "Stephan Rachel"
    ],
    "abstract": "Magnetic textures such as skyrmions in thin films grown on substrates possess\nsignificant technological potential. Inhomogeneous magnetic structures can be\ndescribed as homogeneous ferromagnetic order in the presence of anisotropic\nspin-orbit coupling (SOC). It remains unexplored, however, how this {\\it\ninduced} SOC stemming from the magnetic textures interacts with the SOC of the\nsubstrate. Here we show that these two contributions to SOC are in general {\\it\nnot} additive. We demonstrate this by employing a spintronics gauge theory. We\nfurther compute local currents which, when considered in the proper frame,\nmatch the spintronics gauge theory results. Finally, we analyze global\ntransport quantities and show that they substantiate our previous results\nquantitatively. The implications for skyrmionics as well as topological\nsuperconductivity are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.13598v1",
    "published": "2025-05-19T18:00:02+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.13599v2",
    "title": "Decoding across transversal Clifford gates in the surface code",
    "authors": [
      "Marc Serra-Peralta",
      "Mackenzie H. Shaw",
      "Barbara M. Terhal"
    ],
    "abstract": "Transversal logical gates offer the opportunity for fast and low-noise logic,\nparticularly when interspersed by a single round of parity check measurements\nof the underlying code. Using such circuits for the surface code requires\ndecoding across logical gates, complicating the decoding task. We show how one\ncan decode across an arbitrary sequence of transversal gates for the unrotated\nsurface code, using a fast \"logical observable\" minimum-weight-perfect-matching\n(MWPM) based decoder, and benchmark its performance in Clifford circuits under\ncircuit-level noise. We propose windowed logical observable matching decoders\nto address the problem of fully efficient decoding: our basic windowed decoder\nis computationally efficient under the restriction of quiescent (slow) resets.\nOur two-step windowed decoder can be computationally inefficient but allows\nfast resets. For both windowed decoders we identify errors which scale\nsublinearly in $d$ - depending on the structure of the circuit - which can lead\nto logical failure, and we propose methods to adapt the decoding to remove such\nfailures. Our work highlights the complexity and interest in efficient decoding\nof fast logic for the surface code.",
    "pdf_url": "http://arxiv.org/pdf/2505.13599v2",
    "published": "2025-05-19T18:00:02+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13593v1",
    "title": "The High-redshift Blazar MG3 J163554+3629: Physical Properties and the Enigma of Its Unexpected Supermassive Black Hole Growth",
    "authors": [
      "Jose Maria Sanchez Zaballa",
      "Eugenio Bottacini",
      "Andrea Tramacere"
    ],
    "abstract": "There is general consensus that active galactic nuclei (AGNs) derive their\nradiating power from a supermassive black hole (SMBH) that accretes matter.\nYet, their precise powering mechanisms and the resulting growth of the SMBH are\npoorly understood, especially for AGNs at high redshift. Blazars are AGNs\npointing their jet toward the observer, thus being detectable from radio\nthrough gamma rays at high redshift due to Doppler boosting. The blazar MG3\nJ163554+3629 is located at redshift z=3.65 and it is a flat spectrum radio\nquasar (FSRQ). In this work, we show the results of the modeling of its\nspectral energy distribution (SED) from radio to gamma rays with a one-zone\nleptonic model. We estimate the uncertainties through a Markov Chain Monte\nCarlo approach. As a result, we infer the black hole mass M_BH = 1.1(+0.2,-0.1)\nx 10^9 Msun and a modest magnetic field of B = 6.56(+0.13,-0.09) x 10^-2 G in\nline with the Compton dominance observed in high-redshift FSRQs. The emitting\nregion is outside the broad line region but within the region of the dust torus\nradius. The rather small accretion efficiency of eta=0.083 is not solely\ninferred through the SED modeling but also through the energetics. An evolution\nstudy suggests that in an Eddington-limited accretion process the SMBH did not\nhave time enough to grow from an initial seed mass of ~10^6 Msun at z~30 into a\nmass of M_BH ~ 10^9 Msun at z=3.65. Faster mass growth might be obtained in a\nsuper-Eddington process throughout frequent episodes. Alternative scenarios\npropose that the existence of the jet itself can facilitate a more rapid\ngrowth.",
    "pdf_url": "http://arxiv.org/pdf/2505.13593v1",
    "published": "2025-05-19T18:00:01+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13594v1",
    "title": "Fant√¥mas: epistemic and nuclear uncertainties for the parton distributions of the pion",
    "authors": [
      "Lucas Kotz",
      "Aurore Courtoy",
      "Pavel Nadolsky",
      "Maximiliano Ponce-Chavez"
    ],
    "abstract": "We present Fanto10, a new ensemble of NLO error parton distribution functions\n(PDFs) in a charged pion that provides the most detailed estimate of\nuncertainties from experimental, theoretical, and methodological sources in\norder to enable faithful comparisons against upcoming precision experiments and\nab initio QCD predictions. For the first time, the Fanto10 PDFs quantify two\nimportant types of uncertainties, arising from in-depth exploration of feasible\nfunctional forms of pion PDFs and from the nuclear PDFs describing the internal\ncomposition of the tungsten target in the key E615 data set for pion-nuclear\nDrell-Yan process. Accounting for these uncertainties modifies physics\nconclusions of more restrictive analyses about the pion's gluon and quark sea\ncomposition. These advancements are made by employing the recently developed\nC++ framework Fant\\^omas for systematic exploration of epistemic sources of PDF\nuncertainties, such as those arising from the choice of the PDF functional\nforms and sampling over methodological choices and third-party inputs, e.g.,\nthe nuclear PDF uncertainty in the presented case. The framework employs\npolynomial universal approximators (B\\'ezier curves) to parametrize diverse PDF\nfunctional forms and reduce biases associated with the PDF parametrization\nchoice. Its other component combines PDF ensembles from multiple preliminary\nfits into a single published ensemble of Hessian error PDFs. We review key\nsteps of the Fant\\^omas methodology, properties of Fanto10 PDFs, and\nimplications for future studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.13594v1",
    "published": "2025-05-19T18:00:01+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13587v2",
    "title": "Fast correlated decoding of transversal logical algorithms",
    "authors": [
      "Madelyn Cain",
      "Dolev Bluvstein",
      "Chen Zhao",
      "Shouzhen Gu",
      "Nishad Maskara",
      "Marcin Kalinowski",
      "Alexandra A. Geim",
      "Aleksander Kubica",
      "Mikhail D. Lukin",
      "Hengyun Zhou"
    ],
    "abstract": "Quantum error correction (QEC) is required for large-scale computation, but\nincurs a significant resource overhead. Recent advances have shown that by\njointly decoding logical qubits in algorithms composed of transversal gates,\nthe number of syndrome extraction rounds can be reduced by a factor of the code\ndistance $d$, at the cost of increased classical decoding complexity. Here, we\nreformulate the problem of decoding transversal circuits by directly decoding\nrelevant logical operator products as they propagate through the circuit. This\nprocedure transforms the decoding task into one closely resembling that of a\nsingle-qubit memory propagating through time. The resulting approach leads to\nfast decoding and reduced problem size while maintaining high performance.\nFocusing on the surface code, we prove that this method enables fault-tolerant\ndecoding with minimum-weight perfect matching, and benchmark its performance on\nexample circuits including magic state distillation. We find that the threshold\nis comparable to that of a single-qubit memory, and that the total decoding run\ntime can be, in fact, less than that of conventional lattice surgery. Our\napproach enables fast correlated decoding, providing a pathway to directly\nextend single-qubit QEC techniques to transversal algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.13587v2",
    "published": "2025-05-19T18:00:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13588v1",
    "title": "Forward vs Backward: Improving BAO Constraints with Field-Level Inference",
    "authors": [
      "Ivana Babiƒá",
      "Fabian Schmidt",
      "Beatriz Tucci"
    ],
    "abstract": "We present results of field-level inference of the baryon acoustic\noscillation (BAO) scale $r_s$ on rest-frame dark matter halo catalogs. Our\nfield-level constraint on $r_s$ is obtained by explicitly sampling the initial\nconditions along with the bias and noise parameters via the LEFTfield EFT-based\nforward model. Comparing with a standard reconstruction pipeline applied to the\nsame data and over the same scales, the field-level constraint on the BAO scale\nimproves by a factor of $\\sim 1.2-1.4$ over standard BAO reconstruction. We\npoint to a surprisingly simple source of the additional information.",
    "pdf_url": "http://arxiv.org/pdf/2505.13588v1",
    "published": "2025-05-19T18:00:00+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13589v1",
    "title": "Distinguishing the origin of eccentric black-hole mergers with gravitational-wave spin measurements",
    "authors": [
      "Jakob Stegmann",
      "Davide Gerosa",
      "Isobel Romero-Shaw",
      "Giulia Fumagalli",
      "Hiromichi Tagawa",
      "Lorenz Zwick"
    ],
    "abstract": "It remains an open question whether the binary black hole mergers observed\nwith gravitational-wave detectors originate from the evolution of isolated\nmassive binary stars or were dynamically driven by perturbations from the\nenvironment. Recent evidence for non-zero orbital eccentricity in a handful of\nevents is seen as support for a non-negligible fraction of the population\nexperiencing external driving of the merger. However, it is unclear from which\nformation channel eccentric binary black-hole mergers would originate: dense\nstar clusters, hierarchical field triples, active galactic nuclei, or wide\nbinaries in the Galaxy could all be culprits. Here, we investigate whether the\nspin properties of eccentric mergers could be used to break this degeneracy.\nUsing the fact that different formation channels are predicted to either\nproduce eccentric mergers with mutually aligned or randomly oriented black-hole\nspins, we investigate how many confident detections would be needed in order\nfor the two models to be statistically distinguishable. If a few percent of\nbinary black hole mergers retain measurable eccentricity in the bandwidth of\nground-based detectors, we report a $\\sim40\\,\\%$ chance that we could\nconfidently distinguish both models after the fifth observing run of the\nLIGO-Virgo-KAGRA detector network, $\\sim80\\,\\%$ for LIGO A#, and $\\sim98\\,\\%$\nfor the Einstein Telescope and Cosmic Explorer.",
    "pdf_url": "http://arxiv.org/pdf/2505.13589v1",
    "published": "2025-05-19T18:00:00+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.SR",
      "gr-qc"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13590v1",
    "title": "Formation and evolution of boxy/peanut bulges in the Auriga cosmological simulations",
    "authors": [
      "Paula D. L√≥pez",
      "Francesca Fragkoudi",
      "Sof√≠a A. Cora",
      "Cecilia Scannapieco",
      "R√ºdiger Pakmor",
      "Robert J. J. Grand",
      "Facundo G√≥mez",
      "Federico Marinacci"
    ],
    "abstract": "Boxy/peanut (b/p) or X-shaped bulges have been extensively explored with\ntheory and numerical simulations of isolated galaxies. However, it is only\nrecently that advances in hydrodynamical cosmological simulations have made it\npossible to explore b/p bulges in a cosmological setting, with much remaining\nto be understood about their formation and evolution. By using the Auriga\nmagneto-hydrodynamical cosmological zoom-in simulations, we characterise the\nstructural parameters of b/p bulges and how they form and evolve throughout\ncosmic history. We develop a method for estimating the b/p strength that allows\nus to identify the formation time and size of these structures. We find that\nb/p bulges in Auriga form between $\\sim 1.1-1.6\\, \\mathrm Gyr$ after bar\nformation, following a `buckling' episode; some galaxies undergo multiple\nbucklings and events of b/p growth, with some b/p structures `dissolving'\nbetween buckling events. We find that at $z=0$, the b/p bulges have an extent\nof almost half the bar length. Finally, we analyse the evolution of the b/p\nfraction over redshift, finding that at $z=0$, two thirds of galaxies host a\nbar, and of these, $45$ per cent have a b/p. This b/p fraction is within the\nobserved range at $z=0$, although on the low end as compared to some\nobservational studies. The b/p fraction decreases to $20$ per cent at $z=0.5$,\nand falls to zero at $z \\sim 1$; this is in line with the observed trend of\ndeclining b/p fraction with redshift. We discuss possible culprits for the\napparent mismatch in b/p occurrence between observations and cosmological\nsimulations, what causes them to form (or not) in these simulations, and what\nthis might reveal about models of galaxy formation and evolution.",
    "pdf_url": "http://arxiv.org/pdf/2505.13590v1",
    "published": "2025-05-19T18:00:00+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13591v1",
    "title": "Modeling Galaxy Surveys with Hybrid SBI",
    "authors": [
      "Gemma Zhang",
      "Chirag Modi",
      "Oliver H. E. Philcox"
    ],
    "abstract": "Simulation-based inference (SBI) has emerged as a powerful tool for\nextracting cosmological information from galaxy surveys deep into the\nnon-linear regime. Despite its great promise, its application is limited by the\ncomputational cost of running simulations that can describe the\nincreasingly-large cosmological datasets. Recent work proposed a hybrid SBI\nframework (HySBI), which combines SBI on small-scales with perturbation theory\n(PT) on large-scales, allowing information to be extracted from high-resolution\nobservations without large-volume simulations. In this work, we lay out the\nHySBI framework for galaxy clustering, a key step towards its application to\nnext-generation datasets. We study the choice of priors on the parameters for\nmodeling galaxies in PT analysis and in simulation-based analyses, as well as\ninvestigate their cosmology dependence. By jointly modeling large- and\nsmall-scale statistics and their associated nuisance parameters, we show that\nHySBI can obtain 20\\% and 60\\% tighter constraints on $\\Omega_m$ and\n$\\sigma_8$, respectively, compared to traditional PT analyses, thus\ndemonstrating the efficacy of this approach to maximally extract information\nfrom upcoming spectroscopic datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.13591v1",
    "published": "2025-05-19T18:00:00+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA",
      "astro-ph.IM",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13592v1",
    "title": "Magnetised Bounds for Conformal Field Theories",
    "authors": [
      "Christopher P. Herzog",
      "William H. Pannell",
      "Biswajit Sahoo",
      "Andreas Stergiou"
    ],
    "abstract": "Aspects of parity-preserving, three-dimensional conformal field theories\n(CFTs) with a global $U(1)$ symmetry in the presence of a background magnetic\nfield are investigated. A local effective action is constructed to\nfour-derivative order, based on an assumption that the magnetic field drives\nthe theory into a gapped phase. This action is evaluated in a variety of\nbackgrounds, and is used to obtain one- and two-point functions of the\nconserved current and stress-energy tensor. Dispersive arguments are developed\nand shown to impose powerful constraints on the Wilson coefficients of the\neffective action, leading to universal predictions for the CFT response at\nlarge magnetic field and the scaling dimensions of background monopole\noperators. These general results are further examined through explicit\ncalculations in the free complex scalar, free Dirac fermion, and a holographic\nEinstein-Hilbert-Maxwell model.",
    "pdf_url": "http://arxiv.org/pdf/2505.13592v1",
    "published": "2025-05-19T18:00:00+00:00",
    "categories": [
      "hep-th",
      "cond-mat.str-el"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13586v1",
    "title": "Half Search Space is All You Need",
    "authors": [
      "Pavel Rumiantsev",
      "Mark Coates"
    ],
    "abstract": "Neural Architecture Search (NAS) is a powerful tool for automating\narchitecture design. One-Shot NAS techniques, such as DARTS, have gained\nsubstantial popularity due to their combination of search efficiency with\nsimplicity of implementation. By design, One-Shot methods have high GPU memory\nrequirements during the search. To mitigate this issue, we propose to prune the\nsearch space in an efficient automatic manner to reduce memory consumption and\nsearch time while preserving the search accuracy. Specifically, we utilise\nZero-Shot NAS to efficiently remove low-performing architectures from the\nsearch space before applying One-Shot NAS to the pruned search space.\nExperimental results on the DARTS search space show that our approach reduces\nmemory consumption by 81% compared to the baseline One-Shot setup while\nachieving the same level of accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.13586v1",
    "published": "2025-05-19T17:59:59+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13448v1",
    "title": "CIE: Controlling Language Model Text Generations Using Continuous Signals",
    "authors": [
      "Vinay Samuel",
      "Harshita Diddee",
      "Yiming Zhang",
      "Daphne Ippolito"
    ],
    "abstract": "Aligning language models with user intent is becoming increasingly relevant\nto enhance user experience. This calls for designing methods that can allow\nusers to control the properties of the language that LMs generate. For example,\ncontrolling the length of the generation, the complexity of the language that\ngets chosen, the sentiment, tone, etc. Most existing work attempts to integrate\nusers' control by conditioning LM generations on natural language prompts or\ndiscrete control signals, which are often brittle and hard to scale. In this\nwork, we are interested in \\textit{continuous} control signals, ones that exist\nalong a spectrum that can't easily be captured in a natural language prompt or\nvia existing techniques in conditional generation. Through a case study in\ncontrolling the precise response-length of generations produced by LMs, we\ndemonstrate how after fine-tuning, behaviors of language models can be\ncontrolled via continuous signals -- as vectors that are interpolated between a\n\"low\" and a \"high\" token embedding. Our method more reliably exerts\nresponse-length control than in-context learning methods or fine-tuning methods\nthat represent the control signal as a discrete signal. Our full open-sourced\ncode and datasets are available at https://github.com/vsamuel2003/CIE.",
    "pdf_url": "http://arxiv.org/pdf/2505.13448v1",
    "published": "2025-05-19T17:59:58+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13447v1",
    "title": "Mean Flows for One-step Generative Modeling",
    "authors": [
      "Zhengyang Geng",
      "Mingyang Deng",
      "Xingjian Bai",
      "J. Zico Kolter",
      "Kaiming He"
    ],
    "abstract": "We propose a principled and effective framework for one-step generative\nmodeling. We introduce the notion of average velocity to characterize flow\nfields, in contrast to instantaneous velocity modeled by Flow Matching methods.\nA well-defined identity between average and instantaneous velocities is derived\nand used to guide neural network training. Our method, termed the MeanFlow\nmodel, is self-contained and requires no pre-training, distillation, or\ncurriculum learning. MeanFlow demonstrates strong empirical performance: it\nachieves an FID of 3.43 with a single function evaluation (1-NFE) on ImageNet\n256x256 trained from scratch, significantly outperforming previous\nstate-of-the-art one-step diffusion/flow models. Our study substantially\nnarrows the gap between one-step diffusion/flow models and their multi-step\npredecessors, and we hope it will motivate future research to revisit the\nfoundations of these powerful models.",
    "pdf_url": "http://arxiv.org/pdf/2505.13447v1",
    "published": "2025-05-19T17:59:42+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13446v1",
    "title": "Unlocking Non-Invasive Brain-to-Text",
    "authors": [
      "Dulhan Jayalath",
      "Gilad Landau",
      "Oiwi Parker Jones"
    ],
    "abstract": "Despite major advances in surgical brain-to-text (B2T), i.e. transcribing\nspeech from invasive brain recordings, non-invasive alternatives have yet to\nsurpass even chance on standard metrics. This remains a barrier to building a\nnon-invasive brain-computer interface (BCI) capable of restoring communication\nin paralysed individuals without surgery. Here, we present the first\nnon-invasive B2T result that significantly exceeds these critical baselines,\nraising BLEU by $1.4\\mathrm{-}2.6\\times$ over prior work. This result is driven\nby three contributions: (1) we extend recent word-classification models with\nLLM-based rescoring, transforming single-word predictors into closed-vocabulary\nB2T systems; (2) we introduce a predictive in-filling approach to handle\nout-of-vocabulary (OOV) words, substantially expanding the effective\nvocabulary; and (3) we demonstrate, for the first time, how to scale\nnon-invasive B2T models across datasets, unlocking deep learning at scale and\nimproving accuracy by $2.1\\mathrm{-}2.3\\times$. Through these contributions, we\noffer new insights into the roles of data quality and vocabulary size.\nTogether, our results remove a major obstacle to realising practical\nnon-invasive B2T systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13446v1",
    "published": "2025-05-19T17:59:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13445v1",
    "title": "Trust, But Verify: A Self-Verification Approach to Reinforcement Learning with Verifiable Rewards",
    "authors": [
      "Xiaoyuan Liu",
      "Tian Liang",
      "Zhiwei He",
      "Jiahao Xu",
      "Wenxuan Wang",
      "Pinjia He",
      "Zhaopeng Tu",
      "Haitao Mi",
      "Dong Yu"
    ],
    "abstract": "Large Language Models (LLMs) show great promise in complex reasoning, with\nReinforcement Learning with Verifiable Rewards (RLVR) being a key enhancement\nstrategy. However, a prevalent issue is ``superficial self-reflection'', where\nmodels fail to robustly verify their own outputs. We introduce RISE\n(Reinforcing Reasoning with Self-Verification), a novel online RL framework\ndesigned to tackle this. RISE explicitly and simultaneously trains an LLM to\nimprove both its problem-solving and self-verification abilities within a\nsingle, integrated RL process. The core mechanism involves leveraging\nverifiable rewards from an outcome verifier to provide on-the-fly feedback for\nboth solution generation and self-verification tasks. In each iteration, the\nmodel generates solutions, then critiques its own on-policy generated\nsolutions, with both trajectories contributing to the policy update. Extensive\nexperiments on diverse mathematical reasoning benchmarks show that RISE\nconsistently improves model's problem-solving accuracy while concurrently\nfostering strong self-verification skills. Our analyses highlight the\nadvantages of online verification and the benefits of increased verification\ncompute. Additionally, RISE models exhibit more frequent and accurate\nself-verification behaviors during reasoning. These advantages reinforce RISE\nas a flexible and effective path towards developing more robust and self-aware\nreasoners.",
    "pdf_url": "http://arxiv.org/pdf/2505.13445v1",
    "published": "2025-05-19T17:59:31+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13444v1",
    "title": "ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models",
    "authors": [
      "Liyan Tang",
      "Grace Kim",
      "Xinyu Zhao",
      "Thom Lake",
      "Wenxuan Ding",
      "Fangcong Yin",
      "Prasann Singhal",
      "Manya Wadhwa",
      "Zeyu Leo Liu",
      "Zayne Sprague",
      "Ramya Namuduri",
      "Bodun Hu",
      "Juan Diego Rodriguez",
      "Puyuan Peng",
      "Greg Durrett"
    ],
    "abstract": "Chart understanding presents a unique challenge for large vision-language\nmodels (LVLMs), as it requires the integration of sophisticated textual and\nvisual reasoning capabilities. However, current LVLMs exhibit a notable\nimbalance between these skills, falling short on visual reasoning that is\ndifficult to perform in text. We conduct a case study using a synthetic dataset\nsolvable only through visual reasoning and show that model performance degrades\nsignificantly with increasing visual complexity, while human performance\nremains robust. We then introduce ChartMuseum, a new Chart Question Answering\n(QA) benchmark containing 1,162 expert-annotated questions spanning multiple\nreasoning types, curated from real-world charts across 184 sources,\nspecifically built to evaluate complex visual and textual reasoning. Unlike\nprior chart understanding benchmarks -- where frontier models perform similarly\nand near saturation -- our benchmark exposes a substantial gap between model\nand human performance, while effectively differentiating model capabilities:\nalthough humans achieve 93% accuracy, the best-performing model Gemini-2.5-Pro\nattains only 63.0%, and the leading open-source LVLM Qwen2.5-VL-72B-Instruct\nachieves only 38.5%. Moreover, on questions requiring primarily visual\nreasoning, all models experience a 35%-55% performance drop from\ntext-reasoning-heavy question performance. Lastly, our qualitative error\nanalysis reveals specific categories of visual reasoning that are challenging\nfor current LVLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13444v1",
    "published": "2025-05-19T17:59:27+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13443v1",
    "title": "Wonderings on Wiggly Bispectra: Non-linear Evolution and Reconstruction of Oscillations in the Squeezed Bispectrum",
    "authors": [
      "Samuel Goldstein",
      "Oliver H. E. Philcox",
      "Emanuele Fondi",
      "William R. Coulton"
    ],
    "abstract": "Oscillations in the primordial bispectrum are sourced by a range of\ninflationary phenomena, including features in the inflaton potential and\ninteractions with massive fields through the Cosmological Collider scenario.\nThese signatures offer a powerful window into early-universe physics. In this\nwork, we study how oscillations of the form $\\lim_{q\\ll k}B(q,k)\\propto\n\\cos(\\mu \\ln(q/k))$ impact the non-linear squeezed matter bispectrum. Using a\nsuite of $N$-body simulations with non-Gaussian initial conditions, we show\nthat non-linear evolution significantly damps these oscillations, effectively\nerasing the signal on scales $k \\gtrsim 0.3~h/{\\rm Mpc}$ at redshift $z=0$.\nThis damping is well-described by the Zel'dovich approximation and can be\nmodeled deep into the non-linear regime using non-perturbative separate\nuniverse simulations. Promisingly, we show that reconstruction techniques\ndeveloped for baryon acoustic oscillation (BAO) analyses can largely undo this\ndamping, improving constraints on the amplitude (phase) of oscillations in the\nprimordial squeezed bispectrum by up to a factor of five (four) at $z=0$. We\nalso discuss several challenges with modeling the non-linear evolution of the\nsqueezed bispectrum in the Cosmological Collider scenario, where the bispectrum\nis suppressed by a factor of $(q/k)^{3/2}$ relative to the template studied\nhere. Our findings pave the way for future searches for oscillatory bispectra\nusing large-scale structure data.",
    "pdf_url": "http://arxiv.org/pdf/2505.13443v1",
    "published": "2025-05-19T17:59:23+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13442v2",
    "title": "Emergence of cross-layer composite spins in La$_4$Ni$_3$O$_{10}$ under pressure and possible routes to enhance its superconductivity",
    "authors": [
      "Ruoshi Jiang",
      "Zhiyu Fan",
      "Bartomeu Monserrat",
      "Wei Ku"
    ],
    "abstract": "Trilayer La$_4$Ni$_3$O$_{10}$ has been recently found to exhibit\nsuperconductivity in its high-pressure phase, similar to the previously\ndiscovered bilayer La$_3$Ni$_2$O$_7$, but with a notably lower transition\ntemperature. To date the pressure effects on the electronic correlations\nbeneficial for unconventional superconductivity remains unclear, as well as the\npotential similarities or differences compared to the bilayer\nLa$_3$Ni$_2$O$_7$. We use a multi-energy-scale derivation of the inter-layer\nelectron dynamics to identify the dominant emergent spin-charge correlations in\ntrilayer La$_4$Ni$_3$O$_{10}$. Similar to the bilayer La$_3$Ni$_2$O$_7$, we\nfind fractionalization of ionic spins in the high-pressure phase that results\nin cuprate-like spin-$\\frac{1}{2}$ ions correlated with itinerant carriers.\nThis suggests a similar superconducting mechanism in other nickelate and\ncuprate superconductors. Interestingly, extra composite spins emerge as\ncross-layer trimers in the trilayer system, whose suppression of ionic spin\nfluctuations naturally explains the weaker superconductivity observed in\nLa$_4$Ni$_3$O$_{10}$, and indicates that lowering layer symmetry is a viable\nstrategy to improve superconductivity in this trilayer nickelate.",
    "pdf_url": "http://arxiv.org/pdf/2505.13442v2",
    "published": "2025-05-19T17:59:11+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.13441v2",
    "title": "GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation",
    "authors": [
      "Abhay Deshpande",
      "Yuquan Deng",
      "Arijit Ray",
      "Jordi Salvador",
      "Winson Han",
      "Jiafei Duan",
      "Kuo-Hao Zeng",
      "Yuke Zhu",
      "Ranjay Krishna",
      "Rose Hendrix"
    ],
    "abstract": "We present GrasMolmo, a generalizable open-vocabulary task-oriented grasping\n(TOG) model. GraspMolmo predicts semantically appropriate, stable grasps\nconditioned on a natural language instruction and a single RGB-D frame. For\ninstance, given \"pour me some tea\", GraspMolmo selects a grasp on a teapot\nhandle rather than its body. Unlike prior TOG methods, which are limited by\nsmall datasets, simplistic language, and uncluttered scenes, GraspMolmo learns\nfrom PRISM, a novel large-scale synthetic dataset of 379k samples featuring\ncluttered environments and diverse, realistic task descriptions. We fine-tune\nthe Molmo visual-language model on this data, enabling GraspMolmo to generalize\nto novel open-vocabulary instructions and objects. In challenging real-world\nevaluations, GraspMolmo achieves state-of-the-art results, with a 70%\nprediction success on complex tasks, compared to the 35% achieved by the next\nbest alternative. GraspMolmo also successfully demonstrates the ability to\npredict semantically correct bimanual grasps zero-shot. We release our\nsynthetic dataset, code, model, and benchmarks to accelerate research in\ntask-semantic robotic manipulation, which, along with videos, are available at\nhttps://abhaybd.github.io/GraspMolmo/.",
    "pdf_url": "http://arxiv.org/pdf/2505.13441v2",
    "published": "2025-05-19T17:59:06+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13440v1",
    "title": "Recollection from Pensieve: Novel View Synthesis via Learning from Uncalibrated Videos",
    "authors": [
      "Ruoyu Wang",
      "Yi Ma",
      "Shenghua Gao"
    ],
    "abstract": "Currently almost all state-of-the-art novel view synthesis and reconstruction\nmodels rely on calibrated cameras or additional geometric priors for training.\nThese prerequisites significantly limit their applicability to massive\nuncalibrated data. To alleviate this requirement and unlock the potential for\nself-supervised training on large-scale uncalibrated videos, we propose a novel\ntwo-stage strategy to train a view synthesis model from only raw video frames\nor multi-view images, without providing camera parameters or other priors. In\nthe first stage, we learn to reconstruct the scene implicitly in a latent space\nwithout relying on any explicit 3D representation. Specifically, we predict\nper-frame latent camera and scene context features, and employ a view synthesis\nmodel as a proxy for explicit rendering. This pretraining stage substantially\nreduces the optimization complexity and encourages the network to learn the\nunderlying 3D consistency in a self-supervised manner. The learned latent\ncamera and implicit scene representation have a large gap compared with the\nreal 3D world. To reduce this gap, we introduce the second stage training by\nexplicitly predicting 3D Gaussian primitives. We additionally apply explicit\nGaussian Splatting rendering loss and depth projection loss to align the\nlearned latent representations with physically grounded 3D geometry. In this\nway, Stage 1 provides a strong initialization and Stage 2 enforces 3D\nconsistency - the two stages are complementary and mutually beneficial.\nExtensive experiments demonstrate the effectiveness of our approach, achieving\nhigh-quality novel view synthesis and accurate camera pose estimation, compared\nto methods that employ supervision with calibration, pose, or depth\ninformation. The code is available at https://github.com/Dwawayu/Pensieve.",
    "pdf_url": "http://arxiv.org/pdf/2505.13440v1",
    "published": "2025-05-19T17:59:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13439v1",
    "title": "VTBench: Evaluating Visual Tokenizers for Autoregressive Image Generation",
    "authors": [
      "Huawei Lin",
      "Tong Geng",
      "Zhaozhuo Xu",
      "Weijie Zhao"
    ],
    "abstract": "Autoregressive (AR) models have recently shown strong performance in image\ngeneration, where a critical component is the visual tokenizer (VT) that maps\ncontinuous pixel inputs to discrete token sequences. The quality of the VT\nlargely defines the upper bound of AR model performance. However, current\ndiscrete VTs fall significantly behind continuous variational autoencoders\n(VAEs), leading to degraded image reconstructions and poor preservation of\ndetails and text. Existing benchmarks focus on end-to-end generation quality,\nwithout isolating VT performance. To address this gap, we introduce VTBench, a\ncomprehensive benchmark that systematically evaluates VTs across three core\ntasks: Image Reconstruction, Detail Preservation, and Text Preservation, and\ncovers a diverse range of evaluation scenarios. We systematically assess\nstate-of-the-art VTs using a set of metrics to evaluate the quality of\nreconstructed images. Our findings reveal that continuous VAEs produce superior\nvisual representations compared to discrete VTs, particularly in retaining\nspatial structure and semantic detail. In contrast, the degraded\nrepresentations produced by discrete VTs often lead to distorted\nreconstructions, loss of fine-grained textures, and failures in preserving text\nand object integrity. Furthermore, we conduct experiments on GPT-4o image\ngeneration and discuss its potential AR nature, offering new insights into the\nrole of visual tokenization. We release our benchmark and codebase publicly to\nsupport further research and call on the community to develop strong,\ngeneral-purpose open-source VTs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13439v1",
    "published": "2025-05-19T17:59:01+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13438v2",
    "title": "Optimizing Anytime Reasoning via Budget Relative Policy Optimization",
    "authors": [
      "Penghui Qi",
      "Zichen Liu",
      "Tianyu Pang",
      "Chao Du",
      "Wee Sun Lee",
      "Min Lin"
    ],
    "abstract": "Scaling test-time compute is crucial for enhancing the reasoning capabilities\nof large language models (LLMs). Existing approaches typically employ\nreinforcement learning (RL) to maximize a verifiable reward obtained at the end\nof reasoning traces. However, such methods optimize only the final performance\nunder a large and fixed token budget, which hinders efficiency in both training\nand deployment. In this work, we present a novel framework, AnytimeReasoner, to\noptimize anytime reasoning performance, which aims to improve token efficiency\nand the flexibility of reasoning under varying token budget constraints. To\nachieve this, we truncate the complete thinking process to fit within sampled\ntoken budgets from a prior distribution, compelling the model to summarize the\noptimal answer for each truncated thinking for verification. This introduces\nverifiable dense rewards into the reasoning process, facilitating more\neffective credit assignment in RL optimization. We then optimize the thinking\nand summary policies in a decoupled manner to maximize the cumulative reward.\nAdditionally, we introduce a novel variance reduction technique, Budget\nRelative Policy Optimization (BRPO), to enhance the robustness and efficiency\nof the learning process when reinforcing the thinking policy. Empirical results\nin mathematical reasoning tasks demonstrate that our method consistently\noutperforms GRPO across all thinking budgets under various prior distributions,\nenhancing both training and token efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.13438v2",
    "published": "2025-05-19T17:58:44+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13437v1",
    "title": "FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance",
    "authors": [
      "Dian Shao",
      "Mingfei Shi",
      "Shengda Xu",
      "Haodong Chen",
      "Yongle Huang",
      "Binglu Wang"
    ],
    "abstract": "Despite significant advances in video generation, synthesizing physically\nplausible human actions remains a persistent challenge, particularly in\nmodeling fine-grained semantics and complex temporal dynamics. For instance,\ngenerating gymnastics routines such as \"switch leap with 0.5 turn\" poses\nsubstantial difficulties for current methods, often yielding unsatisfactory\nresults. To bridge this gap, we propose FinePhys, a Fine-grained human action\ngeneration framework that incorporates Physics to obtain effective skeletal\nguidance. Specifically, FinePhys first estimates 2D poses in an online manner\nand then performs 2D-to-3D dimension lifting via in-context learning. To\nmitigate the instability and limited interpretability of purely data-driven 3D\nposes, we further introduce a physics-based motion re-estimation module\ngoverned by Euler-Lagrange equations, calculating joint accelerations via\nbidirectional temporal updating. The physically predicted 3D poses are then\nfused with data-driven ones, offering multi-scale 2D heatmap guidance for the\ndiffusion process. Evaluated on three fine-grained action subsets from FineGym\n(FX-JUMP, FX-TURN, and FX-SALTO), FinePhys significantly outperforms\ncompetitive baselines. Comprehensive qualitative results further demonstrate\nFinePhys's ability to generate more natural and plausible fine-grained human\nactions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13437v1",
    "published": "2025-05-19T17:58:11+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13436v1",
    "title": "KinTwin: Imitation Learning with Torque and Muscle Driven Biomechanical Models Enables Precise Replication of Able-Bodied and Impaired Movement from Markerless Motion Capture",
    "authors": [
      "R. James Cotton"
    ],
    "abstract": "Broader access to high-quality movement analysis could greatly benefit\nmovement science and rehabilitation, such as allowing more detailed\ncharacterization of movement impairments and responses to interventions, or\neven enabling early detection of new neurological conditions or fall risk.\nWhile emerging technologies are making it easier to capture kinematics with\nbiomechanical models, or how joint angles change over time, inferring the\nunderlying physics that give rise to these movements, including ground reaction\nforces, joint torques, or even muscle activations, is still challenging. Here\nwe explore whether imitation learning applied to a biomechanical model from a\nlarge dataset of movements from able-bodied and impaired individuals can learn\nto compute these inverse dynamics. Although imitation learning in human pose\nestimation has seen great interest in recent years, our work differences in\nseveral ways: we focus on using an accurate biomechanical model instead of\nmodels adopted for computer vision, we test it on a dataset that contains\nparticipants with impaired movements, we reported detailed tracking metrics\nrelevant for the clinical measurement of movement including joint angles and\nground contact events, and finally we apply imitation learning to a\nmuscle-driven neuromusculoskeletal model. We show that our imitation learning\npolicy, KinTwin, can accurately replicate the kinematics of a wide range of\nmovements, including those with assistive devices or therapist assistance, and\nthat it can infer clinically meaningful differences in joint torques and muscle\nactivations. Our work demonstrates the potential for using imitation learning\nto enable high-quality movement analysis in clinical practice.",
    "pdf_url": "http://arxiv.org/pdf/2505.13436v1",
    "published": "2025-05-19T17:58:03+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13435v1",
    "title": "Optical signatures of coherence in molecular dimers",
    "authors": [
      "Priyankar Banerjee",
      "Adam Burgess",
      "Julian Wiercinski",
      "Moritz Cygorek",
      "Erik M. Gauger"
    ],
    "abstract": "We calculate experimentally measurable signatures of quantum correlations in\na coupled molecular dimer that strongly interacts with its vibrational\nenvironment. We investigate intensity and mode-resolved photon coincidences for\ndifferent relative orientations of such dimers, and observe spatio-temporal\ncorrelations for various configurations. We find that projective measurements\ncan produce cooperative signatures even when emitters are arranged orthogonal\nto each other. To model effects of vibrational environments that are present in\nrealistic experimental situations, we use the polaron framework. Further, we\nalso account for the effects of finite instrument response, varying\ntemperature, and presence of static disorder. We analyse the effect of disorder\nin both dimer orientation and measurement direction and find that photon\ncoincidences remain well-resolvable using state-of-the-art detectors. This work\nenhances our understanding of cooperative emission from two coupled emitters\nand offers direction for future experiments on probing their coherent dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.13435v1",
    "published": "2025-05-19T17:57:54+00:00",
    "categories": [
      "quant-ph",
      "physics.chem-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13434v1",
    "title": "SMOTExT: SMOTE meets Large Language Models",
    "authors": [
      "Mateusz Bystro≈Ñski",
      "Miko≈Çaj Ho≈Çysz",
      "Grzegorz Piotrowski",
      "Nitesh V. Chawla",
      "Tomasz Kajdanowicz"
    ],
    "abstract": "Data scarcity and class imbalance are persistent challenges in training\nrobust NLP models, especially in specialized domains or low-resource settings.\nWe propose a novel technique, SMOTExT, that adapts the idea of Synthetic\nMinority Over-sampling (SMOTE) to textual data. Our method generates new\nsynthetic examples by interpolating between BERT-based embeddings of two\nexisting examples and then decoding the resulting latent point into text with\nxRAG architecture. By leveraging xRAG's cross-modal retrieval-generation\nframework, we can effectively turn interpolated vectors into coherent text.\nWhile this is preliminary work supported by qualitative outputs only, the\nmethod shows strong potential for knowledge distillation and data augmentation\nin few-shot settings. Notably, our approach also shows promise for\nprivacy-preserving machine learning: in early experiments, training models\nsolely on generated data achieved comparable performance to models trained on\nthe original dataset. This suggests a viable path toward safe and effective\nlearning under data protection constraints.",
    "pdf_url": "http://arxiv.org/pdf/2505.13434v1",
    "published": "2025-05-19T17:57:36+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13433v1",
    "title": "Nucleon-nucleon correlation functions from different interactions in comparison",
    "authors": [
      "Matthias G√∂bel",
      "Alejandro Kievsky"
    ],
    "abstract": "Correlation functions as they can be observed in heavy-ion collisions using\nthe femtoscopy technique are a powerful tool to study the interaction among\ndifferent baryons or mesons. Specifically, the multi-nucleon correlation\nfunctions have been under intense experimental and theoretical investigation in\nthe recent years. Due to the interest of using this observable as an input in\nthe construction of potentials between hadrons we revisit the nucleon-nucleon\ncorrelation function and calculate it using different nuclear interactions at\nhigh precision. Since the nucleon-nucleon potential is determined to reproduce\nthe two-nucleon scattering data, we would like to critically evaluate the\namount of this information captured by the correlation function. We study the\ndependence of the correlations on the nuclear force giving detailed insights\ninto the calculations, in particular the convergence behavior in the partial\nwaves. The coupling between the different partial-wave channels is taken into\naccount and the relevance of this effect is quantified. To make contact with\nprecedent studies the results based on the Argonne V18 interaction are\npresented. Then we consider also the Norfolk NV2-IIa and NV2-IIb chiral EFT\ninteractions. The analysis of the differences between the correlations of the\nvarious interactions shows that for momenta between 0 and 500 MeV there are\nvariations of up to 5.9 % for the $nn$ system, of up to 1.8 % for the $np$\nsystem, and of 1.4 % for the $pp$ system.",
    "pdf_url": "http://arxiv.org/pdf/2505.13433v1",
    "published": "2025-05-19T17:57:27+00:00",
    "categories": [
      "nucl-th",
      "nucl-ex"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13432v2",
    "title": "Synthetic-Powered Predictive Inference",
    "authors": [
      "Meshi Bashari",
      "Roy Maor Lotan",
      "Yonghoon Lee",
      "Edgar Dobriban",
      "Yaniv Romano"
    ],
    "abstract": "Conformal prediction is a framework for predictive inference with a\ndistribution-free, finite-sample guarantee. However, it tends to provide\nuninformative prediction sets when calibration data are scarce. This paper\nintroduces Synthetic-powered predictive inference (SPI), a novel framework that\nincorporates synthetic data -- e.g., from a generative model -- to improve\nsample efficiency. At the core of our method is a score transporter: an\nempirical quantile mapping that aligns nonconformity scores from trusted, real\ndata with those from synthetic data. By carefully integrating the score\ntransporter into the calibration process, SPI provably achieves finite-sample\ncoverage guarantees without making any assumptions about the real and synthetic\ndata distributions. When the score distributions are well aligned, SPI yields\nsubstantially tighter and more informative prediction sets than standard\nconformal prediction. Experiments on image classification -- augmenting data\nwith synthetic diffusion-model generated images -- and on tabular regression\ndemonstrate notable improvements in predictive efficiency in data-scarce\nsettings.",
    "pdf_url": "http://arxiv.org/pdf/2505.13432v2",
    "published": "2025-05-19T17:55:56+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13585v2",
    "title": "Scalable Bayesian Monte Carlo: fast uncertainty estimation beyond deep ensembles",
    "authors": [
      "Xinzhu Liang",
      "Joseph M. Lukens",
      "Sanjaya Lohani",
      "Brian T. Kirby",
      "Thomas A. Searles",
      "Xin Qiu",
      "Kody J. H. Law"
    ],
    "abstract": "This work introduces a new method designed for Bayesian deep learning called\nscalable Bayesian Monte Carlo (SBMC). The method is comprised of a model and an\nalgorithm. The model interpolates between a point estimator and the posterior.\nThe algorithm is a parallel implementation of sequential Monte Carlo sampler\n(SMC$_\\parallel$) or Markov chain Monte Carlo (MCMC$_\\parallel$). We\ncollectively refer to these consistent (asymptotically unbiased) algorithms as\nBayesian Monte Carlo (BMC), and any such algorithm can be used in our SBMC\nmethod. The utility of the method is demonstrated on practical examples: MNIST,\nCIFAR, IMDb. A systematic numerical study reveals that for the same wall-clock\ntime as state-of-the-art (SOTA) methods like deep ensembles (DE), SBMC achieves\ncomparable or better accuracy and substantially improved uncertainty\nquantification (UQ)--in particular, epistemic UQ. This is demonstrated on the\ndownstream task of estimating the confidence in predictions, which can be used\nfor reliability assessment or abstention decisions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13585v2",
    "published": "2025-05-19T17:55:32+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.CO"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.13431v2",
    "title": "A Practical Guide for Incorporating Symmetry in Diffusion Policy",
    "authors": [
      "Dian Wang",
      "Boce Hu",
      "Shuran Song",
      "Robin Walters",
      "Robert Platt"
    ],
    "abstract": "Recently, equivariant neural networks for policy learning have shown\npromising improvements in sample efficiency and generalization, however, their\nwide adoption faces substantial barriers due to implementation complexity.\nEquivariant architectures typically require specialized mathematical\nformulations and custom network design, posing significant challenges when\nintegrating with modern policy frameworks like diffusion-based models. In this\npaper, we explore a number of straightforward and practical approaches to\nincorporate symmetry benefits into diffusion policies without the overhead of\nfull equivariant designs. Specifically, we investigate (i) invariant\nrepresentations via relative trajectory actions and eye-in-hand perception,\n(ii) integrating equivariant vision encoders, and (iii) symmetric feature\nextraction with pretrained encoders using Frame Averaging. We first prove that\ncombining eye-in-hand perception with relative or delta action parameterization\nyields inherent SE(3)-invariance, thus improving policy generalization. We then\nperform a systematic experimental study on those design choices for integrating\nsymmetry in diffusion policies, and conclude that an invariant representation\nwith equivariant feature extraction significantly improves the policy\nperformance. Our method achieves performance on par with or exceeding fully\nequivariant architectures while greatly simplifying implementation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13431v2",
    "published": "2025-05-19T17:55:28+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13430v2",
    "title": "Fine-tuning Quantized Neural Networks with Zeroth-order Optimization",
    "authors": [
      "Sifeng Shang",
      "Jiayi Zhou",
      "Chenyu Lin",
      "Minxian Li",
      "Kaiyang Zhou"
    ],
    "abstract": "As the size of large language models grows exponentially, GPU memory has\nbecome a bottleneck for adapting these models to downstream tasks. In this\npaper, we aim to push the limits of memory-efficient training by minimizing\nmemory usage on model weights, gradients, and optimizer states, within a\nunified framework. Our idea is to eliminate both gradients and optimizer states\nusing zeroth-order optimization, which approximates gradients by perturbing\nweights during forward passes to identify gradient directions. To minimize\nmemory usage on weights, we employ model quantization, e.g., converting from\nbfloat16 to int4. However, directly applying zeroth-order optimization to\nquantized weights is infeasible due to the precision gap between discrete\nweights and continuous gradients, which would otherwise require de-quantization\nand re-quantization. To overcome this challenge, we propose Quantized\nZeroth-order Optimization (QZO), a simple yet effective approach that perturbs\nthe continuous quantization scale for gradient estimation and uses a\ndirectional derivative clipping method to stabilize training. QZO is orthogonal\nto both scalar-based and codebook-based post-training quantization methods.\nCompared to full-parameter fine-tuning in 16 bits, QZO can reduce the total\nmemory cost by more than 18$\\times$ for 4-bit LLMs, and enables fine-tuning\nLlama-2-13B within a single 24GB GPU. Code will be released publicly.",
    "pdf_url": "http://arxiv.org/pdf/2505.13430v2",
    "published": "2025-05-19T17:55:15+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13429v1",
    "title": "Understanding Complexity in VideoQA via Visual Program Generation",
    "authors": [
      "Cristobal Eyzaguirre",
      "Igor Vasiljevic",
      "Achal Dave",
      "Jiajun Wu",
      "Rares Andrei Ambrus",
      "Thomas Kollar",
      "Juan Carlos Niebles",
      "Pavel Tokmakov"
    ],
    "abstract": "We propose a data-driven approach to analyzing query complexity in Video\nQuestion Answering (VideoQA). Previous efforts in benchmark design have relied\non human expertise to design challenging questions, yet we experimentally show\nthat humans struggle to predict which questions are difficult for machine\nlearning models. Our automatic approach leverages recent advances in code\ngeneration for visual question answering, using the complexity of generated\ncode as a proxy for question difficulty. We demonstrate that this measure\ncorrelates significantly better with model performance than human estimates. To\noperationalize this insight, we propose an algorithm for estimating question\ncomplexity from code. It identifies fine-grained primitives that correlate with\nthe hardest questions for any given set of models, making it easy to scale to\nnew approaches in the future. Finally, to further illustrate the utility of our\nmethod, we extend it to automatically generate complex questions, constructing\na new benchmark that is 1.9 times harder than the popular NExT-QA.",
    "pdf_url": "http://arxiv.org/pdf/2505.13429v1",
    "published": "2025-05-19T17:55:14+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13428v1",
    "title": "Meta-rotations and the Structure of Stable Matchings in the Student Project Allocation Problem",
    "authors": [
      "Peace Ayegba",
      "Sofiat Olaosebikan",
      "David Manlove"
    ],
    "abstract": "We formally introduce and present the concept of meta-rotations as a tool for\nnavigating the lattice of stable matchings in the Student Project Allocation\nproblem with lecturer preferences over students (SPA-S). Building on the\nstructural result that the set of stable matchings in any SPA-S instance forms\na distributive lattice, we define meta-rotations for this setting and\ndemonstrate how they compactly encode transitions between matchings. Our\nframework generalises the classical notion of rotations in bipartite settings\nand provides a systematic way to traverse the lattice, thereby enabling\nefficient enumeration of the set of stable matchings in any given SPA-S\ninstance.",
    "pdf_url": "http://arxiv.org/pdf/2505.13428v1",
    "published": "2025-05-19T17:55:10+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13427v2",
    "title": "MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision",
    "authors": [
      "Lingxiao Du",
      "Fanqing Meng",
      "Zongkai Liu",
      "Zhixiang Zhou",
      "Ping Luo",
      "Qiaosheng Zhang",
      "Wenqi Shao"
    ],
    "abstract": "While Multimodal Large Language Models (MLLMs) have achieved impressive\nprogress in vision-language understanding, they still struggle with complex\nmulti-step reasoning, often producing logically inconsistent or partially\ncorrect solutions. A key limitation lies in the lack of fine-grained\nsupervision over intermediate reasoning steps. To address this, we propose\nMM-PRM, a process reward model trained within a fully automated, scalable\nframework. We first build MM-Policy, a strong multimodal model trained on\ndiverse mathematical reasoning data. Then, we construct MM-K12, a curated\ndataset of 10,000 multimodal math problems with verifiable answers, which\nserves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based\npipeline, we generate over 700k step-level annotations without human labeling.\nThe resulting PRM is used to score candidate reasoning paths in the Best-of-N\ninference setup and achieves significant improvements across both in-domain\n(MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.)\nbenchmarks. Further analysis confirms the effectiveness of soft labels, smaller\nlearning rates, and path diversity in optimizing PRM performance. MM-PRM\ndemonstrates that process supervision is a powerful tool for enhancing the\nlogical robustness of multimodal reasoning systems. We release all our codes\nand data at https://github.com/ModalMinds/MM-PRM.",
    "pdf_url": "http://arxiv.org/pdf/2505.13427v2",
    "published": "2025-05-19T17:55:08+00:00",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13426v1",
    "title": "G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language Model via Reinforcement Learning",
    "authors": [
      "Liang Chen",
      "Hongcheng Gao",
      "Tianyu Liu",
      "Zhiqi Huang",
      "Flood Sung",
      "Xinyu Zhou",
      "Yuxin Wu",
      "Baobao Chang"
    ],
    "abstract": "Vision-Language Models (VLMs) excel in many direct multimodal tasks but\nstruggle to translate this prowess into effective decision-making within\ninteractive, visually rich environments like games. This ``knowing-doing'' gap\nsignificantly limits their potential as autonomous agents, as leading VLMs\noften performing badly in simple games. To address this, we introduce VLM-Gym,\na curated reinforcement learning (RL) environment featuring diverse visual\ngames with unified interfaces and adjustable, compositional difficulty,\nspecifically designed for scalable multi-game parallel training. Leveraging\nVLM-Gym, we train G0 models using pure RL-driven self-evolution, which\ndemonstrate emergent perception and reasoning patterns. To further mitigate\nchallenges arising from game diversity, we develop G1 models. G1 incorporates a\nperception-enhanced cold start prior to RL fine-tuning. Our resulting G1 models\nconsistently surpass their teacher across all games and outperform leading\nproprietary models like Claude-3.7-Sonnet-Thinking. Systematic analysis reveals\nan intriguing finding: perception and reasoning abilities mutually bootstrap\neach other throughout the RL training process. Source code including VLM-Gym\nand RL training are released at https://github.com/chenllliang/G1 to foster\nfuture research in advancing VLMs as capable interactive agents.",
    "pdf_url": "http://arxiv.org/pdf/2505.13426v1",
    "published": "2025-05-19T17:54:39+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13425v1",
    "title": "Learnware of Language Models: Specialized Small Language Models Can Do Big",
    "authors": [
      "Zhi-Hao Tan",
      "Zi-Chen Zhao",
      "Hao-Yu Shi",
      "Xin-Yu Zhang",
      "Peng Tan",
      "Yang Yu",
      "Zhi-Hua Zhou"
    ],
    "abstract": "The learnware paradigm offers a novel approach to machine learning by\nenabling users to reuse a set of well-trained models for tasks beyond the\nmodels' original purposes. It eliminates the need to build models from scratch,\ninstead relying on specifications (representations of a model's capabilities)\nto identify and leverage the most suitable models for new tasks. While\nlearnware has proven effective in many scenarios, its application to language\nmodels has remained largely unexplored. At the same time, large language models\n(LLMs) have demonstrated remarkable universal question-answering abilities, yet\nthey face challenges in specialized scenarios due to data scarcity, privacy\nconcerns, and high computational costs, thus more and more specialized small\nlanguage models (SLMs) are being trained for specific domains. To address these\nlimitations systematically, the learnware paradigm provides a promising\nsolution by enabling maximum utilization of specialized SLMs, and allowing\nusers to identify and reuse them in a collaborative and privacy-preserving\nmanner.\n  This paper presents a preliminary attempt to apply the learnware paradigm to\nlanguage models. We simulated a learnware system comprising approximately 100\nlearnwares of specialized SLMs with 8B parameters, fine-tuned across finance,\nhealthcare, and mathematics domains. Each learnware contains an SLM and a\nspecification, which enables users to identify the most relevant models without\nexposing their own data. Experimental results demonstrate promising\nperformance: by selecting one suitable learnware for each task-specific\ninference, the system outperforms the base SLMs on all benchmarks. Compared to\nLLMs, the system outperforms Qwen1.5-110B, Qwen2.5-72B, and\nLlama3.1-70B-Instruct by at least 14% in finance domain tasks, and surpasses\nFlan-PaLM-540B (ranked 7th on the Open Medical LLM Leaderboard) in medical\ndomain tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13425v1",
    "published": "2025-05-19T17:54:35+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13424v3",
    "title": "The Enduring Relevance of Semiempirical Quantum Mechanics",
    "authors": [
      "Jonathan E. Moussa"
    ],
    "abstract": "The development of semiempirical models to simplify quantum mechanical\ndescriptions of atomistic systems is a practice that started soon after the\ndiscovery of quantum mechanics and continues to the present day. There are now\nmany methods for atomistic simulation with many software implementations and\nmany users, on a scale large enough to be considered as a software market.\nSemiempirical models occupied a large share of this market in its early days,\nbut the research activity in atomistic simulation has steadily polarized over\nthe last three decades towards general-purpose but expensive ab initio quantum\nmechanics methods and fast but special-purpose molecular mechanics methods. I\noffer perspective on recent trends in atomistic simulation from the middle\nground of semiempirical modeling, to learn from its past success and consider\nits possible paths to future growth. In particular, there is a lot of ongoing\nresearch activity in combining semiempirical quantum mechanics with machine\nlearning models and some unrealized possibilities of tighter integration\nbetween ab initio and semiempirical quantum mechanics with more flexible\ntheoretical frameworks and more modular software components.",
    "pdf_url": "http://arxiv.org/pdf/2505.13424v3",
    "published": "2025-05-19T17:53:45+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13423v1",
    "title": "On modified Hawking radiation under quantum gravity effects in the fermion sector",
    "authors": [
      "Ivan P-Castro",
      "H√©ctor Aguilera-Trujillo",
      "Hugo Garc√≠a-Compe√°n",
      "Abdel P√©rez-Lorenzana"
    ],
    "abstract": "In this letter, after briefly discussing the Hawking radiation (HR) as a\nquantum tunneling, we emphasize that special care must be taken when computing\ntemperature corrections in the presence of Lorentz invariance violation (LIV),\nparticularly by ensuring consistency between the modified dispersion relation\nand the gamma matrix structure used to describe fermions that are tunneling. We\npresent a consistent implementation of such corrections in static, spherically\nsymmetric black hole (BH) spacetimes. Our results show that introducing terms\nthat increase/decrease the energy in the dispersion relation--originally\ndetermined by Lorentz invariance--leads to a corresponding increase/decrease in\nthe Hawking temperature, when the dispersion relation is uniquely determined.\nWe also determined the changes in Bekenstein-Hawking entropy for the\nReissner-Nordstr\\\"om and Schwarzschild BHs, including corrections from LIV\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.13423v1",
    "published": "2025-05-19T17:53:36+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.13422v1",
    "title": "Machine learning the first stage in 2SLS: Practical guidance from bias decomposition and simulation",
    "authors": [
      "Connor Lennon",
      "Edward Rubin",
      "Glen Waddell"
    ],
    "abstract": "Machine learning (ML) primarily evolved to solve \"prediction problems.\" The\nfirst stage of two-stage least squares (2SLS) is a prediction problem,\nsuggesting potential gains from ML first-stage assistance. However, little\nguidance exists on when ML helps 2SLS$\\unicode{x2014}$or when it hurts. We\ninvestigate the implications of inserting ML into 2SLS, decomposing the bias\ninto three informative components. Mechanically, ML-in-2SLS procedures face\nissues common to prediction and causal-inference settings$\\unicode{x2014}$and\ntheir interaction. Through simulation, we show linear ML methods (e.g.,\npost-Lasso) work well, while nonlinear methods (e.g., random forests, neural\nnets) generate substantial bias in second-stage\nestimates$\\unicode{x2014}$potentially exceeding the bias of endogenous OLS.",
    "pdf_url": "http://arxiv.org/pdf/2505.13422v1",
    "published": "2025-05-19T17:53:15+00:00",
    "categories": [
      "econ.EM",
      "cs.LG",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2505.13421v1",
    "title": "Make Still Further Progress: Chain of Thoughts for Tabular Data Leaderboard",
    "authors": [
      "Si-Yang Liu",
      "Qile Zhou",
      "Han-Jia Ye"
    ],
    "abstract": "Tabular data, a fundamental data format in machine learning, is predominantly\nutilized in competitions and real-world applications. The performance of\ntabular models--such as gradient boosted decision trees and neural\nnetworks--can vary significantly across datasets due to differences in feature\ndistributions and task characteristics. Achieving top performance on each\ndataset often requires specialized expert knowledge. To address this\nvariability, practitioners often aggregate the predictions of multiple models.\nHowever, conventional aggregation strategies typically rely on static\ncombination rules and lack instance-level adaptability. In this work, we\npropose an in-context ensemble framework for tabular prediction that leverages\nlarge language models (LLMs) to perform dynamic, instance-specific integration\nof external model predictions. Without access to raw tabular features or\nsemantic information, our method constructs a context around each test instance\nusing its nearest neighbors and the predictions from a pool of external models.\nWithin this enriched context, we introduce Chain of Tabular Thoughts (CoT$^2$),\na prompting strategy that guides LLMs through multi-step, interpretable\nreasoning, making still further progress toward expert-level decision-making.\nExperimental results show that our method outperforms well-tuned baselines and\nstandard ensemble techniques across a wide range of tabular datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.13421v1",
    "published": "2025-05-19T17:52:58+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13420v2",
    "title": "Scalar-Induced Gravitational Waves in Palatini $f(R)$ Gravity",
    "authors": [
      "Samuel S√°nchez L√≥pez",
      "Jos√© Jaime Terente D√≠az"
    ],
    "abstract": "Primordial scalar perturbations that reenter the horizon after inflation may\ninduce a second-order Gravitational Wave spectrum with information about the\nprimordial Universe on scales inaccessible to Cosmic Microwave Background\nexperiments. In this work, we develop a general framework for the study of\nScalar-Induced Gravitational Waves in Palatini $f(R)$ gravity, a theory that\nwas proven to successfully realise inflation and quintessence, and consider the\ncase of the Starobinsky-like model as an example. A regime of radiation\ndomination with a subdominant matter component is assumed, allowing for a\nwell-motivated perturbative approach to the gravity modifications. We calculate\nthe kernel function and the density spectrum numerically and find accurate\nanalytical expressions. The spectral density, which may be tested across a wide\nrange of frequencies by upcoming Gravitational Wave experiments, is shown to\ndiffer from the General Relativity and metric $f(R)$ gravity predictions under\ncertain conditions. We comment on previous results in the literature regarding\nthe metric formulation and make special emphasis on the potential of these\ndistinctive features of the spectrum to probe the two formalisms of gravity.",
    "pdf_url": "http://arxiv.org/pdf/2505.13420v2",
    "published": "2025-05-19T17:52:30+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13419v1",
    "title": "FEALLM: Advancing Facial Emotion Analysis in Multimodal Large Language Models with Emotional Synergy and Reasoning",
    "authors": [
      "Zhuozhao Hu",
      "Kaishen Yuan",
      "Xin Liu",
      "Zitong Yu",
      "Yuan Zong",
      "Jingang Shi",
      "Huanjing Yue",
      "Jingyu Yang"
    ],
    "abstract": "Facial Emotion Analysis (FEA) plays a crucial role in visual affective\ncomputing, aiming to infer a person's emotional state based on facial data.\nScientifically, facial expressions (FEs) result from the coordinated movement\nof facial muscles, which can be decomposed into specific action units (AUs)\nthat provide detailed emotional insights. However, traditional methods often\nstruggle with limited interpretability, constrained generalization and\nreasoning abilities. Recently, Multimodal Large Language Models (MLLMs) have\nshown exceptional performance in various visual tasks, while they still face\nsignificant challenges in FEA due to the lack of specialized datasets and their\ninability to capture the intricate relationships between FEs and AUs. To\naddress these issues, we introduce a novel FEA Instruction Dataset that\nprovides accurate and aligned FE and AU descriptions and establishes causal\nreasoning relationships between them, followed by constructing a new benchmark,\nFEABench. Moreover, we propose FEALLM, a novel MLLM architecture designed to\ncapture more detailed facial information, enhancing its capability in FEA\ntasks. Our model demonstrates strong performance on FEABench and impressive\ngeneralization capability through zero-shot evaluation on various datasets,\nincluding RAF-DB, AffectNet, BP4D, and DISFA, showcasing its robustness and\neffectiveness in FEA tasks. The dataset and code will be available at\nhttps://github.com/953206211/FEALLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.13419v1",
    "published": "2025-05-19T17:52:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13418v1",
    "title": "Dementia Through Different Eyes: Explainable Modeling of Human and LLM Perceptions for Early Awareness",
    "authors": [
      "Lotem Peled-Cohen",
      "Maya Zadok",
      "Nitay Calderon",
      "Hila Gonen",
      "Roi Reichart"
    ],
    "abstract": "Cognitive decline often surfaces in language years before diagnosis. It is\nfrequently non-experts, such as those closest to the patient, who first sense a\nchange and raise concern. As LLMs become integrated into daily communication\nand used over prolonged periods, it may even be an LLM that notices something\nis off. But what exactly do they notice--and should be noticing--when making\nthat judgment? This paper investigates how dementia is perceived through\nlanguage by non-experts. We presented transcribed picture descriptions to\nnon-expert humans and LLMs, asking them to intuitively judge whether each text\nwas produced by someone healthy or with dementia. We introduce an explainable\nmethod that uses LLMs to extract high-level, expert-guided features\nrepresenting these picture descriptions, and use logistic regression to model\nhuman and LLM perceptions and compare with clinical diagnoses. Our analysis\nreveals that human perception of dementia is inconsistent and relies on a\nnarrow, and sometimes misleading, set of cues. LLMs, by contrast, draw on a\nricher, more nuanced feature set that aligns more closely with clinical\npatterns. Still, both groups show a tendency toward false negatives, frequently\noverlooking dementia cases. Through our interpretable framework and the\ninsights it provides, we hope to help non-experts better recognize the\nlinguistic signs that matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.13418v1",
    "published": "2025-05-19T17:51:35+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13417v1",
    "title": "AdaptThink: Reasoning Models Can Learn When to Think",
    "authors": [
      "Jiajie Zhang",
      "Nianyi Lin",
      "Lei Hou",
      "Ling Feng",
      "Juanzi Li"
    ],
    "abstract": "Recently, large reasoning models have achieved impressive performance on\nvarious tasks by employing human-like deep thinking. However, the lengthy\nthinking process substantially increases inference overhead, making efficiency\na critical bottleneck. In this work, we first demonstrate that NoThinking,\nwhich prompts the reasoning model to skip thinking and directly generate the\nfinal solution, is a better choice for relatively simple tasks in terms of both\nperformance and efficiency. Motivated by this, we propose AdaptThink, a novel\nRL algorithm to teach reasoning models to choose the optimal thinking mode\nadaptively based on problem difficulty. Specifically, AdaptThink features two\ncore components: (1) a constrained optimization objective that encourages the\nmodel to choose NoThinking while maintaining the overall performance; (2) an\nimportance sampling strategy that balances Thinking and NoThinking samples\nduring on-policy training, thereby enabling cold start and allowing the model\nto explore and exploit both thinking modes throughout the training process. Our\nexperiments indicate that AdaptThink significantly reduces the inference costs\nwhile further enhancing performance. Notably, on three math datasets,\nAdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B\nby 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive\nthinking-mode selection for optimizing the balance between reasoning quality\nand efficiency. Our codes and models are available at\nhttps://github.com/THU-KEG/AdaptThink.",
    "pdf_url": "http://arxiv.org/pdf/2505.13417v1",
    "published": "2025-05-19T17:50:52+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13416v1",
    "title": "Gluon: Making Muon & Scion Great Again! (Bridging Theory and Practice of LMO-based Optimizers for LLMs)",
    "authors": [
      "Artem Riabinin",
      "Egor Shulgin",
      "Kaja Gruntkowska",
      "Peter Richt√°rik"
    ],
    "abstract": "Recent developments in deep learning optimization have brought about\nradically new algorithms based on the Linear Minimization Oracle (LMO)\nframework, such as $\\sf Muon$ and $\\sf Scion$. After over a decade of $\\sf\nAdam$'s dominance, these LMO-based methods are emerging as viable replacements,\noffering several practical advantages such as improved memory efficiency,\nbetter hyperparameter transferability, and most importantly, superior empirical\nperformance on large-scale tasks, including LLM training. However, a\nsignificant gap remains between their practical use and our current theoretical\nunderstanding: prior analyses (1) overlook the layer-wise LMO application of\nthese optimizers in practice, and (2) rely on an unrealistic smoothness\nassumption, leading to impractically small stepsizes. To address both, we\npropose a new LMO-based method called $\\sf Gluon$, capturing prior\ntheoretically analyzed methods as special cases, and introduce a new refined\ngeneralized smoothness model that captures the layer-wise geometry of neural\nnetworks, matches the layer-wise practical implementation of $\\sf Muon$ and\n$\\sf Scion$, and leads to convergence guarantees with strong practical\npredictive power. Unlike prior results, our theoretical stepsizes closely match\nthe fine-tuned values reported by Pethick et al. (2025). Our experiments with\nNanoGPT and CNN confirm that our assumption holds along the optimization\ntrajectory, ultimately closing the gap between theory and practice.",
    "pdf_url": "http://arxiv.org/pdf/2505.13416v1",
    "published": "2025-05-19T17:50:45+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13415v1",
    "title": "Optical signatures of bulk g-wave altermagnetism in MnTe",
    "authors": [
      "Luca Haag",
      "Marius Weber",
      "Kai Leckron",
      "Libor ≈†mejkal",
      "Jairo Sinova",
      "Hans Christian Schneider"
    ],
    "abstract": "In planar altermagnets, optical excitation by linearly polarized ultrashort\npulses can induce spin polarizations in the electronic excited states in a\ncontrolled fashion, even though the material is magnetically compensated. Here,\nwe theoretically analyze the response of the prototypical bulk g-wave\naltermagnet $\\alpha$-MnTe to polarized ultrashort pulses. By calculating the\nexcited electron distributions based on ab-initio band structure data, we show\nhow this excited electronic spin response in $\\alpha$-MnTe exhibits different\nsymmetries which are determined by the nodal planes intrinsic to the bulk\ng-wave altermagnet. We present a simple procedure to obtain the symmetry of the\nelectronic spin response from the two-dimensional cuts through the\nthree-dimensional band structure.",
    "pdf_url": "http://arxiv.org/pdf/2505.13415v1",
    "published": "2025-05-19T17:48:26+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.13414v1",
    "title": "GuidedMorph: Two-Stage Deformable Registration for Breast MRI",
    "authors": [
      "Yaqian Chen",
      "Hanxue Gu",
      "Haoyu Dong",
      "Qihang Li",
      "Yuwen Chen",
      "Nicholas Konz",
      "Lin Li",
      "Maciej A. Mazurowski"
    ],
    "abstract": "Accurately registering breast MR images from different time points enables\nthe alignment of anatomical structures and tracking of tumor progression,\nsupporting more effective breast cancer detection, diagnosis, and treatment\nplanning. However, the complexity of dense tissue and its highly non-rigid\nnature pose challenges for conventional registration methods, which primarily\nfocus on aligning general structures while overlooking intricate internal\ndetails. To address this, we propose \\textbf{GuidedMorph}, a novel two-stage\nregistration framework designed to better align dense tissue. In addition to a\nsingle-scale network for global structure alignment, we introduce a framework\nthat utilizes dense tissue information to track breast movement. The learned\ntransformation fields are fused by introducing the Dual Spatial Transformer\nNetwork (DSTN), improving overall alignment accuracy. A novel warping method\nbased on the Euclidean distance transform (EDT) is also proposed to accurately\nwarp the registered dense tissue and breast masks, preserving fine structural\ndetails during deformation. The framework supports paradigms that require\nexternal segmentation models and with image data only. It also operates\neffectively with the VoxelMorph and TransMorph backbones, offering a versatile\nsolution for breast registration. We validate our method on ISPY2 and internal\ndataset, demonstrating superior performance in dense tissue, overall breast\nalignment, and breast structural similarity index measure (SSIM), with notable\nimprovements by over 13.01% in dense tissue Dice, 3.13% in breast Dice, and\n1.21% in breast SSIM compared to the best learning-based baseline.",
    "pdf_url": "http://arxiv.org/pdf/2505.13414v1",
    "published": "2025-05-19T17:48:06+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13413v1",
    "title": "Joint Velocity-Growth Flow Matching for Single-Cell Dynamics Modeling",
    "authors": [
      "Dongyi Wang",
      "Yuanwei Jiang",
      "Zhenyi Zhang",
      "Xiang Gu",
      "Peijie Zhou",
      "Jian Sun"
    ],
    "abstract": "Learning the underlying dynamics of single cells from snapshot data has\ngained increasing attention in scientific and machine learning research. The\ndestructive measurement technique and cell proliferation/death result in\nunpaired and unbalanced data between snapshots, making the learning of the\nunderlying dynamics challenging. In this paper, we propose joint\nVelocity-Growth Flow Matching (VGFM), a novel paradigm that jointly learns\nstate transition and mass growth of single-cell populations via flow matching.\nVGFM builds an ideal single-cell dynamics containing velocity of state and\ngrowth of mass, driven by a presented two-period dynamic understanding of the\nstatic semi-relaxed optimal transport, a mathematical tool that seeks the\ncoupling between unpaired and unbalanced data. To enable practical usage, we\napproximate the ideal dynamics using neural networks, forming our joint\nvelocity and growth matching framework. A distribution fitting loss is also\nemployed in VGFM to further improve the fitting performance for snapshot data.\nExtensive experimental results on both synthetic and real datasets demonstrate\nthat VGFM can capture the underlying biological dynamics accounting for mass\nand state variations over time, outperforming existing approaches for\nsingle-cell dynamics modeling.",
    "pdf_url": "http://arxiv.org/pdf/2505.13413v1",
    "published": "2025-05-19T17:48:04+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13412v2",
    "title": "Counts and end-curves in two-parameter persistence",
    "authors": [
      "Thomas Br√ºstle",
      "Steve Oudot",
      "Luis Scoccola",
      "Hugh Thomas"
    ],
    "abstract": "Given a finite dimensional, bigraded module over the polynomial ring in two\nvariables, we define its two-parameter count, a natural number, and its\nend-curves, a set of plane curves. These are two-dimensional analogues of the\nnotions of bar-count and endpoints of singly-graded modules over the polynomial\nring in one variable, from persistence theory. We show that our count is the\nunique one satisfying certain natural conditions; as a consequence, several\ninclusion-exclusion formulas in two-parameter persistence yield the same\npositive number, which equals our count, and which in turn equals the number of\nend-curves, giving geometric meaning to this count. We show that the end-curves\ndetermine the classical Betti tables by showing that they interpolate between\ngenerators, relations, and syzygies. Using the band representations of a\ncertain string algebra, we show that the set of end-curves admits a canonical\npartition, where each part forms a closed curve on the plane; we call this the\nboundary of the module. As an invariant, the boundary is neither weaker nor\nstronger than the rank invariant, but, in contrast to the rank invariant, it is\na complete invariant on the set of spread-decomposable representations. Our\nresults connect several lines of work in multiparameter persistence, and their\nextension to modules over the real-exponent polynomial ring in two variables\nrelates to two-dimensional Morse theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.13412v2",
    "published": "2025-05-19T17:47:51+00:00",
    "categories": [
      "math.RT",
      "cs.CG",
      "math.AC",
      "math.AT"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13411v1",
    "title": "Musical Chords by the Numbers",
    "authors": [
      "Matthias Beck",
      "Emily Clader"
    ],
    "abstract": "The mathematics of musical intervals and scales has been extensively studied.\nVastly simplified, our ears seem to prefer intervals whose frequency ratios\nhave small numerator and denominator, such as 2:1 (octave), 3:2 (perfect\nfifth), 4:3 (perfect fourth), and so on. While there also have been numerous\nstudies on the mathematics of musical chords, very few of them consider a model\nthat measures consonance/dissonance of a given chord in analogy with this\nsimple-fractions perspective. Our aim is to develop a measure for the\nconsonance of a chord with crucial symmetry features, including invariance\nunder chord translation, inversion, and interval sets. We apply our model to\nchords in various musical scales and compare it to existing models and\nempirical studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.13411v1",
    "published": "2025-05-19T17:47:45+00:00",
    "categories": [
      "math.HO",
      "00A65"
    ],
    "primary_category": "math.HO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13584v1",
    "title": "Self-Supervised Learning for Image Segmentation: A Comprehensive Survey",
    "authors": [
      "Thangarajah Akilan",
      "Nusrat Jahan",
      "Wandong Zhang"
    ],
    "abstract": "Supervised learning demands large amounts of precisely annotated data to\nachieve promising results. Such data curation is labor-intensive and imposes\nsignificant overhead regarding time and costs. Self-supervised learning (SSL)\npartially overcomes these limitations by exploiting vast amounts of unlabeled\ndata and creating surrogate (pretext or proxy) tasks to learn useful\nrepresentations without manual labeling. As a result, SSL has become a powerful\nmachine learning (ML) paradigm for solving several practical downstream\ncomputer vision problems, such as classification, detection, and segmentation.\nImage segmentation is the cornerstone of many high-level visual perception\napplications, including medical imaging, intelligent transportation,\nagriculture, and surveillance. Although there is substantial research potential\nfor developing advanced algorithms for SSL-based semantic segmentation, a\ncomprehensive study of existing methodologies is essential to trace advances\nand guide emerging researchers. This survey thoroughly investigates over 150\nrecent image segmentation articles, particularly focusing on SSL. It provides a\npractical categorization of pretext tasks, downstream tasks, and commonly used\nbenchmark datasets for image segmentation research. It concludes with key\nobservations distilled from a large body of literature and offers future\ndirections to make this research field more accessible and comprehensible for\nreaders.",
    "pdf_url": "http://arxiv.org/pdf/2505.13584v1",
    "published": "2025-05-19T17:47:32+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13410v1",
    "title": "Joint stochastic localization and applications",
    "authors": [
      "Tom Alberts",
      "Yiming Xu",
      "Qiang Ye"
    ],
    "abstract": "Stochastic localization is a pathwise analysis technique originating from\nconvex geometry. This paper explores certain algorithmic aspects of stochastic\nlocalization as a computational tool. First, we unify various existing\nstochastic localization schemes and discuss their localization rates and\nregularization. We then introduce a joint stochastic localization framework for\nconstructing couplings between probability distributions. As an initial\napplication, we extend the optimal couplings between normal distributions under\nthe 2-Wasserstein distance to log-concave distributions and derive a normal\napproximation result. As a further application, we introduce a family of\ndistributional distances based on the couplings induced by joint stochastic\nlocalization. Under a specific choice of the localization process, the induced\ndistance is topologically equivalent to the 2-Wasserstein distance for\nprobability measures supported on a common compact set. Moreover, weighted\nversions of this distance are related to several statistical divergences\ncommonly used in practice. The proposed distances also motivate new methods for\ndistribution estimation that are of independent interest.",
    "pdf_url": "http://arxiv.org/pdf/2505.13410v1",
    "published": "2025-05-19T17:47:05+00:00",
    "categories": [
      "math.ST",
      "math.PR",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.13409v1",
    "title": "Recombinant dynamical systems",
    "authors": [
      "Saul Kato"
    ],
    "abstract": "We describe a connectionist model that attempts to capture a notion of\nexperience-based problem solving or task learning, whereby solutions to newly\nencountered problems are composed from remembered solutions to prior problems.\nWe apply this model to the computational problem of \\emph{efficient sequence\ngeneration}, a problem for which there is no obvious gradient descent\nprocedure, and for which not all posable problem instances are solvable.\nEmpirical tests show promising evidence of utility.",
    "pdf_url": "http://arxiv.org/pdf/2505.13409v1",
    "published": "2025-05-19T17:45:10+00:00",
    "categories": [
      "cs.NE",
      "q-bio.NC"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13408v1",
    "title": "CoT-Kinetics: A Theoretical Modeling Assessing LRM Reasoning Process",
    "authors": [
      "Jinhe Bi",
      "Danqi Yan",
      "Yifan Wang",
      "Wenke Huang",
      "Haokun Chen",
      "Guancheng Wan",
      "Mang Ye",
      "Xun Xiao",
      "Hinrich Schuetze",
      "Volker Tresp",
      "Yunpu Ma"
    ],
    "abstract": "Recent Large Reasoning Models significantly improve the reasoning ability of\nLarge Language Models by learning to reason, exhibiting the promising\nperformance in solving complex tasks. LRMs solve tasks that require complex\nreasoning by explicitly generating reasoning trajectories together with\nanswers. Nevertheless, judging the quality of such an output answer is not easy\nbecause only considering the correctness of the answer is not enough and the\nsoundness of the reasoning trajectory part matters as well. Logically, if the\nsoundness of the reasoning part is poor, even if the answer is correct, the\nconfidence of the derived answer should be low. Existing methods did consider\njointly assessing the overall output answer by taking into account the\nreasoning part, however, their capability is still not satisfactory as the\ncausal relationship of the reasoning to the concluded answer cannot properly\nreflected. In this paper, inspired by classical mechanics, we present a novel\napproach towards establishing a CoT-Kinetics energy equation. Specifically, our\nCoT-Kinetics energy equation formulates the token state transformation process,\nwhich is regulated by LRM internal transformer layers, as like a particle\nkinetics dynamics governed in a mechanical field. Our CoT-Kinetics energy\nassigns a scalar score to evaluate specifically the soundness of the reasoning\nphase, telling how confident the derived answer could be given the evaluated\nreasoning. As such, the LRM's overall output quality can be accurately\nmeasured, rather than a coarse judgment (e.g., correct or incorrect) anymore.",
    "pdf_url": "http://arxiv.org/pdf/2505.13408v1",
    "published": "2025-05-19T17:44:26+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13407v1",
    "title": "Insufficient evidence for DMS and DMDS in the atmosphere of K2-18 b. From a joint analysis of JWST NIRISS, NIRSpec, and MIRI observations",
    "authors": [
      "R. Luque",
      "C. Piaulet-Ghorayeb",
      "M. Radica",
      "Q. Xue",
      "M. Zhang",
      "J. L. Bean",
      "D. Samra",
      "M. E. Steinrueck"
    ],
    "abstract": "Recent JWST observations of the temperate sub-Neptune K2-18 b have been\ninterpreted as suggestive of a liquid water ocean with possible biological\nactivity. Signatures of DMS and DMDS have been claimed in the near-infrared\n(using the NIRISS and NIRSpec instruments) and mid-infrared (using MIRI).\nHowever, the statistical significance of the atmospheric imprints of these\npotential biomarkers has yet to be quantified from a joint analysis of the\nentire planet spectrum. We test the robustness of the proposed DMS/DMDS\ndetections by simultaneously modeling the NIRISS and NIRSpec observations\njointly with the MIRI spectrum, considering different data reductions and\nmodeling choices. We use three well-tested pipelines to re-reduce the JWST\nobservations, and two retrieval codes to analyze the resulting transmission\nspectra as well as previously published data. Our joint analysis of the\npanchromatic (0.6 - 12 um) spectrum of K2-18 b finds insufficient evidence for\nthe presence of DMS and/or DMDS in the atmosphere of the planet. Furthermore,\nother molecules containing methyl functional groups (e.g., ethane) with\nabsorption bands similar to DMS/DMDS provide an equally good fit to the data.\nWe find that any marginal preferences are the result of limiting the number of\nmolecules considered in the model and oversensitivity to small changes between\ndata reductions. Our results confirm that there is no statistical significance\nfor DMS or DMDS in K2-18 b's atmosphere. While previous works have demonstrated\nthis on MIRI or NIRISS/NIRSpec observations alone, our analysis of the full\ntransmission spectrum does not support claims of potential biomarkers. Using\nthe best-fitting model including DMS/DMDS on the published data, we estimate\nthat ~25 more MIRI transits would be needed for a 3-sigma rejection of a flat\nline relative to DMS/DMDS features in the planet's mid-infrared transmission\nspectrum.",
    "pdf_url": "http://arxiv.org/pdf/2505.13407v1",
    "published": "2025-05-19T17:41:33+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13406v1",
    "title": "AutoMathKG: The automated mathematical knowledge graph based on LLM and vector database",
    "authors": [
      "Rong Bian",
      "Yu Geng",
      "Zijian Yang",
      "Bing Cheng"
    ],
    "abstract": "A mathematical knowledge graph (KG) presents knowledge within the field of\nmathematics in a structured manner. Constructing a math KG using natural\nlanguage is an essential but challenging task. There are two major limitations\nof existing works: first, they are constrained by corpus completeness, often\ndiscarding or manually supplementing incomplete knowledge; second, they\ntypically fail to fully automate the integration of diverse knowledge sources.\nThis paper proposes AutoMathKG, a high-quality, wide-coverage, and\nmulti-dimensional math KG capable of automatic updates. AutoMathKG regards\nmathematics as a vast directed graph composed of Definition, Theorem, and\nProblem entities, with their reference relationships as edges. It integrates\nknowledge from ProofWiki, textbooks, arXiv papers, and TheoremQA, enhancing\nentities and relationships with large language models (LLMs) via in-context\nlearning for data augmentation. To search for similar entities, MathVD, a\nvector database, is built through two designed embedding strategies using\nSBERT. To automatically update, two mechanisms are proposed. For knowledge\ncompletion mechanism, Math LLM is developed to interact with AutoMathKG,\nproviding missing proofs or solutions. For knowledge fusion mechanism, MathVD\nis used to retrieve similar entities, and LLM is used to determine whether to\nmerge with a candidate or add as a new entity. A wide range of experiments\ndemonstrate the advanced performance and broad applicability of the AutoMathKG\nsystem, including superior reachability query results in MathVD compared to\nfive baselines and robust mathematical reasoning capability in Math LLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.13406v1",
    "published": "2025-05-19T17:41:29+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13405v4",
    "title": "A Dataless Reinforcement Learning Approach to Rounding Hyperplane Optimization for Max-Cut",
    "authors": [
      "Gabriel Maliakal",
      "Ismail Alkhouri",
      "Alvaro Velasquez",
      "Adam M Alessio",
      "Saiprasad Ravishankar"
    ],
    "abstract": "The Maximum Cut (MaxCut) problem is NP-Complete, and obtaining its optimal\nsolution is NP-hard in the worst case. As a result, heuristic-based algorithms\nare commonly used, though their design often requires significant domain\nexpertise. More recently, learning-based methods trained on large (un)labeled\ndatasets have been proposed; however, these approaches often struggle with\ngeneralizability and scalability. A well-known approximation algorithm for\nMaxCut is the Goemans-Williamson (GW) algorithm, which relaxes the Quadratic\nUnconstrained Binary Optimization (QUBO) formulation into a semidefinite\nprogram (SDP). The GW algorithm then applies hyperplane rounding by uniformly\nsampling a random hyperplane to convert the SDP solution into binary node\nassignments. In this paper, we propose a training-data-free approach based on a\nnon-episodic reinforcement learning formulation, in which an agent learns to\nselect improved rounding hyperplanes that yield better cuts than those produced\nby the GW algorithm. By optimizing over a Markov Decision Process (MDP), our\nmethod consistently achieves better cuts across large-scale graphs with varying\ndensities and degree distributions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13405v4",
    "published": "2025-05-19T17:41:10+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13404v2",
    "title": "Granary: Speech Recognition and Translation Dataset in 25 European Languages",
    "authors": [
      "Nithin Rao Koluguri",
      "Monica Sekoyan",
      "George Zelenfroynd",
      "Sasha Meister",
      "Shuoyang Ding",
      "Sofia Kostandian",
      "He Huang",
      "Nikolay Karpov",
      "Jagadeesh Balam",
      "Vitaly Lavrukhin",
      "Yifan Peng",
      "Sara Papi",
      "Marco Gaido",
      "Alessio Brutti",
      "Boris Ginsburg"
    ],
    "abstract": "Multi-task and multilingual approaches benefit large models, yet speech\nprocessing for low-resource languages remains underexplored due to data\nscarcity. To address this, we present Granary, a large-scale collection of\nspeech datasets for recognition and translation across 25 European languages.\nThis is the first open-source effort at this scale for both transcription and\ntranslation. We enhance data quality using a pseudo-labeling pipeline with\nsegmentation, two-pass inference, hallucination filtering, and punctuation\nrestoration. We further generate translation pairs from pseudo-labeled\ntranscriptions using EuroLLM, followed by a data filtration pipeline. Designed\nfor efficiency, our pipeline processes vast amount of data within hours. We\nassess models trained on processed data by comparing their performance on\npreviously curated datasets for both high- and low-resource languages. Our\nfindings show that these models achieve similar performance using approx. 50%\nless data. Dataset will be made available at\nhttps://hf.co/datasets/nvidia/Granary",
    "pdf_url": "http://arxiv.org/pdf/2505.13404v2",
    "published": "2025-05-19T17:40:58+00:00",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15848v1",
    "title": "Sionna Research Kit: A GPU-Accelerated Research Platform for AI-RAN",
    "authors": [
      "Sebastian Cammerer",
      "Guillermo Marcus",
      "Tobias Zirr",
      "Fay√ßal A√Øt Aoudia",
      "Lorenzo Maggi",
      "Jakob Hoydis",
      "Alexander Keller"
    ],
    "abstract": "We introduce the NVIDIA Sionna Research Kit, a GPU-accelerated research\nplatform for developing and testing AI/ML algorithms in 5G NR cellular\nnetworks. Powered by the NVIDIA Jetson AGX Orin, the platform leverages\naccelerated computing to deliver high throughput and real-time signal\nprocessing, while offering the flexibility of a software-defined stack. Built\non OpenAirInterface (OAI), it unlocks a broad range of research opportunities.\nThese include developing 5G NR and ORAN compliant algorithms, collecting\nreal-world data for AI/ML training, and rapidly deploying innovative solutions\nin a very affordable testbed. Additionally, AI/ML hardware acceleration\npromotes the exploration of use cases in edge computing and AI radio access\nnetworks (AI-RAN). To demonstrate the capabilities, we deploy a real-time\nneural receiver - trained with NVIDIA Sionna and using the NVIDIA TensorRT\nlibrary for inference - in a 5G NR cellular network using commercial user\nequipment. The code examples will be made publicly available, enabling\nresearchers to adopt and extend the platform for their own projects.",
    "pdf_url": "http://arxiv.org/pdf/2505.15848v1",
    "published": "2025-05-19T17:38:05+00:00",
    "categories": [
      "cs.NI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13403v1",
    "title": "MR. Judge: Multimodal Reasoner as a Judge",
    "authors": [
      "Renjie Pi",
      "Felix Bai",
      "Qibin Chen",
      "Simon Wang",
      "Jiulong Shan",
      "Kieran Liu",
      "Meng Cao"
    ],
    "abstract": "The paradigm of using Large Language Models (LLMs) and Multimodal Large\nLanguage Models (MLLMs) as evaluative judges has emerged as an effective\napproach in RLHF and inference-time scaling. In this work, we propose\nMultimodal Reasoner as a Judge (MR. Judge), a paradigm for empowering\ngeneral-purpose MLLMs judges with strong reasoning capabilities. Instead of\ndirectly assigning scores for each response, we formulate the judgement process\nas a reasoning-inspired multiple-choice problem. Specifically, the judge model\nfirst conducts deliberate reasoning covering different aspects of the responses\nand eventually selects the best response from them. This reasoning process not\nonly improves the interpretibility of the judgement, but also greatly enhances\nthe performance of MLLM judges. To cope with the lack of questions with scored\nresponses, we propose the following strategy to achieve automatic annotation:\n1) Reverse Response Candidates Synthesis: starting from a supervised\nfine-tuning (SFT) dataset, we treat the original response as the best candidate\nand prompt the MLLM to generate plausible but flawed negative candidates. 2)\nText-based reasoning extraction: we carefully design a data synthesis pipeline\nfor distilling the reasoning capability from a text-based reasoning model,\nwhich is adopted to enable the MLLM judges to regain complex reasoning ability\nvia warm up supervised fine-tuning. Experiments demonstrate that our MR. Judge\nis effective across a wide range of tasks. Specifically, our MR. Judge-7B\nsurpasses GPT-4o by 9.9% on VL-RewardBench, and improves performance on MM-Vet\nduring inference-time scaling by up to 7.7%.",
    "pdf_url": "http://arxiv.org/pdf/2505.13403v1",
    "published": "2025-05-19T17:37:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13402v1",
    "title": "HydroX, a light dark matter search with hydrogen-doped liquid xenon time projection chambers",
    "authors": [
      "W. H. Lippincott",
      "H. N. Nelson",
      "D. S. Akerib",
      "C. Amarasinghe",
      "A. Ames",
      "H. M. Araujo",
      "J. W. Bargemann",
      "M. C. Carmona-Benitez",
      "R. Coronel",
      "C. E. Dahl",
      "S. Dey",
      "J. Genovesi",
      "S. J. Haselschwardt",
      "E. Jacquet",
      "D. Khaitan",
      "D. Kodroff",
      "S. Kravitz",
      "W. Lorenzon",
      "S. Luitz",
      "A. Manalaysay",
      "C. Maupin",
      "M. E. Monzani",
      "K. C. Oliver-Mallory",
      "E. Perry",
      "Y. Qie",
      "T. Shutt",
      "D. J. Temples",
      "M. Trask",
      "A. Wang",
      "F. L. H. Wolfs",
      "D. Woodward",
      "R. Zhang",
      "T. Zhang"
    ],
    "abstract": "Experimental efforts searching for dark matter particles over the last few\ndecades have ruled out many candidates led by the new generation of tonne-scale\nliquid xenon. For light dark matter, hydrogen could be a better target than\nxenon as it would offer a better kinematic match to the low mass particles.\nThis article describes the HydroX concept, an idea to expand the dark matter\nsensitivity reach of large liquid xenon detectors by adding hydrogen to the\nliquid xenon. We discuss the nature of signal generation in liquid xenon to\nargue that the signal produced at the interaction site by a dark\nmatter-hydrogen interaction could be significantly enhanced over the same\ninteraction on xenon, increasing the sensitivity to the lightest particles. We\ndiscuss the technical implications of adding hydrogen to a xenon detector, as\nwell as some background considerations. Finally, we make projections as to the\npotential sensitivity of a HydroX implementation and discuss next steps.",
    "pdf_url": "http://arxiv.org/pdf/2505.13402v1",
    "published": "2025-05-19T17:36:59+00:00",
    "categories": [
      "hep-ex",
      "physics.ins-det"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.13401v3",
    "title": "Unraveling superradiance: Entanglement and mutual information in collective decay",
    "authors": [
      "Xin H. H. Zhang",
      "Daniel Malz",
      "Peter Rabl"
    ],
    "abstract": "We study the collective decay of an initially inverted ensemble of two-level\nemitters in two distinct scenarios: when coupled to a squeezed photonic\nreservoir and when interacting with a one-dimensional waveguide. Using a\nquantum-state diffusion approach to unravel the emission process, we\ninvestigate entanglement and classical correlations along individual quantum\ntrajectories over time. This numerical analysis shows that despite an initial\nbuild-up of entanglement and a significant amount of entanglement due to either\nspin squeezing or dark states at late times, the essential features of the\nsuperradiant burst are well described by averages over fully factorizable\nstates. We explain this observation in terms of an almost complete\nfactorization of all 2-local observables, which we identify as a generic\nproperty of superradiant decay. Based on this insight, we provide a purely\nclassical theory for the burst in squeezed superradiance, which is both\nintuitive and exact for a large number of emitters. Moreover, we find that our\nnumerical approach also performs well in the presence of subradiant states,\nwhich dominate the slow residual decay of non-uniform ensembles at late times.",
    "pdf_url": "http://arxiv.org/pdf/2505.13401v3",
    "published": "2025-05-19T17:36:37+00:00",
    "categories": [
      "quant-ph",
      "physics.atom-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.18191v1",
    "title": "SzCORE as a benchmark: report from the seizure detection challenge at the 2025 AI in Epilepsy and Neurological Disorders Conference",
    "authors": [
      "Jonathan Dan",
      "Amirhossein Shahbazinia",
      "Christodoulos Kechris",
      "David Atienza"
    ],
    "abstract": "Reliable automatic seizure detection from long-term EEG remains a challenge,\nas current machine learning models often fail to generalize across patients or\nclinical settings. Manual EEG review remains the clinical standard,\nunderscoring the need for robust models and standardized evaluation. To\nrigorously assess algorithm performance, we organized a challenge using a\nprivate dataset of continuous EEG recordings from 65 subjects (4,360 hours).\nExpert neurophysiologists annotated the data, providing ground truth for\nseizure events. Participants were required to detect seizure onset and\nduration, with evaluation based on event-based metrics, including sensitivity,\nprecision, F1-score, and false positives per day. The SzCORE framework ensured\nstandardized evaluation. The primary ranking criterion was the event-based\nF1-score, reflecting clinical relevance by balancing sensitivity and false\npositives. The challenge received 30 submissions from 19 teams, with 28\nalgorithms evaluated. Results revealed wide variability in performance, with a\ntop F1-score of 43% (sensitivity 37%, precision 45%), highlighting the ongoing\ndifficulty of seizure detection. The challenge also revealed a gap between\nreported performance and real-world evaluation, emphasizing the importance of\nrigorous benchmarking. Compared to previous challenges and commercial systems,\nthe best-performing algorithm in this contest showed improved performance.\nImportantly, the challenge platform now supports continuous benchmarking,\nenabling reproducible research, integration of new datasets, and clinical\nevaluation of seizure detection algorithms using a standardized framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.18191v1",
    "published": "2025-05-19T17:36:20+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13400v1",
    "title": "Robin: A multi-agent system for automating scientific discovery",
    "authors": [
      "Ali Essam Ghareeb",
      "Benjamin Chang",
      "Ludovico Mitchener",
      "Angela Yiu",
      "Caralyn J. Szostkiewicz",
      "Jon M. Laurent",
      "Muhammed T. Razzak",
      "Andrew D. White",
      "Michaela M. Hinks",
      "Samuel G. Rodriques"
    ],
    "abstract": "Scientific discovery is driven by the iterative process of background\nresearch, hypothesis generation, experimentation, and data analysis. Despite\nrecent advancements in applying artificial intelligence to scientific\ndiscovery, no system has yet automated all of these stages in a single\nworkflow. Here, we introduce Robin, the first multi-agent system capable of\nfully automating the key intellectual steps of the scientific process. By\nintegrating literature search agents with data analysis agents, Robin can\ngenerate hypotheses, propose experiments, interpret experimental results, and\ngenerate updated hypotheses, achieving a semi-autonomous approach to scientific\ndiscovery. By applying this system, we were able to identify a novel treatment\nfor dry age-related macular degeneration (dAMD), the major cause of blindness\nin the developed world. Robin proposed enhancing retinal pigment epithelium\nphagocytosis as a therapeutic strategy, and identified and validated a\npromising therapeutic candidate, ripasudil. Ripasudil is a clinically-used rho\nkinase (ROCK) inhibitor that has never previously been proposed for treating\ndAMD. To elucidate the mechanism of ripasudil-induced upregulation of\nphagocytosis, Robin then proposed and analyzed a follow-up RNA-seq experiment,\nwhich revealed upregulation of ABCA1, a critical lipid efflux pump and possible\nnovel target. All hypotheses, experimental plans, data analyses, and data\nfigures in the main text of this report were produced by Robin. As the first AI\nsystem to autonomously discover and validate a novel therapeutic candidate\nwithin an iterative lab-in-the-loop framework, Robin establishes a new paradigm\nfor AI-driven scientific discovery.",
    "pdf_url": "http://arxiv.org/pdf/2505.13400v1",
    "published": "2025-05-19T17:36:17+00:00",
    "categories": [
      "cs.AI",
      "cs.MA",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13399v1",
    "title": "Filtering out large-scale noise for cluster weak-lensing mass estimation",
    "authors": [
      "C. Murray",
      "C. Combet",
      "C. Payerne",
      "M. Ricci"
    ],
    "abstract": "We present a new method for estimating galaxy cluster masses using\nweak-lensing magnification. The effect of weak-lensing magnification introduces\na correlation between the position of foreground galaxy clusters and the\ndensity of background sources. Therefore, cluster masses can be inferred\nthrough observations of these correlations. In this work, we introduce a method\nthat allows us to considerably reduce noise correlations between different\nradial bins of the cluster magnification signal via a Wiener filtering of our\nobserved magnification field on large scales. This method can reduce the\nuncertainty on the estimated galaxy cluster mass and it can also be applied to\ncluster mass estimation for weak-lensing shear. The method was applied to\nHyper-Suprime Cam galaxies and CAMIRA clusters detected within the\nHyper-Suprime Cam survey (HSC). With HSC data, we find that our filtering\nmethod significantly reduces the correlation of noise between radial\nmagnification bins. The estimated cluster mass is consistent between the\nfiltered and unfiltered methods, with similar errors between the two methods as\nour current measurement errors contain significant contributions from the\nirreducible shot-noise. For deeper surveys, the effects of shot noise will be\nless important and this method will lead to greater improvements on the\nestimated cluster mass.",
    "pdf_url": "http://arxiv.org/pdf/2505.13399v1",
    "published": "2025-05-19T17:36:01+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13398v2",
    "title": "A Minimum Description Length Approach to Regularization in Neural Networks",
    "authors": [
      "Matan Abudy",
      "Orr Well",
      "Emmanuel Chemla",
      "Roni Katzir",
      "Nur Lan"
    ],
    "abstract": "State-of-the-art neural networks can be trained to become remarkable\nsolutions to many problems. But while these architectures can express symbolic,\nperfect solutions, trained models often arrive at approximations instead. We\nshow that the choice of regularization method plays a crucial role: when\ntrained on formal languages with standard regularization ($L_1$, $L_2$, or\nnone), expressive architectures not only fail to converge to correct solutions\nbut are actively pushed away from perfect initializations. In contrast,\napplying the Minimum Description Length (MDL) principle to balance model\ncomplexity with data fit provides a theoretically grounded regularization\nmethod. Using MDL, perfect solutions are selected over approximations,\nindependently of the optimization algorithm. We propose that unlike existing\nregularization techniques, MDL introduces the appropriate inductive bias to\neffectively counteract overfitting and promote generalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.13398v2",
    "published": "2025-05-19T17:34:56+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13397v1",
    "title": "Learning by solving differential equations",
    "authors": [
      "Benoit Dherin",
      "Michael Munn",
      "Hanna Mazzawi",
      "Michael Wunder",
      "Sourabh Medapati",
      "Javier Gonzalvo"
    ],
    "abstract": "Modern deep learning algorithms use variations of gradient descent as their\nmain learning methods. Gradient descent can be understood as the simplest\nOrdinary Differential Equation (ODE) solver; namely, the Euler method applied\nto the gradient flow differential equation. Since Euler, many ODE solvers have\nbeen devised that follow the gradient flow equation more precisely and more\nstably. Runge-Kutta (RK) methods provide a family of very powerful explicit and\nimplicit high-order ODE solvers. However, these higher-order solvers have not\nfound wide application in deep learning so far. In this work, we evaluate the\nperformance of higher-order RK solvers when applied in deep learning, study\ntheir limitations, and propose ways to overcome these drawbacks. In particular,\nwe explore how to improve their performance by naturally incorporating key\ningredients of modern neural network optimizers such as preconditioning,\nadaptive learning rates, and momentum.",
    "pdf_url": "http://arxiv.org/pdf/2505.13397v1",
    "published": "2025-05-19T17:34:32+00:00",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13396v1",
    "title": "On expectations and variances in the hard-core model on bounded degree graphs",
    "authors": [
      "Ewan Davies",
      "Juspreet Singh Sandhu",
      "Brian Tan"
    ],
    "abstract": "We extend the study of the occupancy fraction of the hard-core model in two\nnovel directions. One direction gives a tight lower bound in terms of\nindividual vertex degrees, extending work of Sah, Sawhney, Stoner and Zhao\nwhich bounds the partition function. The other bounds the variance of the size\nof an independent set drawn from the model, which is strictly stronger than\nbounding the occupancy fraction.\n  In the setting of triangle-free graphs, we make progress on a recent\nconjecture of Buys, van den Heuvel and Kang on extensions of Shearer's classic\nbounds on the independence number to the occupancy fraction of the hard-core\nmodel.\n  Sufficiently strong lower bounds on both the expectation and the variance in\ntriangle-free graphs have the potential to improve the known bounds on the\noff-diagonal Ramsey number $R(3,t)$, and to shed light on the algorithmic\nbarrier one observes for independent sets in sparse random graphs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13396v1",
    "published": "2025-05-19T17:34:23+00:00",
    "categories": [
      "math.CO",
      "cs.DM"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13395v1",
    "title": "Building Next-to-Next Leading Logarithmic parton showers: the PanScales recipe",
    "authors": [
      "Silvia Ferrario Ravasio"
    ],
    "abstract": "Parton showers lie at the core of Shower Monte Carlo event generators, the\ndefault theoretical tools used to interpret collider data. In these\nproceedings, we summarise the strategy of the PanScales collaboration that led\nto the attainment of the first demonstrably next-to-next-to-leading-logarithmic\naccurate parton showers.",
    "pdf_url": "http://arxiv.org/pdf/2505.13395v1",
    "published": "2025-05-19T17:33:55+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13394v2",
    "title": "Multireference Embedding and Fragmentation Methods for Classical and Quantum Computers: from Model Systems to Realistic Applications",
    "authors": [
      "Shreya Verma",
      "Abhishek Mitra",
      "Qiaohong Wang",
      "Ruhee D'Cunha",
      "Bhavnesh Jangid",
      "Matthew R. Hennefarth",
      "Valay Agarawal",
      "Leon Otis",
      "Soumi Haldar",
      "Matthew R. Hermes",
      "Laura Gagliardi"
    ],
    "abstract": "One of the primary challenges in quantum chemistry is the accurate modeling\nof strong electron correlation. While multireference methods effectively\ncapture such correlation, their steep scaling with system size prohibits their\napplication to large molecules and extended materials. Quantum embedding offers\na promising solution by partitioning complex systems into manageable\nsubsystems. In this review, we highlight recent advances in multireference\ndensity matrix embedding and localized active space self-consistent field\napproaches for complex molecules and extended materials. We discuss both\nclassical implementations and the emerging potential of these methods on\nquantum computers. By extending classical embedding concepts to the quantum\nlandscape, these algorithms have the potential to expand the reach of\nmultireference methods in quantum chemistry and materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.13394v2",
    "published": "2025-05-19T17:33:53+00:00",
    "categories": [
      "physics.chem-ph",
      "quant-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13393v2",
    "title": "IG Parser: A Software Package for the Encoding of Institutional Statements using the Institutional Grammar",
    "authors": [
      "Christopher K. Frantz"
    ],
    "abstract": "This article provides an overview of IG Parser, a software that facilitates\nqualitative content analysis of formal (e.g., legal) rules or informal (e.g.,\nsocial) norms, and strategies (such as conventions) -- referred to as\ninstitutions -- that govern social systems and operate configurally to describe\ninstitutional systems. To this end, the IG Parser employs a distinctive syntax\nthat ensures rigorous encoding of natural language, while automating the\ntransformation into various formats that support the downstream analysis using\ndiverse analytical techniques. The conceptual core of the IG Parser is an\nassociated syntax, IG Script, that operationalizes the conceptual foundations\nof the Institutional Grammar, and more specifically the Institutional Grammar\n2.0, an analytical paradigm for institutional analysis. This article presents\nthe IG Parser, including its conceptual foundations, the syntax specification\nof IG Script, and its architectural principles. This overview is augmented with\nselective illustrative examples that highlight its use and the associated\nbenefits.",
    "pdf_url": "http://arxiv.org/pdf/2505.13393v2",
    "published": "2025-05-19T17:33:15+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "68T30, 68T50",
      "E.2; H.1.0; I.7.2; I.6.5; K.4.1"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13392v1",
    "title": "Beyond-Diagonal RIS Prototype and Performance Evaluation",
    "authors": [
      "Jean Tapie",
      "Matteo Nerini",
      "Bruno Clerckx",
      "Philipp del Hougne"
    ],
    "abstract": "We present the first experimental prototype of a reflective beyond-diagonal\nreconfigurable intelligent surface (BD-RIS), i.e., a RIS with reconfigurable\ninter-element connections. Our BD-RIS consists of an antenna array whose ports\nare terminated by a tunable load network. The latter can terminate each antenna\nport with three distinct individual loads or connect it to an adjacent antenna\nport. Extensive performance evaluations in a rich-scattering environment\nvalidate that inter-element connections are beneficial. Moreover, we observe\nthat our tunable load network's mentioned hardware constraints significantly\ninfluence, first, the achievable performance, second, the benefits of having\ninter-element connections, and, third, the importance of mutual-coupling\nawareness during optimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.13392v1",
    "published": "2025-05-19T17:32:48+00:00",
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT",
      "physics.app-ph"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13391v1",
    "title": "Advancing Generalization Across a Variety of Abstract Visual Reasoning Tasks",
    "authors": [
      "Miko≈Çaj Ma≈Çki≈Ñski",
      "Jacek Ma≈Ñdziuk"
    ],
    "abstract": "The abstract visual reasoning (AVR) domain presents a diverse suite of\nanalogy-based tasks devoted to studying model generalization. Recent years have\nbrought dynamic progress in the field, particularly in i.i.d. scenarios, in\nwhich models are trained and evaluated on the same data distributions.\nNevertheless, o.o.d. setups that assess model generalization to new test\ndistributions remain challenging even for the most recent models. To advance\ngeneralization in AVR tasks, we present the Pathways of Normalized Group\nConvolution model (PoNG), a novel neural architecture that features group\nconvolution, normalization, and a parallel design. We consider a wide set of\nAVR benchmarks, including Raven's Progressive Matrices and visual analogy\nproblems with both synthetic and real-world images. The experiments demonstrate\nstrong generalization capabilities of the proposed model, which in several\nsettings outperforms the existing literature methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13391v1",
    "published": "2025-05-19T17:32:07+00:00",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13390v1",
    "title": "MGPBD: A Multigrid Accelerated Global XPBD Solver",
    "authors": [
      "Chunlei Li",
      "Peng Yu",
      "Tiantian Liu",
      "Siyuan Yu",
      "Yuting Xiao",
      "Shuai Li",
      "Aimin Hao",
      "Yang Gao",
      "Qinping Zhao"
    ],
    "abstract": "We introduce a novel Unsmoothed Aggregation (UA) Algebraic Multigrid (AMG)\nmethod combined with Preconditioned Conjugate Gradient (PCG) to overcome the\nlimitations of Extended Position-Based Dynamics (XPBD) in high-resolution and\nhigh-stiffness simulations. While XPBD excels in simulating deformable objects\ndue to its speed and simplicity, its nonlinear Gauss-Seidel (GS) solver often\nstruggles with low-frequency errors, leading to instability and stalling\nissues, especially in high-resolution, high-stiffness simulations. Our\nmultigrid approach addresses these issues efficiently by leveraging AMG. To\nreduce the computational overhead of traditional AMG, where prolongator\nconstruction can consume up to two-thirds of the runtime, we propose a lazy\nsetup strategy that reuses prolongators across iterations based on matrix\nstructure and physical significance. Furthermore, we introduce a simplified\nmethod for constructing near-kernel components by applying a few sweeps of\niterative methods to the homogeneous equation, achieving convergence rates\ncomparable to adaptive smoothed aggregation (adaptive-SA) at a lower\ncomputational cost. Experimental results demonstrate that our method\nsignificantly improves convergence rates and numerical stability, enabling\nefficient and stable high-resolution simulations of deformable objects.",
    "pdf_url": "http://arxiv.org/pdf/2505.13390v1",
    "published": "2025-05-19T17:31:47+00:00",
    "categories": [
      "cs.GR",
      "I.3.6"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13389v4",
    "title": "VSA: Faster Video Diffusion with Trainable Sparse Attention",
    "authors": [
      "Peiyuan Zhang",
      "Yongqi Chen",
      "Haofeng Huang",
      "Will Lin",
      "Zhengzhong Liu",
      "Ion Stoica",
      "Eric Xing",
      "Hao Zhang"
    ],
    "abstract": "Scaling video diffusion transformers (DiTs) is limited by their quadratic 3D\nattention, even though most of the attention mass concentrates on a small\nsubset of positions. We turn this observation into VSA, a trainable,\nhardware-efficient sparse attention that replaces full attention at \\emph{both}\ntraining and inference. In VSA, a lightweight coarse stage pools tokens into\ntiles and identifies high-weight \\emph{critical tokens}; a fine stage computes\ntoken-level attention only inside those tiles subjecting to block computing\nlayout to ensure hard efficiency. This leads to a single differentiable kernel\nthat trains end-to-end, requires no post-hoc profiling, and sustains 85\\% of\nFlashAttention3 MFU. We perform a large sweep of ablation studies and\nscaling-law experiments by pretraining DiTs from 60M to 1.4B parameters. VSA\nreaches a Pareto point that cuts training FLOPS by 2.53$\\times$ with no drop in\ndiffusion loss. Retrofitting the open-source Wan-2.1 model speeds up attention\ntime by 6$\\times$ and lowers end-to-end generation time from 31s to 18s with\ncomparable quality. These results establish trainable sparse attention as a\npractical alternative to full attention and a key enabler for further scaling\nof video diffusion models. Code will be available at\nhttps://github.com/hao-ai-lab/FastVideo.",
    "pdf_url": "http://arxiv.org/pdf/2505.13389v4",
    "published": "2025-05-19T17:30:13+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13388v2",
    "title": "R3: Robust Rubric-Agnostic Reward Models",
    "authors": [
      "David Anugraha",
      "Zilu Tang",
      "Lester James V. Miranda",
      "Hanyang Zhao",
      "Mohammad Rifqi Farhansyah",
      "Garry Kuwanto",
      "Derry Wijaya",
      "Genta Indra Winata"
    ],
    "abstract": "Reward models are essential for aligning language model outputs with human\npreferences, yet existing approaches often lack both controllability and\ninterpretability. These models are typically optimized for narrow objectives,\nlimiting their generalizability to broader downstream tasks. Moreover, their\nscalar outputs are difficult to interpret without contextual reasoning. To\naddress these limitations, we introduce R3, a novel reward modeling framework\nthat is rubric-agnostic, generalizable across evaluation dimensions, and\nprovides interpretable, reasoned score assignments. R3 enables more transparent\nand flexible evaluation of language models, supporting robust alignment with\ndiverse human values and use cases. Our models, data, and code are available as\nopen source at https://github.com/rubricreward/r3",
    "pdf_url": "http://arxiv.org/pdf/2505.13388v2",
    "published": "2025-05-19T17:29:03+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13387v2",
    "title": "Constraining Reheating Temperature, Inflaton-SM Coupling and Dark Matter Mass in Light of ACT DR6 Observations",
    "authors": [
      "Rajesh Mondal",
      "Sourav Mondal",
      "Ayan Chakraborty"
    ],
    "abstract": "We explore the phenomenological implications of the latest Atacama Cosmology\nTelescope (ACT) DR6 observations, in combination with Planck 2018, BICEP/Keck\n2018, and DESI, on the physics of inflation and post-inflationary reheating. We\nfocus on the $\\alpha$-attractor class of inflationary models (both E- and\nT-models) and consider two reheating scenarios: perturbative inflaton ($\\phi$)\ndecay ($\\phi \\rightarrow bb$) and inflaton annihilation ($\\phi \\phi \\rightarrow\nbb$) into Standard Model (SM) bosonic particles ($b$). By solving the Boltzmann\nequations, we derive bounds on key reheating parameters, including the\nreheating temperature, the inflaton equation of state (EoS), and the\ninflaton-SM coupling, in light of ACT data. To accurately constrain the\ncoupling, we incorporate the Bose enhancement effect in the decay width. To\nensure the validity of our perturbative approach, we also identify the regime\nwhere nonperturbative effects, such as parametric resonance, become\nsignificant. Additionally, we include indirect constraints from primordial\ngravitational waves (PGWs), which can impact the effective number of\nrelativistic species, $\\Delta N_{\\rm eff}$. These constraints further bound the\nreheating temperature, particularly in scenarios with a stiff EoS. Finally, we\nanalyze dark matter (DM) production through purely gravitational interactions\nduring reheating and determine the allowed mass ranges consistent with the\nconstrained reheating parameter space and recent ACT data.",
    "pdf_url": "http://arxiv.org/pdf/2505.13387v2",
    "published": "2025-05-19T17:28:52+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13386v1",
    "title": "Proton heating estimates from near-Earth observations of coronal mass ejections in solar cycle 24",
    "authors": [
      "Debesh Bhattacharjee",
      "Prasad Subramanian",
      "Saikat majumder",
      "Wageesh Mishra"
    ],
    "abstract": "As solar coronal mass ejections (CMEs) propagate through the heliosphere,\nthey expend energy in heating protons to compensate for the cooling that occurs\ndue to expansion. CME propagation models usually treat energy dissipation\nimplicitly via a polytropic index ($\\delta$). Here we calculate the power\ndissipation implied by a given $\\delta$ and compare it with the power available\nin the turbulent velocity fluctuations. We make this comparison using\nnear-Earth {\\em in-situ} observations of 27 of the most geoeffective CMEs\n($D_{\\rm st} < -75$ nT) in solar cycle 24. For $\\delta = 5/3$, the power in the\nturbulent velocity fluctuations is $\\approx 54$\\% smaller than what would be\nrequired to maintain the proton temperature at the observed values. If the\npower in the turbulent cascade is assumed to be fully expended in local proton\nheating, the most probable value for $\\delta$ is 1.35. Our results contribute\nto a better understanding of CME energetics, and thereby to improved CME\npropagation models and estimates of Earth arrival times.",
    "pdf_url": "http://arxiv.org/pdf/2505.13386v1",
    "published": "2025-05-19T17:28:27+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13385v1",
    "title": "Scaling laws for softened hadron production at LHC energies",
    "authors": [
      "D. Rosales Herrera",
      "J. R. Alvarado Garc√≠a",
      "A. Fern√°ndez T√©llez",
      "E. Cuautle",
      "J. E. Ram√≠rez"
    ],
    "abstract": "In this paper, we conduct a data-driven study of the production of softened\nhadrons and their contribution to the transverse momentum spectrum. To this\nend, we assume that the production of charged particles at soft and hard scales\nfundamentally results from the fragmentation of color strings. We analyze the\n$p_\\text{T}$-spectrum data from pp to AA collisions at LHC energies reported by\nthe ALICE Collaboration, finding that, in all cases, the data can be collapsed\ninto a $p_\\text{T}$-exponential trend in the range 1 GeV$<p_\\text{T}<$6 GeV.\nWith this insight, the description of the $p_\\text{T}$-spectrum should contain\ninformation on the charged particle production coming from two different\nsources: fragmentation of color strings and collective phenomena that\nredistribute the transverse momentum and enhance the production of particles at\nintermediate $p_\\text{T}$. We also found different relations between the\neffective temperature, multiplicity, and average $p_\\text{T}$ for pp and AA\ncollisions, indicating inherent dissimilarities between small and large\ncolliding systems. In contrast, the contribution of the softened hadrons to the\n$p_\\text{T}$-spectrum and average $p_\\text{T}$ collapse onto scaling laws. Our\nresults show that the physical mechanisms producing softened hadrons have\nsimilar origins for all colliding systems, revealing a stronger dependence on\nfreeze-out parameters rather than the system size.",
    "pdf_url": "http://arxiv.org/pdf/2505.13385v1",
    "published": "2025-05-19T17:28:09+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13384v1",
    "title": "An Empirical Bayes approach to ARX Estimation",
    "authors": [
      "Timofei Leahu",
      "Giorgio Picci"
    ],
    "abstract": "Empirical Bayes inference is based on estimation of the parameters of an a\npriori distribution from the observed data. The estimation technique of the\nparameters of the prior, called hyperparameters, is based on the marginal\ndistribution obtained by integrating the joint density of the model with\nrespect to the prior. This is a key step which needs to be properly adapted to\nthe problem at hand. In this paper we study Empirical Bayes inference of linear\nautoregressive models with inputs (ARX models) for time series and compare the\nperformance of the marginal parametric estimator with that a full Empirical\nBayesian analysis based on the estimated prior. Such a comparison, can only\nmake sense for a (realistic) finite data length. In this setting, we propose a\nnew estimation technique of the hyperparameters by a sequential Bayes procedure\nwhich is essentially a backward Kalman filter. It turns out that for finite\ndata length the marginal Bayes tends to behave slightly better than the full\nEmpirical Bayesian parameter estimator and so also in the case of slowly\nvarying random parameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.13384v1",
    "published": "2025-05-19T17:28:03+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13383v1",
    "title": "Inverse-Designed Silicon Nitride Nanophotonics",
    "authors": [
      "Toby Bi",
      "Shuangyou Zhang",
      "Egemen Bostan",
      "Danxian Liu",
      "Aditya Paul",
      "Olga Ohletz",
      "Irina Harder",
      "Yaojing Zhang",
      "Alekhya Ghosh",
      "Abdullah Alabbadi",
      "Masoud Kheyri",
      "Tianyi Zeng",
      "Jesse Lu",
      "Kiyoul Yang",
      "Pascal Del'Haye"
    ],
    "abstract": "Silicon nitride photonics has enabled integration of a variety of components\nfor applications in linear and nonlinear optics, including telecommunications,\noptical clocks, astrocombs, bio-sensing, and LiDAR. With the advent of inverse\ndesign - where desired device performance is specified and closely achieved\nthrough iterative, gradient-based optimization - and the increasing\navailability of silicon nitride photonics via foundries, it is now feasible to\nexpand the photonic design library beyond the limits of traditional approaches\nand unlock new functionalities. In this work, we present inverse-designed\nphotonics on a silicon nitride platform and demonstrate both the design\ncapabilities and experimental validation of manipulating light in wavelength\nand spatial mode dimensions to high-Q resonators with controllable wavelength\nrange and dispersion. Furthermore, we use these inverse-designed structures to\nform optical cavities that hold promise for on-chip nonlinear and quantum\noptics experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.13383v1",
    "published": "2025-05-19T17:26:32+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.13382v1",
    "title": "The localization transition for the directed polymer in a random environment is smooth",
    "authors": [
      "Hubert Lacoin"
    ],
    "abstract": "When $d\\ge 3$, the directed polymer a in random environment on $\\mathbb Z^d$\nis known to display a phase transition from a diffusive phase, known as\n\\textit{weak disorder} to a localized phase, referred to as \\textit{strong\ndisorder}. This transition is encoded by the behavior of the the free energy of\nthe model, defined by $$\\mathfrak f(\\beta):=\\lim_{N\\to \\infty} (1/n)\\log\nW^{\\beta}_n$$ where $W^{\\beta}_n$ is the normalized partition function for the\ndirected polymer of length $n$. More precisely weak disorder corresponds to\n$\\mathfrak f(\\beta)=0$ and strong disorder to $\\mathfrak f(\\beta)<0$.\nMonotonicity and continuity of $\\mathfrak f$ implies that there exists\n$\\beta_c\\in [0,\\infty]$ such that weak disorder is equivalent to $\\beta\\in\n[0,\\beta_c]$. Furthermore $\\beta_c>0$ if and only if $d\\ge 3$. We prove that\nthis transition is infinitely smooth in the sense that $\\mathfrak f$ grows\nslower than any power function at the vicinity of $\\beta_c$, that is $$\n\\lim_{\\beta \\downarrow \\beta_c }\\frac{\\log |\\mathfrak f(\\beta)|}{\\log\n(\\beta-\\beta_c)}=\\infty.$$",
    "pdf_url": "http://arxiv.org/pdf/2505.13382v1",
    "published": "2025-05-19T17:25:15+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13381v1",
    "title": "How Adding Metacognitive Requirements in Support of AI Feedback in Practice Exams Transforms Student Learning Behaviors",
    "authors": [
      "Mak Ahmad",
      "Prerna Ravi",
      "David Karger",
      "Marc Facciotti"
    ],
    "abstract": "Providing personalized, detailed feedback at scale in large undergraduate\nSTEM courses remains a persistent challenge. We present an empirically\nevaluated practice exam system that integrates AI generated feedback with\ntargeted textbook references, deployed in a large introductory biology course.\nOur system encourages metacognitive behavior by asking students to explain\ntheir answers and declare their confidence. It uses OpenAI's GPT-4o to generate\npersonalized feedback based on this information, while directing them to\nrelevant textbook sections. Through interaction logs from consenting\nparticipants across three midterms (541, 342, and 413 students respectively),\ntotaling 28,313 question-student interactions across 146 learning objectives,\nalong with 279 surveys and 23 interviews, we examined the system's impact on\nlearning outcomes and engagement. Across all midterms, feedback types showed no\nstatistically significant performance differences, though some trends suggested\npotential benefits. The most substantial impact came from the required\nconfidence ratings and explanations, which students reported transferring to\ntheir actual exam strategies. About 40 percent of students engaged with\ntextbook references when prompted by feedback -- far higher than traditional\nreading rates. Survey data revealed high satisfaction (mean rating 4.1 of 5),\nwith 82.1 percent reporting increased confidence on practiced midterm topics,\nand 73.4 percent indicating they could recall and apply specific concepts. Our\nfindings suggest that embedding structured reflection requirements may be more\nimpactful than sophisticated feedback mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.13381v1",
    "published": "2025-05-19T17:25:07+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "K.3.1; I.2.7; H.5.2"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13380v1",
    "title": "CompeteSMoE -- Statistically Guaranteed Mixture of Experts Training via Competition",
    "authors": [
      "Nam V. Nguyen",
      "Huy Nguyen",
      "Quang Pham",
      "Van Nguyen",
      "Savitha Ramasamy",
      "Nhat Ho"
    ],
    "abstract": "Sparse mixture of experts (SMoE) offers an appealing solution to scale up the\nmodel complexity beyond the mean of increasing the network's depth or width.\nHowever, we argue that effective SMoE training remains challenging because of\nthe suboptimal routing process where experts that perform computation do not\ndirectly contribute to the routing process. In this work, we propose\ncompetition, a novel mechanism to route tokens to experts with the highest\nneural response. Theoretically, we show that the competition mechanism enjoys a\nbetter sample efficiency than the traditional softmax routing. Furthermore, we\ndevelop CompeteSMoE, a simple yet effective algorithm to train large language\nmodels by deploying a router to learn the competition policy, thus enjoying\nstrong performances at a low training overhead. Our extensive empirical\nevaluations on both the visual instruction tuning and language pre-training\ntasks demonstrate the efficacy, robustness, and scalability of CompeteSMoE\ncompared to state-of-the-art SMoE strategies. We have made the implementation\navailable at: https://github.com/Fsoft-AIC/CompeteSMoE. This work is an\nimproved version of the previous study at arXiv:2402.02526",
    "pdf_url": "http://arxiv.org/pdf/2505.13380v1",
    "published": "2025-05-19T17:24:26+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13379v2",
    "title": "Thinkless: LLM Learns When to Think",
    "authors": [
      "Gongfan Fang",
      "Xinyin Ma",
      "Xinchao Wang"
    ],
    "abstract": "Reasoning Language Models, capable of extended chain-of-thought reasoning,\nhave demonstrated remarkable performance on tasks requiring complex logical\ninference. However, applying elaborate reasoning for all queries often results\nin substantial computational inefficiencies, particularly when many problems\nadmit straightforward solutions. This motivates an open question: Can LLMs\nlearn when to think? To answer this, we propose Thinkless, a learnable\nframework that empowers an LLM to adaptively select between short-form and\nlong-form reasoning, based on both task complexity and the model's ability.\nThinkless is trained under a reinforcement learning paradigm and employs two\ncontrol tokens, <short> for concise responses and <think> for detailed\nreasoning. At the core of our method is a Decoupled Group Relative Policy\nOptimization (DeGRPO) algorithm, which decomposes the learning objective of\nhybrid reasoning into two components: (1) a control token loss that governs the\nselection of the reasoning mode, and (2) a response loss that improves the\naccuracy of the generated answers. This decoupled formulation enables\nfine-grained control over the contributions of each objective, stabilizing\ntraining and effectively preventing collapse observed in vanilla GRPO.\nEmpirically, on several benchmarks such as Minerva Algebra, MATH-500, and\nGSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% -\n90%, significantly improving the efficiency of Reasoning Language Models. The\ncode is available at https://github.com/VainF/Thinkless",
    "pdf_url": "http://arxiv.org/pdf/2505.13379v2",
    "published": "2025-05-19T17:24:16+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13378v2",
    "title": "The SXS Collaboration's third catalog of binary black hole simulations",
    "authors": [
      "Mark A. Scheel",
      "Michael Boyle",
      "Keefe Mitman",
      "Nils Deppe",
      "Leo C. Stein",
      "Crist√≥bal Armaza",
      "Marceline S. Bonilla",
      "Luisa T. Buchman",
      "Andrea Ceja",
      "Himanshu Chaudhary",
      "Yitian Chen",
      "Maxence Corman",
      "K√°roly Zolt√°n Csuk√°s",
      "C. Melize Ferrus",
      "Scott E. Field",
      "Matthew Giesler",
      "Sarah Habib",
      "Fran√ßois H√©bert",
      "Daniel A. Hemberger",
      "Dante A. B. Iozzo",
      "Tousif Islam",
      "Ken Z. Jones",
      "Aniket Khairnar",
      "Lawrence E. Kidder",
      "Taylor Knapp",
      "Prayush Kumar",
      "Guillermo Lara",
      "Oliver Long",
      "Geoffrey Lovelace",
      "Sizheng Ma",
      "Denyz Melchor",
      "Marlo Morales",
      "Jordan Moxon",
      "Peter James Nee",
      "Kyle C. Nelli",
      "Eamonn O'Shea",
      "Serguei Ossokine",
      "Robert Owen",
      "Harald P. Pfeiffer",
      "Isabella G. Pretto",
      "Teresita Ramirez-Aguilar",
      "Antoni Ramos-Buades",
      "Adhrit Ravichandran",
      "Abhishek Ravishankar",
      "Samuel Rodriguez",
      "Hannes R. R√ºter",
      "Jennifer Sanchez",
      "Md Arif Shaikh",
      "Dongze Sun",
      "B√©la Szil√°gyi",
      "Daniel Tellez",
      "Saul A. Teukolsky",
      "Sierra Thomas",
      "William Throwe",
      "Vijay Varma",
      "Nils L. Vu",
      "Marissa Walker",
      "Nikolas A. Wittek",
      "Jooheon Yoo"
    ],
    "abstract": "We present a major update to the Simulating eXtreme Spacetimes (SXS)\nCollaboration's catalog of binary black hole simulations. Using highly\nefficient spectral methods implemented in the Spectral Einstein Code (SpEC), we\nhave nearly doubled the total number of binary configurations from 2,018 to\n3,756. The catalog now densely covers the parameter space with precessing\nsimulations up to mass ratio $q=8$ and dimensionless spins up to\n$|\\vec{\\chi}|\\le0.8$ with near-zero eccentricity. The catalog also includes\nsome simulations at higher mass ratios with moderate spin and more than 250\neccentric simulations. We have also deprecated and rerun some simulations from\nour previous catalog (e.g., simulations run with a much older version of SpEC\nor that had anomalously high errors in the waveform). The median waveform\ndifference (which is similar to the mismatch) between resolutions over the\nsimulations in the catalog is $4\\times10^{-4}$. The simulations have a median\nof 22 orbits, while the longest simulation has 148 orbits. We have corrected\neach waveform in the catalog to be in the binary's center-of-mass frame and\nexhibit gravitational-wave memory. We estimate the total CPU cost of all\nsimulations in the catalog to be 480,000,000 core-hours. We find that using\nspectral methods for binary black hole simulations is over 1,000 times more\nefficient than much shorter finite-difference simulations of comparable\naccuracy. The full catalog is publicly available through the sxs Python package\nand at https://data.black-holes.org .",
    "pdf_url": "http://arxiv.org/pdf/2505.13378v2",
    "published": "2025-05-19T17:21:54+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.13377v1",
    "title": "Restoration Score Distillation: From Corrupted Diffusion Pretraining to One-Step High-Quality Generation",
    "authors": [
      "Yasi Zhang",
      "Tianyu Chen",
      "Zhendong Wang",
      "Ying Nian Wu",
      "Mingyuan Zhou",
      "Oscar Leong"
    ],
    "abstract": "Learning generative models from corrupted data is a fundamental yet\npersistently challenging task across scientific disciplines, particularly when\naccess to clean data is limited or expensive. Denoising Score Distillation\n(DSD) \\cite{chen2025denoising} recently introduced a novel and surprisingly\neffective strategy that leverages score distillation to train high-fidelity\ngenerative models directly from noisy observations. Building upon this\nfoundation, we propose \\textit{Restoration Score Distillation} (RSD), a\nprincipled generalization of DSD that accommodates a broader range of\ncorruption types, such as blurred, incomplete, or low-resolution images. RSD\noperates by first pretraining a teacher diffusion model solely on corrupted\ndata and subsequently distilling it into a single-step generator that produces\nhigh-quality reconstructions. Empirically, RSD consistently surpasses its\nteacher model across diverse restoration tasks on both natural and scientific\ndatasets. Moreover, beyond standard diffusion objectives, the RSD framework is\ncompatible with several corruption-aware training techniques such as Ambient\nTweedie, Ambient Diffusion, and its Fourier-space variant, enabling flexible\nintegration with recent advances in diffusion modeling. Theoretically, we\ndemonstrate that in a linear regime, RSD recovers the eigenspace of the clean\ndata covariance matrix from linear measurements, thereby serving as an implicit\nregularizer. This interpretation recasts score distillation not only as a\nsampling acceleration technique but as a principled approach to enhancing\ngenerative performance in severely degraded data regimes.",
    "pdf_url": "http://arxiv.org/pdf/2505.13377v1",
    "published": "2025-05-19T17:21:03+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13375v3",
    "title": "Minimum-Excess-Work Guidance",
    "authors": [
      "Christopher Kolloff",
      "Tobias H√∂ppe",
      "Emmanouil Angelis",
      "Mathias Jacob Schreiner",
      "Stefan Bauer",
      "Andrea Dittadi",
      "Simon Olsson"
    ],
    "abstract": "We propose a regularization framework inspired by thermodynamic work for\nguiding pre-trained probability flow generative models (e.g., continuous\nnormalizing flows or diffusion models) by minimizing excess work, a concept\nrooted in statistical mechanics and with strong conceptual connections to\noptimal transport. Our approach enables efficient guidance in sparse-data\nregimes common to scientific applications, where only limited target samples or\npartial density constraints are available. We introduce two strategies: Path\nGuidance for sampling rare transition states by concentrating probability mass\non user-defined subsets, and Observable Guidance for aligning generated\ndistributions with experimental observables while preserving entropy. We\ndemonstrate the framework's versatility on a coarse-grained protein model,\nguiding it to sample transition configurations between folded/unfolded states\nand correct systematic biases using experimental data. The method bridges\nthermodynamic principles with modern generative architectures, offering a\nprincipled, efficient, and physics-inspired alternative to standard fine-tuning\nin data-scarce domains. Empirical results highlight improved sample efficiency\nand bias reduction, underscoring its applicability to molecular simulations and\nbeyond.",
    "pdf_url": "http://arxiv.org/pdf/2505.13375v3",
    "published": "2025-05-19T17:19:43+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.13376v1",
    "title": "Seeing, Saying, Solving: An LLM-to-TL Framework for Cooperative Robots",
    "authors": [
      "Dan BW Choe",
      "Sundhar Vinodh Sangeetha",
      "Steven Emanuel",
      "Chih-Yuan Chiu",
      "Samuel Coogan",
      "Shreyas Kousik"
    ],
    "abstract": "Increased robot deployment, such as in warehousing, has revealed a need for\nseamless collaboration among heterogeneous robot teams to resolve unforeseen\nconflicts. To address this challenge, we propose a novel, decentralized\nframework for robots to request and provide help. The framework begins with\nrobots detecting conflicts using a Vision Language Model (VLM), then reasoning\nover whether help is needed. If so, it crafts and broadcasts a natural language\n(NL) help request using a Large Language Model (LLM). Potential helper robots\nreason over the request and offer help (if able), along with information about\nimpact to their current tasks. Helper reasoning is implemented via an LLM\ngrounded in Signal Temporal Logic (STL) using a Backus-Naur Form (BNF) grammar\nto guarantee syntactically valid NL-to-STL translations, which are then solved\nas a Mixed Integer Linear Program (MILP). Finally, the requester robot chooses\na helper by reasoning over impact on the overall system. We evaluate our system\nvia experiments considering different strategies for choosing a helper, and\nfind that a requester robot can minimize overall time impact on the system by\nconsidering multiple help offers versus simple heuristics (e.g., selecting the\nnearest robot to help).",
    "pdf_url": "http://arxiv.org/pdf/2505.13376v1",
    "published": "2025-05-19T17:19:43+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13374v1",
    "title": "Structure-preserving schemes conserving entropy and kinetic energy",
    "authors": [
      "Kunal Bahuguna",
      "Ramesh Kolluru",
      "S. V. Raghurama Rao"
    ],
    "abstract": "This paper presents a novel structure-preserving scheme for Euler equations,\nfocusing on the numerical conservation of entropy and kinetic energy. Explicit\nflux functions engineered to conserve entropy are introduced within the\nfinite-volume framework. Further, discrete kinetic energy conservation too is\nintroduced. A systematic inquiry is presented, commencing with an overview of\nnumerical entropy conservation and formulation of entropy-conserving and\nkinetic energy-preserving fluxes, followed by the study of their properties and\nefficacy. A novelty introduced is to associate numerical entropy conservation\nto the discretization of the energy conservation equation. Furthermore, an\nentropy-stable shock-capturing diffusion method and a hybrid approach utilizing\nthe entropy distance to manage smooth regions effectively are also introduced.\nThe addition of artificial viscosity in appropriate regions ensures entropy\ngeneration sufficient to prevent numerical instabilities. Various test cases,\nshowcasing the efficacy and stability of the proposed methodology, are\npresented.",
    "pdf_url": "http://arxiv.org/pdf/2505.13374v1",
    "published": "2025-05-19T17:19:39+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.comp-ph"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13373v1",
    "title": "State- versus Reaction-Based Information Processing in Biochemical Networks",
    "authors": [
      "Anne-Lena Moor",
      "Age Tjalma",
      "Manuel Reinhardt",
      "Pieter Rein ten Wolde",
      "Christoph Zechner"
    ],
    "abstract": "Trajectory mutual information is frequently used to quantify information\ntransfer in biochemical systems. Tractable solutions of the trajectory mutual\ninformation can be obtained via the widely used Linear-Noise Approximation\n(LNA) using Gaussian channel theory. This approach is expected to be accurate\nfor sufficiently large systems. However, recent observations show that there\nare cases, where the mutual information obtained this way differs qualitatively\nfrom results derived using an exact Markov jump process formalism, and that the\ndifferences persist even for large systems. In this letter, we show that these\ndifferences can be explained by introducing the notion of reaction- versus\nstate-based descriptions of trajectories. In chemical systems, the information\nis encoded in the sequence of reaction events, and the reaction-based\ntrajectories of Markov jump processes capture this information. In contrast,\nthe commonly used form of the LNA uses a state (concentration) based\ndescription of trajectories, which contains, in general, less information than\na reaction-based description. Here, we show that an alternative formulation of\nthe LNA that retains the reaction-specific information of trajectories can\naccurately describe the trajectory mutual information for large systems. We\nillustrate the consequences of different trajectory descriptions for two common\ncellular reaction motifs and discuss the connection with Berg-Purcell and\nMaximum-Likelihood sensing.",
    "pdf_url": "http://arxiv.org/pdf/2505.13373v1",
    "published": "2025-05-19T17:19:19+00:00",
    "categories": [
      "q-bio.MN"
    ],
    "primary_category": "q-bio.MN"
  },
  {
    "id": "http://arxiv.org/abs/2505.13372v1",
    "title": "Exploiting Symbolic Heuristics for the Synthesis of Domain-Specific Temporal Planning Guidance using Reinforcement Learning",
    "authors": [
      "Irene Brugnara",
      "Alessandro Valentini",
      "Andrea Micheli"
    ],
    "abstract": "Recent work investigated the use of Reinforcement Learning (RL) for the\nsynthesis of heuristic guidance to improve the performance of temporal planners\nwhen a domain is fixed and a set of training problems (not plans) is given. The\nidea is to extract a heuristic from the value function of a particular\n(possibly infinite-state) MDP constructed over the training problems.\n  In this paper, we propose an evolution of this learning and planning\nframework that focuses on exploiting the information provided by symbolic\nheuristics during both the RL and planning phases. First, we formalize\ndifferent reward schemata for the synthesis and use symbolic heuristics to\nmitigate the problems caused by the truncation of episodes needed to deal with\nthe potentially infinite MDP. Second, we propose learning a residual of an\nexisting symbolic heuristic, which is a \"correction\" of the heuristic value,\ninstead of eagerly learning the whole heuristic from scratch. Finally, we use\nthe learned heuristic in combination with a symbolic heuristic using a\nmultiple-queue planning approach to balance systematic search with imperfect\nlearned information. We experimentally compare all the approaches, highlighting\ntheir strengths and weaknesses and significantly advancing the state of the art\nfor this planning and learning schema.",
    "pdf_url": "http://arxiv.org/pdf/2505.13372v1",
    "published": "2025-05-19T17:19:13+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13371v1",
    "title": "A new lower bound for the Ramsey numbers $R(3,k)$",
    "authors": [
      "Marcelo Campos",
      "Matthew Jenssen",
      "Marcus Michelen",
      "Julian Sahasrabudhe"
    ],
    "abstract": "We prove a new lower bound for the off-diagonal Ramsey numbers, \\[ R(3,k)\n\\geq \\bigg( \\frac{1}{3}+ o(1) \\bigg) \\frac{k^2}{\\log k }\\, , \\] thereby\nnarrowing the gap between the upper and lower bounds to a factor of $3+o(1)$.\nThis improves the best known lower bound of $(1/4+o(1))k^2/\\log k$ due,\nindependently, to Bohman and Keevash, and Fiz Pontiveros, Griffiths and Morris,\nresulting from their celebrated analysis of the triangle-free process. As a\nconsequence, we disprove a conjecture of Fiz Pontiveros, Griffiths and Morris\nthat the constant $1/4$ is sharp.",
    "pdf_url": "http://arxiv.org/pdf/2505.13371v1",
    "published": "2025-05-19T17:18:29+00:00",
    "categories": [
      "math.CO",
      "math.PR"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13370v1",
    "title": "A Kolmogorov-Arnold Neural Model for Cascading Extremes",
    "authors": [
      "Miguel de Carvalho",
      "Clemente Ferrer",
      "Ronny Vallejos"
    ],
    "abstract": "This paper addresses the growing concern of cascading extreme events, such as\nan extreme earthquake followed by a tsunami, by presenting a novel method for\nrisk assessment focused on these domino effects. The proposed approach develops\nan extreme value theory framework within a Kolmogorov-Arnold network (KAN) to\nestimate the probability of one extreme event triggering another, conditionally\non a feature vector. An extra layer is added to the KAN's architecture to\nenforce the definition of the parameter of interest within the unit interval,\nand we refer to the resulting neural model as KANE (KAN with Natural\nEnforcement). The proposed method is backed by exhaustive numerical studies and\nfurther illustrated with real-world applications to seismology and climatology.",
    "pdf_url": "http://arxiv.org/pdf/2505.13370v1",
    "published": "2025-05-19T17:17:08+00:00",
    "categories": [
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.13369v1",
    "title": "Variational formulas for determinant of Laplacian on higher genus polyhedral surface",
    "authors": [
      "Dmitrii Korikov",
      "Alexey Kokotov"
    ],
    "abstract": "Let $X$ be a Riemann surface of genus $g\\ge 1$ endowed with a flat conical\nmetric $m$ and let ${\\rm det}\\,\\Delta$ be the $\\zeta$-regularized determinant\nof the Friedrichs Laplacian on $(X,m)$. We derive variational formulas for\n${\\rm det}\\,\\Delta$ with respect to conical points and conical angles within a\ngiven conformal class. Integration of them leads to an explicit expression for\n${\\rm det}\\,\\Delta$ up to moduli dependent factor. The latter, in principle,\ncan be calculated via comparison of the above result with the well-known\nformulas for the case of flat conical metrics with trivial holonomy.",
    "pdf_url": "http://arxiv.org/pdf/2505.13369v1",
    "published": "2025-05-19T17:15:01+00:00",
    "categories": [
      "math.DG",
      "math.SP",
      "Primary 58J52, 35P99, 30F10, 30F45, Secondary 32G15, 32G08"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13368v1",
    "title": "Principal 3-Bundles with Adjusted Connections",
    "authors": [
      "Gianni Gagliardo",
      "Christian Saemann",
      "Roberto Tellez-Dominguez"
    ],
    "abstract": "We explore the notion of adjusted connection for principal 3-bundles. We\nfirst derive the explicit form of an adjustment datum for 3-term\n$L_\\infty$-algebras, which allows us to give a local description of such\nadjusted connections and their infinitesimal symmetries. We then introduce the\nnotion of an adjusted 2-crossed module of Lie groups and provide the explicit\nglobal description of principal 3-bundles with adjusted connections in terms of\ndifferential cocycles. These connections appear in a number of context within\nhigh-energy physics, and we list local examples arising in gauged supergravity\nand a global example arising in various contexts in string/M-theory. Our\nprimary motivation, however, stems from U-duality, and we define a notion of\ncategorified torus that forms an adjusted 2-crossed module, which we hope to be\nuseful in lifting T-duality to M-theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.13368v1",
    "published": "2025-05-19T17:14:42+00:00",
    "categories": [
      "math-ph",
      "hep-th",
      "math.DG",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13367v1",
    "title": "Reflection phase shifts of bouncing Bogoliubov waves",
    "authors": [
      "Carsten Henkel"
    ],
    "abstract": "The Bogoliubov-de Gennes equations are solved for an inhomogeneous condensate\nin the vicinity of a turning point, addressing the full continuous spectrum. A\nbasis change in the space of the two Bogoliubov \"particle\" and \"hole\"\namplitudes is introduced that decouples them approximately. We find a spatially\nextended mode that governs mainly excitations in the condensate phase, while\nanother mode is localised to regions with density gradients. An analytical and\nnumerical discussion of the phase shift is provided that incident matter waves\nsuffer upon reflection at the turning point, forming standing waves. As an\napplication, we compute eigenfrequencies in a gravitational trap, without\nrecourse to the local density approximation. The non-condensate density at\nfinite temperature and its quantum depletion are discussed in a companion\npaper.",
    "pdf_url": "http://arxiv.org/pdf/2505.13367v1",
    "published": "2025-05-19T17:14:12+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.13366v1",
    "title": "A Game-Theoretic Quantum Algorithm for Solving Magic Squares",
    "authors": [
      "Sarah Chehade",
      "Andrea Delgado",
      "Elaine Wong"
    ],
    "abstract": "Variational quantum algorithms (VQAs) offer a promising near-term approach to\nfinding optimal quantum strategies for playing non-local games. These games\ntest quantum correlations beyond classical limits and enable entanglement\nverification. In this work, we present a variational framework for the Magic\nSquare Game (MSG), a two-player non-local game with perfect quantum advantage.\nWe construct a value Hamiltonian that encodes the game's parity and consistency\nconstraints, then optimize parameterized quantum circuits to minimize this\ncost. Our approach builds on the stabilizer formalism, leverages commutation\nstructure for circuit design, and is hardware-efficient. Compared to existing\nwork, our contribution emphasizes algebraic structure and interpretability. We\nvalidate our method through numerical experiments and outline generalizations\nto larger games.",
    "pdf_url": "http://arxiv.org/pdf/2505.13366v1",
    "published": "2025-05-19T17:12:53+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13365v1",
    "title": "Mixed Quantum-Classical Methods for Polaron Spectral Functions",
    "authors": [
      "Haimi Nguyen",
      "Arkajit Mandal",
      "Ankit Mahajan",
      "David R. Reichman"
    ],
    "abstract": "In this work, using two distinct semiclassical approaches, namely the\nmean-field Ehrenfest (MFE) method and the mapping approach to surface hopping\n(MASH), we investigate the spectral function of a single charge interacting\nwith phonons on a lattice. This quantity is relevant for the description of\nangle-resolved photoemission experiments. Focusing on the one-dimensional\nHolstein model, we compare the performance of these approaches across a range\nof coupling strengths and lattice sizes, exposing the relative strengths and\nweaknesses of each. We demonstrate that these approaches can be efficiently\napplied with reasonable accuracy to ab initio polaron models. Our work provides\na route to the calculation of spectral properties in realistic\nelectron-phonon-coupled systems in a computationally inexpensive manner with\nencouraging accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.13365v1",
    "published": "2025-05-19T17:11:00+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.str-el"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13364v1",
    "title": "Modeling Innovation Ecosystem Dynamics through Interacting Reinforced Bernoulli Processes",
    "authors": [
      "Giacomo Aletti",
      "Irene Crimaldi",
      "Andrea Ghiglietti",
      "Federico Nutarelli"
    ],
    "abstract": "Understanding how capabilities evolve into core capabilities-and how core\ncapabilities may ossify into rigidities-is central to innovation strategy\n[https://www.jstor.org/stable/2486355,\nhttps://www.barnesandnoble.com/w/dynamic-capabilities-and-strategic-management-david-j-teece/1102436798].\n  To address this, we propose a novel formal model based on interacting\nreinforced Bernoulli processes. This framework captures how patent successes\npropagate across technological categories and how these categories co-evolve.\nThe model is able to jointly account for several stylized facts in the\nempirical innovation literature, including sublinear success growth\n(success-probability decay), convergence of success shares across fields, and\ndiminishing cross-category correlations over time.\n  Empirical validation using GLOBAL PATSTAT (1980-2018) supports the\ntheoretical predictions. We estimate the structural parameters of the\ninteraction matrix and we also propose a statistical procedure to make\ninference on the intensity of cross-category interactions under the mean-field\nassumption.",
    "pdf_url": "http://arxiv.org/pdf/2505.13364v1",
    "published": "2025-05-19T17:10:22+00:00",
    "categories": [
      "stat.AP",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13363v1",
    "title": "Heterogeneous diffusion in an harmonic potential: the role of the interpretation",
    "authors": [
      "Adrian Pacheco-Pozo",
      "Igor M. Sokolov",
      "Ralf Metzler",
      "Diego Krapf"
    ],
    "abstract": "Diffusion in heterogeneous energy and diffusivity landscapes is widespread in\nbiological systems. However, solving the Langevin equation in such environments\nintroduces ambiguity due to the interpretation parameter $\\alpha$, which\ndepends on the underlying physics and can take values in the range\n$0<\\alpha<1$. The typical interpretations are It\\^o ($\\alpha=0$), Stratonovich\n($\\alpha=1/2$), and H\\\"anggi-Klimontovich ($\\alpha=1$). Here, we analyse the\nmotion of a particle in an harmonic potential -- modelled as an\nOrnstein-Uhlenbeck process -- with diffusivity that varies in space. Our focus\nis on two-phase systems with a discontinuity in environmental properties at\n$x=0$. We derive the probability density of the particle position for the\nprocess, and consider two paradigmatic situations. In the first one, the\ndamping coefficient remains constant, and fluctuation-dissipation relations are\nnot satisfied. In the second one, these relations are enforced, leading to a\nposition-dependent damping coefficient. In both cases, we provide solutions as\na function of the interpretation parameter $\\alpha$, with particular attention\nto the It\\^o, Stratonovich, and H\\\"anggi-Klimontovich interpretations,\nrevealing fundamentally different behaviours, in particular with respect to an\ninterface located at the potential minimum.",
    "pdf_url": "http://arxiv.org/pdf/2505.13363v1",
    "published": "2025-05-19T17:07:46+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.dis-nn",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.13362v1",
    "title": "DynaNoise: Dynamic Probabilistic Noise Injection for Defending Against Membership Inference Attacks",
    "authors": [
      "Javad Forough",
      "Hamed Haddadi"
    ],
    "abstract": "Membership Inference Attacks (MIAs) pose a significant risk to the privacy of\ntraining datasets by exploiting subtle differences in model outputs to\ndetermine whether a particular data sample was used during training. These\nattacks can compromise sensitive information, especially in domains such as\nhealthcare and finance, where data privacy is paramount. Traditional mitigation\ntechniques, such as static differential privacy, rely on injecting a fixed\namount of noise during training or inference. However, this approach often\nleads to a detrimental trade-off: the noise may be insufficient to counter\nsophisticated attacks or, when increased, may substantially degrade model\nperformance. In this paper, we present DynaNoise, an adaptive approach that\ndynamically modulates noise injection based on query sensitivity. Our approach\nperforms sensitivity analysis using measures such as Shannon entropy to\nevaluate the risk associated with each query and adjusts the noise variance\naccordingly. A probabilistic smoothing step is then applied to renormalize the\nperturbed outputs, ensuring that the model maintains high accuracy while\neffectively obfuscating membership signals. We further propose an empirical\nmetric, the Membership Inference Defense Privacy-Utility Tradeoff (MIDPUT),\nwhich quantifies the balance between reducing attack success rates and\npreserving the target model's accuracy. Our extensive evaluation on several\nbenchmark datasets demonstrates that DynaNoise not only significantly reduces\nMIA success rates but also achieves up to a fourfold improvement in the MIDPUT\nmetric compared to the state-of-the-art. Moreover, DynaNoise maintains\ncompetitive model accuracy while imposing only marginal inference overhead,\nhighlighting its potential as an effective and efficient privacy defense\nagainst MIAs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13362v1",
    "published": "2025-05-19T17:07:00+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13361v2",
    "title": "Feedback-Driven Dynamical Model for Axonal Extension on Parallel Micropatterns",
    "authors": [
      "Kyle Cheng",
      "Udathari Kumarasinghe",
      "Cristian Staii"
    ],
    "abstract": "Despite significant advances in understanding neuronal development, a fully\nquantitative framework that integrates intracellular mechanisms with\nenvironmental cues during axonal growth remains incomplete. Here, we present a\nunified biophysical model that captures key mechanochemical processes governing\naxonal extension on micropatterned substrates. In these environments, axons\npreferentially align with the pattern direction, form bundles, and advance at\nconstant speed. The model integrates four core components: (i) actin-adhesion\ntraction coupling, (ii) lateral inhibition between neighboring axons, (iii)\ntubulin transport from soma to the growth cone, and (4) orientation dynamics\nguided by the substrate anisotropy. Dynamical systems analysis reveals that the\nsaddle-node bifurcation in the actin adhesion subsystem drives a transition to\na high-traction motile state, while traction feedback shifts a pitchfork\nbifurcation in the signaling loop, promoting symmetry breaking and robust\nalignment. An exact linear solution in the tubulin transport subsystem\nfunctions as a built-in speed regulator, ensuring stable elongation rates.\nSimulations using experimentally inferred parameters accurately reproduce\nelongation speed, alignment variance, and bundle spacing. The model provides\nexplicit design rules for enhancing axonal alignment through modulation of\nsubstrate stiffness and adhesion dynamics. By identifying key control\nparameters, this work enables rational design of biomaterials for neural repair\nand engineered tissue systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13361v2",
    "published": "2025-05-19T17:06:21+00:00",
    "categories": [
      "q-bio.NC",
      "nlin.AO",
      "q-bio.CB",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13360v1",
    "title": "What Prompts Don't Say: Understanding and Managing Underspecification in LLM Prompts",
    "authors": [
      "Chenyang Yang",
      "Yike Shi",
      "Qianou Ma",
      "Michael Xieyang Liu",
      "Christian K√§stner",
      "Tongshuang Wu"
    ],
    "abstract": "Building LLM-powered software requires developers to communicate their\nrequirements through natural language, but developer prompts are frequently\nunderspecified, failing to fully capture many user-important requirements. In\nthis paper, we present an in-depth analysis of prompt underspecification,\nshowing that while LLMs can often (41.1%) guess unspecified requirements by\ndefault, such behavior is less robust: Underspecified prompts are 2x more\nlikely to regress over model or prompt changes, sometimes with accuracy drops\nby more than 20%. We then demonstrate that simply adding more requirements to a\nprompt does not reliably improve performance, due to LLMs' limited\ninstruction-following capabilities and competing constraints, and standard\nprompt optimizers do not offer much help. To address this, we introduce novel\nrequirements-aware prompt optimization mechanisms that can improve performance\nby 4.8% on average over baselines that naively specify everything in the\nprompt. Beyond prompt optimization, we envision that effectively managing\nprompt underspecification requires a broader process, including proactive\nrequirements discovery, evaluation, and monitoring.",
    "pdf_url": "http://arxiv.org/pdf/2505.13360v1",
    "published": "2025-05-19T17:03:42+00:00",
    "categories": [
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13359v1",
    "title": "Polarization Properties of Energetic Pulsars at Meterwavelengths",
    "authors": [
      "Dipanjan Mitra",
      "Rahul Basu",
      "George I. Melikidze"
    ],
    "abstract": "Polarization behaviour shows a transition in the pulsar population, where\nenergetic sources with higher spin-down energy loss, $\\dot{E} > 10^{34}$\nerg~s$^{-1}$, often have fractional linear polarisation ($L/I$) close to 100\\%,\nwhile below this range $L/I$ is usually lower than 50\\%. The polarisation\nbehaviour has been primarily studied at higher frequencies above 1 GHz, and in\nthis work we explore the single pulse polarisation behaviour in pulsars with\n$\\dot{E} > 5\\times10^{33}$ erg~s$^{-1}$ at a lower frequency range of 300-750\nMHz. The polarisation behaviour can be divided into two categories, the first\nwith $L/I>$ 70\\% where the polarisation position angle (PPA) follows a single\ntrack, and a second group with $L/I <$ 70\\% and scattered PPA behaviour with or\nwithout orthogonal modes. However, there are some single pulses in the first\ncategory that also have lower $L/I$ and exhibit the presence of two\npolarisation modes along orthogonal tracks. The radio emission in pulsars\narises due to coherent curvature radiation (CCR) from charge bunches, which\ndevelops due to non-linear instabilities in the pulsar plasma forming charge\nseparated envelope solitons. The CCR excites orthogonally polarised X and O\nmodes oriented perpendicular and parallel to the magnetic field line planes,\nthat detach in the plasma and propagate independently. The O-mode is seven\ntimes stronger than the X-mode but gets damped in the medium. We show that\nincoherent mixing of the X and O modes with different levels of damping can\nreproduce the observed polarisation features in the energetic pulsar\npopulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13359v1",
    "published": "2025-05-19T17:03:15+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13358v2",
    "title": "One-Step Offline Distillation of Diffusion-based Models via Koopman Modeling",
    "authors": [
      "Nimrod Berman",
      "Ilan Naiman",
      "Moshe Eliasof",
      "Hedi Zisling",
      "Omri Azencot"
    ],
    "abstract": "Diffusion-based generative models have demonstrated exceptional performance,\nyet their iterative sampling procedures remain computationally expensive. A\nprominent strategy to mitigate this cost is distillation, with offline\ndistillation offering particular advantages in terms of efficiency, modularity,\nand flexibility. In this work, we identify two key observations that motivate a\nprincipled distillation framework: (1) while diffusion models have been viewed\nthrough the lens of dynamical systems theory, powerful and underexplored tools\ncan be further leveraged; and (2) diffusion models inherently impose\nstructured, semantically coherent trajectories in latent space. Building on\nthese observations, we introduce the Koopman Distillation Model KDM, a novel\noffline distillation approach grounded in Koopman theory-a classical framework\nfor representing nonlinear dynamics linearly in a transformed space. KDM\nencodes noisy inputs into an embedded space where a learned linear operator\npropagates them forward, followed by a decoder that reconstructs clean samples.\nThis enables single-step generation while preserving semantic fidelity. We\nprovide theoretical justification for our approach: (1) under mild assumptions,\nthe learned diffusion dynamics admit a finite-dimensional Koopman\nrepresentation; and (2) proximity in the Koopman latent space correlates with\nsemantic similarity in the generated outputs, allowing for effective trajectory\nalignment. Empirically, KDM achieves state-of-the-art performance across\nstandard offline distillation benchmarks, improving FID scores by up to 40% in\na single generation step. All implementation details and code for the\nexperimental setups are provided in our GitHub -\nhttps://github.com/azencot-group/KDM, or in our project page -\nhttps://sites.google.com/view/koopman-distillation-model.",
    "pdf_url": "http://arxiv.org/pdf/2505.13358v2",
    "published": "2025-05-19T16:59:47+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13357v1",
    "title": "Introducing Instruction-Accurate Simulators for Performance Estimation of Autotuning Workloads",
    "authors": [
      "Rebecca Pelke",
      "Nils Bosbach",
      "Lennart M. Reimann",
      "Rainer Leupers"
    ],
    "abstract": "Accelerating Machine Learning (ML) workloads requires efficient methods due\nto their large optimization space. Autotuning has emerged as an effective\napproach for systematically evaluating variations of implementations.\nTraditionally, autotuning requires the workloads to be executed on the target\nhardware (HW). We present an interface that allows executing autotuning\nworkloads on simulators. This approach offers high scalability when the\navailability of the target HW is limited, as many simulations can be run in\nparallel on any accessible HW. Additionally, we evaluate the feasibility of\nusing fast instruction-accurate simulators for autotuning. We train various\npredictors to forecast the performance of ML workload implementations on the\ntarget HW based on simulation statistics. Our results demonstrate that the\ntuned predictors are highly effective. The best workload implementation in\nterms of actual run time on the target HW is always within the top 3 % of\npredictions for the tested x86, ARM, and RISC-V-based architectures. In the\nbest case, this approach outperforms native execution on the target HW for\nembedded architectures when running as few as three samples on three simulators\nin parallel.",
    "pdf_url": "http://arxiv.org/pdf/2505.13357v1",
    "published": "2025-05-19T16:59:07+00:00",
    "categories": [
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13356v1",
    "title": "Quantum Hardware-in-the-Loop for Optimal Power Flow in Renewable-Integrated Power Systems",
    "authors": [
      "Zeynab Kaseb",
      "Rahul Rane",
      "Aleksandra Lekic",
      "Matthias Moller",
      "Amin Khodaei",
      "Peter Palensky",
      "Pedro P. Vergara"
    ],
    "abstract": "This paper presents a proof-of-concept for integrating quantum hardware with\nreal-time digital simulator (RTDS) to model and control modern power systems,\nincluding renewable energy resources. Power flow (PF) analysis and optimal\npower flow (OPF) studies are conducted using RTDS coupled with Fujitsu's CMOS\nDigital Annealer and D-Wave's Advantage quantum processors. The adiabatic\nquantum power flow (AQPF) and adiabatic quantum optimal power flow (AQOPF)\nalgorithms are used to perform PF and OPF, respectively, on quantum and\nquantum-inspired hardware. The experiments are performed on the IEEE 9-bus test\nsystem and a modified version that includes solar and wind farms. The findings\ndemonstrate that the AQPF and AQOPF algorithms can accurately perform PF and\nOPF, yielding results that closely match those of classical Newton-Raphson (NR)\nsolvers while also exhibiting robust convergence. Furthermore, the integration\nof renewable energy sources (RES) within the AQOPF framework proves effective\nin maintaining system stability and performance, even under variable generation\nconditions. These findings highlight the potential of quantum computing to\nsignificantly enhance the modeling and control of future power grids,\nparticularly in systems with high renewable energy penetration.",
    "pdf_url": "http://arxiv.org/pdf/2505.13356v1",
    "published": "2025-05-19T16:58:58+00:00",
    "categories": [
      "eess.SY",
      "cs.NA",
      "cs.SY",
      "math.NA"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13355v1",
    "title": "Multi-Armed Bandits Meet Large Language Models",
    "authors": [
      "Djallel Bouneffouf",
      "Raphael Feraud"
    ],
    "abstract": "Bandit algorithms and Large Language Models (LLMs) have emerged as powerful\ntools in artificial intelligence, each addressing distinct yet complementary\nchallenges in decision-making and natural language processing. This survey\nexplores the synergistic potential between these two fields, highlighting how\nbandit algorithms can enhance the performance of LLMs and how LLMs, in turn,\ncan provide novel insights for improving bandit-based decision-making. We first\nexamine the role of bandit algorithms in optimizing LLM fine-tuning, prompt\nengineering, and adaptive response generation, focusing on their ability to\nbalance exploration and exploitation in large-scale learning tasks.\nSubsequently, we explore how LLMs can augment bandit algorithms through\nadvanced contextual understanding, dynamic adaptation, and improved policy\nselection using natural language reasoning. By providing a comprehensive review\nof existing research and identifying key challenges and opportunities, this\nsurvey aims to bridge the gap between bandit algorithms and LLMs, paving the\nway for innovative applications and interdisciplinary research in AI.",
    "pdf_url": "http://arxiv.org/pdf/2505.13355v1",
    "published": "2025-05-19T16:57:57+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13353v2",
    "title": "Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning",
    "authors": [
      "Adam ≈†torek",
      "Mukur Gupta",
      "Samira Hajizadeh",
      "Prashast Srivastava",
      "Suman Jana"
    ],
    "abstract": "Although modern Large Language Models (LLMs) support extremely large\ncontexts, their effectiveness in utilizing long context for code reasoning\nremains unclear. This paper investigates LLM reasoning ability over code\nsnippets within large repositories and how it relates to their recall ability.\nSpecifically, we differentiate between lexical code recall (verbatim retrieval)\nand semantic code recall (remembering what the code does). To measure semantic\nrecall, we propose SemTrace, a code reasoning technique where the impact of\nspecific statements on output is attributable and unpredictable. We also\npresent a method to quantify semantic recall sensitivity in existing\nbenchmarks. Our evaluation of state-of-the-art LLMs reveals a significant drop\nin code reasoning accuracy as a code snippet approaches the middle of the input\ncontext, particularly with techniques requiring high semantic recall like\nSemTrace. Moreover, we find that lexical recall varies by granularity, with\nmodels excelling at function retrieval but struggling with line-by-line recall.\nNotably, a disconnect exists between lexical and semantic recall, suggesting\ndifferent underlying mechanisms. Finally, our findings indicate that current\ncode reasoning benchmarks may exhibit low semantic recall sensitivity,\npotentially underestimating LLM challenges in leveraging in-context\ninformation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13353v2",
    "published": "2025-05-19T16:56:31+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13354v1",
    "title": "A large-scale analysis of public-facing, community-built chatbots on Character.AI",
    "authors": [
      "Owen Lee",
      "Kenneth Joseph"
    ],
    "abstract": "This paper presents the first large-scale analysis of public-facing chatbots\non Character.AI, a rapidly growing social media platform where users create and\ninteract with chatbots. Character.AI is distinctive in that it merges\ngenerative AI with user-generated content, enabling users to build bots-often\nmodeled after fictional or public personas-for others to engage with. It is\nalso popular, with over 20 million monthly active users, and impactful, with\nrecent headlines detailing significant issues with youth engagement on the\nsite. Character.AI is thus of interest to study both substantively and\nconceptually. To this end, we present a descriptive overview of the site using\na dataset of 2.1 million English-language prompts (or ``greetings'') for\nchatbots on the site, created by around 1 million users. Our work explores the\nprevalence of different fandoms on the site, broader tropes that persist across\nfandoms, and how dynamics of power intersect with gender within greetings.\nOverall, our findings illuminate an emerging form of online (para)social\ninteraction that toes a unique and important intersection between generative AI\nand user-generated content.",
    "pdf_url": "http://arxiv.org/pdf/2505.13354v1",
    "published": "2025-05-19T16:56:31+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13352v1",
    "title": "Emergent High-Entropy Phases in Geometrically Frustrated Pyrochlore Magnets",
    "authors": [
      "Prakash Timsina",
      "Andres Chappa",
      "Deema Alyones",
      "Igor Vasiliev",
      "Ludi Miao"
    ],
    "abstract": "Frustrated magnets provide a platform for exploring exotic phases beyond\nconventional ordering, with potential relevance to functional materials and\ninformation technologies. In this work, we use Monte Carlo simulations to map\nthe thermodynamic phase diagram of pyrochlore iridates R2Ir2O7 (R = Dy, Ho)\nwith three stable magnetic ground-state stable phases: frustrated spin-ice 2 in\n2 out (2I2O) phase, frustrated fragmented 3 in 1 out/1 in 3 out (3I1O/1I3O)\nphase, and antiferromagnetic all in all out (AIAO) phase without frustration.\nWe discovered two additional emergent metastable phases at finite temperatures,\nlocated between the boundaries separating those stable phases. These metastable\nphases exhibit high magnetic susceptibility and high entropy without long-range\norder. Their stabilization arises from entropic minimization of the free\nenergy, where the entropy dominates energetic competition near phase boundaries\nat finite temperatures. Our results demonstrate a platform to engineer highly\nsusceptible and degenerated states through frustration and thermal activation,\noffering a foundation for entropy-based design of metastable phases in\ncorrelated systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13352v1",
    "published": "2025-05-19T16:56:04+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.13351v1",
    "title": "Poisson structure on predual of Banach Lie algebroid",
    "authors": [
      "Tomasz Goli≈Ñski",
      "Grzegorz Jakimowicz"
    ],
    "abstract": "We construct the linear Poisson structure on the predual bundle of a Banach\nLie algebroid. It is an alternative approach to the already known results on\nthe linear sub-Poisson structure on the dual bundle. We also discuss the\nexistence of queer Banach Lie algebroids. An example of a precotangent bundle\nis presented.",
    "pdf_url": "http://arxiv.org/pdf/2505.13351v1",
    "published": "2025-05-19T16:54:02+00:00",
    "categories": [
      "math.DG",
      "math-ph",
      "math.FA",
      "math.MP"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13350v1",
    "title": "Approximating Global Contact-Implicit MPC via Sampling and Local Complementarity",
    "authors": [
      "Sharanya Venkatesh",
      "Bibit Bianchini",
      "Alp Aydinoglu",
      "William Yang",
      "Michael Posa"
    ],
    "abstract": "To achieve general-purpose dexterous manipulation, robots must rapidly devise\nand execute contact-rich behaviors. Existing model-based controllers are\nincapable of globally optimizing in real-time over the exponential number of\npossible contact sequences. Instead, recent progress in contact-implicit\ncontrol has leveraged simpler models that, while still hybrid, make local\napproximations. However, the use of local models inherently limits the\ncontroller to only exploit nearby interactions, potentially requiring\nintervention to richly explore the space of possible contacts. We present a\nnovel approach which leverages the strengths of local complementarity-based\ncontrol in combination with low-dimensional, but global, sampling of possible\nend-effector locations. Our key insight is to consider a contact-free stage\npreceding a contact-rich stage at every control loop. Our algorithm, in\nparallel, samples end effector locations to which the contact-free stage can\nmove the robot, then considers the cost predicted by contact-rich MPC local to\neach sampled location. The result is a globally-informed, contact-implicit\ncontroller capable of real-time dexterous manipulation. We demonstrate our\ncontroller on precise, non-prehensile manipulation of non-convex objects using\na Franka Panda arm. Project page: https://approximating-global-ci-mpc.github.io",
    "pdf_url": "http://arxiv.org/pdf/2505.13350v1",
    "published": "2025-05-19T16:52:53+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13349v1",
    "title": "Signature change as phase transition in holography",
    "authors": [
      "Marcelo Botta Cantcheff"
    ],
    "abstract": "In holographic quantum gravity, Euclidean pieces of the spacetime appear in\nthe large N limit as representing semi-classical states of the theory. In this\nessay, we argue that the duals of entangled states are spacetime geometries\nthat contain Euclidean regions in order to preserve classical connectivity.\nThereby, the proposal is to extend the ER-EPR conjecture to regimes whether\nwormholes (Einstein-Rosen bridges) become unstable but the entangled structure\nof the dual state persists.",
    "pdf_url": "http://arxiv.org/pdf/2505.13349v1",
    "published": "2025-05-19T16:52:10+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13348v1",
    "title": "Investigating the Vulnerability of LLM-as-a-Judge Architectures to Prompt-Injection Attacks",
    "authors": [
      "Narek Maloyan",
      "Bislan Ashinov",
      "Dmitry Namiot"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly employed as evaluators\n(LLM-as-a-Judge) for assessing the quality of machine-generated text. This\nparadigm offers scalability and cost-effectiveness compared to human\nannotation. However, the reliability and security of such systems, particularly\ntheir robustness against adversarial manipulations, remain critical concerns.\nThis paper investigates the vulnerability of LLM-as-a-Judge architectures to\nprompt-injection attacks, where malicious inputs are designed to compromise the\njudge's decision-making process. We formalize two primary attack strategies:\nComparative Undermining Attack (CUA), which directly targets the final decision\noutput, and Justification Manipulation Attack (JMA), which aims to alter the\nmodel's generated reasoning. Using the Greedy Coordinate Gradient (GCG)\noptimization method, we craft adversarial suffixes appended to one of the\nresponses being compared. Experiments conducted on the MT-Bench Human Judgments\ndataset with open-source instruction-tuned LLMs (Qwen2.5-3B-Instruct and\nFalcon3-3B-Instruct) demonstrate significant susceptibility. The CUA achieves\nan Attack Success Rate (ASR) exceeding 30\\%, while JMA also shows notable\neffectiveness. These findings highlight substantial vulnerabilities in current\nLLM-as-a-Judge systems, underscoring the need for robust defense mechanisms and\nfurther research into adversarial evaluation and trustworthiness in LLM-based\nassessment frameworks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13348v1",
    "published": "2025-05-19T16:51:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13347v2",
    "title": "Groups of $\\mathrm{I}_G$-type",
    "authors": [
      "Carsten Dietzel"
    ],
    "abstract": "In this work, we address a question posed by Dehornoy et al. in the book\n\"Foundations of Garside Theory\" that asks for a theory of groups of\n$\\mathrm{I}_G$-type when $G$ is a Garside group. In this article, we introduce\na broader notion than the one suggested by Dehornoy et al.: given a\nleft-ordered group $G$, we define a group of $\\mathrm{I}_G$-type as a\nleft-ordered group whose partial order is isomorphic to those of $G$.\nFurthermore, we develop methods to give a characterization of groups of\n$\\mathrm{I}_{\\Gamma}$-type in terms of skew braces when $\\Gamma$ is an\nArtin-Tits group of spherical type and classify all groups of\n$\\mathrm{I}_{\\Gamma}$-type where $\\Gamma$ is an irreducible spherical\nArtin-Tits group, therefore providing an answer to another question of Dehornoy\net al. concerning $\\mathrm{I}_{B_n}$ structures where $B_n$ is the braid group\non $n$ strands with its canonical Garside structure.",
    "pdf_url": "http://arxiv.org/pdf/2505.13347v2",
    "published": "2025-05-19T16:50:52+00:00",
    "categories": [
      "math.GR",
      "math.RA",
      "06B99, 06F15, 20F36, 20N99"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13346v3",
    "title": "J4R: Learning to Judge with Equivalent Initial State Group Relative Policy Optimization",
    "authors": [
      "Austin Xu",
      "Yilun Zhou",
      "Xuan-Phi Nguyen",
      "Caiming Xiong",
      "Shafiq Joty"
    ],
    "abstract": "To keep pace with the increasing pace of large language models (LLM)\ndevelopment, model output evaluation has transitioned away from time-consuming\nhuman evaluation to automatic evaluation, where LLMs themselves are tasked with\nassessing and critiquing other model outputs. LLM-as-judge models are a class\nof generative evaluators that excel in evaluating relatively simple domains,\nlike chat quality, but struggle in reasoning intensive domains where model\nresponses contain more substantive and challenging content. To remedy existing\njudge shortcomings, we explore training judges with reinforcement learning\n(RL). We make three key contributions: (1) We propose the Equivalent Initial\nState Group Relative Policy Optimization (EIS-GRPO) algorithm, which allows us\nto train our judge to be robust to positional biases that arise in more complex\nevaluation settings. (2) We introduce ReasoningJudgeBench, a benchmark that\nevaluates judges in diverse reasoning settings not covered by prior work. (3)\nWe train Judge for Reasoning (J4R), a 7B judge trained with EIS-GRPO that\noutperforms GPT-4o and the next best small judge by 6.7% and 9%, matching or\nexceeding the performance of larger GRPO-trained judges on both JudgeBench and\nReasoningJudgeBench.",
    "pdf_url": "http://arxiv.org/pdf/2505.13346v3",
    "published": "2025-05-19T16:50:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13345v1",
    "title": "Occult: Optimizing Collaborative Communication across Experts for Accelerated Parallel MoE Training and Inference",
    "authors": [
      "Shuqing Luo",
      "Pingzhi Li",
      "Jie Peng",
      "Hanrui Wang",
      "Yang",
      "Zhao",
      "Yu",
      "Cao",
      "Yu Cheng",
      "Tianlong Chen"
    ],
    "abstract": "Mixture-of-experts (MoE) architectures could achieve impressive computational\nefficiency with expert parallelism, which relies heavily on all-to-all\ncommunication across devices. Unfortunately, such communication overhead\ntypically constitutes a significant portion of the total runtime, hampering the\nscalability of distributed training and inference for modern MoE models\n(consuming over $40\\%$ runtime in large-scale training). In this paper, we\nfirst define collaborative communication to illustrate this intrinsic\nlimitation, and then propose system- and algorithm-level innovations to reduce\ncommunication costs. Specifically, given a pair of experts co-activated by one\ntoken, we call them \"collaborated\", which comprises $2$ cases as intra- and\ninter-collaboration, depending on whether they are kept on the same device. Our\npilot investigations reveal that augmenting the proportion of\nintra-collaboration can accelerate expert parallelism at scale. It motivates us\nto strategically optimize collaborative communication for accelerated MoE\ntraining and inference, dubbed Occult. Our designs are capable of either\ndelivering exact results with reduced communication cost or controllably\nminimizing the cost with collaboration pruning, materialized by modified\nfine-tuning. Comprehensive experiments on various MoE-LLMs demonstrate that\nOccult can be faster than popular state-of-the-art inference or training\nframeworks (more than $1.5\\times$ speed up across multiple tasks and models)\nwith comparable or superior quality compared to the standard fine-tuning. Code\nis available at\n$\\href{https://github.com/UNITES-Lab/Occult}{https://github.com/UNITES-Lab/Occult}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.13345v1",
    "published": "2025-05-19T16:50:27+00:00",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13344v1",
    "title": "RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE Optimization on Diffusion Transformers",
    "authors": [
      "Ahmet Berke Gokmen",
      "Yigit Ekin",
      "Bahri Batuhan Bilecen",
      "Aysegul Dundar"
    ],
    "abstract": "We propose RoPECraft, a training-free video motion transfer method for\ndiffusion transformers that operates solely by modifying their rotary\npositional embeddings (RoPE). We first extract dense optical flow from a\nreference video, and utilize the resulting motion offsets to warp the\ncomplex-exponential tensors of RoPE, effectively encoding motion into the\ngeneration process. These embeddings are then further optimized during\ndenoising time steps via trajectory alignment between the predicted and target\nvelocities using a flow-matching objective. To keep the output faithful to the\ntext prompt and prevent duplicate generations, we incorporate a regularization\nterm based on the phase components of the reference video's Fourier transform,\nprojecting the phase angles onto a smooth manifold to suppress high-frequency\nartifacts. Experiments on benchmarks reveal that RoPECraft outperforms all\nrecently published methods, both qualitatively and quantitatively.",
    "pdf_url": "http://arxiv.org/pdf/2505.13344v1",
    "published": "2025-05-19T16:50:26+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13343v1",
    "title": "MRM3: Machine Readable ML Model Metadata",
    "authors": [
      "Andrej ƒåop",
      "Bla≈æ Bertalaniƒç",
      "Marko Grobelnik",
      "Carolina Fortuna"
    ],
    "abstract": "As the complexity and number of machine learning (ML) models grows,\nwell-documented ML models are essential for developers and companies to use or\nadapt them to their specific use cases. Model metadata, already present in\nunstructured format as model cards in online repositories such as Hugging Face,\ncould be more structured and machine readable while also incorporating\nenvironmental impact metrics such as energy consumption and carbon footprint.\nOur work extends the existing State of the Art by defining a structured schema\nfor ML model metadata focusing on machine-readable format and support for\nintegration into a knowledge graph (KG) for better organization and querying,\nenabling a wider set of use cases. Furthermore, we present an example wireless\nlocalization model metadata dataset consisting of 22 models trained on 4\ndatasets, integrated into a Neo4j-based KG with 113 nodes and 199 relations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13343v1",
    "published": "2025-05-19T16:50:00+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13342v1",
    "title": "Detect and Correct: A Selective Noise Correction Method for Learning with Noisy Labels",
    "authors": [
      "Yuval Grinberg",
      "Nimrod Harel",
      "Jacob Goldberger",
      "Ofir Lindenbaum"
    ],
    "abstract": "Falsely annotated samples, also known as noisy labels, can significantly harm\nthe performance of deep learning models. Two main approaches for learning with\nnoisy labels are global noise estimation and data filtering. Global noise\nestimation approximates the noise across the entire dataset using a noise\ntransition matrix, but it can unnecessarily adjust correct labels, leaving room\nfor local improvements. Data filtering, on the other hand, discards potentially\nnoisy samples but risks losing valuable data. Our method identifies potentially\nnoisy samples based on their loss distribution. We then apply a selection\nprocess to separate noisy and clean samples and learn a noise transition matrix\nto correct the loss for noisy samples while leaving the clean data unaffected,\nthereby improving the training process. Our approach ensures robust learning\nand enhanced model performance by preserving valuable information from noisy\nsamples and refining the correction process. We applied our method to standard\nimage datasets (MNIST, CIFAR-10, and CIFAR-100) and a biological scRNA-seq\ncell-type annotation dataset. We observed a significant improvement in model\naccuracy and robustness compared to traditional methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13342v1",
    "published": "2025-05-19T16:49:27+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13341v1",
    "title": "Starting Seatwork Earlier as a Valid Measure of Student Engagement",
    "authors": [
      "Ashish Gurung",
      "Jionghao Lin",
      "Zhongtian Huang",
      "Conrad Borchers",
      "Ryan S. Baker",
      "Vincent Aleven",
      "Kenneth R. Koedinger"
    ],
    "abstract": "Prior work has developed a range of automated measures (\"detectors\") of\nstudent self-regulation and engagement from student log data. These measures\nhave been successfully used to make discoveries about student learning. Here,\nwe extend this line of research to an underexplored aspect of self-regulation:\nstudents' decisions about when to start and stop working on learning software\nduring classwork. In the first of two analyses, we build on prior work on\nsession-level measures (e.g., delayed start, early stop) to evaluate their\nreliability and predictive validity. We compute these measures from year-long\nlog data from Cognitive Tutor for students in grades 8-12 (N = 222). Our\nfindings show that these measures exhibit moderate to high month-to-month\nreliability (G > .75), comparable to or exceeding gaming-the-system behavior.\nAdditionally, they enhance the prediction of final math scores beyond prior\nknowledge and gaming-the-system behaviors. The improvement in learning outcome\npredictions beyond time-on-task suggests they capture a broader motivational\nstate tied to overall learning. The second analysis demonstrates the\ncross-system generalizability of these measures in i-Ready, where they predict\nstate test scores for grade 7 students (N = 818). By leveraging log data, we\nintroduce system-general naturally embedded measures that complement\nmotivational surveys without extra instrumentation or disruption of instruction\ntime. Our findings demonstrate the potential of session-level logs to mine\nvalid and generalizable measures with broad applications in the predictive\nmodeling of learning outcomes and analysis of learner self-regulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13341v1",
    "published": "2025-05-19T16:49:08+00:00",
    "categories": [
      "cs.CY",
      "stat.AP"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13340v2",
    "title": "Limit distribution of the sample volume fraction of Boolean set",
    "authors": [
      "Hermine Bierm√©",
      "Olivier Durieu",
      "Donatas Surgailis"
    ],
    "abstract": "We study the limit distribution of the volume fraction estimator $\\widehat\np_{\\lambda, A}$ (= the Lebesgue measure of the intersection $\\mathcal{X}\\cap\n(\\lambda A)$ of a random set $\\mathcal{X}$ with a large observation set\n$\\lambda A$, divided by the Lebesgue measure of $\\lambda A$), as $\\lambda \\to\n\\infty$, for a Boolean set $\\mathcal{X}$ formed by uniformly scattered random\ngrains $\\Xi \\subset \\mathbb{R}^\\nu$. We obtain general conditions on generic\ngrain set $\\Xi$ under which $\\widehat p_{\\lambda, A}$ has an $\\alpha$-stable\nlimit distribution with index $1 < \\alpha \\le 2$. A large class of Boolean\nmodels with randomly homothetic grains satisfying these conditions is\nintroduced. We also discuss the limit distribution of the sample volume\nfraction of a Boolean set\n  observed on a large subset of a $\\nu_0$-dimensional $(1 \\le \\nu_0 \\le \\nu\n-1$) hyperplane of $\\mathbb{R}^\\nu$.",
    "pdf_url": "http://arxiv.org/pdf/2505.13340v2",
    "published": "2025-05-19T16:48:26+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13339v1",
    "title": "OPA-Pack: Object-Property-Aware Robotic Bin Packing",
    "authors": [
      "Jia-Hui Pan",
      "Yeok Tatt Cheah",
      "Zhengzhe Liu",
      "Ka-Hei Hui",
      "Xiaojie Gao",
      "Pheng-Ann Heng",
      "Yun-Hui Liu",
      "Chi-Wing Fu"
    ],
    "abstract": "Robotic bin packing aids in a wide range of real-world scenarios such as\ne-commerce and warehouses. Yet, existing works focus mainly on considering the\nshape of objects to optimize packing compactness and neglect object properties\nsuch as fragility, edibility, and chemistry that humans typically consider when\npacking objects. This paper presents OPA-Pack (Object-Property-Aware Packing\nframework), the first framework that equips the robot with object property\nconsiderations in planning the object packing. Technical-wise, we develop a\nnovel object property recognition scheme with retrieval-augmented generation\nand chain-of-thought reasoning, and build a dataset with object property\nannotations for 1,032 everyday objects. Also, we formulate OPA-Net, aiming to\njointly separate incompatible object pairs and reduce pressure on fragile\nobjects, while compacting the packing. Further, OPA-Net consists of a property\nembedding layer to encode the property of candidate objects to be packed,\ntogether with a fragility heightmap and an avoidance heightmap to keep track of\nthe packed objects. Then, we design a reward function and adopt a deep\nQ-learning scheme to train OPA-Net. Experimental results manifest that OPA-Pack\ngreatly improves the accuracy of separating incompatible object pairs (from 52%\nto 95%) and largely reduces pressure on fragile objects (by 29.4%), while\nmaintaining good packing compactness. Besides, we demonstrate the effectiveness\nof OPA-Pack on a real packing platform, showcasing its practicality in\nreal-world scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.13339v1",
    "published": "2025-05-19T16:48:14+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13338v2",
    "title": "Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation",
    "authors": [
      "Qiongqiong Wang",
      "Hardik B. Sailor",
      "Tianchi Liu",
      "Ai Ti Aw"
    ],
    "abstract": "Current speech-LLMs exhibit limited capability in contextual reasoning\nalongside paralinguistic understanding, primarily due to the lack of\nQuestion-Answer (QA) datasets that cover both aspects. We propose a novel\nframework for dataset generation from in-the-wild speech data, that integrates\ncontextual reasoning with paralinguistic information. It consists of a pseudo\nparalinguistic label-based data condensation of in-the-wild speech and\nLLM-based Contextual Paralinguistic QA (CPQA) generation. The effectiveness is\nvalidated by a strong correlation in evaluations of the Qwen2-Audio-7B-Instruct\nmodel on a dataset created by our framework and human-generated CPQA dataset.\nThe results also reveal the speech-LLM's limitations in handling empathetic\nreasoning tasks, highlighting the need for such datasets and more robust\nmodels. The proposed framework is first of its kind and has potential in\ntraining more robust speech-LLMs with paralinguistic reasoning capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.13338v2",
    "published": "2025-05-19T16:47:46+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13337v1",
    "title": "Neural-Enhanced Rate Adaptation and Computation Distribution for Emerging mmWave Multi-User 3D Video Streaming Systems",
    "authors": [
      "Babak Badnava",
      "Jacob Chakareski",
      "Morteza Hashemi"
    ],
    "abstract": "We investigate multitask edge-user communication-computation resource\nallocation for $360^\\circ$ video streaming in an edge-computing enabled\nmillimeter wave (mmWave) multi-user virtual reality system. To balance the\ncommunication-computation trade-offs that arise herein, we formulate a video\nquality maximization problem that integrates interdependent\nmultitask/multi-user action spaces and rebuffering time/quality variation\nconstraints. We formulate a deep reinforcement learning framework for\n\\underline{m}ulti-\\underline{t}ask \\underline{r}ate adaptation and\n\\underline{c}omputation distribution (MTRC) to solve the problem of interest.\nOur solution does not rely on a priori knowledge about the environment and uses\nonly prior video streaming statistics (e.g., throughput, decoding time, and\ntransmission delay), and content information, to adjust the assigned video\nbitrates and computation distribution, as it observes the induced streaming\nperformance online. Moreover, to capture the task interdependence in the\nenvironment, we leverage neural network cascades to extend our MTRC method to\ntwo novel variants denoted as R1C2 and C1R2. We train all three methods with\nreal-world mmWave network traces and $360^\\circ$ video datasets to evaluate\ntheir performance in terms of expected quality of experience (QoE), viewport\npeak signal-to-noise ratio (PSNR), rebuffering time, and quality variation. We\noutperform state-of-the-art rate adaptation algorithms, with C1R2 showing best\nresults and achieving $5.21-6.06$ dB PSNR gains, $2.18-2.70$x rebuffering time\nreduction, and $4.14-4.50$ dB quality variation reduction.",
    "pdf_url": "http://arxiv.org/pdf/2505.13337v1",
    "published": "2025-05-19T16:45:30+00:00",
    "categories": [
      "cs.IT",
      "cs.ET",
      "cs.MM",
      "cs.SY",
      "eess.SY",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13336v1",
    "title": "Breather solutions for semilinear wave equations",
    "authors": [
      "Julia Henninger",
      "Sebastian Ohrem",
      "Wolfgang Reichel"
    ],
    "abstract": "We prove existence of real-valued, time-periodic and spatially localized\nsolutions (breathers) of semilinear wave equations $V(x)u_{tt} - u_{xx} =\n\\Gamma(x) |u|^{p-1} u$ on $\\mathbb{R}^2$ for all values of $p\\in (1,\\infty)$.\nUsing tools from the calculus of variations our main result provides breathers\nas ground states of an indefinite functional under suitable conditions on $V,\n\\Gamma$ beyond the limitations of pure $x$-periodicity. Such an approach\nrequires a detailed analysis of the wave operator acting on time-periodic\nfunctions. Hence a generalization of the Floquet-Bloch theory for periodic\nSturm-Liouville operators is needed which applies to perturbed periodic\noperators. For this purpose we develop a suitable functional calculus for the\nweighted operator $-\\frac{1}{V(x)}\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2}$ with an\nexplicit control of its spectral measure. Based on this we prove embedding\ntheorems from the form domain of the wave operator into $L^q$-spaces, which is\nkey to controlling nonlinearities. We complement our existence theory with\nexplicit examples of coefficient functions $V$ and temporal periods $T$ which\nsupport breathers.",
    "pdf_url": "http://arxiv.org/pdf/2505.13336v1",
    "published": "2025-05-19T16:45:08+00:00",
    "categories": [
      "math.AP",
      "Primary: 35L71, 49J35, Secondary: 35B10, 34L05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13335v1",
    "title": "Scalable Importance Sampling in High Dimensions with Low-Rank Mixture Proposals",
    "authors": [
      "Liam A. Kruse",
      "Marc R. Schlichting",
      "Mykel J. Kochenderfer"
    ],
    "abstract": "Importance sampling is a Monte Carlo technique for efficiently estimating the\nlikelihood of rare events by biasing the sampling distribution towards the rare\nevent of interest. By drawing weighted samples from a learned proposal\ndistribution, importance sampling allows for more sample-efficient estimation\nof rare events or tails of distributions. A common choice of proposal density\nis a Gaussian mixture model (GMM). However, estimating full-rank GMM covariance\nmatrices in high dimensions is a challenging task due to numerical\ninstabilities. In this work, we propose using mixtures of probabilistic\nprincipal component analyzers (MPPCA) as the parametric proposal density for\nimportance sampling methods. MPPCA models are a type of low-rank mixture model\nthat can be fit quickly using expectation-maximization, even in\nhigh-dimensional spaces. We validate our method on three simulated systems,\ndemonstrating consistent gains in sample efficiency and quality of failure\ndistribution characterization.",
    "pdf_url": "http://arxiv.org/pdf/2505.13335v1",
    "published": "2025-05-19T16:44:48+00:00",
    "categories": [
      "stat.ML",
      "cs.RO"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.13334v1",
    "title": "Measuring Social Influence with Networked Synthetic Control",
    "authors": [
      "Ho-Chun Herbert Chang"
    ],
    "abstract": "Measuring social influence is difficult due to the lack of counter-factuals\nand comparisons. By combining machine learning-based modeling and network\nscience, we present general properties of social value, a recent measure for\nsocial influence using synthetic control applicable to political behavior.\nSocial value diverges from centrality measures on in that it relies on an\nexternal regressor to predict an output variable of interest, generates a\nsynthetic measure of influence, then distributes individual contribution based\non a social network. Through theoretical derivations, we show the properties of\nSV under linear regression with and without interaction, across lattice\nnetworks, power-law networks, and random graphs. A reduction in computation can\nbe achieved for any ensemble model. Through simulation, we find that the\ngeneralized friendship paradox holds -- that in certain situations, your\nfriends have on average more influence than you do.",
    "pdf_url": "http://arxiv.org/pdf/2505.13334v1",
    "published": "2025-05-19T16:44:46+00:00",
    "categories": [
      "cs.SI",
      "cs.LG"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13333v1",
    "title": "FAUST XXV. A potential new molecular outflow in [BHB2007] 11",
    "authors": [
      "A. Mart√≠nez-Henares",
      "I. Jim√©nez-Serra",
      "C. Vastel",
      "T. Sakai",
      "L. Evans",
      "J. E. Pineda",
      "M. J. Maureira",
      "E. Bianchi",
      "C. J. Chandler",
      "C. Codella",
      "M. De Simone",
      "L. Podio",
      "G. Sabatini",
      "Y. Aikawa",
      "F. O. Alves",
      "M. Bouvier",
      "P. Caselli",
      "C. Ceccarelli",
      "N. Cuello",
      "F. Fontani",
      "T. Hanawa",
      "D. Johnstone",
      "L. Loinard",
      "G. Moellenbrock",
      "S. Ohashi",
      "N. Sakai",
      "D. Segura-Cox",
      "B. Svoboda",
      "S. Yamamoto"
    ],
    "abstract": "During the early stages of star formation, accretion processes such as infall\nfrom the envelope and molecular streamers, and ejection of matter through winds\nand jets take place simultaneously. The Class 0/I binary [BHB2007] 11 shows\nevidence for accretion and ejection at the scales of the circumbinary disk and\nthe inner close binary. Recent H$_2$CO observations showed two elongated\nstructures with hints of outflowing motion almost perpendicular to the main CO\noutflow, which is launched from the circumbinary disk. With the aim of\nverifying the nature of these elongated structures, we analyze the line\nemission of H$^{13}$CO$^+$, CCH, c-C$_3$H$_2$ and SiO observed with ALMA within\nthe Large Program FAUST. These molecules trace material moving at velocities\nclose to the ambient cloud velocity. The images of H$^{13}$CO$^+$, CCH,\nc-C$_3$H$_2$ show the elongated structures, whose gas kinematics are consistent\nwith outflowing motions and with rotation in the opposite sense to the main CO\noutflow. The derived mass loss rate from these large-scale structures is\n$(1.8\\pm0.5)\\times10^{-6}M_{\\odot}\\textrm{ yr}^{-1}$, in agreement with those\nmeasured in outflows driven by Class 0/I protostars. The SiO image reveals\ncompact emission close to the binary system, with a slight elongation aligned\nwith the larger-scale structures. This suggests that SiO is released from the\nsputtering of dust grains in the shocked material at the base of the potential\nnew outflow, with a relative abundance of $\\geq(0.11-2.0)\\times10^{-9}$.\nHowever, higher angular and spectral resolution observations are needed to\naccurately estimate the outflow launching radius and its powering source. Given\nthe location and the abundance of the SiO emission, we propose that the second\noutflow may be launched from inside the circumbinary disk, likely by the less\nmassive companion, which is actively accreting material from its surroundings.",
    "pdf_url": "http://arxiv.org/pdf/2505.13333v1",
    "published": "2025-05-19T16:44:45+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13332v1",
    "title": "Monoidal categorification of genus zero skein algebras",
    "authors": [
      "Dylan G. L. Allegretti",
      "Hyun Kyu Kim",
      "Peng Shan"
    ],
    "abstract": "We prove a conjecture of the first and third named authors relating the\nKauffman bracket skein algebra of a genus zero surface with boundary to a\nquantized $K$-theoretic Coulomb branch. As a consequence, we see that our skein\nalgebra arises as the Grothendieck ring of the bounded derived category of\nequivariant coherent sheaves on the Braverman-Finkelberg-Nakajima variety of\ntriples with monoidal structure defined by the convolution product. We thus\ngive a monoidal categorification of the skein algebra, partially answering a\nquestion posed by D. Thurston.",
    "pdf_url": "http://arxiv.org/pdf/2505.13332v1",
    "published": "2025-05-19T16:44:26+00:00",
    "categories": [
      "math.RT",
      "hep-th",
      "math.GT",
      "math.QA"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13331v1",
    "title": "Learning Driven Elastic Task Multi-Connectivity Immersive Computing Systems",
    "authors": [
      "Babak Badnava",
      "Jacob Chakareski",
      "Morteza Hashemi"
    ],
    "abstract": "In virtual reality (VR) environments, computational tasks exhibit an elastic\nnature, meaning they can dynamically adjust based on various user and system\nconstraints. This elasticity is essential for maintaining immersive\nexperiences; however, it also introduces challenges for communication and\ncomputing in VR systems. In this paper, we investigate elastic task offloading\nfor multi-user edge-computing-enabled VR systems with multi-connectivity,\naiming to maximize the computational energy-efficiency (computational\nthroughput per unit of energy consumed). To balance the induced communication,\ncomputation, energy consumption, and quality of experience trade-offs due to\nthe elasticity of VR tasks, we formulate a constrained stochastic computational\nenergy-efficiency optimization problem that integrates the\nmulti-connectivity/multi-user action space and the elastic nature of VR\ncomputational tasks. We formulate a centralized phasic policy gradient (CPPG)\nframework to solve the problem of interest online, using only prior elastic\ntask offloading statistics (energy consumption, response time, and transmission\ntime), and task information (i.e., task size and computational intensity),\nwhile observing the induced system performance (energy consumption and\nlatency). We further extend our approach to decentralized learning by\nformulating an independent phasic policy gradient (IPPG) method and a\ndecentralized shared multi-armed bandit (DSMAB) method. We train our methods\nwith real-world 4G, 5G, and WiGig network traces and 360 video datasets to\nevaluate their performance in terms of response time, energy efficiency,\nscalability, and delivered quality of experience. We also provide a\ncomprehensive analysis of task size and its effect on offloading policy and\nsystem performance. In particular, we show that CPPG reduces latency by 28% and\nenergy consumption by 78% compared to IPPG.",
    "pdf_url": "http://arxiv.org/pdf/2505.13331v1",
    "published": "2025-05-19T16:44:02+00:00",
    "categories": [
      "cs.NI",
      "cs.ET",
      "cs.MM",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13330v1",
    "title": "Ionic strength-driven cavitation nucleation: from energy deposition-based to tension-based cavitation",
    "authors": [
      "Junhao Cai",
      "Yuhan Li",
      "Yunqiao Liu",
      "Benlong Wang",
      "Mingbo Li"
    ],
    "abstract": "In this work, we present a unified experimental and simulation investigation\nof cavitation in aqueous electrolyte solutions, combining nanosecond\nlaser-induced optical breakdown and all-atom molecular dynamics (MD)\nsimulations under tensile stress. Across both cavitation scenarios, we find\nthat cavitation inception and intensity (bubble nucleation count,\ncavitation-zone length, vapor-volume fraction) are governed by ionic strength\nalone, with negligible dependence on the ion species. In laser experiments,\nincreasing ionic strength lowers the breakdown threshold and amplifies bubble\ngeneration by supplying extra seed electrons for inverse Bremsstrahlung-driven\navalanche ionization. We elucidate the mechanism of action of the ionic\nstrength through the MD simulations, which essentially quantifies the net\ncharge density in the bulk, and thus its combined influence on the generation\nof seed electrons and the perturbation of the hydration network. These findings\nidentify ionic strength serving as a unifying parameter controlling cavitation\nin electrolyte solutions: whether driven by rapid energy deposition or by\ntensile stress imposed.",
    "pdf_url": "http://arxiv.org/pdf/2505.13330v1",
    "published": "2025-05-19T16:42:39+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.13583v2",
    "title": "Physiological and Transcriptional Responses of Arabidopsis thaliana to Simulated Lunar and Martian Regolith Substrates",
    "authors": [
      "A'nya Buckner",
      "Sarah Lang",
      "Rafael Loureiro"
    ],
    "abstract": "The integration of plant-based bioregenerative life support systems is a\ncentral objective in NASA's Moon to Mars strategy. Arabidopsis thaliana, a\nmodel organism with extensive genomic resources, serves as a key species to\ninvestigate plant resilience in extraterrestrial environments. We assessed the\nphysiological and gene expression responses of A. thaliana (Col-0) grown in two\noff-world regolith simulants: LHS-2 (lunar highlands) and MGS-1 (Martian\nglobal). Plants exposed to these substrates exhibited significant reductions in\nroot elongation, biomass, and chlorophyll content, along with elevated\nanthocyanin levels and transcriptional upregulation of stress-related genes\nincluding IRT1, PCS1, SOD1, and JAZ1. Evidence of jasmonic acid pathway\nactivation and auxin signaling suppression suggests metal-induced hormonal\nmisregulation. Our integrated analysis of morphological traits, pigment\naccumulation, and transcriptomic profiles reveals distinct mineral-specific\nstress responses, offering critical insights into substrate engineering\nstrategies for future space agriculture.",
    "pdf_url": "http://arxiv.org/pdf/2505.13583v2",
    "published": "2025-05-19T16:40:43+00:00",
    "categories": [
      "q-bio.QM"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.13329v1",
    "title": "Recommender Systems for Democracy: Toward Adversarial Robustness in Voting Advice Applications",
    "authors": [
      "Fr√©d√©ric Berdoz",
      "Dustin Brunner",
      "Yann Vonlanthen",
      "Roger Wattenhofer"
    ],
    "abstract": "Voting advice applications (VAAs) help millions of voters understand which\npolitical parties or candidates best align with their views. This paper\nexplores the potential risks these applications pose to the democratic process\nwhen targeted by adversarial entities. In particular, we expose 11 manipulation\nstrategies and measure their impact using data from Switzerland's primary VAA,\nSmartvote, collected during the last two national elections. We find that\naltering application parameters, such as the matching method, can shift a\nparty's recommendation frequency by up to 105%. Cherry-picking questionnaire\nitems can increase party recommendation frequency by over 261%, while subtle\nchanges to parties' or candidates' responses can lead to a 248% increase. To\naddress these vulnerabilities, we propose adversarial robustness properties\nVAAs should satisfy, introduce empirical metrics for assessing the resilience\nof various matching methods, and suggest possible avenues for research toward\nmitigating the effect of manipulation. Our framework is key to ensuring secure\nand reliable AI-based VAAs poised to emerge in the near future.",
    "pdf_url": "http://arxiv.org/pdf/2505.13329v1",
    "published": "2025-05-19T16:38:06+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13328v1",
    "title": "Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges",
    "authors": [
      "Hongru Wang",
      "Wenyu Huang",
      "Yufei Wang",
      "Yuanhao Xi",
      "Jianqiao Lu",
      "Huan Zhang",
      "Nan Hu",
      "Zeming Liu",
      "Jeff Z. Pan",
      "Kam-Fai Wong"
    ],
    "abstract": "Existing benchmarks that assess Language Models (LMs) as Language Agents\n(LAs) for tool use primarily focus on stateless, single-turn interactions or\npartial evaluations, such as tool selection in a single turn, overlooking the\ninherent stateful nature of interactions in multi-turn applications. To fulfill\nthis gap, we propose \\texttt{DialogTool}, a multi-turn dialogue dataset with\nstateful tool interactions considering the whole life cycle of tool use, across\nsix key tasks in three stages: 1) \\textit{tool creation}; 2) \\textit{tool\nutilization}: tool awareness, tool selection, tool execution; and 3)\n\\textit{role-consistent response}: response generation and role play.\nFurthermore, we build \\texttt{VirtualMobile} -- an embodied virtual mobile\nevaluation environment to simulate API calls and assess the robustness of the\ncreated APIs\\footnote{We will use tools and APIs alternatively, there are no\nsignificant differences between them in this paper.}. Taking advantage of these\nartifacts, we conduct comprehensive evaluation on 13 distinct open- and\nclosed-source LLMs and provide detailed analysis at each stage, revealing that\nthe existing state-of-the-art LLMs still cannot perform well to use tools over\nlong horizons.",
    "pdf_url": "http://arxiv.org/pdf/2505.13328v1",
    "published": "2025-05-19T16:36:13+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13327v3",
    "title": "Benchmarking Unified Face Attack Detection via Hierarchical Prompt Tuning",
    "authors": [
      "Ajian Liu",
      "Haocheng Yuan",
      "Xiao Guo",
      "Hui Ma",
      "Wanyi Zhuang",
      "Changtao Miao",
      "Yan Hong",
      "Chuanbiao Song",
      "Jun Lan",
      "Qi Chu",
      "Tao Gong",
      "Yanyan Liang",
      "Weiqiang Wang",
      "Jun Wan",
      "Xiaoming Liu",
      "Zhen Lei"
    ],
    "abstract": "PAD and FFD are proposed to protect face data from physical media-based\nPresentation Attacks and digital editing-based DeepFakes, respectively.\nHowever, isolated training of these two models significantly increases\nvulnerability towards unknown attacks, burdening deployment environments. The\nlack of a Unified Face Attack Detection model to simultaneously handle attacks\nin these two categories is mainly attributed to two factors: (1) A benchmark\nthat is sufficient for models to explore is lacking. Existing UAD datasets only\ncontain limited attack types and samples, leading to the model's confined\nability to address abundant advanced threats. In light of these, through an\nexplainable hierarchical way, we propose the most extensive and sophisticated\ncollection of forgery techniques available to date, namely UniAttackDataPlus.\nOur UniAttackData+ encompasses 2,875 identities and their 54 kinds of\ncorresponding falsified samples, in a total of 697,347 videos. (2) The absence\nof a trustworthy classification criterion. Current methods endeavor to explore\nan arbitrary criterion within the same semantic space, which fails to exist\nwhen encountering diverse attacks. Thus, we present a novel Visual-Language\nModel-based Hierarchical Prompt Tuning Framework that adaptively explores\nmultiple classification criteria from different semantic spaces. Specifically,\nwe construct a VP-Tree to explore various classification rules hierarchically.\nThen, by adaptively pruning the prompts, the model can select the most suitable\nprompts guiding the encoder to extract discriminative features at different\nlevels in a coarse-to-fine manner. Finally, to help the model understand the\nclassification criteria in visual space, we propose a DPI module to project the\nvisual prompts to the text encoder to help obtain a more accurate semantics.",
    "pdf_url": "http://arxiv.org/pdf/2505.13327v3",
    "published": "2025-05-19T16:35:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13326v1",
    "title": "Thinking Short and Right Over Thinking Long: Serving LLM Reasoning Efficiently and Accurately",
    "authors": [
      "Yuhang Wang",
      "Youhe Jiang",
      "Bin Cui",
      "Fangcheng Fu"
    ],
    "abstract": "Recent advances in test-time scaling suggest that Large Language Models\n(LLMs) can gain better capabilities by generating Chain-of-Thought reasoning\n(analogous to human thinking) to respond a given request, and meanwhile\nexploring more reasoning branches (i.e., generating multiple responses and\nensembling them) can improve the final output quality. However, when\nincorporating the two scaling dimensions, we find that the system efficiency is\ndampened significantly for two reasons. Firstly, the time cost to generate the\nfinal output increases substantially as many reasoning branches would be\ntrapped in the over-thinking dilemma, producing excessively long responses.\nSecondly, generating multiple reasoning branches for each request increases\nmemory consumption, which is unsuitable for LLM serving since we can only batch\na limited number of requests to process simultaneously. To address this, we\npresent SART, a serving framework for efficient and accurate LLM reasoning. The\nessential idea is to manage the thinking to be short and right, rather than\nlong. For one thing, we devise a redundant sampling with early stopping\napproach based on empirical observations and theoretic analysis, which\nincreases the likelihood of obtaining short-thinking responses when sampling\nreasoning branches. For another, we propose to dynamically prune low-quality\nbranches so that only right-thinking branches are maintained, reducing the\nmemory consumption and allowing us to batch more requests. Experimental results\ndemonstrate that SART not only improves the accuracy of LLM reasoning but also\nenhances the serving efficiency, outperforming existing methods by up to 28.2\ntimes and on average 15.7 times in terms of efficiency when achieving the same\nlevel of accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.13326v1",
    "published": "2025-05-19T16:34:56+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13325v2",
    "title": "Discretion in the Loop: Human Expertise in Algorithm-Assisted College Advising",
    "authors": [
      "Kara Schechtman",
      "Benjamin Brandon",
      "Jenise Stafford",
      "Hannah Li",
      "Lydia T. Liu"
    ],
    "abstract": "In higher education, many institutions use algorithmic alerts to flag at-risk\nstudents and deliver advising at scale. While much research has focused on\nevaluating algorithmic predictions, relatively little is known about how\ndiscretionary interventions by human experts shape outcomes in\nalgorithm-assisted settings. We study this question using rich quantitative and\nqualitative data from a randomized controlled trial of an algorithm-assisted\nadvising program at Georgia State University. Taking a mixed-methods approach,\nwe examine whether and how advisors use context unavailable to an algorithm to\nguide interventions and influence student success. We develop a causal\ngraphical framework for human expertise in the interventional setting,\nextending prior work on discretion in purely predictive settings. We then test\na necessary condition for discretionary expertise using structured advisor logs\nand student outcomes data, identifying several interventions that meet the\ncriterion for statistical significance. Accordingly, we estimate that 2 out of\n3 interventions taken by advisors in the treatment arm were plausibly \"expertly\ntargeted\" to students using non-algorithmic context. Systematic qualitative\nanalysis of advisor notes corroborates these findings, showing a pattern of\nadvisors incorporating diverse forms of contextual information--such as\npersonal circumstances, financial issues, and student engagement--into their\ndecisions. Our results offer theoretical and practical insight into the\nreal-world effectiveness of algorithm-supported college advising, and\nunderscore the importance of accounting for human expertise in the design,\nevaluation, and implementation of algorithmic decision systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13325v2",
    "published": "2025-05-19T16:34:40+00:00",
    "categories": [
      "cs.CY",
      "stat.AP",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13324v1",
    "title": "From What Ifs to Insights: Counterfactuals in Causal Inference vs. Explainable AI",
    "authors": [
      "Galit Shmueli",
      "David Martens",
      "Jaewon Yoo",
      "Travis Greene"
    ],
    "abstract": "Counterfactuals play a pivotal role in the two distinct data science fields\nof causal inference (CI) and explainable artificial intelligence (XAI). While\nthe core idea behind counterfactuals remains the same in both fields--the\nexamination of what would have happened under different circumstances--there\nare key differences in how they are used and interpreted. We introduce a formal\ndefinition that encompasses the multi-faceted concept of the counterfactual in\nCI and XAI. We then discuss how counterfactuals are used, evaluated, generated,\nand operationalized in CI vs. XAI, highlighting conceptual and practical\ndifferences. By comparing and contrasting the two, we hope to identify\nopportunities for cross-fertilization across CI and XAI.",
    "pdf_url": "http://arxiv.org/pdf/2505.13324v1",
    "published": "2025-05-19T16:34:36+00:00",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "econ.EM",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.13323v2",
    "title": "Probing the $Œõ_{b}\\to Œõ_{c}^{*}œÑ\\barŒΩ_œÑ$ decays with leptoquarks",
    "authors": [
      "C P Haritha",
      "Karthik Jain",
      "Barilang Mawlong"
    ],
    "abstract": "The extension of the standard model to include a single scalar or vector\nleptoquark has been shown to account for the observed deviations in the lepton\nflavor universality ratios in the $b \\to c \\ell \\nu_{\\ell}$ and $b \\to s \\ell\n\\ell$ transitions. Exploring new physics in the $b \\to c \\tau \\nu_{\\tau}$\ndecays, in this work we analyze the baryonic decay channels $\\Lambda_b \\to\n\\Lambda_{c}^{*}(2595,2625) \\tau^- \\bar{\\nu}_\\tau$ beyond the standard model.\nSpecifically, we investigate the role of leptoquarks in these decays, focusing\non the $U_1$ vector leptoquark and the $S_1$ scalar leptoquark. Employing\nrecent lattice QCD results for the $\\Lambda_b \\to \\Lambda_{c}^{*}$ form\nfactors, the helicity amplitudes for all possible four-fermion interactions are\nworked out explicitly and presented here. Utilizing the current $b \\to c \\ell\n\\nu_{\\ell}$ experimental data, we impose constraints on the leptoquark\ncouplings and test new physics sensitivity of various observables for the decay\nprocesses under consideration. Our analysis demonstrates the significance of\ntesting the lepton flavor universality ratio $R_{\\Lambda_{c}^{*}}$ as it is\nobserved to be particularly sensitive to these leptoquarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13323v2",
    "published": "2025-05-19T16:34:08+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13322v1",
    "title": "Differential smoothness of bi-quadratic algebras with PBW basis",
    "authors": [
      "Andr√©s Rubiano",
      "Armando Reyes"
    ],
    "abstract": "We investigate the differential smoothness of bi-quadratic algebras with PBW\nbasis.",
    "pdf_url": "http://arxiv.org/pdf/2505.13322v1",
    "published": "2025-05-19T16:33:28+00:00",
    "categories": [
      "math.DG",
      "math.QA",
      "math.RA",
      "16E45, 16S30, 16S32, 16S36, 16S38, 16S99, 16T05, 58B34"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13321v2",
    "title": "First Nucleon Gluon PDF from Large Momentum Effective Theory",
    "authors": [
      "William Good",
      "Fei Yao",
      "Huey-Wen Lin"
    ],
    "abstract": "We report the first nucleon gluon parton distribution function (PDF) using\nLarge-Momentum Effective Theory (LaMET). We focus on the gluon operator which\nwas demonstrated to have the best signal-to-noise in the previous attempt [1]\nin computing gluon PDFs using LaMET. We compute the corresponding Wilson\ncoefficients needed for the hybrid-renormalized matrix elements and the\nmatching kernel to convert the quasi-PDF to the lightcone one at the one-loop\nlevel. We demonstrate that with the proper Wilson coefficients in place, the\ncounterterms for the renormalization are independent of the hadron and mass\nwithin statistical error. Using the resulting renormalization, we then compute\nthe nucleon PDF using a HISQ ensemble generated by the MILC collaboration with\n$N_f=2+1+1$, $a \\approx 0.12$ fm, with valence pion masses of 310 and 690 MeV\nand two gauge link smearing techniques. Despite the physics effects of the\nheavier than physical pion masses and gauge link smearing, this calculation\nprovides excellent proof of principle and compares reasonably with selected\nglobal fit results.",
    "pdf_url": "http://arxiv.org/pdf/2505.13321v2",
    "published": "2025-05-19T16:32:53+00:00",
    "categories": [
      "hep-lat",
      "hep-ph"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2505.13320v1",
    "title": "Semi-analytical solutions of passive scalar transport in generalized Newtonian fluid flow",
    "authors": [
      "Christopher A. Bowers",
      "Cass T. Miller"
    ],
    "abstract": "Transport during flow of generalized Newtonian fluids (GNFs) appears often in\nsystems that can be treated in a simplified form as either cylindrical tubes or\nslit openings between parallel plates. Based on the pioneering work of Taylor,\nanalytical solutions for transport in these simplified systems were derived\ngenerally. This includes analytical solutions for advection dominated\ntransport, as well as a computation of the enhanced molecular diffusion\ncoefficient in low Peclet number systems. The newly derived general solutions\nfor species transport were applied to Cross and Carreau model fluids using a\nsemi-analytical solution for velocity of these fluids. The semi-analytical\nsolutions derived herein were compared to microscale simulations and showed\nagreement to within the numerical error of those simulations. The\nsemi-analytical transport solutions derived here were developed without\nassuming any specific fluid rheology, thus these solutions can be applied to\nother non-Newtonian fluids, such as viscoelastic or viscoplastic fluids, as a\nstraightforward extension of this work.",
    "pdf_url": "http://arxiv.org/pdf/2505.13320v1",
    "published": "2025-05-19T16:30:28+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.13319v2",
    "title": "SVAFD: A Secure and Verifiable Co-Aggregation Protocol for Federated Distillation",
    "authors": [
      "Tian Wen",
      "Sheng Sun",
      "Yuwei Wang",
      "Peiyan Chen",
      "Zhiyuan Wu",
      "Min Liu",
      "Bo Gao"
    ],
    "abstract": "Secure Aggregation (SA) is an indispensable component of Federated Learning\n(FL) that concentrates on privacy preservation while allowing for robust\naggregation. However, most SA designs rely heavily on the unrealistic\nassumption of homogeneous model architectures. Federated Distillation (FD),\nwhich aggregates locally computed logits instead of model parameters,\nintroduces a promising alternative for cooperative training in heterogeneous\nmodel settings. Nevertheless, we recognize two major challenges in implementing\nSA for FD. (i) Prior SA designs encourage a dominant server, who is solely\nresponsible for collecting, aggregating and distributing. Such central\nauthority facilitates server to forge aggregation proofs or collude to bypass\nthe claimed security guarantees; (ii) Existing SA, tailored for FL models,\noverlook the intrinsic properties of logits, making them unsuitable for FD.\n  To address these challenges, we propose SVAFD, the first SA protocol that is\nspecifically designed for FD. At a high level, SVAFD incorporates two\ninnovations: (i) a multilateral co-aggregation method tha redefines the\nresponsibilities of clients and server. Clients autonomously evaluate and\naggregate logits shares locally with a lightweight coding scheme, while the\nserver handles ciphertext decoding and performs the task of generating\nverification proofs; (ii) a quality-aware knowledge filtration method that\nfacilitates biased logits exclusion against poisoning attacks. Moreover, SVAFD\nis resilient to stragglers and colluding clients, making it well-suited for\ndynamic networks in real-world applications. We have implemented the SVAFD\nprototype over four emerging FD architectures and evaluated it against\npoisoning and inference attacks. Results demonstrate that SVAFD improves model\naccuracy, making it a significant step forward in secure and verifiable\naggregation for heterogeneous FL systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13319v2",
    "published": "2025-05-19T16:30:27+00:00",
    "categories": [
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13318v2",
    "title": "VesselGPT: Autoregressive Modeling of Vascular Geometry",
    "authors": [
      "Paula Feldman",
      "Martin Sinnona",
      "Claudio Delrieux",
      "Viviana Siless",
      "Emmanuel Iarussi"
    ],
    "abstract": "Anatomical trees are critical for clinical diagnosis and treatment planning,\nyet their complex and diverse geometry make accurate representation a\nsignificant challenge. Motivated by the latest advances in large language\nmodels, we introduce an autoregressive method for synthesizing anatomical\ntrees. Our approach first embeds vessel structures into a learned discrete\nvocabulary using a VQ-VAE architecture, then models their generation\nautoregressively with a GPT-2 model. This method effectively captures intricate\ngeometries and branching patterns, enabling realistic vascular tree synthesis.\nComprehensive qualitative and quantitative evaluations reveal that our\ntechnique achieves high-fidelity tree reconstruction with compact discrete\nrepresentations. Moreover, our B-spline representation of vessel cross-sections\npreserves critical morphological details that are often overlooked in previous'\nmethods parameterizations. To the best of our knowledge, this work is the first\nto generate blood vessels in an autoregressive manner. Code is available at\nhttps://github.com/LIA-DiTella/VesselGPT-MICCAI.",
    "pdf_url": "http://arxiv.org/pdf/2505.13318v2",
    "published": "2025-05-19T16:30:26+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13317v3",
    "title": "Unlabeled Data or Pre-trained Model: Rethinking Semi-Supervised Learning and Pretrain-Finetuning",
    "authors": [
      "Song-Lin Lv",
      "Rui Zhu",
      "Yu-Feng Li",
      "Lan-Zhe Guo"
    ],
    "abstract": "Semi-supervised learning (SSL) alleviates the cost of data labeling process\nby exploiting unlabeled data, and has achieved promising results on various\ntasks such as image classification. Meanwhile, the Pretrain-Finetuning paradigm\nhas garnered significant attention in recent years, and exploiting pre-trained\nmodels could also reduce the requirement of labeled data in downstream tasks.\nTherefore, a question naturally occurs: \\emph{When the labeled data is scarce\nin the target tasks, should we exploit unlabeled data or pre-trained models?}\nTo answer this question, we select pre-trained Vision-Language Models (VLMs) as\nrepresentative pretrain-finetuning instances and propose \\textit{Few-shot SSL}\n-- a framework that enables fair comparison between these two paradigms by\ncontrolling the amount of labeled data used. Extensive experiments across\nvarious settings demonstrate that pre-trained VLMs generally outperform SSL\nmethods in nearly all cases, except when the data has low resolution or lacks\nclear semantic structure. Therefore, we encourage future SSL research to\ncompare with pre-trained models and explore deeper integration, such as using\npre-trained knowledge to enhance pseudo-labeling. To support future research,\nwe release our unified reproduction and evaluation framework. Codes are\navailable\n\\href{https://anonymous.4open.science/r/Rethinking-SSL-and-Pretrain-Finetuning-5566\n}{here}.",
    "pdf_url": "http://arxiv.org/pdf/2505.13317v3",
    "published": "2025-05-19T16:29:20+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13316v1",
    "title": "Denoising Diffusion Probabilistic Model for Point Cloud Compression at Low Bit-Rates",
    "authors": [
      "Gabriele Spadaro",
      "Alberto Presta",
      "Jhony H. Giraldo",
      "Marco Grangetto",
      "Wei Hu",
      "Giuseppe Valenzise",
      "Attilio Fiandrotti",
      "Enzo Tartaglione"
    ],
    "abstract": "Efficient compression of low-bit-rate point clouds is critical for\nbandwidth-constrained applications. However, existing techniques mainly focus\non high-fidelity reconstruction, requiring many bits for compression. This\npaper proposes a \"Denoising Diffusion Probabilistic Model\" (DDPM) architecture\nfor point cloud compression (DDPM-PCC) at low bit-rates. A PointNet encoder\nproduces the condition vector for the generation, which is then quantized via a\nlearnable vector quantizer. This configuration allows to achieve a low bitrates\nwhile preserving quality. Experiments on ShapeNet and ModelNet40 show improved\nrate-distortion at low rates compared to standardized and state-of-the-art\napproaches. We publicly released the code at\nhttps://github.com/EIDOSLAB/DDPM-PCC.",
    "pdf_url": "http://arxiv.org/pdf/2505.13316v1",
    "published": "2025-05-19T16:29:12+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13315v2",
    "title": "KHRONOS: a Kernel-Based Neural Architecture for Rapid, Resource-Efficient Scientific Computation",
    "authors": [
      "Reza T. Batley",
      "Sourav Saha"
    ],
    "abstract": "Contemporary models of high dimensional physical systems are constrained by\nthe curse of dimensionality and a reliance on dense data. We introduce KHRONOS\n(Kernel Expansion Hierarchy for Reduced Order, Neural Optimized Surrogates), an\nAI framework for model based, model free and model inversion tasks. KHRONOS\nconstructs continuously differentiable target fields with a hierarchical\ncomposition of per-dimension kernel expansions, which are tensorized into modes\nand then superposed. We evaluate KHRONOS on a canonical 2D, Poisson equation\nbenchmark: across 16 to 512 degrees of freedom (DoFs), it obtained L_2-square\nerrors of 5e-4 down to 6e-11. This represents a greater than 100-fold gain over\nKolmogorov Arnold Networks (which itself reports a 100 times improvement on\nMLPs/PINNs with 100 times fewer parameters) when controlling for the number of\nparameters. This also represents a 1e6-fold improvement in L_2-square error\ncompared to standard linear FEM at comparable DoFs. Inference complexity is\ndominated by inner products, yielding sub-millisecond full-field predictions\nthat scale to an arbitrary resolution. For inverse problems, KHRONOS\nfacilitates rapid, iterative level set recovery in only a few forward\nevaluations, with sub-microsecond per sample latency. KHRONOS's scalability,\nexpressivity, and interpretability open new avenues in constrained edge\ncomputing, online control, computer vision, and beyond.",
    "pdf_url": "http://arxiv.org/pdf/2505.13315v2",
    "published": "2025-05-19T16:29:07+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13314v1",
    "title": "A Simultaneous Self And Base Station Positioning via Resonant beam for Extensible System",
    "authors": [
      "Guangkun Zhang",
      "Wen Fang",
      "Mingliang Xiong",
      "Qingwen Liu",
      "Mengyuan Xu",
      "Yunfeng Bai",
      "Mingqing Liu",
      "Siyuan Du"
    ],
    "abstract": "High-precision positioning in GPS-denied environments is a demanding but\nchallenging technology. Resonant Beam Positioning (RBP) utilizes a resonant\nbeam with properties such as energy focusing, self-establishment,\nself-alignment, and passive operation, offering a promising solution for this\ntask. However, traditional RBP algorithms require a fixed number of resonant\nbeam base stations, which can be costly to expand to increase coverage. To\naddress this limitation, we propose a distributed resonant beam positioning\n(DRBP) system that simultaneously estimates the base station and mobile target\n(MT) positions. The MT receives resonant beam samples to locate the base\nstation in this system. Subsequently, it estimates self-position based on the\nknown locations of the base stations. The DRBP system facilitates\nself-positioning on the MT side, enabling dynamic expansion of both the number\nof base stations and the coverage area. Numerical results demonstrate that DRBP\nachieves a positioning root mean square error (RMSE) of $0.1$ m and a rotation\nRMSE of 2$^\\circ$, validating the system's high accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.13314v1",
    "published": "2025-05-19T16:28:53+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.13313v2",
    "title": "Early Post Asymptotic Giant Branch Instability: Does it Affect White Dwarf Hydrogen Envelope Mass?",
    "authors": [
      "James MacDonald"
    ],
    "abstract": "Although most white dwarf stars have hydrogen-dominated atmospheres, a\nsignificant fraction have atmospheres in which hydrogen is spectroscopically\nabsent, with the fraction of hydrogen-free atmospheres varying with effective\ntemperature. Estimates of the total mass of hydrogen, MH, in the stellar\nenvelope from either asteroseismology or spectral evolution are at odds with\npredicted values from theoretical stellar evolution modeling. Recent work has\nfound that models in the early post Asymptotic Giant Branch (AGB) phase of\nevolution can exhibit thermally and dynamical unstable behavior. Here we\ninvestigate whether this Early Post AGB Instability (EPAGBI) can help resolve\nthe conflict in MH values determined from white dwarf spectral evolution,\nanalysis of DAV pulsations and canonical stellar evolution modeling, by\nevolving models of mass 1 and 2Msun through the AGB phases and to the white\ndwarf cooling track. The MH values at the end of the calculations are in the\nrange consistent with asteroseismic determinations. The major impact of EPAGBIs\nis that they cause loops in the HRD, which are absent when the EPAGBI is\nsuppressed. Such loops might be detectable in a long-term monitoring program,\nor by their imprint on planetary nebula morphology imparted by the cyclically\nvarying mass loss rate. Since the characteristic timescale of the looping in\nthe HRD depends on the stellar mass, it could provide a way to determine the\nstellar mass just after AGB departure. Another EPAGBI signature is the\nproduction of Li by the Cameron-Fowler process. During the EPAGBI phase the\nphotospheric temperature is always too high for the Li I resonance line to be\ndetected. However, 7Be is convected to the photosphere in significant amounts\n(up to 400 times the solar photospheric mass fraction) at various times in the\nEPAGBI phase, which may be detectable by observing the Be II resonance doublet.",
    "pdf_url": "http://arxiv.org/pdf/2505.13313v2",
    "published": "2025-05-19T16:28:50+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13312v1",
    "title": "GUARD: Generation-time LLM Unlearning via Adaptive Restriction and Detection",
    "authors": [
      "Zhijie Deng",
      "Chris Yuhao Liu",
      "Zirui Pang",
      "Xinlei He",
      "Lei Feng",
      "Qi Xuan",
      "Zhaowei Zhu",
      "Jiaheng Wei"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in\nmemorizing vast amounts of knowledge across diverse domains. However, the\nability to selectively forget specific knowledge is critical for ensuring the\nsafety and compliance of deployed models. Existing unlearning efforts typically\nfine-tune the model with resources such as forget data, retain data, and a\ncalibration model. These additional gradient steps blur the decision boundary\nbetween forget and retain knowledge, making unlearning often at the expense of\noverall performance. To avoid the negative impact of fine-tuning, it would be\nbetter to unlearn solely at inference time by safely guarding the model against\ngenerating responses related to the forget target, without destroying the\nfluency of text generation. In this work, we propose Generation-time Unlearning\nvia Adaptive Restriction and Detection (GUARD), a framework that enables\ndynamic unlearning during LLM generation. Specifically, we first employ a\nprompt classifier to detect unlearning targets and extract the corresponding\nforbidden token. We then dynamically penalize and filter candidate tokens\nduring generation using a combination of token matching and semantic matching,\neffectively preventing the model from leaking the forgotten content.\nExperimental results on copyright content unlearning tasks over the Harry\nPotter dataset and the MUSE benchmark, as well as entity unlearning tasks on\nthe TOFU dataset, demonstrate that GUARD achieves strong forget quality across\nvarious tasks while causing almost no degradation to the LLM's general\ncapabilities, striking an excellent trade-off between forgetting and utility.",
    "pdf_url": "http://arxiv.org/pdf/2505.13312v1",
    "published": "2025-05-19T16:26:58+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13311v1",
    "title": "Synthesis of Communication Policies for Multi-Agent Systems Robust to Communication Restrictions",
    "authors": [
      "Saleh Soudijani",
      "Rayna Dimitrova"
    ],
    "abstract": "We study stochastic multi-agent systems in which agents must cooperate to\nmaximize the probability of achieving a common reach-avoid objective. In many\napplications, during the execution of the system, the communication between the\nagents can be constrained by restrictions on the bandwidth currently available\nfor exchanging local-state information between the agents.\n  In this paper, we propose a method for computing joint action and\ncommunication policies for the group of agents that aim to satisfy the\ncommunication restrictions as much as possible while achieving the optimal\nreach-avoid probability when communication is unconstrained. Our method\nsynthesizes a pair of action and communication policies robust to restrictions\non the number of agents allowed to communicate. To this end, we introduce a\nnovel cost function that measures the amount of information exchanged beyond\nwhat the communication policy allows. We evaluate our approach experimentally\non a range of benchmarks and demonstrate that it is capable of computing pairs\nof action and communication policies that satisfy the communication\nrestrictions, if such exist.",
    "pdf_url": "http://arxiv.org/pdf/2505.13311v1",
    "published": "2025-05-19T16:26:57+00:00",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13310v1",
    "title": "Frequency-Dependent Power Consumption Modeling of CMOS Transmitters for WNoC Architectures",
    "authors": [
      "Mohammad Shahmoradi",
      "Korkut Kaan Tokg√∂z",
      "Eduard Alarc√≥n",
      "Sergi Abadal"
    ],
    "abstract": "Wireless Network-on-Chip (WNoC) systems, which wirelessly interconnect the\nchips of a computing system, have been proposed as a complement to existing\nchip-to-chip wired links. However, their feasibility depends on the\navailability of custom-designed high-speed, tiny, ultra-efficient transceivers.\nThis represents a challenge due to the tradeoffs between bandwidth, area, and\nenergy efficiency that are found as frequency increases, which suggests that\nthere is an optimal frequency region. To aid in the search for such an optimal\ndesign point, this paper presents a behavioral model that quantifies the\nexpected power consumption of oscillators, mixers, and power amplifiers as a\nfunction of frequency. The model is built on extensive surveys of the\nrespective sub-blocks, all based on experimental data. By putting together the\nmodels of the three sub-blocks, a comprehensive power model is obtained, which\nwill aid in selecting the optimal operating frequency for WNoC systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13310v1",
    "published": "2025-05-19T16:26:53+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "eess.SP"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13309v1",
    "title": "eStonefish-scenes: A synthetically generated dataset for underwater event-based optical flow prediction tasks",
    "authors": [
      "Jad Mansour",
      "Sebastian Realpe",
      "Hayat Rajani",
      "Michele Grimaldi",
      "Rafael Garcia",
      "Nuno Gracias"
    ],
    "abstract": "The combined use of event-based vision and Spiking Neural Networks (SNNs) is\nexpected to significantly impact robotics, particularly in tasks like visual\nodometry and obstacle avoidance. While existing real-world event-based datasets\nfor optical flow prediction, typically captured with Unmanned Aerial Vehicles\n(UAVs), offer valuable insights, they are limited in diversity, scalability,\nand are challenging to collect. Moreover, there is a notable lack of labelled\ndatasets for underwater applications, which hinders the integration of\nevent-based vision with Autonomous Underwater Vehicles (AUVs). To address this,\nsynthetic datasets could provide a scalable solution while bridging the gap\nbetween simulation and reality. In this work, we introduce eStonefish-scenes, a\nsynthetic event-based optical flow dataset based on the Stonefish simulator.\nAlong with the dataset, we present a data generation pipeline that enables the\ncreation of customizable underwater environments. This pipeline allows for\nsimulating dynamic scenarios, such as biologically inspired schools of fish\nexhibiting realistic motion patterns, including obstacle avoidance and reactive\nnavigation around corals. Additionally, we introduce a scene generator that can\nbuild realistic reef seabeds by randomly distributing coral across the terrain.\nTo streamline data accessibility, we present eWiz, a comprehensive library\ndesigned for processing event-based data, offering tools for data loading,\naugmentation, visualization, encoding, and training data generation, along with\nloss functions and performance metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.13309v1",
    "published": "2025-05-19T16:26:18+00:00",
    "categories": [
      "cs.CV",
      "I.2.5; I.2.6; I.2.9; I.2.10"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13308v1",
    "title": "Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space",
    "authors": [
      "Hengli Li",
      "Chenxi Li",
      "Tong Wu",
      "Xuekai Zhu",
      "Yuxuan Wang",
      "Zhaoxin Yu",
      "Eric Hanchen Jiang",
      "Song-Chun Zhu",
      "Zixia Jia",
      "Ying Nian Wu",
      "Zilong Zheng"
    ],
    "abstract": "Reasoning ability, a core component of human intelligence, continues to pose\na significant challenge for Large Language Models (LLMs) in the pursuit of AGI.\nAlthough model performance has improved under the training scaling law,\nsignificant challenges remain, particularly with respect to training\nalgorithms, such as catastrophic forgetting, and the limited availability of\nnovel training data. As an alternative, test-time scaling enhances reasoning\nperformance by increasing test-time computation without parameter updating.\nUnlike prior methods in this paradigm focused on token space, we propose\nleveraging latent space for more effective reasoning and better adherence to\nthe test-time scaling law. We introduce LatentSeek, a novel framework that\nenhances LLM reasoning through Test-Time Instance-level Adaptation (TTIA)\nwithin the model's latent space. Specifically, LatentSeek leverages policy\ngradient to iteratively update latent representations, guided by self-generated\nreward signals. LatentSeek is evaluated on a range of reasoning benchmarks,\nincluding GSM8K, MATH-500, and AIME2024, across multiple LLM architectures.\nResults show that LatentSeek consistently outperforms strong baselines, such as\nChain-of-Thought prompting and fine-tuning-based methods. Furthermore, our\nanalysis demonstrates that LatentSeek is highly efficient, typically converging\nwithin a few iterations for problems of average complexity, while also\nbenefiting from additional iterations, thereby highlighting the potential of\ntest-time scaling in the latent space. These findings position LatentSeek as a\nlightweight, scalable, and effective solution for enhancing the reasoning\ncapabilities of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13308v1",
    "published": "2025-05-19T16:26:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13306v1",
    "title": "GMM-Based Comprehensive Feature Extraction and Relative Distance Preservation For Few-Shot Cross-Modal Retrieval",
    "authors": [
      "Chengsong Sun",
      "Weiping Li",
      "Xiang Li",
      "Yuankun Liu",
      "Lianlei Shan"
    ],
    "abstract": "Few-shot cross-modal retrieval focuses on learning cross-modal\nrepresentations with limited training samples, enabling the model to handle\nunseen classes during inference. Unlike traditional cross-modal retrieval\ntasks, which assume that both training and testing data share the same class\ndistribution, few-shot retrieval involves data with sparse representations\nacross modalities. Existing methods often fail to adequately model the\nmulti-peak distribution of few-shot cross-modal data, resulting in two main\nbiases in the latent semantic space: intra-modal bias, where sparse samples\nfail to capture intra-class diversity, and inter-modal bias, where\nmisalignments between image and text distributions exacerbate the semantic gap.\nThese biases hinder retrieval accuracy. To address these issues, we propose a\nnovel method, GCRDP, for few-shot cross-modal retrieval. This approach\neffectively captures the complex multi-peak distribution of data using a\nGaussian Mixture Model (GMM) and incorporates a multi-positive sample\ncontrastive learning mechanism for comprehensive feature modeling.\nAdditionally, we introduce a new strategy for cross-modal semantic alignment,\nwhich constrains the relative distances between image and text feature\ndistributions, thereby improving the accuracy of cross-modal representations.\nWe validate our approach through extensive experiments on four benchmark\ndatasets, demonstrating superior performance over six state-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13306v1",
    "published": "2025-05-19T16:25:55+00:00",
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13307v1",
    "title": "RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning",
    "authors": [
      "Qiguang Chen",
      "Libo Qin",
      "Jinhao Liu",
      "Yue Liao",
      "Jiaqi Wang",
      "Jingxuan Zhou",
      "Wanxiang Che"
    ],
    "abstract": "Chain-of-Thought (CoT) reasoning has proven effective in enhancing large\nlanguage models (LLMs) on complex tasks, spurring research into its underlying\nmechanisms. However, two primary challenges remain for real-world applications:\n(1) the lack of quantitative metrics and actionable guidelines for evaluating\nand optimizing measurable boundaries of CoT capability, and (2) the absence of\nmethods to assess boundaries of unmeasurable CoT capability, such as multimodal\nperception. To address these gaps, we introduce the Reasoning Boundary\nFramework++ (RBF++). To tackle the first challenge, we define the reasoning\nboundary (RB) as the maximum limit of CoT performance. We also propose a\ncombination law for RBs, enabling quantitative analysis and offering actionable\nguidance across various CoT tasks. For the second challenge, particularly in\nmultimodal scenarios, we introduce a constant assumption, which replaces\nunmeasurable RBs with scenario-specific constants. Additionally, we propose the\nreasoning boundary division mechanism, which divides unmeasurable RBs into two\nsub-boundaries, facilitating the quantification and optimization of both\nunmeasurable domain knowledge and multimodal perception capabilities. Extensive\nexperiments involving 38 models across 13 tasks validate the feasibility of our\nframework in cross-modal settings. Additionally, we evaluate 10 CoT strategies,\noffer insights into optimization and decay from two complementary perspectives,\nand expand evaluation benchmarks for measuring RBs in LLM reasoning. We hope\nthis work advances the understanding of RBs and optimization strategies in\nLLMs. Code and data are available at\nhttps://github.com/LightChen233/reasoning-boundary.",
    "pdf_url": "http://arxiv.org/pdf/2505.13307v1",
    "published": "2025-05-19T16:25:55+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13305v2",
    "title": "Kinematic dynamos and resolution limits for Smoothed Particle Magnetohydrodynamics",
    "authors": [
      "Nikyta Shchutskyi",
      "Matthieu Schaller",
      "Orestis A. Karapiperis",
      "Federico A. Stasyszyn",
      "Axel Brandenburg"
    ],
    "abstract": "Understanding the origin and evolution of magnetic fields on cosmological\nscales opens up a window into the physics of the early Universe. Numerical\nsimulations of such fields require a careful treatment to faithfully solve the\nequations of magnetohydrodynamics (MHD) without introducing numerical\nartefacts. In this paper, we study the growth of the magnetic fields in\ncontrolled kinematic dynamo setups using both smoothed particle hydrodynamics\nimplementations in the SWIFT code. We assess the quality of the reconstructed\nsolution in the Roberts flow case against the reference implementation in the\nPencil code and find generally a good agreement. Similarly, we reproduce the\nknown features of the more complex ABC flow. Using a simple induction-diffusion\nbalance model to analyse the results, we construct an \"overwinding\" trigger\nmetric to locally detect regions where the magnetic diffusion cannot counteract\nthe expected induction because of limitations in the method's ability to\nresolve magnetic field gradients. This metric is then used to identify the\nnecessary resolution and resistivity levels to counteract the overwinding\nproblem. We finally apply this metric to adiabatic cosmological simulations and\ndiscuss the resolution requirements needed to resolve the growth of the\nprimordial fields without artefacts.",
    "pdf_url": "http://arxiv.org/pdf/2505.13305v2",
    "published": "2025-05-19T16:23:37+00:00",
    "categories": [
      "astro-ph.CO",
      "physics.comp-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13304v2",
    "title": "A Family of Aperiodic Tilings with Tunable Quantum Geometric Tensor",
    "authors": [
      "Hector Roche Carrasco",
      "Justin Schirmann",
      "Aurelien Mordret",
      "Adolfo G. Grushin"
    ],
    "abstract": "The strict geometric rules that define aperiodic tilings lead to the unique\nspectral and transport properties of quasicrystals, but also limit our ability\nto design them. In this work, we explore the first continuously tunable family\nof two-dimensional aperiodic tilings in which the underlying real-space\ngeometry becomes a control knob of the wave-function's quantum geometric\ntensor. The real-space geometry can be used to tune into topological phases\noccupying an expanded phase space compared to crystals, or into a\ndisorder-driven topological Anderson insulator. The quantum metric can also be\ntuned continuously, opening new routes towards tunable single- and many-body\nphysics in aperiodic solid-state and synthetic systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13304v2",
    "published": "2025-05-19T16:21:17+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.13303v1",
    "title": "A note on additive commutator groups in certain algebras",
    "authors": [
      "Nguyen Thi Thai Ha",
      "Tran Nam Son",
      "Pham Duy Vinh"
    ],
    "abstract": "We study whether a unital associative algebra $ A $ over a field admits a\ndecomposition of the form $A = Z(A) + [A,A]$ where $ Z(A) $ is the center of $\nA $ and $ [A,A] $ denotes the additive subgroup of $A$ generated by all\nadditive commutators of $A$. Among our main considerations are the cases in\nwhich $A$ is the matrix ring over a division ring, a generalized quaternion\nalgebra, or a semisimple finite-dimensional algebra. We also discuss some\napplications that do not necessarily require the decomposition, such as the\ncase where $ A $ is the twisted group algebra of a locally finite group over a\nfield of characteristic zero: if all additive commutators of $A$ are central,\nthen $ A $ must be commutative.",
    "pdf_url": "http://arxiv.org/pdf/2505.13303v1",
    "published": "2025-05-19T16:21:07+00:00",
    "categories": [
      "math.RA"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13302v1",
    "title": "I'll believe it when I see it: Images increase misinformation sharing in Vision-Language Models",
    "authors": [
      "Alice Plebe",
      "Timothy Douglas",
      "Diana Riazi",
      "R. Maria del Rio-Chanona"
    ],
    "abstract": "Large language models are increasingly integrated into news recommendation\nsystems, raising concerns about their role in spreading misinformation. In\nhumans, visual content is known to boost credibility and shareability of\ninformation, yet its effect on vision-language models (VLMs) remains unclear.\nWe present the first study examining how images influence VLMs' propensity to\nreshare news content, whether this effect varies across model families, and how\npersona conditioning and content attributes modulate this behavior. To support\nthis analysis, we introduce two methodological contributions: a\njailbreaking-inspired prompting strategy that elicits resharing decisions from\nVLMs while simulating users with antisocial traits and political alignments;\nand a multimodal dataset of fact-checked political news from PolitiFact, paired\nwith corresponding images and ground-truth veracity labels. Experiments across\nmodel families reveal that image presence increases resharing rates by 4.8% for\ntrue news and 15.0% for false news. Persona conditioning further modulates this\neffect: Dark Triad traits amplify resharing of false news, whereas\nRepublican-aligned profiles exhibit reduced veracity sensitivity. Of all the\ntested models, only Claude-3-Haiku demonstrates robustness to visual\nmisinformation. These findings highlight emerging risks in multimodal model\nbehavior and motivate the development of tailored evaluation frameworks and\nmitigation strategies for personalized AI systems. Code and dataset are\navailable at: https://github.com/3lis/misinfo_vlm",
    "pdf_url": "http://arxiv.org/pdf/2505.13302v1",
    "published": "2025-05-19T16:20:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13301v1",
    "title": "Gamma Analytical Modeling Evolution (GAME) I: The physical implications of deriving the stellar mass functions from z=0 to z=8",
    "authors": [
      "Antonios Katsianis",
      "Qingshan Wang",
      "Xiaohu Yang",
      "Xian Zhong Zheng",
      "Pedro Cataldi",
      "Nicola Napolitano",
      "Weishan Zhu",
      "Nicolas Tejos",
      "Weiguang Cui",
      "Cheng Li",
      "Weipeng Lin",
      "Long-long Feng",
      "Junde Li",
      "Ying Tang",
      "Yuchang Li",
      "Hangxin Pu"
    ],
    "abstract": "The $\\Gamma$ growth model is an effective parameterization employed across\nvarious scientific disciplines and scales to depict growth. It has been\ndemonstrated that the cosmic star formation rate density (CSFRD) can also be\ndescribed broadly by this pattern, i.e. $\\frac{dM(T)}{dT} = M_{z,0}\\, \\times\n\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\, T^{\\alpha-1} e^{-\\beta \\, T }$\nM$_{\\odot}$ Gyr$^{-1}$, where $M_{z,0}$ is the stellar mass at $z$ = 0, $\\alpha\n= 3.0$, $\\beta = 0.5 $ Gyr$^{-1}$ and $T$ describes time. We use the identical\n$\\Gamma$ growth pattern given by the CSFRD to extend the present day (z = 0)\nstellar mass bins $M_{\\ast}(T)$ of the Galaxy Stellar Mass Function (GSMF) and\ninvestigate if we are able to reproduce observations for the high redshift\nGSMFs. Surprisingly, our scheme describes successfully the evolution of the\nGSMF over 13.5 Gyrs, especially for objects with intermediate and low masses.\nWe observe some deviations that manifest {\\it solely} at very high redshifts\n($z > 1.5$, i.e. more than 9.5 Gyr ago) and {\\it specifically} for very small\nand exceedingly massive objects. We discuss the possible solutions (e.g.\nimpacts of mergers) for these offsets. Our formalism suggests that the\nevolution of the GSMF is set by simple (few parameters) and physically\nmotivated arguments. The parameters $\\beta$ and $\\alpha$ are theoretically\nconsistent within a multi-scale context and are determined from the dynamical\ntime scale ($\\beta$) and the radial distribution of the accreting matter\n($\\alpha$). We demonstrate that both our formalism and state-of-the-art\nsimulations are consistent with recent GSMFs derived from JWST data at high\nredshifts.",
    "pdf_url": "http://arxiv.org/pdf/2505.13301v1",
    "published": "2025-05-19T16:20:42+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13300v2",
    "title": "DD-Ranking: Rethinking the Evaluation of Dataset Distillation",
    "authors": [
      "Zekai Li",
      "Xinhao Zhong",
      "Samir Khaki",
      "Zhiyuan Liang",
      "Yuhao Zhou",
      "Mingjia Shi",
      "Ziqiao Wang",
      "Xuanlei Zhao",
      "Wangbo Zhao",
      "Ziheng Qin",
      "Mengxuan Wu",
      "Pengfei Zhou",
      "Haonan Wang",
      "David Junhao Zhang",
      "Jia-Wei Liu",
      "Shaobo Wang",
      "Dai Liu",
      "Linfeng Zhang",
      "Guang Li",
      "Kun Wang",
      "Zheng Zhu",
      "Zhiheng Ma",
      "Joey Tianyi Zhou",
      "Jiancheng Lv",
      "Yaochu Jin",
      "Peihao Wang",
      "Kaipeng Zhang",
      "Lingjuan Lyu",
      "Yiran Huang",
      "Zeynep Akata",
      "Zhiwei Deng",
      "Xindi Wu",
      "George Cazenavette",
      "Yuzhang Shang",
      "Justin Cui",
      "Jindong Gu",
      "Qian Zheng",
      "Hao Ye",
      "Shuo Wang",
      "Xiaobo Wang",
      "Yan Yan",
      "Angela Yao",
      "Mike Zheng Shou",
      "Tianlong Chen",
      "Hakan Bilen",
      "Baharan Mirzasoleiman",
      "Manolis Kellis",
      "Konstantinos N. Plataniotis",
      "Zhangyang Wang",
      "Bo Zhao",
      "Yang You",
      "Kai Wang"
    ],
    "abstract": "In recent years, dataset distillation has provided a reliable solution for\ndata compression, where models trained on the resulting smaller synthetic\ndatasets achieve performance comparable to those trained on the original\ndatasets. To further improve the performance of synthetic datasets, various\ntraining pipelines and optimization objectives have been proposed, greatly\nadvancing the field of dataset distillation. Recent decoupled dataset\ndistillation methods introduce soft labels and stronger data augmentation\nduring the post-evaluation phase and scale dataset distillation up to larger\ndatasets (e.g., ImageNet-1K). However, this raises a question: Is accuracy\nstill a reliable metric to fairly evaluate dataset distillation methods? Our\nempirical findings suggest that the performance improvements of these methods\noften stem from additional techniques rather than the inherent quality of the\nimages themselves, with even randomly sampled images achieving superior\nresults. Such misaligned evaluation settings severely hinder the development of\nDD. Therefore, we propose DD-Ranking, a unified evaluation framework, along\nwith new general evaluation metrics to uncover the true performance\nimprovements achieved by different methods. By refocusing on the actual\ninformation enhancement of distilled datasets, DD-Ranking provides a more\ncomprehensive and fair evaluation standard for future research advancements.",
    "pdf_url": "http://arxiv.org/pdf/2505.13300v2",
    "published": "2025-05-19T16:19:50+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13299v1",
    "title": "Smoothed SGD for quantiles: Bahadur representation and Gaussian approximation",
    "authors": [
      "Likai Chen",
      "Georg Keilbar",
      "Wei Biao Wu"
    ],
    "abstract": "This paper considers the estimation of quantiles via a smoothed version of\nthe stochastic gradient descent (SGD) algorithm. By smoothing the score\nfunction in the conventional SGD quantile algorithm, we achieve monotonicity in\nthe quantile level in that the estimated quantile curves do not cross. We\nderive non-asymptotic tail probability bounds for the smoothed SGD quantile\nestimate both for the case with and without Polyak-Ruppert averaging. For the\nlatter, we also provide a uniform Bahadur representation and a resulting\nGaussian approximation result. Numerical studies show good finite sample\nbehavior for our theoretical results.",
    "pdf_url": "http://arxiv.org/pdf/2505.13299v1",
    "published": "2025-05-19T16:19:44+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.13298v2",
    "title": "Polarization modes of gravitational waves in general symmetric teleparallel gravity",
    "authors": [
      "Yu-Qi Dong",
      "Xiao-Bin Lai",
      "Yu-Zhi Fan",
      "Yu-Xiao Liu"
    ],
    "abstract": "In this paper, we investigate the polarization modes of gravitational waves\nwithin the most general symmetric teleparallel gravity theory that allows for\nsecond-order field equations We consider both scenarios where test particles\neither carry or do not carry a hypermomentum charge. Our findings reveal the\nexistence of tensor, vector, and scalar modes of gravitational waves. Firstly,\nthe theory supports the + and $\\times$ tensor modes propagating at the speed of\nlight. Secondly, in the case where particles do not carry hypermomentum, vector\nmodes propagating at the speed of light exist only within a very specific\nparameter space. However, when particles do carry hypermomentum, there are two\nshear modes that propagate at the speed of light, while the vector-$x$ and\nvector-$y$ modes emerge only under very specific conditions. Thirdly, in the\npresence of hypermomentum, there is always a longitudinal mode propagating at\nthe speed of light. The universal existence of the shear modes and the\nlongitudinal mode in the presence of hypermomentum is a key feature of\nsymmetric teleparallel gravity, distinguishing it from the Riemannian framework\nthrough gravitational wave polarization detection. We also analyze the\npolarization modes in two widely studied special theories: $f(Q)$ theory and\nquadratic non-metricity theory. Our study reveals that, within the $f(Q)$\ngravity framework, it is crucial to assume that matter fields are independent\nof the connection, as any dependence would lead to unphysical results.",
    "pdf_url": "http://arxiv.org/pdf/2505.13298v2",
    "published": "2025-05-19T16:18:22+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.13297v1",
    "title": "The CHIME/FRB Discovery of the Extremely Active Fast Radio Burst Source FRB 20240114A",
    "authors": [
      "Kaitlyn Shin",
      "Alice Curtin",
      "Maxwell Fine",
      "Ayush Pandhi",
      "Shion Andrew",
      "Mohit Bhardwaj",
      "Shami Chatterjee",
      "Amanda M. Cook",
      "Emmanuel Fonseca",
      "B. M. Gaensler",
      "Jason Hessels",
      "Naman Jain",
      "Victoria M. Kaspi",
      "Bikash Kharel",
      "Adam E. Lanman",
      "Mattias Lazda",
      "Calvin Leung",
      "Robert Main",
      "Kiyoshi W. Masui",
      "Daniele Michilli",
      "Mason Ng",
      "Kenzie Nimmo",
      "Aaron B. Pearlman",
      "Ue-Li Pen",
      "Ziggy Pleunis",
      "Masoud Rafiei-Ravandi",
      "Mawson Sammons",
      "Ketan R. Sand",
      "Paul Scholz",
      "Kendrick Smith",
      "Ingrid Stairs"
    ],
    "abstract": "Among the thousands of observed fast radio bursts (FRBs), a few sources\nexhibit exceptionally high burst activity observable by many telescopes across\na broad range of radio frequencies. Almost all of these highly active repeaters\nhave been discovered by CHIME/FRB, due to its daily observations of the entire\nNorthern sky as a transit radio telescope. FRB 20240114A is a source discovered\nand reported by CHIME/FRB to the community in January 2024; given its low\ndeclination, even the detection of a few bursts hints at a high burst rate.\nFollowing the community announcement of this source as a potentially active\nrepeater, it was extensively followed up by other observatories and has emerged\nas one of the most prolific FRB repeaters ever observed. This paper presents\nthe five bursts CHIME/FRB observed from FRB 20240114A, with channelized raw\nvoltage data saved for two bursts. We do not observe changes in the DM of the\nsource greater than ~1.3 pc cm$^{-3}$ in our observations over nearly a year\nbaseline. We find an RM of ~ +320 rad m$^{-2}$. We do not find evidence for\nscattering at the level of < 0.3 ms in the bursts, and we find no evidence for\nastrophysical scintillation. In our observations of FRB 20240114A, we see a\nburst rate ~49x higher than the median burst rate of apparent non-repeaters\nalso discovered by CHIME/FRB. Each discovery of highly active FRBs provides a\nvaluable opportunity to investigate whether there is a fundamental difference\nbetween repeating and apparently non-repeating sources.",
    "pdf_url": "http://arxiv.org/pdf/2505.13297v1",
    "published": "2025-05-19T16:17:57+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13296v1",
    "title": "Inflight calibration of SRG/ART-XC point spread function at large off-axis angles",
    "authors": [
      "R. Krivonos",
      "R. Burenin",
      "E. Filippova",
      "I. Lapshov",
      "A. Tkachenko",
      "A. Semena",
      "I. Mereminskiy",
      "V. Arefiev",
      "A. Lutovinov",
      "B. D. Ramsey",
      "J. J. Kolodziejczak",
      "D. A. Swartz",
      "C. -T. Chen",
      "S. R. Ehlert",
      "A. Vikhlinin"
    ],
    "abstract": "The knowledge of the point spread function (PSF) of the Mikhail Pavlinsky\nAstronomical Roentgen Telescope - X-ray Concentrator (ART-XC) telescope aboard\nthe Spectrum-Roentgen-Gamma (SRG) observatory plays an especially crucial role\nin the detection of point X-ray sources in the all-sky survey and the studies\nof extended X-ray objects with low surface brightness. In this work, we\ncalibrate the far off-axis shape of the ART-XC PSF using in-flight data of Sco\nX-1 and the Crab Nebula, in all-sky survey or scan mode, respectively. We\ndemonstrate that the so-called \"slewing\" ART-XC PSF (in contrast to the on-axis\nPSF), in convolution with the detector pixels, is consistent with ground\ncalibration performed at the Marshall Space Flight Center, and can be used to\nmodel the PSF up to large off-axis distances in all-sky survey or scan modes.\nThe radial profile of the Crab Nebula in the 4-12 keV band shows an extended\nstructure out to ~150\" and is consistent with Sco X-1 at larger off-axis\nangles. Finally, we performed an analytic parametrization of the slewing ART-XC\nPSF as a function of energy.",
    "pdf_url": "http://arxiv.org/pdf/2505.13296v1",
    "published": "2025-05-19T16:17:12+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.13295v1",
    "title": "A planetary-mass candidate imaged in the Young Suns Exoplanet Survey",
    "authors": [
      "Pengyu Liu",
      "Matthew A. Kenworthy",
      "Beth A. Biller",
      "Alex Wallace",
      "Tomas Stolker",
      "Sebastiaan Haffert",
      "Christian Ginski",
      "Eric E. Mamajek",
      "Alfred Castro-Ginard",
      "Tiffany Meshkat",
      "Mark J. Pecaut",
      "Maddalena Reggiani",
      "Jared R. Males",
      "Laird M. Close",
      "Olivier Guyon",
      "Isabella Doty",
      "Kyle Van Gorkom",
      "Alex Hedglen",
      "Maggie Kautz",
      "Jay Kueny",
      "Joshua Liberman",
      "Jialin Li",
      "Joseph D. Long",
      "Jennifer Lumbres",
      "Eden McEwen",
      "Logan Pearce",
      "Roswell R. Roberts IV",
      "Lauren Schatz",
      "Katie Twitchell"
    ],
    "abstract": "Directly imaged exoplanets in wide orbits challenge current gas giant\nformation theories. They need to form quickly and acquire enough material\nbefore the disk dissipates, which cannot be accommodated by in-situ formation\nby core accretion. We search for wide separation ($>$ 100 au) planetary-mass\ncompanions with the Young Suns Exoplanet Survey (YSES). Here, we present a\nplanetary-mass candidate companion discovered in the survey. We conducted\nfollow-up observations of the candidate system after the first epoch\nobservations and obtained six epochs of observations for this system between\n2018 and 2024, and integral field spectroscopy of the stellar component. We\nreport the detection of a candidate companion with H=22.04 $\\pm$ 0.13 mag at a\nprojected separation of 730 $\\pm$ 10 au away from the primary star. High\nangular resolution imaging observations of the central star show it is a visual\nbinary. Acceleration data, orbital fitting, spectral energy distribution\nfitting and radial velocity differences all suggest that there is at least one\nmore unresolved low-mass stellar companion in this system. The planetary-mass\ncandidate shows a significant proper motion comparable to that of the primary\nstar. We estimate an age of 19-28 Myr for the primary star. We cannot confirm\nthe companionship of the candidate due to the unknown barycentre of the stars.\nLong-term imaging and radial velocity monitoring of the central stars, along\nwith spectroscopy of the candidate companion, are key to resolving the nature\nof this system. If confirmed, the candidate companion would have a mass of 3-5\nMj estimated with the ATMO evolutionary model. It would be another cold\nlow-mass planet imaged similar to 51 Eri b and AF Lep b. Its extremely wide\nseparation from the host star would challenge the formation theory of gas giant\nexoplanets.",
    "pdf_url": "http://arxiv.org/pdf/2505.13295v1",
    "published": "2025-05-19T16:16:29+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13294v1",
    "title": "Output behavior equivalence and simultaneous subspace identification of systems and faults",
    "authors": [
      "Gabriel de Albuquerque Gleizer"
    ],
    "abstract": "We address the problem of identifying a system subject to additive faults,\nwhile simultaneously reconstructing the fault signal via subspace methods. We\ndo not require nominal data for the identification, neither do we impose any\nassumption on the class of faults, e.g., sensor or actuator faults. We show\nthat, under mild assumptions on the fault signal, standard PI-MOESP can recover\nthe system matrices associated to the input-output subsystem. Then we introduce\nthe concept of output behavior equivalence, which characterizes systems with\nthe same output behavior set, and present a method to establish this\nequivalence from system matrices. Finally, we show how to estimate from data\nthe complete set of fault matrices for which there exist a fault signal with\nminimal dimension that explains the data.",
    "pdf_url": "http://arxiv.org/pdf/2505.13294v1",
    "published": "2025-05-19T16:16:00+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13293v1",
    "title": "Calibration-free single-frame super-resolution fluorescence microscopy",
    "authors": [
      "Ane≈æka Dost√°lov√°",
      "Dominik Va≈°inka",
      "Robert St√°rek",
      "Miroslav Je≈æek"
    ],
    "abstract": "Molecular fluorescence microscopy is a leading approach to super-resolution\nand nanoscale imaging in life and material sciences. However, super-resolution\nfluorescence microscopy is often bottlenecked by system-specific calibrations\nand long acquisitions of sparsely blinking molecules. We present a\ndeep-learning approach that reconstructs super-resolved images directly from a\nsingle diffraction-limited camera frame. The model is trained exclusively on\nsynthetic data encompassing a wide range of optical and sample parameters,\nenabling robust generalization across microscopes and experimental conditions.\nApplied to dense terrylene samples with 150 ms acquisition time, our method\nsignificantly reduces reconstruction error compared to Richardson-Lucy\ndeconvolution and ThunderSTORM multi-emitter fitting. The results confirm the\nability to resolve emitters separated by 35 nm at 580 nm wavelength,\ncorresponding to sevenfold resolution improvement beyond the Rayleigh\ncriterion. By delivering unprecedented details from a single short camera\nexposure without prior information and calibration, our approach enables\nplug-and-play super-resolution imaging of fast, dense, or light-sensitive\nsamples on standard wide-field setups.",
    "pdf_url": "http://arxiv.org/pdf/2505.13293v1",
    "published": "2025-05-19T16:14:45+00:00",
    "categories": [
      "physics.optics",
      "quant-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.13292v1",
    "title": "Cross-Cloud Data Privacy Protection: Optimizing Collaborative Mechanisms of AI Systems by Integrating Federated Learning and LLMs",
    "authors": [
      "Huaiying Luo",
      "Cheng Ji"
    ],
    "abstract": "In the age of cloud computing, data privacy protection has become a major\nchallenge, especially when sharing sensitive data across cloud environments.\nHowever, how to optimize collaboration across cloud environments remains an\nunresolved problem. In this paper, we combine federated learning with\nlarge-scale language models to optimize the collaborative mechanism of AI\nsystems. Based on the existing federated learning framework, we introduce a\ncross-cloud architecture in which federated learning works by aggregating model\nupdates from decentralized nodes without exposing the original data. At the\nsame time, combined with large-scale language models, its powerful context and\nsemantic understanding capabilities are used to improve model training\nefficiency and decision-making ability. We've further innovated by introducing\na secure communication layer to ensure the privacy and integrity of model\nupdates and training data. The model enables continuous model adaptation and\nfine-tuning across different cloud environments while protecting sensitive\ndata. Experimental results show that the proposed method is significantly\nbetter than the traditional federated learning model in terms of accuracy,\nconvergence speed and data privacy protection.",
    "pdf_url": "http://arxiv.org/pdf/2505.13292v1",
    "published": "2025-05-19T16:14:27+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13291v1",
    "title": "TimeSeriesGym: A Scalable Benchmark for (Time Series) Machine Learning Engineering Agents",
    "authors": [
      "Yifu Cai",
      "Xinyu Li",
      "Mononito Goswami",
      "Micha≈Ç Wili≈Ñski",
      "Gus Welter",
      "Artur Dubrawski"
    ],
    "abstract": "We introduce TimeSeriesGym, a scalable benchmarking framework for evaluating\nArtificial Intelligence (AI) agents on time series machine learning engineering\nchallenges. Existing benchmarks lack scalability, focus narrowly on model\nbuilding in well-defined settings, and evaluate only a limited set of research\nartifacts (e.g., CSV submission files). To make AI agent benchmarking more\nrelevant to the practice of machine learning engineering, our framework scales\nalong two critical dimensions. First, recognizing that effective ML engineering\nrequires a range of diverse skills, TimeSeriesGym incorporates challenges from\ndiverse sources spanning multiple domains and tasks. We design challenges to\nevaluate both isolated capabilities (including data handling, understanding\nresearch repositories, and code translation) and their combinations, and rather\nthan addressing each challenge independently, we develop tools that support\ndesigning multiple challenges at scale. Second, we implement evaluation\nmechanisms for multiple research artifacts, including submission files, code,\nand models, using both precise numeric measures and more flexible LLM-based\nevaluation approaches. This dual strategy balances objective assessment with\ncontextual judgment. Although our initial focus is on time series applications,\nour framework can be readily extended to other data modalities, broadly\nenhancing the comprehensiveness and practical utility of agentic AI evaluation.\nWe open-source our benchmarking framework to facilitate future research on the\nML engineering capabilities of AI agents.",
    "pdf_url": "http://arxiv.org/pdf/2505.13291v1",
    "published": "2025-05-19T16:11:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13290v1",
    "title": "Type Ia supernova growth-rate measurement with LSST simulations: intrinsic scatter systematics",
    "authors": [
      "Bastien Carreres",
      "Rebecca C. Chen",
      "Erik R. Peterson",
      "Dan Scolnic",
      "Corentin Ravoux",
      "Damiano Rosselli",
      "Maria Acevedo",
      "Julian E. Bautista",
      "Dominique Fouchez",
      "Llu√≠s Galbany",
      "Benjamin Racine",
      "The LSST Dark Energy Science Collaboration"
    ],
    "abstract": "Measurement of the growth rate of structures ($\\fsig$) with Type Ia\nsupernovae (\\sns) will improve our understanding of the nature of dark energy\nand enable tests of general relativity. In this paper, we generate simulations\nof the 10 year \\sn\\ dataset of the Rubin-LSST survey, including a correlated\nvelocity field from a N-body simulation and realistic models of \\sns\\\nproperties and their correlations with host-galaxy properties. We find, similar\nto SN~Ia analyses that constrain the dark energy equation-of-state parameters\n$w_0w_a$, that constraints on $\\fsig$ can be biased depending on the intrinsic\nscatter of \\sns. While for the majority of intrinsic scatter models we recover\n$\\fsig$ with a precision of $\\sim13 - 14\\%$, for the most realistic dust-based\nmodel, we find that the presence of non-Gaussianities in Hubble diagram\nresiduals leads to a bias on $\\fsig$ of about $\\sim-20\\%$. When trying to\ncorrect for the dust-based intrinsic scatter, we find that the propagation of\nthe uncertainty on the model parameters does not significantly increase the\nerror on $\\fsig$. We also find that while the main component of the error\nbudget of $\\fsig$ is the statistical uncertainty ($>75\\%$ of the total error\nbudget), the systematic error budget is dominated by the uncertainty on the\ndamping parameter, $\\sigma_u$, that gives an empirical description of the\neffect of redshift space distortions on the velocity power spectrum. Our\nresults motivate a search for new methods to correct for the non-Gaussian\ndistribution of the Hubble diagram residuals, as well as an improved modeling\nof the damping parameter.",
    "pdf_url": "http://arxiv.org/pdf/2505.13290v1",
    "published": "2025-05-19T16:10:34+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13289v1",
    "title": "RECON: Robust symmetry discovery via Explicit Canonical Orientation Normalization",
    "authors": [
      "Alonso Urbano",
      "David W. Romero",
      "Max Zimmer",
      "Sebastian Pokutta"
    ],
    "abstract": "Real-world data often exhibits unknown or approximate symmetries, yet\nexisting equivariant networks must commit to a fixed transformation group prior\nto training, e.g., continuous $SO(2)$ rotations. This mismatch degrades\nperformance when the actual data symmetries differ from those in the\ntransformation group. We introduce RECON, a framework to discover each input's\nintrinsic symmetry distribution from unlabeled data. RECON leverages class-pose\ndecompositions and applies a data-driven normalization to align arbitrary\nreference frames into a common natural pose, yielding directly comparable and\ninterpretable symmetry descriptors. We demonstrate effective symmetry discovery\non 2D image benchmarks and -- for the first time -- extend it to 3D\ntransformation groups, paving the way towards more flexible equivariant\nmodeling.",
    "pdf_url": "http://arxiv.org/pdf/2505.13289v1",
    "published": "2025-05-19T16:10:23+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13288v3",
    "title": "Counting totally real units and eigenvalue patterns in $\\rm{SL}_n(\\mathbb Z)$ and $\\rm{Sp}_{2n}(\\mathbb Z)$ in thin tubes",
    "authors": [
      "Hee Oh"
    ],
    "abstract": "For a vector $v=(v_1,\\dots ,v_n)$ with $v_1>\\cdots>v_n$ and $\\sum v_i=0$, we\nstudy the \"directional entropy\" of two arithmetic objects: (1) the logarithmic\nembeddings of degree-$n$ totally real units, and (2) the logarithmic eigenvalue\ndata of $\\operatorname{SL}_n(\\mathbb Z)$. In each case, the entropy in the\ndirection of $v$ is $\\mathsf E_n(v)=\n\\rho_{\\operatorname{SL}_n}(v)=\\sum_{i=1}^{n-1}(n-i)\\,v_i,$ the value of the\nhalf-sum of positive roots of $\\operatorname{SL}_n(\\mathbb R)$ evaluated at\n$v$. More precisely, the number of objects lying in a thin tube around the ray\n$\\mathbb R_+v$ and of norm at most $T$ grows on the order of $\n\\exp\\!\\bigl(\\rho_{\\operatorname{SL}_n}(v)\\,T\\bigr)$ as $T\\to \\infty$.\n  Because each eigenvalue data determines an $\\operatorname{SL}_n(\\mathbb\nR)$-conjugacy class, this implies a lower bound of order\n$\\exp\\!\\bigl(\\rho_{\\operatorname{SL}_n}(v)T\\bigr)$ for the number of\n$\\operatorname{SL}_n(\\mathbb Z)$-conjugacy classes with a prescribed eigenvalue\ndata; we also obtain an upper bound of order\n$\\exp\\!\\bigl(2\\rho_{\\operatorname{SL}_n}(v)T\\bigr)$.\n  A parallel argument for the symplectic lattice\n$\\operatorname{Sp}_{2n}(\\mathbb Z)$, taken in the symmetric direction\n$v=(v_1,\\dots ,v_n,-v_n,\\dots ,-v_1),\\quad v_1>\\cdots>v_n>0,$ shows that\n$\\mathsf\nE_{2n}^{\\operatorname{Sp}}(v)=\\rho_{\\operatorname{Sp}_{2n}}(v)=\\sum_{i=1}^n(n+1-i)v_i,$\nthe half-sum of positive roots of $\\operatorname{Sp}_{2n}(\\mathbb R)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.13288v3",
    "published": "2025-05-19T16:09:54+00:00",
    "categories": [
      "math.NT",
      "math.DS",
      "math.GR",
      "math.GT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.14723v1",
    "title": "QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding",
    "authors": [
      "Subrata Biswas",
      "Mohammad Nur Hossain Khan",
      "Bashima Islam"
    ],
    "abstract": "Spoken Language Understanding (SLU) systems must balance performance and\nefficiency, particularly in resource-constrained environments. Existing methods\napply distillation and quantization separately, leading to suboptimal\ncompression as distillation ignores quantization constraints. We propose QUADS,\na unified framework that optimizes both through multi-stage training with a\npre-tuned model, enhancing adaptability to low-bit regimes while maintaining\naccuracy. QUADS achieves 71.13\\% accuracy on SLURP and 99.20\\% on FSC, with\nonly minor degradations of up to 5.56\\% compared to state-of-the-art models.\nAdditionally, it reduces computational complexity by 60--73$\\times$ (GMACs) and\nmodel size by 83--700$\\times$, demonstrating strong robustness under extreme\nquantization. These results establish QUADS as a highly efficient solution for\nreal-world, resource-constrained SLU applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.14723v1",
    "published": "2025-05-19T16:09:51+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13287v1",
    "title": "Level Generation with Quantum Reservoir Computing",
    "authors": [
      "Jo√£o S. Ferreira",
      "Pierre Fromholz",
      "Hari Shaji",
      "James R. Wootton"
    ],
    "abstract": "Reservoir computing is a form of machine learning particularly suited for\ntime series analysis, including forecasting predictions. We take an\nimplementation of \\emph{quantum} reservoir computing that was initially\ndesigned to generate variants of musical scores and adapt it to create levels\nof Super Mario Bros. Motivated by our analysis of these levels, we develop a\nnew Roblox \\textit{obby} where the courses can be generated in real time on\nsuperconducting qubit hardware, and investigate some of the constraints placed\nby such real-time generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13287v1",
    "published": "2025-05-19T16:09:30+00:00",
    "categories": [
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13286v1",
    "title": "Black Holes with Global Monopoles in 4D Noncommutative Einstein Gauss Bonnet Gravity",
    "authors": [
      "B. Hamil"
    ],
    "abstract": "In this work, we construct an exact spherically symmetric black hole solution\nwith a global monopole in the context of four-dimensional noncommutative\nEinstein-Gauss-Bonnet gravity. We modeled the spacetime noncommutativity via a\nLorentzian-smeared mass distribution. Then we study the horizon structure and\nfind that this black hole can have two configurations: one degenerate horizon\nor no horizon, depending on the black hole parameters. We also analyze\nthermodynamics and thermal stability by computing the Hawking temperature,\nentropy, and heat capacity. Our analysis reveals that the Hawking temperature\nand entropy acquire corrections from the noncommutative parameter $\\Theta$, the\nenergy scale of symmetry breaking $\\eta$, and the Gauss-Bonnet coupling\nconstant $\\alpha$. The heat capacity exhibits divergences that signal\nsecond-order phase transitions. Thereafter, we study the black hole shadow\nemploying the null geodesics and the Hamiltonian-Jacobi equation. Our results\nshow that the shadow decreases with increasing $\\Theta$ or $\\alpha$ and\nincreases with increasing $\\eta$. Finally, we analyze quasinormal modes or\nscalar perturbations, we compute them via the 6th-order WKB method, and compare\nthem to the shadow radius methods in the eikonal limit.",
    "pdf_url": "http://arxiv.org/pdf/2505.13286v1",
    "published": "2025-05-19T16:08:14+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "83C57",
      "G.1.8; F.2.1"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.13285v1",
    "title": "On the precise form of the inverse Markov factor for convex sets",
    "authors": [
      "Mikhail A. Komarov"
    ],
    "abstract": "Let $K\\subset \\mathbb{C}$ be a convex compact set, and let $\\Pi_n(K)$ be the\nclass of polynomials of exact degree $n$, all of whose zeros lie in $K$. The\nTur\\'an type inverse Markov factor is defined by $M_n(K)=\\inf_{P\\in \\Pi_n(K)}\n\\left(\\|P'\\|_{C(K)}/\\|P\\|_{C(K)}\\right)$. A combination of two well-known\nresults due to Levenberg and Poletsky (2002) and R\\'ev\\'esz (2006) provides the\nlower bound $M_n(K)\\ge c\\left(wn/d^2+\\sqrt{n}/d\\right)$, $c:=0.00015$, where\n$d>0$ is the diameter of $K$ and $w\\ge 0$ is the minimal width (the smallest\ndistance between two parallel lines between which $K$ lies). We prove that this\nbound is essentially sharp, namely, $M_n(K)\\le\n28\\left(wn/d^2+\\sqrt{n}/d\\right)$ for all $n,w,d$.",
    "pdf_url": "http://arxiv.org/pdf/2505.13285v1",
    "published": "2025-05-19T16:07:32+00:00",
    "categories": [
      "math.CA",
      "41A17"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13284v1",
    "title": "Intuitionistic BV (Extended version)",
    "authors": [
      "Matteo Acclavio",
      "Lutz Strassburger"
    ],
    "abstract": "We present the logic IBV, which is an intuitionistic version of BV, in the\nsense that its restriction to the MLL connectives is exactly IMLL, the\nintuitionistic version of MLL. For this logic we give a deep inference proof\nsystem and show cut elimination. We also show that the logic obtained from IBV\nby dropping the associativity of the new non-commutative seq-connective is an\nintuitionistic variant of the recently introduced logic NML. For this logic,\ncalled INML, we give a cut-free sequent calculus.",
    "pdf_url": "http://arxiv.org/pdf/2505.13284v1",
    "published": "2025-05-19T16:07:16+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13283v1",
    "title": "Accelerating Bayesian Optimal Experimental Design via Local Radial Basis Functions: Application to Soft Material Characterization",
    "authors": [
      "Tianyi Chu",
      "Jonathan B. Estrada",
      "Spencer H. Bryngelson"
    ],
    "abstract": "We develop a computational approach that significantly improves the\nefficiency of Bayesian optimal experimental design (BOED) using local radial\nbasis functions (RBFs). The presented RBF--BOED method uses the intrinsic\nability of RBFs to handle scattered parameter points, a property that aligns\nnaturally with the probabilistic sampling inherent in Bayesian methods. By\nconstructing accurate deterministic surrogates from local neighborhood\ninformation, the method enables high-order approximations with reduced\ncomputational overhead. As a result, computing the expected information gain\n(EIG) requires evaluating only a small uniformly sampled subset of prior\nparameter values, greatly reducing the number of expensive forward-model\nsimulations needed. For demonstration, we apply RBF--BOED to optimize a\nlaser-induced cavitation (LIC) experimental setup, where forward simulations\nfollow from inertial microcavitation rheometry (IMR) and characterize the\nviscoelastic properties of hydrogels. Two experimental design scenarios,\nsingle- and multi-constitutive-model problems, are explored. Results show that\nEIG estimates can be obtained at just 8% of the full computational cost in a\nfive-model problem within a two-dimensional design space. This advance offers a\nscalable path toward optimal experimental design in soft and biological\nmaterials.",
    "pdf_url": "http://arxiv.org/pdf/2505.13283v1",
    "published": "2025-05-19T16:06:23+00:00",
    "categories": [
      "physics.comp-ph",
      "cond-mat.soft"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13282v4",
    "title": "Rank, Chunk and Expand: Lineage-Oriented Reasoning for Taxonomy Expansion",
    "authors": [
      "Sahil Mishra",
      "Kumar Arjun",
      "Tanmoy Chakraborty"
    ],
    "abstract": "Taxonomies are hierarchical knowledge graphs crucial for recommendation\nsystems, and web applications. As data grows, expanding taxonomies is\nessential, but existing methods face key challenges: (1) discriminative models\nstruggle with representation limits and generalization, while (2) generative\nmethods either process all candidates at once, introducing noise and exceeding\ncontext limits, or discard relevant entities by selecting noisy candidates. We\npropose LORex (Lineage-Oriented Reasoning for Taxonomy Expansion), a\nplug-and-play framework that combines discriminative ranking and generative\nreasoning for efficient taxonomy expansion. Unlike prior methods, LORex ranks\nand chunks candidate terms into batches, filtering noise and iteratively\nrefining selections by reasoning candidates' hierarchy to ensure contextual\nefficiency. Extensive experiments across four benchmarks and twelve baselines\nshow that LORex improves accuracy by 12% and Wu & Palmer similarity by 5% over\nstate-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13282v4",
    "published": "2025-05-19T16:06:13+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13281v1",
    "title": "Computer Vision Models Show Human-Like Sensitivity to Geometric and Topological Concepts",
    "authors": [
      "Zekun Wang",
      "Sashank Varma"
    ],
    "abstract": "With the rapid improvement of machine learning (ML) models, cognitive\nscientists are increasingly asking about their alignment with how humans think.\nHere, we ask this question for computer vision models and human sensitivity to\ngeometric and topological (GT) concepts. Under the core knowledge account,\nthese concepts are innate and supported by dedicated neural circuitry. In this\nwork, we investigate an alternative explanation, that GT concepts are learned\n``for free'' through everyday interaction with the environment. We do so using\ncomputer visions models, which are trained on large image datasets. We build on\nprior studies to investigate the overall performance and human alignment of\nthree classes of models -- convolutional neural networks (CNNs),\ntransformer-based models, and vision-language models -- on an odd-one-out task\ntesting 43 GT concepts spanning seven classes. Transformer-based models achieve\nthe highest overall accuracy, surpassing that of young children. They also show\nstrong alignment with children's performance, finding the same classes of\nconcepts easy vs. difficult. By contrast, vision-language models underperform\ntheir vision-only counterparts and deviate further from human profiles,\nindicating that na\\\"ive multimodality might compromise abstract geometric\nsensitivity. These findings support the use of computer vision models to\nevaluate the sufficiency of the learning account for explaining human\nsensitivity to GT concepts, while also suggesting that integrating linguistic\nand visual representations might have unpredicted deleterious consequences.",
    "pdf_url": "http://arxiv.org/pdf/2505.13281v1",
    "published": "2025-05-19T16:04:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13280v1",
    "title": "FlowPure: Continuous Normalizing Flows for Adversarial Purification",
    "authors": [
      "Elias Collaert",
      "Abel Rodr√≠guez",
      "Sander Joos",
      "Lieven Desmet",
      "Vera Rimmer"
    ],
    "abstract": "Despite significant advancements in the area, adversarial robustness remains\na critical challenge in systems employing machine learning models. The removal\nof adversarial perturbations at inference time, known as adversarial\npurification, has emerged as a promising defense strategy. To achieve this,\nstate-of-the-art methods leverage diffusion models that inject Gaussian noise\nduring a forward process to dilute adversarial perturbations, followed by a\ndenoising step to restore clean samples before classification. In this work, we\npropose FlowPure, a novel purification method based on Continuous Normalizing\nFlows (CNFs) trained with Conditional Flow Matching (CFM) to learn mappings\nfrom adversarial examples to their clean counterparts. Unlike prior\ndiffusion-based approaches that rely on fixed noise processes, FlowPure can\nleverage specific attack knowledge to improve robustness under known threats,\nwhile also supporting a more general stochastic variant trained on Gaussian\nperturbations for settings where such knowledge is unavailable. Experiments on\nCIFAR-10 and CIFAR-100 demonstrate that our method outperforms state-of-the-art\npurification-based defenses in preprocessor-blind and white-box scenarios, and\ncan do so while fully preserving benign accuracy in the former. Moreover, our\nresults show that not only is FlowPure a highly effective purifier but it also\nholds a strong potential for adversarial detection, identifying\npreprocessor-blind PGD samples with near-perfect accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.13280v1",
    "published": "2025-05-19T16:04:43+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13279v2",
    "title": "Event-Driven Dynamic Scene Depth Completion",
    "authors": [
      "Zhiqiang Yan",
      "Jianhao Jiao",
      "Zhengxue Wang",
      "Gim Hee Lee"
    ],
    "abstract": "Depth completion in dynamic scenes poses significant challenges due to rapid\nego-motion and object motion, which can severely degrade the quality of input\nmodalities such as RGB images and LiDAR measurements. Conventional RGB-D\nsensors often struggle to align precisely and capture reliable depth under such\nconditions. In contrast, event cameras with their high temporal resolution and\nsensitivity to motion at the pixel level provide complementary cues that are\n%particularly beneficial in dynamic environments.To this end, we propose\nEventDC, the first event-driven depth completion framework. It consists of two\nkey components: Event-Modulated Alignment (EMA) and Local Depth Filtering\n(LDF). Both modules adaptively learn the two fundamental components of\nconvolution operations: offsets and weights conditioned on motion-sensitive\nevent streams. In the encoder, EMA leverages events to modulate the sampling\npositions of RGB-D features to achieve pixel redistribution for improved\nalignment and fusion. In the decoder, LDF refines depth estimations around\nmoving objects by learning motion-aware masks from events. Additionally,\nEventDC incorporates two loss terms to further benefit global alignment and\nenhance local depth recovery. Moreover, we establish the first benchmark for\nevent-based depth completion comprising one real-world and two synthetic\ndatasets to facilitate future research. Extensive experiments on this benchmark\ndemonstrate the superiority of our EventDC.",
    "pdf_url": "http://arxiv.org/pdf/2505.13279v2",
    "published": "2025-05-19T16:02:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13278v1",
    "title": "Hybrid Voting-Based Task Assignment in Modular Construction Scenarios",
    "authors": [
      "Daniel Weiner",
      "Raj Korpan"
    ],
    "abstract": "Modular construction, involving off-site prefabrication and on-site assembly,\noffers significant advantages but presents complex coordination challenges for\nrobotic automation. Effective task allocation is critical for leveraging\nmulti-agent systems (MAS) in these structured environments. This paper\nintroduces the Hybrid Voting-Based Task Assignment (HVBTA) framework, a novel\napproach to optimizing collaboration between heterogeneous multi-agent\nconstruction teams. Inspired by human reasoning in task delegation, HVBTA\nuniquely integrates multiple voting mechanisms with the capabilities of a Large\nLanguage Model (LLM) for nuanced suitability assessment between agent\ncapabilities and task requirements. The framework operates by assigning\nCapability Profiles to agents and detailed requirement lists called Task\nDescriptions to construction tasks, subsequently generating a quantitative\nSuitability Matrix. Six distinct voting methods, augmented by a pre-trained\nLLM, analyze this matrix to robustly identify the optimal agent for each task.\nConflict-Based Search (CBS) is integrated for decentralized, collision-free\npath planning, ensuring efficient and safe spatio-temporal coordination of the\nrobotic team during assembly operations. HVBTA enables efficient, conflict-free\nassignment and coordination, facilitating potentially faster and more accurate\nmodular assembly. Current work is evaluating HVBTA's performance across various\nsimulated construction scenarios involving diverse robotic platforms and task\ncomplexities. While designed as a generalizable framework for any domain with\nclearly definable tasks and capabilities, HVBTA will be particularly effective\nfor addressing the demanding coordination requirements of multi-agent\ncollaborative robotics in modular construction due to the predetermined\nconstruction planning involved.",
    "pdf_url": "http://arxiv.org/pdf/2505.13278v1",
    "published": "2025-05-19T16:01:36+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13277v1",
    "title": "Low-regret Strategies for Energy Systems Planning in a Highly Uncertain Future",
    "authors": [
      "Gabriel Wiest",
      "Niklas Nolzen",
      "Florian Baader",
      "Andr√© Bardow",
      "Stefano Moret"
    ],
    "abstract": "Large uncertainties in the energy transition urge decision-makers to develop\nlow-regret strategies, i.e., strategies that perform well regardless of how the\nfuture unfolds. To address this challenge, we introduce a decision-support\nframework that identifies low-regret strategies in energy system planning under\nuncertainty. Our framework (i) automatically identifies strategies, (ii)\nevaluates their performance in terms of regret, (iii) assesses the key drivers\nof regret, and (iv) supports the decision process with intuitive decision\ntrees, regret curves and decision maps. We apply the framework to evaluate the\noptimal use of biomass in the transition to net-zero energy systems,\nconsidering all major biomass utilization options: biofuels, biomethane,\nchemicals, hydrogen, biochar, electricity, and heat. Producing fuels and\nchemicals from biomass performs best across various decision-making criteria.\nIn contrast, the current use of biomass, mainly for low-temperature heat\nsupply, results in high regret, making it a must-avoid in the energy\ntransition.",
    "pdf_url": "http://arxiv.org/pdf/2505.13277v1",
    "published": "2025-05-19T16:00:48+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13276v1",
    "title": "CHAD-KG: A Knowledge Graph for Representing Cultural Heritage Objects and Digitisation Paradata",
    "authors": [
      "Sebastian Barzaghi",
      "Arianna Moretti",
      "Ivan Heibi",
      "Silvio Peroni"
    ],
    "abstract": "This paper presents CHAD-KG, a knowledge graph designed to describe\nbibliographic metadata and digitisation paradata of cultural heritage objects\nin exhibitions, museums, and collections. It also documents the related data\nmodel and materialisation engine. Originally based on two tabular datasets, the\ndata was converted into RDF according to CHAD-AP, an OWL application profile\nbuilt on standards like CIDOC-CRM, LRMoo, CRMdig, and Getty AAT. A reproducible\npipeline, developed with a Morph-KGC extension, was used to generate the graph.\nCHAD-KG now serves as the main metadata source for the Digital Twin of the\ntemporary exhibition titled \\emph{The Other Renaissance - Ulisse Aldrovandi and\nThe Wonders Of The World}, and other collections related to the digitisation\nwork under development in a nationwide funded project, i.e. Project CHANGES\n(https://fondazionechanges.org). To ensure accessibility and reuse, it offers a\nSPARQL endpoint, a user interface, open documentation, and is published on\nZenodo under a CC0 license. The project improves the semantic interoperability\nof cultural heritage data, with future work aiming to extend the data model and\nmaterialisation pipeline to better capture the complexities of acquisition and\ndigitisation, further enrich the dataset and broaden its relevance to similar\ninitiatives.",
    "pdf_url": "http://arxiv.org/pdf/2505.13276v1",
    "published": "2025-05-19T15:59:17+00:00",
    "categories": [
      "cs.DL"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2505.14722v1",
    "title": "ComBAT Harmonization for diffusion MRI: Challenges and Best Practices",
    "authors": [
      "Pierre-Marc Jodoin",
      "Manon Edde",
      "Gabriel Girard",
      "F√©lix Dumais",
      "Guillaume Theaud",
      "Matthieu Dumont",
      "Jean-Christophe Houde",
      "Yoan David",
      "Maxime Descoteaux"
    ],
    "abstract": "Over the years, ComBAT has become the standard method for harmonizing\nMRI-derived measurements, with its ability to compensate for site-related\nadditive and multiplicative biases while preserving biological variability.\nHowever, ComBAT relies on a set of assumptions that, when violated, can result\nin flawed harmonization. In this paper, we thoroughly review ComBAT's\nmathematical foundation, outlining these assumptions, and exploring their\nimplications for the demographic composition necessary for optimal results.\n  Through a series of experiments involving a slightly modified version of\nComBAT called Pairwise-ComBAT tailored for normative modeling applications, we\nassess the impact of various population characteristics, including population\nsize, age distribution, the absence of certain covariates, and the magnitude of\nadditive and multiplicative factors. Based on these experiments, we present\nfive essential recommendations that should be carefully considered to enhance\nconsistency and supporting reproducibility, two essential factors for open\nscience, collaborative research, and real-life clinical deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.14722v1",
    "published": "2025-05-19T15:58:33+00:00",
    "categories": [
      "stat.AP",
      "cs.CV",
      "cs.LG",
      "physics.med-ph"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.17071v1",
    "title": "What's in a prompt? Language models encode literary style in prompt embeddings",
    "authors": [
      "Rapha√´l Sarfati",
      "Haley Moller",
      "Toni J. B. Liu",
      "Nicolas Boull√©",
      "Christopher Earls"
    ],
    "abstract": "Large language models use high-dimensional latent spaces to encode and\nprocess textual information. Much work has investigated how the conceptual\ncontent of words translates into geometrical relationships between their vector\nrepresentations. Fewer studies analyze how the cumulative information of an\nentire prompt becomes condensed into individual embeddings under the action of\ntransformer layers. We use literary pieces to show that information about\nintangible, rather than factual, aspects of the prompt are contained in deep\nrepresentations. We observe that short excerpts (10 - 100 tokens) from\ndifferent novels separate in the latent space independently from what\nnext-token prediction they converge towards. Ensembles from books from the same\nauthors are much more entangled than across authors, suggesting that embeddings\nencode stylistic features. This geometry of style may have applications for\nauthorship attribution and literary analysis, but most importantly reveals the\nsophistication of information processing and compression accomplished by\nlanguage models.",
    "pdf_url": "http://arxiv.org/pdf/2505.17071v1",
    "published": "2025-05-19T15:56:13+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13275v1",
    "title": "Neural Functional: Learning Function to Scalar Maps for Neural PDE Surrogates",
    "authors": [
      "Anthony Zhou",
      "Amir Barati Farimani"
    ],
    "abstract": "Many architectures for neural PDE surrogates have been proposed in recent\nyears, largely based on neural networks or operator learning. In this work, we\nderive and propose a new architecture, the Neural Functional, which learns\nfunction to scalar mappings. Its implementation leverages insights from\noperator learning and neural fields, and we show the ability of neural\nfunctionals to implicitly learn functional derivatives. For the first time,\nthis allows for an extension of Hamiltonian mechanics to neural PDE surrogates\nby learning the Hamiltonian functional and optimizing its functional\nderivatives. We demonstrate that the Hamiltonian Neural Functional can be an\neffective surrogate model through improved stability and conserving energy-like\nquantities on 1D and 2D PDEs. Beyond PDEs, functionals are prevalent in\nphysics; functional approximation and learning with its gradients may find\nother uses, such as in molecular dynamics or design optimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.13275v1",
    "published": "2025-05-19T15:55:38+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13274v1",
    "title": "Weak convergence of the integral of semi-Markov processes",
    "authors": [
      "Andrea Pedicone",
      "Fabrizio Cinque"
    ],
    "abstract": "We study the asymptotic properties, in the weak sense, of regenerative\nprocesses and Markov renewal processes. For the latter, we derive both\nrenewal-type results, also concerning the related counting process, and\nergodic-type ones, including the so-called phi-mixing property. This\ntheoretical framework permits us to study the weak limit of the integral of a\nsemi-Markov process, which can be interpret as the position of a particle\nmoving with finite velocities taken for a random time according to the Markov\nrenewal process underlying the semi-Markov one. Under mild conditions, we\nobtain the weak convergence to scaled Brownian motion. As a particular case,\nthis result establishes the weak convergence of the classical generalized\ntelegraph process.",
    "pdf_url": "http://arxiv.org/pdf/2505.13274v1",
    "published": "2025-05-19T15:55:11+00:00",
    "categories": [
      "math.PR",
      "60F17, 60K15, 60F05"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13273v1",
    "title": "Seeing the Unseen: How EMoE Unveils Bias in Text-to-Image Diffusion Models",
    "authors": [
      "Lucas Berry",
      "Axel Brando",
      "Wei-Di Chang",
      "Juan Camilo Gamboa Higuera",
      "David Meger"
    ],
    "abstract": "Estimating uncertainty in text-to-image diffusion models is challenging\nbecause of their large parameter counts (often exceeding 100 million) and\noperation in complex, high-dimensional spaces with virtually infinite input\npossibilities. In this paper, we propose Epistemic Mixture of Experts (EMoE), a\nnovel framework for efficiently estimating epistemic uncertainty in diffusion\nmodels. EMoE leverages pre-trained networks without requiring additional\ntraining, enabling direct uncertainty estimation from a prompt. We leverage a\nlatent space within the diffusion process that captures epistemic uncertainty\nbetter than existing methods. Experimental results on the COCO dataset\ndemonstrate EMoE's effectiveness, showing a strong correlation between\nuncertainty and image quality. Additionally, EMoE identifies under-sampled\nlanguages and regions with higher uncertainty, revealing hidden biases in the\ntraining set. This capability demonstrates the relevance of EMoE as a tool for\naddressing fairness and accountability in AI-generated content.",
    "pdf_url": "http://arxiv.org/pdf/2505.13273v1",
    "published": "2025-05-19T15:53:32+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13272v1",
    "title": "Null-adjusted persistence function for high-resolution community detection",
    "authors": [
      "Alessandro Avellone",
      "Paolo Bartesaghi",
      "Stefano Benati",
      "Christos Charalambous",
      "Rosanna Grassi"
    ],
    "abstract": "Modularity and persistence probability are two widely used quality functions\nfor detecting communities in complex networks. In this paper, we introduce a\nnew objective function called null-adjusted persistence, which incorporates\nfeatures from both modularity and persistence probability, as it implies a\ncomparison of persistence probability with the same null model of modularity.\nWe prove key analytic properties of this new function. We show that the\nnull-adjusted persistence overcomes the limitations of modularity, such as\nscaling behavior and resolution limits, and the limitation of the persistence\nprobability, which is an increasing function with respect to the cluster size.\nWe propose to find the partition that maximizes the null-adjusted persistence\nwith a variation of the Louvain method and we tested its effectiveness on\nbenchmark and real networks. We found out that maximizing null-adjusted\npersistence outperforms modularity maximization, as it detects higher\nresolution partitions in dense and large networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13272v1",
    "published": "2025-05-19T15:52:49+00:00",
    "categories": [
      "physics.soc-ph",
      "math.OC"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13271v2",
    "title": "CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning",
    "authors": [
      "Lei Sheng",
      "Shuai-Shuai Xu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated strong capabilities in\ntranslating natural language questions about relational databases into SQL\nqueries. In particular, test-time scaling techniques such as Self-Consistency\nand Self-Correction can enhance SQL generation accuracy by increasing\ncomputational effort during inference. However, these methods have notable\nlimitations: Self-Consistency may select suboptimal outputs despite majority\nvotes, while Self-Correction typically addresses only syntactic errors. To\nleverage the strengths of both approaches, we propose CSC-SQL, a novel method\nthat integrates Self-Consistency and Self-Correction. CSC-SQL selects the two\nmost frequently occurring outputs from parallel sampling and feeds them into a\nmerge revision model for correction. Additionally, we employ the Group Relative\nPolicy Optimization (GRPO) algorithm to fine-tune both the SQL generation and\nrevision models via reinforcement learning, significantly enhancing output\nquality. Experimental results confirm the effectiveness and generalizability of\nCSC-SQL. On the BIRD private test set, our 7B model achieves 71.72\\% execution\naccuracy, while the 32B model achieves 73.67\\%. The code has been open sourced\nat https://github.com/CycloneBoy/csc_sql.",
    "pdf_url": "http://arxiv.org/pdf/2505.13271v2",
    "published": "2025-05-19T15:52:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13270v1",
    "title": "Distilling a speech and music encoder with task arithmetic",
    "authors": [
      "Fabian Ritter-Gutierrez",
      "Yi-Cheng Lin",
      "Jui-Chiang Wei",
      "Jeremy H. M Wong",
      "Eng Siong Chng",
      "Nancy F. Chen",
      "Hung-yi Lee"
    ],
    "abstract": "Despite the progress in self-supervised learning (SSL) for speech and music,\nexisting models treat these domains separately, limiting their capacity for\nunified audio understanding. A unified model is desirable for applications that\nrequire general representations, e.g. audio large language models. Nonetheless,\ndirectly training a general model for speech and music is computationally\nexpensive. Knowledge Distillation of teacher ensembles may be a natural\nsolution, but we posit that decoupling the distillation of the speech and music\nSSL models allows for more flexibility. Thus, we propose to learn distilled\ntask vectors and then linearly interpolate them to form a unified speech+music\nmodel. This strategy enables flexible domain emphasis through adjustable\nweights and is also simpler to train. Experiments on speech and music\nbenchmarks demonstrate that our method yields superior overall performance\ncompared to ensemble distillation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13270v1",
    "published": "2025-05-19T15:51:53+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.13582v1",
    "title": "Uncovering Critical Sets of Deep Neural Networks via Sample-Independent Critical Lifting",
    "authors": [
      "Leyang Zhang",
      "Yaoyu Zhang",
      "Tao Luo"
    ],
    "abstract": "This paper investigates the sample dependence of critical points for neural\nnetworks. We introduce a sample-independent critical lifting operator that\nassociates a parameter of one network with a set of parameters of another, thus\ndefining sample-dependent and sample-independent lifted critical points. We\nthen show by example that previously studied critical embeddings do not capture\nall sample-independent lifted critical points. Finally, we demonstrate the\nexistence of sample-dependent lifted critical points for sufficiently large\nsample sizes and prove that saddles appear among them.",
    "pdf_url": "http://arxiv.org/pdf/2505.13582v1",
    "published": "2025-05-19T15:50:36+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13269v2",
    "title": "Correlation between U/Th and Pb/Os abundance ratios and its application in nuclear cosmochronology",
    "authors": [
      "Y. Y. Huang",
      "Q. Q. Cui",
      "X. H. Wu",
      "S. Q. Zhang"
    ],
    "abstract": "The abundance ratios of radioactive elements U/Th and stable elements Pb/Os\nfrom the $r$-process are found to have a strong correlation. This correlation\nis quite robust with respect to astrophysical conditions. The U/Th-Pb/Os\ncorrelation is then applied to provide customized initial abundance ratios U/Th\nfrom the observed abundance ratios Pb/Os for six $r$-process enhanced\nmetal-poor stars respectively. Ages of these six metal-poor stars are predicted\nby the U/Th chronometer, which are approximately between $11$ and $15$ Gyr.\nTheir ages are compatible with the cosmic age of 13.8 billion years predicted\nfrom the cosmic microwave background radiation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13269v2",
    "published": "2025-05-19T15:49:45+00:00",
    "categories": [
      "nucl-th",
      "astro-ph.SR"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.14721v1",
    "title": "The emerging AI 'revolution tranquille' in America",
    "authors": [
      "Omar R. Malik"
    ],
    "abstract": "Using data from the U.S. Census Bureaus Business Trends and Outlook Survey\n(BTOS), I examine the adoption of AI among US firms at national, state,\nindustry, and firm size levels. I find that adoption remains overall low (only\naround 7% of firms currently use AI), but is on a steady upward trajectory with\na rising share of firms planning to implement AI. Adoption rates vary\nsignificantly across regions and sectors: some states are emerging as early\nadopters, while others lag, and knowledge-intensive industries (such as\ninformation technology and professional services) along with larger firms show\nhigher openness to AI adoption compared to sectors like construction or small\nbusinesses. In general, these trends indicate that a quiet revolution in AI\nadoption is underway; a gradual but expanding diffusion of AI across the\neconomy with important implications for future productivity and policy.",
    "pdf_url": "http://arxiv.org/pdf/2505.14721v1",
    "published": "2025-05-19T15:49:32+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.13268v1",
    "title": "Representation of perceived prosodic similarity of conversational feedback",
    "authors": [
      "Livia Qian",
      "Carol Figueroa",
      "Gabriel Skantze"
    ],
    "abstract": "Vocal feedback (e.g., `mhm', `yeah', `okay') is an important component of\nspoken dialogue and is crucial to ensuring common ground in conversational\nsystems. The exact meaning of such feedback is conveyed through both lexical\nand prosodic form. In this work, we investigate the perceived prosodic\nsimilarity of vocal feedback with the same lexical form, and to what extent\nexisting speech representations reflect such similarities. A triadic comparison\ntask with recruited participants is used to measure perceived similarity of\nfeedback responses taken from two different datasets. We find that spectral and\nself-supervised speech representations encode prosody better than extracted\npitch features, especially in the case of feedback from the same speaker. We\nalso find that it is possible to further condense and align the representations\nto human perception through contrastive learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.13268v1",
    "published": "2025-05-19T15:47:51+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13267v1",
    "title": "Radio continuum spectra of SFGs in the XMM-LSS Field below-threshold",
    "authors": [
      "E. F. Ocran",
      "A. R. Taylor",
      "J. M. Stil",
      "M. Vaccari",
      "S. Sekhar",
      "C. H. Ishwara-Chandra",
      "Jae-Woo Kim"
    ],
    "abstract": "This study investigates the radio spectral properties of\n\\textit{K}$_{S}$-selected star-forming galaxies (SFGs) in the XMM-LSS field\nusing extensive multiwavelength data. By employing various diagnostics, SFGs\nare distinguished from quiescent galaxies and AGN across seven redshift bins\n($\\rm{0.1\\leq\\,\\textit{z}\\,\\leq\\,3.0}$). The broadband radio frequency spectral\nenergy distribution is analysed at observer-frame frequencies from 144 to 1500\nMHz using median stacking techniques correcting for median flux boosting. We\ninvestigate the relationship between the radio spectral index, $\\alpha$ (where\n$S\\propto\\nu^{\\alpha}$) and redshift ($z$). Our analysis reveals no significant\ninverse correlation between $\\alpha$ and $z$, indicating that the radio\nspectrum remains independent with varying redshift. We fit the stacked median\nradio SEDs with a power law (\\textit{PL}), curved power law (\\textit{CPL}) and\ndouble power law (\\textit{DPL}) models. For the \\textit{DPL} and \\textit{CPL}\nmodels, we observe a consistent steepening of the low-frequency spectral index\nacross all redshift bins. For the \\textit{CPL} model, the curvature term $q$ is\ngreater than zero in all redshift bins. Model comparisons indicate that spectra\nare generally well fitted by all the models considered. At 1500 MHz, SFGs\ndisplay both a steep synchrotron component and a flat free-free emission\ncomponent, with a thermal fraction consistently around 11$\\%$ to 18$\\%$.\nFurther deep radio observations, with higher resolution to better deal with\nsource blending and confusion noise and wider frequency coverage to better\nseparate non-thermal and thermal radio emission, are required to reveal the\ndetailed physical processes, thus clarifying the nature of radio sources.",
    "pdf_url": "http://arxiv.org/pdf/2505.13267v1",
    "published": "2025-05-19T15:47:45+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13266v1",
    "title": "DB3D-L: Depth-aware BEV Feature Transformation for Accurate 3D Lane Detection",
    "authors": [
      "Yehao Liu",
      "Xiaosu Xu",
      "Zijian Wang",
      "Yiqing Yao"
    ],
    "abstract": "3D Lane detection plays an important role in autonomous driving. Recent\nadvances primarily build Birds-Eye-View (BEV) feature from front-view (FV)\nimages to perceive 3D information of Lane more effectively. However,\nconstructing accurate BEV information from FV image is limited due to the\nlacking of depth information, causing previous works often rely heavily on the\nassumption of a flat ground plane. Leveraging monocular depth estimation to\nassist in constructing BEV features is less constrained, but existing methods\nstruggle to effectively integrate the two tasks. To address the above issue, in\nthis paper, an accurate 3D lane detection method based on depth-aware BEV\nfeature transtormation is proposed. In detail, an effective feature extraction\nmodule is designed, in which a Depth Net is integrated to obtain the vital\ndepth information for 3D perception, thereby simplifying the complexity of view\ntransformation. Subquently a feature reduce module is proposed to reduce height\ndimension of FV features and depth features, thereby enables effective fusion\nof crucial FV features and depth features. Then a fusion module is designed to\nbuild BEV feature from prime FV feature and depth information. The proposed\nmethod performs comparably with state-of-the-art methods on both synthetic\nApollo, realistic OpenLane datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.13266v1",
    "published": "2025-05-19T15:47:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13265v2",
    "title": "Selfless reduced free product $C^*$-algebras",
    "authors": [
      "Ben Hayes",
      "Srivatsav Kunnawalkam Elayavalli",
      "Leonel Robert"
    ],
    "abstract": "We study selflessness in the general setting of reduced free products of\n$C^*$-algebras. Towards this end, we develop a suitable theory of rapid decay\nfor filtrations in arbitrary $C^*$-probability spaces. We provide several\nnatural examples and permanence properties of this phenomenon. By using this\nframework in combination with von Neumann algebraic techniques involving\napproximate forms of orthogonality, we are able to prove selflessness for\ngeneral families of reduced free product $C^*$-algebras. As an instance of our\nresults, we prove selflessness and thus strict comparison for the canonical\n$C^*$-algebras generated by Voiculescu's free semicircular systems. Our results\nalso provide new examples of purely infinite reduced free products.",
    "pdf_url": "http://arxiv.org/pdf/2505.13265v2",
    "published": "2025-05-19T15:46:40+00:00",
    "categories": [
      "math.OA"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13264v1",
    "title": "Net-Zero: A Comparative Study on Neural Network Design for Climate-Economic PDEs Under Uncertainty",
    "authors": [
      "Carlos Rodriguez-Pardo",
      "Louis Daumas",
      "Leonardo Chiani",
      "Massimo Tavoni"
    ],
    "abstract": "Climate-economic modeling under uncertainty presents significant\ncomputational challenges that may limit policymakers' ability to address\nclimate change effectively. This paper explores neural network-based approaches\nfor solving high-dimensional optimal control problems arising from models that\nincorporate ambiguity aversion in climate mitigation decisions. We develop a\ncontinuous-time endogenous-growth economic model that accounts for multiple\nmitigation pathways, including emission-free capital and carbon intensity\nreductions. Given the inherent complexity and high dimensionality of these\nmodels, traditional numerical methods become computationally intractable. We\nbenchmark several neural network architectures against finite-difference\ngenerated solutions, evaluating their ability to capture the dynamic\ninteractions between uncertainty, technology transitions, and optimal climate\npolicy. Our findings demonstrate that appropriate neural architecture selection\nsignificantly impacts both solution accuracy and computational efficiency when\nmodeling climate-economic systems under uncertainty. These methodological\nadvances enable more sophisticated modeling of climate policy decisions,\nallowing for better representation of technology transitions and\nuncertainty-critical elements for developing effective mitigation strategies in\nthe face of climate change.",
    "pdf_url": "http://arxiv.org/pdf/2505.13264v1",
    "published": "2025-05-19T15:46:12+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "cs.PF",
      "math.AP",
      "68T07 (Primary) 35Q91, 91B76 (Secondary)",
      "I.2.1; I.5.1; J.4"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13263v1",
    "title": "Are requirements really all you need? A case study of LLM-driven configuration code generation for automotive simulations",
    "authors": [
      "Krzysztof Lebioda",
      "Nenad Petrovic",
      "Fengjunjie Pan",
      "Vahid Zolfaghari",
      "Andre Schamschurko",
      "Alois Knoll"
    ],
    "abstract": "Large Language Models (LLMs) are taking many industries by storm. They\npossess impressive reasoning capabilities and are capable of handling complex\nproblems, as shown by their steadily improving scores on coding and\nmathematical benchmarks. However, are the models currently available truly\ncapable of addressing real-world challenges, such as those found in the\nautomotive industry? How well can they understand high-level, abstract\ninstructions? Can they translate these instructions directly into functional\ncode, or do they still need help and supervision? In this work, we put one of\nthe current state-of-the-art models to the test. We evaluate its performance in\nthe task of translating abstract requirements, extracted from automotive\nstandards and documents, into configuration code for CARLA simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13263v1",
    "published": "2025-05-19T15:44:24+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13262v1",
    "title": "Rational points on K3 surfaces of degree 2",
    "authors": [
      "J√∫lia Mart√≠nez-Mar√≠n"
    ],
    "abstract": "A K3 surface over a number field has infinitely many rational points over a\nfinite field extension. For K3 surfaces of degree 2, arising as double covers\nof $\\mathbb{P}^2$ branched along a smooth sextic curve, we give a bound for the\ndegree of such an extension. Moreover, using ideas of van Luijk and a surface\nconstructed by Enselhans and Jahnel, we give an explicit family of K3 surfaces\nof degree 2 defined over $\\mathbb{Q}$ with geometric Picard number 1 and\ninfinitely many $\\mathbb{Q}$-rational points that is Zariski dense in the\nmoduli space of K3 surfaces of degree 2.",
    "pdf_url": "http://arxiv.org/pdf/2505.13262v1",
    "published": "2025-05-19T15:43:35+00:00",
    "categories": [
      "math.NT",
      "math.AG"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13261v1",
    "title": "Unlocking the Potential of Difficulty Prior in RL-based Multimodal Reasoning",
    "authors": [
      "Mingrui Chen",
      "Haogeng Liu",
      "Hao Liang",
      "Huaibo Huang",
      "Wentao Zhang",
      "Ran He"
    ],
    "abstract": "In this work, we investigate how explicitly modeling problem's difficulty\nprior information shapes the effectiveness of reinforcement learning based\nfine-tuning for multimodal reasoning. Our exploration mainly comprises of\nfollowing three perspective: First, through offline data curation, we analyze\nthe U-shaped difficulty distribution of two given datasets using the base model\nby multi-round sampling, and then filter out prompts that are either too simple\nor extremely difficult to provide meaningful gradients and perform subsequent\ntwo-stage training. Second, we implement an online advantage differentiation,\ncomputing group-wise empirical accuracy as a difficulty proxy to adaptively\nreweight advantages estimation, providing stronger learning signals for more\nchallenging problems. Finally, we introduce difficulty hints as explicit\nprompts for more complex samples in the second training stage, encouraging the\nmodel to calibrate its reasoning depth and perform reflective validation\nchecks. Our comprehensive approach demonstrates significant performances across\nvarious multi-modal mathematical reasoning benchmarks with only 2K+0.6K\ntwo-stage training data.",
    "pdf_url": "http://arxiv.org/pdf/2505.13261v1",
    "published": "2025-05-19T15:43:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13260v2",
    "title": "Some remarks on Quillen's D√©vissage theorem",
    "authors": [
      "Alexander I. Efimov"
    ],
    "abstract": "In this paper we give a different proof of Quillen's D\\'evissage theorem\nusing Barwick's theorem of the heart. The key ingredient is a certain short\nexact sequence of dg categories, which is closely related with the\nAuslander-type construction for nilpotent extensions which was used in the\npapers of Kuznetsov-Lunts \\cite{KL15}, Land-Tamme \\cite{LT19} and the author\n\\cite{E20}.",
    "pdf_url": "http://arxiv.org/pdf/2505.13260v2",
    "published": "2025-05-19T15:42:40+00:00",
    "categories": [
      "math.KT",
      "math.AG",
      "math.CT",
      "19D55"
    ],
    "primary_category": "math.KT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13581v1",
    "title": "RAR: Setting Knowledge Tripwires for Retrieval Augmented Rejection",
    "authors": [
      "Tommaso Mario Buonocore",
      "Enea Parimbelli"
    ],
    "abstract": "Content moderation for large language models (LLMs) remains a significant\nchallenge, requiring flexible and adaptable solutions that can quickly respond\nto emerging threats. This paper introduces Retrieval Augmented Rejection (RAR),\na novel approach that leverages a retrieval-augmented generation (RAG)\narchitecture to dynamically reject unsafe user queries without model\nretraining. By strategically inserting and marking malicious documents into the\nvector database, the system can identify and reject harmful requests when these\ndocuments are retrieved. Our preliminary results show that RAR achieves\ncomparable performance to embedded moderation in LLMs like Claude 3.5 Sonnet,\nwhile offering superior flexibility and real-time customization capabilities, a\nfundamental feature to timely address critical vulnerabilities. This approach\nintroduces no architectural changes to existing RAG systems, requiring only the\naddition of specially crafted documents and a simple rejection mechanism based\non retrieval results.",
    "pdf_url": "http://arxiv.org/pdf/2505.13581v1",
    "published": "2025-05-19T15:41:39+00:00",
    "categories": [
      "cs.IR",
      "cs.CL",
      "cs.CR",
      "68M25, 68T07",
      "I.2.7; K.6.5"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13259v2",
    "title": "From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery",
    "authors": [
      "Tianshi Zheng",
      "Zheye Deng",
      "Hong Ting Tsang",
      "Weiqi Wang",
      "Jiaxin Bai",
      "Zihao Wang",
      "Yangqiu Song"
    ],
    "abstract": "Large Language Models (LLMs) are catalyzing a paradigm shift in scientific\ndiscovery, evolving from task-specific automation tools into increasingly\nautonomous agents and fundamentally redefining research processes and human-AI\ncollaboration. This survey systematically charts this burgeoning field, placing\na central focus on the changing roles and escalating capabilities of LLMs in\nscience. Through the lens of the scientific method, we introduce a foundational\nthree-level taxonomy-Tool, Analyst, and Scientist-to delineate their escalating\nautonomy and evolving responsibilities within the research lifecycle. We\nfurther identify pivotal challenges and future research trajectories such as\nrobotic automation, self-improvement, and ethical governance. Overall, this\nsurvey provides a conceptual architecture and strategic foresight to navigate\nand shape the future of AI-driven scientific discovery, fostering both rapid\ninnovation and responsible advancement. Github Repository:\nhttps://github.com/HKUST-KnowComp/Awesome-LLM-Scientific-Discovery.",
    "pdf_url": "http://arxiv.org/pdf/2505.13259v2",
    "published": "2025-05-19T15:41:32+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13258v1",
    "title": "Effective and Transparent RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability",
    "authors": [
      "Jingyi Ren",
      "Yekun Xu",
      "Xiaolong Wang",
      "Weitao Li",
      "Weizhi Ma",
      "Yang Liu"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has significantly improved the\nperformance of large language models (LLMs) on knowledge-intensive domains.\nHowever, although RAG achieved successes across distinct domains, there are\nstill some unsolved challenges: 1) Effectiveness. Existing research mainly\nfocuses on developing more powerful RAG retrievers, but how to enhance the\ngenerator's (LLM's) ability to utilize the retrieved information for reasoning\nand generation? 2) Transparency. Most RAG methods ignore which retrieved\ncontent actually contributes to the reasoning process, resulting in a lack of\ninterpretability and visibility. To address this, we propose ARENA\n(Adaptive-Rewarded Evidence Navigation Agent), a transparent RAG generator\nframework trained via reinforcement learning (RL) with our proposed rewards.\nBased on the structured generation and adaptive reward calculation, our\nRL-based training enables the model to identify key evidence, perform\nstructured reasoning, and generate answers with interpretable decision traces.\nApplied to Qwen2.5-7B-Instruct and Llama3.1-8B-Instruct, abundant experiments\nwith various RAG baselines demonstrate that our model achieves 10-30%\nimprovements on all multi-hop QA datasets, which is comparable with the SOTA\nCommercially-developed LLMs (e.g., OpenAI-o1, DeepSeek-R1). Further analyses\nshow that ARENA has strong flexibility to be adopted on new datasets without\nextra training. Our models and codes are publicly released.",
    "pdf_url": "http://arxiv.org/pdf/2505.13258v1",
    "published": "2025-05-19T15:40:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13257v1",
    "title": "WikiPersonas: What Can We Learn From Personalized Alignment to Famous People?",
    "authors": [
      "Zilu Tang",
      "Afra Feyza Aky√ºrek",
      "Ekin Aky√ºrek",
      "Derry Wijaya"
    ],
    "abstract": "Preference alignment has become a standard pipeline in finetuning models to\nfollow \\emph{generic} human preferences. Majority of work seeks to optimize\nmodel to produce responses that would be preferable \\emph{on average},\nsimplifying the diverse and often \\emph{contradicting} space of human\npreferences. While research has increasingly focused on personalized alignment:\nadapting models to individual user preferences, there is a lack of personalized\npreference dataset which focus on nuanced individual-level preferences. To\naddress this, we introduce WikiPersona: the first fine-grained personalization\nusing well-documented, famous individuals. Our dataset challenges models to\nalign with these personas through an interpretable process: generating\nverifiable textual descriptions of a persona's background and preferences in\naddition to alignment. We systematically evaluate different personalization\napproaches and find that as few-shot prompting with preferences and fine-tuning\nfail to simultaneously ensure effectiveness and efficiency, using\n\\textit{inferred personal preferences} as prefixes enables effective\npersonalization, especially in topics where preferences clash while leading to\nmore equitable generalization across unseen personas.",
    "pdf_url": "http://arxiv.org/pdf/2505.13257v1",
    "published": "2025-05-19T15:39:48+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13256v2",
    "title": "Soft bounds for local triple products and the subconvexity-QUE implication for $\\mathrm{GL}_2$",
    "authors": [
      "Paul D. Nelson"
    ],
    "abstract": "We give a soft proof of a uniform upper bound for the local factors in the\ntriple product formula, sufficient for deducing effective and general forms of\nquantum unique ergodicity (QUE) from subconvexity.",
    "pdf_url": "http://arxiv.org/pdf/2505.13256v2",
    "published": "2025-05-19T15:39:31+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13255v2",
    "title": "Policy Contrastive Decoding for Robotic Foundation Models",
    "authors": [
      "Shihan Wu",
      "Ji Zhang",
      "Xu Luo",
      "Junlin Xie",
      "Jingkuan Song",
      "Heng Tao Shen",
      "Lianli Gao"
    ],
    "abstract": "Robotic foundation models, or generalist robot policies, hold immense\npotential to enable flexible, general-purpose and dexterous robotic systems.\nDespite their advancements, our empirical experiments reveal that existing\nrobot policies are prone to learning spurious correlations from pre-training\ntrajectories, adversely affecting their generalization capabilities beyond the\ntraining data. To tackle this, we propose a novel Policy Contrastive Decoding\n(PCD) approach, which redirects the robot policy's focus toward object-relevant\nvisual clues by contrasting action probability distributions derived from\noriginal and object-masked visual inputs. As a training-free method, our PCD\ncan be used as a plugin to improve different types of robot policies without\nneeding to finetune or access model weights. We conduct extensive experiments\non top of three open-source robot policies, including the autoregressive policy\nOpenVLA and the diffusion-based policies Octo and $\\pi_0$. The obtained results\nin both simulation and real-world environments prove PCD's flexibility and\neffectiveness, e.g., PCD enhances the state-of-the-art policy $\\pi_0$ by 8% in\nthe simulation environment and by 108% in the real-world environment. Code and\ndemos are publicly available at: https://Koorye.github.io/proj/PCD.",
    "pdf_url": "http://arxiv.org/pdf/2505.13255v2",
    "published": "2025-05-19T15:39:08+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13254v1",
    "title": "HeteroSpec: Leveraging Contextual Heterogeneity for Efficient Speculative Decoding",
    "authors": [
      "Siran Liu",
      "Yang Ye",
      "Qianchao Zhu",
      "Zheng Cao",
      "Yongchao He"
    ],
    "abstract": "Autoregressive decoding, the standard approach for Large Language Model (LLM)\ninference, remains a significant bottleneck due to its sequential nature. While\nspeculative decoding algorithms mitigate this inefficiency through parallel\nverification, they fail to exploit the inherent heterogeneity in linguistic\ncomplexity, a key factor leading to suboptimal resource allocation. We address\nthis by proposing HeteroSpec, a heterogeneity-adaptive speculative decoding\nframework that dynamically optimizes computational resource allocation based on\nlinguistic context complexity. HeteroSpec introduces two key mechanisms: (1) A\nnovel cumulative meta-path Top-$K$ entropy metric for efficiently identifying\npredictable contexts. (2) A dynamic resource allocation strategy based on\ndata-driven entropy partitioning, enabling adaptive speculative expansion and\npruning tailored to local context difficulty. Evaluated on five public\nbenchmarks and four models, HeteroSpec achieves an average speedup of\n4.26$\\times$. It consistently outperforms state-of-the-art EAGLE-3 across\nspeedup rates, average acceptance length, and verification cost. Notably,\nHeteroSpec requires no draft model retraining, incurs minimal overhead, and is\northogonal to other acceleration techniques. It demonstrates enhanced\nacceleration with stronger draft models, establishing a new paradigm for\ncontext-aware LLM inference acceleration.",
    "pdf_url": "http://arxiv.org/pdf/2505.13254v1",
    "published": "2025-05-19T15:38:40+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13253v1",
    "title": "Composing Dextrous Grasping and In-hand Manipulation via Scoring with a Reinforcement Learning Critic",
    "authors": [
      "Lennart R√∂stel",
      "Dominik Winkelbauer",
      "Johannes Pitz",
      "Leon Sievers",
      "Berthold B√§uml"
    ],
    "abstract": "In-hand manipulation and grasping are fundamental yet often separately\naddressed tasks in robotics. For deriving in-hand manipulation policies,\nreinforcement learning has recently shown great success. However, the derived\ncontrollers are not yet useful in real-world scenarios because they often\nrequire a human operator to place the objects in suitable initial (grasping)\nstates. Finding stable grasps that also promote the desired in-hand\nmanipulation goal is an open problem. In this work, we propose a method for\nbridging this gap by leveraging the critic network of a reinforcement learning\nagent trained for in-hand manipulation to score and select initial grasps. Our\nexperiments show that this method significantly increases the success rate of\nin-hand manipulation without requiring additional training. We also present an\nimplementation of a full grasp manipulation pipeline on a real-world system,\nenabling autonomous grasping and reorientation even of unwieldy objects.",
    "pdf_url": "http://arxiv.org/pdf/2505.13253v1",
    "published": "2025-05-19T15:36:34+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13252v1",
    "title": "Natural Language Planning via Coding and Inference Scaling",
    "authors": [
      "Rikhil Amonkar",
      "Ronan Le Bras",
      "Li Zhang"
    ],
    "abstract": "Real-life textual planning tasks such as meeting scheduling have posed much\nchallenge to LLMs especially when the complexity is high. While previous work\nprimarily studied auto-regressive generation of plans with closed-source\nmodels, we systematically evaluate both closed- and open-source models,\nincluding those that scales output length with complexity during inference, in\ngenerating programs, which are executed to output the plan. We consider not\nonly standard Python code, but also the code to a constraint satisfaction\nproblem solver. Despite the algorithmic nature of the task, we show that\nprogramming often but not always outperforms planning. Our detailed error\nanalysis also indicates a lack of robustness and efficiency in the generated\ncode that hinders generalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.13252v1",
    "published": "2025-05-19T15:35:17+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13251v1",
    "title": "Stronger Together: Unleashing the Social Impact of Hate Speech Research",
    "authors": [
      "Sidney Wong"
    ],
    "abstract": "The advent of the internet has been both a blessing and a curse for once\nmarginalised communities. When used well, the internet can be used to connect\nand establish communities crossing different intersections; however, it can\nalso be used as a tool to alienate people and communities as well as perpetuate\nhate, misinformation, and disinformation especially on social media platforms.\nWe propose steering hate speech research and researchers away from pre-existing\ncomputational solutions and consider social methods to inform social solutions\nto address this social problem. In a similar way linguistics research can\ninform language planning policy, linguists should apply what we know about\nlanguage and society to mitigate some of the emergent risks and dangers of\nanti-social behaviour in digital spaces. We argue linguists and NLP researchers\ncan play a principle role in unleashing the social impact potential of\nlinguistics research working alongside communities, advocates, activists, and\npolicymakers to enable equitable digital inclusion and to close the digital\ndivide.",
    "pdf_url": "http://arxiv.org/pdf/2505.13251v1",
    "published": "2025-05-19T15:34:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13250v1",
    "title": "Joint Depth and Reflectivity Estimation using Single-Photon LiDAR",
    "authors": [
      "Hashan K. Weerasooriya",
      "Prateek Chennuri",
      "Weijian Zhang",
      "Istvan Gyongy",
      "Stanley H. Chan"
    ],
    "abstract": "Single-Photon Light Detection and Ranging (SP-LiDAR is emerging as a leading\ntechnology for long-range, high-precision 3D vision tasks. In SP-LiDAR,\ntimestamps encode two complementary pieces of information: pulse travel time\n(depth) and the number of photons reflected by the object (reflectivity).\nExisting SP-LiDAR reconstruction methods typically recover depth and\nreflectivity separately or sequentially use one modality to estimate the other.\nMoreover, the conventional 3D histogram construction is effective mainly for\nslow-moving or stationary scenes. In dynamic scenes, however, it is more\nefficient and effective to directly process the timestamps. In this paper, we\nintroduce an estimation method to simultaneously recover both depth and\nreflectivity in fast-moving scenes. We offer two contributions: (1) A\ntheoretical analysis demonstrating the mutual correlation between depth and\nreflectivity and the conditions under which joint estimation becomes\nbeneficial. (2) A novel reconstruction method, \"SPLiDER\", which exploits the\nshared information to enhance signal recovery. On both synthetic and real\nSP-LiDAR data, our method outperforms existing approaches, achieving superior\njoint reconstruction quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.13250v1",
    "published": "2025-05-19T15:33:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13580v1",
    "title": "OMGPT: A Sequence Modeling Framework for Data-driven Operational Decision Making",
    "authors": [
      "Hanzhao Wang",
      "Guanting Chen",
      "Kalyan Talluri",
      "Xiaocheng Li"
    ],
    "abstract": "We build a Generative Pre-trained Transformer (GPT) model from scratch to\nsolve sequential decision making tasks arising in contexts of operations\nresearch and management science which we call OMGPT. We first propose a general\nsequence modeling framework to cover several operational decision making tasks\nas special cases, such as dynamic pricing, inventory management, resource\nallocation, and queueing control. Under the framework, all these tasks can be\nviewed as a sequential prediction problem where the goal is to predict the\noptimal future action given all the historical information. Then we train a\ntransformer-based neural network model (OMGPT) as a natural and powerful\narchitecture for sequential modeling. This marks a paradigm shift compared to\nthe existing methods for these OR/OM tasks in that (i) the OMGPT model can take\nadvantage of the huge amount of pre-trained data; (ii) when tackling these\nproblems, OMGPT does not assume any analytical model structure and enables a\ndirect and rich mapping from the history to the future actions. Either of these\ntwo aspects, to the best of our knowledge, is not achieved by any existing\nmethod. We establish a Bayesian perspective to theoretically understand the\nworking mechanism of the OMGPT on these tasks, which relates its performance\nwith the pre-training task diversity and the divergence between the testing\ntask and pre-training tasks. Numerically, we observe a surprising performance\nof the proposed model across all the above tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13580v1",
    "published": "2025-05-19T15:33:03+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13249v1",
    "title": "RN-F: A Novel Approach for Mitigating Contaminated Data in Large Language Models",
    "authors": [
      "Le Vu Anh",
      "Dinh Duc Nha Nguyen",
      "Phi Long Nguyen"
    ],
    "abstract": "Large Language Models (LLMs) have become foundational in modern artificial\nintelligence, powering a wide range of applications from code generation and\nvirtual assistants to scientific research and enterprise automation. However,\nconcerns about data contamination--where test data overlaps with training\ndata--have raised serious questions about the reliability of these\napplications. Despite awareness of this issue, existing methods fall short in\neffectively identifying or mitigating contamination. In this paper, we propose\nResidual-Noise Fingerprinting (RN-F), a novel framework for detecting\ncontaminated data in LLMs. RN-F is a single-pass, gradient-free detection\nmethod that leverages residual signal patterns without introducing additional\nfloating-point operations. Our approach is lightweight, model-agnostic, and\nefficient. We evaluate RN-F on multiple LLMs across various contaminated\ndatasets and show that it consistently outperforms existing state-of-the-art\nmethods, achieving performance improvements of up to 10.5% in contamination\ndetection metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.13249v1",
    "published": "2025-05-19T15:32:49+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13579v1",
    "title": "Learning Wavelet-Sparse FDK for 3D Cone-Beam CT Reconstruction",
    "authors": [
      "Yipeng Sun",
      "Linda-Sophie Schneider",
      "Chengze Ye",
      "Mingxuan Gu",
      "Siyuan Mei",
      "Siming Bayer",
      "Andreas Maier"
    ],
    "abstract": "Cone-Beam Computed Tomography (CBCT) is essential in medical imaging, and the\nFeldkamp-Davis-Kress (FDK) algorithm is a popular choice for reconstruction due\nto its efficiency. However, FDK is susceptible to noise and artifacts. While\nrecent deep learning methods offer improved image quality, they often increase\ncomputational complexity and lack the interpretability of traditional methods.\nIn this paper, we introduce an enhanced FDK-based neural network that maintains\nthe classical algorithm's interpretability by selectively integrating trainable\nelements into the cosine weighting and filtering stages. Recognizing the\nchallenge of a large parameter space inherent in 3D CBCT data, we leverage\nwavelet transformations to create sparse representations of the cosine weights\nand filters. This strategic sparsification reduces the parameter count by\n$93.75\\%$ without compromising performance, accelerates convergence, and\nimportantly, maintains the inference computational cost equivalent to the\nclassical FDK algorithm. Our method not only ensures volumetric consistency and\nboosts robustness to noise, but is also designed for straightforward\nintegration into existing CT reconstruction pipelines. This presents a\npragmatic enhancement that can benefit clinical applications, particularly in\nenvironments with computational limitations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13579v1",
    "published": "2025-05-19T15:31:40+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13248v2",
    "title": "Distributed Beamforming Using Decentralized Time Synchronization in a Six-Element Array",
    "authors": [
      "Naim Shandi",
      "Jason M. Merlo",
      "Jeffrey A. Nanzer"
    ],
    "abstract": "We demonstrate a distributed beamforming and beamsteering from a six-node\ndistributed phased array using fully wireless coordination with decentralized\ntime synchronization. In wireless applications such as distributed beamforming,\nhigh-accuracy time synchronization across the array is crucial for high\ncoherent gain. The decentralized time synchronization method employed is based\non the average consensus algorithm and the two-way time transfer method\npresented in our previous work, which achieved picosecond time synchronization\nwith a cabled frequency reference. The system presented in this paper utilizes\na centralized wireless frequency transfer method to achieve wireless frequency\nsyntonization in a fully wireless coordination and a distributed computing\nsystem architecture. We experimentally evaluate system performance through\nbeamforming and beamsteering to a receiver 16.3 m away from the six-node\nnon-uniformly distributed antenna array, achieving an average coherent gain of\n98% of the ideal gain at a carrier frequency of 1.05 GHz. The average time\nsynchronization accuracy achieved was less than 36 ps.",
    "pdf_url": "http://arxiv.org/pdf/2505.13248v2",
    "published": "2025-05-19T15:30:33+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13247v2",
    "title": "Topology and the Infrared Structure of Quantum Electrodynamics",
    "authors": [
      "J. Gamboa"
    ],
    "abstract": "We study infrared divergences in quantum electrodynamics using geometric\nphases and the adiabatic approximation in quantum field theory. In this\nframework, the asymptotic \\textit{in} and \\textit{out} states are modified by\nBerry phases, $e^{i \\Delta \\alpha_{\\text{in}}}$ and $e^{i \\Delta\n\\alpha_{\\text{out}}}$, which encode the infrared structure non-perturbatively\nand regulate soft-photon divergences.\n  Unlike the Faddeev--Kulish formalism, which employs perturbative dressing\nwith coherent states, our approach reformulates the effective action in terms\nof Berry connections in field space. This yields finite, gauge-invariant\nscattering amplitudes without requiring a sum over soft-photon emissions.\n  We show that infrared divergences cancel to all orders in the bremsstrahlung\nvertex function $\\Gamma^\\mu(p_1, p_2)$, due to destructive interference among\ninequivalent Berry phases. As an application, we study the formation of\npositronium in the infrared regime and argue that the dressed \\(S\\)-matrix\nexhibits a functional singularity at $s = 4 m_e^2$, corresponding to a physical\npole generated by topological flux.",
    "pdf_url": "http://arxiv.org/pdf/2505.13247v2",
    "published": "2025-05-19T15:29:59+00:00",
    "categories": [
      "hep-th",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13246v1",
    "title": "Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems",
    "authors": [
      "Roberto Pugliese",
      "George Kourousias",
      "Francesco Venier",
      "Grazia Garlatti Costa"
    ],
    "abstract": "The exponential growth of scientific literature presents significant\nchallenges for researchers navigating the complex knowledge landscape. We\npropose \"Agentic Publications\", a novel LLM-driven framework complementing\ntraditional publishing by transforming papers into interactive knowledge\nsystems. Our architecture integrates structured data with unstructured content\nthrough retrieval-augmented generation and multi-agent verification. The\nframework offers interfaces for both humans and machines, combining narrative\nexplanations with machine-readable outputs while addressing ethical\nconsiderations through automated validation and transparent governance. Key\nfeatures include continuous knowledge updates, automatic integration of new\nfindings, and customizable detail levels. Our proof-of-concept demonstrates\nmultilingual interaction, API accessibility, and structured knowledge\nrepresentation through vector databases, knowledge graphs, and verification\nagents. This approach enhances scientific communication across disciplines,\nimproving efficiency and collaboration while preserving traditional publishing\npathways, particularly valuable for interdisciplinary fields where knowledge\nintegration remains challenging.",
    "pdf_url": "http://arxiv.org/pdf/2505.13246v1",
    "published": "2025-05-19T15:28:10+00:00",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13245v3",
    "title": "Ab initio study of strain-driven vacancy clustering in aluminum",
    "authors": [
      "Sayan Bhowmik",
      "Abhiraj Sharma",
      "Andrew J. Medford",
      "John E. Pask",
      "Phanish Suryanarayana"
    ],
    "abstract": "We present a first principles investigation of strain-driven vacancy\nclustering in aluminum. Specifically, we perform Kohn-Sham density functional\ntheory calculations to study the influence of hydrostatic strains on clustering\nin tri-, quad-, and heptavacancies. We find that compressive strains are a key\ndriving force for vacancy aggregation, particularly for collapse of clusters on\nthe (111) plane, consistent with prior experimental observations of vacancy\nclusters on this plane. Notably, we find that the heptavacancy on the (111)\nplane collapses to form a prismatic dislocation loop for hydrostatic\ncompressive strains exceeding 5\\%, highlighting the critical role of such\nstrains in prismatic dislocation loop nucleation in aluminum.",
    "pdf_url": "http://arxiv.org/pdf/2505.13245v3",
    "published": "2025-05-19T15:26:24+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.13244v1",
    "title": "JNLP at SemEval-2025 Task 11: Cross-Lingual Multi-Label Emotion Detection Using Generative Models",
    "authors": [
      "Jieying Xue",
      "Phuong Minh Nguyen",
      "Minh Le Nguyen",
      "Xin Liu"
    ],
    "abstract": "With the rapid advancement of global digitalization, users from different\ncountries increasingly rely on social media for information exchange. In this\ncontext, multilingual multi-label emotion detection has emerged as a critical\nresearch area. This study addresses SemEval-2025 Task 11: Bridging the Gap in\nText-Based Emotion Detection. Our paper focuses on two sub-tracks of this task:\n(1) Track A: Multi-label emotion detection, and (2) Track B: Emotion intensity.\nTo tackle multilingual challenges, we leverage pre-trained multilingual models\nand focus on two architectures: (1) a fine-tuned BERT-based classification\nmodel and (2) an instruction-tuned generative LLM. Additionally, we propose two\nmethods for handling multi-label classification: the base method, which maps an\ninput directly to all its corresponding emotion labels, and the pairwise\nmethod, which models the relationship between the input text and each emotion\ncategory individually. Experimental results demonstrate the strong\ngeneralization ability of our approach in multilingual emotion recognition. In\nTrack A, our method achieved Top 4 performance across 10 languages, ranking 1st\nin Hindi. In Track B, our approach also secured Top 5 performance in 7\nlanguages, highlighting its simplicity and effectiveness\\footnote{Our code is\navailable at https://github.com/yingjie7/mlingual_multilabel_emo_detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.13244v1",
    "published": "2025-05-19T15:24:53+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13243v1",
    "title": "Conformalized Decision Risk Assessment",
    "authors": [
      "Wenbin Zhou",
      "Agni Orfanoudaki",
      "Shixiang Zhu"
    ],
    "abstract": "High-stakes decisions in domains such as healthcare, energy, and public\npolicy are often made by human experts using domain knowledge and heuristics,\nyet are increasingly supported by predictive and optimization-based tools. A\ndominant approach in operations research is the predict-then-optimize paradigm,\nwhere a predictive model estimates uncertain inputs, and an optimization model\nrecommends a decision. However, this approach often lacks interpretability and\ncan fail under distributional uncertainty -- particularly when the outcome\ndistribution is multi-modal or complex -- leading to brittle or misleading\ndecisions. In this paper, we introduce CREDO, a novel framework that\nquantifies, for any candidate decision, a distribution-free upper bound on the\nprobability that the decision is suboptimal. By combining inverse optimization\ngeometry with conformal prediction and generative modeling, CREDO produces risk\ncertificates that are both statistically rigorous and practically\ninterpretable. This framework enables human decision-makers to audit and\nvalidate their own decisions under uncertainty, bridging the gap between\nalgorithmic tools and real-world judgment.",
    "pdf_url": "http://arxiv.org/pdf/2505.13243v1",
    "published": "2025-05-19T15:24:38+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.13242v1",
    "title": "ALMA observation of evolving magnetized corona in the radio-quiet changing-state AGN NGC 1566",
    "authors": [
      "Arghajit Jana",
      "Claudio Ricci",
      "Sophie M. Venselaar",
      "Chin-Shin Chang",
      "Mai Liao",
      "Yoshiyuki Inoue",
      "Taiki Kawamuro",
      "Franz E. Bauer",
      "Elena Shablovinskaya",
      "Benny Trakhtenbrot",
      "Jacob S. Elford",
      "Michael J. Koss"
    ],
    "abstract": "The origin of compact millimeter (mm) continuum emission from radio-quiet\nAGNs (RQAGNs) is still not fully understood. Changing-state AGNs (CSAGNs)\ndisplay rapid and strong variability, which can allow us to investigate the\norigin of the mm emission. We present here the results of the first study of\nthe mm continuum variability of a CSAGN using archival ALMA band 6 ($\\sim 230$\nGHz) observations of NGC 1566 obtained in 2014-2023. We find a positive\ncorrelation between the mm and X-ray flux with an intrinsic scatter of 0.05 dex\n($1\\sigma$), suggesting a common origin. The mm spectral index ($\\alpha_{\\rm\nmm}$) is found in the range of $0.13\\pm0.38$ to $-0.26\\pm0.53$, consistent with\na compact optically thick synchrotron source. No significant correlation was\nfound between the $\\alpha_{\\rm mm}$ and the mm flux. The mm/X-ray ratio also\nshows no clear link to the Eddington ratio but is higher in the low-accretion\nstate. We discuss several scenarios about the origin of the mm emission in NGC\n1566. We find that synchrotron emission in the magnetized X-ray corona appears\nto be the most probable origin of mm emission, confirming that mm emission can\nbe used as a tracer of AGN activity in RQAGNs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13242v1",
    "published": "2025-05-19T15:23:33+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13241v2",
    "title": "Reconstructing Physics-Informed Machine Learning for Traffic Flow Modeling: a Multi-Gradient Descent and Pareto Learning Approach",
    "authors": [
      "Yuan-Zheng Lei",
      "Yaobang Gong",
      "Dianwei Chen",
      "Yao Cheng",
      "Xianfeng Terry Yang"
    ],
    "abstract": "Physics-informed machine learning (PIML) is crucial in modern traffic flow\nmodeling because it combines the benefits of both physics-based and data-driven\napproaches. In conventional PIML, physical information is typically\nincorporated by constructing a hybrid loss function that combines data-driven\nloss and physics loss through linear scalarization. The goal is to find a\ntrade-off between these two objectives to improve the accuracy of model\npredictions. However, from a mathematical perspective, linear scalarization is\nlimited to identifying only the convex region of the Pareto front, as it treats\ndata-driven and physics losses as separate objectives. Given that most PIML\nloss functions are non-convex, linear scalarization restricts the achievable\ntrade-off solutions. Moreover, tuning the weighting coefficients for the two\nloss components can be both time-consuming and computationally challenging. To\naddress these limitations, this paper introduces a paradigm shift in PIML by\nreformulating the training process as a multi-objective optimization problem,\ntreating data-driven loss and physics loss independently. We apply several\nmulti-gradient descent algorithms (MGDAs), including traditional multi-gradient\ndescent (TMGD) and dual cone gradient descent (DCGD), to explore the Pareto\nfront in this multi-objective setting. These methods are evaluated on both\nmacroscopic and microscopic traffic flow models. In the macroscopic case, MGDAs\nachieved comparable performance to traditional linear scalarization methods.\nNotably, in the microscopic case, MGDAs significantly outperformed their\nscalarization-based counterparts, demonstrating the advantages of a\nmulti-objective optimization approach in complex PIML scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.13241v2",
    "published": "2025-05-19T15:23:24+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13240v1",
    "title": "Did the Corona Borealis-A2142 supercluster binary-like system originate as a proto-cluster binary embedded in a primordial cloud of galaxies?",
    "authors": [
      "Baiesi Pillastrini G. Carlo"
    ],
    "abstract": "The formation of the giant binary-like system composed by the Corona Borealis\nand Abell 2142 superclusters is an intriguing conundrum of the formation of\nlarge scale structures since, from the observational point of view, it\nrepresents a rare peculiarity in the distribution of massive galaxy\nsuperclusters. Having a configuration similar to a giant binary system\ninterconnected by a huge filament, it is likely one if not the unique case to\ndate observed in the Local Universe. So a question arise: how and when did it\nform? Here, the CrB and A2142 system has been hypothesized to be a descendent\nof a primordial binary system composed of two close galaxy proto-clusters, the\nCrB and A2142, originated from two independent collapsing process within a\ndense cloud of galaxies. Then, assuming that at a certain point the decoupling\noccurred due to the interplay of gravity-antigravity of DE, they began to move\naway in radial motion from each other following the accelerate expansion of the\nUniverse. In the context of the LCDM model a Newtonian approximation of the two\nbody motion in presence of DE has been applied using current physical\nparameters of the CrB and A2142 system with the aim to calculate the look-back\ntime at decoupling. Its compatibility with the era of formation of the\nprimordial galaxy proto-clusters has been tested. The event of the binary\ndecoupling happened in a time larger than the age of the Universe! Of course,\nafter such a result the advanced hypothesis on the origins of the CrB-A2142\nsystem can be rejected, but not the test of compatibility since the look-back\ntime at the error lower limit is 12.5 Gys ( z = 4.5) largely consistent with\nobservations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13240v1",
    "published": "2025-05-19T15:23:06+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13239v1",
    "title": "Network-wide Quantum Key Distribution with Onion Routing Relay",
    "authors": [
      "Pedro Otero-Garc√≠a",
      "David P√©rez-Castro",
      "Manuel Fern√°ndez-Veiga",
      "Ana Fern√°ndez-Vilas"
    ],
    "abstract": "The advancement of quantum computing threatens classical cryptographic\nmethods, necessitating the development of secure quantum key distribution (QKD)\nsolutions for QKD Networks (QKDN). In this paper, a novel key distribution\nprotocol, Onion Routing Relay (ORR), that integrates onion routing (OR) with\npost-quantum cryptography (PQC) in a key-relay (KR) model is evaluated for\nQKDNs. This approach increases the security by enhancing confidentiality,\nintegrity, authenticity, and anonymity in quantum-secure communications. By\nemploying PQC-based encapsulation, ORR pretends to avoid the security risks\nposed by intermediate malicious nodes and ensures end-to-end security. Results\nshow that the performance of the ORR model, against current key-relay (KR) and\ntrusted-node (TN) approaches, demonstrating its feasibility and applicability\nin high-security environments maintaining a consistent Quality of Service\n(QoS). The results show that while ORR incurs higher encryption overhead, it\nprovides substantial security improvements without significantly impacting the\noverall key distribution time.",
    "pdf_url": "http://arxiv.org/pdf/2505.13239v1",
    "published": "2025-05-19T15:21:11+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13238v4",
    "title": "A Geometry-Grounded Data Perimeter in Azure",
    "authors": [
      "Christophe Parisel"
    ],
    "abstract": "While data perimeter is ubiquitous in cybersecurity speak, it rarely defines\nhow boundary points are arranged. In this paper we show how Azure s blast\nradius ultrametric provides the distance, and how solving the Traveling\nSalesman Problem in this ultrametric space provides the ordering, yielding a\ntrue geometric contour: an actionable perimeter measure for SPN prioritization.",
    "pdf_url": "http://arxiv.org/pdf/2505.13238v4",
    "published": "2025-05-19T15:21:08+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13237v3",
    "title": "SAKURA: On the Multi-hop Reasoning of Large Audio-Language Models Based on Speech and Audio Information",
    "authors": [
      "Chih-Kai Yang",
      "Neo Ho",
      "Yen-Ting Piao",
      "Hung-yi Lee"
    ],
    "abstract": "Large audio-language models (LALMs) extend the large language models with\nmultimodal understanding in speech, audio, etc. While their performances on\nspeech and audio-processing tasks are extensively studied, their reasoning\nabilities remain underexplored. Particularly, their multi-hop reasoning, the\nability to recall and integrate multiple facts, lacks systematic evaluation.\nExisting benchmarks focus on general speech and audio-processing tasks,\nconversational abilities, and fairness but overlook this aspect. To bridge this\ngap, we introduce SAKURA, a benchmark assessing LALMs' multi-hop reasoning\nbased on speech and audio information. Results show that LALMs struggle to\nintegrate speech/audio representations for multi-hop reasoning, even when they\nextract the relevant information correctly, highlighting a fundamental\nchallenge in multimodal reasoning. Our findings expose a critical limitation in\nLALMs, offering insights and resources for future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.13237v3",
    "published": "2025-05-19T15:20:32+00:00",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.17070v1",
    "title": "Improving endpoint detection in end-to-end streaming ASR for conversational speech",
    "authors": [
      "Anandh C",
      "Karthik Pandia Durai",
      "Jeena Prakash",
      "Manickavela Arumugam",
      "Kadri Hacioglu",
      "S. Pavankumar Dubagunta",
      "Andreas Stolcke",
      "Shankar Venkatesan",
      "Aravind Ganapathiraju"
    ],
    "abstract": "ASR endpointing (EP) plays a major role in delivering a good user experience\nin products supporting human or artificial agents in human-human/machine\nconversations. Transducer-based ASR (T-ASR) is an end-to-end (E2E) ASR\nmodelling technique preferred for streaming. A major limitation of T-ASR is\ndelayed emission of ASR outputs, which could lead to errors or delays in EP.\nInaccurate EP will cut the user off while speaking, returning incomplete\ntranscript while delays in EP will increase the perceived latency, degrading\nthe user experience. We propose methods to improve EP by addressing delayed\nemission along with EP mistakes. To address the delayed emission problem, we\nintroduce an end-of-word token at the end of each word, along with a delay\npenalty. The EP delay is addressed by obtaining a reliable frame-level speech\nactivity detection using an auxiliary network. We apply the proposed methods on\nSwitchboard conversational speech corpus and evaluate it against a delay\npenalty method.",
    "pdf_url": "http://arxiv.org/pdf/2505.17070v1",
    "published": "2025-05-19T15:19:59+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13236v1",
    "title": "Multiple-Order Tensor Field Theory: Enumeration of unitary invariant observables",
    "authors": [
      "Joseph Ben Geloun",
      "Arnauld Solente"
    ],
    "abstract": "In Tensor Field Theory (TFT), observables are defined through tensor field\ncontractions that produce unitary invariants for complex-valued tensor fields.\nTraditionally, these observables are constructed using tensor fields of a fixed\norder $d$. Here, we propose an extended theoretical framework for TFT that\nincorporates tensor fields of varying orders $d'$, satisfying $d' \\leq d$. We\nthen establish a comprehensive group-theoretic formalism that enables the\nsystematic enumeration of these complex TFT observables. This approach\nencompasses existing counting methods and therefore recovers known results in\nspecific limiting cases. Additionally, we provide computational tools to\nfacilitate the enumeration of these invariants, unveiling novel integer\nsequences that have not been documented elsewhere.",
    "pdf_url": "http://arxiv.org/pdf/2505.13236v1",
    "published": "2025-05-19T15:19:16+00:00",
    "categories": [
      "math-ph",
      "hep-th",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13235v1",
    "title": "WriteViT: Handwritten Text Generation with Vision Transformer",
    "authors": [
      "Dang Hoai Nam",
      "Huynh Tong Dang Khoa",
      "Vo Nguyen Le Duy"
    ],
    "abstract": "Humans can quickly generalize handwriting styles from a single example by\nintuitively separating content from style. Machines, however, struggle with\nthis task, especially in low-data settings, often missing subtle spatial and\nstylistic cues. Motivated by this gap, we introduce WriteViT, a one-shot\nhandwritten text synthesis framework that incorporates Vision Transformers\n(ViT), a family of models that have shown strong performance across various\ncomputer vision tasks. WriteViT integrates a ViT-based Writer Identifier for\nextracting style embeddings, a multi-scale generator built with Transformer\nencoder-decoder blocks enhanced by conditional positional encoding (CPE), and a\nlightweight ViT-based recognizer. While previous methods typically rely on CNNs\nor CRNNs, our design leverages transformers in key components to better capture\nboth fine-grained stroke details and higher-level style information. Although\nhandwritten text synthesis has been widely explored, its application to\nVietnamese -- a language rich in diacritics and complex typography -- remains\nlimited. Experiments on Vietnamese and English datasets demonstrate that\nWriteViT produces high-quality, style-consistent handwriting while maintaining\nstrong recognition performance in low-resource scenarios. These results\nhighlight the promise of transformer-based designs for multilingual handwriting\ngeneration and efficient style adaptation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13235v1",
    "published": "2025-05-19T15:17:53+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13234v1",
    "title": "Path signatures of ODE solutions",
    "authors": [
      "Francesco Galuppi",
      "Giovanni Moreno",
      "Pierpaola Santarsiero"
    ],
    "abstract": "The signature of a path is a sequence of tensors which allows to uniquely\nreconstruct the path. By employing the geometric theory of nonlinear systems of\nordinary differential equations, we find necessary and sufficient algebraic\nconditions on the signature tensors of a path to be a solution of a given\nsystem of ODEs. As an application, we describe in detail the systems of ODEs\nthat describe the trajectories of a vector field, in particular a linear and\nHamiltonian one.",
    "pdf_url": "http://arxiv.org/pdf/2505.13234v1",
    "published": "2025-05-19T15:17:02+00:00",
    "categories": [
      "math.AG",
      "math.DG",
      "15A69, 60L10, 34A34"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13233v1",
    "title": "From Local Details to Global Context: Advancing Vision-Language Models with Attention-Based Selection",
    "authors": [
      "Lincan Cai",
      "Jingxuan Kang",
      "Shuang Li",
      "Wenxuan Ma",
      "Binhui Xie",
      "Zhida Qin",
      "Jian Liang"
    ],
    "abstract": "Pretrained vision-language models (VLMs), e.g., CLIP, demonstrate impressive\nzero-shot capabilities on downstream tasks. Prior research highlights the\ncrucial role of visual augmentation techniques, like random cropping, in\nalignment with fine-grained class descriptions generated by large language\nmodels (LLMs), significantly enhancing zero-shot performance by incorporating\nmulti-view information. However, the inherent randomness of these augmentations\ncan inevitably introduce background artifacts and cause models to overly focus\non local details, compromising global semantic understanding. To address these\nissues, we propose an \\textbf{A}ttention-\\textbf{B}ased \\textbf{S}election\n(\\textbf{ABS}) method from local details to global context, which applies\nattention-guided cropping in both raw images and feature space, supplement\nglobal semantic information through strategic feature selection. Additionally,\nwe introduce a soft matching technique to effectively filter LLM descriptions\nfor better alignment. \\textbf{ABS} achieves state-of-the-art performance on\nout-of-distribution generalization and zero-shot classification tasks. Notably,\n\\textbf{ABS} is training-free and even rivals few-shot and test-time adaptation\nmethods. Our code is available at\n\\href{https://github.com/BIT-DA/ABS}{\\textcolor{darkgreen}{https://github.com/BIT-DA/ABS}}.",
    "pdf_url": "http://arxiv.org/pdf/2505.13233v1",
    "published": "2025-05-19T15:15:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13232v3",
    "title": "StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment",
    "authors": [
      "Younghyun Kim",
      "Jongheon Jeong",
      "Sangkyung Kwak",
      "Kyungmin Lee",
      "Juho Lee",
      "Jinwoo Shin"
    ],
    "abstract": "Learning robust representations from data often requires scale, which has led\nto the success of recent zero-shot models such as CLIP. However, the obtained\nrobustness can easily be deteriorated when these models are fine-tuned on other\ndownstream tasks (e.g., of smaller scales). Previous works often interpret this\nphenomenon in the context of domain shift, developing fine-tuning methods that\naim to preserve the original domain as much as possible. However, in a\ndifferent context, fine-tuned models with limited data are also prone to\nlearning features that are spurious to humans, such as background or texture.\nIn this paper, we propose StarFT (Spurious Textual Alignment Regularization), a\nnovel framework for fine-tuning zero-shot models to enhance robustness by\npreventing them from learning spuriosity. We introduce a regularization that\naligns the output distribution for spuriosity-injected labels with the original\nzero-shot model, ensuring that the model is not induced to extract irrelevant\nfeatures further from these descriptions. We leverage recent language models to\nget such spuriosity-injected labels by generating alternative textual\ndescriptions that highlight potentially confounding features. Extensive\nexperiments validate the robust generalization of StarFT and its emerging\nproperties: zero-shot group robustness and improved zero-shot classification.\nNotably, StarFT boosts both worst-group and average accuracy by 14.30% and\n3.02%, respectively, in the Waterbirds group shift scenario, where other robust\nfine-tuning baselines show even degraded performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.13232v3",
    "published": "2025-05-19T15:15:35+00:00",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13231v1",
    "title": "Investigating Active Sampling for Hardness Classification with Vision-Based Tactile Sensors",
    "authors": [
      "Junyi Chen",
      "Alap Kshirsagar",
      "Frederik Heller",
      "Mario G√≥mez Andreu",
      "Boris Belousov",
      "Tim Schneider",
      "Lisa P. Y. Lin",
      "Katja Doerschner",
      "Knut Drewing",
      "Jan Peters"
    ],
    "abstract": "One of the most important object properties that humans and robots perceive\nthrough touch is hardness. This paper investigates information-theoretic active\nsampling strategies for sample-efficient hardness classification with\nvision-based tactile sensors. We evaluate three probabilistic classifier models\nand two model-uncertainty-based sampling strategies on a robotic setup as well\nas on a previously published dataset of samples collected by human testers. Our\nfindings indicate that the active sampling approaches, driven by uncertainty\nmetrics, surpass a random sampling baseline in terms of accuracy and stability.\nAdditionally, while in our human study, the participants achieve an average\naccuracy of 48.00%, our best approach achieves an average accuracy of 88.78% on\nthe same set of objects, demonstrating the effectiveness of vision-based\ntactile sensors for object hardness classification.",
    "pdf_url": "http://arxiv.org/pdf/2505.13231v1",
    "published": "2025-05-19T15:15:27+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13230v1",
    "title": "Implicit bias produces neural scaling laws in learning curves, from perceptrons to deep networks",
    "authors": [
      "Francesco D'Amico",
      "Dario Bocchi",
      "Matteo Negri"
    ],
    "abstract": "Scaling laws in deep learning - empirical power-law relationships linking\nmodel performance to resource growth - have emerged as simple yet striking\nregularities across architectures, datasets, and tasks. These laws are\nparticularly impactful in guiding the design of state-of-the-art models, since\nthey quantify the benefits of increasing data or model size, and hint at the\nfoundations of interpretability in machine learning. However, most studies\nfocus on asymptotic behavior at the end of training or on the optimal training\ntime given the model size. In this work, we uncover a richer picture by\nanalyzing the entire training dynamics through the lens of spectral complexity\nnorms. We identify two novel dynamical scaling laws that govern how performance\nevolves during training. These laws together recover the well-known test error\nscaling at convergence, offering a mechanistic explanation of generalization\nemergence. Our findings are consistent across CNNs, ResNets, and Vision\nTransformers trained on MNIST, CIFAR-10 and CIFAR-100. Furthermore, we provide\nanalytical support using a solvable model: a single-layer perceptron trained\nwith binary cross-entropy. In this setting, we show that the growth of spectral\ncomplexity driven by the implicit bias mirrors the generalization behavior\nobserved at fixed norm, allowing us to connect the performance dynamics to\nclassical learning rules in the perceptron.",
    "pdf_url": "http://arxiv.org/pdf/2505.13230v1",
    "published": "2025-05-19T15:13:36+00:00",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13229v3",
    "title": "PARF: An Adaptive Abstraction-Strategy Tuner for Static Analysis",
    "authors": [
      "Zhongyi Wang",
      "Mingshuai Chen",
      "Tengjie Lin",
      "Linyu Yang",
      "Junhao Zhuo",
      "Qiuye Wang",
      "Shengchao Qin",
      "Xiao Yi",
      "Jianwei Yin"
    ],
    "abstract": "We launch Parf - a toolkit for adaptively tuning abstraction strategies of\nstatic program analyzers in a fully automated manner. Parf models various types\nof external parameters (encoding abstraction strategies) as random variables\nsubject to probability distributions over latticed parameter spaces. It\nincrementally refines the probability distributions based on accumulated\nintermediate results generated by repeatedly sampling and analyzing, thereby\nultimately yielding a set of highly accurate abstraction strategies. Parf is\nimplemented on top of Frama-C/Eva - an off-the-shelf open-source static\nanalyzer for C programs. Parf provides a web-based user interface facilitating\nthe intuitive configuration of static analyzers and visualization of dynamic\ndistribution refinement of the abstraction strategies. It further supports the\nidentification of dominant parameters in Frama-C/Eva analysis. Benchmark\nexperiments and a case study demonstrate the competitive performance of Parf\nfor analyzing complex, large-scale real-world programs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13229v3",
    "published": "2025-05-19T15:13:34+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13228v1",
    "title": "Sensitivity to New Physics Phenomena in Anomaly Detection: A Study of Untunable Hyperparameters",
    "authors": [
      "Fernando Abreu de Souza",
      "Maura Barros",
      "Nuno Filipe Castro",
      "Miguel Crispim Rom√£o",
      "C√©u Neiva",
      "Rute Pedro"
    ],
    "abstract": "The search for physics beyond the Standard Model (BSM) at collider\nexperiments requires model-independent strategies to avoid missing possible\ndiscoveries of unexpected signals. Anomaly detection (AD) techniques offer a\npromising approach by identifying deviations from the Standard Model (SM) and\nhave been extensively studied. The sensitivity of these methods to untunable\nhyperparameters has not been systematically compared, however. This study\naddresses it by investigating four semi-supervised AD methods -- Auto-Encoders,\nDeep Support Vector Data Description, Histogram-based Outlier Score, and\nIsolation Forest -- trained on simulated SM background events. In this paper,\nwe study the sensitivity of these methods to BSM benchmark signals as a\nfunction of these untunable hyperparameters. Such a study is complemented by a\nproposal of a non-parametric permutation test using signal-agnostic statistics,\nwhich can provide a robust statistical assessment.",
    "pdf_url": "http://arxiv.org/pdf/2505.13228v1",
    "published": "2025-05-19T15:12:26+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "physics.data-an"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13227v2",
    "title": "Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis",
    "authors": [
      "Tianbao Xie",
      "Jiaqi Deng",
      "Xiaochuan Li",
      "Junlin Yang",
      "Haoyuan Wu",
      "Jixuan Chen",
      "Wenjing Hu",
      "Xinyuan Wang",
      "Yuhui Xu",
      "Zekun Wang",
      "Yiheng Xu",
      "Junli Wang",
      "Doyen Sahoo",
      "Tao Yu",
      "Caiming Xiong"
    ],
    "abstract": "Graphical user interface (GUI) grounding, the ability to map natural language\ninstructions to specific actions on graphical user interfaces, remains a\ncritical bottleneck in computer use agent development. Current benchmarks\noversimplify grounding tasks as short referring expressions, failing to capture\nthe complexity of real-world interactions that require software commonsense,\nlayout understanding, and fine-grained manipulation capabilities. To address\nthese limitations, we introduce OSWorld-G, a comprehensive benchmark comprising\n564 finely annotated samples across diverse task types including text matching,\nelement recognition, layout understanding, and precise manipulation.\nAdditionally, we synthesize and release the largest computer use grounding\ndataset Jedi, which contains 4 million examples through multi-perspective\ndecoupling of tasks. Our multi-scale models trained on Jedi demonstrate its\neffectiveness by outperforming existing approaches on ScreenSpot-v2,\nScreenSpot-Pro, and our OSWorld-G. Furthermore, we demonstrate that improved\ngrounding with Jedi directly enhances agentic capabilities of general\nfoundation models on complex computer tasks, improving from 5% to 27% on\nOSWorld. Through detailed ablation studies, we identify key factors\ncontributing to grounding performance and verify that combining specialized\ndata for different interface elements enables compositional generalization to\nnovel interfaces. All benchmark, data, checkpoints, and code are open-sourced\nand available at https://osworld-grounding.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2505.13227v2",
    "published": "2025-05-19T15:09:23+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13226v6",
    "title": "Partitewise Entanglement",
    "authors": [
      "Yu Guo",
      "Ning Yang"
    ],
    "abstract": "It is known that $\\rho^{AB}$ as a bipartite reduced state of the 3-qubit GHZ\nstate is separable, but part $A$ and part $B$ indeed ``share tripartite\nentanglement'' in the GHZ state. Namely, whether a state can ``share'' more\nentanglement is dependent on the global system it lives in. We explore here\nsuch kind of entanglement in any $n$-partite system with arbitrary dimensions,\n$n\\geqslant3$, and call it partitewise entanglement (PWE) which includes\npairwise entanglement (PE) proposed in [Phys. Rev. A 110, 032420(2024)] as a\nspecial case. We propose three classes of the partitewise entanglement measures\nwhich are based on the genuine entanglement measure, the minimal bipartition,\nand the minimal distance from the partitewise separable states, respectively.\nThe former two methods are far-ranging since all of them are defined by the\nreduced function$^{1}$. Consequently, we establish the framework of the\nresource theory of the partitewise entanglement. In addition, we investigate\nthe partitewise entanglement extensibility and give a measure of such\nextensibility, and from which we find that the maximal partitewise entanglement\nextension is its purification. At last, the relation between this extensibility\nand the partitewise entanglement is discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.13226v6",
    "published": "2025-05-19T15:09:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13225v1",
    "title": "Automatic Complementary Separation Pruning Toward Lightweight CNNs",
    "authors": [
      "David Levin",
      "Gonen Singer"
    ],
    "abstract": "In this paper, we present Automatic Complementary Separation Pruning (ACSP),\na novel and fully automated pruning method for convolutional neural networks.\nACSP integrates the strengths of both structured pruning and activation-based\npruning, enabling the efficient removal of entire components such as neurons\nand channels while leveraging activations to identify and retain the most\nrelevant components. Our approach is designed specifically for supervised\nlearning tasks, where we construct a graph space that encodes the separation\ncapabilities of each component with respect to all class pairs. By employing\ncomplementary selection principles and utilizing a clustering algorithm, ACSP\nensures that the selected components maintain diverse and complementary\nseparation capabilities, reducing redundancy and maintaining high network\nperformance. The method automatically determines the optimal subset of\ncomponents in each layer, utilizing a knee-finding algorithm to select the\nminimal subset that preserves performance without requiring user-defined\npruning volumes. Extensive experiments on multiple architectures, including\nVGG-16, ResNet-50, and MobileNet-V2, across datasets like CIFAR-10, CIFAR-100,\nand ImageNet-1K, demonstrate that ACSP achieves competitive accuracy compared\nto other methods while significantly reducing computational costs. This fully\nautomated approach not only enhances scalability but also makes ACSP especially\npractical for real-world deployment by eliminating the need for manually\ndefining the pruning volume.",
    "pdf_url": "http://arxiv.org/pdf/2505.13225v1",
    "published": "2025-05-19T15:08:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13224v1",
    "title": "Brackets in multicontact geometry and multisymplectization",
    "authors": [
      "Manuel de Le√≥n",
      "Rub√©n Izquierdo-L√≥pez",
      "Xavier Rivas"
    ],
    "abstract": "In this paper we introduce a graded bracket of forms on multicontact\nmanifolds. This bracket satisfies a graded Jacobi identity as well as two\ndifferent versions of the Leibniz rule, one of them being a weak Leibniz rule,\nextending the well-known notions in contact geometry. In addition, we develop\nthe multisymplectization of multicontact structures to relate these brackets to\nthe ones present in multisymplectic geometry and obtain the field equations in\nan abstract context. The Jacobi bracket also permits to study the evolution of\nobservables and study the dissipation phenomena, which we also address.\nFinally, we apply the results to classical dissipative field theories.",
    "pdf_url": "http://arxiv.org/pdf/2505.13224v1",
    "published": "2025-05-19T15:08:10+00:00",
    "categories": [
      "math.DG",
      "math-ph",
      "math.MP",
      "53D42, 70S20, 35B06, 53D10, 53Z05, 70S10"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13223v2",
    "title": "Group Symmetry Enables Faster Optimization in Inverse Problems",
    "authors": [
      "Junqi Tang",
      "Guixian Xu"
    ],
    "abstract": "We prove for the first time that, if a linear inverse problem exhibits a\ngroup symmetry structure, gradient-based optimizers can be designed to exploit\nthis structure for faster convergence rates. This theoretical finding\ndemonstrates the existence of a special class of structure-adaptive\noptimization algorithms which are tailored for symmetry-structured inverse\nproblems such as CT/MRI/PET, compressed sensing, and image processing\napplications such as inpainting/deconvolution, etc.",
    "pdf_url": "http://arxiv.org/pdf/2505.13223v2",
    "published": "2025-05-19T15:07:32+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13578v2",
    "title": "Symmetry-Breaking Descent for Invariant Cost Functionals",
    "authors": [
      "Mikhail Osipov"
    ],
    "abstract": "We study the problem of reducing a task cost functional $W : H^s(M) \\to\n\\mathbb{R}$, not assumed continuous or differentiable, defined over\nSobolev-class signals $S \\in H^s(M) $, in the presence of a global symmetry\ngroup $G \\subset \\mathrm{Diff}(M)$. The group acts on signals by pullback, and\nthe cost $W$ is invariant under this action. Such scenarios arise in machine\nlearning and related optimization tasks, where performance metrics may be\ndiscontinuous or model-internal.\n  We propose a variational method that exploits the symmetry structure to\nconstruct explicit deformations of the input signal. A deformation control\nfield $ \\phi: M \\to \\mathbb R^d$, obtained by minimizing an auxiliary energy\nfunctional, induces a flow that generically lies in the normal space (with\nrespect to the $L^2$ inner product) to the $G$-orbit of $S$, and hence is a\nnatural candidate to cross the decision boundary of the $G $-invariant cost.\n  We analyze two variants of the coupling term: (1) purely geometric,\nindependent of $W$, and (2) weakly coupled to $W$. Under mild conditions, we\nshow that symmetry-breaking deformations of the signal can reduce the cost.\n  Our approach requires no gradient backpropagation or training labels and\noperates entirely at test time. It provides a principled tool for optimizing\ndiscontinuous invariant cost functionals via Lie-algebraic variational flows.",
    "pdf_url": "http://arxiv.org/pdf/2505.13578v2",
    "published": "2025-05-19T15:06:31+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13222v1",
    "title": "Partial Wave Analysis of $e^{+}e^{-} \\rightarrow œÄ^{+}œÄ^{-}J/œà$ and Cross Section Measurement of $e^{+}e^{-} \\rightarrow œÄ^{\\pm}Z_{c}(3900)^{\\mp}$ from 4.1271 to 4.3583 GeV",
    "authors": [
      "BESIII Collaboration",
      "M. Ablikim",
      "M. N. Achasov",
      "P. Adlarson",
      "O. Afedulidis",
      "X. C. Ai",
      "R. Aliberti",
      "A. Amoroso",
      "Q. An",
      "Y. Bai",
      "O. Bakina",
      "I. Balossino",
      "Y. Ban",
      "H. -R. Bao",
      "V. Batozskaya",
      "K. Begzsuren",
      "N. Berger",
      "M. Berlowski",
      "M. Bertani",
      "D. Bettoni",
      "F. Bianchi",
      "E. Bianco",
      "A. Bortone",
      "I. Boyko",
      "R. A. Briere",
      "A. Brueggemann",
      "H. Cai",
      "X. Cai",
      "A. Calcaterra",
      "G. F. Cao",
      "N. Cao",
      "S. A. Cetin",
      "J. F. Chang",
      "G. R. Che",
      "G. Chelkov",
      "C. Chen",
      "C. H. Chen",
      "Chao Chen",
      "G. Chen",
      "H. S. Chen",
      "H. Y. Chen",
      "M. L. Chen",
      "S. J. Chen",
      "S. L. Chen",
      "S. M. Chen",
      "T. Chen",
      "X. R. Chen",
      "X. T. Chen",
      "Y. B. Chen",
      "Y. Q. Chen",
      "Z. J. Chen",
      "Z. Y. Chen",
      "S. K. Choi",
      "G. Cibinetto",
      "F. Cossio",
      "J. J. Cui",
      "H. L. Dai",
      "J. P. Dai",
      "A. Dbeyssi",
      "R. E. de Boer",
      "D. Dedovich",
      "C. Q. Deng",
      "Z. Y. Deng",
      "A. Denig",
      "I. Denysenko",
      "M. Destefanis",
      "F. De Mori",
      "B. Ding",
      "X. X. Ding",
      "Y. Ding",
      "Y. Ding",
      "J. Dong",
      "L. Y. Dong",
      "M. Y. Dong",
      "X. Dong",
      "M. C. Du",
      "S. X. Du",
      "Y. Y. Duan",
      "Z. H. Duan",
      "P. Egorov",
      "Y. H. Fan",
      "J. Fang",
      "J. Fang",
      "S. S. Fang",
      "W. X. Fang",
      "Y. Fang",
      "Y. Q. Fang",
      "R. Farinelli",
      "L. Fava",
      "F. Feldbauer",
      "G. Felici",
      "C. Q. Feng",
      "J. H. Feng",
      "Y. T. Feng",
      "M. Fritsch",
      "C. D. Fu",
      "J. L. Fu",
      "Y. W. Fu",
      "H. Gao",
      "X. B. Gao",
      "Y. N. Gao",
      "Yang Gao",
      "S. Garbolino",
      "I. Garzia",
      "L. Ge",
      "P. T. Ge",
      "Z. W. Ge",
      "C. Geng",
      "E. M. Gersabeck",
      "A. Gilman",
      "K. Goetzen",
      "L. Gong",
      "W. X. Gong",
      "W. Gradl",
      "S. Gramigna",
      "M. Greco",
      "M. H. Gu",
      "Y. T. Gu",
      "C. Y. Guan",
      "A. Q. Guo",
      "L. B. Guo",
      "M. J. Guo",
      "R. P. Guo",
      "Y. P. Guo",
      "A. Guskov",
      "J. Gutierrez",
      "K. L. Han",
      "T. T. Han",
      "F. Hanisch",
      "X. Q. Hao",
      "F. A. Harris",
      "K. K. He",
      "K. L. He",
      "F. H. Heinsius",
      "C. H. Heinz",
      "Y. K. Heng",
      "C. Herold",
      "T. Holtmann",
      "P. C. Hong",
      "G. Y. Hou",
      "X. T. Hou",
      "Y. R. Hou",
      "Z. L. Hou",
      "B. Y. Hu",
      "H. M. Hu",
      "J. F. Hu",
      "S. L. Hu",
      "T. Hu",
      "Y. Hu",
      "G. S. Huang",
      "K. X. Huang",
      "L. Q. Huang",
      "X. T. Huang",
      "Y. P. Huang",
      "Y. S. Huang",
      "T. Hussain",
      "F. H√∂lzken",
      "N. H√ºsken",
      "N. in der Wiesche",
      "J. Jackson",
      "S. Janchiv",
      "J. H. Jeong",
      "Q. Ji",
      "Q. P. Ji",
      "W. Ji",
      "X. B. Ji",
      "X. L. Ji",
      "Y. Y. Ji",
      "X. Q. Jia",
      "Z. K. Jia",
      "D. Jiang",
      "H. B. Jiang",
      "P. C. Jiang",
      "S. S. Jiang",
      "T. J. Jiang",
      "X. S. Jiang",
      "Y. Jiang",
      "J. B. Jiao",
      "J. K. Jiao",
      "Z. Jiao",
      "S. Jin",
      "Y. Jin",
      "M. Q. Jing",
      "X. M. Jing",
      "T. Johansson",
      "S. Kabana",
      "N. Kalantar-Nayestanaki",
      "X. L. Kang",
      "X. S. Kang",
      "M. Kavatsyuk",
      "B. C. Ke",
      "V. Khachatryan",
      "A. Khoukaz",
      "R. Kiuchi",
      "O. B. Kolcu",
      "B. Kopf",
      "M. Kuessner",
      "X. Kui",
      "N. Kumar",
      "A. Kupsc",
      "W. K√ºhn",
      "J. J. Lane",
      "P. Larin",
      "L. Lavezzi",
      "T. T. Lei",
      "Z. H. Lei",
      "M. Lellmann",
      "T. Lenz",
      "C. Li",
      "C. Li",
      "C. H. Li",
      "Cheng Li",
      "D. M. Li",
      "F. Li",
      "G. Li",
      "H. B. Li",
      "H. J. Li",
      "H. N. Li",
      "Hui Li",
      "J. R. Li",
      "J. S. Li",
      "K. Li",
      "L. J. Li",
      "L. K. Li",
      "Lei Li",
      "M. H. Li",
      "P. R. Li",
      "Q. M. Li",
      "Q. X. Li",
      "R. Li",
      "S. X. Li",
      "T. Li",
      "W. D. Li",
      "W. G. Li",
      "X. Li",
      "X. H. Li",
      "X. L. Li",
      "X. Y. Li",
      "X. Z. Li",
      "Y. G. Li",
      "Z. J. Li",
      "Z. Y. Li",
      "C. Liang",
      "H. Liang",
      "H. Liang",
      "Y. F. Liang",
      "Y. T. Liang",
      "G. R. Liao",
      "L. Z. Liao",
      "Y. P. Liao",
      "J. Libby",
      "A. Limphirat",
      "C. C. Lin",
      "D. X. Lin",
      "T. Lin",
      "B. J. Liu",
      "B. X. Liu",
      "C. Liu",
      "C. X. Liu",
      "F. Liu",
      "F. H. Liu",
      "Feng Liu",
      "G. M. Liu",
      "H. Liu",
      "H. B. Liu",
      "H. H. Liu",
      "H. M. Liu",
      "Huihui Liu",
      "J. B. Liu",
      "J. Y. Liu",
      "K. Liu",
      "K. Y. Liu",
      "Ke Liu",
      "L. Liu",
      "L. C. Liu",
      "Lu Liu",
      "M. H. Liu",
      "P. L. Liu",
      "Q. Liu",
      "S. B. Liu",
      "T. Liu",
      "W. K. Liu",
      "W. M. Liu",
      "X. Liu",
      "X. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. B. Liu",
      "Z. A. Liu",
      "Z. D. Liu",
      "Z. Q. Liu",
      "X. C. Lou",
      "F. X. Lu",
      "H. J. Lu",
      "J. G. Lu",
      "X. L. Lu",
      "Y. Lu",
      "Y. P. Lu",
      "Z. H. Lu",
      "C. L. Luo",
      "J. R. Luo",
      "M. X. Luo",
      "T. Luo",
      "X. L. Luo",
      "X. R. Lyu",
      "Y. F. Lyu",
      "F. C. Ma",
      "H. Ma",
      "H. L. Ma",
      "J. L. Ma",
      "L. L. Ma",
      "M. M. Ma",
      "Q. M. Ma",
      "R. Q. Ma",
      "T. Ma",
      "X. T. Ma",
      "X. Y. Ma",
      "Y. Ma",
      "Y. M. Ma",
      "F. E. Maas",
      "M. Maggiora",
      "S. Malde",
      "Y. J. Mao",
      "Z. P. Mao",
      "S. Marcello",
      "Z. X. Meng",
      "J. G. Messchendorp",
      "G. Mezzadri",
      "H. Miao",
      "T. J. Min",
      "R. E. Mitchell",
      "X. H. Mo",
      "B. Moses",
      "N. Yu. Muchnoi",
      "J. Muskalla",
      "Y. Nefedov",
      "F. Nerling",
      "L. S. Nie",
      "I. B. Nikolaev",
      "Z. Ning",
      "S. Nisar",
      "Q. L. Niu",
      "W. D. Niu",
      "Y. Niu",
      "S. L. Olsen",
      "Q. Ouyang",
      "S. Pacetti",
      "X. Pan",
      "Y. Pan",
      "A. Pathak",
      "P. Patteri",
      "Y. P. Pei",
      "M. Pelizaeus",
      "H. P. Peng",
      "Y. Y. Peng",
      "K. Peters",
      "J. L. Ping",
      "R. G. Ping",
      "S. Plura",
      "V. Prasad",
      "F. Z. Qi",
      "H. Qi",
      "H. R. Qi",
      "M. Qi",
      "T. Y. Qi",
      "S. Qian",
      "W. B. Qian",
      "C. F. Qiao",
      "X. K. Qiao",
      "J. J. Qin",
      "L. Q. Qin",
      "L. Y. Qin",
      "X. P. Qin",
      "X. S. Qin",
      "Z. H. Qin",
      "J. F. Qiu",
      "Z. H. Qu",
      "C. F. Redmer",
      "K. J. Ren",
      "A. Rivetti",
      "M. Rolo",
      "G. Rong",
      "Ch. Rosner",
      "S. N. Ruan",
      "N. Salone",
      "A. Sarantsev",
      "Y. Schelhaas",
      "K. Sch√∂enning",
      "M. Scodeggio",
      "K. Y. Shan",
      "W. Shan",
      "X. Y. Shan",
      "Z. J. Shang",
      "J. F. Shangguan",
      "L. G. Shao",
      "M. Shao",
      "C. P. Shen",
      "H. F. Shen",
      "W. H. Shen",
      "X. Y. Shen",
      "B. A. Shi",
      "H. Shi",
      "H. C. Shi",
      "J. L. Shi",
      "J. Y. Shi",
      "Q. Q. Shi",
      "S. Y. Shi",
      "X. Shi",
      "J. J. Song",
      "T. Z. Song",
      "W. M. Song",
      "Y. J. Song",
      "Y. X. Song",
      "S. Sosio",
      "S. Spataro",
      "F. Stieler",
      "Y. J. Su",
      "G. B. Sun",
      "G. X. Sun",
      "H. Sun",
      "H. K. Sun",
      "J. F. Sun",
      "K. Sun",
      "L. Sun",
      "S. S. Sun",
      "T. Sun",
      "W. Y. Sun",
      "Y. Sun",
      "Y. J. Sun",
      "Y. Z. Sun",
      "Z. Q. Sun",
      "Z. T. Sun",
      "C. J. Tang",
      "G. Y. Tang",
      "J. Tang",
      "M. Tang",
      "Y. A. Tang",
      "L. Y. Tao",
      "Q. T. Tao",
      "M. Tat",
      "J. X. Teng",
      "V. Thoren",
      "W. H. Tian",
      "Y. Tian",
      "Z. F. Tian",
      "I. Uman",
      "Y. Wan",
      "S. J. Wang",
      "B. Wang",
      "B. L. Wang",
      "Bo Wang",
      "D. Y. Wang",
      "F. Wang",
      "H. J. Wang",
      "J. J. Wang",
      "J. P. Wang",
      "K. Wang",
      "L. L. Wang",
      "M. Wang",
      "N. Y. Wang",
      "S. Wang",
      "S. Wang",
      "T. Wang",
      "T. J. Wang",
      "W. Wang",
      "W. Wang",
      "W. P. Wang",
      "X. Wang",
      "X. F. Wang",
      "X. J. Wang",
      "X. L. Wang",
      "X. N. Wang",
      "Y. Wang",
      "Y. D. Wang",
      "Y. F. Wang",
      "Y. L. Wang",
      "Y. N. Wang",
      "Y. Q. Wang",
      "Yaqian Wang",
      "Yi Wang",
      "Z. Wang",
      "Z. L. Wang",
      "Z. Y. Wang",
      "Ziyi Wang",
      "D. H. Wei",
      "F. Weidner",
      "S. P. Wen",
      "Y. R. Wen",
      "U. Wiedner",
      "G. Wilkinson",
      "M. Wolke",
      "L. Wollenberg",
      "C. Wu",
      "J. F. Wu",
      "L. H. Wu",
      "L. J. Wu",
      "X. Wu",
      "X. H. Wu",
      "Y. Wu",
      "Y. H. Wu",
      "Y. J. Wu",
      "Z. Wu",
      "L. Xia",
      "X. M. Xian",
      "B. H. Xiang",
      "T. Xiang",
      "D. Xiao",
      "G. Y. Xiao",
      "S. Y. Xiao",
      "Y. L. Xiao",
      "Z. J. Xiao",
      "C. Xie",
      "X. H. Xie",
      "Y. Xie",
      "Y. G. Xie",
      "Y. H. Xie",
      "Z. P. Xie",
      "T. Y. Xing",
      "C. F. Xu",
      "C. J. Xu",
      "G. F. Xu",
      "H. Y. Xu",
      "M. Xu",
      "Q. J. Xu",
      "Q. N. Xu",
      "W. Xu",
      "W. L. Xu",
      "X. P. Xu",
      "Y. C. Xu",
      "Z. P. Xu",
      "Z. S. Xu",
      "F. Yan",
      "L. Yan",
      "W. B. Yan",
      "W. C. Yan",
      "X. Q. Yan",
      "H. J. Yang",
      "H. L. Yang",
      "H. X. Yang",
      "T. Yang",
      "Y. Yang",
      "Y. F. Yang",
      "Y. F. Yang",
      "Y. X. Yang",
      "Z. W. Yang",
      "Z. P. Yao",
      "M. Ye",
      "M. H. Ye",
      "J. H. Yin",
      "Z. Y. You",
      "B. X. Yu",
      "C. X. Yu",
      "G. Yu",
      "J. S. Yu",
      "T. Yu",
      "X. D. Yu",
      "Y. C. Yu",
      "C. Z. Yuan",
      "J. Yuan",
      "J. Yuan",
      "L. Yuan",
      "S. C. Yuan",
      "Y. Yuan",
      "Z. Y. Yuan",
      "C. X. Yue",
      "A. A. Zafar",
      "F. R. Zeng",
      "S. H. Zeng",
      "X. Zeng",
      "Y. Zeng",
      "Y. J. Zeng",
      "Y. J. Zeng",
      "X. Y. Zhai",
      "Y. C. Zhai",
      "Y. H. Zhan",
      "A. Q. Zhang",
      "B. L. Zhang",
      "B. X. Zhang",
      "D. H. Zhang",
      "G. Y. Zhang",
      "H. Zhang",
      "H. Zhang",
      "H. C. Zhang",
      "H. H. Zhang",
      "H. H. Zhang",
      "H. Q. Zhang",
      "H. R. Zhang",
      "H. Y. Zhang",
      "J. Zhang",
      "J. Zhang",
      "J. J. Zhang",
      "J. L. Zhang",
      "J. Q. Zhang",
      "J. S. Zhang",
      "J. W. Zhang",
      "J. X. Zhang",
      "J. Y. Zhang",
      "J. Z. Zhang",
      "Jianyu Zhang",
      "L. M. Zhang",
      "Lei Zhang",
      "P. Zhang",
      "Q. Y. Zhang",
      "R. Y. Zhang",
      "S. H. Zhang",
      "Shulei Zhang",
      "X. D. Zhang",
      "X. M. Zhang",
      "X. Y. Zhang",
      "Y. Zhang",
      "Y. Zhang",
      "Y. T. Zhang",
      "Y. H. Zhang",
      "Y. M. Zhang",
      "Yan Zhang",
      "Z. D. Zhang",
      "Z. H. Zhang",
      "Z. L. Zhang",
      "Z. Y. Zhang",
      "Z. Y. Zhang",
      "Z. Z. Zhang",
      "G. Zhao",
      "J. Y. Zhao",
      "J. Z. Zhao",
      "L. Zhao",
      "Lei Zhao",
      "M. G. Zhao",
      "N. Zhao",
      "R. P. Zhao",
      "S. J. Zhao",
      "Y. B. Zhao",
      "Y. X. Zhao",
      "Z. G. Zhao",
      "A. Zhemchugov",
      "B. Zheng",
      "B. M. Zheng",
      "J. P. Zheng",
      "W. J. Zheng",
      "Y. H. Zheng",
      "B. Zhong",
      "X. Zhong",
      "H. Zhou",
      "J. Y. Zhou",
      "L. P. Zhou",
      "S. Zhou",
      "X. Zhou",
      "X. K. Zhou",
      "X. R. Zhou",
      "X. Y. Zhou",
      "Y. Z. Zhou",
      "J. Zhu",
      "K. Zhu",
      "K. J. Zhu",
      "K. S. Zhu",
      "L. Zhu",
      "L. X. Zhu",
      "S. H. Zhu",
      "S. Q. Zhu",
      "T. J. Zhu",
      "W. D. Zhu",
      "Y. C. Zhu",
      "Z. A. Zhu",
      "J. H. Zou",
      "J. Zu"
    ],
    "abstract": "Based on 12.0 $\\mathrm{fb^{-1}}$ of $e^{+}e^{-}$ collision data samples\ncollected by the BESIII detector at center-of-mass energies from 4.1271 to\n4.3583 GeV, a partial wave analysis is performed for the process $e^{+}e^{-}\n\\rightarrow \\pi^{+}\\pi^{-}J/\\psi$. The cross sections for the sub processes\n${e^{+}e^{-}\\rightarrow\\pi^{+}Z_{c}(3900)^{-}+c.c.\\rightarrow\\pi^{+}\\pi^{-}J/\\psi}$,\n$f_{0}(980)(\\rightarrow\\pi^{+}\\pi^{-})J/\\psi$, and\n$(\\pi^{+}\\pi^{-})_{\\rm{S\\mbox{-}wave}} J/\\psi$ are measured for the first time.\nThe mass and width of the $Z_{c}(3900)^{\\pm}$ are determined to be\n$3884.6\\pm0.7\\pm3.3$ MeV/$c^{2}$ and $37.2\\pm1.3\\pm6.6$ MeV, respectively. The\nfirst errors are statistical and the second systematic. The final state\n$(\\pi^{+}\\pi^{-})_{\\rm{S\\mbox{-}wave}} J/\\psi$ dominates the process\n$e^{+}e^{-} \\rightarrow \\pi^{+}\\pi^{-}J/\\psi$. By analyzing the cross sections\nof $\\pi^{\\pm}Z_{c}(3900)^{\\mp}$ and $f_{0}(980)J/\\psi$, $Y(4220)$ has been\nobserved. Its mass and width are determined to be $4225.8\\pm4.2\\pm3.1$\nMeV/$c^{2}$ and $55.3\\pm9.5\\pm11.1$ MeV, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.13222v1",
    "published": "2025-05-19T15:05:50+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.17069v1",
    "title": "Blindfolded Spider-man Optimization: A Single-Point Metaheuristics Suitable for Continuous and Discrete Spaces",
    "authors": [
      "Satyam Mittal"
    ],
    "abstract": "In this study, we introduce a new single point metaheuristic optimization\napproach suitable for both continuous and discrete domains. The proposed\nalgorithm, entitled Blindfolded Spiderman Optimization, follows a piecewise\nlinear search trajectory where each line segment considers a move to an\nimproved solution point. The trajectory resembles spiderman jumping from one\nbuilding to the highest neighbor building in a blindfolded manner. Blindfolded\nSpiderman Optimization builds on top of the Buggy Pinball Optimization\nalgorithm. Blindfolded Spiderman Optimization is tested on 16 mathematical\noptimization functions and one discrete problem of Unbounded Knapsack. We\nperform a thorough evaluation of Blindfolded Spiderman Optimization against\nestablished and state-of-the-art metaheuristic optimization methods, including\nWhale Optimization, Grey Wolf Optimization, Particle Swarm Optimization,\nSimulated Annealing, Threshold Accepting, and Buggy Pinball Optimization\nconsidering various optimization domains and dimensions. We show that\nBlindfolded Spiderman Optimization achieves great performance on both\ncontinuous and discrete spaces, and superior performance compared to all\nsingle-point metaheuristic approaches considered.",
    "pdf_url": "http://arxiv.org/pdf/2505.17069v1",
    "published": "2025-05-19T15:05:21+00:00",
    "categories": [
      "cs.NE",
      "math.OC"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13221v1",
    "title": "Heyde characterization theorem for some classes of locally compact Abelian groups",
    "authors": [
      "Gennadiy Feldman"
    ],
    "abstract": "Let $L_1$ and $L_2$ be linear forms of real-valued independent random\nvariables. By Heyde's theorem, if the conditional distribution of $L_2$ given\n$L_1$ is symmetric, then the random variables are Gaussian. A number of papers\nare devoted to generalisation of Heyde's theorem to the case, where independent\nrandom variables take values in a locally compact Abelian group $X$. The\narticle continues these studies. We consider the case, where $X$ is either a\ntotally disconnected group or is of the form $\\mathbb{R}^n\\times G$, where $G$\nis a totally disconnected group consisting of compact elements. The proof is\nbased on the study of solutions of the Heyde functional equation on the\ncharacter group of the original group. In so doing, we use methods of abstract\nharmonic analysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.13221v1",
    "published": "2025-05-19T15:03:33+00:00",
    "categories": [
      "math.PR",
      "39B52, 43A35, 60B15, 62E10"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13220v1",
    "title": "SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science",
    "authors": [
      "Jie Ying",
      "Zihong Chen",
      "Zhefan Wang",
      "Wanli Jiang",
      "Chenyang Wang",
      "Zhonghang Yuan",
      "Haoyang Su",
      "Huanjun Kong",
      "Fan Yang",
      "Nanqing Dong"
    ],
    "abstract": "Seed science is essential for modern agriculture, directly influencing crop\nyields and global food security. However, challenges such as interdisciplinary\ncomplexity and high costs with limited returns hinder progress, leading to a\nshortage of experts and insufficient technological support. While large\nlanguage models (LLMs) have shown promise across various fields, their\napplication in seed science remains limited due to the scarcity of digital\nresources, complex gene-trait relationships, and the lack of standardized\nbenchmarks. To address this gap, we introduce SeedBench -- the first multi-task\nbenchmark specifically designed for seed science. Developed in collaboration\nwith domain experts, SeedBench focuses on seed breeding and simulates key\naspects of modern breeding processes. We conduct a comprehensive evaluation of\n26 leading LLMs, encompassing proprietary, open-source, and domain-specific\nfine-tuned models. Our findings not only highlight the substantial gaps between\nthe power of LLMs and the real-world seed science problems, but also make a\nfoundational step for research on LLMs for seed design.",
    "pdf_url": "http://arxiv.org/pdf/2505.13220v1",
    "published": "2025-05-19T15:02:59+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13219v5",
    "title": "PiT: Progressive Diffusion Transformer",
    "authors": [
      "Jiafu Wu",
      "Yabiao Wang",
      "Jian Li",
      "Jinlong Peng",
      "Yun Cao",
      "Chengjie Wang",
      "Jiangning Zhang"
    ],
    "abstract": "Diffusion Transformers (DiTs) achieve remarkable performance within image\ngeneration via the transformer architecture. Conventionally, DiTs are\nconstructed by stacking serial isotropic global modeling transformers, which\nface significant quadratic computational cost. However, through empirical\nanalysis, we find that DiTs do not rely as heavily on global information as\npreviously believed. In fact, most layers exhibit significant redundancy in\nglobal computation. Additionally, conventional attention mechanisms suffer from\nlow-frequency inertia, limiting their efficiency. To address these issues, we\npropose Pseudo Shifted Window Attention (PSWA), which fundamentally mitigates\nglobal attention redundancy. PSWA achieves moderate global-local information\nthrough window attention. It further utilizes a high-frequency bridging branch\nto simulate shifted window operations, which both enrich the high-frequency\ninformation and strengthen inter-window connections. Furthermore, we propose\nthe Progressive Coverage Channel Allocation (PCCA) strategy that captures\nhigh-order attention without additional computational cost. Based on these\ninnovations, we propose a series of Pseudo Progressive Diffusion Transformer\n(PiT). Our extensive experiments show their superior performance; for example,\nour proposed PiT-L achieves 54% FID improvement over DiT-XL/2 while using less\ncomputation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13219v5",
    "published": "2025-05-19T15:02:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13218v1",
    "title": "Human Response to Decision Support in Face Matching: The Influence of Task Difficulty and Machine Accuracy",
    "authors": [
      "Marina Est√©vez-Almenzar",
      "Ricardo Baeza-Yates",
      "Carlos Castillo"
    ],
    "abstract": "Decision support systems enhanced by Artificial Intelligence (AI) are\nincreasingly being used in high-stakes scenarios where errors or biased\noutcomes can have significant consequences. In this work, we explore the\nconditions under which AI-based decision support systems affect the decision\naccuracy of humans involved in face matching tasks. Previous work suggests that\nthis largely depends on various factors, such as the specific nature of the\ntask and how users perceive the quality of the decision support, among others.\nHence, we conduct extensive experiments to examine how both task difficulty and\nthe precision of the system influence human outcomes. Our results show a strong\ninfluence of task difficulty, which not only makes humans less precise but also\nless capable of determining whether the decision support system is yielding\naccurate suggestions or not. This has implications for the design of decision\nsupport systems, and calls for a careful examination of the context in which\nthey are deployed and on how they are perceived by users.",
    "pdf_url": "http://arxiv.org/pdf/2505.13218v1",
    "published": "2025-05-19T15:01:22+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13217v1",
    "title": "Quantum Hamiltonian Certification",
    "authors": [
      "Minbo Gao",
      "Zhengfeng Ji",
      "Qisheng Wang",
      "Wenjun Yu",
      "Qi Zhao"
    ],
    "abstract": "We formalize and study the Hamiltonian certification problem. Given access to\n$e^{-\\mathrm{i} Ht}$ for an unknown Hamiltonian $H$, the goal of the problem is\nto determine whether $H$ is $\\varepsilon_1$-close to or $\\varepsilon_2$-far\nfrom a target Hamiltonian $H_0$. While Hamiltonian learning methods have been\nextensively studied, they often require restrictive assumptions and suffer from\ninefficiencies when adapted for certification tasks.\n  This work introduces a direct and efficient framework for Hamiltonian\ncertification. Our approach achieves \\textit{optimal} total evolution time\n$\\Theta((\\varepsilon_2-\\varepsilon_1)^{-1})$ for certification under the\nnormalized Frobenius norm, without prior structural assumptions. This approach\nalso extends to certify Hamiltonians with respect to all Pauli norms and\nnormalized Schatten $p$-norms for $1\\leq p\\leq2$ in the one-sided error setting\n($\\varepsilon_1=0$). Notably, the result in Pauli $1$-norm suggests a quadratic\nadvantage of our approach over all possible Hamiltonian learning approaches. We\nalso establish matching lower bounds to show the optimality of our approach\nacross all the above norms. We complement our result by showing that the\ncertification problem with respect to normalized Schatten $\\infty$-norm is\n$\\mathsf{coQMA}$-hard, and therefore unlikely to have efficient solutions. This\nhardness result provides strong evidence that our focus on the above metrics is\nnot merely a technical choice but a requirement for efficient certification.\n  To enhance practical applicability, we develop an ancilla-free certification\nmethod that maintains the inverse precision scaling while eliminating the need\nfor auxiliary qubits, making our approach immediately accessible for near-term\nquantum devices with limited resources.",
    "pdf_url": "http://arxiv.org/pdf/2505.13217v1",
    "published": "2025-05-19T15:00:58+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13216v1",
    "title": "Spatio-temporal patterns of active epigenetic turnover",
    "authors": [
      "Fabrizio Olmeda",
      "Misha Gupta",
      "Onurcan Bektas",
      "Steffen Rulands"
    ],
    "abstract": "DNA methylation is a primary layer of epigenetic modification that plays a\npivotal role in the regulation of development, aging, and cancer. The\nconcurrent activity of opposing enzymes that mediate DNA methylation and\ndemethylation gives rise to a biochemical cycle and active turnover of DNA\nmethylation. While the ensuing biochemical oscillations have been implicated in\nthe regulation of cell differentiation, their functional role and\nspatio-temporal dynamics are, however, unknown. In this work, we demonstrate\nthat chromatin-mediated coupling between these local biochemical cycles can\nlead to the emergence of phase-locked domains, regions of locally synchronized\nturnover activity, whose coarsening is arrested by genomic heterogeneity. We\nintroduce a minimal model based on stochastic oscillators with constrained\nlong-range and non-reciprocal interactions, shaped by the local chromatin\norganization. Through a combination of analytical theory and stochastic\nsimulations, we predict both the degree of synchronization and the typical size\nof emergent phase-locked domains. We qualitatively test these predictions using\nsingle-cell sequencing data. Our results show that DNA methylation turnover\nexhibits surprisingly rich spatio-temporal patterns which may be used by cells\nto control cell differentiation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13216v1",
    "published": "2025-05-19T15:00:26+00:00",
    "categories": [
      "physics.bio-ph"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13215v1",
    "title": "Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation",
    "authors": [
      "Seungjun Oh",
      "Younggeun Lee",
      "Hyejin Jeon",
      "Eunbyung Park"
    ],
    "abstract": "Recent advancements in dynamic 3D scene reconstruction have shown promising\nresults, enabling high-fidelity 3D novel view synthesis with improved temporal\nconsistency. Among these, 4D Gaussian Splatting (4DGS) has emerged as an\nappealing approach due to its ability to model high-fidelity spatial and\ntemporal variations. However, existing methods suffer from substantial\ncomputational and memory overhead due to the redundant allocation of 4D\nGaussians to static regions, which can also degrade image quality. In this\nwork, we introduce hybrid 3D-4D Gaussian Splatting (3D-4DGS), a novel framework\nthat adaptively represents static regions with 3D Gaussians while reserving 4D\nGaussians for dynamic elements. Our method begins with a fully 4D Gaussian\nrepresentation and iteratively converts temporally invariant Gaussians into 3D,\nsignificantly reducing the number of parameters and improving computational\nefficiency. Meanwhile, dynamic Gaussians retain their full 4D representation,\ncapturing complex motions with high fidelity. Our approach achieves\nsignificantly faster training times compared to baseline 4D Gaussian Splatting\nmethods while maintaining or improving the visual quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.13215v1",
    "published": "2025-05-19T14:59:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13214v1",
    "title": "Observational Signatures of Janis-Newman-Winicour Strongly Naked Singularity",
    "authors": [
      "Zeqian Zhang"
    ],
    "abstract": "This paper explores the unique observational signatures of accretion onto a\nJanis-Newman-Winicour (JNW) strongly naked singularity, particularly in the\nabsence of a photon sphere. The surrounding spacetime of such a singularity\nexhibits pronounced reflective properties, causing light rays traveling in its\nvicinity to undergo reflection and produce paired imaging trajectories in both\naccretion disk and hot spot models. Our simulations reveal that this reflection\neffect generates additional images in the gravitational lensing patterns and\nsignificantly alters the temporal brightness profiles of the lensed images.\nThese reflection-induced paired images, together with their\ninclination-dependent behavior, offer distinct observational signatures that\ncould potentially distinguish a JNW strongly naked singularity from a black\nhole based on future high-resolution observations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13214v1",
    "published": "2025-05-19T14:59:45+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.13213v1",
    "title": "Diffusion Models with Double Guidance: Generate with aggregated datasets",
    "authors": [
      "Yanfeng Yang",
      "Kenji Fukumizu"
    ],
    "abstract": "Creating large-scale datasets for training high-performance generative models\nis often prohibitively expensive, especially when associated attributes or\nannotations must be provided. As a result, merging existing datasets has become\na common strategy. However, the sets of attributes across datasets are often\ninconsistent, and their naive concatenation typically leads to block-wise\nmissing conditions. This presents a significant challenge for conditional\ngenerative modeling when the multiple attributes are used jointly as\nconditions, thereby limiting the model's controllability and applicability. To\naddress this issue, we propose a novel generative approach, Diffusion Model\nwith Double Guidance, which enables precise conditional generation even when no\ntraining samples contain all conditions simultaneously. Our method maintains\nrigorous control over multiple conditions without requiring joint annotations.\nWe demonstrate its effectiveness in molecular and image generation tasks, where\nit outperforms existing baselines both in alignment with target conditional\ndistributions and in controllability under missing condition settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.13213v1",
    "published": "2025-05-19T14:59:35+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.18190v2",
    "title": "PhySense: Sensor Placement Optimization for Accurate Physics Sensing",
    "authors": [
      "Yuezhou Ma",
      "Haixu Wu",
      "Hang Zhou",
      "Huikun Weng",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "abstract": "Physics sensing plays a central role in many scientific and engineering\ndomains, which inherently involves two coupled tasks: reconstructing dense\nphysical fields from sparse observations and optimizing scattered sensor\nplacements to observe maximum information. While deep learning has made rapid\nadvances in sparse-data reconstruction, existing methods generally omit\noptimization of sensor placements, leaving the mutual enhancement between\nreconstruction and placement on the shelf. To change this suboptimal practice,\nwe propose PhySense, a synergistic two-stage framework that learns to jointly\nreconstruct physical fields and to optimize sensor placements, both aiming for\naccurate physics sensing. The first stage involves a flow-based generative\nmodel enhanced by cross-attention to adaptively fuse sparse observations.\nLeveraging the reconstruction feedback, the second stage performs sensor\nplacement via projected gradient descent to satisfy spatial constraints. We\nfurther prove that the learning objectives of the two stages are consistent\nwith classical variance-minimization principles, providing theoretical\nguarantees. Extensive experiments across three challenging benchmarks,\nespecially a 3D geometry dataset, indicate PhySense achieves state-of-the-art\nphysics sensing accuracy and discovers informative sensor placements previously\nunconsidered.",
    "pdf_url": "http://arxiv.org/pdf/2505.18190v2",
    "published": "2025-05-19T14:59:11+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13212v2",
    "title": "RB-SCD: A New Benchmark for Semantic Change Detection of Roads and Bridges in Traffic Scenes",
    "authors": [
      "Qingling Shu",
      "Sibao Chen",
      "Zhihui You",
      "Wei Lu",
      "Jin Tang",
      "Bin Luo"
    ],
    "abstract": "With the rapid modernization of urban transportation, accurately detecting\nchanges such as road and bridge construction, renovation, and demolition is\ncrucial for urban planning and traffic management. However, existing methods\noften struggle to extract fine-grained semantic changes in complex traffic\nscenes, largely due to the lack of high-quality annotated change detection (CD)\ndatasets. To address this, we introduce the Road and Bridge Semantic Change\nDetection (RB-SCD) dataset, a comprehensive benchmark consisting of 260 pairs\nof high-resolution remote sensing images. RB-SCD spans diverse geographic areas\nand includes a wide variety of road and bridge types across over ten cities in\nmultiple countries. It covers 11 distinct categories of semantic changes,\nenabling detailed structural and functional analysis. Based on this challenging\ndataset, we propose a novel framework called the Multimodal Frequency-Driven\nChange Detector (MFDCD). For the first time, MFDCD integrates multimodal\nfeature characteristics in the frequency domain. It comprises two key\ncomponents: the Dynamic Frequency Coupler (DFC) and the Textual Frequency\nFilter (TFF). DFC couples hierarchical visual features with wavelet-based\nfrequency components, enhancing the perception of fine-grained and\ncross-temporal structural changes. TFF transforms textual features extracted by\nthe CLIP model into the frequency domain via Fourier transform and applies\ngraph-based filtering to extract salient frequency responses. These are then\nfused with visual features to enable effective multimodal representation\nlearning. Extensive experiments show that MFDCD achieves strong performance on\nRB-SCD and three public benchmarks. The RB-SCD dataset, with its rich and\ndiverse annotations, serves as a valuable resource for advancing research in\nroad and bridge change detection under complex traffic conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13212v2",
    "published": "2025-05-19T14:59:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13211v1",
    "title": "MAGI-1: Autoregressive Video Generation at Scale",
    "authors": [
      "Sand. ai",
      "Hansi Teng",
      "Hongyu Jia",
      "Lei Sun",
      "Lingzhi Li",
      "Maolin Li",
      "Mingqiu Tang",
      "Shuai Han",
      "Tianning Zhang",
      "W. Q. Zhang",
      "Weifeng Luo",
      "Xiaoyang Kang",
      "Yuchen Sun",
      "Yue Cao",
      "Yunpeng Huang",
      "Yutong Lin",
      "Yuxin Fang",
      "Zewei Tao",
      "Zheng Zhang",
      "Zhongshu Wang",
      "Zixun Liu",
      "Dai Shi",
      "Guoli Su",
      "Hanwen Sun",
      "Hong Pan",
      "Jie Wang",
      "Jiexin Sheng",
      "Min Cui",
      "Min Hu",
      "Ming Yan",
      "Shucheng Yin",
      "Siran Zhang",
      "Tingting Liu",
      "Xianping Yin",
      "Xiaoyu Yang",
      "Xin Song",
      "Xuan Hu",
      "Yankai Zhang",
      "Yuqiao Li"
    ],
    "abstract": "We present MAGI-1, a world model that generates videos by autoregressively\npredicting a sequence of video chunks, defined as fixed-length segments of\nconsecutive frames. Trained to denoise per-chunk noise that increases\nmonotonically over time, MAGI-1 enables causal temporal modeling and naturally\nsupports streaming generation. It achieves strong performance on image-to-video\n(I2V) tasks conditioned on text instructions, providing high temporal\nconsistency and scalability, which are made possible by several algorithmic\ninnovations and a dedicated infrastructure stack. MAGI-1 facilitates\ncontrollable generation via chunk-wise prompting and supports real-time,\nmemory-efficient deployment by maintaining constant peak inference cost,\nregardless of video length. The largest variant of MAGI-1 comprises 24 billion\nparameters and supports context lengths of up to 4 million tokens,\ndemonstrating the scalability and robustness of our approach. The code and\nmodels are available at https://github.com/SandAI-org/MAGI-1 and\nhttps://github.com/SandAI-org/MagiAttention. The product can be accessed at\nhttps://sand.ai.",
    "pdf_url": "http://arxiv.org/pdf/2505.13211v1",
    "published": "2025-05-19T14:58:50+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13210v1",
    "title": "Picturized and Recited with Dialects: A Multimodal Chinese Representation Framework for Sentiment Analysis of Classical Chinese Poetry",
    "authors": [
      "Xiaocong Du",
      "Haoyu Pei",
      "Haipeng Zhang"
    ],
    "abstract": "Classical Chinese poetry is a vital and enduring part of Chinese literature,\nconveying profound emotional resonance. Existing studies analyze sentiment\nbased on textual meanings, overlooking the unique rhythmic and visual features\ninherent in poetry,especially since it is often recited and accompanied by\nChinese paintings. In this work, we propose a dialect-enhanced multimodal\nframework for classical Chinese poetry sentiment analysis. We extract\nsentence-level audio features from the poetry and incorporate audio from\nmultiple dialects,which may retain regional ancient Chinese phonetic features,\nenriching the phonetic representation. Additionally, we generate sentence-level\nvisual features, and the multimodal features are fused with textual features\nenhanced by LLM translation through multimodal contrastive representation\nlearning. Our framework outperforms state-of-the-art methods on two public\ndatasets, achieving at least 2.51% improvement in accuracy and 1.63% in macro\nF1. We open-source the code to facilitate research in this area and provide\ninsights for general multimodal Chinese representation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13210v1",
    "published": "2025-05-19T14:58:44+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13577v2",
    "title": "VocalAgent: Large Language Models for Vocal Health Diagnostics with Safety-Aware Evaluation",
    "authors": [
      "Yubin Kim",
      "Taehan Kim",
      "Wonjune Kang",
      "Eugene Park",
      "Joonsik Yoon",
      "Dongjae Lee",
      "Xin Liu",
      "Daniel McDuff",
      "Hyeonhoon Lee",
      "Cynthia Breazeal",
      "Hae Won Park"
    ],
    "abstract": "Vocal health plays a crucial role in peoples' lives, significantly impacting\ntheir communicative abilities and interactions. However, despite the global\nprevalence of voice disorders, many lack access to convenient diagnosis and\ntreatment. This paper introduces VocalAgent, an audio large language model\n(LLM) to address these challenges through vocal health diagnosis. We leverage\nQwen-Audio-Chat fine-tuned on three datasets collected in-situ from hospital\npatients, and present a multifaceted evaluation framework encompassing a safety\nassessment to mitigate diagnostic biases, cross-lingual performance analysis,\nand modality ablation studies. VocalAgent demonstrates superior accuracy on\nvoice disorder classification compared to state-of-the-art baselines. Its\nLLM-based method offers a scalable solution for broader adoption of health\ndiagnostics, while underscoring the importance of ethical and technical\nvalidation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13577v2",
    "published": "2025-05-19T14:58:42+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.13209v1",
    "title": "Quantum confinement and carbon nanodots: A conceptual view for the origin of diffuse interstellar bands",
    "authors": [
      "A. P. Jones"
    ],
    "abstract": "The nature of the Diffuse Interstellar Band (DIB) carriers is perhaps the\nmost studied, longest standing, unresolved problem in astronomy. While four\nbands have been associated with the fullerene cation (C^+_60) the vast majority\n(> 550) remain unidentified. This works is an attempt to provide a conceptual\nframework for the typical energy transitions that are central to explaining the\norigin of DIBs, however, it does not make an association between these\ntransitions and any particular DIBs. The effect of quantum confinement on\nexcitons is used, including charge transfer excitons, to construct a generic\nbasis for the electronic transitions that could, in principle, be coherent with\nthe energies associated with DIBs. In this model the carriers are carbon\nnanodots (CNDs) modelled as nanodiamonds and a-C(:H) nanoparticles. These\npreliminary results seem to show that particle size dependent effects in\nnanodiamond and a-C(:H) CNDs could be consistent with the positions of, and\nintervals between, some of the DIBs. One particular strength of the model is\nthat predicts single bands from the majority of single-size particles and, at\nmost, two bands from some of these same carriers. In the latter case the two\nbands come from different transitions and may or may not inter-correlate,\ndepending upon the local environment. This generic framework indicates that the\nsize dependent fundamental transitions in CNDs could provide a viable scenario\nfor the origin of some DIB-type bands. While this work does not identify a\nsingle DIB, it furnishes a conceptual view for the DIB origin, and suggests\nthat a more refined exploration of quantum confinement size effects, and\nexciton physics within the astronomical domain might prove fruitful. This work\nalso hints at the requirement for stable configurations for particular size\ndomains in order to explain DIB wavelength stability.",
    "pdf_url": "http://arxiv.org/pdf/2505.13209v1",
    "published": "2025-05-19T14:58:41+00:00",
    "categories": [
      "astro-ph.GA",
      "quant-ph"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13208v1",
    "title": "Efficient Generation of Parameterised Quantum Circuits from Large Texts",
    "authors": [
      "Colin Krawchuk",
      "Nikhil Khatri",
      "Neil John Ortega",
      "Dimitri Kartsaklis"
    ],
    "abstract": "Quantum approaches to natural language processing (NLP) are redefining how\nlinguistic information is represented and processed. While traditional hybrid\nquantum-classical models rely heavily on classical neural networks, recent\nadvancements propose a novel framework, DisCoCirc, capable of directly encoding\nentire documents as parameterised quantum circuits (PQCs), besides enjoying\nsome additional interpretability and compositionality benefits. Following these\nideas, this paper introduces an efficient methodology for converting\nlarge-scale texts into quantum circuits using tree-like representations of\npregroup diagrams. Exploiting the compositional parallels between language and\nquantum mechanics, grounded in symmetric monoidal categories, our approach\nenables faithful and efficient encoding of syntactic and discourse\nrelationships in long and complex texts (up to 6410 words in our experiments)\nto quantum circuits. The developed system is provided to the community as part\nof the augmented open-source quantum NLP package lambeq Gen II.",
    "pdf_url": "http://arxiv.org/pdf/2505.13208v1",
    "published": "2025-05-19T14:57:53+00:00",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13207v1",
    "title": "Discrete Time Crystals in the spin-s Central Spin Model",
    "authors": [
      "Hillol Biswas",
      "Sayan Choudhury"
    ],
    "abstract": "We propose periodic driving protocols to realize discrete time crystals\n(DTCs) in a spin-s central spin model. Interestingly, we identify parameter\nregimes, where eternal period-doubling and higher-order(HO)-DTCs can be\nrealized, even for finite-sized systems. We have determined the dependence of\nthe DTC order on the number of satellite spins and the central spin value, s.\nIntriguingly, we find that certain classes of HO-DTCs produce a series of\nmaximally entangled Bell cat and super-cat states during their dynamical\nevolution. Finally, we demonstrate that the HO-DTCs can be employed for\nquantum-enhanced multiparameter sensing at the Heisenberg limit.",
    "pdf_url": "http://arxiv.org/pdf/2505.13207v1",
    "published": "2025-05-19T14:57:39+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.quant-gas",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13206v1",
    "title": "Rapidly Varying Completely Random Measures for Modeling Extremely Sparse Networks",
    "authors": [
      "Valentin Kilian",
      "Benjamin Guedj",
      "Fran√ßois Caron"
    ],
    "abstract": "Completely random measures (CRMs) are fundamental to Bayesian nonparametric\nmodels, with applications in clustering, feature allocation, and network\nanalysis. A key quantity of interest is the Laplace exponent, whose asymptotic\nbehavior determines how the random structures scale. When the Laplace exponent\ngrows nearly linearly - known as rapid variation - the induced models exhibit\napproximately linear growth in the number of clusters, features, or edges with\nsample size or network nodes. This regime is especially relevant for modeling\nsparse networks, yet existing CRM constructions lack tractability under rapid\nvariation. We address this by introducing a new class of CRMs with index of\nvariation $\\alpha\\in(0,1]$, defined as mixtures of stable or generalized gamma\nprocesses. These models offer interpretable parameters, include well-known CRMs\nas limiting cases, and retain analytical tractability through a tractable\nLaplace exponent and simple size-biased representation. We analyze the\nasymptotic properties of this CRM class and apply it to the Caron-Fox framework\nfor sparse graphs. The resulting models produce networks with near-linear edge\ngrowth, aligning with empirical evidence from large-scale networks.\nAdditionally, we present efficient algorithms for simulation and posterior\ninference, demonstrating practical advantages through experiments on real-world\nsparse network datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.13206v1",
    "published": "2025-05-19T14:57:12+00:00",
    "categories": [
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.14720v1",
    "title": "A High-Flux Electron Detector System to Measure Non-linear Compton Scattering at LUXE",
    "authors": [
      "Antonios Athanassiadis",
      "Robert Ariniello",
      "Louis Helary",
      "Luke Hendriks",
      "Ruth Jacobs",
      "Alexander Knetsch",
      "Jenny List",
      "Sebastian Meuren",
      "Gudrid Moortgat-Pick",
      "Ivan Rajkovic",
      "Evan Ranken",
      "David A. Reis",
      "Stefan Schmitt",
      "Ivo Schulthess",
      "Doug Storey",
      "Junzhi Wang",
      "Matthew Wing"
    ],
    "abstract": "Recently, advancements in high-intensity laser technology have enabled the\nexploration of non-perturbative Quantum Electrodynamics (QED) in strong-field\nregimes. Notable aspects include non-linear Compton scattering and\nBreit-Wheeler pair production, observable when colliding high-intensity laser\npulses and relativistic electron beams. The LUXE experiment at DESY and the\nE-320 experiment at SLAC aim to study these phenomena by measuring the created\nhigh-flux Compton electrons and photons. We propose a novel detector system\nfeaturing a segmented gas-filled Cherenkov detector with a scintillator screen\nand camera setup, designed to efficiently detect high-flux Compton electrons.\nPreliminary results from E-320 measurement campaigns demonstrate methods for\nreconstructing electron energy spectra, aiming to reveal crucial features of\nnon-perturbative QED.",
    "pdf_url": "http://arxiv.org/pdf/2505.14720v1",
    "published": "2025-05-19T14:56:27+00:00",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.13205v2",
    "title": "Quantum Knowledge Distillation for Large Language Models",
    "authors": [
      "Lingxiao Li",
      "Yihao Wang",
      "Jiacheng Fan",
      "Jing Li",
      "Sujuan Qin",
      "Qiaoyan Wen",
      "Fei Gao"
    ],
    "abstract": "As foundational tools in natural language processing, Large Language Models\n(LLMs) have immense parameter scales, which makes deployment and inference\nincreasingly prohibitive, especially in resource-constrained devices.\nTherefore, knowledge distillation for LLMs, i.e., compressing the LLM to a\nsmaller model, is meaningful. With strong parameter representation capacity,\nquantum computing is regarded as a promising solution. Here, we propose a\nQuantum knowledge Distillation model for LLMs (QD-LLM) that leverages\nvariational quantum circuits to learn from LLMs. In classical simulation,\nQD-LLM outperforms several mainstream distillation methods on multiple text\nclassification tasks in terms of both accuracy and efficiency using only 11\nqubits. The results reveal an interesting phenomenon that the simulation of\nquantum student models may be regarded as a new class of quantum-inspired\nclassical algorithms. Remarkably, we deploy the obtained circuits on the Baihua\nsuperconducting quantum processor via the Quafu platform to assess practical\nfeasibility. The model maintains stable inference performance despite hardware\nconstraints such as decoherence and finite sampling. In summary, QD-LLM marks a\nfoundational step in connecting quantum computing with LLMs, demonstrating the\nfeasibility of quantum-native approaches that aim to compress and deploy models\nof increasingly larger scales. The code of this article has been open-sourced\nat https://github.com/Lilingxiao-bupt/QD-LLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.13205v2",
    "published": "2025-05-19T14:56:24+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13204v2",
    "title": "Alignment-Augmented Speculative Decoding with Alignment Sampling and Conditional Verification",
    "authors": [
      "Jikai Wang",
      "Zhenxu Tian",
      "Juntao Li",
      "Qingrong Xia",
      "Xinyu Duan",
      "Zhefeng Wang",
      "Baoxing Huai",
      "Min Zhang"
    ],
    "abstract": "Recent works have revealed the great potential of speculative decoding in\naccelerating the autoregressive generation process of large language models.\nThe success of these methods relies on the alignment between draft candidates\nand the sampled outputs of the target model. Existing methods mainly achieve\ndraft-target alignment with training-based methods, e.g., EAGLE, Medusa,\ninvolving considerable training costs. In this paper, we present a\ntraining-free alignment-augmented speculative decoding algorithm. We propose\nalignment sampling, which leverages output distribution obtained in the\nprefilling phase to provide more aligned draft candidates. To further benefit\nfrom high-quality but non-aligned draft candidates, we also introduce a simple\nyet effective flexible verification strategy. Through an adaptive probability\nthreshold, our approach can improve generation accuracy while further improving\ninference efficiency. Experiments on 8 datasets (including question answering,\nsummarization and code completion tasks) show that our approach increases the\naverage generation score by 3.3 points for the LLaMA3 model. Our method\nachieves a mean acceptance length up to 2.39 and speed up generation by 2.23.",
    "pdf_url": "http://arxiv.org/pdf/2505.13204v2",
    "published": "2025-05-19T14:55:41+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13203v1",
    "title": "Abstract zip data",
    "authors": [
      "Christopher Lang"
    ],
    "abstract": "The topological space of the stack of $G$-zips can be computed using a\nrefinement process. We extend this refinement process to a more general\nframework and show that in many situations this process can be used to compute\nthe equivalence classes of a certain equivalence relation, which in the case of\n$G$-zips is precisely the topological space.",
    "pdf_url": "http://arxiv.org/pdf/2505.13203v1",
    "published": "2025-05-19T14:55:07+00:00",
    "categories": [
      "math.AT",
      "math.AG",
      "14D23 (Primary) 14L15, 14L30 (Secondary)"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13202v1",
    "title": "SIMBA -- A Bayesian Decision Framework for the Identification of Optimal Biomarker Subgroups for Cancer Basket Clinical Trials",
    "authors": [
      "Shijie Yuan",
      "Jiaxin Liu",
      "Zhihua Gong",
      "Xia Qin",
      "Crystal Qin",
      "Yuan Ji",
      "Peter M√ºller"
    ],
    "abstract": "We consider basket trials in which a biomarker-targeting drug may be\nefficacious for patients across different disease indications. Patients are\nenrolled if their cells exhibit some levels of biomarker expression. The\nthreshold level is allowed to vary by indication. The proposed SIMBA method\nuses a decision framework to identify optimal biomarker subgroups (OBS) defined\nby an optimal biomarker threshold for each indication. The optimality is\nachieved through minimizing a posterior expected loss that balances estimation\naccuracy and investigator preference for broadly effective therapeutics. A\nBayesian hierarchical model is proposed to adaptively borrow information across\nindications and enhance the accuracy in the estimation of the OBS. The\noperating characteristics of SIMBA are assessed via simulations and compared\nagainst a simplified version and an existing alternative method, both of which\ndo not borrow information. SIMBA is expected to improve the identification of\npatient sub-populations that may benefit from a biomarker-driven therapeutics.",
    "pdf_url": "http://arxiv.org/pdf/2505.13202v1",
    "published": "2025-05-19T14:54:28+00:00",
    "categories": [
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13201v1",
    "title": "MatPredict: a dataset and benchmark for learning material properties of diverse indoor objects",
    "authors": [
      "Yuzhen Chen",
      "Hojun Son",
      "Arpan Kusari"
    ],
    "abstract": "Determining material properties from camera images can expand the ability to\nidentify complex objects in indoor environments, which is valuable for consumer\nrobotics applications. To support this, we introduce MatPredict, a dataset that\ncombines the high-quality synthetic objects from Replica dataset with MatSynth\ndataset's material properties classes - to create objects with diverse material\nproperties. We select 3D meshes of specific foreground objects and render them\nwith different material properties. In total, we generate \\textbf{18} commonly\noccurring objects with \\textbf{14} different materials. We showcase how we\nprovide variability in terms of lighting and camera placement for these\nobjects. Next, we provide a benchmark for inferring material properties from\nvisual images using these perturbed models in the scene, discussing the\nspecific neural network models involved and their performance based on\ndifferent image comparison metrics. By accurately simulating light interactions\nwith different materials, we can enhance realism, which is crucial for training\nmodels effectively through large-scale simulations. This research aims to\nrevolutionize perception in consumer robotics. The dataset is provided\n\\href{https://huggingface.co/datasets/UMTRI/MatPredict}{here} and the code is\nprovided \\href{https://github.com/arpan-kusari/MatPredict}{here}.",
    "pdf_url": "http://arxiv.org/pdf/2505.13201v1",
    "published": "2025-05-19T14:54:04+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13200v2",
    "title": "Quantum Kinetic Uncertainty Relations in Mesoscopic Conductors at Strong Coupling",
    "authors": [
      "Gianmichele Blasi",
      "Ricard Ravell Rodr√≠guez",
      "Mykhailo Moskalets",
      "Rosa L√≥pez",
      "G√©raldine Haack"
    ],
    "abstract": "Kinetic Uncertainty Relations (KURs) establish quantum transport precision\nlimits by linking signal-to-noise ratio (SNR) to the system's dynamical\nactivity, valid in the weak-coupling regime where particle-like transport\ndominates. At strong coupling, quantum coherence challenges the validity of\nKURs and questions the meaning of the concept of activity itself. Here, we\nintroduce a generalized dynamical activity valid at arbitrary coupling and\nderive a steady-state quantum KUR (QKUR) expressed in terms of this generalized\nactivity. Explicit expressions are obtained within Green's function and\nLandauer-B\\\"uttiker formalisms. This QKUR ensures that uncertainty relations\nare valid across all coupling strengths, offering a general framework for\nout-of-equilibrium quantum transport precision analysis. We illustrate these\nconcepts for paradigmatic quantum-coherent mesoscopic devices: a single quantum\nchannel pinched by a quantum point contact and open single- and double-quantum\ndot systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13200v2",
    "published": "2025-05-19T14:52:23+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.stat-mech",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.13199v1",
    "title": "On some classes of bivalent and trivalent planar graphs",
    "authors": [
      "Jorge Alencar",
      "Jean-Guy Caputo",
      "Leonardo de Lima",
      "Arnaud Knippel"
    ],
    "abstract": "A graph is called bivalent or trivalent if there exists an eigenvector of the\ngraph Laplacian composed from {-1,1} or {-1,0,1}, respectively. These bivalent\nand trivalent eigenvectors are important for engineering applications, in\nparticular for vibrating systems. In this article, we determine the structure\nof bivalent and trivalent graphs in the following planar graph families: trees,\nunicyclic, bicyclic, and cactus.",
    "pdf_url": "http://arxiv.org/pdf/2505.13199v1",
    "published": "2025-05-19T14:52:04+00:00",
    "categories": [
      "math.CO",
      "math-ph",
      "math.MP",
      "math.SP"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13198v3",
    "title": "Ultrafast Electron Temperature Dynamics in Spintronic Terahertz Emitters Studied by Optical-Pump Terahertz-Probe Spectroscopy",
    "authors": [
      "Felix Selz",
      "Johanna K√∂lbel",
      "Felix Paries",
      "Georg von Freymann",
      "Daniel Molter",
      "Daniel M. Mittleman"
    ],
    "abstract": "Spintronic terahertz emitters (STEs) pumped by femtosecond lasers have become\na widely used source of broadband terahertz radiation. However, the strength of\nthe emitted field is limited in part by the optical damage threshold at the\npump wavelength. Thermal management of STEs can be improved by understanding\nelectron temperature relaxation in the spintronic metal layer. Here, we present\na measurement of electron temperature dynamics on a picosecond timescale using\noptical-pump terahertz-probe spectroscopy. We observe that the optical pump\ninduces a change in terahertz transmission through the STE. By analyzing the\nresulting signal with a two-temperature model, we extract the dynamic electron\ntemperature of the STE. This approach offers an advantage over other methods by\navoiding additional heating of the sample by the probe pulse, making it\nparticularly suitable for studying cumulative heating effects, which are\nbelieved to contribute to optical damage under MHz repetition rate pumping.",
    "pdf_url": "http://arxiv.org/pdf/2505.13198v3",
    "published": "2025-05-19T14:51:55+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.13197v2",
    "title": "Inferring stochastic dynamics with growth from cross-sectional data",
    "authors": [
      "Stephen Zhang",
      "Suryanarayana Maddu",
      "Xiaojie Qiu",
      "Victor Chard√®s"
    ],
    "abstract": "Time-resolved single-cell omics data offers high-throughput, genome-wide\nmeasurements of cellular states, which are instrumental to reverse-engineer the\nprocesses underpinning cell fate. Such technologies are inherently destructive,\nallowing only cross-sectional measurements of the underlying stochastic\ndynamical system. Furthermore, cells may divide or die in addition to changing\ntheir molecular state. Collectively these present a major challenge to\ninferring realistic biophysical models. We present a novel approach,\n\\emph{unbalanced} probability flow inference, that addresses this challenge for\nbiological processes modelled as stochastic dynamics with growth. By leveraging\na Lagrangian formulation of the Fokker-Planck equation, our method accurately\ndisentangles drift from intrinsic noise and growth. We showcase the\napplicability of our approach through evaluation on a range of simulated and\nreal single-cell RNA-seq datasets. Comparing to several existing methods, we\nfind our method achieves higher accuracy while enjoying a simple two-step\ntraining scheme.",
    "pdf_url": "http://arxiv.org/pdf/2505.13197v2",
    "published": "2025-05-19T14:51:47+00:00",
    "categories": [
      "cs.LG",
      "physics.bio-ph",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13196v1",
    "title": "A Physics-Inspired Optimizer: Velocity Regularized Adam",
    "authors": [
      "Pranav Vaidhyanathan",
      "Lucas Schorling",
      "Natalia Ares",
      "Michael A. Osborne"
    ],
    "abstract": "We introduce Velocity-Regularized Adam (VRAdam), a physics-inspired optimizer\nfor training deep neural networks that draws on ideas from quartic terms for\nkinetic energy with its stabilizing effects on various system dynamics.\nPrevious algorithms, including the ubiquitous Adam, operate at the so called\nadaptive edge of stability regime during training leading to rapid oscillations\nand slowed convergence of loss. However, VRAdam adds a higher order penalty on\nthe learning rate based on the velocity such that the algorithm automatically\nslows down whenever weight updates become large. In practice, we observe that\nthe effective dynamic learning rate shrinks in high-velocity regimes, damping\noscillations and allowing for a more aggressive base step size when necessary\nwithout divergence. By combining this velocity-based regularizer for global\ndamping with per-parameter scaling of Adam to create a hybrid optimizer, we\ndemonstrate that VRAdam consistently exceeds the performance against standard\noptimizers including AdamW. We benchmark various tasks such as image\nclassification, language modeling, image generation and generative modeling\nusing diverse architectures and training methodologies including Convolutional\nNeural Networks (CNNs), Transformers, and GFlowNets.",
    "pdf_url": "http://arxiv.org/pdf/2505.13196v1",
    "published": "2025-05-19T14:51:40+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13195v1",
    "title": "Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities",
    "authors": [
      "Lili Zhang",
      "Haomiaomiao Wang",
      "Long Cheng",
      "Libao Deng",
      "Tomas Ward"
    ],
    "abstract": "As Large Language Models (LLMs) become increasingly integrated into\nreal-world decision-making systems, understanding their behavioural\nvulnerabilities remains a critical challenge for AI safety and alignment. While\nexisting evaluation metrics focus primarily on reasoning accuracy or factual\ncorrectness, they often overlook whether LLMs are robust to adversarial\nmanipulation or capable of using adaptive strategy in dynamic environments.\nThis paper introduces an adversarial evaluation framework designed to\nsystematically stress-test the decision-making processes of LLMs under\ninteractive and adversarial conditions. Drawing on methodologies from cognitive\npsychology and game theory, our framework probes how models respond in two\ncanonical tasks: the two-armed bandit task and the Multi-Round Trust Task.\nThese tasks capture key aspects of exploration-exploitation trade-offs, social\ncooperation, and strategic flexibility. We apply this framework to several\nstate-of-the-art LLMs, including GPT-3.5, GPT-4, Gemini-1.5, and DeepSeek-V3,\nrevealing model-specific susceptibilities to manipulation and rigidity in\nstrategy adaptation. Our findings highlight distinct behavioral patterns across\nmodels and emphasize the importance of adaptability and fairness recognition\nfor trustworthy AI deployment. Rather than offering a performance benchmark,\nthis work proposes a methodology for diagnosing decision-making weaknesses in\nLLM-based agents, providing actionable insights for alignment and safety\nresearch.",
    "pdf_url": "http://arxiv.org/pdf/2505.13195v1",
    "published": "2025-05-19T14:50:44+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13194v2",
    "title": "Finite $N$ Bulk Hilbert Space in ETH Matrix Model for double-scaled SYK",
    "authors": [
      "Masamichi Miyaji",
      "Soichiro Mori",
      "Kazumi Okuyama"
    ],
    "abstract": "We extend the notion of chord number in the strict large $N$ double-scaled\nSachdev-Ye-Kitaev (DSSYK) model to the corresponding finite $N$ ETH matrix\nmodel. The chord number in the strict large $N$ DSSYK model is known to\ncorrespond to the discrete length of the Einstein-Rosen bridge in the gravity\ndual, which reduces to the renormalized geodesic length in JT gravity at weak\ncoupling. At finite $N$, these chord number states form an over-complete basis\nof the non-perturbative Hilbert space, as the structure of the inner product\ngets significantly modified due to the Cayley-Hamilton theorem: There are\ninfinitely many null states. In this paper, by considering ``EFT for\ngravitational observables'' or a version of ``non-isometric code'', we\nconstruct a family of chord number operators at finite $N$. While the\nconstructed chord number operator depends on the reference chord number state,\nit realizes approximate $q$-deformed oscillator algebra and reproduces\nsemiclassical bulk geometry around the reference state. As a special case, we\nwill show that when the reference is chosen to be the chord number zero state,\nthe chord number operator precisely matches with the Krylov state complexity,\nleading to the ``ramp-slope-plateau'' behavior at late times, implying the\nformation of ``gray hole''.",
    "pdf_url": "http://arxiv.org/pdf/2505.13194v2",
    "published": "2025-05-19T14:49:22+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13193v1",
    "title": "Singularity of the spectrum of typical minimal smooth area-preserving flows in any genus",
    "authors": [
      "Krzysztof FrƒÖczek",
      "Adam Kanigowski",
      "Corinna Ulcigrai"
    ],
    "abstract": "We consider smooth flows preserving a smooth invariant measure, or,\nequivalently, locally Hamiltonian flows on compact orientable surfaces and show\nthat almost every such locally Hamiltonian flow with only simple saddles has\nsingular spectrum. Furthermore, we prove that almost every pair of such flows\nis spectrally disjoint. More in general, singularity of the spectrum and\npairwise disjointness holds for special flows over a full measure set of\ninterval exchange transformations under a roof with symmetric logarithmic\nsingularities. The spectral result is proved using a criterion for singularity\nbased on tightness of Birkhoff sums with exponential tails decay and the\ncancellations proved by the last author to prove absence of mixing in this\nclass of flows, by showing that the latter can be combined with rigidity.\nDisjointness of pairs then follows by producing mixing times (for the second\nflow), using a new mechanism for shearing based on resonant rigidity times.",
    "pdf_url": "http://arxiv.org/pdf/2505.13193v1",
    "published": "2025-05-19T14:49:13+00:00",
    "categories": [
      "math.DS",
      "math-ph",
      "math.MP",
      "37A10, 37E35, 37A30, 37C10, 37D40, 37F30, 37N05"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13192v1",
    "title": "True Zero-Shot Inference of Dynamical Systems Preserving Long-Term Statistics",
    "authors": [
      "Christoph J√ºrgen Hemmer",
      "Daniel Durstewitz"
    ],
    "abstract": "Complex, temporally evolving phenomena, from climate to brain activity, are\ngoverned by dynamical systems (DS). DS reconstruction (DSR) seeks to infer\ngenerative surrogate models of these from observed data, reproducing their\nlong-term behavior. Existing DSR approaches require purpose-training for any\nnew system observed, lacking the zero-shot and in-context inference\ncapabilities known from LLMs. Here we introduce DynaMix, a novel multivariate\nALRNN-based mixture-of-experts architecture pre-trained for DSR, the first DSR\nmodel able to generalize zero-shot to out-of-domain DS. Just from a provided\ncontext signal, without any re-training, DynaMix faithfully forecasts the\nlong-term evolution of novel DS where existing time series (TS) foundation\nmodels, like Chronos, fail -- at a fraction of the number of parameters and\norders of magnitude faster inference times. DynaMix outperforms TS foundation\nmodels in terms of long-term statistics, and often also short-term forecasts,\neven on real-world time series, like traffic or weather data, typically used\nfor training and evaluating TS models, but not at all part of DynaMix' training\ncorpus. We illustrate some of the failure modes of TS models for DSR problems,\nand conclude that models built on DS principles may bear a huge potential also\nfor advancing the TS prediction field.",
    "pdf_url": "http://arxiv.org/pdf/2505.13192v1",
    "published": "2025-05-19T14:49:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS",
      "nlin.CD"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13191v1",
    "title": "Emergence of Fixational and Saccadic Movements in a Multi-Level Recurrent Attention Model for Vision",
    "authors": [
      "Pengcheng Pan",
      "Yonekura Shogo",
      "Yasuo Kuniyoshi"
    ],
    "abstract": "Inspired by foveal vision, hard attention models promise interpretability and\nparameter economy. However, existing models like the Recurrent Model of Visual\nAttention (RAM) and Deep Recurrent Attention Model (DRAM) failed to model the\nhierarchy of human vision system, that compromise on the visual exploration\ndynamics. As a result, they tend to produce attention that are either overly\nfixational or excessively saccadic, diverging from human eye movement behavior.\nIn this paper, we propose a Multi-Level Recurrent Attention Model (MRAM), a\nnovel hard attention framework that explicitly models the neural hierarchy of\nhuman visual processing. By decoupling the function of glimpse location\ngeneration and task execution in two recurrent layers, MRAM emergent a balanced\nbehavior between fixation and saccadic movement. Our results show that MRAM not\nonly achieves more human-like attention dynamics, but also consistently\noutperforms CNN, RAM and DRAM baselines on standard image classification\nbenchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13191v1",
    "published": "2025-05-19T14:48:36+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13190v1",
    "title": "Combinatorial Sample-and Back-Focal-Plane (BFP) Imaging. Pt. I: Instrument and acquisition parameters affecting BFP images and their analysis",
    "authors": [
      "Omer Shavit",
      "Herv√© Suaudeau",
      "Carine Julien",
      "Hodaya Klimovsky",
      "Natalia Ma√±as-Chavernas",
      "Adi Salomon",
      "Martin Oheim"
    ],
    "abstract": "The back-focal plane (BFP) of a high-numerical aperture objective contains\nthe fluoro-phore radiation pattern, which encodes information about the axial\nfluorophore position, molecular orientation and the local refractive index of\nthe embedding medium. BFP image acquisition and analysis are common to\nconoscopy, k-space imaging, supercritical-angle fluorescence (SAF) and\nsingle-molecule detection, but they are rarely being used in biological\nfluorescence. This work addresses a critical gap in quantitative microscopy by\nenabling reliable, real-time BFP imaging under low-light conditions and/or\nshort exposure times, typical of biological experiments. By systematically\nanalyzing how key parameters - such as Bertrand lens position, defocus, pixel\nsize, and binning - affect BFP image quality and SAF/UAF ratios, we provide a\nrobust framework for accurate axial fluorophore localization and near-membrane\nrefractive-index measurements. The described hardware- and software integration\nallows for multi-dimensional image-series and online quality control, reducing\nexperimental error and enhancing reproducibility. Our contributions lay the\nfoundation for standardized BFP imaging across laboratories, expanding its\napplication to dynamic biological systems, and opening the door to machine\nlearning-based analysis pipelines. Ultimately, this work transforms BFP imaging\nfrom an expert-dependent technique into a reproducible and scalable tool for\nsurface-sensitive fluorescence microscopy.",
    "pdf_url": "http://arxiv.org/pdf/2505.13190v1",
    "published": "2025-05-19T14:46:24+00:00",
    "categories": [
      "physics.optics",
      "q-bio.QM"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.13189v1",
    "title": "A Malliavin-Gamma calculus approach to Score Based Diffusion Generative models for random fields",
    "authors": [
      "Giacomo Greco"
    ],
    "abstract": "We adopt a Gamma and Malliavin Calculi point of view in order to generalize\nScore-based diffusion Generative Models (SGMs) to an infinite-dimensional\nabstract Hilbertian setting. Particularly, we define the forward noising\nprocess using Dirichlet forms associated to the Cameron-Martin space of\nGaussian measures and Wiener chaoses; whereas by relying on an abstract\ntime-reversal formula, we show that the score function is a Malliavin\nderivative and it corresponds to a conditional expectation. This allows us to\ngeneralize SGMs to the infinite-dimensional setting. Moreover, we extend\nexisting finite-dimensional entropic convergence bounds to this Hilbertian\nsetting by highlighting the role played by the Cameron-Martin norm in the\nFisher information of the data distribution. Lastly, we specify our discussion\nfor spherical random fields, considering as source of noise a Whittle-Mat\\'ern\nrandom spherical field.",
    "pdf_url": "http://arxiv.org/pdf/2505.13189v1",
    "published": "2025-05-19T14:46:04+00:00",
    "categories": [
      "math.PR",
      "cs.LG",
      "stat.ML",
      "62D05, 60G60, 60J46, 60H07, 60H30"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13188v2",
    "title": "When a Reinforcement Learning Agent Encounters Unknown Unknowns",
    "authors": [
      "Juntian Zhu",
      "Miguel de Carvalho",
      "Zhouwang Yang",
      "Fengxiang He"
    ],
    "abstract": "An AI agent might surprisingly find she has reached an unknown state which\nshe has never been aware of -- an unknown unknown. We mathematically ground\nthis scenario in reinforcement learning: an agent, after taking an action\ncalculated from value functions $Q$ and $V$ defined on the {\\it {aware\ndomain}}, reaches a state out of the domain. To enable the agent to handle this\nscenario, we propose an {\\it episodic Markov decision {process} with growing\nawareness} (EMDP-GA) model, taking a new {\\it noninformative value expansion}\n(NIVE) approach to expand value functions to newly aware areas: when an agent\narrives at an unknown unknown, value functions $Q$ and $V$ whereon are\ninitialised by noninformative beliefs -- the averaged values on the aware\ndomain. This design is out of respect for the complete absence of knowledge in\nthe newly discovered state. The upper confidence bound momentum Q-learning is\nthen adapted to the growing awareness for training the EMDP-GA model. We prove\nthat (1) the regret of our approach is asymptotically consistent with the state\nof the art (SOTA) without exposure to unknown unknowns in an extremely\nuncertain environment, and (2) our computational complexity and space\ncomplexity are comparable with the SOTA -- these collectively suggest that\nthough an unknown unknown is surprising, it will be asymptotically properly\ndiscovered with decent speed and an affordable cost.",
    "pdf_url": "http://arxiv.org/pdf/2505.13188v2",
    "published": "2025-05-19T14:45:58+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13187v1",
    "title": "Plane sextics and a nonspecial divisor in the moduli space of cubic fourfolds",
    "authors": [
      "Elena Sammarco"
    ],
    "abstract": "We show that the property of admitting a net of polar quadrics with\ndiscriminant locus a plane sextic curve with at least 10 nodes is nongeneral\nfor a cubic fourfold. In particular, we study cubic fourfolds having a polar\nnet with an irreducible 10-nodal discriminant curve. They form a divisor in the\nmoduli space of cubic fourfolds which we prove is not a Noether-Lefschetz\ndivisor.",
    "pdf_url": "http://arxiv.org/pdf/2505.13187v1",
    "published": "2025-05-19T14:44:35+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13186v1",
    "title": "Interpretable Robotic Friction Learning via Symbolic Regression",
    "authors": [
      "Philipp Scholl",
      "Alexander Dietrich",
      "Sebastian Wolf",
      "Jinoh Lee",
      "Alin-Albu Sch√§ffer",
      "Gitta Kutyniok",
      "Maged Iskandar"
    ],
    "abstract": "Accurately modeling the friction torque in robotic joints has long been\nchallenging due to the request for a robust mathematical description.\nTraditional model-based approaches are often labor-intensive, requiring\nextensive experiments and expert knowledge, and they are difficult to adapt to\nnew scenarios and dependencies. On the other hand, data-driven methods based on\nneural networks are easier to implement but often lack robustness,\ninterpretability, and trustworthiness--key considerations for robotic hardware\nand safety-critical applications such as human-robot interaction. To address\nthe limitations of both approaches, we propose the use of symbolic regression\n(SR) to estimate the friction torque. SR generates interpretable symbolic\nformulas similar to those produced by model-based methods while being flexible\nto accommodate various dynamic effects and dependencies. In this work, we apply\nSR algorithms to approximate the friction torque using collected data from a\nKUKA LWR-IV+ robot. Our results show that SR not only yields formulas with\ncomparable complexity to model-based approaches but also achieves higher\naccuracy. Moreover, SR-derived formulas can be seamlessly extended to include\nload dependencies and other dynamic factors.",
    "pdf_url": "http://arxiv.org/pdf/2505.13186v1",
    "published": "2025-05-19T14:44:02+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13185v2",
    "title": "Filtering in a hazard rate change-point model with financial and life-insurance applications",
    "authors": [
      "Matteo Buttarazzi",
      "Claudia Ceci"
    ],
    "abstract": "This paper develops a continuous-time filtering framework for estimating a\nhazard rate subject to an unobservable change-point. This framework arises\nnaturally in both financial and insurance applications, where the default\nintensity of a firm or the mortality rate of an individual may experience a\nsudden jump at an unobservable time, representing, for instance, a shift in the\nfirm's risk profile or a deterioration in an individual's health status. By\nemploying a progressive enlargement of filtration, we integrate noisy\nobservations of the hazard rate with default-related information. We\ncharacterise the filter, i.e. the conditional probability of the change-point\ngiven the information flow, as the unique strong solution to a stochastic\ndifferential equation driven by the innovation process enriched with the\ndiscontinuous component. A sensitivity analysis and a comparison of the\nfilter's behaviour under various information structures are provided. Our\nframework further allows for the derivation of an explicit formula for the\nsurvival probability conditional on partial information. This result applies to\nthe pricing of credit-sensitive financial instruments such as defaultable\nbonds, credit default swaps, and life insurance contracts. Finally, a numerical\nanalysis illustrates how partial information leads to delayed adjustments in\nthe estimation of the hazard rate and consequently to mispricing of\ncredit-sensitive instruments when compared to a full-information setting.",
    "pdf_url": "http://arxiv.org/pdf/2505.13185v2",
    "published": "2025-05-19T14:41:52+00:00",
    "categories": [
      "q-fin.MF",
      "math.PR",
      "q-fin.PR",
      "60G35, 91G40, 91G05, 60G55"
    ],
    "primary_category": "q-fin.MF"
  },
  {
    "id": "http://arxiv.org/abs/2505.13184v1",
    "title": "Repeated quantum backflow and overflow",
    "authors": [
      "Christopher J. Fewster",
      "Harkan J. Kirk-Karakaya"
    ],
    "abstract": "Quantum backflow is a surprising phenomenon in which a quantum particle,\nmoving in one dimension and with a state of rightwards momentum, can exhibit a\nnet probability transfer to the left-hand half-line over a finite time\ninterval. We generalise the setting of quantum backflow to allow for $M$\ndisjoint time intervals, considering the sum of probability differences for\neach interval. In classical statistical particle mechanics, the total backflow\nlies in the interval $[-1,0]$ for all $M$, indicating rightwards probability\ntransfer. By contrast, we show that, in quantum mechanics, the maximum $M$-fold\nbackflow is positive and unbounded from above as $M$ increases, demonstrating\nthat there are states that exhibit repeated periods of backflow.\n  Moreover, for $M\\ge 2$, we discover a new phenomenon; namely, that there are\nstates whose total backflow is below $-1$, giving a probability transfer to the\nright-hand half-line beyond that possible in classical statistical particle\nmechanics. We call this effect \"quantum overflow\". The maximum extent of the\nbackflow and overflow effects is described by a hierarchy of backflow and\noverflow functions and constants, where the $M$'th backflow (overflow) constant\nis the supremum (infimum) of the $M$'th backflow (overflow) function. The $M=1$\nbackflow constant was first identified by Bracken and Melloy.\n  Our results are obtained by formulating the $M$-fold backflow problem in\nterms of the spectra of suitable bounded operators. Using this formulation, we\nalso study limiting cases of the backflow and overflow functions, including\ncases in which two disjoint intervals merge. Our analytical results are\nsupported by detailed numerical investigations. Among other things, by applying\nnumerical acceleration methods, we obtain a new estimate of the Bracken-Melloy\nconstant of $0.0384506$ which is slightly lower than the previously accepted\nvalue of $0.038452$.",
    "pdf_url": "http://arxiv.org/pdf/2505.13184v1",
    "published": "2025-05-19T14:40:15+00:00",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01997v1",
    "title": "NELM: Modern Open-Source Software for Multipurpose Impedance Spectra Analysis",
    "authors": [
      "Natalia A. Boitsova",
      "Anna A. Abelit",
      "Daniil D. Stupin"
    ],
    "abstract": "Nowadays electrical impedance spectroscopy (EIS) has become an advanced\nexperimental technique with a wide range of applications: from simple passive\ncircuits diagnostics to semiconductor high-end device development and\nbreakthrough technologies in bio-sensing. Although hardware for EIS today is\nwell developed, the EIS analysis software is mainly custom, old fashioned, i.e.\nit is limited by features, does not utilize the progress in the modern computer\nscience and hardware, and is usually implemented in close-source code or\nwritten on outdated programming languages, which causes slow progress in field\nof the EIS and complicates researchers attempts of development in EIS\nautonomous devices, such as implants. In this article, we introduce a free and\nopen-sourced MatLab/GNU Octave package for EIS analysis called NELM, which\nprovides powerful equipment tools for matching experimental impedance data with\ntheoretical equivalent circuits. Our software has an user friendly interface\nand supports different formats of input data, fitting programs, and impedance\nmodels. In addition, we have developed NELM with implementation of the latest\nprogress in computation science such as symbolic calculations, parallel\ncomputing, and artificial intelligence. The abilities of NELM were validated by\nits applications in the different fields of science, such as semiconductor\nstudies, bioimpedance and electrochemestry, which demonstrated high-efficiency\nof the proposed software package and showed that it is a promising tool for\nsolving actual problems in electronic industry, biosensorics, and healthcare\ntechnologies.",
    "pdf_url": "http://arxiv.org/pdf/2506.01997v1",
    "published": "2025-05-19T14:39:55+00:00",
    "categories": [
      "physics.app-ph",
      "physics.comp-ph",
      "physics.data-an"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13183v1",
    "title": "Fully Differential Soft Gluon Evolution at the Amplitude Level",
    "authors": [
      "Jeffrey R. Forshaw",
      "Simon Pl√§tzer",
      "Fernando Torre Gonz√°lez"
    ],
    "abstract": "We study differential intra-jet radiation patterns in jet production at full\ncolour. We present a systematic study of several QCD $2\\to 2$ processes and\nalso multi-jet production from a colourless initial state. We examine how\nsubleading colour corrections are distributed differentially in phase space and\nfind that mere normalization effects due to subleading colour can be due to\nsubtle cancellations across phase space. In general, we find that subleading\ncolour does affect the shapes of distributions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13183v1",
    "published": "2025-05-19T14:39:53+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13182v9",
    "title": "Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping",
    "authors": [
      "Jianfeng Xu"
    ],
    "abstract": "[Objective] This study addresses key challenges in machine learning, namely\nthe absence of a unified formal theoretical framework and the lack of\nfoundational theories for model interpretability and ethical safety. [Methods]\nWe first construct a formal information model, explicitly defining the\nontological states and carrier mappings of typical machine learning stages\nusing sets of well-formed formulas. By introducing learnable and processable\npredicates, as well as learning and processing functions, we analyze the causal\nchain logic and constraint laws governing machine learning processes. [Results]\nWe establish the Machine Learning Theory Meta-Framework (MLT-MF), on which we\nfurther propose universal definitions for model interpretability and ethical\nsafety. We prove and validate three key theorems: the relationship between\nmodel interpretability and information existence, ethical safety assurance, and\nthe upper bound estimation of total variation distance (TVD). [Limitations] The\ncurrent framework assumes ideal, noise-free information enabling mappings and\nfocuses primarily on model learning and processing logic in static scenarios.\nIt does not yet address information fusion and conflict resolution across\nontological spaces in multimodal or multi-agent systems. [Conclusions] This\nwork overcomes the limitations of fragmented research and provides a unified\ntheoretical foundation for systematically addressing critical issues in\ncontemporary machine learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.13182v9",
    "published": "2025-05-19T14:39:41+00:00",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13181v1",
    "title": "Efficient Speech Language Modeling via Energy Distance in Continuous Latent Space",
    "authors": [
      "Zhengrui Ma",
      "Yang Feng",
      "Chenze Shao",
      "Fandong Meng",
      "Jie Zhou",
      "Min Zhang"
    ],
    "abstract": "We introduce SLED, an alternative approach to speech language modeling by\nencoding speech waveforms into sequences of continuous latent representations\nand modeling them autoregressively using an energy distance objective. The\nenergy distance offers an analytical measure of the distributional gap by\ncontrasting simulated and target samples, enabling efficient training to\ncapture the underlying continuous autoregressive distribution. By bypassing\nreliance on residual vector quantization, SLED avoids discretization errors and\neliminates the need for the complicated hierarchical architectures common in\nexisting speech language models. It simplifies the overall modeling pipeline\nwhile preserving the richness of speech information and maintaining inference\nefficiency. Empirical results demonstrate that SLED achieves strong performance\nin both zero-shot and streaming speech synthesis, showing its potential for\nbroader applications in general-purpose speech language models.",
    "pdf_url": "http://arxiv.org/pdf/2505.13181v1",
    "published": "2025-05-19T14:38:59+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13180v1",
    "title": "ViPlan: A Benchmark for Visual Planning with Symbolic Predicates and Vision-Language Models",
    "authors": [
      "Matteo Merler",
      "Nicola Dainese",
      "Minttu Alakuijala",
      "Giovanni Bonetta",
      "Pietro Ferrazzi",
      "Yu Tian",
      "Bernardo Magnini",
      "Pekka Marttinen"
    ],
    "abstract": "Integrating Large Language Models with symbolic planners is a promising\ndirection for obtaining verifiable and grounded plans compared to planning in\nnatural language, with recent works extending this idea to visual domains using\nVision-Language Models (VLMs). However, rigorous comparison between\nVLM-grounded symbolic approaches and methods that plan directly with a VLM has\nbeen hindered by a lack of common environments, evaluation protocols and model\ncoverage. We introduce ViPlan, the first open-source benchmark for Visual\nPlanning with symbolic predicates and VLMs. ViPlan features a series of\nincreasingly challenging tasks in two domains: a visual variant of the classic\nBlocksworld planning problem and a simulated household robotics environment. We\nbenchmark nine open-source VLM families across multiple sizes, along with\nselected closed models, evaluating both VLM-grounded symbolic planning and\nusing the models directly to propose actions. We find symbolic planning to\noutperform direct VLM planning in Blocksworld, where accurate image grounding\nis crucial, whereas the opposite is true in the household robotics tasks, where\ncommonsense knowledge and the ability to recover from errors are beneficial.\nFinally, we show that across most models and methods, there is no significant\nbenefit to using Chain-of-Thought prompting, suggesting that current VLMs still\nstruggle with visual reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.13180v1",
    "published": "2025-05-19T14:38:15+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13179v1",
    "title": "Lattice thermal conductivity of 16 elemental metals from molecular dynamics simulations with a unified neuroevolution potential",
    "authors": [
      "Shuo Cao",
      "Ao Wang",
      "Zheyong Fan",
      "Hua Bao",
      "Ping Qian",
      "Ye Su",
      "Yu Yan"
    ],
    "abstract": "Metals play a crucial role in heat management in electronic devices, such as\nintegrated circuits, making it vital to understand heat transport in elementary\nmetals and alloys. In this work, we systematically study phonon thermal\ntransport in 16 metals using the efficient homogeneous nonequilibrium molecular\ndynamics (HNEMD) method and the recently developed unified neuroevolution\npotential version 1 (UNEP-v1) for 16 metals and their alloys. We compare our\nresults with existing ones based on the Boltzmann transport equation (BTE)\napproach and find that our HNEMD results align well with BTE results obtained\nby considering phonon-phonon scattering only. By contrast, HNEMD results based\non the conventional embedded-atom method potential show less satisfactory\nagreement with BTE ones. Given the high accuracy of the UNEP-v1 model\ndemonstrated in various metal alloys, we anticipate that the HNEMD method\ncombined with the UNEP-v1 model will be a promising tool for exploring phonon\nthermal transport properties in complex systems such as high-entropy alloys.",
    "pdf_url": "http://arxiv.org/pdf/2505.13179v1",
    "published": "2025-05-19T14:35:00+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.13178v2",
    "title": "On the stability analysis of astrophysical cooling functions",
    "authors": [
      "Amanda Stricklan",
      "Tim Waters",
      "James Klimchuk"
    ],
    "abstract": "To model the temperature evolution of optically thin astrophysical\nenvironments at MHD scales, radiative and collisional cooling rates are\ntypically either pre-tabulated or fit into a functional form and then input\ninto MHD codes as a radiative loss function. Thermal balance requires estimates\nof the analogous heating rates, which are harder to calculate, and due to\nuncertainties in the underlying dissipative heating processes, these rates are\noften simply parameterized. The resulting net cooling function defines an\nequilibrium curve that varies with density and temperature. Such cooling\nfunctions can make the gas prone to thermal instability (TI), which will cause\ndepartures from equilibrium. There has been no systematic study of thermally\nunstable parameter space for nonequilibrium states. Motivated by our recent\nfinding that there is a related linear instability, catastrophic cooling\ninstability, that can dominate over TI, here we carry out such a study. We show\nthat Balbus' instability criteria for TI can be used to define a critical\ncooling rate, $\\Lambda_c$, that permits a nonequilibrium analysis of cooling\nfunctions through the mapping of TI zones. We furthermore extend Balbus'\ncriteria to account for thermal conduction. Upon applying a $\\Lambda_c$-based\nstability analysis to coronal loop simulations, we find that loops undergoing\nperiodic episodes of coronal rain formation are linearly unstable to\ncatastrophic cooling instability, while TI is stabilized by thermal conduction.",
    "pdf_url": "http://arxiv.org/pdf/2505.13178v2",
    "published": "2025-05-19T14:32:56+00:00",
    "categories": [
      "astro-ph.SR",
      "physics.plasm-ph"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13177v1",
    "title": "Parametric Stability Analysis for Circuit Quantum Electrodynamical Hardwares",
    "authors": [
      "Maria Gabriela Boada",
      "Andrea Delgado",
      "Jose Morales Escalante"
    ],
    "abstract": "The transmon qubit, essential to quantum computation, exhibits disordered\ndynamics under strong parametric drives critical to its control. We present a\ncombined theoretical and numerical study of stability regions in circuit QED\nusing Floquet theory, focusing on the appearance of Arnold tongues that\ndistinguish stable from unstable regimes. Starting from simple Josephson\ncircuits and progressing to full multimode qubit-cavity systems, we show how\ntime-dependent modulation maps the dynamics to Mathieu-type equations,\nrevealing thresholds for parametric resonances. Perturbative corrections\ncapture effects like higher harmonics and weak nonlinearities. Simulations\nvalidate these predictions and expose sensitivity to fabrication parameters.\nThese findings inform thresholds for readout fidelity, amplifier gain, and\nmulti-qubit gate stability.",
    "pdf_url": "http://arxiv.org/pdf/2505.13177v1",
    "published": "2025-05-19T14:31:46+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13176v2",
    "title": "ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models",
    "authors": [
      "Zihao Cheng",
      "Hongru Wang",
      "Zeming Liu",
      "Yuhang Guo",
      "Yuanfang Guo",
      "Yunhong Wang",
      "Haifeng Wang"
    ],
    "abstract": "While integrating external tools into large language models (LLMs) enhances\ntheir ability to access real-time information and domain-specific services,\nexisting approaches focus narrowly on functional tool selection following user\ninstructions, overlooking the context-aware personalization in tool selection.\nThis oversight leads to suboptimal user satisfaction and inefficient tool\nutilization, particularly when overlapping toolsets require nuanced selection\nbased on contextual factors. To bridge this gap, we introduce ToolSpectrum, a\nbenchmark designed to evaluate LLMs' capabilities in personalized tool\nutilization. Specifically, we formalize two key dimensions of personalization,\nuser profile and environmental factors, and analyze their individual and\nsynergistic impacts on tool utilization. Through extensive experiments on\nToolSpectrum, we demonstrate that personalized tool utilization significantly\nimproves user experience across diverse scenarios. However, even\nstate-of-the-art LLMs exhibit the limited ability to reason jointly about user\nprofiles and environmental factors, often prioritizing one dimension at the\nexpense of the other. Our findings underscore the necessity of context-aware\npersonalization in tool-augmented LLMs and reveal critical limitations for\ncurrent models. Our data and code are available at\nhttps://github.com/Chengziha0/ToolSpectrum.",
    "pdf_url": "http://arxiv.org/pdf/2505.13176v2",
    "published": "2025-05-19T14:30:46+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13175v1",
    "title": "Enhancing LLMs for Time Series Forecasting via Structure-Guided Cross-Modal Alignment",
    "authors": [
      "Siming Sun",
      "Kai Zhang",
      "Xuejun Jiang",
      "Wenchao Meng",
      "Qinmin Yang"
    ],
    "abstract": "The emerging paradigm of leveraging pretrained large language models (LLMs)\nfor time series forecasting has predominantly employed linguistic-temporal\nmodality alignment strategies through token-level or layer-wise feature\nmapping. However, these approaches fundamentally neglect a critical insight:\nthe core competency of LLMs resides not merely in processing localized token\nfeatures but in their inherent capacity to model holistic sequence structures.\nThis paper posits that effective cross-modal alignment necessitates structural\nconsistency at the sequence level. We propose the Structure-Guided Cross-Modal\nAlignment (SGCMA), a framework that fully exploits and aligns the\nstate-transition graph structures shared by time-series and linguistic data as\nsequential modalities, thereby endowing time series with language-like\nproperties and delivering stronger generalization after modality alignment.\nSGCMA consists of two key components, namely Structure Alignment and Semantic\nAlignment. In Structure Alignment, a state transition matrix is learned from\ntext data through Hidden Markov Models (HMMs), and a shallow transformer-based\nMaximum Entropy Markov Model (MEMM) receives the hot-start transition matrix\nand annotates each temporal patch into state probability, ensuring that the\ntemporal representation sequence inherits language-like sequential dynamics. In\nSemantic Alignment, cross-attention is applied between temporal patches and the\ntop-k tokens within each state, and the ultimate temporal embeddings are\nderived by the expected value of these embeddings using a weighted average\nbased on state probabilities. Experiments on multiple benchmarks demonstrate\nthat SGCMA achieves state-of-the-art performance, offering a novel approach to\ncross-modal alignment in time series forecasting.",
    "pdf_url": "http://arxiv.org/pdf/2505.13175v1",
    "published": "2025-05-19T14:30:41+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13174v1",
    "title": "FlowCut: Unsupervised Video Instance Segmentation via Temporal Mask Matching",
    "authors": [
      "Alp Eren Sari",
      "Paolo Favaro"
    ],
    "abstract": "We propose FlowCut, a simple and capable method for unsupervised video\ninstance segmentation consisting of a three-stage framework to construct a\nhigh-quality video dataset with pseudo labels. To our knowledge, our work is\nthe first attempt to curate a video dataset with pseudo-labels for unsupervised\nvideo instance segmentation. In the first stage, we generate pseudo-instance\nmasks by exploiting the affinities of features from both images and optical\nflows. In the second stage, we construct short video segments containing\nhigh-quality, consistent pseudo-instance masks by temporally matching them\nacross the frames. In the third stage, we use the YouTubeVIS-2021 video dataset\nto extract our training instance segmentation set, and then train a video\nsegmentation model. FlowCut achieves state-of-the-art performance on the\nYouTubeVIS-2019, YouTubeVIS-2021, DAVIS-2017, and DAVIS-2017 Motion benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13174v1",
    "published": "2025-05-19T14:30:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13173v2",
    "title": "A Case Study of Cross-Lingual Zero-Shot Generalization for Classical Languages in LLMs",
    "authors": [
      "V. S. D. S. Mahesh Akavarapu",
      "Hrishikesh Terdalkar",
      "Pramit Bhattacharyya",
      "Shubhangi Agarwal",
      "Vishakha Deulgaonkar",
      "Pralay Manna",
      "Chaitali Dangarikar",
      "Arnab Bhattacharya"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable generalization\ncapabilities across diverse tasks and languages. In this study, we focus on\nnatural language understanding in three classical languages -- Sanskrit,\nAncient Greek and Latin -- to investigate the factors affecting cross-lingual\nzero-shot generalization. First, we explore named entity recognition and\nmachine translation into English. While LLMs perform equal to or better than\nfine-tuned baselines on out-of-domain data, smaller models often struggle,\nespecially with niche or abstract entity types. In addition, we concentrate on\nSanskrit by presenting a factoid question-answering (QA) dataset and show that\nincorporating context via retrieval-augmented generation approach significantly\nboosts performance. In contrast, we observe pronounced performance drops for\nsmaller LLMs across these QA tasks. These results suggest model scale as an\nimportant factor influencing cross-lingual generalization. Assuming that models\nused such as GPT-4o and Llama-3.1 are not instruction fine-tuned on classical\nlanguages, our findings provide insights into how LLMs may generalize on these\nlanguages and their consequent utility in classical studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.13173v2",
    "published": "2025-05-19T14:30:10+00:00",
    "categories": [
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13172v1",
    "title": "Effective thermal conduction of a Signorini-type problem in composites with rough interface",
    "authors": [
      "Sara Monsurr√≤",
      "Carmen Perugia",
      "Federica Raimondi"
    ],
    "abstract": "We analyse the effect of a Signorini-type interface condition on the\nasymptotic behaviour, as {\\epsilon} tends to zero, of a problem posed in an\nopen bounded cylinder of {R^N}, {N\\geq 2}, divided in two connected components\nby an imperfect rough surface. The Signorini-type condition is expressed by\nmeans of two complementary equalities involving the jump of the solution on the\ninterface and its conormal derivative via a parameter {\\gamma}. Different limit\nproblems are obtained according to the values of {\\gamma} and the amplitude of\nthe interface oscillations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13172v1",
    "published": "2025-05-19T14:30:02+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13171v2",
    "title": "Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks",
    "authors": [
      "Yixuan Xu",
      "Antoni-Joan Solergibert i Llaquet",
      "Antoine Bosselut",
      "Imanol Schlag"
    ],
    "abstract": "Large language models are known to memorize parts of their training data,\nposing risk of copyright violations. To systematically examine this risk, we\npretrain language models (1B/3B/8B) from scratch on 83B tokens, mixing\nweb-scale data with public domain books used to simulate copyrighted content at\ncontrolled frequencies at lengths at least ten times longer than prior work. We\nthereby identified the offset effect, a phenomenon characterized by two key\nfindings: (1) verbatim memorization is most strongly triggered by short\nprefixes drawn from the beginning of the context window, with memorization\ndecreasing counterintuitively as prefix length increases; and (2) a sharp\ndecline in verbatim recall when prefix begins offset from the initial tokens of\nthe context window. We attribute this to positional fragility: models rely\ndisproportionately on the earliest tokens in their context window as retrieval\nanchors, making them sensitive to even slight shifts. We further observe that\nwhen the model fails to retrieve memorized content, it often produces\ndegenerated text. Leveraging these findings, we show that shifting sensitive\ndata deeper into the context window suppresses both extractable memorization\nand degeneration. Our results suggest that positional offset is a critical and\npreviously overlooked axis for evaluating memorization risks, since prior work\nimplicitly assumed uniformity by probing only from the beginning of training\nsequences.",
    "pdf_url": "http://arxiv.org/pdf/2505.13171v2",
    "published": "2025-05-19T14:28:35+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13170v2",
    "title": "Dynamics and equilibrium states of infinite systems of lattice bosons",
    "authors": [
      "Andreas Deuchert",
      "Jonas Lampart",
      "Marius Lemm"
    ],
    "abstract": "We consider the dynamics of systems of lattice bosons with infinitely many\ndegrees of freedom. We show that their dynamics defines a group of\nautomorphisms on a $C^*$--algebra introduced by Buchholz, which extends the\nresolvent algebra of local field operators. For states that admit uniform\nbounds on moments of the local particle number, we derive propagation bounds of\nLieb--Robinson type. Using these bounds, we show that the dynamics of local\nobservables gives rise to a strongly continuous unitary group in the GNS\nrepresentation. Moreover, accumulation points of finite-volume Gibbs states\nsatisfy the KMS condition with respect to this group. This, in particular,\nproves the existence of KMS states.",
    "pdf_url": "http://arxiv.org/pdf/2505.13170v2",
    "published": "2025-05-19T14:26:59+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "82C10, 82C20, 82B20, 81R15"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13169v1",
    "title": "RIFLES: Resource-effIcient Federated LEarning via Scheduling",
    "authors": [
      "Sara Alosaime",
      "Arshad Jhumka"
    ],
    "abstract": "Federated Learning (FL) is a privacy-preserving machine learning technique\nthat allows decentralized collaborative model training across a set of\ndistributed clients, by avoiding raw data exchange. A fundamental component of\nFL is the selection of a subset of clients in each round for model training by\na central server. Current selection strategies are myopic in nature in that\nthey are based on past or current interactions, often leading to inefficiency\nissues such as straggling clients. In this paper, we address this serious\nshortcoming by proposing the RIFLES approach that builds a novel availability\nforecasting layer to support the client selection process. We make the\nfollowing contributions: (i) we formalise the sequential selection problem and\nreduce it to a scheduling problem and show that the problem is NP-complete,\n(ii) leveraging heartbeat messages from clients, RIFLES build an availability\nprediction layer to support (long term) selection decisions, (iii) we propose a\nnovel adaptive selection strategy to support efficient learning and resource\nusage. To circumvent the inherent exponential complexity, we present RIFLES, a\nheuristic that leverages clients' historical availability data by using a\nCNN-LSTM time series forecasting model, allowing the server to predict the\noptimal participation times of clients, thereby enabling informed selection\ndecisions. By comparing against other FL techniques, we show that RIFLES\nprovide significant improvement by between 10%-50% on a variety of metrics such\nas accuracy and test loss. To the best of our knowledge, it is the first work\nto investigate FL as a scheduling problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.13169v1",
    "published": "2025-05-19T14:26:33+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13168v2",
    "title": "Knots that share four surgeries",
    "authors": [
      "Marc Kegel",
      "Lisa Piccirillo"
    ],
    "abstract": "Distinct knots K, K' can sometimes share a common p/q-framed Dehn surgery. A\nfolk conjecture held that for a fixed pair of knots, this can occur for at most\none value of p/q. We disprove this conjecture by constructing pairs of distinct\nknots K,K' that have common Dehn surgeries for four distinct slopes. We also\nconstruct non-isotopic Legendrian knots K,K' that have contactomorphic contact\n(+1)-and (-1)-surgeries, disproving an analogous conjecture in contact\ngeometry.",
    "pdf_url": "http://arxiv.org/pdf/2505.13168v2",
    "published": "2025-05-19T14:26:19+00:00",
    "categories": [
      "math.GT",
      "math.SG",
      "57R65, 57K10, 57R65, 57R58, 57K16, 57K14, 57K32"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13167v1",
    "title": "Spatially resolved stellar populations and emission lines properties in nearby galaxies with J-PLUS -- I. Method and first results for the M101 group",
    "authors": [
      "J. Thain√°-Batista",
      "R. Cid Fernandes",
      "R. M. Gonz√°lez Delgado",
      "J. E. Rodr√≠guez-Mart√≠n",
      "R. Garc√≠a-Benito",
      "G. Mart√≠nez-Solaeche",
      "L. A. D√≠az-Garc√≠a",
      "V. H. Sasse",
      "A. Lumbreras-Calle",
      "A. M. Conrado",
      "J. Alcaniz",
      "R. E. Angulo",
      "A. J. Cenarro",
      "D. Crist√≥bal-Hornillos",
      "R. A. Dupke",
      "A. Ederoclite",
      "C. Hern√°ndez-Monteagudo",
      "C. L√≥pez-Sanjuan",
      "A. Mar√≠n-Franch",
      "M. Moles",
      "L. Sodr√© Jr.",
      "H. V√°zquez Rami√≥",
      "J. Varela"
    ],
    "abstract": "Spatially resolved maps of stellar populations and nebular emission are key\ntools for understanding the physical properties and evolutionary stages of\ngalaxies. We aim to characterize the spatially resolved stellar population and\nemission line properties of galaxies in the M101 group using Javalambre\nPhotometric Local Universe Survey (J-PLUS) data. The datacubes first go through\npre-processing steps, which include masking, noise suppression, PSF\nhomogenization, and spatial binning. The improved data are then analyzed with\nthe spectral synthesis code \\alstar, which has been previously shown to produce\nexcellent results with the unique 12 bands filter system of J-PLUS and S-PLUS.\nWe produce maps of stellar mass surface density ($\\Sigma_\\star$), mean stellar\nage and metallicity, star formation rate surface density ($\\Sigma_{\\rm SFR}$),\ndust attenuation, and emission line properties such as fluxes and equivalent\nwidths of the main optical lines. Relations among these properties are\nexplored. All galaxies exhibit a well-defined age-$\\Sigma_\\star$ relation,\nexcept for the dwarfs. Similarly, all of the galaxies follow local\n$\\Sigma_\\star$-$\\Sigma_{\\rm SFR}$ star-forming MS relations, with specific star\nformation rates that grow for less massive systems. A stellar\n$\\Sigma_\\star$-metallicity relation is clearly present in M101, while other\ngalaxies have either flatter or undefined relations. Nebular metallicities\ncorrelate with $\\Sigma_\\star$ for all galaxies. This study demonstrates the\nability of J-PLUS to perform IFS-like analysis of galaxies, offering robust\nspatially resolved measurements of stellar populations and emission lines over\nlarge fields of view. The M101 group analysis showcases the potential for\nexpanding such studies to other groups and clusters, contributing to the\nunderstanding of galaxy evolution across different environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.13167v1",
    "published": "2025-05-19T14:26:07+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13166v1",
    "title": "The moduli space of multi-monopoles on a Riemann surface",
    "authors": [
      "Ollie Thakar"
    ],
    "abstract": "We study the moduli space of solutions to the Seiberg-Witten equations with\n$N$ spinors on a compact Riemann surface. These moduli spaces arise in a\nprogram to define a new enumerative invariant of 3-manifolds. They are also of\nindependent interest in the geometry of algebraic curves, as they parameterize\ngeneralized divisors in Brill-Noether theory for higher rank vector bundles. We\ncompute the Euler characteristic of these spaces, completing a computation\ninitiated by Doan, and then compute their rational homology using spectral\ncurves and techniques of Fulton and Lazarsfeld.",
    "pdf_url": "http://arxiv.org/pdf/2505.13166v1",
    "published": "2025-05-19T14:24:44+00:00",
    "categories": [
      "math.DG",
      "math.AG",
      "math.GT",
      "58D27 (Primary), 14H51, 32G13, 53C07 (Secondary)"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13576v1",
    "title": "FlexFed: Mitigating Catastrophic Forgetting in Heterogeneous Federated Learning in Pervasive Computing Environments",
    "authors": [
      "Sara Alosaime",
      "Arshad Jhumka"
    ],
    "abstract": "Federated Learning (FL) enables collaborative model training while preserving\nprivacy by allowing clients to share model updates instead of raw data.\nPervasive computing environments (e.g., for Human Activity Recognition, HAR),\nwhich we focus on in this paper, are characterized by resource-constrained end\ndevices, streaming sensor data and intermittent client participation.\nVariations in user behavior, common in HAR environments, often result in\nnon-stationary data distributions. As such, existing FL approaches face\nchallenges in HAR settings due to differing assumptions. The combined effects\nof HAR characteristics, namely heterogeneous data and intermittent\nparticipation, can lead to a severe issue called catastrophic forgetting (CF).\nUnlike Continuous Learning (CL), which addresses CF using memory and replay\nmechanisms, FL's privacy constraints prohibit such strategies.\n  To tackle CF in HAR environments, we propose FlexFed, a novel FL approach\nthat prioritizes data retention for efficient memory use and dynamically\nadjusts offline training frequency based on distribution shifts, client\ncapability and offline duration. To better quantify CF in FL, we introduce a\nnew metric that accounts for under-represented data, enabling more accurate\nevaluations. We also develop a realistic HAR-based evaluation framework that\nsimulates streaming data, dynamic distributions, imbalances and varying\navailability. Experiments show that FlexFed mitigates CF more effectively,\nimproves FL efficiency by 10 to 15 % and achieves faster, more stable\nconvergence, especially for infrequent or under-represented data.",
    "pdf_url": "http://arxiv.org/pdf/2505.13576v1",
    "published": "2025-05-19T14:23:37+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13165v1",
    "title": "A parametric finite element method for a degenerate multi-phase Stefan problem with triple junctions",
    "authors": [
      "Tokuhiro Eto",
      "Harald Garcke",
      "Robert N√ºrnberg"
    ],
    "abstract": "In this study, we propose a parametric finite element method for a degenerate\nmulti-phase Stefan problem with triple junctions. This model describes the\nenergy-driven motion of a surface cluster whose distributional solution was\nstudied by Garcke and Sturzenhecker. We approximate the weak formulation of\nthis sharp interface model by an unfitted finite element method that uses\nparametric elements for the representation of the moving interfaces. We\nestablish existence and uniqueness of the discrete solution and prove\nunconditional stability of the proposed scheme. Moreover, a modification of the\noriginal scheme leads to a structure-preserving variant, in that it conserves\nthe discrete analogue of a quantity that is preserved by the classical\nsolution. Some numerical results demonstrate the applicability of our\nintroduced schemes.",
    "pdf_url": "http://arxiv.org/pdf/2505.13165v1",
    "published": "2025-05-19T14:23:35+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13163v2",
    "title": "Hypergeometric Discriminants",
    "authors": [
      "Saiei-Jaeyeong Matsubara-Heo"
    ],
    "abstract": "Given a family of varieties, the Euler discriminant locus distinguishes\npoints where Euler characteristic differs from its generic value. We introduce\na hypergeometric system associated with a flat family of very affine locally\ncomplete intersection varieties. It is proven that the Euler discriminant locus\nis its singular locus and is purely one-codimensional unless it is empty. Of\nparticular interest is a family of very affine hypersurfaces. We coin the term\nhypergeometric discriminant for the characteristic cycle of the hypergeometric\nsystem and establish a formula in terms of likelihood equations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13163v2",
    "published": "2025-05-19T14:22:30+00:00",
    "categories": [
      "math.AG",
      "hep-th"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13164v1",
    "title": "High-Rate Nested-Lattice Quantized Matrix Multiplication with Small Lookup Tables",
    "authors": [
      "Iris Kaplan",
      "Or Ordentlich"
    ],
    "abstract": "Recent work have shown that the quantization for matrix multiplication\nproblem can be optimally solved by quantizing each column in each matrix using\na nested lattice code, and then multiplying the de-quantized matrices. It was\nfurther demonstrated that when product codes of sub-dimension $d$ and rate $R$\nare used, the de-quantization and inner product operations can be implemented\nwith querying a lookup table (LUT) of size $2^{2dR}$, but this is only useful\nwhen $dR$ is sufficiently small. This in turn limits LUT-based inner product\ndecoding to low-rate quantizers. In this work, we develop a rate $R$\nhierarchical nested lattice quantization framework, which quantizes each vector\nto $M$ layers, and admits LUT-based inner product decoding using an LUT of size\n$2^{2d\\frac{R}{M}}$, allowing for high-rate quantization. We provide analytic\nbounds on the loss of the developed scheme compared to standard nested lattice\nquantizers, and also numerically illustrate that this loss is negligible. Thus,\nour scheme enables to use small LUTs without compromising the overall\ndistortion.",
    "pdf_url": "http://arxiv.org/pdf/2505.13164v1",
    "published": "2025-05-19T14:22:30+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13162v1",
    "title": "Conditions for Quantum Violation of Macrorealism in Large-spin Limit",
    "authors": [
      "Qi-Hong Cai",
      "Xue-Hao Yu",
      "Ma-Cheng Yang",
      "Ao-Xiang Liu",
      "Cong-Feng Qiao"
    ],
    "abstract": "This study investigates how macroscopic classical behavior emerges from a\nquantum underpinning with counterintuitive characteristics. The deviation from\nclassical standpoint of a quantum system's temporal correlations is measured\nvia the entropic Leggett-Garg inequality. We introduce a geometric framework to\nderive entropic Leggett-Garg inequalities involving higher-order correlations,\nand analyze their asymptotic behavior in large-spin systems by employing the\nWKB approximation. Results show that, for maximally mixed states, quantum\nviolations converge to a constant in the macroscopic limit, rather than growing\nlogarithmically with the system's entropy, indicating that macroscopic realism\nincreasingly dominates as the number of energy levels expands. However,\nexceptions arise with certain parameter settings, where the semiclassical\napproximation breaks down entirely, enabling inequalities to exhibit maximal\nquantum violation, thus revealing that quantum and classical descriptions\nremain incompatible even on a macroscopic scale. It is noteworthy this\nviolation originates exclusively from the temporal correlations of a single\nsystem, distinguishing it from macroscopic quantum phenomena observed in\nmany-body systems such as superconductivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.13162v1",
    "published": "2025-05-19T14:22:28+00:00",
    "categories": [
      "quant-ph",
      "hep-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13161v1",
    "title": "The Star Formation and Chemical Evolution Histories of Ursa Minor Dwarf Spheroidal Galaxy",
    "authors": [
      "Kyosuke S. Sato",
      "Yutaka Komiyama",
      "Sakurako Okamoto",
      "Masafumi Yagi",
      "Itsuki Ogami",
      "Mikito Tanaka",
      "Nobuo Arimoto",
      "Masashi Chiba",
      "Evan N. Kirby",
      "Rosemary F. G. Wyse"
    ],
    "abstract": "We derive the star formation history (SFH) and chemical evolution history\n(CEH) of the Ursa Minor (UMi) dwarf spheroidal galaxy (dSph). We detect two\ndistinct stellar populations that exist over 6 times half-light radius from its\ncenter. The results are obtained by applying a newly developed algorithm to the\ndeep and wide-field photometric dataset taken with Hyper Suprime-Cam on the\nSubaru Telescope. The algorithm employs the genetic algorithm and the simulated\nannealing to minimize a $\\chi^{2}$ value between the observed color-magnitude\ndiagram (CMD) and synthetic CMD generated from the stellar isochrones. The age\nand metallicity resolutions are set to $0.5$ Gyr and $0.1$ dex, respectively.\nThe accuracy assessment with mock galaxies shows that it returns the peaks of\nmetallicity distributions and star formation period within 1 $\\sigma$ of input\nvalue in the case of a single population. In tests with two populations, two\ndistinct metallicity peaks are identified without an offset from the input\nvalues, indicating the robustness of this algorithm. The detected two\npopulations in the UMi dSph have the metallicity peaks of [Fe/H] = $-2.2$ and\n$-2.5$; the metal-rich population started its star formation about 1 Gyr later\nthan the metal-poor one. The SFH of both metal-rich and metal-poor populations\nvaries with distance from the center of the UMi dSph, without any\nage-gradients. These results suggest that the UMi dSph underwent a complex\nformation process, contrary to the simple formation history of dwarf galaxies\npreviously thought.",
    "pdf_url": "http://arxiv.org/pdf/2505.13161v1",
    "published": "2025-05-19T14:20:26+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13160v1",
    "title": "eBPF-Based Instrumentation for Generalisable Diagnosis of Performance Degradation",
    "authors": [
      "Diogo Landau",
      "Jorge Barbosa",
      "Nishant Saurabh"
    ],
    "abstract": "Online Data Intensive applications (e.g. message brokers, ML inference and\ndatabases) are core components of the modern internet, providing critical\nfunctionalities to connecting services. The load variability and interference\nthey experience are generally the main causes of Quality of Service (QoS)\ndegradation, harming depending applications, and resulting in an impaired\nend-user experience. Uncovering the cause of QoS degradation requires detailed\ninstrumentation of an application's activity. Existing generalisable approaches\nutilise readily available system metrics that encode interference in kernel\nmetrics, but unfortunately, these approaches lack the required detail to\npinpoint granular causes of performance degradation (e.g., lock, disk and CPU\ncontention). In contrast, this paper explores the use of fine-grained\nsystem-level metrics to facilitate an application-agnostic diagnosis of QoS\ndegradation. To this end, we introduce and implement $16$ $\\textit{eBPF-based\nmetrics}$ spanning over six kernel subsystems, which capture statistics over\nkernel events that often highlight obstacles impeding an application's\nprogress. We demonstrate the use of our $\\textit{eBPF-based metrics}$ through\nextensive experiments containing a representative set of online data-intensive\napplications. Results show that the implemented metrics can deconstruct\nperformance degradation when applications face variable workload patterns and\ncommon resource contention scenarios, while also revealing applications'\ninternal architecture constraints.",
    "pdf_url": "http://arxiv.org/pdf/2505.13160v1",
    "published": "2025-05-19T14:19:04+00:00",
    "categories": [
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13159v1",
    "title": "MXDOTP: A RISC-V ISA Extension for Enabling Microscaling (MX) Floating-Point Dot Products",
    "authors": [
      "Gamze ƒ∞slamoƒülu",
      "Luca Bertaccini",
      "Arpan Suravi Prasad",
      "Francesco Conti",
      "Angelo Garofalo",
      "Luca Benini"
    ],
    "abstract": "Fast and energy-efficient low-bitwidth floating-point (FP) arithmetic is\nessential for Artificial Intelligence (AI) systems. Microscaling (MX)\nstandardized formats have recently emerged as a promising alternative to\nbaseline low-bitwidth FP formats, offering improved accuracy with a block-wise\nshared exponent scale combined with per-element values. However, efficiently\nexecuting the key linear algebra primitives for AI applications on MX formats\nrequires specialized hardware support for the fundamental operators such as\nscaled dot product. In this work, we propose MXDOTP, the first RISC-V ISA\nextension for MX dot products, focusing on the 8-bit MXFP8 FP format. We extend\nthe open-source Snitch RISC-V core with a dedicated MXFP8 dot\nproduct-accumulate unit, which fully consumes blocks of eight 8-bit operands\npacked into 64-bit inputs. To feed MXDOTP at full utilization with four\noperands per cycle, including block scales, we exploit Snitch's Stream Semantic\nRegisters (SSRs), achieving up to 80% utilization with minimal impact on the\nSnitch core's architecture and no modification to the register file.\nImplemented in 12 nm FinFET, a cluster with eight MXDOTP-extended cores reaches\nup to 356 GFLOPS/W when computing MXFP8 matrix multiplications at 0.8 V, 1 GHz.\nCompared to a software baseline, where MX dot products are computed by type\ncasting FP8 inputs to FP32 for higher accumulation precision and applying\nexplicit block scaling, the cluster achieves 25x speedup and 12.5x better\nenergy efficiency at a minimal 5.1% area increase.",
    "pdf_url": "http://arxiv.org/pdf/2505.13159v1",
    "published": "2025-05-19T14:18:34+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13158v1",
    "title": "Network-wide Quantum Key Distribution with Onion Routing Relay (Conference Version)",
    "authors": [
      "Pedro Otero-Garc√≠a",
      "David P√©rez-Castro",
      "Manuel Fern√°ndez-Veiga",
      "Ana Fern√°ndez-Vilas"
    ],
    "abstract": "The advancement of quantum computing threatens classical cryptographic\nmethods, necessitating the development of secure quantum key distribution (QKD)\nsolutions for QKD Networks (QKDN). In this paper, a novel key distribution\nprotocol, Onion Routing Relay (ORR), that integrates onion routing (OR) with\npost-quantum cryptography (PQC) in a key-relay (KR) model is evaluated for\nQKDNs. This approach increases the security by enhancing confidentiality,\nintegrity, authenticity (CIA principles), and anonymity in quantum-secure\ncommunications. By employing PQC-based encapsulation, ORR aims to avoid the\nsecurity risks posed by intermediate malicious nodes and ensures end-to-end\nsecurity. Our results show a competitive performance of the basic ORR model,\nagainst current KR and trusted-node (TN) approaches, demonstrating its\nfeasibility and applicability in high-security environments maintaining a\nconsistent Quality of Service (QoS). The results also show that while basic ORR\nincurs higher encryption overhead, it provides substantial security\nimprovements without significantly impacting the overall key distribution time.\nNevertheless, the introduction of an end-to-end authentication extension\n(ORR-Ext) has a significant impact on the Quality of Service (QoS), thereby\nlimiting its suitability to applications with stringent security requirements.",
    "pdf_url": "http://arxiv.org/pdf/2505.13158v1",
    "published": "2025-05-19T14:18:19+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13157v1",
    "title": "Role-Playing Evaluation for Large Language Models",
    "authors": [
      "Yassine El Boudouri",
      "Walter Nuninger",
      "Julian Alvarez",
      "Yvan Peter"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate a notable capacity for adopting\npersonas and engaging in role-playing. However, evaluating this ability\npresents significant challenges, as human assessments are resource-intensive\nand automated evaluations can be biased. To address this, we introduce\nRole-Playing Eval (RPEval), a novel benchmark designed to assess LLM\nrole-playing capabilities across four key dimensions: emotional understanding,\ndecision-making, moral alignment, and in-character consistency. This article\ndetails the construction of RPEval and presents baseline evaluations. Our code\nand dataset are available at https://github.com/yelboudouri/RPEval",
    "pdf_url": "http://arxiv.org/pdf/2505.13157v1",
    "published": "2025-05-19T14:18:16+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13156v1",
    "title": "Tianyi: A Traditional Chinese Medicine all-rounder language model and its Real-World Clinical Practice",
    "authors": [
      "Zhi Liu",
      "Tao Yang",
      "Jing Wang",
      "Yexin Chen",
      "Zhan Gao",
      "Jiaxi Yang",
      "Kui Chen",
      "Bingji Lu",
      "Xiaochen Li",
      "Changyong Luo",
      "Yan Li",
      "Xiaohong Gu",
      "Peng Cao"
    ],
    "abstract": "Natural medicines, particularly Traditional Chinese Medicine (TCM), are\ngaining global recognition for their therapeutic potential in addressing human\nsymptoms and diseases. TCM, with its systematic theories and extensive\npractical experience, provides abundant resources for healthcare. However, the\neffective application of TCM requires precise syndrome diagnosis, determination\nof treatment principles, and prescription formulation, which demand decades of\nclinical expertise. Despite advancements in TCM-based decision systems, machine\nlearning, and deep learning research, limitations in data and single-objective\nconstraints hinder their practical application. In recent years, large language\nmodels (LLMs) have demonstrated potential in complex tasks, but lack\nspecialization in TCM and face significant challenges, such as too big model\nscale to deploy and issues with hallucination. To address these challenges, we\nintroduce Tianyi with 7.6-billion-parameter LLM, a model scale proper and\nspecifically designed for TCM, pre-trained and fine-tuned on diverse TCM\ncorpora, including classical texts, expert treatises, clinical records, and\nknowledge graphs. Tianyi is designed to assimilate interconnected and\nsystematic TCM knowledge through a progressive learning manner. Additionally,\nwe establish TCMEval, a comprehensive evaluation benchmark, to assess LLMs in\nTCM examinations, clinical tasks, domain-specific question-answering, and\nreal-world trials. The extensive evaluations demonstrate the significant\npotential of Tianyi as an AI assistant in TCM clinical practice and research,\nbridging the gap between TCM knowledge and practical application.",
    "pdf_url": "http://arxiv.org/pdf/2505.13156v1",
    "published": "2025-05-19T14:17:37+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13155v2",
    "title": "It√¥-Wentzell-Lions formulae for flows of full and conditional measures on semimartingales",
    "authors": [
      "Liu Jisheng",
      "Zhang Jing"
    ],
    "abstract": "In this paper, we establish the It\\^o-Wentzell-Lions formulae for flows of\nboth full and conditional measures on general semimartingales. This generalizes\nthe existing works on flows of measures on It\\^o processes. The key technical\ncomponents involve an appropriate approximation of random fields by cylindrical\nfunctions and localization techniques. Moreover, we present the specific\nformulae in two special cases, including It\\^o-Wentzell-Lions formulae for\ntime-space-measure-dependent functions and for functions driven by Poisson\nrandom measures.",
    "pdf_url": "http://arxiv.org/pdf/2505.13155v2",
    "published": "2025-05-19T14:16:27+00:00",
    "categories": [
      "math.PR",
      "math.OC"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13154v1",
    "title": "A conformally mapped numerical wave tank supporting piston and flap wavemakers",
    "authors": [
      "Andreas Holm Akselsen"
    ],
    "abstract": "This paper advances the development of the conformally mapped model for\naccurate simulation of two-dimensional water waves, here with emphasis on\nmapping boundaries that represent piston- and flap-type wavemakers. With this,\na complete numerical representation of wave flumes is provided -- the first of\nits kind based on conformal mapping. The model is validated both theoretically\nand experimentally, with special attention devoted to wavemaker characteristics\nand the generation of spurious waves. It is further demonstrated that the\nmethod accurately predicts the spectral evolutions of generated wave fields.\nThe model is computationally efficient, with beyond real-time computation but\nfor the smallest tested periods, making it ideal for numerical wave calibration\nand for replicating experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.13154v1",
    "published": "2025-05-19T14:15:46+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.13153v1",
    "title": "Prink: $k_s$-Anonymization for Streaming Data in Apache Flink",
    "authors": [
      "Philip Groneberg",
      "Saskia Nu√±ez von Voigt",
      "Thomas Janke",
      "Louis Loechel",
      "Karl Wolf",
      "Elias Gr√ºnewald",
      "Frank Pallas"
    ],
    "abstract": "In this paper, we present Prink, a novel and practically applicable concept\nand fully implemented prototype for ks-anonymizing data streams in real-world\napplication architectures. Building upon the pre-existing, yet rudimentary\nCASTLE scheme, Prink for the first time introduces semantics-aware\nks-anonymization of non-numerical (such as categorical or hierarchically\ngeneralizable) streaming data in a information loss-optimized manner. In\naddition, it provides native integration into Apache Flink, one of the\nprevailing frameworks for enterprise-grade stream data processing in numerous\napplication domains.\n  Our contributions excel the previously established state of the art for the\nprivacy guarantee-providing anonymization of streaming data in that they 1)\nallow to include non-numerical data in the anonymization process, 2) provide\ndiscrete datapoints instead of aggregates, thereby facilitating flexible data\nuse, 3) are applicable in real-world system contexts with minimal integration\nefforts, and 4) are experimentally proven to raise acceptable performance\noverheads and information loss in realistic settings. With these\ncharacteristics, Prink provides an anonymization approach which is practically\nfeasible for a broad variety of real-world, enterprise-grade stream processing\napplications and environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.13153v1",
    "published": "2025-05-19T14:13:30+00:00",
    "categories": [
      "cs.DC",
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13152v1",
    "title": "Higher fidelity perceptual image and video compression with a latent conditioned residual denoising diffusion model",
    "authors": [
      "Jonas Brenig",
      "Radu Timofte"
    ],
    "abstract": "Denoising diffusion models achieved impressive results on several image\ngeneration tasks often outperforming GAN based models. Recently, the generative\ncapabilities of diffusion models have been employed for perceptual image\ncompression, such as in CDC. A major drawback of these diffusion-based methods\nis that, while producing impressive perceptual quality images they are dropping\nin fidelity/increasing the distortion to the original uncompressed images when\ncompared with other traditional or learned image compression schemes aiming for\nfidelity. In this paper, we propose a hybrid compression scheme optimized for\nperceptual quality, extending the approach of the CDC model with a decoder\nnetwork in order to reduce the impact on distortion metrics such as PSNR. After\nusing the decoder network to generate an initial image, optimized for\ndistortion, the latent conditioned diffusion model refines the reconstruction\nfor perceptual quality by predicting the residual. On standard benchmarks, we\nachieve up to +2dB PSNR fidelity improvements while maintaining comparable\nLPIPS and FID perceptual scores when compared with CDC. Additionally, the\napproach is easily extensible to video compression, where we achieve similar\nresults.",
    "pdf_url": "http://arxiv.org/pdf/2505.13152v1",
    "published": "2025-05-19T14:13:14+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13151v1",
    "title": "Homogeneous pseudo-Riemannian structures of metrics of Kaluza-Klein type on the three-dimensional anti-de Sitter spacetime",
    "authors": [
      "Fumihiro Ueno"
    ],
    "abstract": "We classify homogeneous pseudo-Riemannian structures of a three-parameter\nfamily of metrics called Kaluza-Klein type on the three-dimensional anti-de\nSitter spacetime with their induced groups of isometries and reductive\ndecompositions. We also obtain the classification of homogeneous almost contact\nand paracontact metric structures of metrics of Kaluza-Klein type on the\nthree-dimensional anti-de Sitter spacetime with their isometry groups and\nreductive decompositions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13151v1",
    "published": "2025-05-19T14:13:01+00:00",
    "categories": [
      "math.DG",
      "53C30 (primary), 53C35 (secondary)"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13150v1",
    "title": "Zero-Shot Adaptation of Behavioral Foundation Models to Unseen Dynamics",
    "authors": [
      "Maksim Bobrin",
      "Ilya Zisman",
      "Alexander Nikulin",
      "Vladislav Kurenkov",
      "Dmitry Dylov"
    ],
    "abstract": "Behavioral Foundation Models (BFMs) proved successful in producing policies\nfor arbitrary tasks in a zero-shot manner, requiring no test-time training or\ntask-specific fine-tuning. Among the most promising BFMs are the ones that\nestimate the successor measure learned in an unsupervised way from\ntask-agnostic offline data. However, these methods fail to react to changes in\nthe dynamics, making them inefficient under partial observability or when the\ntransition function changes. This hinders the applicability of BFMs in a\nreal-world setting, e.g., in robotics, where the dynamics can unexpectedly\nchange at test time. In this work, we demonstrate that Forward-Backward (FB)\nrepresentation, one of the methods from the BFM family, cannot distinguish\nbetween distinct dynamics, leading to an interference among the latent\ndirections, which parametrize different policies. To address this, we propose a\nFB model with a transformer-based belief estimator, which greatly facilitates\nzero-shot adaptation. We also show that partitioning the policy encoding space\ninto dynamics-specific clusters, aligned with the context-embedding directions,\nyields additional gain in performance. These traits allow our method to respond\nto the dynamics observed during training and to generalize to unseen ones.\nEmpirically, in the changing dynamics setting, our approach achieves up to a 2x\nhigher zero-shot returns compared to the baselines for both discrete and\ncontinuous tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13150v1",
    "published": "2025-05-19T14:12:19+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13147v2",
    "title": "What if Deception Cannot be Detected? A Cross-Linguistic Study on the Limits of Deception Detection from Text",
    "authors": [
      "Aswathy Velutharambath",
      "Kai Sassenberg",
      "Roman Klinger"
    ],
    "abstract": "Can deception be detected solely from written text? Cues of deceptive\ncommunication are inherently subtle, even more so in text-only communication.\nYet, prior studies have reported considerable success in automatic deception\ndetection. We hypothesize that such findings are largely driven by artifacts\nintroduced during data collection and do not generalize beyond specific\ndatasets. We revisit this assumption by introducing a belief-based deception\nframework, which defines deception as a misalignment between an author's claims\nand true beliefs, irrespective of factual accuracy, allowing deception cues to\nbe studied in isolation. Based on this framework, we construct three corpora,\ncollectively referred to as DeFaBel, including a German-language corpus of\ndeceptive and non-deceptive arguments and a multilingual version in German and\nEnglish, each collected under varying conditions to account for belief change\nand enable cross-linguistic analysis. Using these corpora, we evaluate commonly\nreported linguistic cues of deception. Across all three DeFaBel variants, these\ncues show negligible, statistically insignificant correlations with deception\nlabels, contrary to prior work that treats such cues as reliable indicators. We\nfurther benchmark against other English deception datasets following similar\ndata collection protocols. While some show statistically significant\ncorrelations, effect sizes remain low and, critically, the set of predictive\ncues is inconsistent across datasets. We also evaluate deception detection\nusing feature-based models, pretrained language models, and instruction-tuned\nlarge language models. While some models perform well on established deception\ndatasets, they consistently perform near chance on DeFaBel. Our findings\nchallenge the assumption that deception can be reliably inferred from\nlinguistic cues and call for rethinking how deception is studied and modeled in\nNLP.",
    "pdf_url": "http://arxiv.org/pdf/2505.13147v2",
    "published": "2025-05-19T14:12:05+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13148v1",
    "title": "Capacitance of a Cube and a Hollow Cylinder",
    "authors": [
      "Haiyong Gu",
      "Liyuan Huang",
      "Peide Yang",
      "Tianshu Luo"
    ],
    "abstract": "We extended the surface element method proposed by Reitan and Higgins for\ncalculating the capacitance of cubes, subdividing each face of a cube into up\nto \\(600 \\times 600 \\) Subsquares. When each face was divided into \\(90 \\times\n90\\) Subsquares, the capacitance of the unit cube reached a maximum value of\n\\(0.6608\\) cm (\\(0.7352\\) pF). We further applied this method to compute the\ncapacitance of hollow cylinders by dividing them into \\(q\\) annular rings (each\n\\( 1\\) cm in width), with each ring subdivided into \\(m\\) square elements (\n\\(1\\) cm side length). The capacitance of hollow cylinders under varying\n\\(q/m\\) ratios was calculated and compared with Lekner's numerical results and\nCavendish's experimental measurements, showing excellent agreement with both.",
    "pdf_url": "http://arxiv.org/pdf/2505.13148v1",
    "published": "2025-05-19T14:12:05+00:00",
    "categories": [
      "physics.class-ph"
    ],
    "primary_category": "physics.class-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13149v1",
    "title": "Flow interactions and forward flight dynamics of tandem flapping wings",
    "authors": [
      "Fang Fang",
      "Christiana Mavroyiakoumou",
      "Leif Ristroph",
      "Michael J. Shelley"
    ],
    "abstract": "We examine theoretically the flow interactions and forward flight dynamics of\ntandem or in-line flapping wings. Two wings are driven vertically with\nprescribed heaving-and-plunging motions, and the horizontal propulsion speeds\nand positions are dynamically selected through aero- or hydro-dynamic\ninteractions. Our simulations employ an improved vortex sheet method to solve\nfor the locomotion of the pair within the collective flow field, and we\nidentify 'schooling states' in which the wings travel together with nearly\nconstant separation. Multiple terminal configurations are achieved by varying\nthe initial conditions, and the emergent separations are approximately integer\nmultiples of the wavelength traced out by each wing. We explain the stability\nof these states by perturbing the follower and mapping out an effective\npotential for its position in the leader's wake. Each equilibrium position is\nstabilized since smaller separations are associated with in-phase follower-wake\nmotions that constructively reinforce the flow but lead to decreased thrust on\nthe follower; larger separations are associated with antagonistic follower-wake\nmotions, increased thrust, and a weakened collective wake. The equilibria and\ntheir stability are also corroborated by a linearized theory for the motion of\nthe leader, the wake it produces, and its effect on the follower. We also\nconsider a weakly-flapping follower driven with lower heaving amplitude than\nthe leader. We identify 'keep-up' conditions for which the wings may still\n'school' together despite their dissimilar kinematics, with the 'freeloading'\nfollower passively assuming a favorable position within the wake that permits\nit to travel significantly faster than it would in isolation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13149v1",
    "published": "2025-05-19T14:12:05+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.bio-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.13146v1",
    "title": "Exponential enhancement of sensitivity in Ramsey interferometry with optically thick ensemble of atoms",
    "authors": [
      "S. A. Moiseev",
      "K. I. Gerasimov",
      "M. M. Minnegaliev",
      "I. V. Brekotkin",
      "E. S. Moiseev"
    ],
    "abstract": "Ramsey interferometry is a cornerstone technique for precise measurement of\ntime and frequency in modern clocks. The Ramsey experiments are typically done\nin optically dilute samples of atoms to improve homogeneity and avoid\nback-action of atoms on excitation pulses. In contrast to later belief, we\npredict and experimentally show that in optically thick samples with\ninhomogeneous broadening of resonant transition, the back-action can lead to\nthe highly enhanced narrowing of Ramsey resonance. The linewidth narrowing and\ncorresponding precision of the frequency measurement scale exponentially with\nan increase in optical depth of a sample and can reach the limits set by\nhomogeneous broadening. We show that this effect is caused by a nonlinear\ninterference of multiple echoes formed inside the atomic medium, which is\nexperimentally confirmed with $^{167}\\text{Er}^{3+}$ ions in\n$\\text{Y}_2\\text{SiO}_5$ crystal. Our findings open new opportunities for\nnonlinear high-resolution spectroscopy of resonant media and sensitivity\nenhancement in a new generation of solid state clocks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13146v1",
    "published": "2025-05-19T14:11:56+00:00",
    "categories": [
      "quant-ph",
      "physics.atom-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13145v2",
    "title": "Observing the Sun with the Atacama Large Aperture Submillimeter Telescope (AtLAST): Forecasting Full-disk Observations",
    "authors": [
      "Mats Kirkaune",
      "Sven Wedemeyer",
      "Joshiwa van Marrewijk",
      "Tony Mroczkowski",
      "Thomas W. Morris"
    ],
    "abstract": "The Atacama Large Millimeter Array (ALMA) has revolutionised the field of\nsolar millimetre astronomy with its high angular resolution and cadence.\nHowever, with a limited field of view (FOV), targeted observations of highly\ndynamic phenomena such of flares are challenging. A large aperture single-dish\ntelescope with a large FOV, such as the future Atacama Large Aperture\nSubmillimeter Telescope (AtLAST), would prove useful in observing such\nphenomena, as one could scan the full solar disk on shorter timescales. We\naimed to explore what FOVs, detector counts, and scan strategies are suitable\nfor AtLAST to push the required full-disk scan times below 1 minute, enabling\nregular observations of dynamic solar phenomena. Utilising the maria code, we\nwere able to simulate solar observations with AtLAST, and thoroughly explored\nhow instrumental properties and scanning strategies affect the full-disk\nobservations in the planned frequency bands. We find the double-circle scan\npattern, currently employed at ALMA for full-disk mapping to also be an\nacceptable way of scanning the Sun with AtLAST. Using small to intermediately\nsized instruments (1000 - 50,000 detector elements), the estimated\nobservational cadence would be less than 1 minute across AtLAST's frequency\nrange with a reasonable pixel spacing. Using instruments with larger FOVs\n($\\gtrapprox 0.25^\\circ$, equivalent to $\\gtrapprox$ 1 R$_\\odot$), we find a\nsimple circular scan to be more efficient, achieving cadences on second time\nscales, but requiring more detector elements ($\\gtrapprox$ 100,000). We find\nthat a large FOV single-dish telescope such as AtLAST could provide the solar\nmillimetre community with hitherto unachievable observations, namely full-disk\nobservations at high cadence and adequate resolution. With cadences potentially\ndown to seconds, such an instrument would be ideal in the study of quickly\nevolving solar phenomena.",
    "pdf_url": "http://arxiv.org/pdf/2505.13145v2",
    "published": "2025-05-19T14:11:53+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13144v1",
    "title": "Temporal Distance-aware Transition Augmentation for Offline Model-based Reinforcement Learning",
    "authors": [
      "Dongsu Lee",
      "Minhae Kwon"
    ],
    "abstract": "The goal of offline reinforcement learning (RL) is to extract a\nhigh-performance policy from the fixed datasets, minimizing performance\ndegradation due to out-of-distribution (OOD) samples. Offline model-based RL\n(MBRL) is a promising approach that ameliorates OOD issues by enriching\nstate-action transitions with augmentations synthesized via a learned dynamics\nmodel. Unfortunately, seminal offline MBRL methods often struggle in\nsparse-reward, long-horizon tasks. In this work, we introduce a novel MBRL\nframework, dubbed Temporal Distance-Aware Transition Augmentation (TempDATA),\nthat generates augmented transitions in a temporally structured latent space\nrather than in raw state space. To model long-horizon behavior, TempDATA learns\na latent abstraction that captures a temporal distance from both trajectory and\ntransition levels of state space. Our experiments confirm that TempDATA\noutperforms previous offline MBRL methods and achieves matching or surpassing\nthe performance of diffusion-based trajectory augmentation and goal-conditioned\nRL on the D4RL AntMaze, FrankaKitchen, CALVIN, and pixel-based FrankaKitchen.",
    "pdf_url": "http://arxiv.org/pdf/2505.13144v1",
    "published": "2025-05-19T14:11:14+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13143v1",
    "title": "Auditing Meta-Cognitive Hallucinations in Reasoning Large Language Models",
    "authors": [
      "Haolang Lu",
      "Yilian Liu",
      "Jingxin Xu",
      "Guoshun Nan",
      "Yuanlong Yu",
      "Zhican Chen",
      "Kun Wang"
    ],
    "abstract": "The development of Reasoning Large Language Models (RLLMs) has significantly\nimproved multi-step reasoning capabilities, but it has also made hallucination\nproblems more frequent and harder to eliminate. While existing approaches\nmitigate hallucinations through external knowledge integration, model parameter\nanalysis, or self-verification, they often fail to capture how hallucinations\nemerge and evolve across the reasoning chain. In this work, we study the\ncausality of hallucinations under constrained knowledge domains by auditing the\nChain-of-Thought (CoT) trajectory and assessing the model's cognitive\nconfidence in potentially erroneous or biased claims. Our analysis reveals that\nin long-CoT settings, RLLMs can iteratively reinforce biases and errors through\nflawed reflective reasoning, eventually leading to hallucinated reasoning\npaths. Surprisingly, even direct interventions at the origin of hallucinations\noften fail to reverse their effects, as reasoning chains exhibit 'chain\ndisloyalty' -- a resistance to correction and a tendency to preserve flawed\nlogic. Furthermore, we show that existing hallucination detection methods are\nless reliable and interpretable than previously assumed in complex reasoning\nscenarios. Unlike methods such as circuit tracing that require access to model\ninternals, our black-box auditing approach supports interpretable long-chain\nhallucination attribution, offering better generalizability and practical\nutility. Code and data are available at:\nhttps://anonymous.4open.science/r/repo_for_meta_hallucination",
    "pdf_url": "http://arxiv.org/pdf/2505.13143v1",
    "published": "2025-05-19T14:11:09+00:00",
    "categories": [
      "cs.CY",
      "68T27",
      "I.2.7"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13142v1",
    "title": "Parallel Layer Normalization for Universal Approximation",
    "authors": [
      "Yunhao Ni",
      "Yuhe Liu",
      "Wenxin Sun",
      "Yitong Tang",
      "Yuxin Guo",
      "Peilin Feng",
      "Wenjun Wu",
      "Lei Huang"
    ],
    "abstract": "Universal approximation theorem (UAT) is a fundamental theory for deep neural\nnetworks (DNNs), demonstrating their powerful representation capacity to\nrepresent and approximate any function. The analyses and proofs of UAT are\nbased on traditional network with only linear and nonlinear activation\nfunctions, but omitting normalization layers, which are commonly employed to\nenhance the training of modern networks. This paper conducts research on UAT of\nDNNs with normalization layers for the first time. We theoretically prove that\nan infinitely wide network -- composed solely of parallel layer normalization\n(PLN) and linear layers -- has universal approximation capacity. Additionally,\nwe investigate the minimum number of neurons required to approximate\n$L$-Lipchitz continuous functions, with a single hidden-layer network. We\ncompare the approximation capacity of PLN with traditional activation functions\nin theory. Different from the traditional activation functions, we identify\nthat PLN can act as both activation function and normalization in deep neural\nnetworks at the same time. We also find that PLN can improve the performance\nwhen replacing LN in transformer architectures, which reveals the potential of\nPLN used in neural architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.13142v1",
    "published": "2025-05-19T14:10:23+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13141v2",
    "title": "Language-Specific Latent Process Hinders Cross-Lingual Performance",
    "authors": [
      "Zheng Wei Lim",
      "Alham Fikri Aji",
      "Trevor Cohn"
    ],
    "abstract": "Large language models (LLMs) are demonstrably capable of cross-lingual\ntransfer, but can produce inconsistent output when prompted with the same\nqueries written in different languages. To understand how language models are\nable to generalize knowledge from one language to the others, we apply the\nlogit lens to interpret the implicit steps taken by LLMs to solve multilingual\nmulti-choice reasoning questions. We find LLMs predict inconsistently and are\nless accurate because they rely on subspaces of individual languages, rather\nthan working in a shared semantic space. While larger models are more\nmultilingual, we show their hidden states are more likely to dissociate from\nthe shared representation compared to smaller models, but are nevertheless more\ncapable of retrieving knowledge embedded across different languages. Finally,\nwe demonstrate that knowledge sharing can be modulated by steering the models'\nlatent processing towards the shared semantic space. We find reinforcing\nutilization of the shared space improves the models' multilingual reasoning\nperformance, as a result of more knowledge transfer from, and better output\nconsistency with English.",
    "pdf_url": "http://arxiv.org/pdf/2505.13141v2",
    "published": "2025-05-19T14:10:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13140v1",
    "title": "CacheFlow: Fast Human Motion Prediction by Cached Normalizing Flow",
    "authors": [
      "Takahiro Maeda",
      "Jinkun Cao",
      "Norimichi Ukita",
      "Kris Kitani"
    ],
    "abstract": "Many density estimation techniques for 3D human motion prediction require a\nsignificant amount of inference time, often exceeding the duration of the\npredicted time horizon. To address the need for faster density estimation for\n3D human motion prediction, we introduce a novel flow-based method for human\nmotion prediction called CacheFlow. Unlike previous conditional generative\nmodels that suffer from time efficiency, CacheFlow takes advantage of an\nunconditional flow-based generative model that transforms a Gaussian mixture\ninto the density of future motions. The results of the computation of the\nflow-based generative model can be precomputed and cached. Then, for\nconditional prediction, we seek a mapping from historical trajectories to\nsamples in the Gaussian mixture. This mapping can be done by a much more\nlightweight model, thus saving significant computation overhead compared to a\ntypical conditional flow model. In such a two-stage fashion and by caching\nresults from the slow flow model computation, we build our CacheFlow without\nloss of prediction accuracy and model expressiveness. This inference process is\ncompleted in approximately one millisecond, making it 4 times faster than\nprevious VAE methods and 30 times faster than previous diffusion-based methods\non standard benchmarks such as Human3.6M and AMASS datasets. Furthermore, our\nmethod demonstrates improved density estimation accuracy and comparable\nprediction accuracy to a SOTA method on Human3.6M. Our code and models will be\npublicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.13140v1",
    "published": "2025-05-19T14:09:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13139v1",
    "title": "Persistence of integrable wave dynamics in the Discrete Gross--Pitaevskii equation: the focusing case",
    "authors": [
      "G. Fotopoulos",
      "N. I. Karachalios",
      "V. Koukouloyannis"
    ],
    "abstract": "Expanding upon our prior findings on the proximity of dynamics between\nintegrable and non-integrable systems within the framework of nonlinear\nSchr\\\"odinger equations, we examine this phenomenon for the focusing Discrete\nGross-Pitaevskii equation in comparison to the Ablowitz-Ladik lattice. The\npresence of the harmonic trap necessitates the study of the Ablowitz-Ladik\nlattice in weighted spaces. We establish estimates for the distance between\nsolutions in the suitable metric, providing a comprehensive description of the\npotential evolution of this distance for general initial data. These results\napply to a broad class of nonlinear Schr\\\"odinger models, including both\ndiscrete and partial differential equations. For the Discrete Gross-Pitaevskii\nequation, they guarantee the long-term persistence of small-amplitude bright\nsolitons, driven by the analytical solution of the AL lattice, especially in\nthe presence of a weak harmonic trap. Numerical simulations confirm the\ntheoretical predictions about the proximity of dynamics between the systems\nover long times. They also reveal that the soliton exhibits remarkable\nrobustness, even as the effects of the weak harmonic trap become increasingly\nsignificant, leading to the soliton's curved orbit.",
    "pdf_url": "http://arxiv.org/pdf/2505.13139v1",
    "published": "2025-05-19T14:08:53+00:00",
    "categories": [
      "nlin.PS",
      "math-ph",
      "math.MP",
      "35Q55, 37L60"
    ],
    "primary_category": "nlin.PS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13575v1",
    "title": "An Overview of Arithmetic Adaptations for Inference of Convolutional Neural Networks on Re-configurable Hardware",
    "authors": [
      "Ilkay Wunderlich",
      "Benjamin Koch",
      "Sven Sch√∂nfeld"
    ],
    "abstract": "Convolutional Neural Networks (CNNs) have gained high popularity as a tool\nfor computer vision tasks and for that reason are used in various applications.\nThere are many different concepts, like single shot detectors, that have been\npublished for detecting objects in images or video streams. However, CNNs\nsuffer from disadvantages regarding the deployment on embedded platforms such\nas re-configurable hardware like Field Programmable Gate Arrays (FPGAs). Due to\nthe high computational intensity, memory requirements and arithmetic\nconditions, a variety of strategies for running CNNs on FPGAs have been\ndeveloped. The following methods showcase our best practice approaches for a\nTinyYOLOv3 detector network on a XILINX Artix-7 FPGA using techniques like\nfusion of batch normalization, filter pruning and post training network\nquantization.",
    "pdf_url": "http://arxiv.org/pdf/2505.13575v1",
    "published": "2025-05-19T14:08:28+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13138v1",
    "title": "Neurosymbolic Diffusion Models",
    "authors": [
      "Emile van Krieken",
      "Pasquale Minervini",
      "Edoardo Ponti",
      "Antonio Vergari"
    ],
    "abstract": "Neurosymbolic (NeSy) predictors combine neural perception with symbolic\nreasoning to solve tasks like visual reasoning. However, standard NeSy\npredictors assume conditional independence between the symbols they extract,\nthus limiting their ability to model interactions and uncertainty - often\nleading to overconfident predictions and poor out-of-distribution\ngeneralisation. To overcome the limitations of the independence assumption, we\nintroduce neurosymbolic diffusion models (NeSyDMs), a new class of NeSy\npredictors that use discrete diffusion to model dependencies between symbols.\nOur approach reuses the independence assumption from NeSy predictors at each\nstep of the diffusion process, enabling scalable learning while capturing\nsymbol dependencies and uncertainty quantification. Across both synthetic and\nreal-world benchmarks - including high-dimensional visual path planning and\nrule-based autonomous driving - NeSyDMs achieve state-of-the-art accuracy among\nNeSy predictors and demonstrate strong calibration.",
    "pdf_url": "http://arxiv.org/pdf/2505.13138v1",
    "published": "2025-05-19T14:07:47+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13137v1",
    "title": "Learning to Adapt to Position Bias in Vision Transformer Classifiers",
    "authors": [
      "Robert-Jan Bruintjes",
      "Jan van Gemert"
    ],
    "abstract": "How discriminative position information is for image classification depends\non the data. On the one hand, the camera position is arbitrary and objects can\nappear anywhere in the image, arguing for translation invariance. At the same\ntime, position information is key for exploiting capture/center bias, and scene\nlayout, e.g.: the sky is up. We show that position bias, the level to which a\ndataset is more easily solved when positional information on input features is\nused, plays a crucial role in the performance of Vision Transformers image\nclassifiers. To investigate, we propose Position-SHAP, a direct measure of\nposition bias by extending SHAP to work with position embeddings. We show\nvarious levels of position bias in different datasets, and find that the\noptimal choice of position embedding depends on the position bias apparent in\nthe dataset. We therefore propose Auto-PE, a single-parameter position\nembedding extension, which allows the position embedding to modulate its norm,\nenabling the unlearning of position information. Auto-PE combines with existing\nPEs to match or improve accuracy on classification datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.13137v1",
    "published": "2025-05-19T14:07:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13136v1",
    "title": "ModernGBERT: German-only 1B Encoder Model Trained from Scratch",
    "authors": [
      "Anton Ehrmanntraut",
      "Julia Wunderle",
      "Jan Pfister",
      "Fotis Jannidis",
      "Andreas Hotho"
    ],
    "abstract": "Despite the prominence of decoder-only language models, encoders remain\ncrucial for resource-constrained applications. We introduce ModernGBERT (134M,\n1B), a fully transparent family of German encoder models trained from scratch,\nincorporating architectural innovations from ModernBERT. To evaluate the\npractical trade-offs of training encoders from scratch, we also present\nLL\\\"aMmlein2Vec (120M, 1B, 7B), a family of encoders derived from German\ndecoder-only models via LLM2Vec. We benchmark all models on natural language\nunderstanding, text embedding, and long-context reasoning tasks, enabling a\ncontrolled comparison between dedicated encoders and converted decoders. Our\nresults show that ModernGBERT 1B outperforms prior state-of-the-art German\nencoders as well as encoders adapted via LLM2Vec, with regard to performance\nand parameter-efficiency. All models, training data, checkpoints and code are\npublicly available, advancing the German NLP ecosystem with transparent,\nhigh-performance encoder models.",
    "pdf_url": "http://arxiv.org/pdf/2505.13136v1",
    "published": "2025-05-19T14:07:20+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13135v1",
    "title": "Aspects of complexity in automotive software systems and their relation to maintainability effort. A case study",
    "authors": [
      "Bengt Haraldsson",
      "Miroslaw Staron"
    ],
    "abstract": "Context: Large embedded systems in vehicles tend to grow in size and\ncomplexity, which causes challenges when maintaining these systems. Objective:\nWe explore how developers perceive the relation between maintainability effort\nand various sources of complexity. Methods: We conduct a case study at Scania\nAB, a heavy vehicle OEM. The units of analysis are two large software systems\nand their development teams/organizations. Results: Our results show that\nmaintainability effort is driven by system internal complexity in the form of\nvariant management and complex hardware control tasks. The maintainability is\nalso influenced by emergent complexity caused by the system's longevity and\nconstant growth. Besides these system-internal complexities, maintainability\neffort is also influenced by external complexities, such as organizational\ncoordination and business needs. During the study, developer trade-off\nstrategies for minimizing maintainability effort emerged. Conclusions:\nComplexity is a good proxy of maintainability effort, and allows developers to\ncreate strategies for managing the maintainability effort. Adequate complexity\nmetrics include both external aspects -- e.g., coordination complexity -- and\ninternal ones -- e.g., McCabe Cyclomatic Complexity.",
    "pdf_url": "http://arxiv.org/pdf/2505.13135v1",
    "published": "2025-05-19T14:06:24+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13134v1",
    "title": "A near-optimal Quadratic Goldreich-Levin algorithm",
    "authors": [
      "Jop Bri√´t",
      "Davi Castro-Silva"
    ],
    "abstract": "In this paper, we give a quadratic Goldreich-Levin algorithm that is close to\noptimal in the following ways. Given a bounded function $f$ on the Boolean\nhypercube $\\mathbb{F}_2^n$ and any $\\varepsilon>0$, the algorithm returns a\nquadratic polynomial $q: \\mathbb{F}_2^n \\to \\mathbb{F}_2$ so that the\ncorrelation of $f$ with the function $(-1)^q$ is within an additive\n$\\varepsilon$ of the maximum possible correlation with a quadratic phase\nfunction. The algorithm runs in $O_\\varepsilon(n^3)$ time and makes\n$O_\\varepsilon(n^2\\log n)$ queries to $f$, which matches the\ninformation-theoretic lower bound of $\\Omega(n^2)$ queries up to a logarithmic\nfactor.\n  As a result, we obtain a number of corollaries:\n  - A near-optimal self-corrector of quadratic Reed-Muller codes, which makes\n$O_\\varepsilon(n^2\\log n)$ queries to a Boolean function $f$ and returns a\nquadratic polynomial $q$ whose relative Hamming distance to $f$ is within\n$\\varepsilon$ of the minimum distance.\n  - An algorithmic polynomial inverse theorem for the order-3 Gowers uniformity\nnorm.\n  - An algorithm that makes a polynomial number of queries to a bounded\nfunction $f$ and decomposes $f$ as a sum of poly$(1/\\varepsilon)$ quadratic\nphase functions and error terms of order $\\varepsilon$.\n  Our algorithm is obtained using ideas from recent work on quantum learning\ntheory. Its construction deviates from previous approaches based on algorithmic\nproofs of the inverse theorem for the order-3 uniformity norm (and in\nparticular does not rely on the recent resolution of the polynomial\nFre\\u{\\i}man-Ruzsa conjecture).",
    "pdf_url": "http://arxiv.org/pdf/2505.13134v1",
    "published": "2025-05-19T14:03:36+00:00",
    "categories": [
      "cs.CC",
      "math.CO"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13133v2",
    "title": "Central $L$ values of congruent number elliptic curves",
    "authors": [
      "Xuejun Guo",
      "Dongxi Ye",
      "Hongbo Yin"
    ],
    "abstract": "Let $E_n$ be the congruent number elliptic curve $y^2=x^3-n^2x$, where $n$ is\nsquare-free and not divisible by primes $p\\equiv 3\\pmod 4$. In this paper, we\nprove that $L(E_n,1)$ can be expressed as the square of CM values of some\nsimple theta functions, generalizing two classical formulas of Gauss. Our\nresult is meaningful in both theory and practical computation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13133v2",
    "published": "2025-05-19T14:03:03+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13574v1",
    "title": "Single arm interferometry to probe the scalar field dark matter",
    "authors": [
      "Antonio Capolupo",
      "Gabriele Pisacane",
      "Aniello Quaranta",
      "Raoul Serao"
    ],
    "abstract": "We analyse the interaction of photons with a scalar dark matter field \\phi\nand we propose to use a single arm interferometer to reveal this interaction\nand constrain the parameters of the scalar dark matter model. By considering a\nbeam of coherent light and two spatially separated squeezing operations, we\nshow that the interaction of photons with scalar dark matter leads to an\nobservable deviation in the outgoing light state, with respect to free\nevolution. Therefore the single arm interferometer may yield a novel revelation\nmethod for scalar dark matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.13574v1",
    "published": "2025-05-19T14:01:31+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.14719v3",
    "title": "MSVIT: Improving Spiking Vision Transformer Using Multi-scale Attention Fusion",
    "authors": [
      "Wei Hua",
      "Chenlin Zhou",
      "Jibin Wu",
      "Yansong Chua",
      "Yangyang Shu"
    ],
    "abstract": "The combination of Spiking Neural Networks (SNNs) with Vision Transformer\narchitectures has garnered significant attention due to their potential for\nenergy-efficient and high-performance computing paradigms. However, a\nsubstantial performance gap still exists between SNN-based and ANN-based\ntransformer architectures. While existing methods propose spiking\nself-attention mechanisms that are successfully combined with SNNs, the overall\narchitectures proposed by these methods suffer from a bottleneck in effectively\nextracting features from different image scales. In this paper, we address this\nissue and propose MSVIT. This novel spike-driven Transformer architecture\nfirstly uses multi-scale spiking attention (MSSA) to enhance the capabilities\nof spiking attention blocks. We validate our approach across various main\ndatasets. The experimental results show that MSVIT outperforms existing\nSNN-based models, positioning itself as a state-of-the-art solution among\nSNN-transformer architectures. The codes are available at\nhttps://github.com/Nanhu-AI-Lab/MSViT.",
    "pdf_url": "http://arxiv.org/pdf/2505.14719v3",
    "published": "2025-05-19T14:01:03+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13132v1",
    "title": "Ocean wave spectrum reconstruction from HF radar data and its application to wave height estimation",
    "authors": [
      "Kaede Watanabe",
      "Toshiaki Yachimura",
      "Tsubasa Terada",
      "Hiroshi Kameda",
      "Ryuhei Takahashi",
      "Hiroshi Suito"
    ],
    "abstract": "Real-time estimation of ocean wave heights using high-frequency (HF) radar\nhas attracted great attention. This method offers the benefit of easy\nmaintenance by virtue of its ground-based installation. However, it is\nadversely affected by issues such as low estimation accuracy. As described\nherein, we propose an algorithm based on the nonnegative sparse regularization\nmethod to estimate the energy distribution of the component waves, known as the\nocean wave spectrum, from HF radar data. After proving a stability estimate of\nthis algorithm, we perform numerical simulations to verify the proposed\nmethod's effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.13132v1",
    "published": "2025-05-19T14:00:22+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13131v1",
    "title": "Constraint-Aware Diffusion Guidance for Robotics: Real-Time Obstacle Avoidance for Autonomous Racing",
    "authors": [
      "Hao Ma",
      "Sabrina Bodmer",
      "Andrea Carron",
      "Melanie Zeilinger",
      "Michael Muehlebach"
    ],
    "abstract": "Diffusion models hold great potential in robotics due to their ability to\ncapture complex, high-dimensional data distributions. However, their lack of\nconstraint-awareness limits their deployment in safety-critical applications.\nWe propose Constraint-Aware Diffusion Guidance (CoDiG), a data-efficient and\ngeneral-purpose framework that integrates barrier functions into the denoising\nprocess, guiding diffusion sampling toward constraint-satisfying outputs. CoDiG\nenables constraint satisfaction even with limited training data and generalizes\nacross tasks. We evaluate our framework in the challenging setting of miniature\nautonomous racing, where real-time obstacle avoidance is essential. Real-world\nexperiments show that CoDiG generates safe outputs efficiently under dynamic\nconditions, highlighting its potential for broader robotic applications. A\ndemonstration video is available at https://youtu.be/KNYsTdtdxOU.",
    "pdf_url": "http://arxiv.org/pdf/2505.13131v1",
    "published": "2025-05-19T14:00:17+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13129v1",
    "title": "Optimizing Retrieval Augmented Generation for Object Constraint Language",
    "authors": [
      "Kevin Chenhao Li",
      "Vahid Zolfaghari",
      "Nenad Petrovic",
      "Fengjunjie Pan",
      "Alois Knoll"
    ],
    "abstract": "The Object Constraint Language (OCL) is essential for defining precise\nconstraints within Model-Based Systems Engineering (MBSE). However, manually\nwriting OCL rules is complex and time-consuming. This study explores the\noptimization of Retrieval-Augmented Generation (RAG) for automating OCL rule\ngeneration, focusing on the impact of different retrieval strategies. We\nevaluate three retrieval approaches $\\unicode{x2013}$ BM25 (lexical-based),\nBERT-based (semantic retrieval), and SPLADE (sparse-vector retrieval)\n$\\unicode{x2013}$ analyzing their effectiveness in providing relevant context\nfor a large language model.\n  To further assess our approach, we compare and benchmark our\nretrieval-optimized generation results against PathOCL, a state-of-the-art\ngraph-based method. We directly compare BM25, BERT, and SPLADE retrieval\nmethods with PathOCL to understand how different retrieval methods perform for\na unified evaluation framework. Our experimental results, focusing on\nretrieval-augmented generation, indicate that while retrieval can enhance\ngeneration accuracy, its effectiveness depends on the retrieval method and the\nnumber of retrieved chunks (k). BM25 underperforms the baseline, whereas\nsemantic approaches (BERT and SPLADE) achieve better results, with SPLADE\nperforming best at lower k values. However, excessive retrieval with high k\nparameter can lead to retrieving irrelevant chunks which degrades model\nperformance. Our findings highlight the importance of optimizing retrieval\nconfigurations to balance context relevance and output consistency. This\nresearch provides insights into improving OCL rule generation using RAG and\nunderscores the need for tailoring retrieval.",
    "pdf_url": "http://arxiv.org/pdf/2505.13129v1",
    "published": "2025-05-19T14:00:10+00:00",
    "categories": [
      "cs.IR",
      "cs.SE"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13130v1",
    "title": "Adaptive Image Restoration for Video Surveillance: A Real-Time Approach",
    "authors": [
      "Muhammad Awais Amin",
      "Adama Ilboudo",
      "Abdul Samad bin Shahid",
      "Amjad Ali",
      "Waqas Haider Khan Bangyal"
    ],
    "abstract": "One of the major challenges in the field of computer vision especially for\ndetection, segmentation, recognition, monitoring, and automated solutions, is\nthe quality of images. Image degradation, often caused by factors such as rain,\nfog, lighting, etc., has a negative impact on automated\ndecision-making.Furthermore, several image restoration solutions exist,\nincluding restoration models for single degradation and restoration models for\nmultiple degradations. However, these solutions are not suitable for real-time\nprocessing. In this study, the aim was to develop a real-time image restoration\nsolution for video surveillance. To achieve this, using transfer learning with\nResNet_50, we developed a model for automatically identifying the types of\ndegradation present in an image to reference the necessary treatment(s) for\nimage restoration. Our solution has the advantage of being flexible and\nscalable.",
    "pdf_url": "http://arxiv.org/pdf/2505.13130v1",
    "published": "2025-05-19T14:00:10+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13128v1",
    "title": "Testing for sufficient follow-up in cure models with categorical covariates",
    "authors": [
      "Tsz Pang Yuen",
      "Eni Musta",
      "Ingrid Van Keilegom"
    ],
    "abstract": "In survival analysis, estimating the fraction of 'immune' or 'cured' subjects\nwho will never experience the event of interest, requires a sufficiently long\nfollow-up period. A few statistical tests have been proposed to test the\nassumption of sufficient follow-up, i.e. whether the right extreme of the\ncensoring distribution exceeds that of the survival time of the uncured\nsubjects. However, in practice the problem remains challenging. To address\nthis, a relaxed notion of 'practically' sufficient follow-up has been\nintroduced recently, suggesting that the follow-up would be considered\nsufficiently long if the probability for the event occurring after the end of\nthe study is very small. All these existing tests do not incorporate covariate\ninformation, which might affect the cure rate and the survival times. We extend\nthe test for 'practically' sufficient follow-up to settings with categorical\ncovariates. While a straightforward intersection-union type test could reject\nthe null hypothesis of insufficient follow-up only if such hypothesis is\nrejected for all covariate values, in practice this approach is overly\nconservative and lacks power. To improve upon this, we propose a novel test\nprocedure that relies on the test decision for one properly chosen covariate\nvalue. Our approach relies on the assumption that the conditional density of\nthe uncured survival time is a non-increasing function of time in the tail\nregion. We show that both methods yield tests of asymptotically level $\\alpha$\nand investigate their finite sample performance through simulations. The\npractical application of the methods is illustrated using a leukemia dataset.",
    "pdf_url": "http://arxiv.org/pdf/2505.13128v1",
    "published": "2025-05-19T13:59:39+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.13127v1",
    "title": "Goodness-of-fit tests for spatial point processes: A power study",
    "authors": [
      "Chiara Fend",
      "Claudia Redenbach"
    ],
    "abstract": "Spatial point processes are used as models in many different fields ranging\nfrom ecology and forestry to cosmology and materials science. In recent years,\nmodel validation, and in particular goodness-of-fit testing of a proposed point\nprocess model have seen many advances. Most of the proposed tests are based on\na functional summary statistic of the observed pattern. In this paper, the\nempirical powers of many possible goodness-of-fit tests that can be constructed\nfrom such a summary statistic are compared in an extensive simulation study.\nRecently introduced functional summary statistics derived from topological data\nanalysis and new constructions for the test statistic such as the continuous\nranked probability score are included in the comparison. We discuss the\nperformance of specific combinations of functional summary statistic and test\nstatistic and their robustness with respect to other tuning parameters.\nFinally, tests using more than one individual functional summary statistic are\nalso investigated. The results allow us to provide guidelines on how to choose\npowerful tests in a particular test stetting.",
    "pdf_url": "http://arxiv.org/pdf/2505.13127v1",
    "published": "2025-05-19T13:58:37+00:00",
    "categories": [
      "stat.ME",
      "60G55, 62M30, 62F03 (Primary) 62R40 (Secondary)"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.13126v2",
    "title": "Zero-Shot Iterative Formalization and Planning in Partially Observable Environments",
    "authors": [
      "Liancheng Gong",
      "Wang Zhu",
      "Jesse Thomason",
      "Li Zhang"
    ],
    "abstract": "Using LLMs not to predict plans but to formalize an environment into the\nPlanning Domain Definition Language (PDDL) has been shown to improve\nperformance and control. Existing work focuses on fully observable\nenvironments; we tackle the more realistic and challenging partially observable\nenvironments that lack of complete, reliable information. We propose PDDLego+,\na framework to iteratively formalize, plan, grow, and refine PDDL\nrepresentations in a zero-shot manner, without needing access to any existing\ntrajectories. On two textual simulated environments, we show that PDDLego+\nimproves goal reaching success and exhibits robustness against problem\ncomplexity. We also show that the domain knowledge captured after a successful\ntrial can benefit future tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13126v2",
    "published": "2025-05-19T13:58:15+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13125v2",
    "title": "On consistency of the interacting (anti)holomorphic higher-spin sector",
    "authors": [
      "A. V. Korybut"
    ],
    "abstract": "In the recently proposed generating systems for the (anti)holomorphic sector\nof the 4d higher spin theory and for the off-shell higher spin theory in\ngeneric dimension locality was achieved due to a peculiar limiting star\nproduct. Even though the generating systems exhibit all-order locality, the\nproduct itself encounters uncertainties when functions from specific classes\nare multiplied. This fact leads to the absence of the Leibniz rule for the\ndifferential operator acting on the auxiliary variables $z$ and, hence, its\nambiguous definition in the generating equations. We identify the gap in the\noriginal proof of consistency associated with this freedom. Nonetheless\nconsidered generating systems are perfectly consistent as shown by direct\ncomputations on the resulting vertices. Considering specific orderings of\nfields we show that consistency rests on the star-exchange-like identities for\nthe limiting star product formulated and proved here. Connection with the 4d\nVasiliev theory is discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.13125v2",
    "published": "2025-05-19T13:57:05+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13124v1",
    "title": "$Œº$PC: Scaling Predictive Coding to 100+ Layer Networks",
    "authors": [
      "Francesco Innocenti",
      "El Mehdi Achour",
      "Christopher L. Buckley"
    ],
    "abstract": "The biological implausibility of backpropagation (BP) has motivated many\nalternative, brain-inspired algorithms that attempt to rely only on local\ninformation, such as predictive coding (PC) and equilibrium propagation.\nHowever, these algorithms have notoriously struggled to train very deep\nnetworks, preventing them from competing with BP in large-scale settings.\nIndeed, scaling PC networks (PCNs) has recently been posed as a challenge for\nthe community (Pinchetti et al., 2024). Here, we show that 100+ layer PCNs can\nbe trained reliably using a Depth-$\\mu$P parameterisation (Yang et al., 2023;\nBordelon et al., 2023) which we call \"$\\mu$PC\". Through an extensive analysis\nof the scaling behaviour of PCNs, we reveal several pathologies that make\nstandard PCNs difficult to train at large depths. We then show that, despite\naddressing only some of these instabilities, $\\mu$PC allows stable training of\nvery deep (up to 128-layer) residual networks on simple classification tasks\nwith competitive performance and little tuning compared to current benchmarks.\nMoreover, $\\mu$PC enables zero-shot transfer of both weight and activity\nlearning rates across widths and depths. Our results have implications for\nother local algorithms and could be extended to convolutional and transformer\narchitectures. Code for $\\mu$PC is made available as part of a JAX library for\nPCNs at https://github.com/thebuckleylab/jpc (Innocenti et al., 2024).",
    "pdf_url": "http://arxiv.org/pdf/2505.13124v1",
    "published": "2025-05-19T13:54:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.18910v1",
    "title": "Asymptotic analysis and design of linear elastic shell lattice metamaterials",
    "authors": [
      "Di Zhang",
      "Ligang Liu"
    ],
    "abstract": "We present an asymptotic analysis of shell lattice metamaterials based on\nCiarlet's shell theory, introducing a new metric--asymptotic directional\nstiffness (ADS)--to quantify how the geometry of the middle surface governs the\neffective stiffness. We prove a convergence theorem that rigorously\ncharacterizes ADS and establishes its upper bound, along with necessary and\nsufficient condition for achieving it. As a key result, our theory provides the\nfirst rigorous explanation for the high bulk modulus observed in Triply\nPeriodic Minimal Surfaces (TPMS)-based shell lattices. To optimize ADS on\ngeneral periodic surfaces, we propose a triangular-mesh-based discretization\nand shape optimization framework. Numerical experiments validate the\ntheoretical findings and demonstrate the effectiveness of the optimization\nunder various design objectives. Our implementation is available at\nhttps://github.com/lavenklau/minisurf.",
    "pdf_url": "http://arxiv.org/pdf/2506.18910v1",
    "published": "2025-05-19T13:53:35+00:00",
    "categories": [
      "math.AP",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13573v1",
    "title": "FreeMesh: Boosting Mesh Generation with Coordinates Merging",
    "authors": [
      "Jian Liu",
      "Haohan Weng",
      "Biwen Lei",
      "Xianghui Yang",
      "Zibo Zhao",
      "Zhuo Chen",
      "Song Guo",
      "Tao Han",
      "Chunchao Guo"
    ],
    "abstract": "The next-coordinate prediction paradigm has emerged as the de facto standard\nin current auto-regressive mesh generation methods. Despite their\neffectiveness, there is no efficient measurement for the various tokenizers\nthat serialize meshes into sequences. In this paper, we introduce a new metric\nPer-Token-Mesh-Entropy (PTME) to evaluate the existing mesh tokenizers\ntheoretically without any training. Building upon PTME, we propose a\nplug-and-play tokenization technique called coordinate merging. It further\nimproves the compression ratios of existing tokenizers by rearranging and\nmerging the most frequent patterns of coordinates. Through experiments on\nvarious tokenization methods like MeshXL, MeshAnything V2, and Edgerunner, we\nfurther validate the performance of our method. We hope that the proposed PTME\nand coordinate merging can enhance the existing mesh tokenizers and guide the\nfurther development of native mesh generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13573v1",
    "published": "2025-05-19T13:52:57+00:00",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13123v1",
    "title": "Just Dance with $œÄ$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection",
    "authors": [
      "Snehashis Majhi",
      "Giacomo D'Amicantonio",
      "Antitza Dantcheva",
      "Quan Kong",
      "Lorenzo Garattoni",
      "Gianpiero Francesca",
      "Egor Bondarev",
      "Francois Bremond"
    ],
    "abstract": "Weakly-supervised methods for video anomaly detection (VAD) are\nconventionally based merely on RGB spatio-temporal features, which continues to\nlimit their reliability in real-world scenarios. This is due to the fact that\nRGB-features are not sufficiently distinctive in setting apart categories such\nas shoplifting from visually similar events. Therefore, towards robust complex\nreal-world VAD, it is essential to augment RGB spatio-temporal features by\nadditional modalities. Motivated by this, we introduce the Poly-modal Induced\nframework for VAD: \"PI-VAD\", a novel approach that augments RGB representations\nby five additional modalities. Specifically, the modalities include sensitivity\nto fine-grained motion (Pose), three dimensional scene and entity\nrepresentation (Depth), surrounding objects (Panoptic masks), global motion\n(optical flow), as well as language cues (VLM). Each modality represents an\naxis of a polygon, streamlined to add salient cues to RGB. PI-VAD includes two\nplug-in modules, namely Pseudo-modality Generation module and Cross Modal\nInduction module, which generate modality-specific prototypical representation\nand, thereby, induce multi-modal information into RGB cues. These modules\noperate by performing anomaly-aware auxiliary tasks and necessitate five\nmodality backbones -- only during training. Notably, PI-VAD achieves\nstate-of-the-art accuracy on three prominent VAD datasets encompassing\nreal-world scenarios, without requiring the computational overhead of five\nmodality backbones at inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.13123v1",
    "published": "2025-05-19T13:51:57+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13122v1",
    "title": "When majority rules, minority loses: bias amplification of gradient descent",
    "authors": [
      "Fran√ßois Bachoc",
      "J√©r√¥me Bolte",
      "Ryan Boustany",
      "Jean-Michel Loubes"
    ],
    "abstract": "Despite growing empirical evidence of bias amplification in machine learning,\nits theoretical foundations remain poorly understood. We develop a formal\nframework for majority-minority learning tasks, showing how standard training\ncan favor majority groups and produce stereotypical predictors that neglect\nminority-specific features. Assuming population and variance imbalance, our\nanalysis reveals three key findings: (i) the close proximity between\n``full-data'' and stereotypical predictors, (ii) the dominance of a region\nwhere training the entire model tends to merely learn the majority traits, and\n(iii) a lower bound on the additional training required. Our results are\nillustrated through experiments in deep learning for tabular and image\nclassification tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13122v1",
    "published": "2025-05-19T13:51:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13121v1",
    "title": "Fractional Einstein field equations in $2+1$ dimensional spacetime",
    "authors": [
      "E. Contreras",
      "A. Di Teodoro",
      "M. Mena"
    ],
    "abstract": "In this work, we introduce a new fractional derivative that modifies the\nconventional Riemann-Liouville operator to obtain a set of fractional Einstein\nfield equations within a 2+1 dimensional spacetime by assuming a static and\ncircularly symmetric metric. The main reason for introducing this new\nderivative stems from addressing the divergence encountered during the\nconstruction of Christoffel symbols when using the Caputo operator and the\nappearance of unwanted terms when using the Riemann-Liouville derivative\nbecause of the well-known fact that its action on constants does not vanish, as\nexpected. The key innovation of the new operator ensures that the derivative of\na constant is zero. As a particular application, we explore whether the\nBa\\~nados-Teitelboim-Zanelli black hole metric is a solution to fractional\nEinstein equations. Our results reveal that for values of the fractional\nparameter close to one, the effective matter sector corresponds to a charged\nBTZ solution with an anisotropic cosmological constant.",
    "pdf_url": "http://arxiv.org/pdf/2505.13121v1",
    "published": "2025-05-19T13:51:46+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.18189v1",
    "title": "Generating Realistic Multi-Beat ECG Signals",
    "authors": [
      "Paul P√∂hl",
      "Viktor Schlegel",
      "Hao Li",
      "Anil Bharath"
    ],
    "abstract": "Generating synthetic ECG data has numerous applications in healthcare, from\neducational purposes to simulating scenarios and forecasting trends. While\nrecent diffusion models excel at generating short ECG segments, they struggle\nwith longer sequences needed for many clinical applications. This paper\nproposes a novel three-layer synthesis framework for generating realistic\nlong-form ECG signals. We first generate high-fidelity single beats using a\ndiffusion model, then synthesize inter-beat features preserving critical\ntemporal dependencies, and finally assemble beats into coherent long sequences\nusing feature-guided matching. Our comprehensive evaluation demonstrates that\nthe resulting synthetic ECGs maintain both beat-level morphological fidelity\nand clinically relevant inter-beat relationships. In arrhythmia classification\ntasks, our long-form synthetic ECGs significantly outperform end-to-end\nlong-form ECG generation using the diffusion model, highlighting their\npotential for increasing utility for downstream applications. The approach\nenables generation of unprecedented multi-minute ECG sequences while preserving\nessential diagnostic characteristics.",
    "pdf_url": "http://arxiv.org/pdf/2505.18189v1",
    "published": "2025-05-19T13:50:58+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13120v2",
    "title": "Pseudo-holomorphic curves with a fixed complex structure in positive symplectic manifolds",
    "authors": [
      "Alessio Cela",
      "Aleksander Doan"
    ],
    "abstract": "We prove a symplectic version of a conjecture of Lian and Pandharipande: in\nsufficiently high degree, the fixed-domain Gromov-Witten invariants of positive\nsymplectic manifolds are signed counts of pseudo-holomorphic curves. The\noriginal conjecture in the complex algebraic setting was recently disproved by\nBeheshti et al. However, we show that the statement holds when the complex\nstructure is replaced by a generic almost complex structure. The proof relies\non showing that the fixed-domain Gromov-Witten pseudocycle can be constructed\nwithout the use of inhomogeneous or domain-dependent perturbations, which\nanswers positively a question posed by Ruan and Tian.",
    "pdf_url": "http://arxiv.org/pdf/2505.13120v2",
    "published": "2025-05-19T13:49:54+00:00",
    "categories": [
      "math.SG",
      "math.AG"
    ],
    "primary_category": "math.SG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13119v1",
    "title": "A rapid black hole spin or emission from the plunging region?",
    "authors": [
      "Andrew Mummery",
      "Jiachen Jiang",
      "Adam Ingram",
      "Andrew Fabian",
      "Jake Rule"
    ],
    "abstract": "Emission from within the plunging region of black hole accretion flows has\nrecently been detected in two X-ray binary systems. There is, furthermore, a\npossible discrepancy between the inferred spins of gravitational wave and\nelectromagnetically detected black holes. Motivated by these two results we\ndemonstrate, using theoretical calculations, numerical simulations and\nobservational data, that the inclusion of emission from within the innermost\nstable circular orbit (ISCO) results in a black hole with a low spin producing\na thermal continuum X-ray spectrum that mimics that produced by a much more\nrapidly rotating black hole surrounded by a disk with no emission from within\nthe ISCO. We demonstrate this explicitly using the observed X-ray spectrum of a\ncanonical soft-state high mass X-ray binary system M33 X-7. A vanishing ISCO\ntemperature model requires a high spin $a_\\bullet = 0.84\\pm0.05$, as has been\nfound previously in the literature. However, a disk around a Schwarzschild\nblack hole can equally well (in fact slightly better) describe the data,\nprovided that photons emitted from within the plunging region are included, and\nthe ISCO stress is in line with that seen in numerical simulations of the\naccretion process. We then present an analysis of two further soft-state X-ray\nbinaries (MAXI J1820+070 and MAXI J0637$-$430) which require the presence of\nintra-ISCO emission at high statistical significance. These two sources sit on\nthe low-spin moderate-stress part of the degeneracy exhibited by M33 X-7,\nsuggesting that when high quality data are available the high-spin low-stress\nregion of parameter space is ruled out. We discuss how future advances in\nnumerical simulations and data modelling will be essential to determining the\nspin of X-ray binary black holes which may well be systematically lower than\ncurrent continuum fitting methods suggest.",
    "pdf_url": "http://arxiv.org/pdf/2505.13119v1",
    "published": "2025-05-19T13:49:09+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13118v1",
    "title": "Unveil Sources of Uncertainty: Feature Contribution to Conformal Prediction Intervals",
    "authors": [
      "Marouane Il Idrissi",
      "Agathe Fernandes Machado",
      "Ewen Gallic",
      "Arthur Charpentier"
    ],
    "abstract": "Cooperative game theory methods, notably Shapley values, have significantly\nenhanced machine learning (ML) interpretability. However, existing explainable\nAI (XAI) frameworks mainly attribute average model predictions, overlooking\npredictive uncertainty. This work addresses that gap by proposing a novel,\nmodel-agnostic uncertainty attribution (UA) method grounded in conformal\nprediction (CP). By defining cooperative games where CP interval\nproperties-such as width and bounds-serve as value functions, we systematically\nattribute predictive uncertainty to input features. Extending beyond the\ntraditional Shapley values, we use the richer class of Harsanyi allocations,\nand in particular the proportional Shapley values, which distribute attribution\nproportionally to feature importance. We propose a Monte Carlo approximation\nmethod with robust statistical guarantees to address computational feasibility,\nsignificantly improving runtime efficiency. Our comprehensive experiments on\nsynthetic benchmarks and real-world datasets demonstrate the practical utility\nand interpretative depth of our approach. By combining cooperative game theory\nand conformal prediction, we offer a rigorous, flexible toolkit for\nunderstanding and communicating predictive uncertainty in high-stakes ML\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2505.13118v1",
    "published": "2025-05-19T13:49:05+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13117v1",
    "title": "Entropy production rate in thermodynamically consistent flocks",
    "authors": [
      "Tal Agranov",
      "Robert L. Jack",
      "Michael E. Cates",
      "√âtienne Fodor"
    ],
    "abstract": "We study the entropy production rate (EPR) of aligning self-propelled\nparticles which undergo a flocking transition towards a polarized collective\nmotion. In our thermodynamically consistent lattice model, individual\nself-propulsion is the exclusive source of irreversibility. We derive the\nfluctuating hydrodynamics for large system sizes using a controlled\ncoarse-graining: our procedure entails an exact correspondence between the EPR\nevaluated at the hydrodynamic and particle-based levels. We reveal that EPR is\nmaximal when the system adopts a homogeneous configuration, either apolar or\npolar, and reduced in the non-homogeneous state where a polar band travels in a\napolar background due to strong spatial EPR modulations. By analyzing the\nlatter we also show that asymmetric energetic exchanges occur at the trailing\nand leading edges, which we map into a thermodynamic cycle in\ndensity-polarization space. Finally, we demonstrate that the regime of weak\nself-propulsion features a singular scaling of EPR, and a non-analyticity of\nthe travelling band profiles.",
    "pdf_url": "http://arxiv.org/pdf/2505.13117v1",
    "published": "2025-05-19T13:48:53+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.13116v1",
    "title": "Continuous Fair SMOTE -- Fairness-Aware Stream Learning from Imbalanced Data",
    "authors": [
      "Kathrin Lammers",
      "Valerie Vaquet",
      "Barbara Hammer"
    ],
    "abstract": "As machine learning is increasingly applied in an online fashion to deal with\nevolving data streams, the fairness of these algorithms is a matter of growing\nethical and legal concern. In many use cases, class imbalance in the data also\nneeds to be dealt with to ensure predictive performance. Current fairness-aware\nstream learners typically attempt to solve these issues through in- or\npost-processing by focusing on optimizing one specific discrimination metric,\naddressing class imbalance in a separate processing step. While C-SMOTE is a\nhighly effective model-agnostic pre-processing approach to mitigate class\nimbalance, as a side effect of this method, algorithmic bias is often\nintroduced.\n  Therefore, we propose CFSMOTE - a fairness-aware, continuous SMOTE variant -\nas a pre-processing approach to simultaneously address the class imbalance and\nfairness concerns by employing situation testing and balancing\nfairness-relevant groups during oversampling. Unlike other fairness-aware\nstream learners, CFSMOTE is not optimizing for only one specific fairness\nmetric, therefore avoiding potentially problematic trade-offs. Our experiments\nshow significant improvement on several common group fairness metrics in\ncomparison to vanilla C-SMOTE while maintaining competitive performance, also\nin comparison to other fairness-aware algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.13116v1",
    "published": "2025-05-19T13:46:47+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13115v1",
    "title": "Benchmarking and Confidence Evaluation of LALMs For Temporal Reasoning",
    "authors": [
      "Debarpan Bhattacharya",
      "Apoorva Kulkarni",
      "Sriram Ganapathy"
    ],
    "abstract": "The popular success of text-based large language models (LLM) has streamlined\nthe attention of the multimodal community to combine other modalities like\nvision and audio along with text to achieve similar multimodal capabilities. In\nthis quest, large audio language models (LALMs) have to be evaluated on\nreasoning related tasks which are different from traditional classification or\ngeneration tasks. Towards this goal, we propose a novel dataset called temporal\nreasoning evaluation of audio (TREA).\n  We benchmark open-source LALMs and observe that they are consistently behind\nhuman capabilities on the tasks in the TREA dataset. While evaluating LALMs, we\nalso propose an uncertainty metric, which computes the invariance of the model\nto semantically identical perturbations of the input. Our analysis shows that\nthe accuracy and uncertainty metrics are not necessarily correlated and thus,\npoints to a need for wholesome evaluation of LALMs for high-stakes\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2505.13115v1",
    "published": "2025-05-19T13:46:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13114v2",
    "title": "A Kahlerian approche to the Schrodinger equation in Siegel jacobi Space of the lognormal distribution",
    "authors": [
      "Prosper Rosaire Mama Assandje",
      "Joseph Dongho",
      "Thomas Bouetou Bouetou"
    ],
    "abstract": "In this paper, we describe the evolution of spectral curves in the Siegel\nJacobi space through the Schrodinger equation constructed from a Kahler\ngeometry induced on the lognormal statistical manifold via Dombrowski's\nconstruction. We introduce new holomorphic structures and show that the\nHamiltonian vector field coincides with the fundamental vector field generated\nby holomorphic isometries. We construct the time dependent Schrodinger equation\nfrom this geometric setting and show that the associated energy is not\nconstant, but varies with time. This work establishes a bridge between Kahler\ngeometry, statistical models, and the formalism of quantum mechanics.",
    "pdf_url": "http://arxiv.org/pdf/2505.13114v2",
    "published": "2025-05-19T13:44:03+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13113v2",
    "title": "Quantifying dissipation in flocking dynamics: When tracking internal states matters",
    "authors": [
      "Karel Proesmans",
      "Gianmaria Falasco",
      "Atul Tanaji Mohite",
      "Massimiliano Esposito",
      "√âtienne Fodor"
    ],
    "abstract": "Aligning self-propelled particles undergo a nonequilibrium flocking\ntransition from apolar to polar phases as their interactions become stronger.\nWe propose a thermodynamically consistent lattice model, in which the internal\nstate of the particles biases their diffusion, to capture such a transition.\nChanges of internal states and jumps between lattice sites obey local detailed\nbalance with respect to the same interaction energy. We unveil a crossover\nbetween two regimes: for weak interactions, the dissipation is maximal, and\npartial inference (namely, based on discarding the dynamics of internal states)\nleads to a severe underestimation; for strong interactions, the dissipation is\nreduced, and partial inference captures most of the dissipation. Finally, we\nreveal that the macroscopic dissipation, evaluated at the hydrodynamic level,\ncoincides with the microscopic dissipation upon coarse-graining. We argue that\nthis correspondence stems from a generic mapping of active lattice models with\nlocal detailed balance into a specific class of non-ideal reaction-diffusion\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13113v2",
    "published": "2025-05-19T13:43:10+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2506.08020v1",
    "title": "Bi-level Unbalanced Optimal Transport for Partial Domain Adaptation",
    "authors": [
      "Zi-Ying Chen",
      "Chuan-Xian Ren",
      "Hong Yan"
    ],
    "abstract": "Partial domain adaptation (PDA) problem requires aligning cross-domain\nsamples while distinguishing the outlier classes for accurate knowledge\ntransfer. The widely used weighting framework tries to address the outlier\nclasses by introducing the reweighed source domain with a similar label\ndistribution to the target domain. However, the empirical modeling of weights\ncan only characterize the sample-wise relations, which leads to insufficient\nexploration of cluster structures, and the weights could be sensitive to the\ninaccurate prediction and cause confusion on the outlier classes. To tackle\nthese issues, we propose a Bi-level Unbalanced Optimal Transport (BUOT) model\nto simultaneously characterize the sample-wise and class-wise relations in a\nunified transport framework. Specifically, a cooperation mechanism between\nsample-level and class-level transport is introduced, where the sample-level\ntransport provides essential structure information for the class-level\nknowledge transfer, while the class-level transport supplies discriminative\ninformation for the outlier identification. The bi-level transport plan\nprovides guidance for the alignment process. By incorporating the label-aware\ntransport cost, the local transport structure is ensured and a fast computation\nformulation is derived to improve the efficiency. Extensive experiments on\nbenchmark datasets validate the competitiveness of BUOT.",
    "pdf_url": "http://arxiv.org/pdf/2506.08020v1",
    "published": "2025-05-19T13:40:40+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13112v2",
    "title": "Attention-based clustering",
    "authors": [
      "Rodrigo Maulen-Soto",
      "Claire Boyer",
      "Pierre Marion"
    ],
    "abstract": "Transformers have emerged as a powerful neural network architecture capable\nof tackling a wide range of learning tasks. In this work, we provide a\ntheoretical analysis of their ability to automatically extract structure from\ndata in an unsupervised setting. In particular, we demonstrate their\nsuitability for clustering when the input data is generated from a Gaussian\nmixture model. To this end, we study a simplified two-head attention layer and\ndefine a population risk whose minimization with unlabeled data drives the head\nparameters to align with the true mixture centroids. This phenomenon highlights\nthe ability of attention-based layers to capture underlying distributional\nstructure. We further examine an attention layer with key, query, and value\nmatrices fixed to the identity, and show that, even without any trainable\nparameters, it can perform in-context quantization, revealing the surprising\ncapacity of transformer-based methods to adapt dynamically to input-specific\ndistributions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13112v2",
    "published": "2025-05-19T13:39:56+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.13111v1",
    "title": "Why Knowledge Distillation Works in Generative Models: A Minimal Working Explanation",
    "authors": [
      "Sungmin Cha",
      "Kyunghyun Cho"
    ],
    "abstract": "Knowledge distillation (KD) is a core component in the training and\ndeployment of modern generative models, particularly large language models\n(LLMs). While its empirical benefits are well documented--enabling smaller\nstudent models to emulate the performance of much larger teachers--the\nunderlying mechanisms by which KD improves generative quality remain poorly\nunderstood. In this work, we present a minimal working explanation of KD in\ngenerative modeling. Using a controlled simulation with mixtures of Gaussians,\nwe demonstrate that distillation induces a trade-off between precision and\nrecall in the student model. As the teacher distribution becomes more\nselective, the student concentrates more probability mass on high-likelihood\nregions at the expense of coverage--a behavior modulated by a single\nentropy-controlling parameter. We then validate this effect in a large-scale\nlanguage modeling setup using the SmolLM2 family of models. Empirical results\nreveal the same precision-recall dynamics observed in simulation, where\nprecision corresponds to sample quality and recall to distributional coverage.\nThis precision-recall trade-off proves especially beneficial in scenarios where\nsample quality outweighs diversity, such as instruction tuning or downstream\ngeneration. Our analysis provides a simple and general explanation for the\neffectiveness of KD in generative modeling.",
    "pdf_url": "http://arxiv.org/pdf/2505.13111v1",
    "published": "2025-05-19T13:39:47+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13110v1",
    "title": "Linear analysis of I-C-Love universal relations for neutron stars",
    "authors": [
      "Zexin Hu",
      "Yong Gao",
      "Lijing Shao"
    ],
    "abstract": "Neutron stars (NSs) are excellent laboratories for testing gravity theories\nas they are strongly self-gravitating bodies and have rich observational\nphenomena. However, strong-gravity effects in NS could be degenerate with their\nequation of state (EOS) which is largely unknown. Fortunately, there exist the\nso-called universal relations among the NS macroscopic quantities that are\nfound to be insensitive to the underlying EOS. Studying the origin of these\nrelations can lead to a better understanding of NSs and the gravitational\ninteraction. We develop a new perspective of view to analyze the I-C and I-Love\nuniversal relations for NSs. At the linear order, we separate the deviation of\nthe universal relations into two parts, where one is the EOS perturbation while\nthe other only depends on the background star structures. The smallness of the\nsecond part fully determines the universality of the relation irrespective of\nthe form of the first part. We discuss the validity of our linear approximation\nwhen considering the difference among realistic EOSs. Our study can be regarded\nas a new frame for quantitative representation of the universality and may\nprovide new insights to the universal relations of NSs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13110v1",
    "published": "2025-05-19T13:37:12+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.HE"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.13109v2",
    "title": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference",
    "authors": [
      "Guangda Liu",
      "Chengwei Li",
      "Zhenyu Ning",
      "Minyi Guo",
      "Jieru Zhao"
    ],
    "abstract": "Large language models (LLMs) have been widely deployed with rapidly expanding\ncontext windows to support increasingly demanding applications. However, long\ncontexts pose significant deployment challenges, primarily due to the KV cache\nwhose size grows proportionally with context length. While KV cache compression\nmethods are proposed to address this issue, KV dropping methods incur\nconsiderable accuracy loss, and KV retrieval methods suffer from significant\nefficiency bottlenecks. We propose FreeKV, an algorithm-system co-optimization\nframework to enhance KV retrieval efficiency while preserving accuracy. On the\nalgorithm side, FreeKV introduces speculative retrieval to shift the KV\nselection and recall processes out of the critical path, combined with\nfine-grained correction to ensure accuracy. On the system side, FreeKV employs\nhybrid KV layouts across CPU and GPU memory to eliminate fragmented data\ntransfers, and leverages double-buffered streamed recall to further improve\nefficiency. Experiments demonstrate that FreeKV achieves near-lossless accuracy\nacross various scenarios and models, delivering up to 13$\\times$ speedup\ncompared to SOTA KV retrieval methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13109v2",
    "published": "2025-05-19T13:36:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13108v1",
    "title": "On the bilinear cone multiplier",
    "authors": [
      "Saurabh Shrivastava",
      "Kalachand Shuin"
    ],
    "abstract": "For $f,g \\in \\mathscr{S}(\\R^n), n\\geq 3$, consider the bilinear cone\nmultiplier operator defined by\n  \\[{T}^{\\lambda}_{R}(f,g)(x):=\\int_{\\mathbb{R}^{2n}}m^{\\lambda}\\left(\\frac{\\xi'}{R\\xi_n},\\frac{\\eta'}{R\\eta_n}\\right)\\hat{f}(\\xi)\\hat{g}(\\eta)e^{2\\pi\\iota\nx\\cdot(\\xi+\\eta)}~d\\xi d\\eta,\\]\n  where $\\lambda>0, R>0$ and\n\\[m^{\\lambda}\\left(\\frac{\\xi'}{R\\xi_n},\\frac{\\eta'}{R\\eta_n}\\right)=\\Big(1-\\frac{|\\xi'|^2}{R^2\\xi^2_n}-\\frac{|\\eta'|^2}{R^2\\eta^2_n}\\Big)^{\\lambda}_{+}\\varphi(\\xi_n)\\varphi(\\eta_n),\\]\n  $(\\xi',\\xi_n), (\\eta',\\eta_n)\\in\\mathbb{R}^{n-1}\\times \\mathbb{R}$ and\n$\\varphi\\in C_{c}^{\\infty}([\\frac{1}{2},2])$.\n  We investigate the problem of pointwise almost everywhere convergence of\n${T}^{\\lambda}_{R}(f,g)(x)$ as $R\\rightarrow \\infty$ for $(f,g)\\in\nL^{p_1}\\times L^{p_2}$ for a wide range of exponents $p_1, p_2$ satisfying the\nH\\\"{o}lder relation $\\frac{1}{p_1}+\\frac{1}{p_2}=\\frac{1}{p}$. This assertion\nis proved by establishing suitable weighted $L^{2}\\times L^{2}\\rightarrow\nL^{1}$--estimates of the maximal bilinear cone multiplier operator\n  \\[{T}^{\\lambda}_{*}(f,g)(x):=\\sup_{R>0}|{T}^{\\lambda}_{R}(f,g)(x)|.\\]",
    "pdf_url": "http://arxiv.org/pdf/2505.13108v1",
    "published": "2025-05-19T13:36:25+00:00",
    "categories": [
      "math.CA",
      "42B15, 42B25"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13107v1",
    "title": "Electronic and optical and topological properties of defects in bismuthene",
    "authors": [
      "Gabriel Elyas Gama Araujo",
      "Andreia Luisa da Rosa",
      "Alexandre Cavalheiro Dias",
      "Thomas Frauenheim"
    ],
    "abstract": "In this work we use first principles density-functional theory and\nBethe-Salpeter equation together with tight-binding based maximally localized\nwannier functions (MLWF-TB) to investigate the electronic, optical and\ntopological properties of two-dimensional bismuth (bismuthene) containing\nvacancy defects. We demonstrate that these properties depends on the shape and\nsize of the nanopores. Furthermore, \\textit{ab initio} molecular dynamics\n(AIMD) simulations shows that all pores are thermally stable at room\ntemperature. Finally, adsorption of gas phase small molecules indicates that\nthese pores can serve as sensors, opening the path for further applications in\ngas separation and sensing.",
    "pdf_url": "http://arxiv.org/pdf/2505.13107v1",
    "published": "2025-05-19T13:36:07+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.13106v1",
    "title": "How to optimise tournament draws: The case of the 2022 FIFA World Cup",
    "authors": [
      "L√°szl√≥ Csat√≥"
    ],
    "abstract": "The organisers of major sports competitions use different policies with\nrespect to constraints in the group draw. Our paper aims to rationalise these\nchoices by analysing the trade-off between attractiveness (the number of games\nplayed by teams from the same geographic zone) and fairness (the departure of\nthe draw mechanism from a uniform distribution). A parametric optimisation\nmodel is formulated and applied to the 2022 FIFA World Cup draw. A flaw of the\ndraw procedure is identified: the pre-assignment of the host to a group implies\nadditional but unnecessary distortions. All Pareto efficient sets of draw\nconstraints are determined via simulations. The proposed framework can be used\nto find the optimal draw rules of a tournament and justify the distortion of\nthe draw procedure for the stakeholders.",
    "pdf_url": "http://arxiv.org/pdf/2505.13106v1",
    "published": "2025-05-19T13:36:00+00:00",
    "categories": [
      "math.OC",
      "physics.soc-ph",
      "stat.AP",
      "62-08, 90-10, 90B90, 91B14"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13105v2",
    "title": "Mode-Prefix-Based Control of Switched Linear Systems with Applications to Fault Tolerance",
    "authors": [
      "Ram Padmanabhan",
      "Antoine Aspeel",
      "Necmiye Ozay",
      "Melkior Ornik"
    ],
    "abstract": "In this paper, we consider the problem of designing prefix-based optimal\ncontrollers for switched linear systems over finite horizons. This problem\narises in fault-tolerant control, when system faults result in abrupt changes\nin dynamics. We consider a class of mode-prefix-based linear controllers that\ndepend only on the history of the switching signal. The proposed optimal\ncontrol problems seek to minimize both expected performance and worst-case\nperformance over switching signals. We show that this problem can be reduced to\na convex optimization problem. To this end, we synthesize one controller for\neach switching signal under a prefix constraint that ensures consistency\nbetween controllers. Then, system level synthesis is used to obtain a convex\nprogram in terms of the system-level parameters. In particular, it is shown\nthat the prefix constraints are linear in terms of the system-level parameters.\nFinally, we apply this framework for optimal control of a fighter jet model\nsuffering from system faults, illustrating how fault tolerance is ensured.",
    "pdf_url": "http://arxiv.org/pdf/2505.13105v2",
    "published": "2025-05-19T13:35:18+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13104v1",
    "title": "A Unified Framework for the Transportability of Population-Level Causal Measures",
    "authors": [
      "Ahmed Boughdiri",
      "Cl√©ment Berenfeld",
      "Julie Josse",
      "Erwan Scornet"
    ],
    "abstract": "Generalization methods offer a powerful solution to one of the key drawbacks\nof randomized controlled trials (RCTs): their limited representativeness. By\nenabling the transport of treatment effect estimates to target populations\nsubject to distributional shifts, these methods are increasingly recognized as\nthe future of meta-analysis, the current gold standard in evidence-based\nmedicine. Yet most existing approaches focus on the risk difference,\noverlooking the diverse range of causal measures routinely reported in clinical\nresearch. Reporting multiple effect measures-both absolute (e.g., risk\ndifference, number needed to treat) and relative (e.g., risk ratio, odds\nratio)-is essential to ensure clinical relevance, policy utility, and\ninterpretability across contexts. To address this gap, we propose a unified\nframework for transporting a broad class of first-moment population causal\neffect measures under covariate shift. We provide identification results under\ntwo conditional exchangeability assumptions, derive both classical and\nsemiparametric estimators, and evaluate their performance through theoretical\nanalysis, simulations, and real-world applications. Our analysis shows the\nspecificity of different causal measures and thus the interest of studying them\nall: for instance, two common approaches (one-step, estimating equation) lead\nto similar estimators for the risk difference but to two distinct estimators\nfor the odds ratio.",
    "pdf_url": "http://arxiv.org/pdf/2505.13104v1",
    "published": "2025-05-19T13:34:25+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.13103v2",
    "title": "Fixing 7,400 Bugs for 1$: Cheap Crash-Site Program Repair",
    "authors": [
      "Han Zheng",
      "Ilia Shumailov",
      "Tianqi Fan",
      "Aiden Hall",
      "Mathias Payer"
    ],
    "abstract": "The rapid advancement of bug-finding techniques has led to the discovery of\nmore vulnerabilities than developers can reasonably fix, creating an urgent\nneed for effective Automated Program Repair (APR) methods. However, the\ncomplexity of modern bugs often makes precise root cause analysis difficult and\nunreliable. To address this challenge, we propose crash-site repair to simplify\nthe repair task while still mitigating the risk of exploitation. In addition,\nwe introduce a template-guided patch generation approach that significantly\nreduces the token cost of Large Language Models (LLMs) while maintaining both\nefficiency and effectiveness.\n  We implement our prototype system, WILLIAMT, and evaluate it against\nstate-of-the-art APR tools. Our results show that, when combined with the\ntop-performing agent CodeRover-S, WILLIAMT reduces token cost by 45.9% and\nincreases the bug-fixing rate to 73.5% (+29.6%) on ARVO, a ground-truth open\nsource software vulnerabilities benchmark. Furthermore, we demonstrate that\nWILLIAMT can function effectively even without access to frontier LLMs: even a\nlocal model running on a Mac M4 Mini achieves a reasonable repair rate. These\nfindings highlight the broad applicability and scalability of WILLIAMT.",
    "pdf_url": "http://arxiv.org/pdf/2505.13103v2",
    "published": "2025-05-19T13:32:51+00:00",
    "categories": [
      "cs.SE",
      "cs.CR"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13102v1",
    "title": "Lightweight Transformer via Unrolling of Mixed Graph Algorithms for Traffic Forecast",
    "authors": [
      "Ji Qi",
      "Tam Thuc Do",
      "Mingxiao Liu",
      "Zhuoshi Pan",
      "Yuzhe Li",
      "Gene Cheung",
      "H. Vicky Zhao"
    ],
    "abstract": "To forecast traffic with both spatial and temporal dimensions, we unroll a\nmixed-graph-based optimization algorithm into a lightweight and interpretable\ntransformer-like neural net. Specifically, we construct two graphs: an\nundirected graph $\\mathcal{G}^u$ capturing spatial correlations across\ngeography, and a directed graph $\\mathcal{G}^d$ capturing sequential\nrelationships over time. We formulate a prediction problem for the future\nsamples of signal $\\mathbf{x}$, assuming it is \"smooth\" with respect to both\n$\\mathcal{G}^u$ and $\\mathcal{G}^d$, where we design new $\\ell_2$ and\n$\\ell_1$-norm variational terms to quantify and promote signal smoothness\n(low-frequency reconstruction) on a directed graph. We construct an iterative\nalgorithm based on alternating direction method of multipliers (ADMM), and\nunroll it into a feed-forward network for data-driven parameter learning. We\ninsert graph learning modules for $\\mathcal{G}^u$ and $\\mathcal{G}^d$, which\nare akin to the self-attention mechanism in classical transformers. Experiments\nshow that our unrolled networks achieve competitive traffic forecast\nperformance as state-of-the-art prediction schemes, while reducing parameter\ncounts drastically. Our code is available in\nhttps://github.com/SingularityUndefined/Unrolling-GSP-STForecast.",
    "pdf_url": "http://arxiv.org/pdf/2505.13102v1",
    "published": "2025-05-19T13:32:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13101v1",
    "title": "ARIW-Framework: Adaptive Robust Iterative Watermarking Framework",
    "authors": [
      "Shaowu Wu",
      "Liting Zeng",
      "Wei Lu",
      "Xiangyang Luo"
    ],
    "abstract": "With the rapid rise of large models, copyright protection for generated image\ncontent has become a critical security challenge. Although deep learning\nwatermarking techniques offer an effective solution for digital image copyright\nprotection, they still face limitations in terms of visual quality, robustness\nand generalization. To address these issues, this paper proposes an adaptive\nrobust iterative watermarking framework (ARIW-Framework) that achieves\nhigh-quality watermarked images while maintaining exceptional robustness and\ngeneralization performance. Specifically, we introduce an iterative approach to\noptimize the encoder for generating robust residuals. The encoder incorporates\nnoise layers and a decoder to compute robustness weights for residuals under\nvarious noise attacks. By employing a parallel optimization strategy, the\nframework enhances robustness against multiple types of noise attacks.\nFurthermore, we leverage image gradients to determine the embedding strength at\neach pixel location, significantly improving the visual quality of the\nwatermarked images. Extensive experiments demonstrate that the proposed method\nachieves superior visual quality while exhibiting remarkable robustness and\ngeneralization against noise attacks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13101v1",
    "published": "2025-05-19T13:31:48+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13100v1",
    "title": "Time series saliency maps: explaining models across multiple domains",
    "authors": [
      "Christodoulos Kechris",
      "Jonathan Dan",
      "David Atienza"
    ],
    "abstract": "Traditional saliency map methods, popularized in computer vision, highlight\nindividual points (pixels) of the input that contribute the most to the model's\noutput. However, in time-series they offer limited insights as semantically\nmeaningful features are often found in other domains. We introduce Cross-domain\nIntegrated Gradients, a generalization of Integrated Gradients. Our method\nenables feature attributions on any domain that can be formulated as an\ninvertible, differentiable transformation of the time domain. Crucially, our\nderivation extends the original Integrated Gradients into the complex domain,\nenabling frequency-based attributions. We provide the necessary theoretical\nguarantees, namely, path independence and completeness. Our approach reveals\ninterpretable, problem-specific attributions that time-domain methods cannot\ncapture, on three real-world tasks: wearable sensor heart rate extraction,\nelectroencephalography-based seizure detection, and zero-shot time-series\nforecasting. We release an open-source Tensorflow/PyTorch library to enable\nplug-and-play cross-domain explainability for time-series models. These results\ndemonstrate the ability of cross-domain integrated gradients to provide\nsemantically meaningful insights in time-series models that are impossible with\ntraditional time-domain saliency.",
    "pdf_url": "http://arxiv.org/pdf/2505.13100v1",
    "published": "2025-05-19T13:31:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13099v2",
    "title": "Industrial Synthetic Segment Pre-training",
    "authors": [
      "Shinichi Mae",
      "Ryousuke Yamada",
      "Hirokatsu Kataoka"
    ],
    "abstract": "Pre-training on real-image datasets has been widely proven effective for\nimproving instance segmentation. However, industrial applications face two key\nchallenges: (1) legal and ethical restrictions, such as ImageNet's prohibition\nof commercial use, and (2) limited transferability due to the domain gap\nbetween web images and industrial imagery. Even recent vision foundation\nmodels, including the segment anything model (SAM), show notable performance\ndegradation in industrial settings. These challenges raise critical questions:\nCan we build a vision foundation model for industrial applications without\nrelying on real images or manual annotations? And can such models outperform\neven fine-tuned SAM on industrial datasets? To address these questions, we\npropose the Instance Core Segmentation Dataset (InsCore), a synthetic\npre-training dataset based on formula-driven supervised learning (FDSL).\nInsCore generates fully annotated instance segmentation images that reflect key\ncharacteristics of industrial data, including complex occlusions, dense\nhierarchical masks, and diverse non-rigid shapes, distinct from typical web\nimagery. Unlike previous methods, InsCore requires neither real images nor\nhuman annotations. Experiments on five industrial datasets show that models\npre-trained with InsCore outperform those trained on COCO and ImageNet-21k, as\nwell as fine-tuned SAM, achieving an average improvement of 6.2 points in\ninstance segmentation performance. This result is achieved using only 100k\nsynthetic images, more than 100 times fewer than the 11 million images in SAM's\nSA-1B dataset, demonstrating the data efficiency of our approach. These\nfindings position InsCore as a practical and license-free vision foundation\nmodel for industrial applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.13099v2",
    "published": "2025-05-19T13:29:40+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13098v1",
    "title": "LLM-KG-Bench 3.0: A Compass for SemanticTechnology Capabilities in the Ocean of LLMs",
    "authors": [
      "Lars-Peter Meyer",
      "Johannes Frey",
      "Desiree Heim",
      "Felix Brei",
      "Claus Stadler",
      "Kurt Junghanns",
      "Michael Martin"
    ],
    "abstract": "Current Large Language Models (LLMs) can assist developing program code\nbeside many other things, but can they support working with Knowledge Graphs\n(KGs) as well? Which LLM is offering the best capabilities in the field of\nSemantic Web and Knowledge Graph Engineering (KGE)? Is this possible to\ndetermine without checking many answers manually? The LLM-KG-Bench framework in\nVersion 3.0 is designed to answer these questions. It consists of an extensible\nset of tasks for automated evaluation of LLM answers and covers different\naspects of working with semantic technologies. In this paper the LLM-KG-Bench\nframework is presented in Version 3 along with a dataset of prompts, answers\nand evaluations generated with it and several state-of-the-art LLMs.\nSignificant enhancements have been made to the framework since its initial\nrelease, including an updated task API that offers greater flexibility in\nhandling evaluation tasks, revised tasks, and extended support for various open\nmodels through the vllm library, among other improvements. A comprehensive\ndataset has been generated using more than 30 contemporary open and proprietary\nLLMs, enabling the creation of exemplary model cards that demonstrate the\nmodels' capabilities in working with RDF and SPARQL, as well as comparing their\nperformance on Turtle and JSON-LD RDF serialization tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13098v1",
    "published": "2025-05-19T13:29:27+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13097v1",
    "title": "An implicit regularized enthalpy Lattice Boltzmann Method for the Stefan problem",
    "authors": [
      "Francky Luddens",
      "Corentin Lothod√©",
      "Ionut Danaila"
    ],
    "abstract": "Solving the Stefan problem, also referred as the heat conduction problem with\nphase change, is a necessary step to solve phase change problems with\nconvection. In this article, we are interested in using the Lattice Boltzmann\nMethod (LBM) to solve the Stefan problem using a regularized total enthalpy\nmodel. The liquid fraction is treated as a nonlinear source/sink term, that\ninvolves the time derivative of the solution. The resulting non-linear system\nis solved using a Newton algorithm. By conserving the locality of the problem,\nthis method is highly scalable, while keeping a high accuracy. The newly\ndeveloped scheme is analyzed theoretically through a Chapman-Enskog expansion\nand illustrated numerically with 1D and 2D benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13097v1",
    "published": "2025-05-19T13:27:53+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13096v1",
    "title": "Domains and Classifying Topoi",
    "authors": [
      "Jonathan Sterling",
      "Lingyuan Ye"
    ],
    "abstract": "We explore a new connection between synthetic domain theory and Grothendieck\ntopoi related to the distributive lattice classifier. In particular, all the\naxioms of synthetic domain theory (including the inductive fixed point object\nand the chain completeness of the dominance) emanate from a countable version\nof the synthetic quasi-coherence principle that has emerged as a central\nfeature in the unification of synthetic algebraic geometry, synthetic Stone\nduality, and synthetic category theory. The duality between quasi-coherent\nalgebras and affine spaces in a topos with a distributive lattice object\nprovides a new set of techniques for reasoning synthetically about domain-like\nstructures, and reveals a broad class of (higher) sheaf models for synthetic\ndomain theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.13096v1",
    "published": "2025-05-19T13:27:48+00:00",
    "categories": [
      "cs.LO",
      "math.CT",
      "math.LO",
      "03B70"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13572v1",
    "title": "Q${}^2$Forge: Minting Competency Questions and SPARQL Queries for Question-Answering Over Knowledge Graphs",
    "authors": [
      "Yousouf Taghzouti",
      "Franck Michel",
      "Tao Jiang",
      "Louis-F√©lix Nothias",
      "Fabien Gandon"
    ],
    "abstract": "The SPARQL query language is the standard method to access knowledge graphs\n(KGs). However, formulating SPARQL queries is a significant challenge for\nnon-expert users, and remains time-consuming for the experienced ones. Best\npractices recommend to document KGs with competency questions and example\nqueries to contextualise the knowledge they contain and illustrate their\npotential applications. In practice, however, this is either not the case or\nthe examples are provided in limited numbers. Large Language Models (LLMs) are\nbeing used in conversational agents and are proving to be an attractive\nsolution with a wide range of applications, from simple question-answering\nabout common knowledge to generating code in a targeted programming language.\nHowever, training and testing these models to produce high quality SPARQL\nqueries from natural language questions requires substantial datasets of\nquestion-query pairs. In this paper, we present Q${}^2$Forge that addresses the\nchallenge of generating new competency questions for a KG and corresponding\nSPARQL queries. It iteratively validates those queries with human feedback and\nLLM as a judge. Q${}^2$Forge is open source, generic, extensible and modular,\nmeaning that the different modules of the application (CQ generation, query\ngeneration and query refinement) can be used separately, as an integrated\npipeline, or replaced by alternative services. The result is a complete\npipeline from competency question formulation to query evaluation, supporting\nthe creation of reference query sets for any target KG.",
    "pdf_url": "http://arxiv.org/pdf/2505.13572v1",
    "published": "2025-05-19T13:26:51+00:00",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.13095v1",
    "title": "Superadditivity of Convex Roof Coherence Measures in Multipartite System",
    "authors": [
      "Honglin Ren",
      "Lin Chen"
    ],
    "abstract": "In this paper, we investigate the convex roof measure of quantum coherence,\nwith a focus on their superadditive properties. We propose sufficient\nconditions and establish a framework for coherence superadditivity in\ntripartite and multipartite systems. Through theoretical derivation, the\nrelevant theorems are given. These results not only expand our understanding of\nthe superadditivity of pure and mixed states but also characterize the\nconditions under which the superadditivity relations reach equality. Finally,\nthe proposed methods and conclusions are verified through representative\nexamples, providing new theoretical insights into the distribution of quantum\ncoherence in multi-part systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13095v1",
    "published": "2025-05-19T13:26:23+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13094v1",
    "title": "Time-Frequency-Based Attention Cache Memory Model for Real-Time Speech Separation",
    "authors": [
      "Guo Chen",
      "Kai Li",
      "Runxuan Yang",
      "Xiaolin Hu"
    ],
    "abstract": "Existing causal speech separation models often underperform compared to\nnon-causal models due to difficulties in retaining historical information. To\naddress this, we propose the Time-Frequency Attention Cache Memory (TFACM)\nmodel, which effectively captures spatio-temporal relationships through an\nattention mechanism and cache memory (CM) for historical information storage.\nIn TFACM, an LSTM layer captures frequency-relative positions, while causal\nmodeling is applied to the time dimension using local and global\nrepresentations. The CM module stores past information, and the causal\nattention refinement (CAR) module further enhances time-based feature\nrepresentations for finer granularity. Experimental results showed that TFACM\nachieveed comparable performance to the SOTA TF-GridNet-Causal model, with\nsignificantly lower complexity and fewer trainable parameters. For more\ndetails, visit the project page: https://cslikai.cn/TFACM/.",
    "pdf_url": "http://arxiv.org/pdf/2505.13094v1",
    "published": "2025-05-19T13:25:51+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.13093v1",
    "title": "Fermionic sub-GeV Dark Matter from evaporating Primordial Black Holes at DarkSide-50",
    "authors": [
      "The DarkSide-50 Collaboration",
      ":",
      "P. Agnes",
      "I. F. Albuquerque",
      "T. Alexander",
      "A. K. Alton",
      "M. Ave",
      "H. O. Back",
      "G. Batignani",
      "K. Biery",
      "V. Bocci",
      "W. M. Bonivento",
      "B. Bottino",
      "S. Bussino",
      "M. Cadeddu",
      "M. Cadoni",
      "R. Calabrese",
      "F. Calaprice",
      "A. Caminata",
      "N. Canci",
      "M. Caravati",
      "N. Cargioli",
      "M. Cariello",
      "M. Carlini",
      "P. Cavalcante",
      "S. Chashin",
      "A. Chepurnov",
      "M. Chianese",
      "D. D'Angelo",
      "S. Davini",
      "S. De Cecco",
      "A. V. Derbin",
      "M. D'Incecco",
      "C. Dionisi",
      "F. Dordei",
      "M. Downing",
      "G. Fiorillo",
      "D. Franco",
      "F. Gabriele",
      "C. Galbiati",
      "C. Ghiano",
      "C. Giganti",
      "G. K. Giovanetti",
      "A. M. Goretti",
      "G. Grilli di Cortona",
      "A. Grobov",
      "M. Gromov",
      "M. Guam",
      "M. Gulino",
      "B. R. Hackett",
      "K. Herner",
      "T. Hessel",
      "F. Hubaut",
      "E. V. Hungerford",
      "A. Ianni",
      "V. Ippolito",
      "K. Keeter",
      "C. L. Kendziora",
      "M. Kimura",
      "I. Kochanek",
      "D. Korablev",
      "G. Korga",
      "A. Kubankin",
      "M. Kuss",
      "M. La Commara",
      "M. Lai",
      "X. Li",
      "M. Lissia",
      "O. Lychagina",
      "I. N. Machulin",
      "L. P. Mapelli",
      "S. M. Mari",
      "J. Maricic",
      "A. Messina",
      "R. Milincic",
      "J. Monroe",
      "M. Morrocchi",
      "V. N. Muratova",
      "P. Musico",
      "A. O. Nozdrina",
      "A. Oleinik",
      "F. Ortica",
      "L. Pagani",
      "M. Pallavicini",
      "L. Pandola",
      "E. Pantic",
      "E. Paoloni",
      "K. Pelczar",
      "N. Pelliccia",
      "S. Piacentini",
      "A. Pocar",
      "M. Poehlmann",
      "S. Pordes",
      "S. S. Poudel",
      "P. Pralavorio",
      "D. Price",
      "F. Ragusa",
      "M. Razeti",
      "A. L. Renshaw",
      "M. Rescigno",
      "J. Rode",
      "A. Romani",
      "D. Sablone",
      "O. Samoylov",
      "S. Sanfilippo",
      "C. Savarese",
      "N. Saviano",
      "B. Schlitzer",
      "D. A. Semenov",
      "A. Shchagin",
      "A. Sheshukov",
      "M. D. Skorokhvatov",
      "O. Smirnov",
      "A. Sotnikov",
      "S. Stracka",
      "Y. Suvorov",
      "R. Tartaglia",
      "G. Testera",
      "A. Tonazzo",
      "E. V. Unzhakov",
      "A. Vishneva",
      "R. B. Vogelaar",
      "M. Wada",
      "H. Wang",
      "Y. Wang",
      "S. Westerdale",
      "M. M. Wojcik",
      "X. Xiao",
      "C. Yang",
      "G. Zuzel"
    ],
    "abstract": "We present a search for boosted dark matter from Primordial Black Holes (PBH)\nevaporation using the DarkSide-50 ionization-signal-only dataset corresponding\nto the experiment's ($12202\\pm180$) ${\\rm kg\\: d}$ exposure. We focus on\nevaporation of PBHs with masses in the range [$10^{14},\\,10^{16}$] g producing\nDirac fermionic dark matter particles with sub-GeV kinetic energy. These\nrelativistic particles, with energies up to hundreds of MeV, can generate\ndetectable signals for masses below $\\mathcal{O}(100)$ MeV. The absence of a\nsignal enables setting complementary limits to those derived from cosmological\nobservations and direct detection searches for cosmic ray-boosted dark matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.13093v1",
    "published": "2025-05-19T13:25:14+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13092v2",
    "title": "Treatment Effect Estimation for Optimal Decision-Making",
    "authors": [
      "Dennis Frauen",
      "Valentyn Melnychuk",
      "Jonas Schweisthal",
      "Mihaela van der Schaar",
      "Stefan Feuerriegel"
    ],
    "abstract": "Decision-making across various fields, such as medicine, heavily relies on\nconditional average treatment effects (CATEs). Practitioners commonly make\ndecisions by checking whether the estimated CATE is positive, even though the\ndecision-making performance of modern CATE estimators is poorly understood from\na theoretical perspective. In this paper, we study optimal decision-making\nbased on two-stage CATE estimators (e.g., DR-learner), which are considered\nstate-of-the-art and widely used in practice. We prove that, while such\nestimators may be optimal for estimating CATE, they can be suboptimal when used\nfor decision-making. Intuitively, this occurs because such estimators\nprioritize CATE accuracy in regions far away from the decision boundary, which\nis ultimately irrelevant to decision-making. As a remedy, we propose a novel\ntwo-stage learning objective that retargets the CATE to balance CATE estimation\nerror and decision performance. We then propose a neural method that optimizes\nan adaptively-smoothed approximation of our learning objective. Finally, we\nconfirm the effectiveness of our method both empirically and theoretically. In\nsum, our work is the first to show how two-stage CATE estimators can be adapted\nfor optimal decision-making.",
    "pdf_url": "http://arxiv.org/pdf/2505.13092v2",
    "published": "2025-05-19T13:24:57+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13091v1",
    "title": "Touch2Shape: Touch-Conditioned 3D Diffusion for Shape Exploration and Reconstruction",
    "authors": [
      "Yuanbo Wang",
      "Zhaoxuan Zhang",
      "Jiajin Qiu",
      "Dilong Sun",
      "Zhengyu Meng",
      "Xiaopeng Wei",
      "Xin Yang"
    ],
    "abstract": "Diffusion models have made breakthroughs in 3D generation tasks. Current 3D\ndiffusion models focus on reconstructing target shape from images or a set of\npartial observations. While excelling in global context understanding, they\nstruggle to capture the local details of complex shapes and limited to the\nocclusion and lighting conditions. To overcome these limitations, we utilize\ntactile images to capture the local 3D information and propose a Touch2Shape\nmodel, which leverages a touch-conditioned diffusion model to explore and\nreconstruct the target shape from touch. For shape reconstruction, we have\ndeveloped a touch embedding module to condition the diffusion model in creating\na compact representation and a touch shape fusion module to refine the\nreconstructed shape. For shape exploration, we combine the diffusion model with\nreinforcement learning to train a policy. This involves using the generated\nlatent vector from the diffusion model to guide the touch exploration policy\ntraining through a novel reward design. Experiments validate the reconstruction\nquality thorough both qualitatively and quantitative analysis, and our touch\nexploration policy further boosts reconstruction performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.13091v1",
    "published": "2025-05-19T13:24:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13090v1",
    "title": "The Effect of Language Diversity When Fine-Tuning Large Language Models for Translation",
    "authors": [
      "David Stap",
      "Christof Monz"
    ],
    "abstract": "Prior research diverges on language diversity in LLM fine-tuning: Some\nstudies report benefits while others find no advantages. Through controlled\nfine-tuning experiments across 132 translation directions, we systematically\nresolve these disparities. We find that expanding language diversity during\nfine-tuning improves translation quality for both unsupervised and --\nsurprisingly -- supervised pairs, despite less diverse models being fine-tuned\nexclusively on these supervised pairs. However, benefits plateau or decrease\nbeyond a certain diversity threshold. We show that increased language diversity\ncreates more language-agnostic representations. These representational\nadaptations help explain the improved performance in models fine-tuned with\ngreater diversity.",
    "pdf_url": "http://arxiv.org/pdf/2505.13090v1",
    "published": "2025-05-19T13:24:01+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13089v2",
    "title": "Systematic Generalization in Language Models Scales with Information Entropy",
    "authors": [
      "Sondre Wold",
      "Lucas Georges Gabriel Charpentier",
      "√âtienne Simon"
    ],
    "abstract": "Systematic generalization remains challenging for current language models,\nwhich are known to be both sensitive to semantically similar permutations of\nthe input and to struggle with known concepts presented in novel contexts.\nAlthough benchmarks exist for assessing compositional behavior, it is unclear\nhow to measure the difficulty of a systematic generalization problem. In this\nwork, we show how one aspect of systematic generalization can be described by\nthe entropy of the distribution of component parts in the training data. We\nformalize a framework for measuring entropy in a sequence-to-sequence task and\nfind that the performance of popular model architectures scales with the\nentropy. Our work connects systematic generalization to information efficiency,\nand our results indicate that success at high entropy can be achieved even\nwithout built-in priors, and that success at low entropy can serve as a target\nfor assessing progress towards robust systematic generalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.13089v2",
    "published": "2025-05-19T13:23:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13088v1",
    "title": "Cross-modal feature fusion for robust point cloud registration with ambiguous geometry",
    "authors": [
      "Zhaoyi Wang",
      "Shengyu Huang",
      "Jemil Avers Butt",
      "Yuanzhou Cai",
      "Matej Varga",
      "Andreas Wieser"
    ],
    "abstract": "Point cloud registration has seen significant advancements with the\napplication of deep learning techniques. However, existing approaches often\noverlook the potential of integrating radiometric information from RGB images.\nThis limitation reduces their effectiveness in aligning point clouds pairs,\nespecially in regions where geometric data alone is insufficient. When used\neffectively, radiometric information can enhance the registration process by\nproviding context that is missing from purely geometric data. In this paper, we\npropose CoFF, a novel Cross-modal Feature Fusion method that utilizes both\npoint cloud geometry and RGB images for pairwise point cloud registration.\nAssuming that the co-registration between point clouds and RGB images is\navailable, CoFF explicitly addresses the challenges where geometric information\nalone is unclear, such as in regions with symmetric similarity or planar\nstructures, through a two-stage fusion of 3D point cloud features and 2D image\nfeatures. It incorporates a cross-modal feature fusion module that assigns\npixel-wise image features to 3D input point clouds to enhance learned 3D point\nfeatures, and integrates patch-wise image features with superpoint features to\nimprove the quality of coarse matching. This is followed by a coarse-to-fine\nmatching module that accurately establishes correspondences using the fused\nfeatures. We extensively evaluate CoFF on four common datasets: 3DMatch,\n3DLoMatch, IndoorLRS, and the recently released ScanNet++ datasets. In\naddition, we assess CoFF on specific subset datasets containing geometrically\nambiguous cases. Our experimental results demonstrate that CoFF achieves\nstate-of-the-art registration performance across all benchmarks, including\nremarkable registration recalls of 95.9% and 81.6% on the widely-used 3DMatch\nand 3DLoMatch datasets, respectively...(Truncated to fit arXiv abstract length)",
    "pdf_url": "http://arxiv.org/pdf/2505.13088v1",
    "published": "2025-05-19T13:22:46+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13087v1",
    "title": "Graph Alignment for Benchmarking Graph Neural Networks and Learning Positional Encodings",
    "authors": [
      "Adrien Lagesse",
      "Marc Lelarge"
    ],
    "abstract": "We propose a novel benchmarking methodology for graph neural networks (GNNs)\nbased on the graph alignment problem, a combinatorial optimization task that\ngeneralizes graph isomorphism by aligning two unlabeled graphs to maximize\noverlapping edges. We frame this problem as a self-supervised learning task and\npresent several methods to generate graph alignment datasets using synthetic\nrandom graphs and real-world graph datasets from multiple domains. For a given\ngraph dataset, we generate a family of graph alignment datasets with increasing\ndifficulty, allowing us to rank the performance of various architectures. Our\nexperiments indicate that anisotropic graph neural networks outperform standard\nconvolutional architectures. To further demonstrate the utility of the graph\nalignment task, we show its effectiveness for unsupervised GNN pre-training,\nwhere the learned node embeddings outperform other positional encodings on\nthree molecular regression tasks and achieve state-of-the-art results on the\nPCQM4Mv2 dataset with significantly fewer parameters. To support\nreproducibility and further research, we provide an open-source Python package\nto generate graph alignment datasets and benchmark new GNN architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.13087v1",
    "published": "2025-05-19T13:22:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13086v1",
    "title": "Coupled integral equations method with open boundary conditions for calculation the characteristics of structured waveguides",
    "authors": [
      "M. I. Ayzatsky"
    ],
    "abstract": "The results of modification of the CASCIE code aimed at implementing open\nboundary conditions are presented. The accelerator section developed at CERN\nwas chosen as a prototype for the structured waveguide under testing. Results\nof testing the CASCIE-M code confirms that the implementation of matrix open\nboundary conditions gives possibility to consider the structure in which waves\nenter and exit without additional reflections from couplers. It was shown that\nthe dependence of the reflection coefficient on frequency differs from the\nsimilar dependence for a waveguide with couplers. It does not have a regular\nsequence of minimum and maximum values associated with reflections from the\ncouplers and the formation of resonance conditions. This indicates that the\nreflections are of a different nature and are associated with inhomogeneity.\nThe proposed modification of the coupled integral equation method allows us to\ninvestigate the accuracy of the field expansion on which coupled mode theory\ncan be constructed that describes structured waveguides.",
    "pdf_url": "http://arxiv.org/pdf/2505.13086v1",
    "published": "2025-05-19T13:21:07+00:00",
    "categories": [
      "physics.acc-ph",
      "physics.comp-ph",
      "physics.optics"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13085v2",
    "title": "Universal Semantic Disentangled Privacy-preserving Speech Representation Learning",
    "authors": [
      "Biel Tura Vecino",
      "Subhadeep Maji",
      "Aravind Varier",
      "Antonio Bonafonte",
      "Ivan Valles",
      "Michael Owen",
      "Leif R√§del",
      "Grant Strimel",
      "Seyi Feyisetan",
      "Roberto Barra Chicote",
      "Ariya Rastrow",
      "Constantinos Papayiannis",
      "Volker Leutnant",
      "Trevor Wood"
    ],
    "abstract": "The use of audio recordings of human speech to train LLMs poses privacy\nconcerns due to these models' potential to generate outputs that closely\nresemble artifacts in the training data. In this study, we propose a speaker\nprivacy-preserving representation learning method through the Universal Speech\nCodec (USC), a computationally efficient encoder-decoder model that\ndisentangles speech into: (i) privacy-preserving semantically rich\nrepresentations, capturing content and speech paralinguistics, and (ii)\nresidual acoustic and speaker representations that enables high-fidelity\nreconstruction. Extensive evaluations presented show that USC's semantic\nrepresentation preserves content, prosody, and sentiment, while removing\npotentially identifiable speaker attributes. Combining both representations,\nUSC achieves state-of-the-art speech reconstruction. Additionally, we introduce\nan evaluation methodology for measuring privacy-preserving properties, aligning\nwith perceptual tests. We compare USC against other codecs in the literature\nand demonstrate its effectiveness on privacy-preserving representation\nlearning, illustrating the trade-offs of speaker anonymization, paralinguistics\nretention and content preservation in the learned semantic representations.\nAudio samples are shared in https://www.amazon.science/usc-samples.",
    "pdf_url": "http://arxiv.org/pdf/2505.13085v2",
    "published": "2025-05-19T13:19:49+00:00",
    "categories": [
      "eess.AS",
      "cs.LG"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13571v1",
    "title": "Autonomous nanoparticle synthesis by design",
    "authors": [
      "Andy S. Anker",
      "Jonas H. Jensen",
      "Miguel Gonzalez-Duque",
      "Rodrigo Moreno",
      "Aleksandra Smolska",
      "Mikkel Juelsholt",
      "Vincent Hardion",
      "Mads R. V. Jorgensen",
      "Andres Faina",
      "Jonathan Quinson",
      "Kasper Stoy",
      "Tejs Vegge"
    ],
    "abstract": "Controlled synthesis of materials with specified atomic structures underpins\ntechnological advances yet remains reliant on iterative, trial-and-error\napproaches. Nanoparticles (NPs), whose atomic arrangement dictates their\nemergent properties, are particularly challenging to synthesise due to numerous\ntunable parameters. Here, we introduce an autonomous approach explicitly\ntargeting synthesis of atomic-scale structures. Our method autonomously designs\nsynthesis protocols by matching real time experimental total scattering (TS)\nand pair distribution function (PDF) data to simulated target patterns, without\nrequiring prior synthesis knowledge. We demonstrate this capability at a\nsynchrotron, successfully synthesising two structurally distinct gold NPs: 5 nm\ndecahedral and 10 nm face-centred cubic structures. Ultimately, specifying a\nsimulated target scattering pattern, thus representing a bespoke atomic\nstructure, and obtaining both the synthesised material and its reproducible\nsynthesis protocol on demand may revolutionise materials design. Thus,\nScatterLab provides a generalisable blueprint for autonomous, atomic\nstructure-targeted synthesis across diverse systems and applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.13571v1",
    "published": "2025-05-19T13:19:30+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.13084v1",
    "title": "Thermodynamic parameters of fluids on conformally connected spacetimes",
    "authors": [
      "Bhera Ram",
      "Bibhas Ranjan Majhi"
    ],
    "abstract": "Local thermal equilibrium generally implies the absence of heat flux within a\nfluid. We find the relations between a set of thermodynamic variables of a\nfluid on a general spacetime and those defined on a conformally connected\nspacetime, assuming both descriptions are at thermal equilibrium. The scaling\nrelations appear to be consistent with Dicke's heuristic argument and the\nprevious analysis done on the basis of various restrictions. Within the present\nframework, it is observed that the satisfaction of Klein's law on one of the\nspacetimes implies its validity on the other one. Moreover, our analysis\nbypasses some of the imposed restrictions and thereby reveals the generality of\nthe earlier predictions. These relations are further shown to preserve the\ngeometric structure of thermodynamics, known as geometrothermodynamics, such\nthat the associated metrics on two conformally connected spacetimes are\nthemselves conformally related. This provides an alternative consistency check\nas well as a distinct geometric interpretation of the relations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13084v1",
    "published": "2025-05-19T13:17:52+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.13083v1",
    "title": "Seismic Isolation of Optical Tables Using Piezo Actuators",
    "authors": [
      "Tailong Wang",
      "Carl Blair",
      "Ammar Al-Jodah",
      "John Winterflood",
      "Jian Liu",
      "Alexander Adams",
      "Aaron Goodwin-Jones",
      "Chunnong Zhao",
      "Li Ju"
    ],
    "abstract": "Seismic isolation is crucial for gravitational wave detectors as it minimizes\nground vibrations, enabling the detection of faint gravitational wave signals.\nAn active seismic isolation platform for precision measurement experiments is\ndescribed. The table features piezo actuation along five degrees of freedom:\nthree translational actuations and two tip-tilt degrees of freedom along the\nhorizontal axes. It is stiff in rotation about the vertical axes. A seismometer\nis used to sense table motion. Piezo actuators are used to suppress seismic\nnoise with feedback control bandwidth of 0.3 to 3 Hz. Suppression levels\nranging from 21 to 36 dB of seismic noise within the frequency range of 0.5 to\n1.3 Hz are demonstrated, as measured by a witness seismometer on the table,\nwith the suppression direction along the axis of the longitudinal translation\nof the suspended mirror on the table. The suppression results in 1\n$\\mathrm{\\mathrm{nm/\\sqrt{Hz}}}$ residual horizontal motion at 1 Hz.\nLimitations such as tilt-to-translation coupling that prevent actuation over\nthe desired range of 0.03 to 3 Hz are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.13083v1",
    "published": "2025-05-19T13:17:31+00:00",
    "categories": [
      "astro-ph.IM",
      "physics.ins-det"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.13082v1",
    "title": "MultiActor-Audiobook: Zero-Shot Audiobook Generation with Faces and Voices of Multiple Speakers",
    "authors": [
      "Kyeongman Park",
      "Seongho Joo",
      "Kyomin Jung"
    ],
    "abstract": "We introduce MultiActor-Audiobook, a zero-shot approach for generating\naudiobooks that automatically produces consistent, expressive, and\nspeaker-appropriate prosody, including intonation and emotion. Previous\naudiobook systems have several limitations: they require users to manually\nconfigure the speaker's prosody, read each sentence with a monotonic tone\ncompared to voice actors, or rely on costly training. However, our\nMultiActor-Audiobook addresses these issues by introducing two novel processes:\n(1) MSP (**Multimodal Speaker Persona Generation**) and (2) LSI (**LLM-based\nScript Instruction Generation**). With these two processes,\nMultiActor-Audiobook can generate more emotionally expressive audiobooks with a\nconsistent speaker prosody without additional training. We compare our system\nwith commercial products, through human and MLLM evaluations, achieving\ncompetitive results. Furthermore, we demonstrate the effectiveness of MSP and\nLSI through ablation studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.13082v1",
    "published": "2025-05-19T13:13:46+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.13081v1",
    "title": "Walking the Tightrope: Disentangling Beneficial and Detrimental Drifts in Non-Stationary Custom-Tuning",
    "authors": [
      "Xiaoyu Yang",
      "Jie Lu",
      "En Yu"
    ],
    "abstract": "This paper uncovers a critical yet overlooked phenomenon in multi-modal large\nlanguage models (MLLMs): detrimental concept drift within chain-of-thought\n(CoT) reasoning during non-stationary reinforcement fine-tuning (RFT), where\nreasoning token distributions evolve unpredictably, thereby introducing\nsignificant biases in final predictions. To address this, we are pioneers in\nestablishing the theoretical bridge between concept drift theory and RFT\nprocesses by formalizing CoT's autoregressive token streams as non-stationary\ndistributions undergoing arbitrary temporal shifts. Leveraging this framework,\nwe propose a novel counterfact-aware RFT that systematically decouples\nbeneficial distribution adaptation from harmful concept drift through concept\ngraph-empowered LLM experts generating counterfactual reasoning trajectories.\nOur solution, Counterfactual Preference Optimization (CPO), enables stable RFT\nin non-stationary environments, particularly within the medical domain, through\ncustom-tuning of counterfactual-aware preference alignment. Extensive\nexperiments demonstrate our superior performance of robustness, generalization\nand coordination within RFT. Besides, we also contributed a large-scale dataset\nCXR-CounterFact (CCF), comprising 320,416 meticulously curated counterfactual\nreasoning trajectories derived from MIMIC-CXR. Our code and data are public.",
    "pdf_url": "http://arxiv.org/pdf/2505.13081v1",
    "published": "2025-05-19T13:13:38+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13080v2",
    "title": "Unifying concepts in information-theoretic time-series analysis",
    "authors": [
      "Annie G. Bryant",
      "Oliver M. Cliff",
      "James M. Shine",
      "Ben D. Fulcher",
      "Joseph T. Lizier"
    ],
    "abstract": "Information theory is a powerful framework for quantifying complexity,\nuncertainty, and dynamical structure in time-series data, with widespread\napplicability across disciplines such as physics, finance, and neuroscience.\nHowever, the literature on these measures remains fragmented, with\ndomain-specific terminologies, inconsistent mathematical notation, and\ndisparate visualization conventions that hinder interdisciplinary integration.\nThis work addresses these challenges by unifying key information-theoretic\ntime-series measures through shared semantic definitions, standardized\nmathematical notation, and cohesive visual representations. We compare these\nmeasures in terms of their theoretical foundations, computational formulations,\nand practical interpretability -- mapping them onto a common conceptual space\nthrough an illustrative case study with functional magnetic resonance imaging\ntime series in the brain. This case study exemplifies the complementary\ninsights these measures offer in characterizing the dynamics of complex neural\nsystems, such as signal complexity and information flow. By providing a\nstructured synthesis, our work aims to enhance interdisciplinary dialogue and\nmethodological adoption, which is particularly critical for reproducibility and\ninteroperability in computational neuroscience. More broadly, our framework\nserves as a resource for researchers seeking to navigate and apply\ninformation-theoretic time-series measures to diverse complex systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13080v2",
    "published": "2025-05-19T13:13:30+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13079v1",
    "title": "Cross-modal Knowledge Transfer Learning as Graph Matching Based on Optimal Transport for ASR",
    "authors": [
      "Xugang Lu",
      "Peng Shen",
      "Yu Tsao",
      "Hisashi Kawai"
    ],
    "abstract": "Transferring linguistic knowledge from a pretrained language model (PLM) to\nacoustic feature learning has proven effective in enhancing end-to-end\nautomatic speech recognition (E2E-ASR). However, aligning representations\nbetween linguistic and acoustic modalities remains a challenge due to inherent\nmodality gaps. Optimal transport (OT) has shown promise in mitigating these\ngaps by minimizing the Wasserstein distance (WD) between linguistic and\nacoustic feature distributions. However, previous OT-based methods overlook\nstructural relationships, treating feature vectors as unordered sets. To\naddress this, we propose Graph Matching Optimal Transport (GM-OT), which models\nlinguistic and acoustic sequences as structured graphs. Nodes represent feature\nembeddings, while edges capture temporal and sequential relationships. GM-OT\nminimizes both WD (between nodes) and Gromov-Wasserstein distance (GWD)\n(between edges), leading to a fused Gromov-Wasserstein distance (FGWD)\nformulation. This enables structured alignment and more efficient knowledge\ntransfer compared to existing OT-based approaches. Theoretical analysis further\nshows that prior OT-based methods in linguistic knowledge transfer can be\nviewed as a special case within our GM-OT framework. We evaluate GM-OT on\nMandarin ASR using a CTC-based E2E-ASR system with a PLM for knowledge\ntransfer. Experimental results demonstrate significant performance gains over\nstate-of-the-art models, validating the effectiveness of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.13079v1",
    "published": "2025-05-19T13:13:18+00:00",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13078v1",
    "title": "Stochastic Orthogonal Regularization for deep projective priors",
    "authors": [
      "Ali Joundi",
      "Yann Traonmilin",
      "Alasdair Newson"
    ],
    "abstract": "Many crucial tasks of image processing and computer vision are formulated as\ninverse problems. Thus, it is of great importance to design fast and robust\nalgorithms to solve these problems. In this paper, we focus on generalized\nprojected gradient descent (GPGD) algorithms where generalized projections are\nrealized with learned neural networks and provide state-of-the-art results for\nimaging inverse problems. Indeed, neural networks allow for projections onto\nunknown low-dimensional sets that model complex data, such as images. We call\nthese projections deep projective priors. In generic settings, when the\northogonal projection onto a lowdimensional model set is used, it has been\nshown, under a restricted isometry assumption, that the corresponding\northogonal PGD converges with a linear rate, yielding near-optimal convergence\n(within the class of GPGD methods) in the classical case of sparse recovery.\nHowever, for deep projective priors trained with classical mean squared error\nlosses, there is little guarantee that the hypotheses for linear convergence\nare satisfied. In this paper, we propose a stochastic orthogonal regularization\nof the training loss for deep projective priors. This regularization is\nmotivated by our theoretical results: a sufficiently good approximation of the\northogonal projection guarantees linear stable recovery with performance close\nto orthogonal PGD. We show experimentally, using two different deep projective\npriors (based on autoencoders and on denoising networks), that our stochastic\northogonal regularization yields projections that improve convergence speed and\nrobustness of GPGD in challenging inverse problem settings, in accordance with\nour theoretical findings.",
    "pdf_url": "http://arxiv.org/pdf/2505.13078v1",
    "published": "2025-05-19T13:12:01+00:00",
    "categories": [
      "eess.IV",
      "cs.NE",
      "math.OC"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13077v2",
    "title": "Advancing Sequential Numerical Prediction in Autoregressive Models",
    "authors": [
      "Xiang Fei",
      "Jinghui Lu",
      "Qi Sun",
      "Hao Feng",
      "Yanjie Wang",
      "Wei Shi",
      "An-Lan Wang",
      "Jingqun Tang",
      "Can Huang"
    ],
    "abstract": "Autoregressive models have become the de facto choice for sequence generation\ntasks, but standard approaches treat digits as independent tokens and apply\ncross-entropy loss, overlooking the coherent structure of numerical sequences.\nThis paper introduces Numerical Token Integrity Loss (NTIL) to address this\ngap. NTIL operates at two levels: (1) token-level, where it extends the Earth\nMover's Distance (EMD) to preserve ordinal relationships between numerical\nvalues, and (2) sequence-level, where it penalizes the overall discrepancy\nbetween the predicted and actual sequences. This dual approach improves\nnumerical prediction and integrates effectively with LLMs/MLLMs. Extensive\nexperiments show significant performance improvements with NTIL.",
    "pdf_url": "http://arxiv.org/pdf/2505.13077v2",
    "published": "2025-05-19T13:11:28+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13076v1",
    "title": "The Hidden Dangers of Browsing AI Agents",
    "authors": [
      "Mykyta Mudryi",
      "Markiyan Chaklosh",
      "Grzegorz W√≥jcik"
    ],
    "abstract": "Autonomous browsing agents powered by large language models (LLMs) are\nincreasingly used to automate web-based tasks. However, their reliance on\ndynamic content, tool execution, and user-provided data exposes them to a broad\nattack surface. This paper presents a comprehensive security evaluation of such\nagents, focusing on systemic vulnerabilities across multiple architectural\nlayers. Our work outlines the first end-to-end threat model for browsing agents\nand provides actionable guidance for securing their deployment in real-world\nenvironments. To address discovered threats, we propose a defense in depth\nstrategy incorporating input sanitization, planner executor isolation, formal\nanalyzers, and session safeguards. These measures protect against both initial\naccess and post exploitation attack vectors. Through a white box analysis of a\npopular open source project, Browser Use, we demonstrate how untrusted web\ncontent can hijack agent behavior and lead to critical security breaches. Our\nfindings include prompt injection, domain validation bypass, and credential\nexfiltration, evidenced by a disclosed CVE and a working proof of concept\nexploit.",
    "pdf_url": "http://arxiv.org/pdf/2505.13076v1",
    "published": "2025-05-19T13:10:29+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13075v1",
    "title": "Microscopic Ghost Imaging with a Tabletop XUV Source",
    "authors": [
      "Sukyoon Oh",
      "Monalisa Mallick",
      "Thomas Siefke",
      "Christian Spielmann"
    ],
    "abstract": "This study introduces a novel lensless imaging approach in the extreme\nultraviolet spectral range, utilizing ghost imaging techniques and a compact\ntabletop high-harmonic generation source. By eliminating conventional lenses\nand optics, this method enables high-resolution, low-dose imaging while\nreducing the complexity and cost associated with large-scale facilities. We\nevaluated the performance of various illumination patterns, including random,\nHadamard, and Fourier patterns, in combination with different reconstruction\nalgorithms such as traditional ghost imaging and compressive sensing. Our\nfindings indicate that structured Hadamard patterns, coupled with compressive\nsensing algorithms, produce high-quality images, allowing for the\nreconstruction of detailed microscopic features. Furthermore, we analyzed the\ninfluence of experimental factors such as sample quality, pattern alignment,\nand noise reduction techniques on image fidelity. This research highlights the\npotential of lensless tabletop extreme ultraviolet ghost imaging for\nhigh-resolution, low-dose applications in materials science, biology, and\nnanotechnology.",
    "pdf_url": "http://arxiv.org/pdf/2505.13075v1",
    "published": "2025-05-19T13:10:18+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.13074v4",
    "title": "RGE effects on new physics searches via gravitational waves",
    "authors": [
      "Katsuya Hashino",
      "Daiki Ueda"
    ],
    "abstract": "Gravitational wave (GW) observations offer a promising probe of new physics\nassociated with a first-order electroweak phase transition. Precision studies\nof the Higgs potential, including Fisher matrix analyses, have been extensively\nconducted in this context. However, significant theoretical uncertainties in\nthe GW spectrum, particularly those due to renormalization scale dependence in\nthe conventional daisy-resummed approach, have cast doubt on the reliability of\nsuch precision measurements. These uncertainties have been highlighted using\nthe Standard Model Effective Field Theory (SMEFT) as a benchmark. To address\nthese issues, we revisit Fisher matrix analyses based on the daisy-resummed\napproach, explicitly incorporating renormalization scale uncertainties. We then\nreassess the prospects for precise new physics measurements using GW\nobservations. Adopting the SMEFT as a benchmark, we study the effects of\none-loop RGE running of dimension-six operators on the Higgs effective\npotential via the Higgs self-couplings, top Yukawa coupling, and gauge\ncouplings, in addition to the SMEFT tree-level effects. We find that future GW\nobservations can remain sensitive to various dimension-six SMEFT effects, even\nin the presence of renormalization scale uncertainties, provided that the SMEFT\n$(H^{\\dagger}H)^3$ operator is precisely measured, e.g., by future collider\nexperiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.13074v4",
    "published": "2025-05-19T13:09:42+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.HE",
      "hep-ex",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13073v1",
    "title": "Structure-Aware Corpus Construction and User-Perception-Aligned Metrics for Large-Language-Model Code Completion",
    "authors": [
      "Dengfeng Liu",
      "Jucai Zhai",
      "Xiaoguang Jiang",
      "Ziqun Li",
      "Qianjin Yu",
      "Feng Liu",
      "Rui Ye",
      "Huang Liu",
      "Zhiguo Yang",
      "Yongsheng Du",
      "Fang Tan"
    ],
    "abstract": "Code completion technology based on large language model has significantly\nimproved the development efficiency of programmers. However, in practical\napplications, there remains a gap between current commonly used code completion\nevaluation metrics and users' actual perception. To address this issue, we\npropose two evaluation metrics for code completion tasks--LCP and ROUGE-LCP,\nfrom the perspective of probabilistic modeling. Furthermore, to tackle the lack\nof effective structural semantic modeling and cross-module dependency\ninformation in LLMs for repository-level code completion scenarios, we propose\na data processing method based on a Structure-Preserving and\nSemantically-Reordered Code Graph (SPSR-Graph). Through theoretical analysis\nand experimental validation, we demonstrate the superiority of the proposed\nevaluation metrics in terms of user perception consistency, as well as the\neffectiveness of the data processing method in enhancing model performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.13073v1",
    "published": "2025-05-19T13:09:32+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13072v1",
    "title": "Orthogonal Survival Learners for Estimating Heterogeneous Treatment Effects from Time-to-Event Data",
    "authors": [
      "Dennis Frauen",
      "Maresa Schr√∂der",
      "Konstantin Hess",
      "Stefan Feuerriegel"
    ],
    "abstract": "Estimating heterogeneous treatment effects (HTEs) is crucial for personalized\ndecision-making. However, this task is challenging in survival analysis, which\nincludes time-to-event data with censored outcomes (e.g., due to study\ndropout). In this paper, we propose a toolbox of novel orthogonal survival\nlearners to estimate HTEs from time-to-event data under censoring. Our learners\nhave three main advantages: (i) we show that learners from our toolbox are\nguaranteed to be orthogonal and thus come with favorable theoretical\nproperties; (ii) our toolbox allows for incorporating a custom weighting\nfunction, which can lead to robustness against different types of low overlap,\nand (iii) our learners are model-agnostic (i.e., they can be combined with\narbitrary machine learning models). We instantiate the learners from our\ntoolbox using several weighting functions and, as a result, propose various\nneural orthogonal survival learners. Some of these coincide with existing\nsurvival learners (including survival versions of the DR- and R-learner), while\nothers are novel and further robust w.r.t. low overlap regimes specific to the\nsurvival setting (i.e., survival overlap and censoring overlap). We then\nempirically verify the effectiveness of our learners for HTE estimation in\ndifferent low-overlap regimes through numerical experiments. In sum, we provide\npractitioners with a large toolbox of learners that can be used for randomized\nand observational studies with censored time-to-event data.",
    "pdf_url": "http://arxiv.org/pdf/2505.13072v1",
    "published": "2025-05-19T13:06:41+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13071v1",
    "title": "OmniFC: Rethinking Federated Clustering via Lossless and Secure Distance Reconstruction",
    "authors": [
      "Jie Yan",
      "Xin Liu",
      "Zhong-Yuan Zhang"
    ],
    "abstract": "Federated clustering (FC) aims to discover global cluster structures across\ndecentralized clients without sharing raw data, making privacy preservation a\nfundamental requirement. There are two critical challenges: (1) privacy leakage\nduring collaboration, and (2) robustness degradation due to aggregation of\nproxy information from non-independent and identically distributed (Non-IID)\nlocal data, leading to inaccurate or inconsistent global clustering. Existing\nsolutions typically rely on model-specific local proxies, which are sensitive\nto data heterogeneity and inherit inductive biases from their centralized\ncounterparts, thus limiting robustness and generality. We propose Omni\nFederated Clustering (OmniFC), a unified and model-agnostic framework.\nLeveraging Lagrange coded computing, our method enables clients to share only\nencoded data, allowing exact reconstruction of the global distance matrix--a\nfundamental representation of sample relationships--without leaking private\ninformation, even under client collusion. This construction is naturally\nresilient to Non-IID data distributions. This approach decouples FC from\nmodel-specific proxies, providing a unified extension mechanism applicable to\ndiverse centralized clustering methods. Theoretical analysis confirms both\nreconstruction fidelity and privacy guarantees, while comprehensive experiments\ndemonstrate OmniFC's superior robustness, effectiveness, and generality across\nvarious benchmarks compared to state-of-the-art methods. Code will be released.",
    "pdf_url": "http://arxiv.org/pdf/2505.13071v1",
    "published": "2025-05-19T13:04:59+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13070v1",
    "title": "RSS-Based Localization: Ensuring Consistency and Asymptotic Efficiency",
    "authors": [
      "Shenghua Hu",
      "Guangyang Zeng",
      "Wenchao Xue",
      "Haitao Fang",
      "Junfeng Wu",
      "Biqiang Mu"
    ],
    "abstract": "We study the problem of signal source localization using received signal\nstrength measurements. We begin by presenting verifiable geometric conditions\nfor sensor deployment that ensure the model's asymptotic localizability. Then\nwe establish the consistency and asymptotic efficiency of the maximum\nlikelihood (ML) estimator. However, computing the ML estimator is challenging\ndue to its reliance on solving a non-convex optimization problem. To overcome\nthis, we propose a two-step estimator that retains the same asymptotic\nproperties as the ML estimator while offering low computational complexity,\nlinear in the number of measurements. The main challenge lies in obtaining a\nconsistent estimator in the first step. To address this, we construct two\nlinear least-squares estimation problems by applying algebraic transformations\nto the nonlinear measurement model, leading to closed-form solutions. In the\nsecond step, we perform a single Gauss-Newton iteration using the consistent\nestimator from the first step as the initialization, achieving the same\nasymptotic efficiency as the ML estimator. Finally, simulation results validate\nthe theoretical property and practical effectiveness of the proposed two-step\nestimator.",
    "pdf_url": "http://arxiv.org/pdf/2505.13070v1",
    "published": "2025-05-19T13:04:51+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13069v1",
    "title": "Suicide Risk Assessment Using Multimodal Speech Features: A Study on the SW1 Challenge Dataset",
    "authors": [
      "Ambre Marie",
      "Ilias Maoudj",
      "Guillaume Dardenne",
      "Gwenol√© Quellec"
    ],
    "abstract": "The 1st SpeechWellness Challenge conveys the need for speech-based suicide\nrisk assessment in adolescents. This study investigates a multimodal approach\nfor this challenge, integrating automatic transcription with WhisperX,\nlinguistic embeddings from Chinese RoBERTa, and audio embeddings from WavLM.\nAdditionally, handcrafted acoustic features -- including MFCCs, spectral\ncontrast, and pitch-related statistics -- were incorporated. We explored three\nfusion strategies: early concatenation, modality-specific processing, and\nweighted attention with mixup regularization. Results show that weighted\nattention provided the best generalization, achieving 69% accuracy on the\ndevelopment set, though a performance gap between development and test sets\nhighlights generalization challenges. Our findings, strictly tied to the\nMINI-KID framework, emphasize the importance of refining embedding\nrepresentations and fusion mechanisms to enhance classification reliability.",
    "pdf_url": "http://arxiv.org/pdf/2505.13069v1",
    "published": "2025-05-19T13:04:37+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS",
      "I.2.7; I.5.1"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13068v1",
    "title": "Revisiting the Slip Boundary Condition: Surface Roughness as a Hidden Tuning Parameter",
    "authors": [
      "Matthias Maier",
      "Peter Munch",
      "Murtazo Nazarov"
    ],
    "abstract": "In this paper, we investigate the effect of boundary surface roughness on\nnumerical simulations of incompressible fluid flow past a cylinder in two and\nthree spatial dimensions furnished with slip boundary conditions. The governing\nequations are approximated using a continuous finite element method, stabilized\nwith a Galerkin least-squares approach.\n  Through a series of numerical experiments, we demonstrate that: $(i)$ the\nintroduction of surface roughness through numerical discretization error, or\nmesh distortion, makes the potential flow solution unstable; $(ii)$ when\nnumerical surface roughness and mesh distortion are minimized by using\nhigh-order isoparametric geometry mappings, a stable potential flow is obtained\nin both two and three dimensions; $(iii)$ numerical surface roughness, mesh\ndistortion and refinement level can be used as control parameters to manipulate\ndrag and lift forces resulting in numerical values spanning more than an order\nof magnitude.\n  Our results cast some doubt on the predictive capability of the slip boundary\ncondition for wall modeling in turbulent simulations of incompressible flow.",
    "pdf_url": "http://arxiv.org/pdf/2505.13068v1",
    "published": "2025-05-19T13:04:32+00:00",
    "categories": [
      "physics.flu-dyn",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.13067v1",
    "title": "Verifying Quantum Memory in the Dynamics of Spin Boson Models",
    "authors": [
      "Charlotte B√§cker",
      "Valentin Link",
      "Walter T. Strunz"
    ],
    "abstract": "We investigate the nature of memory effects in the non-Markovian dynamics of\nspin boson models. Local quantum memory criteria can be used to indicate that\nthe reduced dynamics of an open system necessarily requires a quantum memory in\nits environment. We apply two such criteria, derived from different definitions\nput forward in the literature, to spin boson and two-spin boson models. For the\ncomputation of dynamical maps and process tensors, we employ a numerically\nexact method for non-Markovian open system dynamics based on matrix product\noperator influence functionals, that can be applied across broad parameter\nregimes. We find that, with access to single-intervention process tensors, one\ncan generally predict quantum memory in the dynamics at low temperatures. Given\ninstead only the dynamical map, we are still able to detect quantum memory in\nthe case of resonant environments at short evolution times. Moreover, we\nconfirm quantum memory in the stationary dynamical regime using process tensors\nwith the correlated steady state of system and environment as initial\ncondition.",
    "pdf_url": "http://arxiv.org/pdf/2505.13067v1",
    "published": "2025-05-19T13:02:41+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13570v2",
    "title": "Minimax Rates of Estimation for Optimal Transport Map between Infinite-Dimensional Spaces",
    "authors": [
      "Donlapark Ponnoprat",
      "Masaaki Imaizumi"
    ],
    "abstract": "We investigate the estimation of an optimal transport map between probability\nmeasures on an infinite-dimensional space and reveal its minimax optimal rate.\nOptimal transport theory defines distances within a space of probability\nmeasures, utilizing an optimal transport map as its key component. Estimating\nthe optimal transport map from samples finds several applications, such as\nsimulating dynamics between probability measures and functional data analysis.\nHowever, some transport maps on infinite-dimensional spaces require\nexponential-order data for estimation, which undermines their applicability. In\nthis paper, we investigate the estimation of an optimal transport map between\ninfinite-dimensional spaces, focusing on optimal transport maps characterized\nby the notion of $\\gamma$-smoothness. Consequently, we show that the order of\nthe minimax risk is polynomial rate in the sample size even in the\ninfinite-dimensional setup. We also develop an estimator whose estimation error\nmatches the minimax optimal rate. With these results, we obtain a class of\nreasonably estimable optimal transport maps on infinite-dimensional spaces and\na method for their estimation. Our experiments validate the theory and\npractical utility of our approach with application to functional data analysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.13570v2",
    "published": "2025-05-19T13:00:29+00:00",
    "categories": [
      "math.ST",
      "stat.ML",
      "stat.TH",
      "62G05"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.13066v2",
    "title": "Retention of surface water on tidally locked rocky planets in the Venus zone around M dwarfs",
    "authors": [
      "Yueyun Ouyang",
      "Feng Ding",
      "Jun Yang"
    ],
    "abstract": "Terrestrial planets within the Venus zone surrounding M dwarf stars can\nretain surface ice caps on the perpetual dark side if atmospheric heat\ntransport is inefficient, {as suggested by previous global climate simulations\n\\citep[e.g.,][]{leconte2013}.} This condition is {proposed} to play a role in\nthe potential regional habitability of these planets. However, the amount of\nsurface ice may be limited by considering the water condensed from the steam\natmosphere in a runaway greenhouse state, and the physical mechanism for\ntriggering the condensation process is not clear. Here, we use a two-column\nmoist radiative-convective-subsiding model to investigate the water\ncondensation process on tidally locked planets from the runaway greenhouse\nstate. We find that the water condensation process is characterized by two\ndistinct equilibrium states under the same {incoming stellar flux}. The\ninitiation of condensation corresponds to a warm, unstable state exhibiting\npositive Planck feedback, whereas the termination phase corresponds to a cold,\nstable state exhibiting negative Planck feedback. We further show that the\nsurface water mass in the collapsed state {decreases with the} incoming stellar\nflux, background surface pressure, and optical thickness of non-condensible\ngreenhouse gases, with a global equivalent depth of less than $\\sim 20$ cm. Our\ntwo-column approach provides a straightforward way to understand the water\nevolution on Venus zone planets around M dwarfs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13066v2",
    "published": "2025-05-19T12:57:20+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13065v1",
    "title": "Anomalous Temperature Dependence of Quantum-Geometric Superfluid Weight",
    "authors": [
      "Yuma Hirobe",
      "Taisei Kitamura",
      "Youichi Yanase"
    ],
    "abstract": "The symmetry of Cooper pairs encodes key information about superconductivity\nand has been widely studied through the temperature dependence of the\nsuperfluid weight. However, in systems dominated by quantum geometry,\nconventional theories miss its essential properties. We study the temperature\ndependence of the quantum-geometric superfluid weight and classify the\nrelationship to the superconducting symmetry and band structures. The obtained\npower laws are different from conventional behavior, and unconventional\nsuperconductivity in twisted multilayer graphene is discussed. Our findings\nprovide insights into the superconducting symmetry and the pairing mechanism\nvia quantum geometry.",
    "pdf_url": "http://arxiv.org/pdf/2505.13065v1",
    "published": "2025-05-19T12:54:46+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.13064v1",
    "title": "When do Lyapunov Subcenter Manifolds become Eigenmanifolds?",
    "authors": [
      "Yannik P. Wotte",
      "Arne Sachtler",
      "Alin Albu-Sch√§ffer",
      "Stefano Stramigioli",
      "Cosimo Della Santina"
    ],
    "abstract": "Multi-body mechanical systems have rich internal dynamics, which can be\nexploited to formulate efficient control targets. For periodic regulation tasks\nin robotics applications, this motivated the extension of the theory on\nnonlinear normal modes to Riemannian manifolds, and led to the definition of\nEigenmanifolds. This definition is geometric, which is advantageous for\ngenerality within robotics but also obscures the connection of Eigenmanifolds\nto a large body of results from the literature on nonlinear dynamics. We bridge\nthis gap, showing that Eigenmanifolds are instances of Lyapunov subcenter\nmanifolds (LSMs), and that their stronger geometric properties with respect to\nLSMs follow from a time-symmetry of conservative mechanical systems. This\ndirectly leads to local existence and uniqueness results for Eigenmanifolds.\nFurthermore, we show that an additional spatial symmetry provides\nEigenmanifolds with yet stronger properties of Rosenberg manifolds, which can\nbe favorable for control applications, and we present a sufficient condition\nfor their existence and uniqueness. These theoretical results are numerically\nconfirmed on two mechanical systems with a non-constant inertia tensor: a\ndouble pendulum and a 5-link pendulum.",
    "pdf_url": "http://arxiv.org/pdf/2505.13064v1",
    "published": "2025-05-19T12:54:03+00:00",
    "categories": [
      "math.DS",
      "cs.RO"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13063v1",
    "title": "A continuous calibration of the ATLAS flavour-tagging classifiers via optimal transportation maps",
    "authors": [
      "ATLAS Collaboration"
    ],
    "abstract": "A calibration of the ATLAS flavour-tagging algorithms using a new calibration\nprocedure based on optimal transportation maps is presented. Simultaneous,\ncontinuous corrections to the $b$-jet, $c$-jet, and light-flavour jet\nclassification probabilities from jet-tagging algorithms in simulation are\nderived for $b$-jets using $t\\bar t \\to e\\mu\\nu\\nu bb$ data. After application\nof the derived calibration maps, closure between simulation and observation is\nachieved for jet flavour observables used in ATLAS analyses of Large Hadron\nCollider (LHC) Run 2 proton-proton collision data. This continuous calibration\nopens up new possibilities for the future use of jet flavour information in LHC\nanalyses and also serves as a guide for deriving high-dimensional corrections\nto simulation via transportation maps, an important development for a broad\nrange of inference tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13063v1",
    "published": "2025-05-19T12:53:19+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.13062v3",
    "title": "Hearing from Silence: Reasoning Audio Descriptions from Silent Videos via Vision-Language Model",
    "authors": [
      "Yong Ren",
      "Chenxing Li",
      "Le Xu",
      "Hao Gu",
      "Duzhen Zhang",
      "Yujie Chen",
      "Manjie Xu",
      "Ruibo Fu",
      "Shan Yang",
      "Dong Yu"
    ],
    "abstract": "Humans can intuitively infer sounds from silent videos, but whether\nmultimodal large language models can perform modal-mismatch reasoning without\naccessing target modalities remains relatively unexplored. Current\ntext-assisted-video-to-audio (VT2A) methods excel in video foley tasks but\nstruggle to acquire audio descriptions during inference. We introduce the task\nof Reasoning Audio Descriptions from Silent Videos (SVAD) to address this\nchallenge and investigate vision-language models' (VLMs) capabilities on this\ntask. To further enhance the VLMs' reasoning capacity for the SVAD task, we\nconstruct a CoT-AudioCaps dataset and propose a Chain-of-Thought-based\nsupervised fine-tuning strategy. Experiments on SVAD and subsequent VT2A tasks\ndemonstrate our method's effectiveness in two key aspects: significantly\nimproving VLMs' modal-mismatch reasoning for SVAD and effectively addressing\nthe challenge of acquiring audio descriptions during VT2A inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.13062v3",
    "published": "2025-05-19T12:52:51+00:00",
    "categories": [
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2505.13061v3",
    "title": "3D Visual Illusion Depth Estimation",
    "authors": [
      "Chengtang Yao",
      "Zhidan Liu",
      "Jiaxi Zeng",
      "Lidong Yu",
      "Yuwei Wu",
      "Yunde Jia"
    ],
    "abstract": "3D visual illusion is a perceptual phenomenon where a two-dimensional plane\nis manipulated to simulate three-dimensional spatial relationships, making a\nflat artwork or object look three-dimensional in the human visual system. In\nthis paper, we reveal that the machine visual system is also seriously fooled\nby 3D visual illusions, including monocular and binocular depth estimation. In\norder to explore and analyze the impact of 3D visual illusion on depth\nestimation, we collect a large dataset containing almost 3k scenes and 200k\nimages to train and evaluate SOTA monocular and binocular depth estimation\nmethods. We also propose a robust depth estimation framework that uses common\nsense from a vision-language model to adaptively select reliable depth from\nbinocular disparity and monocular depth. Experiments show that SOTA monocular,\nbinocular, and multi-view depth estimation approaches are all fooled by various\n3D visual illusions, while our method achieves SOTA performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.13061v3",
    "published": "2025-05-19T12:51:03+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13060v1",
    "title": "Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs",
    "authors": [
      "Shmulik Markovich-Golan",
      "Daniel Ohayon",
      "Itay Niv",
      "Yair Hanani"
    ],
    "abstract": "Quantization is essential for Neural Network (NN) compression, reducing model\nsize and computational demands by using lower bit-width data types, though\naggressive reduction often hampers accuracy. Mixed Precision (MP) mitigates\nthis tradeoff by varying the numerical precision across network layers. This\nstudy focuses on automatically selecting an optimal MP configuration within\nPost-Training Quantization (PTQ) for inference. The first key contribution is a\nnovel sensitivity metric derived from a first-order Taylor series expansion of\nthe loss function as a function of quantization errors in weights and\nactivations. This metric, based on the Mean Square Error (MSE) of the loss, is\nefficiently calculated per layer using high-precision forward and backward\npasses over a small calibration dataset. The metric is additive across layers,\nwith low calibration memory overhead as weight optimization is unnecessary. The\nsecond contribution is an accurate hardware-aware method for predicting MP time\ngain by modeling it as additive for sequential sub-graphs. An algorithm\npartitions the model graph into sequential subgraphs, measuring time gain for\neach configuration using a few samples. After calibrating per-layer sensitivity\nand time gain, an Integer Programming (IP) problem is formulated to maximize\ntime gain while keeping loss MSE below a set threshold. Memory gain and\ntheoretical time gain based on Multiply and Accumulate (MAC) operations are\nalso considered. Rigorous experiments on the Intel Gaudi 2 accelerator validate\nthe approach on several Large Language Models (LLMs).",
    "pdf_url": "http://arxiv.org/pdf/2505.13060v1",
    "published": "2025-05-19T12:51:02+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13059v1",
    "title": "Bach-pinched metrics on closed manifolds",
    "authors": [
      "Letizia Branca",
      "Giovanni Catino",
      "Davide Dameno"
    ],
    "abstract": "Exploiting the deformation method introduced by Aubin in his seminal work to\nconstruct constant negative scalar curvature metrics, we show the existence, on\nevery closed manifold of dimension four, of a metric whose Bach tensor is\npinched by the scalar curvature.",
    "pdf_url": "http://arxiv.org/pdf/2505.13059v1",
    "published": "2025-05-19T12:46:37+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13058v2",
    "title": "A Path to Universal Neural Cellular Automata",
    "authors": [
      "Gabriel B√©na",
      "Maxence Faldor",
      "Dan F. M. Goodman",
      "Antoine Cully"
    ],
    "abstract": "Cellular automata have long been celebrated for their ability to generate\ncomplex behaviors from simple, local rules, with well-known discrete models\nlike Conway's Game of Life proven capable of universal computation. Recent\nadvancements have extended cellular automata into continuous domains, raising\nthe question of whether these systems retain the capacity for universal\ncomputation. In parallel, neural cellular automata have emerged as a powerful\nparadigm where rules are learned via gradient descent rather than manually\ndesigned. This work explores the potential of neural cellular automata to\ndevelop a continuous Universal Cellular Automaton through training by gradient\ndescent. We introduce a cellular automaton model, objective functions and\ntraining strategies to guide neural cellular automata toward universal\ncomputation in a continuous setting. Our experiments demonstrate the successful\ntraining of fundamental computational primitives - such as matrix\nmultiplication and transposition - culminating in the emulation of a neural\nnetwork solving the MNIST digit classification task directly within the\ncellular automata state. These results represent a foundational step toward\nrealizing analog general-purpose computers, with implications for understanding\nuniversal computation in continuous dynamics and advancing the automated\ndiscovery of complex cellular automata behaviors via machine learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.13058v2",
    "published": "2025-05-19T12:46:01+00:00",
    "categories": [
      "cs.LG",
      "cs.ET",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13057v1",
    "title": "Disorder-Driven Exceptional Points and Concurrent Topological Phase Transitions in Non-Hermitian Lattice",
    "authors": [
      "Xiaoyu Cheng",
      "Tiantao Qu",
      "Yaqing Yang",
      "Lei Zhang",
      "Jun Chen"
    ],
    "abstract": "Exceptional point (EP) and topological phase transition (TPT) in\nnon-Hermitian systems have recently garnered significant attention owing to\ntheir fundamental importance and potential applications in sensing and\ntopological devices. Beyond the EP induced by non-reciprocal hopping, we show\nthat random disorder can also drive the valence and conduction bands across\nEPs, even twice in the non-Hermitian regime. Remarkably, a TPT can occur\nconcurrently with an EP as disorder strength increases. These disorder-driven\nEPs and concurrent TPTs are well captured by effective medium theory. The\nanalysis reveals that their emergence results from the interplay between\ndisorder-induced energy level renormalization and non-reciprocal\nhopping-induced inter-level coupling, which fundamentally restructures the\nspectral properties of the system. The phase diagram in the parameter space of\nnon-reciprocal hopping and disorder strength identifies robust EP lines.\nInterestingly, two EP lines can emerge from the TPT point in the Hermitian\nlimit. As non-reciprocal hopping increases, these lines split, with one\naligning the TPT, leading to distinct disorder-induced EPs. Our results uncover\na robust, disorder-driven mechanism for generating EPs and concurrent TPTs,\noffering a new direction for exploring non-Hermitian topological matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.13057v1",
    "published": "2025-05-19T12:45:42+00:00",
    "categories": [
      "cond-mat.dis-nn"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.13056v1",
    "title": "Modelling the evolution and influence of dust in cosmological simulations that include the cold phase of the interstellar medium",
    "authors": [
      "James W. Trayford",
      "Joop Schaye",
      "Camila Correa",
      "Sylvia Ploeckinger",
      "Alexander J. Richings",
      "Evgenii Chaikin",
      "Matthieu Schaller",
      "Alejandro Benitez-Llambay",
      "Carlos Frenk",
      "Filip Husko"
    ],
    "abstract": "While marginal in mass terms, dust grains play an outsized role in both the\nphysics and observation of the interstellar medium (ISM). However, explicit\nmodelling of this ISM constituent remains uncommon in large cosmological\nsimulations. In this work, we present a model for the life-cycle of dust in the\nISM that couples to the forthcoming COLIBRE galaxy formation model, which\nexplicitly simulates the cold ISM. We follow 6 distinct grain types: 3 chemical\nspecies, including carbon and two silicate grains, with 2 size bins each. Our\ndust model accounts for seeding of grains from stellar ejecta, self-consistent\nelement-by-element metal yields and depletion, grain size transfer and\ndestruction of dust in the ISM. We detail the calibration of this model,\nparticularly the use of a clumping factor, to account for unresolved gas clouds\nin which dust readily evolves. We present a fiducial run in a 25$^3$~cMpc$^3$\ncosmological volume that displays good agreement with observations of the\ncosmic evolution of dust density, as well as the $z=0$ galaxy dust mass\nfunction and dust scaling relations. We highlight known tensions between\nobservational datasets of the dust-to-gas ratio as a function of metallicity\ndepending on which metallicity calibrator is used; our model favours\nhigher-normalisation metallicity calibrators, which agree with the observations\nwithin 0.1~dex for stellar masses $>10^9 \\; {\\rm M_\\odot}$. We compare the\ngrain size distribution to observations of local galaxies, and find that our\nsimulation suggests a higher concentration of small grains, associated with\nmore diffuse ISM and the warm-neutral medium (WNM), which both play a key role\nin boosting H$_2$ content. Putting these results and modelling approaches in\ncontext, we set the stage for upcoming insights into the dusty ISM of galaxies\nusing the COLIBRE simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13056v1",
    "published": "2025-05-19T12:44:17+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.13055v2",
    "title": "Simplicity is Key: An Unsupervised Pretraining Approach for Sparse Radio Channels",
    "authors": [
      "Jonathan Ott",
      "Maximilian Stahlke",
      "Tobias Feigl",
      "Bjoern M. Eskofier",
      "Christopher Mutschler"
    ],
    "abstract": "We introduce the Sparse pretrained Radio Transformer (SpaRTran), an\nunsupervised representation learning approach based on the concept of\ncompressed sensing for radio channels. Our approach learns embeddings that\nfocus on the physical properties of radio propagation, to create the optimal\nbasis for fine-tuning on radio-based downstream tasks. SpaRTran uses a sparse\ngated autoencoder that induces a simplicity bias to the learned\nrepresentations, resembling the sparse nature of radio propagation. For signal\nreconstruction, it learns a dictionary that holds atomic features, which\nincreases flexibility across signal waveforms and spatiotemporal signal\npatterns. Our experiments show that SpaRTran reduces errors by up to 85 %\ncompared to state-of-the-art methods when fine-tuned on radio fingerprinting, a\nchallenging downstream task. In addition, our method requires less pretraining\neffort and offers greater flexibility, as we train it solely on individual\nradio signals. SpaRTran serves as an excellent base model that can be\nfine-tuned for various radio-based downstream tasks, effectively reducing the\ncost for labeling. In addition, it is significantly more versatile than\nexisting methods and demonstrates superior generalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.13055v2",
    "published": "2025-05-19T12:43:33+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13054v1",
    "title": "Disentangling Coordiante Frames for Task Specific Motion Retargeting in Teleoperation using Shared Control and VR Controllers",
    "authors": [
      "Max Grobbel",
      "Daniel Fl√∂gel",
      "Philipp Rigoll",
      "S√∂ren Hohmann"
    ],
    "abstract": "Task performance in terms of task completion time in teleoperation is still\nfar behind compared to humans conducting tasks directly. One large identified\nimpact on this is the human capability to perform transformations and\nalignments, which is directly influenced by the point of view and the motion\nretargeting strategy. In modern teleoperation systems, motion retargeting is\nusually implemented through a one time calibration or switching modes. Complex\ntasks, like concatenated screwing, might be difficult, because the operator has\nto align (e.g. mirror) rotational and translational input commands. Recent\nresearch has shown, that the separation of translation and rotation leads to\nincreased task performance. This work proposes a formal motion retargeting\nmethod, which separates translational and rotational input commands. This\nmethod is then included in a optimal control based trajectory planner and shown\nto work on a UR5e manipulator.",
    "pdf_url": "http://arxiv.org/pdf/2505.13054v1",
    "published": "2025-05-19T12:43:30+00:00",
    "categories": [
      "cs.RO",
      "cs.HC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13053v1",
    "title": "SNAPE-PM: Building and Utilizing Dynamic Partner Models for Adaptive Explanation Generation",
    "authors": [
      "Amelie S. Robrecht",
      "Christoph R. Kowalski",
      "Stefan Kopp"
    ],
    "abstract": "Adapting to the addressee is crucial for successful explanations, yet poses\nsignificant challenges for dialogsystems. We adopt the approach of treating\nexplanation generation as a non-stationary decision process, where the optimal\nstrategy varies according to changing beliefs about the explainee and the\ninteraction context. In this paper we address the questions of (1) how to track\nthe interaction context and the relevant listener features in a formally\ndefined computational partner model, and (2) how to utilize this model in the\ndynamically adjusted, rational decision process that determines the currently\nbest explanation strategy. We propose a Bayesian inference-based approach to\ncontinuously update the partner model based on user feedback, and a\nnon-stationary Markov Decision Process to adjust decision-making based on the\npartner model values. We evaluate an implementation of this framework with five\nsimulated interlocutors, demonstrating its effectiveness in adapting to\ndifferent partners with constant and even changing feedback behavior. The\nresults show high adaptivity with distinct explanation strategies emerging for\ndifferent partners, highlighting the potential of our approach to improve\nexplainable AI systems and dialogsystems in general.",
    "pdf_url": "http://arxiv.org/pdf/2505.13053v1",
    "published": "2025-05-19T12:42:23+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13052v2",
    "title": "Model Selection for Gaussian-gated Gaussian Mixture of Experts Using Dendrograms of Mixing Measures",
    "authors": [
      "Tuan Thai",
      "TrungTin Nguyen",
      "Dat Do",
      "Nhat Ho",
      "Christopher Drovandi"
    ],
    "abstract": "Mixture of Experts (MoE) models constitute a widely utilized class of\nensemble learning approaches in statistics and machine learning, known for\ntheir flexibility and computational efficiency. They have become integral\ncomponents in numerous state-of-the-art deep neural network architectures,\nparticularly for analyzing heterogeneous data across diverse domains. Despite\ntheir practical success, the theoretical understanding of model selection,\nespecially concerning the optimal number of mixture components or experts,\nremains limited and poses significant challenges. These challenges primarily\nstem from the inclusion of covariates in both the Gaussian gating functions and\nexpert networks, which introduces intrinsic interactions governed by partial\ndifferential equations with respect to their parameters. In this paper, we\nrevisit the concept of dendrograms of mixing measures and introduce a novel\nextension to Gaussian-gated Gaussian MoE models that enables consistent\nestimation of the true number of mixture components and achieves the pointwise\noptimal convergence rate for parameter estimation in overfitted scenarios.\nNotably, this approach circumvents the need to train and compare a range of\nmodels with varying numbers of components, thereby alleviating the\ncomputational burden, particularly in high-dimensional or deep neural network\nsettings. Experimental results on synthetic data demonstrate the effectiveness\nof the proposed method in accurately recovering the number of experts. It\noutperforms common criteria such as the Akaike information criterion, the\nBayesian information criterion, and the integrated completed likelihood, while\nachieving optimal convergence rates for parameter estimation and accurately\napproximating the regression function.",
    "pdf_url": "http://arxiv.org/pdf/2505.13052v2",
    "published": "2025-05-19T12:41:19+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.CO",
      "stat.ME",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.13051v1",
    "title": "Persistent Local Systems of Periodic Spaces",
    "authors": [
      "Adam Onus",
      "Primoz Skraba"
    ],
    "abstract": "The topology of periodic spaces has attracted a lot of interest in recent\nyears in order to study and classify crystalline structures and other large\nhomogeneous data sets, such as the distribution of galaxies in cosmology. In\npractice, these objects are studied by taking a finite sample and introducing\nperiodic boundary conditions, however this introduces and removes many subtle\nhomological features. Here, build on the work of Onus and Robins (2022) and\nOnus and Skraba (2023) to investigate whether one can recover the (persistent)\nhomology of a periodic cell complex $K$ from a finite quotient space $G$ of\nequivalence classes under translations. In particular, we search for a\ncomputationally friendly method to identify all ''toroidal cycles'' of $G$\nwhich do not lift to cycles in $K$. We show that all toroidal and non-toroidal\ncycles of $G$ of arbitrary homology degree can be completely classified for $K$\nof arbitrary periodicity using the recently developed machinery of bisheaves\nand persistent local systems. In doing so, we also introduce a framework for a\ncomputationally viable persistence theory of periodic spaces. Finally, we\noutline algorithms for how to apply our results to real data, including a\npolynomial time algorithm for calculating the canonical persistent local system\nattributed to a given bisheaf.",
    "pdf_url": "http://arxiv.org/pdf/2505.13051v1",
    "published": "2025-05-19T12:41:17+00:00",
    "categories": [
      "math.AT",
      "55N31, 55N30, 57Z25"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13050v1",
    "title": "RGB-to-Polarization Estimation: A New Task and Benchmark Study",
    "authors": [
      "Beibei Lin",
      "Zifeng Yuan",
      "Tingting Chen"
    ],
    "abstract": "Polarization images provide rich physical information that is fundamentally\nabsent from standard RGB images, benefiting a wide range of computer vision\napplications such as reflection separation and material classification.\nHowever, the acquisition of polarization images typically requires additional\noptical components, which increases both the cost and the complexity of the\napplications. To bridge this gap, we introduce a new task: RGB-to-polarization\nimage estimation, which aims to infer polarization information directly from\nRGB images. In this work, we establish the first comprehensive benchmark for\nthis task by leveraging existing polarization datasets and evaluating a diverse\nset of state-of-the-art deep learning models, including both\nrestoration-oriented and generative architectures. Through extensive\nquantitative and qualitative analysis, our benchmark not only establishes the\ncurrent performance ceiling of RGB-to-polarization estimation, but also\nsystematically reveals the respective strengths and limitations of different\nmodel families -- such as direct reconstruction versus generative synthesis,\nand task-specific training versus large-scale pre-training. In addition, we\nprovide some potential directions for future research on polarization\nestimation. This benchmark is intended to serve as a foundational resource to\nfacilitate the design and evaluation of future methods for polarization\nestimation from standard RGB inputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13050v1",
    "published": "2025-05-19T12:38:44+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13049v1",
    "title": "Physics-Aware Compilation for Parallel Quantum Circuit Execution on Neutral Atom Arrays",
    "authors": [
      "Geng Chen",
      "Guowu Yang",
      "Wenjie Sun",
      "Lianhui Yu",
      "Guangwei Deng",
      "Desheng Zheng",
      "Xiaoyu Li"
    ],
    "abstract": "Neutral atom quantum computers are one of the most promising quantum\narchitectures, offering advantages in scalability, dynamic reconfigurability,\nand potential for large-scale implementations. These characteristics create\nunique compilation challenges, especially regarding compilation efficiency\nwhile adapting to hardware flexibility. However, existing methods encounter\nsignificant performance bottlenecks at scale, hindering practical applications.\nWe propose Physics-Aware Compilation (PAC), a method that improves compilation\nefficiency while preserving the inherent flexibility of neutral atom systems.\nPAC introduces physics-aware hardware plane partitioning that strategically\nallocates hardware resources based on physical device characteristics like AOD\nand SLM trap properties and qubit mobility constraints. Additionally, it\nimplements parallel quantum circuit division with an improved Kernighan-Lin\nalgorithm that enables simultaneous execution across independent regions while\nmaintaining circuit fidelity. Our experimental evaluation compares PAC with\nstate-of-the-art methods across increasingly larger array sizes ranging from\n16x16 to 64x64 qubits. Results demonstrate that PAC achieves up to 78.5x\nspeedup on 16x16 arrays while maintaining comparable circuit quality. PAC's\ncompilation efficiency advantage increases with system scale, demonstrating\nscalability for practical quantum applications on larger arrays. PAC explores a\nviable path for practical applications of neutral atom quantum computers by\neffectively addressing the tension between compilation efficiency and hardware\nflexibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.13049v1",
    "published": "2025-05-19T12:38:15+00:00",
    "categories": [
      "quant-ph",
      "cs.ET"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13048v1",
    "title": "How circular is the linear economy? Analysing circularity, resource flows and their relation to GDP",
    "authors": [
      "Amir Rashid"
    ],
    "abstract": "The concept of Circular Economy (CE) has evolved significantly over the past\ndecade, transitioning from a simple model of resource circulation to an\nincreasingly complex and debated framework. While its primary objective remains\nthe elimination of waste and pollution through regenerative processes, CE has\nencountered definitional ambiguities and criticisms. This study critically\nexamines the prevailing circularity metrics, such as the circular material use\nrate or circularity and argues that such narrow definitions obscure the true\npotential of CE by excluding higher-value strategies like maintenance, repair,\nrefurbishment, and remanufacturing. Through a mixed-methods analysis of global\nresource flows (e.g.,104 Gt input in 2020, with only 9% recycled), the study\ndemonstrates how adjusting circularity calculations for non-recoverable\nmaterials reveals a real circularity rate of 27%, far exceeding the apparent\n9%. Yet even this higher rate translates to a mere 1.4% of global GDP,\nunderscoring the limited economic impact of recycling-centric approaches. The\nstudy identifies that 69% of economic value already derives from managing\nexisting stocks, suggesting mainstream CE discourse has largely overlooked the\nmost substantial circular practices already embedded in modern economies. The\nstudy thus proposes a radical change in the assessment framework that, (a)\nreplaces annual input-based metrics with economic value creation as the primary\nindicator, (b) incorporates stock utilization efficiency as a core circularity\nmeasure and (c) establishes new policy targets focused on value retention and\nreuse rather than mere material recovery. These findings necessitate a paradigm\nshift in circular economy strategy -- from counting recycled materials to\noptimizing economic resilience through intelligent stock management and\nservice-based value creation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13048v1",
    "published": "2025-05-19T12:37:39+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.13047v2",
    "title": "PPTNet: A Hybrid Periodic Pattern-Transformer Architecture for Traffic Flow Prediction and Congestion Identification",
    "authors": [
      "Hongrui Kou",
      "Jingkai Li",
      "Ziyu Wang",
      "Zhouhang Lv",
      "Yuxin Zhang",
      "Cheng Wang"
    ],
    "abstract": "Accurate prediction of traffic flow parameters and real time identification\nof congestion states are essential for the efficient operation of intelligent\ntransportation systems. This paper proposes a Periodic Pattern Transformer\nNetwork (PPTNet) for traffic flow prediction, integrating periodic pattern\nextraction with the Transformer architecture, coupled with a fuzzy inference\nmethod for real-time congestion identification. Firstly, a high-precision\ntraffic flow dataset (Traffic Flow Dataset for China's Congested Highways and\nExpressways, TF4CHE) suitable for congested highway scenarios in China is\nconstructed based on drone aerial imagery data. Subsequently, the proposed\nPPTNet employs Fast Fourier Transform to capture multi-scale periodic patterns\nand utilizes two-dimensional Inception convolutions to efficiently extract\nintra and inter periodic features. A Transformer decoder dynamically models\ntemporal dependencies, enabling accurate predictions of traffic density and\nspeed. Finally, congestion probabilities are calculated in real-time using the\npredicted outcomes via a Mamdani fuzzy inference-based congestion\nidentification module. Experimental results demonstrate that the proposed\nPPTNet significantly outperforms mainstream traffic prediction methods in\nprediction accuracy, and the congestion identification module effectively\nidentifies real-time road congestion states, verifying the superiority and\npracticality of the proposed method in real-world traffic scenarios. Project\npage: https://github.com/ADSafetyJointLab/PPTNet.",
    "pdf_url": "http://arxiv.org/pdf/2505.13047v2",
    "published": "2025-05-19T12:36:12+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13046v1",
    "title": "StudyAlign: A Software System for Conducting Web-Based User Studies with Functional Interactive Prototypes",
    "authors": [
      "Florian Lehmann",
      "Daniel Buschek"
    ],
    "abstract": "Interactive systems are commonly prototyped as web applications. This\napproach enables studies with functional prototypes on a large scale. However,\nsetting up these studies can be complex due to implementing experiment\nprocedures, integrating questionnaires, and data logging. To enable such user\nstudies, we developed the software system StudyAlign which offers: 1) a\nfrontend for participants, 2) an admin panel to manage studies, 3) the\npossibility to integrate questionnaires, 4) a JavaScript library to integrate\ndata logging into prototypes, and 5) a backend server for persisting log data,\nand serving logical functions via an API to the different parts of the system.\nWith our system, researchers can set up web-based experiments and focus on the\ndesign and development of interactions and prototypes. Furthermore, our\nsystematic approach facilitates the replication of studies and reduces the\nrequired effort to execute web-based user studies. We conclude with reflections\non using StudyAlign for conducting HCI studies online.",
    "pdf_url": "http://arxiv.org/pdf/2505.13046v1",
    "published": "2025-05-19T12:35:42+00:00",
    "categories": [
      "cs.HC",
      "H.5.2; I.2.7"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13045v1",
    "title": "Stabilization of fields of meromorphic functions on neighborhoods of a rational curve",
    "authors": [
      "Serge Lvovski"
    ],
    "abstract": "Suppose that $F$ is a smooth and connected complex surface (not necessarily\ncompact) containing a smooth rational curve $C$ with positive\nself-intersection. We prove that there exists a neighborhood $U\\supset C$ such\nthat any meromorphic function defined on a connected neighborhood of $C$ in $U$\ncan be extended to a meromorphic function on the entire $U$.",
    "pdf_url": "http://arxiv.org/pdf/2505.13045v1",
    "published": "2025-05-19T12:34:37+00:00",
    "categories": [
      "math.CV",
      "math.AG",
      "32H99, 14E07"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13043v1",
    "title": "A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation",
    "authors": [
      "Hao-Ran Yang",
      "Xiaohui Chen",
      "Chuan-Xian Ren"
    ],
    "abstract": "Aiming to generalize the well-trained gaze estimation model to new target\ndomains, Cross-domain Gaze Estimation (CDGE) is developed for real-world\napplication scenarios. Existing CDGE methods typically extract the\ndomain-invariant features to mitigate domain shift in feature space, which is\nproved insufficient by Generalized Label Shift (GLS) theory. In this paper, we\nintroduce a novel GLS perspective to CDGE and modelize the cross-domain problem\nby label and conditional shift problem. A GLS correction framework is presented\nand a feasible realization is proposed, in which a importance reweighting\nstrategy based on truncated Gaussian distribution is introduced to overcome the\ncontinuity challenges in label shift correction. To embed the reweighted source\ndistribution to conditional invariant learning, we further derive a\nprobability-aware estimation of conditional operator discrepancy. Extensive\nexperiments on standard CDGE tasks with different backbone models validate the\nsuperior generalization capability across domain and applicability on various\nmodels of proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2505.13043v1",
    "published": "2025-05-19T12:33:52+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13044v1",
    "title": "CAIM: Development and Evaluation of a Cognitive AI Memory Framework for Long-Term Interaction with Intelligent Agents",
    "authors": [
      "Rebecca Westh√§u√üer",
      "Frederik Berenz",
      "Wolfgang Minker",
      "Sebastian Zepf"
    ],
    "abstract": "Large language models (LLMs) have advanced the field of artificial\nintelligence (AI) and are a powerful enabler for interactive systems. However,\nthey still face challenges in long-term interactions that require adaptation\ntowards the user as well as contextual knowledge and understanding of the\never-changing environment. To overcome these challenges, holistic memory\nmodeling is required to efficiently retrieve and store relevant information\nacross interaction sessions for suitable responses. Cognitive AI, which aims to\nsimulate the human thought process in a computerized model, highlights\ninteresting aspects, such as thoughts, memory mechanisms, and decision-making,\nthat can contribute towards improved memory modeling for LLMs. Inspired by\nthese cognitive AI principles, we propose our memory framework CAIM. CAIM\nconsists of three modules: 1.) The Memory Controller as the central decision\nunit; 2.) the Memory Retrieval, which filters relevant data for interaction\nupon request; and 3.) the Post-Thinking, which maintains the memory storage. We\ncompare CAIM against existing approaches, focusing on metrics such as retrieval\naccuracy, response correctness, contextual coherence, and memory storage. The\nresults demonstrate that CAIM outperforms baseline frameworks across different\nmetrics, highlighting its context-awareness and potential to improve long-term\nhuman-AI interactions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13044v1",
    "published": "2025-05-19T12:33:52+00:00",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13042v1",
    "title": "An introduction to Neural Networks for Physicists",
    "authors": [
      "G. Caf√© de Miranda",
      "Gubio G. de Lima",
      "Tiago de S. Farias"
    ],
    "abstract": "Machine learning techniques have emerged as powerful tools to tackle various\nchallenges. The integration of machine learning methods with Physics has led to\ninnovative approaches in understanding, controlling, and simulating physical\nphenomena. This article aims to provide a practical introduction to neural\nnetwork and their basic concepts. It presents some perspectives on recent\nadvances at the intersection of machine learning models with physical systems.\nWe introduce practical material to guide the reader in taking their first steps\nin applying neural network to Physics problems. As an illustrative example, we\nprovide four applications of increasing complexity for the problem of a simple\npendulum, namely: parameter fitting of the pendulum's ODE for the small-angle\napproximation; Application of Physics-Inspired Neural Networks (PINNs) to find\nsolutions of the pendulum's ODE in the small-angle regime; Autoencoders applied\nto an image dataset of the pendulum's oscillations for estimating the\ndimensionality of the parameter space in this physical system; and the use of\nSparse Identification of Non-Linear Dynamics (SINDy) architectures for model\ndiscovery and analytical expressions for the nonlinear pendulum problem (large\nangles).",
    "pdf_url": "http://arxiv.org/pdf/2505.13042v1",
    "published": "2025-05-19T12:32:28+00:00",
    "categories": [
      "physics.ed-ph",
      "physics.comp-ph"
    ],
    "primary_category": "physics.ed-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13569v1",
    "title": "Surrogate Modeling of 3D Rayleigh-Benard Convection with Equivariant Autoencoders",
    "authors": [
      "Fynn Fromme",
      "Christine Allen-Blanchette",
      "Hans Harder",
      "Sebastian Peitz"
    ],
    "abstract": "The use of machine learning for modeling, understanding, and controlling\nlarge-scale physics systems is quickly gaining in popularity, with examples\nranging from electromagnetism over nuclear fusion reactors and\nmagneto-hydrodynamics to fluid mechanics and climate modeling. These systems --\ngoverned by partial differential equations -- present unique challenges\nregarding the large number of degrees of freedom and the complex dynamics over\nmany scales both in space and time, and additional measures to improve accuracy\nand sample efficiency are highly desirable. We present an end-to-end\nequivariant surrogate model consisting of an equivariant convolutional\nautoencoder and an equivariant convolutional LSTM using $G$-steerable kernels.\nAs a case study, we consider the three-dimensional Rayleigh-B\\'enard\nconvection, which describes the buoyancy-driven fluid flow between a heated\nbottom and a cooled top plate. While the system is E(2)-equivariant in the\nhorizontal plane, the boundary conditions break the translational equivariance\nin the vertical direction. Our architecture leverages vertically stacked layers\nof $D_4$-steerable kernels, with additional partial kernel sharing in the\nvertical direction for further efficiency improvement. Our results demonstrate\nsignificant gains both in sample and parameter efficiency, as well as a better\nscaling to more complex dynamics, that is, larger Rayleigh numbers. The\naccompanying code is available under\nhttps://github.com/FynnFromme/equivariant-rb-forecasting.",
    "pdf_url": "http://arxiv.org/pdf/2505.13569v1",
    "published": "2025-05-19T12:26:54+00:00",
    "categories": [
      "cs.LG",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13041v1",
    "title": "Imaging the Acceptor Wave Function Anisotropy in Silicon",
    "authors": [
      "Manuel Siegl",
      "Julian Zanon",
      "Joseph Sink",
      "Adonai Rodrigues da Cruz",
      "Holly Hedgeland",
      "Neil J. Curson",
      "Michael E. Flatt√©",
      "Steven R. Schofield"
    ],
    "abstract": "We present the first scanning tunneling microscopy (STM) images of hydrogenic\nacceptor wave functions in silicon. These acceptor states appear as square\nring-like features in STM images and originate from near-surface defects\nintroduced by high-energy bismuth implantation into a silicon (001) wafer.\nScanning tunneling spectroscopy confirms the formation of a p-type surface.\nEffective-mass and tight-binding calculations provide an excellent description\nof the observed square ring-like features, confirming their acceptor character\nand attributing their symmetry to the light- and heavy-hole band degeneracy in\nsilicon. Detailed understanding of the energetic and spatial properties of\nacceptor wave functions in silicon is essential for engineering large-scale\nacceptor-based quantum devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.13041v1",
    "published": "2025-05-19T12:26:52+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.13040v1",
    "title": "Renormalization group analysis of a continuous model with self-organized criticality: Effects of randomly moving environment",
    "authors": [
      "N. V. Antonov",
      "P. I. Kakin",
      "N. M. Lebedev",
      "A. Yu. Luchin"
    ],
    "abstract": "We study a strongly anisotropic self-organized critical system coupled to an\nisotropic random fluid environment. The former is described by a continuous\n(coarse-grained) model due to Hwa and Kardar. The latter is modeled by the\nNavier--Stokes equation with a random stirring force of a rather general form\nthat includes, in particular, the overall shaking of the system and a non-local\npart with power-law spectrum $\\sim k^{4-d-y}$ that describes, in the limiting\ncase $y \\to 4$, a turbulent fluid. The full problem of the two coupled\nstochastic equations is represented as a field theoretic model which is shown\nto be multiplicatively renormalizable and logarithmic at $d=4$. Due to the\ninterplay between isotropic and anisotropic interactions, the corresponding\nrenormalization group (RG) equations reveal a rich pattern of possible infrared\n(large scales, long times) regimes of asymptotic behaviour of various Green's\nfunctions. The attractors of the RG equations in the five-dimensional space of\ncoupling parameters include a two-dimensional surface of Gaussian (free) fixed\npoints, a single fixed point that corresponds to the plain advection by the\nturbulent fluid (the Hwa--Kardar self-interaction is irrelevant) and a\none-dimensional curve of fixed points that corresponds to the case where the\nHwa--Kardar nonlinearity and the uniform stirring are simultaneously relevant.\nThe character of attractiveness is determined by the exponent $y$ and the\ndimension of space $d$; the most interesting case $d=3$ and $y \\to 4$ is\ndescribed by the single fixed point. The corresponding critical dimensions of\nthe frequency and the basic fields are found exactly.",
    "pdf_url": "http://arxiv.org/pdf/2505.13040v1",
    "published": "2025-05-19T12:26:22+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.13039v2",
    "title": "Expert-Like Reparameterization of Heterogeneous Pyramid Receptive Fields in Efficient CNNs for Fair Medical Image Classification",
    "authors": [
      "Xiao Wu",
      "Xiaoqing Zhang",
      "Zunjie Xiao",
      "Lingxi Hu",
      "Risa Higashita",
      "Jiang Liu"
    ],
    "abstract": "Efficient convolutional neural network (CNN) architecture design has\nattracted growing research interests. However, they typically apply single\nreceptive field (RF), small asymmetric RFs, or pyramid RFs to learn different\nfeature representations, still encountering two significant challenges in\nmedical image classification tasks: 1) They have limitations in capturing\ndiverse lesion characteristics efficiently, e.g., tiny, coordination, small and\nsalient, which have unique roles on the classification results, especially\nimbalanced medical image classification. 2) The predictions generated by those\nCNNs are often unfair/biased, bringing a high risk when employing them to\nreal-world medical diagnosis conditions. To tackle these issues, we develop a\nnew concept, Expert-Like Reparameterization of Heterogeneous Pyramid Receptive\nFields (ERoHPRF), to simultaneously boost medical image classification\nperformance and fairness. This concept aims to mimic the multi-expert\nconsultation mode by applying the well-designed heterogeneous pyramid RF bag to\ncapture lesion characteristics with varying significances effectively via\nconvolution operations with multiple heterogeneous kernel sizes. Additionally,\nERoHPRF introduces an expert-like structural reparameterization technique to\nmerge its parameters with the two-stage strategy, ensuring competitive\ncomputation cost and inference speed through comparisons to a single RF. To\nmanifest the effectiveness and generalization ability of ERoHPRF, we\nincorporate it into mainstream efficient CNN architectures. The extensive\nexperiments show that our proposed ERoHPRF maintains a better trade-off than\nstate-of-the-art methods in terms of medical image classification, fairness,\nand computation overhead. The code of this paper is available at\nhttps://github.com/XiaoLing12138/Expert-Like-Reparameterization-of-Heterogeneous-Pyramid-Receptive-Fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.13039v2",
    "published": "2025-05-19T12:23:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13038v1",
    "title": "On the mean-field limit of Vlasov-Poisson-Fokker-Planck equations",
    "authors": [
      "Li Chen",
      "Jinwook Jung",
      "Peter Pickl",
      "Zhenfu Wang"
    ],
    "abstract": "The derivation of effective descriptions for interacting many-body systems is\nan important branch of applied mathematics. We prove a propagation of chaos\nresult for a system of $N$ particles subject to Newtonian time evolution with\nor without additional white noise influencing the velocities of the particles.\nWe assume that the particles interact according to a regularized\nCoulomb-interaction with a regularization parameter that vanishes in the\n$N\\to\\infty$ limit. The respective effective description is the so called\nVlasov-Poisson-Fokker-Planck (VPFP), respectively the Vlasov-Poisson (VP)\nequation in the case of no or sub-dominant white noise. To obtain our result we\ncombine the relative entropy method from \\cite{jabinWang2016} with the control\non the difference between the trajectories of the true and the effective\ndescription provided in \\cite{HLP20} for the VPFP case respectively in\n\\cite{LP} for the VP case. This allows us to prove strong convergence of the\nmarginals, i.e. convergence in $L^1$.",
    "pdf_url": "http://arxiv.org/pdf/2505.13038v1",
    "published": "2025-05-19T12:21:54+00:00",
    "categories": [
      "math-ph",
      "math.AP",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13037v2",
    "title": "Hamiltonian renormalisation IX. U(1)**3 quantum gravity",
    "authors": [
      "M. Rodriguez Zarate",
      "T. Thiemann"
    ],
    "abstract": "In previous works in this series we focussed on Hamiltonian renormalisation\nof free field theories in all spacetime dimensions or interacting theories in\nspacetime dimensions lower than four. In this paper we address the Hamiltonian\nrenormalisation of the U(1)**3 model for Euclidian general relativity in four\nspacetime dimensions which is self-interacting.\n  The Hamiltonian flow needs as an input a choice of *-algebra and\ncorresponding representation thereof or state on it at each resolution scale.\nIf one uses as input the algebras and states that were used in the recent exact\nsolutions of this model, then one finds that the flow finds as fixed point\nthose exact solution theories.",
    "pdf_url": "http://arxiv.org/pdf/2505.13037v2",
    "published": "2025-05-19T12:21:52+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.13036v1",
    "title": "KIT's Offline Speech Translation and Instruction Following Submission for IWSLT 2025",
    "authors": [
      "Sai Koneru",
      "Maike Z√ºfle",
      "Thai-Binh Nguyen",
      "Seymanur Akti",
      "Jan Niehues",
      "Alexander Waibel"
    ],
    "abstract": "The scope of the International Workshop on Spoken Language Translation\n(IWSLT) has recently broadened beyond traditional Speech Translation (ST) to\nencompass a wider array of tasks, including Speech Question Answering and\nSummarization. This shift is partly driven by the growing capabilities of\nmodern systems, particularly with the success of Large Language Models (LLMs).\nIn this paper, we present the Karlsruhe Institute of Technology's submissions\nfor the Offline ST and Instruction Following (IF) tracks, where we leverage\nLLMs to enhance performance across all tasks. For the Offline ST track, we\npropose a pipeline that employs multiple automatic speech recognition systems,\nwhose outputs are fused using an LLM with document-level context. This is\nfollowed by a two-step translation process, incorporating additional refinement\nstep to improve translation quality. For the IF track, we develop an end-to-end\nmodel that integrates a speech encoder with an LLM to perform a wide range of\ninstruction-following tasks. We complement it with a final document-level\nrefinement stage to further enhance output quality by using contextual\ninformation.",
    "pdf_url": "http://arxiv.org/pdf/2505.13036v1",
    "published": "2025-05-19T12:21:29+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13035v1",
    "title": "Energy Dissipation in Cyclic Strain of Amorphous Solids",
    "authors": [
      "Itamar Procaccia",
      "Tuhin Samanta"
    ],
    "abstract": "The study of the response of amorphous materials to oscillatory strain is\ntraditionally performed with many repeated cycles. We argue that it pays to\nconsider carefully just one cycle (and may be a second), to reveal the rich\nphysics that characterizes cyclic strain. The response can be conservative or\ndissipative, with a sharp transition between these options as a function of\npreparation parameters, accompanied by symmetry breaking and the onset of\nscreening. We choose an example for which the mesoscopic theory can be solved\nexactly, and the microscopic physics can be revealed by numerical simulations.\nThe mechanism of energy dissipation (when it exists) is explored in detail,\nshedding light on the reason why repeated cycles exhibit ever decreasing\ndissipation per cycle, which is often consistent with a universal law.",
    "pdf_url": "http://arxiv.org/pdf/2505.13035v1",
    "published": "2025-05-19T12:21:03+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.13034v1",
    "title": "topicwizard -- a Modern, Model-agnostic Framework for Topic Model Visualization and Interpretation",
    "authors": [
      "M√°rton Kardos",
      "Kenneth C. Enevoldsen",
      "Kristoffer Laigaard Nielbo"
    ],
    "abstract": "Topic models are statistical tools that allow their users to gain qualitative\nand quantitative insights into the contents of textual corpora without the need\nfor close reading. They can be applied in a wide range of settings from\ndiscourse analysis, through pretraining data curation, to text filtering. Topic\nmodels are typically parameter-rich, complex models, and interpreting these\nparameters can be challenging for their users. It is typical practice for users\nto interpret topics based on the top 10 highest ranking terms on a given topic.\nThis list-of-words approach, however, gives users a limited and biased picture\nof the content of topics. Thoughtful user interface design and visualizations\ncan help users gain a more complete and accurate understanding of topic models'\noutput. While some visualization utilities do exist for topic models, these are\ntypically limited to a certain type of topic model. We introduce topicwizard, a\nframework for model-agnostic topic model interpretation, that provides\nintuitive and interactive tools that help users examine the complex semantic\nrelations between documents, words and topics learned by topic models.",
    "pdf_url": "http://arxiv.org/pdf/2505.13034v1",
    "published": "2025-05-19T12:19:01+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13033v2",
    "title": "TSPulse: Dual Space Tiny Pre-Trained Models for Rapid Time-Series Analysis",
    "authors": [
      "Vijay Ekambaram",
      "Subodh Kumar",
      "Arindam Jati",
      "Sumanta Mukherjee",
      "Tomoya Sakai",
      "Pankaj Dayama",
      "Wesley M. Gifford",
      "Jayant Kalagnanam"
    ],
    "abstract": "The rise of time-series pre-trained models has advanced temporal\nrepresentation learning, but current state-of-the-art models are often\nlarge-scale, requiring substantial compute. We introduce TSPulse, ultra-compact\ntime-series pre-trained models with only 1M parameters, specialized to perform\nstrongly across classification, anomaly detection, imputation, and retrieval\ntasks. TSPulse introduces innovations at both the architecture and task levels.\nAt the architecture level, it employs a dual-space masked reconstruction,\nlearning from both time and frequency domains to capture complementary signals.\nThis is further enhanced by a dual-embedding disentanglement, generating both\ndetailed embeddings for fine-grained analysis and high-level semantic\nembeddings for broader task understanding. Notably, TSPulse's semantic\nembeddings are robust to shifts in time, magnitude, and noise, which is\nimportant for robust retrieval. At the task level, TSPulse incorporates TSLens,\na fine-tuning component enabling task-specific feature attention. It also\nintroduces a multi-head triangulation technique that correlates deviations from\nmultiple prediction heads, enhancing anomaly detection by fusing complementary\nmodel outputs. Additionally, a hybrid mask pretraining is proposed to improves\nzero-shot imputation by reducing pre-training bias. These architecture and task\ninnovations collectively contribute to TSPulse's significant performance gains:\n5-16% on the UEA classification benchmarks, +20% on the TSB-AD anomaly\ndetection leaderboard, +50% in zero-shot imputation, and +25% in time-series\nretrieval. Remarkably, these results are achieved with just 1M parameters\n(10-100X smaller than existing SOTA models) and allow GPU-free inference,\nsetting a new standard for efficient time-series pre-trained models. The models\ncan be accessed from\nhttps://huggingface.co/ibm-granite/granite-timeseries-tspulse-r1",
    "pdf_url": "http://arxiv.org/pdf/2505.13033v2",
    "published": "2025-05-19T12:18:53+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13032v1",
    "title": "MMAR: A Challenging Benchmark for Deep Reasoning in Speech, Audio, Music, and Their Mix",
    "authors": [
      "Ziyang Ma",
      "Yinghao Ma",
      "Yanqiao Zhu",
      "Chen Yang",
      "Yi-Wen Chao",
      "Ruiyang Xu",
      "Wenxi Chen",
      "Yuanzhe Chen",
      "Zhuo Chen",
      "Jian Cong",
      "Kai Li",
      "Keliang Li",
      "Siyou Li",
      "Xinfeng Li",
      "Xiquan Li",
      "Zheng Lian",
      "Yuzhe Liang",
      "Minghao Liu",
      "Zhikang Niu",
      "Tianrui Wang",
      "Yuping Wang",
      "Yuxuan Wang",
      "Yihao Wu",
      "Guanrou Yang",
      "Jianwei Yu",
      "Ruibin Yuan",
      "Zhisheng Zheng",
      "Ziya Zhou",
      "Haina Zhu",
      "Wei Xue",
      "Emmanouil Benetos",
      "Kai Yu",
      "Eng-Siong Chng",
      "Xie Chen"
    ],
    "abstract": "We introduce MMAR, a new benchmark designed to evaluate the deep reasoning\ncapabilities of Audio-Language Models (ALMs) across massive multi-disciplinary\ntasks. MMAR comprises 1,000 meticulously curated audio-question-answer\ntriplets, collected from real-world internet videos and refined through\niterative error corrections and quality checks to ensure high quality. Unlike\nexisting benchmarks that are limited to specific domains of sound, music, or\nspeech, MMAR extends them to a broad spectrum of real-world audio scenarios,\nincluding mixed-modality combinations of sound, music, and speech. Each\nquestion in MMAR is hierarchically categorized across four reasoning layers:\nSignal, Perception, Semantic, and Cultural, with additional sub-categories\nwithin each layer to reflect task diversity and complexity. To further foster\nresearch in this area, we annotate every question with a Chain-of-Thought (CoT)\nrationale to promote future advancements in audio reasoning. Each item in the\nbenchmark demands multi-step deep reasoning beyond surface-level understanding.\nMoreover, a part of the questions requires graduate-level perceptual and\ndomain-specific knowledge, elevating the benchmark's difficulty and depth. We\nevaluate MMAR using a broad set of models, including Large Audio-Language\nModels (LALMs), Large Audio Reasoning Models (LARMs), Omni Language Models\n(OLMs), Large Language Models (LLMs), and Large Reasoning Models (LRMs), with\naudio caption inputs. The performance of these models on MMAR highlights the\nbenchmark's challenging nature, and our analysis further reveals critical\nlimitations of understanding and reasoning capabilities among current models.\nWe hope MMAR will serve as a catalyst for future advances in this important but\nlittle-explored area.",
    "pdf_url": "http://arxiv.org/pdf/2505.13032v1",
    "published": "2025-05-19T12:18:42+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.13031v2",
    "title": "MindOmni: Unleashing Reasoning Generation in Vision Language Models with RGPO",
    "authors": [
      "Yicheng Xiao",
      "Lin Song",
      "Yukang Chen",
      "Yingmin Luo",
      "Yuxin Chen",
      "Yukang Gan",
      "Wei Huang",
      "Xiu Li",
      "Xiaojuan Qi",
      "Ying Shan"
    ],
    "abstract": "Recent text-to-image systems face limitations in handling multimodal inputs\nand complex reasoning tasks. We introduce MindOmni, a unified multimodal large\nlanguage model that addresses these challenges by incorporating reasoning\ngeneration through reinforcement learning. MindOmni leverages a three-phase\ntraining strategy: i) design of a unified vision language model with a\ndecoder-only diffusion module, ii) supervised fine-tuning with Chain-of-Thought\n(CoT) instruction data, and iii) our proposed Reasoning Generation Policy\nOptimization (RGPO) algorithm, utilizing multimodal feedback to effectively\nguide policy updates. Experimental results demonstrate that MindOmni\noutperforms existing models, achieving impressive performance on both\nunderstanding and generation benchmarks, meanwhile showcasing advanced\nfine-grained reasoning generation capabilities, especially with mathematical\nreasoning instruction. All codes will be made public at\nhttps://github.com/TencentARC/MindOmni",
    "pdf_url": "http://arxiv.org/pdf/2505.13031v2",
    "published": "2025-05-19T12:17:04+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13030v2",
    "title": "Hamiltonian renormalisation VIII. P(Phi,2) quantum field theory",
    "authors": [
      "M. Rodriguez Zarate",
      "T. Thiemann"
    ],
    "abstract": "In previous works in this series we focussed on Hamiltonian renormalisation\nof free field theories in all spacetime dimensions. In this paper we address\nthe Hamiltonian renormalisation of the self-interacting scalar field in two\nspacetime dimensions with polynomial potential, called P(Phi,2). We consider\nonly the finite volume case.\n  The P(Phi,2) theory is one of the few interacting QFT's that can be\nrigorously constructed non-perturbatively. We find that our Hamiltonian\nrenormalisation flow finds this theory indeed as a fixed point.",
    "pdf_url": "http://arxiv.org/pdf/2505.13030v2",
    "published": "2025-05-19T12:16:37+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13029v3",
    "title": "MDDM: A Multi-view Discriminative Enhanced Diffusion-based Model for Speech Enhancement",
    "authors": [
      "Nan Xu",
      "Zhaolong Huang",
      "Xiaonan Zhi"
    ],
    "abstract": "With the development of deep learning, speech enhancement has been greatly\noptimized in terms of speech quality. Previous methods typically focus on the\ndiscriminative supervised learning or generative modeling, which tends to\nintroduce speech distortions or high computational cost. In this paper, we\npropose MDDM, a Multi-view Discriminative enhanced Diffusion-based Model.\nSpecifically, we take the features of three domains (time, frequency and noise)\nas inputs of a discriminative prediction network, generating the preliminary\nspectrogram. Then, the discriminative output can be converted to clean speech\nby several inference sampling steps. Due to the intersection of the\ndistributions between discriminative output and clean target, the smaller\nsampling steps can achieve the competitive performance compared to other\ndiffusion-based methods. Experiments conducted on a public dataset and a\nrealworld dataset validate the effectiveness of MDDM, either on subjective or\nobjective metric.",
    "pdf_url": "http://arxiv.org/pdf/2505.13029v3",
    "published": "2025-05-19T12:15:08+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13028v2",
    "title": "Evaluating the efficacy of LLM Safety Solutions : The Palit Benchmark Dataset",
    "authors": [
      "Sayon Palit",
      "Daniel Woods"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly integrated into critical\nsystems in industries like healthcare and finance. Users can often submit\nqueries to LLM-enabled chatbots, some of which can enrich responses with\ninformation retrieved from internal databases storing sensitive data. This\ngives rise to a range of attacks in which a user submits a malicious query and\nthe LLM-system outputs a response that creates harm to the owner, such as\nleaking internal data or creating legal liability by harming a third-party.\nWhile security tools are being developed to counter these threats, there is\nlittle formal evaluation of their effectiveness and usability. This study\naddresses this gap by conducting a thorough comparative analysis of LLM\nsecurity tools. We identified 13 solutions (9 closed-source, 4 open-source),\nbut only 7 were evaluated due to a lack of participation by proprietary model\nowners.To evaluate, we built a benchmark dataset of malicious prompts, and\nevaluate these tools performance against a baseline LLM model\n(ChatGPT-3.5-Turbo). Our results show that the baseline model has too many\nfalse positives to be used for this task. Lakera Guard and ProtectAI LLM Guard\nemerged as the best overall tools showcasing the tradeoff between usability and\nperformance. The study concluded with recommendations for greater transparency\namong closed source providers, improved context-aware detections, enhanced\nopen-source engagement, increased user awareness, and the adoption of more\nrepresentative performance metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.13028v2",
    "published": "2025-05-19T12:12:00+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "F.2.2; I.2.7; F.2.2; I.2.7; F.2.2; I.2.7"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13027v1",
    "title": "Unpacking Positional Encoding in Transformers: A Spectral Analysis of Content-Position Coupling",
    "authors": [
      "Zihan Gu",
      "Han Zhang",
      "Ruoyu Chen",
      "Yue Hu",
      "Hua Zhang"
    ],
    "abstract": "Positional encoding (PE) is essential for enabling Transformers to model\nsequential structure. However, the mechanisms by which different PE schemes\ncouple token content and positional information-and how these mechanisms\ninfluence model dynamics-remain theoretically underexplored. In this work, we\npresent a unified framework that analyzes PE through the spectral properties of\nToeplitz and related matrices derived from attention logits. We show that\nmultiplicative content-position coupling-exemplified by Rotary Positional\nEncoding (RoPE) via a Hadamard product with a Toeplitz matrix-induces spectral\ncontraction, which theoretically improves optimization stability and\nefficiency. Guided by this theory, we construct synthetic tasks that contrast\ncontent-position dependent and content-position independent settings, and\nevaluate a range of PE methods. Our experiments reveal strong alignment with\ntheory: RoPE consistently outperforms other methods on position-sensitive tasks\nand induces \"single-head deposit\" patterns in early layers, indicating\nlocalized positional processing. Further analyses show that modifying the\nmethod and timing of PE coupling, such as MLA in Deepseek-V3, can effectively\nmitigate this concentration. These results establish explicit content-relative\nmixing with relative-position Toeplitz signals as a key principle for effective\nPE design and provide new insight into how positional structure is integrated\nin Transformer architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.13027v1",
    "published": "2025-05-19T12:11:13+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13026v3",
    "title": "Step-wise Adaptive Integration of Supervised Fine-tuning and Reinforcement Learning for Task-Specific LLMs",
    "authors": [
      "Jack Chen",
      "Fazhong Liu",
      "Naruto Liu",
      "Yuhan Luo",
      "Erqu Qin",
      "Harry Zheng",
      "Tian Dong",
      "Haojin Zhu",
      "Yan Meng",
      "Xiao Wang"
    ],
    "abstract": "Large language models (LLMs) excel at mathematical reasoning and logical\nproblem-solving. The current popular training paradigms primarily use\nsupervised fine-tuning (SFT) and reinforcement learning (RL) to enhance the\nmodels' reasoning abilities. However, when using SFT or RL alone, there are\nrespective challenges: SFT may suffer from overfitting, while RL is prone to\nmode collapse. The state-of-the-art methods have proposed hybrid training\nschemes. However, static switching faces challenges such as poor generalization\nacross different tasks and high dependence on data quality. In response to\nthese challenges, inspired by the curriculum learning-quiz mechanism in human\nreasoning cultivation, We propose SASR, a step-wise adaptive hybrid training\nframework that theoretically unifies SFT and RL and dynamically balances the\ntwo throughout optimization. SASR uses SFT for initial warm-up to establish\nbasic reasoning skills, and then uses an adaptive dynamic adjustment algorithm\nbased on gradient norm and divergence relative to the original distribution to\nseamlessly integrate SFT with the online RL method GRPO. By monitoring the\ntraining status of LLMs and adjusting the training process in sequence, SASR\nensures a smooth transition between training schemes, maintaining core\nreasoning abilities while exploring different paths. Experimental results\ndemonstrate that SASR outperforms SFT, RL, and static hybrid training methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.13026v3",
    "published": "2025-05-19T12:10:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13025v1",
    "title": "LiBOG: Lifelong Learning for Black-Box Optimizer Generation",
    "authors": [
      "Jiyuan Pei",
      "Yi Mei",
      "Jialin Liu",
      "Mengjie Zhang"
    ],
    "abstract": "Meta-Black-Box Optimization (MetaBBO) garners attention due to its success in\nautomating the configuration and generation of black-box optimizers,\nsignificantly reducing the human effort required for optimizer design and\ndiscovering optimizers with higher performance than classic human-designed\noptimizers. However, existing MetaBBO methods conduct one-off training under\nthe assumption that a stationary problem distribution with extensive and\nrepresentative training problem samples is pre-available. This assumption is\noften impractical in real-world scenarios, where diverse problems following\nshifting distribution continually arise. Consequently, there is a pressing need\nfor methods that can continuously learn from new problems encountered\non-the-fly and progressively enhance their capabilities. In this work, we\nexplore a novel paradigm of lifelong learning in MetaBBO and introduce LiBOG, a\nnovel approach designed to learn from sequentially encountered problems and\ngenerate high-performance optimizers for Black-Box Optimization (BBO). LiBOG\nconsolidates knowledge both across tasks and within tasks to mitigate\ncatastrophic forgetting. Extensive experiments demonstrate LiBOG's\neffectiveness in learning to generate high-performance optimizers in a lifelong\nlearning manner, addressing catastrophic forgetting while maintaining\nplasticity to learn new tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13025v1",
    "published": "2025-05-19T12:09:25+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13024v1",
    "title": "The minimum number of distinct eigenvalues of a threshold graph is at most $4$",
    "authors": [
      "Luiz Emilio Allem",
      "Carlos Hoppen",
      "Jo√£o Lazzarin",
      "Lucas Siviero Sibemberg",
      "Fernando Colman Tura"
    ],
    "abstract": "In this note we show that the minimum number of distinct eigenvalues of a\nthreshold graph is at most $4$. Moreover, given any threshold graph $G$ and any\nnonzero real number $\\lambda$, we explicitly construct a matrix $M$ associated\nwith $G$ such that DSpec$(M)\\subseteq\\{-\\lambda,0,\\lambda,2\\lambda\\}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.13024v1",
    "published": "2025-05-19T12:07:51+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.13023v3",
    "title": "Anti-Inpainting: A Proactive Defense Approach against Malicious Diffusion-based Inpainters under Unknown Conditions",
    "authors": [
      "Yimao Guo",
      "Zuomin Qu",
      "Wei Lu",
      "Xiangyang Luo"
    ],
    "abstract": "With the increasing prevalence of diffusion-based malicious image\nmanipulation, existing proactive defense methods struggle to safeguard images\nagainst tampering under unknown conditions. To address this, we propose\nAnti-Inpainting, a proactive defense approach that achieves protection\ncomprising three novel modules. First, we introduce a multi-level deep feature\nextractor to obtain intricate features from the diffusion denoising process,\nenhancing protective effectiveness. Second, we design a multi-scale,\nsemantic-preserving data augmentation technique to enhance the transferability\nof adversarial perturbations across unknown conditions. Finally, we propose a\nselection-based distribution deviation optimization strategy to bolster\nprotection against manipulations guided by diverse random seeds. Extensive\nexperiments on InpaintGuardBench and CelebA-HQ demonstrate that Anti-Inpainting\neffectively defends against diffusion-based inpainters under unknown\nconditions. Additionally, our approach demonstrates robustness against various\nimage purification methods and transferability across different diffusion model\nversions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13023v3",
    "published": "2025-05-19T12:07:29+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13022v1",
    "title": "Endogenous clustering and analogy-based expectation equilibrium",
    "authors": [
      "Philippe Jehiel",
      "Giacomo Weber"
    ],
    "abstract": "Normal-form two-player games are categorized by players into K analogy\nclasses so as to minimize the prediction error about the behavior of the\nopponent. This results in Clustered Analogy-Based Expectation Equilibria in\nwhich strategies are analogy-based expectation equilibria given the analogy\npartitions and analogy partitions minimize the prediction errors given the\nstrategies. We distinguish between environments with self-repelling analogy\npartitions in which some mixing over partitions is required and environments\nwith self-attractive partitions in which several analogy partitions can arise,\nthereby suggesting new channels of belief heterogeneity and equilibrium\nmultiplicity. Various economic applications are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.13022v1",
    "published": "2025-05-19T12:05:47+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.13021v1",
    "title": "The role of data partitioning on the performance of EEG-based deep learning models in supervised cross-subject analysis: a preliminary study",
    "authors": [
      "Federico Del Pup",
      "Andrea Zanola",
      "Louis Fabrice Tshimanga",
      "Alessandra Bertoldo",
      "Livio Finos",
      "Manfredo Atzori"
    ],
    "abstract": "Deep learning is significantly advancing the analysis of\nelectroencephalography (EEG) data by effectively discovering highly nonlinear\npatterns within the signals. Data partitioning and cross-validation are crucial\nfor assessing model performance and ensuring study comparability, as they can\nproduce varied results and data leakage due to specific signal properties\n(e.g., biometric). Such variability leads to incomparable studies and,\nincreasingly, overestimated performance claims, which are detrimental to the\nfield. Nevertheless, no comprehensive guidelines for proper data partitioning\nand cross-validation exist in the domain, nor is there a quantitative\nevaluation of their impact on model accuracy, reliability, and\ngeneralizability. To assist researchers in identifying optimal experimental\nstrategies, this paper thoroughly investigates the role of data partitioning\nand cross-validation in evaluating EEG deep learning models. Five\ncross-validation settings are compared across three supervised cross-subject\nclassification tasks (BCI, Parkinson's, and Alzheimer's disease detection) and\nfour established architectures of increasing complexity (ShallowConvNet,\nEEGNet, DeepConvNet, and Temporal-based ResNet). The comparison of over 100,000\ntrained models underscores, first, the importance of using subject-based\ncross-validation strategies for evaluating EEG deep learning models, except\nwhen within-subject analyses are acceptable (e.g., BCI). Second, it highlights\nthe greater reliability of nested approaches (N-LNSO) compared to non-nested\ncounterparts, which are prone to data leakage and favor larger models\noverfitting to validation data. In conclusion, this work provides EEG deep\nlearning researchers with an analysis of data partitioning and cross-validation\nand offers guidelines to avoid data leakage, currently undermining the domain\nwith potentially overestimated performance claims.",
    "pdf_url": "http://arxiv.org/pdf/2505.13021v1",
    "published": "2025-05-19T12:05:28+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13020v1",
    "title": "Characterizing geodesic deviations in a Topological Star spacetime: massive, charged, spinning and stringy-like objects",
    "authors": [
      "Donato Bini",
      "Giorgio Di Russo"
    ],
    "abstract": "We study deviations from geodesic motions in a Topological Star spacetime for\neither massive, charged and spinning particles, elucidating different\nbehaviours with the Schwarzschild spacetime. We also consider the deviations\nfor the motion of electrically charged stringy probes in $D=5$, framing all\ncases within a unified picture.",
    "pdf_url": "http://arxiv.org/pdf/2505.13020v1",
    "published": "2025-05-19T12:05:27+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.13019v1",
    "title": "Characterizing asymmetric and bimodal long-term financial return distributions through quantum walks",
    "authors": [
      "Stijn De Backer",
      "Luis E. C. Rocha",
      "Jan Ryckebusch",
      "Koen Schoors"
    ],
    "abstract": "The analysis of logarithmic return distributions defined over large time\nscales is crucial for understanding the long-term dynamics of asset price\nmovements. For large time scales of the order of two trading years, the\nanticipated Gaussian behavior of the returns often does not emerge, and their\ndistributions often exhibit a high level of asymmetry and bimodality. These\nfeatures are inadequately captured by the majority of classical models to\naddress financial time series and return distributions. In the presented\nanalysis, we use a model based on the discrete-time quantum walk to\ncharacterize the observed asymmetry and bimodality. The quantum walk\ndistinguishes itself from a classical diffusion process by the occurrence of\ninterference effects, which allows for the generation of bimodal and asymmetric\nprobability distributions. By capturing the broader trends and patterns that\nemerge over extended periods, this analysis complements traditional short-term\nmodels and offers opportunities to more accurately describe the probabilistic\nstructure underlying long-term financial decisions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13019v1",
    "published": "2025-05-19T12:04:10+00:00",
    "categories": [
      "q-fin.ST",
      "q-fin.GN",
      "quant-ph",
      "91B80"
    ],
    "primary_category": "q-fin.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.13018v2",
    "title": "Holographic Einstein Ring of AdS Reissner Nordstr$\\ddot{o}$m Black Holes with Euler Heisenberg Nonlinear Electrodynamics",
    "authors": [
      "Abhishek Baruah",
      "Prabwal Phukon"
    ],
    "abstract": "This study, situated within the framework of the AdS/CFT correspondence,\nemploys wave optics methods to investigate the Einstein ring structure of\nquantum corrected AdS Reissner Nordstr$\\ddot{o}$m black holes governed by Euler\nHeisenberg nonlinear electrodynamics. A wave source placed on the AdS boundary\nyields a response function on the antipodal side, from which a virtual optical\nsystem with a convex lens reconstructs the holographic image of the Einstein\nring. The analysis systematically explores the impact of physical parameters\nand observer position on the ring's morphology. As the observer's position\nvaries, the image transitions from a complete ring to an arc and eventually to\na single bright point. The Einstein ring radius is observed to decrease with\nincreasing radial source position $\\rho$, wave frequency $\\omega$, and chemical\npotential $\\mu$, while it increases with electric charge $e$ and temperature\n$T$. In contrast, the quantum correction parameter $a$ has negligible effect on\nthe ring radius or response amplitude, as its contribution falls off rapidly\nnear the boundary and remains subleading in the wave dynamics. The parameter\n$e$ enhances the electromagnetic lensing strength, leading to a broader ring,\nwhereas increasing $\\rho$ alters wavefront propagation, affecting both\nbrightness peak and ring location. Geometric optics analysis confirms that the\nincident angle of the photon ring matches the Einstein ring angle, validating\nconsistency across frameworks. Overall, the results highlight how nonlinear\nelectromagnetic effects and bulk field configurations manifest in observable\nboundary features, providing a means to distinguish quantum-corrected black\nholes from classical solutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13018v2",
    "published": "2025-05-19T12:03:26+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13017v4",
    "title": "Optimal Scalogram for Computational Complexity Reduction in Acoustic Recognition Using Deep Learning",
    "authors": [
      "Dang Thoai Phan",
      "Tuan Anh Huynh",
      "Van Tuan Pham",
      "Cao Minh Tran",
      "Van Thuan Mai",
      "Ngoc Quy Tran"
    ],
    "abstract": "The Continuous Wavelet Transform (CWT) is an effective tool for feature\nextraction in acoustic recognition using Convolutional Neural Networks (CNNs),\nparticularly when applied to non-stationary audio. However, its high\ncomputational cost poses a significant challenge, often leading researchers to\nprefer alternative methods such as the Short-Time Fourier Transform (STFT). To\naddress this issue, this paper proposes a method to reduce the computational\ncomplexity of CWT by optimizing the length of the wavelet kernel and the hop\nsize of the output scalogram. Experimental results demonstrate that the\nproposed approach significantly reduces computational cost while maintaining\nthe robust performance of the trained model in acoustic recognition tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13017v4",
    "published": "2025-05-19T12:02:56+00:00",
    "categories": [
      "eess.AS",
      "cs.SD",
      "eess.SP"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13016v1",
    "title": "An Attentional Model of Time Discounting",
    "authors": [
      "Zijian Zark Wang"
    ],
    "abstract": "When decision makers evaluate a sequence of rewards, they may pay more\nattention to larger rewards and, given attention is limited, less attention to\nsmaller rewards. They may also become less attentive to each reward when\nattention is spread over a longer period of time. Such reductions in attention\ncould lead to greater discounting of the rewards' values. This paper introduces\na novel theory of time discounting based on these assumptions. The resulting\ndiscount factors in the theory follow a distribution similar to the multinomial\nlogit function. We characterize such discount factors using two approaches: one\nbased on information maximizing exploration and the other based on the optimal\ndiscounting framework. The theory can explain a wide range of anomalies,\nincluding the hidden-zero effect, S-shaped value function, and intertemporal\ncorrelation aversion. Also, it specifies new mediators for some well-known\npsychological effects, such as the common difference effect, risk aversion over\ntime lotteries, and the present bias.",
    "pdf_url": "http://arxiv.org/pdf/2505.13016v1",
    "published": "2025-05-19T12:02:23+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.13015v1",
    "title": "A flexible approach for fat-water separation with bipolar readouts and correction of gradient-induced phase and amplitude effects",
    "authors": [
      "Jorge Campos Pazmino",
      "Ren√©e-Claude Bider",
      "V√©ronique Fortier",
      "Ives R. Levesque"
    ],
    "abstract": "Purpose: To develop a fat-water separation approach that corrects bipolar\nreadout gradient induced effects, without additional scans, that is compatible\nwith any fat-water separation method. Theory and Methods: The proposed approach\ncombines joint fat-water separation of the odd and even echoes of a bipolar\nmulti-echo gradient echo acquisition with an inverse problem to find\nleast-squares estimates for phase and amplitude corrections to eliminate\nbipolar-induced effects. Optimization of sequence parameter selection through\nthe calculation of the number of signal averages (NSA) with Cram\\'er-Rao Bound\ntheory (CRB) is presented. The application of the proposed approach is\ndemonstrated with a graph cut optimization and further characterization of the\naccuracy was performed via Monte Carlo Simulations (MC). The proposed approach\nwas tested in phantoms and in vivo. Proton density fat fraction maps (PDFF)\nwere evaluated to quantify performance. Results: NSA calculations suggest short\nTE1 and {\\Delta}TE=1.5 ms as optimal alternatives for fat-water separation. MC\nsimulations demonstrated accurate estimation of fat and water complex signals,\n{\\psi}, and R_2^* with mean relative error within 1%. In phantoms and in vivo,\nthe proposed approach effectively eliminated effects induced by bipolar readout\ngradients, improving the outcome of the fat-water separation. Conclusion: We\nproposed an approach to correct bipolar readout-induced effects that are\ndetrimental for fat-water separation. This approach can extend the use of\nexisting fat-water separation techniques designed for data acquired using\nunipolar readout gradients to data collected with bipolar readout gradients.",
    "pdf_url": "http://arxiv.org/pdf/2505.13015v1",
    "published": "2025-05-19T11:59:44+00:00",
    "categories": [
      "physics.med-ph"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13014v1",
    "title": "Spectral asymptotics of semi-classical Toeplitz operators on Levi non-degenerate CR manifolds",
    "authors": [
      "Wei-Chuan Shen"
    ],
    "abstract": "We consider any compact CR manifold whose Levi form is non-degenerate of\nconstant signature $(n_-,n_+)$, $n_-+n_+=n$. For $\\lambda>0$ and\n$q\\in\\{0,\\cdots,n\\}$, we let $\\Pi_\\lambda^{(q)}$ be the spectral projection of\nthe Kohn Laplacian of $(0,q)$-forms corresponding to the interval\n$[0,\\lambda]$. For certain classical pseudodifferential operators $P$, we study\na class of generalized elliptic Toeplitz operators\n$T_{P,\\lambda}^{(q)}:=\\Pi_\\lambda^{(q)}\\circ P\\circ \\Pi_\\lambda^{(q)}$. For any\ncut-off $\\chi\\in\\mathscr C^\\infty_c(\\mathbb R\\setminus\\{0\\})$, we establish the\nfull asymptotics of the semi-classical spectral projector\n$\\chi(k^{-1}T_{P,\\lambda}^{(q)})$ as $k\\to+\\infty$. Our main result conclude\nthat the smooth Schwartz kernel $\\chi(k^{-1}T_{P,\\lambda}^{(n_-)})(x,y)$ is the\nsum of two semi-classical oscillatory integrals with complex-valued phase\nfunctions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13014v1",
    "published": "2025-05-19T11:59:18+00:00",
    "categories": [
      "math.CV",
      "math.AP",
      "math.SP",
      "32V30, 32T15, 58J40"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13013v1",
    "title": "On the normality of commuting scheme for general linear Lie algebra",
    "authors": [
      "Artan Sheshmani",
      "Xiaopeng Xia",
      "Beihui Yuan"
    ],
    "abstract": "The commuting scheme $\\mathfrak{C}^{d}_{\\mathfrak{g}}$ for reductive Lie\nalgebra $\\mathfrak{g}$ over an algebraically closed field $\\mathbb{K}$ is the\nsubscheme of $\\mathfrak{g}^{d}$ defined by quadratic equations, whose\n$\\mathbb{K}$-valued points are $d$-tuples of commuting elements in\n$\\mathfrak{g}$ over $\\mathbb{K}$. There is a long-standing conjecture that the\ncommuting scheme $\\mathfrak{C}^{d}_{\\mathfrak{g}}$ is reduced. Moreover, a\nhigher dimensional analog of Chevalley restriction conjecture was conjectured\nby Chen-Ng\\^{o}. We show that the commuting scheme of\n$\\mathfrak{C}^{2}_{\\mathfrak{g}l_{n}}$ is Cohen-Macaulay and normal. As a\ncorollary, we prove a 2-dimensional Chevalley restriction theorem for general\nlinear group in positive characteristic.",
    "pdf_url": "http://arxiv.org/pdf/2505.13013v1",
    "published": "2025-05-19T11:58:04+00:00",
    "categories": [
      "math.AG",
      "math.AC",
      "math.RT",
      "Primary 14L30, Secondary 13C14, 13H10, 14B25, 15A30, 20G05"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13012v1",
    "title": "Asymptotic Performance of Time-Varying Bayesian Optimization",
    "authors": [
      "Anthony Bardou",
      "Patrick Thiran"
    ],
    "abstract": "Time-Varying Bayesian Optimization (TVBO) is the go-to framework for\noptimizing a time-varying black-box objective function that may be noisy and\nexpensive to evaluate. Is it possible for the instantaneous regret of a TVBO\nalgorithm to vanish asymptotically, and if so, when? We answer this question of\ngreat theoretical importance by providing algorithm-independent lower regret\nbounds and upper regret bounds for TVBO algorithms, from which we derive\nsufficient conditions for a TVBO algorithm to have the no-regret property. Our\nanalysis covers all major classes of stationary kernel functions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13012v1",
    "published": "2025-05-19T11:55:02+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.13011v2",
    "title": "Unveiling and Steering Connectome Organization with Interpretable Latent Variables",
    "authors": [
      "Yubin Li",
      "Xingyu Liu",
      "Guozhang Chen"
    ],
    "abstract": "The brain's intricate connectome, a blueprint for its function, presents\nimmense complexity, yet it arises from a compact genetic code, hinting at\nunderlying low-dimensional organizational principles. This work bridges\nconnectomics and representation learning to uncover these principles. We\npropose a framework that combines subgraph extraction from the Drosophila\nconnectome, FlyWire, with a generative model to derive interpretable\nlow-dimensional representations of neural circuitry. Crucially, an\nexplainability module links these latent dimensions to specific structural\nfeatures, offering insights into their functional relevance. We validate our\napproach by demonstrating effective graph reconstruction and, significantly,\nthe ability to manipulate these latent codes to controllably generate\nconnectome subgraphs with predefined properties. This research offers a novel\ntool for understanding brain architecture and a potential avenue for designing\nbio-inspired artificial neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13011v2",
    "published": "2025-05-19T11:54:40+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13010v1",
    "title": "To Bias or Not to Bias: Detecting bias in News with bias-detector",
    "authors": [
      "Himel Ghosh",
      "Ahmed Mosharafa",
      "Georg Groh"
    ],
    "abstract": "Media bias detection is a critical task in ensuring fair and balanced\ninformation dissemination, yet it remains challenging due to the subjectivity\nof bias and the scarcity of high-quality annotated data. In this work, we\nperform sentence-level bias classification by fine-tuning a RoBERTa-based model\non the expert-annotated BABE dataset. Using McNemar's test and the 5x2\ncross-validation paired t-test, we show statistically significant improvements\nin performance when comparing our model to a domain-adaptively pre-trained\nDA-RoBERTa baseline. Furthermore, attention-based analysis shows that our model\navoids common pitfalls like oversensitivity to politically charged terms and\ninstead attends more meaningfully to contextually relevant tokens. For a\ncomprehensive examination of media bias, we present a pipeline that combines\nour model with an already-existing bias-type classifier. Our method exhibits\ngood generalization and interpretability, despite being constrained by\nsentence-level analysis and dataset size because of a lack of larger and more\nadvanced bias corpora. We talk about context-aware modeling, bias\nneutralization, and advanced bias type classification as potential future\ndirections. Our findings contribute to building more robust, explainable, and\nsocially responsible NLP systems for media bias detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.13010v1",
    "published": "2025-05-19T11:54:39+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.17068v1",
    "title": "Predictively Combatting Toxicity in Health-related Online Discussions through Machine Learning",
    "authors": [
      "Jorge Paz-Ruza",
      "Amparo Alonso-Betanzos",
      "Bertha Guijarro-Berdi√±as",
      "Carlos Eiras-Franco"
    ],
    "abstract": "In health-related topics, user toxicity in online discussions frequently\nbecomes a source of social conflict or promotion of dangerous, unscientific\nbehaviour; common approaches for battling it include different forms of\ndetection, flagging and/or removal of existing toxic comments, which is often\ncounterproductive for platforms and users alike. In this work, we propose the\nalternative of combatting user toxicity predictively, anticipating where a user\ncould interact toxically in health-related online discussions. Applying a\nCollaborative Filtering-based Machine Learning methodology, we predict the\ntoxicity in COVID-related conversations between any user and subcommunity of\nReddit, surpassing 80% predictive performance in relevant metrics, and allowing\nus to prevent the pairing of conflicting users and subcommunities.",
    "pdf_url": "http://arxiv.org/pdf/2505.17068v1",
    "published": "2025-05-19T11:53:37+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13009v1",
    "title": "Manifesto from Dagstuhl Perspectives Workshop 24452 -- Reframing Technical Debt",
    "authors": [
      "Paris Avgeriou",
      "Ipek Ozkaya",
      "Heiko Koziolek",
      "Zadia Codabux",
      "Neil Ernst"
    ],
    "abstract": "This is the Dagstuhl Perspectives Workshop 24452 manifesto on Reframing\nTechnical Debt. The manifesto begins with a one-page summary of Values,\nBeliefs, and Principles. It then elaborates on each Value, Belief, and\nPrinciple to explain their rationale and clarify their meaning. Subsequently,\nthe paper describes the current landscape of Technical Debt Management methods\nand tools and explains why the current practice is inadequate and where current\nresearch falls short. The current landscape is organized into five major\ntopics: Technical Debt as Value-Creation, Tooling, Data Collection, the role of\nArchitecture, and Socio-Technical Aspects. Finally, the paper outlines a\nroadmap to realize the stated principles, with concrete milestones to be\naddressed by researchers, software practitioners, and tool vendors. The\nmanifesto is signed by the workshop participants.",
    "pdf_url": "http://arxiv.org/pdf/2505.13009v1",
    "published": "2025-05-19T11:53:14+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13008v2",
    "title": "Adversarial Reasoning for Repair Based on Inferred Program Intent",
    "authors": [
      "He Ye",
      "Aidan Z. H. Yang",
      "Chang Hu",
      "Yanlin Wang",
      "Tao Zhang",
      "Claire Le Goues"
    ],
    "abstract": "Automated program repair (APR) has shown promising results, particularly with\nthe use of neural networks. Currently, most APR tools focus on code\ntransformations specified by test suites, rather than reasoning about the\nprogram intent and the high-level bug specification. Without a proper\nunderstanding of program intent, these tools tend to generate patches that\noverfit incomplete test suites and fail to reflect the developers intentions.\nHowever, reasoning about program intent is challenging. In our work, we propose\nan approach called AdverIntent-Agent, based on critique and adversarial\nreasoning. Our approach is novel to shift the focus from generating multiple\nAPR patches to inferring multiple potential program intents. Ideally, we aim to\ninfer intents that are, to some extent, adversarial to each other, maximizing\nthe probability that at least one aligns closely with the developers original\nintent. AdverIntent-Agent is a multi-agent approach consisting of three agents:\na reasoning agent, a test agent, and a repair agent. First, the reasoning agent\ngenerates adversarial program intents along with the corresponding faulty\nstatements. Next, the test agent produces adversarial test cases that align\nwith each inferred intent, constructing oracles that use the same inputs but\nhave different expected outputs. Finally, the repair agent uses dynamic and\nprecise LLM prompts to generate patches that satisfy both the inferred program\nintent and the generated tests. AdverIntent-Agent was evaluated on two\nbenchmarks: Defects4J 2.0 and HumanEval-Java. AdverIntent-Agent correctly\nrepaired 77 and 105 bugs in both benchmarks, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.13008v2",
    "published": "2025-05-19T11:51:56+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13007v1",
    "title": "Generative Modeling of Random Fields from Limited Data via Constrained Latent Flow Matching",
    "authors": [
      "James E. Warner",
      "Tristan A. Shah",
      "Patrick E. Leser",
      "Geoffrey F. Bomarito",
      "Joshua D. Pribe",
      "Michael C. Stanley"
    ],
    "abstract": "Deep generative models are promising tools for science and engineering, but\ntheir reliance on abundant, high-quality data limits applicability. We present\na novel framework for generative modeling of random fields (probability\ndistributions over continuous functions) that incorporates domain knowledge to\nsupplement limited, sparse, and indirect data. The foundation of the approach\nis latent flow matching, where generative modeling occurs on compressed\nfunction representations in the latent space of a pre-trained variational\nautoencoder (VAE). Innovations include the adoption of a function decoder\nwithin the VAE and integration of physical/statistical constraints into the VAE\ntraining process. In this way, a latent function representation is learned that\nyields continuous random field samples satisfying domain-specific constraints\nwhen decoded, even in data-limited regimes. Efficacy is demonstrated on two\nchallenging applications: wind velocity field reconstruction from sparse\nsensors and material property inference from a limited number of indirect\nmeasurements. Results show that the proposed framework achieves significant\nimprovements in reconstruction accuracy compared to unconstrained methods and\nenables effective inference with relatively small training datasets that is\nintractable without constraints.",
    "pdf_url": "http://arxiv.org/pdf/2505.13007v1",
    "published": "2025-05-19T11:47:44+00:00",
    "categories": [
      "cs.LG",
      "cs.CE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13006v1",
    "title": "Evaluating the Performance of RAG Methods for Conversational AI in the Airport Domain",
    "authors": [
      "Yuyang Li",
      "Philip J. M. Kerbusch",
      "Raimon H. R. Pruim",
      "Tobias K√§fer"
    ],
    "abstract": "Airports from the top 20 in terms of annual passengers are highly dynamic\nenvironments with thousands of flights daily, and they aim to increase the\ndegree of automation. To contribute to this, we implemented a Conversational AI\nsystem that enables staff in an airport to communicate with flight information\nsystems. This system not only answers standard airport queries but also\nresolves airport terminology, jargon, abbreviations, and dynamic questions\ninvolving reasoning. In this paper, we built three different\nRetrieval-Augmented Generation (RAG) methods, including traditional RAG, SQL\nRAG, and Knowledge Graph-based RAG (Graph RAG). Experiments showed that\ntraditional RAG achieved 84.84% accuracy using BM25 + GPT-4 but occasionally\nproduced hallucinations, which is risky to airport safety. In contrast, SQL RAG\nand Graph RAG achieved 80.85% and 91.49% accuracy respectively, with\nsignificantly fewer hallucinations. Moreover, Graph RAG was especially\neffective for questions that involved reasoning. Based on our observations, we\nthus recommend SQL RAG and Graph RAG are better for airport environments, due\nto fewer hallucinations and the ability to handle dynamic questions.",
    "pdf_url": "http://arxiv.org/pdf/2505.13006v1",
    "published": "2025-05-19T11:46:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13005v1",
    "title": "Full exceptional collections on the isotropic Grassmannians",
    "authors": [
      "Lyalya Guseva",
      "Alexander Novikov"
    ],
    "abstract": "We prove that the Kuznetsov--Polishchuk exceptional collections on rational\nhomogeneous spaces of the symplectic groups $\\mathrm{Sp}(2n,\\mathbb{C})$ are\nfull and consist of vector bundles. To achieve this, we construct several\nclasses of complexes, which we call generalized staircase complexes, symplectic\nstaircase complexes and secondary staircase complexes -- each of which may be\nof independent interest.",
    "pdf_url": "http://arxiv.org/pdf/2505.13005v1",
    "published": "2025-05-19T11:43:59+00:00",
    "categories": [
      "math.AG",
      "math.RT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13004v1",
    "title": "EffiBench-X: A Multi-Language Benchmark for Measuring Efficiency of LLM-Generated Code",
    "authors": [
      "Yuhao Qing",
      "Boyu Zhu",
      "Mingzhe Du",
      "Zhijiang Guo",
      "Terry Yue Zhuo",
      "Qianru Zhang",
      "Jie M. Zhang",
      "Heming Cui",
      "Siu-Ming Yiu",
      "Dong Huang",
      "See-Kiong Ng",
      "Luu Anh Tuan"
    ],
    "abstract": "Existing code generation benchmarks primarily evaluate functional\ncorrectness, with limited focus on code efficiency and often restricted to a\nsingle language like Python. To address this gap, we introduce EffiBench-X, the\nfirst multi-language benchmark designed to measure the efficiency of\nLLM-generated code. EffiBench-X supports Python, C++, Java, JavaScript, Ruby,\nand Golang. It comprises competitive programming tasks with human-expert\nsolutions as efficiency baselines. Evaluating state-of-the-art LLMs on\nEffiBench-X reveals that while models generate functionally correct code, they\nconsistently underperform human experts in efficiency. Even the most efficient\nLLM-generated solutions (Qwen3-32B) achieve only around \\textbf{62\\%} of human\nefficiency on average, with significant language-specific variations. LLMs show\nbetter efficiency in Python, Ruby, and JavaScript than in Java, C++, and\nGolang. For instance, DeepSeek-R1's Python code is significantly more efficient\nthan its Java code. These results highlight the critical need for research into\nLLM optimization techniques to improve code efficiency across diverse\nlanguages. The dataset and evaluation infrastructure are submitted and\navailable at https://github.com/EffiBench/EffiBench-X.git and\nhttps://huggingface.co/datasets/EffiBench/effibench-x.",
    "pdf_url": "http://arxiv.org/pdf/2505.13004v1",
    "published": "2025-05-19T11:43:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13003v1",
    "title": "Phase transitions from linear to nonlinear information processing in neural networks",
    "authors": [
      "Masaya Matsumura",
      "Taiki Haga"
    ],
    "abstract": "We investigate a phase transition from linear to nonlinear information\nprocessing in echo state networks, a widely used framework in reservoir\ncomputing. The network consists of randomly connected recurrent nodes perturbed\nby a noise and the output is obtained through linear regression on the network\nstates. By varying the standard deviation of the input weights, we\nsystematically control the nonlinearity of the network. For small input\nstandard deviations, the network operates in an approximately linear regime,\nresulting in limited information processing capacity. However, beyond a\ncritical threshold, the capacity increases rapidly, and this increase becomes\nsharper as the network size grows. Our results indicate the presence of a\ndiscontinuous transition in the limit of infinitely many nodes. This transition\nis fundamentally different from the conventional order-to-chaos transition in\nneural networks, which typically leads to a loss of long-term predictability\nand a decline in the information processing capacity. Furthermore, we establish\na scaling law relating the critical nonlinearity to the noise intensity, which\nimplies that the critical nonlinearity vanishes in the absence of noise.",
    "pdf_url": "http://arxiv.org/pdf/2505.13003v1",
    "published": "2025-05-19T11:42:14+00:00",
    "categories": [
      "cond-mat.dis-nn"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.13002v2",
    "title": "PIM-malloc: A Fast and Scalable Dynamic Memory Allocator for Processing-In-Memory (PIM) Architectures",
    "authors": [
      "Dongjae Lee",
      "Bongjoon Hyun",
      "Youngjin Kwon",
      "Minsoo Rhu"
    ],
    "abstract": "Dynamic memory allocation is essential in modern programming but remains\nunder-supported in current PIM devices. In this work, we first conduct a design\nspace exploration of PIM memory allocators, examining optimal metadata\nplacement and management strategies. Building on these insights, we propose\nPIM-malloc, a fast and scalable allocator for real PIM hardware, improving\nallocation performance by $66\\times$. We further enhance this design with a\nlightweight, per-PIM core hardware cache for dynamic allocation, achieving an\nadditional $31\\%$ performance gain. Finally, we demonstrate the effectiveness\nof PIM-malloc using a dynamic graph update workload, achieving a $28\\times$\nthroughput increase.",
    "pdf_url": "http://arxiv.org/pdf/2505.13002v2",
    "published": "2025-05-19T11:41:21+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13001v1",
    "title": "Competing Magnetic States in the Candidate Altermagnet GdAlGe",
    "authors": [
      "Oleg E. Parfenov",
      "Dmitry V. Averyanov",
      "Ivan S. Sokolov",
      "Alexey N. Mihalyuk",
      "Ivan A. Yakovlev",
      "Oleg A. Kondratev",
      "Alexander N. Taldenkov",
      "Andrey M. Tokmachev",
      "Vyacheslav G. Storchak"
    ],
    "abstract": "Altermagnetism, a newly discovered magnetic order, combines zero net\nmagnetization with non-relativistic spin splitting of electronic bands. Its\nability to utilize the advantages of both antiferromagnets and ferromagnets is\nhighly promising for spintronic applications. Currently, the merge of\naltermagnetism and weak ferromagnetism in a single material excites significant\ninterest as it provides additional control mechanisms over material properties.\nHowever, the role of dimensionality in this interplay is yet to be explored.\nHere, we study magnetism and electron transport in epitaxial films of the\ncandidate altermagnet GdAlGe ranging from bulklike to a single monolayer. The\nfilms exhibit the anomalous Hall effect and negative magnetoresistance. In\ncontrast to altermagnetic GdAlSi, the candidate altermagnet GdAlGe demonstrates\nan admixture of the ferromagnetic state which contribution increases as the\nsystem approaches the 2D limit. The coexistence of the magnetic states induces\ntechnologically important intrinsic exchange bias. The present work underpins\nfuture studies and applications of nanoscale altermagnets.",
    "pdf_url": "http://arxiv.org/pdf/2505.13001v1",
    "published": "2025-05-19T11:41:09+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.13000v1",
    "title": "DualCodec: A Low-Frame-Rate, Semantically-Enhanced Neural Audio Codec for Speech Generation",
    "authors": [
      "Jiaqi Li",
      "Xiaolong Lin",
      "Zhekai Li",
      "Shixi Huang",
      "Yuancheng Wang",
      "Chaoren Wang",
      "Zhenpeng Zhan",
      "Zhizheng Wu"
    ],
    "abstract": "Neural audio codecs form the foundational building blocks for language model\n(LM)-based speech generation. Typically, there is a trade-off between frame\nrate and audio quality. This study introduces a low-frame-rate, semantically\nenhanced codec model. Existing approaches distill semantically rich\nself-supervised (SSL) representations into the first-layer codec tokens. This\nwork proposes DualCodec, a dual-stream encoding approach that integrates SSL\nand waveform representations within an end-to-end codec framework. In this\nsetting, DualCodec enhances the semantic information in the first-layer codec\nand enables the codec system to maintain high audio quality while operating at\na low frame rate. Note that a low-frame-rate codec improves the efficiency of\nspeech generation. Experimental results on audio codec and speech generation\ntasks confirm the effectiveness of the proposed DualCodec compared to\nstate-of-the-art codec systems, such as Mimi Codec, SpeechTokenizer, DAC, and\nEncodec. Demos and codes are available at: https://dualcodec.github.io",
    "pdf_url": "http://arxiv.org/pdf/2505.13000v1",
    "published": "2025-05-19T11:41:08+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.13568v1",
    "title": "The Luminosity of the Darkness: Schechter function in dark sirens",
    "authors": [
      "Cezary Turski",
      "Maria Lisa Brozzetti",
      "Gergely D√°lya",
      "Michele Punturo",
      "Archisman Ghosh"
    ],
    "abstract": "Gravitational waves (GWs) offer a novel avenue for probing the Universe. One\nof their exciting applications is the independent measurement of the Hubble\nconstant, $H_0$, using dark standard sirens, which combine GW signals with\ngalaxy catalogues considering that GW events are hosted by galaxies. However,\ndue to the limited reach of telescopes, galaxy catalogues are incomplete at\nhigh redshifts. The commonly used GLADE+ is complete only up to redshift\n$z=0.1$, necessitating a model accounting for the galaxy luminosity\ndistribution accounting for the selection function of galaxies, typically\ndescribed by the Schechter function. In this paper, we examine the influence of\nthe Schechter function model on dark sirens, focusing on its redshift evolution\nand its impact on $H_0$ and rate parameters measurements. We find that\nneglecting the evolution of the Schechter function can influence the prior in\nredshift on GWs, which has particularly high impact for distant GW events with\nlimited galaxy catalogue support. Moreover, conducting a joint estimation of\n$H_0$ and the rate parameters, we find that allowing them to vary fixes the\nbias in $H_0$ but the rate parameter $\\gamma$ depends on the evolving Schechter\nfunction. Our results underscore the importance of incorporating an evolving\nSchechter function to account for changes in galaxy populations over cosmic\ntime, as this impacts rate parameters to which $H_0$ is sensitive.",
    "pdf_url": "http://arxiv.org/pdf/2505.13568v1",
    "published": "2025-05-19T11:40:58+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12999v1",
    "title": "A generalisable head MRI defacing pipeline: Evaluation on 2,566 meningioma scans",
    "authors": [
      "Lorena Garcia-Foncillas Macias",
      "Aaron Kujawa",
      "Aya Elshalakany",
      "Jonathan Shapey",
      "Tom Vercauteren"
    ],
    "abstract": "Reliable MRI defacing techniques to safeguard patient privacy while\npreserving brain anatomy are critical for research collaboration. Existing\nmethods often struggle with incomplete defacing or degradation of brain tissue\nregions. We present a robust, generalisable defacing pipeline for\nhigh-resolution MRI that integrates atlas-based registration with brain\nmasking. Our method was evaluated on 2,566 heterogeneous clinical scans for\nmeningioma and achieved a 99.92 per cent success rate (2,564/2,566) upon visual\ninspection. Excellent anatomical preservation is demonstrated with a Dice\nsimilarity coefficient of 0.9975 plus or minus 0.0023 between brain masks\nautomatically extracted from the original and defaced volumes. Source code is\navailable at https://github.com/cai4cai/defacing_pipeline.",
    "pdf_url": "http://arxiv.org/pdf/2505.12999v1",
    "published": "2025-05-19T11:39:18+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12998v1",
    "title": "A Skull-Adaptive Framework for AI-Based 3D Transcranial Focused Ultrasound Simulation",
    "authors": [
      "Vinkle Srivastav",
      "Juliette Puel",
      "Jonathan Vappou",
      "Elijah Van Houten",
      "Paolo Cabras",
      "Nicolas Padoy"
    ],
    "abstract": "Transcranial focused ultrasound (tFUS) is an emerging modality for\nnon-invasive brain stimulation and therapeutic intervention, offering\nmillimeter-scale spatial precision and the ability to target deep brain\nstructures. However, the heterogeneous and anisotropic nature of the human\nskull introduces significant distortions to the propagating ultrasound\nwavefront, which require time-consuming patient-specific planning and\ncorrections using numerical solvers for accurate targeting. To enable\ndata-driven approaches in this domain, we introduce TFUScapes, the first\nlarge-scale, high-resolution dataset of tFUS simulations through anatomically\nrealistic human skulls derived from T1-weighted MRI images. We have developed a\nscalable simulation engine pipeline using the k-Wave pseudo-spectral solver,\nwhere each simulation returns a steady-state pressure field generated by a\nfocused ultrasound transducer placed at realistic scalp locations. In addition\nto the dataset, we present DeepTFUS, a deep learning model that estimates\nnormalized pressure fields directly from input 3D CT volumes and transducer\nposition. The model extends a U-Net backbone with transducer-aware\nconditioning, incorporating Fourier-encoded position embeddings and MLP layers\nto create global transducer embeddings. These embeddings are fused with U-Net\nencoder features via feature-wise modulation, dynamic convolutions, and\ncross-attention mechanisms. The model is trained using a combination of\nspatially weighted and gradient-sensitive loss functions, enabling it to\napproximate high-fidelity wavefields. The TFUScapes dataset is publicly\nreleased to accelerate research at the intersection of computational acoustics,\nneurotechnology, and deep learning. The project page is available at\nhttps://github.com/CAMMA-public/TFUScapes.",
    "pdf_url": "http://arxiv.org/pdf/2505.12998v1",
    "published": "2025-05-19T11:37:51+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12997v1",
    "title": "Lexicographic Preferences over Random Availability Functions",
    "authors": [
      "Somdeb Lahiri"
    ],
    "abstract": "We provide an axiomatic characterization of lexicographic preferences over\nthe set of all random availability functions using two assumptions. The first\nassumption is strong monotonicity, which in our framework is equivalent to the\nstrong dominance property in microeconomics. The second assumption is\nindependence of worse alternatives and we show that a weaker version of the\nsame suffices for our purpose.",
    "pdf_url": "http://arxiv.org/pdf/2505.12997v1",
    "published": "2025-05-19T11:35:25+00:00",
    "categories": [
      "econ.TH",
      "math.OC"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.12996v1",
    "title": "ExTrans: Multilingual Deep Reasoning Translation via Exemplar-Enhanced Reinforcement Learning",
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "abstract": "In recent years, the emergence of large reasoning models (LRMs), such as\nOpenAI-o1 and DeepSeek-R1, has shown impressive capabilities in complex\nproblems, e.g., mathematics and coding. Some pioneering studies attempt to\nbring the success of LRMs in neural machine translation (MT). They try to build\nLRMs with deep reasoning MT ability via reinforcement learning (RL). Despite\nsome progress that has been made, these attempts generally focus on several\nhigh-resource languages, e.g., English and Chinese, leaving the performance on\nother languages unclear. Besides, the reward modeling methods in previous work\ndo not fully unleash the potential of reinforcement learning in MT. In this\nwork, we first design a new reward modeling method that compares the\ntranslation results of the policy MT model with a strong LRM (i.e.,\nDeepSeek-R1-671B), and quantifies the comparisons to provide rewards.\nExperimental results demonstrate the superiority of the reward modeling method.\nUsing Qwen2.5-7B-Instruct as the backbone, the trained model achieves the new\nstate-of-the-art performance in literary translation, and outperforms strong\nLRMs including OpenAI-o1 and DeepSeeK-R1. Furthermore, we extend our method to\nthe multilingual settings with 11 languages. With a carefully designed\nlightweight reward modeling in RL, we can simply transfer the strong MT ability\nfrom a single direction into multiple (i.e., 90) translation directions and\nachieve impressive multilingual MT performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.12996v1",
    "published": "2025-05-19T11:34:47+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12995v1",
    "title": "ACE: Confidential Computing for Embedded RISC-V Systems",
    "authors": [
      "Wojciech Ozga",
      "Guerney D. H. Hunt",
      "Michael V. Le",
      "Lennard G√§her",
      "Avraham Shinnar",
      "Elaine R. Palmer",
      "Hani Jamjoom",
      "Silvio Dragone"
    ],
    "abstract": "Confidential computing plays an important role in isolating sensitive\napplications from the vast amount of untrusted code commonly found in the\nmodern cloud. We argue that it can also be leveraged to build safer and more\nsecure mission-critical embedded systems. In this paper, we introduce the\nAssured Confidential Execution (ACE), an open-source and royalty-free\nconfidential computing technology targeted for embedded RISC-V systems. We\npresent a set of principles and a methodology that we used to build \\ACE and\nthat might be applied for developing other embedded systems that require formal\nverification. An evaluation of our prototype on the first available RISC-V\nhardware supporting virtualization indicates that ACE is a viable candidate for\nour target systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12995v1",
    "published": "2025-05-19T11:32:43+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12993v1",
    "title": "Spatiotemporal plasma hologram",
    "authors": [
      "Zhaohui Wu",
      "Hao Peng",
      "Xiaoming Zeng",
      "Zhaoli Li",
      "Xiaodong Wang",
      "Xiao Wang",
      "Jie Mu",
      "Yanlei Zuo",
      "Kainan Zhou",
      "Nathaniel J. Fisch",
      "C. Riconda",
      "S. Weber"
    ],
    "abstract": "We present the first experimental realization of a four-dimensional (4D)\nplasma hologram capable of recording and reconstructing the full spatiotemporal\ninformation of intense laser pulses. The holographic encoding is achieved\nthrough the interference of a long object pulse and a counter-propagating short\nreference pulse, generating an ionized plasma grating that captures both\nspatial and temporal characteristics of the laser field. A first-order\ndiffractive probe enables the retrieval of encoded information, successfully\nreconstructing the spatiotemporal profiles of Gaussian and Laguerre-Gaussian\nbeams. The experiment demonstrates the ability to encode artificial information\ninto the laser pulse via spectral modulation and retrieve it through plasma\ngrating diffraction, high-lighting potential applications in ultraintense\noptical data processing. Key innovations include a single-shot, background-free\nmethod for direct far-field spatiotemporal measurement and the obser-vation of\nlaser focus propagation dynamics in plasma. The plasma grating exhibits a\nstable lifetime of 30-40 ps and supports high repetition rates, suggesting\nusage for high-speed optical switches and plasmatic analog memory. These\nadvancements establish plasma holography as a robust platform for ultrafast\nlaser manipulation, with implications for secure optical communication, analog\ncomputing,and precision spatiotemporal control of high-intensity lasers.",
    "pdf_url": "http://arxiv.org/pdf/2505.12993v1",
    "published": "2025-05-19T11:31:32+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12994v3",
    "title": "Codec-Based Deepfake Source Tracing via Neural Audio Codec Taxonomy",
    "authors": [
      "Xuanjun Chen",
      "I-Ming Lin",
      "Lin Zhang",
      "Jiawei Du",
      "Haibin Wu",
      "Hung-yi Lee",
      "Jyh-Shing Roger Jang"
    ],
    "abstract": "Recent advances in neural audio codec-based speech generation (CoSG) models\nhave produced remarkably realistic audio deepfakes. We refer to deepfake speech\ngenerated by CoSG systems as codec-based deepfake, or CodecFake. Although\nexisting anti-spoofing research on CodecFake predominantly focuses on verifying\nthe authenticity of audio samples, almost no attention was given to tracing the\nCoSG used in generating these deepfakes. In CodecFake generation, processes\nsuch as speech-to-unit encoding, discrete unit modeling, and unit-to-speech\ndecoding are fundamentally based on neural audio codecs. Motivated by this, we\nintroduce source tracing for CodecFake via neural audio codec taxonomy, which\ndissects neural audio codecs to trace CoSG. Our experimental results on the\nCodecFake+ dataset provide promising initial evidence for the feasibility of\nCodecFake source tracing while also highlighting several challenges that\nwarrant further investigation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12994v3",
    "published": "2025-05-19T11:31:32+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.12992v3",
    "title": "Fractured Chain-of-Thought Reasoning",
    "authors": [
      "Baohao Liao",
      "Hanze Dong",
      "Yuhui Xu",
      "Doyen Sahoo",
      "Christof Monz",
      "Junnan Li",
      "Caiming Xiong"
    ],
    "abstract": "Inference-time scaling techniques have significantly bolstered the reasoning\ncapabilities of large language models (LLMs) by harnessing additional\ncomputational effort at inference without retraining. Similarly,\nChain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy\nby generating rich intermediate reasoning trajectories, but these approaches\nincur substantial token costs that impede their deployment in latency-sensitive\nsettings. In this work, we first show that truncated CoT, which stops reasoning\nbefore completion and directly generates the final answer, often matches full\nCoT sampling while using dramatically fewer tokens. Building on this insight,\nwe introduce Fractured Sampling, a unified inference-time strategy that\ninterpolates between full CoT and solution-only sampling along three orthogonal\naxes: (1) the number of reasoning trajectories, (2) the number of final\nsolutions per trajectory, and (3) the depth at which reasoning traces are\ntruncated. Through extensive experiments on five diverse reasoning benchmarks\nand several model scales, we demonstrate that Fractured Sampling consistently\nachieves superior accuracy-cost trade-offs, yielding steep log-linear scaling\ngains in Pass@k versus token budget. Our analysis reveals how to allocate\ncomputation across these dimensions to maximize performance, paving the way for\nmore efficient and scalable LLM reasoning. Code is available at\nhttps://github.com/BaohaoLiao/frac-cot.",
    "pdf_url": "http://arxiv.org/pdf/2505.12992v3",
    "published": "2025-05-19T11:30:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12991v1",
    "title": "Personalized Fine-Tuning with Controllable Synthetic Speech from LLM-Generated Transcripts for Dysarthric Speech Recognition",
    "authors": [
      "Dominik Wagner",
      "Ilja Baumann",
      "Natalie Engert",
      "Seanie Lee",
      "Elmar N√∂th",
      "Korbinian Riedhammer",
      "Tobias Bocklet"
    ],
    "abstract": "In this work, we present our submission to the Speech Accessibility Project\nchallenge for dysarthric speech recognition. We integrate parameter-efficient\nfine-tuning with latent audio representations to improve an encoder-decoder ASR\nsystem. Synthetic training data is generated by fine-tuning Parler-TTS to mimic\ndysarthric speech, using LLM-generated prompts for corpus-consistent target\ntranscripts. Personalization with x-vectors consistently reduces word error\nrates (WERs) over non-personalized fine-tuning. AdaLoRA adapters outperform\nfull fine-tuning and standard low-rank adaptation, achieving relative WER\nreductions of ~23% and ~22%, respectively. Further improvements (~5% WER\nreduction) come from incorporating wav2vec 2.0-based audio representations.\nTraining with synthetic dysarthric speech yields up to ~7% relative WER\nimprovement over personalized fine-tuning alone.",
    "pdf_url": "http://arxiv.org/pdf/2505.12991v1",
    "published": "2025-05-19T11:28:27+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.12990v2",
    "title": "From Theory to Practice: Analyzing VQPM for Quantum Optimization of QUBO Problems",
    "authors": [
      "Ammar Daskin"
    ],
    "abstract": "The variational quantum power method (VQPM), which adapts the classical power\niteration algorithm for quantum settings, has shown promise for eigenvector\nestimation and optimization on quantum hardware. In this work, we provide a\ncomprehensive theoretical and numerical analysis of VQPM by investigating its\nconvergence, robustness, and qubit locking mechanisms. We present detailed\nstrategies for applying VQPM to QUBO problems by leveraging these locking\nmechanisms. Based on the simulations for each strategy we have carried out, we\ngive systematic guidelines for their practical applications. We also offer a\nnumerical comparison with the quantum approximate optimization algorithm (QAOA)\nby running both algorithms on a set of trial problems. Our results indicate\nthat VQPM can be employed as an effective quantum optimization algorithm on\nquantum computers for QUBO problems, and this work can serve as an initial\nguideline for such applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.12990v2",
    "published": "2025-05-19T11:27:49+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12989v1",
    "title": "Ultrafast Laser Induces Macroscopic Symmetry-Breaking of Diamond Color Centers",
    "authors": [
      "Yang Gao",
      "Qi-Zheng Ji",
      "Chao-Bo Liu",
      "Qi Xiao",
      "Chao Lian"
    ],
    "abstract": "We employ real-time time-dependent density functional theory (RT-TDDFT) to\ninvestigate the electron-phonon-spin correlated dynamics in negatively charged\nnitrogen-vacancy centers (NV$^{-}$) and construct a comprehensive dynamical\npicture. Laser excitation promotes minority-spin electrons within 100~fs,\nestablishing a three-fold rotation symmetry breaking (3RSB) charge ordering.\nSubsequently, ionic motion on the potential energy surface of the excited\nelectrons generates two distinct dynamical modes: (1) symmetric oscillations of\ncarbon-nitrogen bonds and (2) dynamic Jahn-Teller distortions (DJT) with 3RSB.\nThese distortions induce nonlocal coherent phonons in the diamond lattice,\nwhich propagate with 3RSB at the sound velocity ($\\sim$2~\\AA/fs). Furthermore,\nthe NV$^{-}$ spin state remains preserved during photoexcitation but undergoes\nrapid reorientation within 100~fs via enhanced spin-orbit-phonon coupling. Our\nRT-TDDFT simulations provide direct time-resolved visualization of these\nprocesses, offering novel insights into the microscopic interplay of electrons,\nphonons, and spins in NV$^{-}$ centers. These results advance the fundamental\nunderstanding of dynamical mechanisms in solid-state quantum systems, with\nimplications for optimizing NV$^{-}$-based quantum sensing technologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.12989v1",
    "published": "2025-05-19T11:27:37+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.12988v1",
    "title": "Optimal Formats for Weight Quantisation",
    "authors": [
      "Douglas Orr",
      "Luka Ribar",
      "Carlo Luschi"
    ],
    "abstract": "Weight quantisation is an essential technique for enabling efficient training\nand deployment of modern deep learning models. However, the recipe book of\nquantisation formats is large and the formats are often chosen empirically. In\nthis paper, we propose a framework for systematic design and analysis of\nquantisation formats. By connecting the question of format design with the\nclassical quantisation theory, we show that the strong practical performance of\npopular formats comes from their ability to represent values using\nvariable-length codes. Framing the optimisation problem as minimising the KL\ndivergence between the original and quantised model outputs, the objective is\naligned with minimising the squared quantisation error of the model parameters.\nWe therefore develop and evaluate squared-error-optimal formats for known\ndistributions, observing significant improvement of variable-length codes over\nfixed-length codes. Uniform quantisation followed by lossless compression with\na variable-length code is shown to be optimal. However, we find that commonly\nused block formats and sparse outlier formats also outperform fixed-length\ncodes, implying they also exploit variable-length encoding. Finally, by using\nthe relationship between the Fisher information and KL divergence, we derive\nthe optimal allocation of bit-widths to individual parameter tensors across the\nmodel's layers, saving up to 0.25 bits per parameter when tested with\ndirect-cast quantisation of language models.",
    "pdf_url": "http://arxiv.org/pdf/2505.12988v1",
    "published": "2025-05-19T11:26:54+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12987v2",
    "title": "High-Performance ARM-on-ARM Virtualization for Multicore SystemC-TLM-Based Virtual Platforms",
    "authors": [
      "Nils Bosbach",
      "Rebecca Pelke",
      "Niko Zurstra√üen",
      "Jan Henrik Weinstock",
      "Lukas J√ºnger",
      "Rainer Leupers"
    ],
    "abstract": "The increasing complexity of hardware and software requires advanced\ndevelopment and test methodologies for modern systems on chips. This paper\npresents a novel approach to ARM-on-ARM virtualization within SystemC-based\nsimulators using Linux's KVM to achieve high-performance simulation. By running\ntarget software natively on ARM-based hosts with hardware-based virtualization\nextensions, our method eliminates the need for instruction-set simulators,\nwhich significantly improves performance. We present a multicore\nSystemC-TLM-based CPU model that can be used as a drop-in replacement for an\ninstruction-set simulator. It places no special requirements on the host\nsystem, making it compatible with various environments. Benchmark results show\nthat our ARM-on-ARM-based virtual platform achieves up to 10 x speedup over\ntraditional instruction-set-simulator-based models on compute-intensive\nworkloads. Depending on the benchmark, speedups increase to more than 100 x.",
    "pdf_url": "http://arxiv.org/pdf/2505.12987v2",
    "published": "2025-05-19T11:21:45+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12986v1",
    "title": "A new approach for solving the problem of creation of inverse electron distribution function and practical recommendations for experimental searches for such media in glow discharges with hollow and flat cathodes",
    "authors": [
      "Chengxun Yuan",
      "E. A. Bogdanov",
      "A. A. Kudryavtsev",
      "Jingfeng Yao",
      "Zhongxiang Zhou"
    ],
    "abstract": "This paper proposes a novel approach for creating an inverse electron\ndistribution function (EDF). Based on the obtained criteria for the formation\nof an inverse EDF in a non-uniform plasma, studies are conducted in low- and\nmedium-pressure glow discharges with flat and hollow cathodes. The results of\nthe numerical modeling and theoretical analysis are used to present reliable\ncriteria and scaling for the evaluation of the possible inversion of the EDF\nunder specific conditions. By solving the nonlocal Boltzmann kinetic equation\nin energy and coordinate variables, it is shown that the simplest way to\nimplement the inversion of the EDF is in a glow discharge with a hollow\ncathode. For such discharges, practical recommendations are developed and\nspecific conditions for the experimental detection of an inverse EDF are\nidentified.",
    "pdf_url": "http://arxiv.org/pdf/2505.12986v1",
    "published": "2025-05-19T11:21:41+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12985v1",
    "title": "Stark Energy Shifts due to Quantum Gravity in RGUP Algebra",
    "authors": [
      "Gaurav Bhandari",
      "S. D. Pathak"
    ],
    "abstract": "In this paper, we investigate the Stark effect in the hydrogen atom under an\nexternal electric field, incorporating relativistic generalized uncertainty\nprinciple (RGUP) corrections within Minkowskian spacetime and calculate the\nupper bound on $\\beta$ the RGUP parameter. Employing RGUP algebra and the\nStetsko-Tkachuk approximation, we derive modifications to the energy spectrum\nfor degenerate and non-degenerate states. The perturbed Hamiltonian, modified\nby RGUP, enfold quantum gravitational effects. Our results reveal quantum\ngravitational corrections to the Stark energy spectrum in the relativistic\nregime, with energy shifts for non-degenerate ($n=1$) and degenerate ($n \\neq\n1$) cases showing additional terms proportional to $\\beta$. These findings\nreduce to standard Stark effect results and non-relativistic GUP frameworks in\nthe limits $\\beta\\rightarrow 0$ and $c \\rightarrow \\infty $, establishing our\nmodel as a generalized framework for analyzing minimal length effects in\nrelativistic quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12985v1",
    "published": "2025-05-19T11:19:24+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP",
      "quant-ph"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.12984v1",
    "title": "Classical and Quantum cosmology for two scalar field Brans-Dicke type theory: A Noether Symmetry approach",
    "authors": [
      "Shriton Hembrom",
      "Roshni Bhaumik",
      "Sourav Dutta",
      "Subenoy Chakraborty"
    ],
    "abstract": "The paper deals with a cosmological model containing two scalar fields which\ncan be considered as an extension of the Brans-Dicke scalar field model. Due to\nhighly coupled non linear field equations, Noether Symmetry analysis has been\nimposed and as a result the Lagrangian as well as the field equations become\nmuch simple in form to have the classical solutions. The relevant cosmological\nparameters are analyzed graphically. Finally, quantum cosmology has been\nstudied by constructing the Wheeler-DeWitt equation and the solution of this\nsecond order partial differential equation has been done using this symmetry\nanalysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.12984v1",
    "published": "2025-05-19T11:19:18+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.12983v1",
    "title": "An Empirical Study of Many-to-Many Summarization with Large Language Models",
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Zengkui Sun",
      "Yunlong Liang",
      "Yuxuan Cao",
      "Jiarong Xu",
      "Haoxiang Shi",
      "Jie Zhou"
    ],
    "abstract": "Many-to-many summarization (M2MS) aims to process documents in any language\nand generate the corresponding summaries also in any language. Recently, large\nlanguage models (LLMs) have shown strong multi-lingual abilities, giving them\nthe potential to perform M2MS in real applications. This work presents a\nsystematic empirical study on LLMs' M2MS ability. Specifically, we first\nreorganize M2MS data based on eight previous domain-specific datasets. The\nreorganized data contains 47.8K samples spanning five domains and six\nlanguages, which could be used to train and evaluate LLMs. Then, we benchmark\n18 LLMs in a zero-shot manner and an instruction-tuning manner. Fine-tuned\ntraditional models (e.g., mBART) are also conducted for comparisons. Our\nexperiments reveal that, zero-shot LLMs achieve competitive results with\nfine-tuned traditional models. After instruct-tuning, open-source LLMs can\nsignificantly improve their M2MS ability, and outperform zero-shot LLMs\n(including GPT-4) in terms of automatic evaluations. In addition, we\ndemonstrate that this task-specific improvement does not sacrifice the LLMs'\ngeneral task-solving abilities. However, as revealed by our human evaluation,\nLLMs still face the factuality issue, and the instruction tuning might\nintensify the issue. Thus, how to control factual errors becomes the key when\nbuilding LLM summarizers in real applications, and is worth noting in future\nresearch.",
    "pdf_url": "http://arxiv.org/pdf/2505.12983v1",
    "published": "2025-05-19T11:18:54+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12982v3",
    "title": "Multi-parameter Control for the $(1+(Œª,Œª))$-GA on OneMax via Deep Reinforcement Learning",
    "authors": [
      "Tai Nguyen",
      "Phong Le",
      "Carola Doerr",
      "Nguyen Dang"
    ],
    "abstract": "It is well known that evolutionary algorithms can benefit from dynamic\nchoices of the key parameters that control their behavior, to adjust their\nsearch strategy to the different stages of the optimization process. A\nprominent example where dynamic parameter choices have shown a provable\nsuper-constant speed-up is the $(1+(\\lambda,\\lambda))$ Genetic Algorithm\noptimizing the OneMax function. While optimal parameter control policies result\nin linear expected running times, this is not possible with static parameter\nchoices. This result has spurred a lot of interest in parameter control\npolicies. However, many works, in particular theoretical running time analyses,\nfocus on controlling one single parameter. Deriving policies for controlling\nmultiple parameters remains very challenging. In this work we reconsider the\nproblem of the $(1+(\\lambda,\\lambda))$ Genetic Algorithm optimizing OneMax. We\ndecouple its four main parameters and investigate how well state-of-the-art\ndeep reinforcement learning techniques can approximate good control policies.\nWe show that although making deep reinforcement learning learn effectively is a\nchallenging task, once it works, it is very powerful and is able to find\npolicies that outperform all previously known control policies on the same\nbenchmark. Based on the results found through reinforcement learning, we derive\na simple control policy that consistently outperforms the default\ntheory-recommended setting by $27\\%$ and the irace-tuned policy, the strongest\nexisting control policy on this benchmark, by $13\\%$, for all tested problem\nsizes up to $40{,}000$.",
    "pdf_url": "http://arxiv.org/pdf/2505.12982v3",
    "published": "2025-05-19T11:18:41+00:00",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12981v2",
    "title": "From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents",
    "authors": [
      "Liangxuan Wu",
      "Chao Wang",
      "Tianming Liu",
      "Yanjie Zhao",
      "Haoyu Wang"
    ],
    "abstract": "The growing adoption of large language models (LLMs) has led to a new\nparadigm in mobile computing--LLM-powered mobile AI agents--capable of\ndecomposing and automating complex tasks directly on smartphones. However, the\nsecurity implications of these agents remain largely unexplored. In this paper,\nwe present the first comprehensive security analysis of mobile LLM agents,\nencompassing three representative categories: System-level AI Agents developed\nby original equipment manufacturers (e.g., YOYO Assistant), Third-party\nUniversal Agents (e.g., Zhipu AI AutoGLM), and Emerging Agent Frameworks (e.g.,\nAlibaba Mobile Agent). We begin by analyzing the general workflow of mobile\nagents and identifying security threats across three core capability\ndimensions: language-based reasoning, GUI-based interaction, and system-level\nexecution. Our analysis reveals 11 distinct attack surfaces, all rooted in the\nunique capabilities and interaction patterns of mobile LLM agents, and spanning\ntheir entire operational lifecycle. To investigate these threats in practice,\nwe introduce AgentScan, a semi-automated security analysis framework that\nsystematically evaluates mobile LLM agents across all 11 attack scenarios.\nApplying AgentScan to nine widely deployed agents, we uncover a concerning\ntrend: every agent is vulnerable to targeted attacks. In the most severe cases,\nagents exhibit vulnerabilities across eight distinct attack vectors. These\nattacks can cause behavioral deviations, privacy leakage, or even full\nexecution hijacking. Based on these findings, we propose a set of defensive\ndesign principles and practical recommendations for building secure mobile LLM\nagents. Our disclosures have received positive feedback from two major device\nvendors. Overall, this work highlights the urgent need for standardized\nsecurity practices in the fast-evolving landscape of LLM-driven mobile\nautomation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12981v2",
    "published": "2025-05-19T11:17:46+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12980v1",
    "title": "Algorithms for Nonlinear Mixed-Integer Location Estimation",
    "authors": [
      "Ophir Uziel",
      "Efi Fogel",
      "Dan Halperin",
      "Sivan Toledo"
    ],
    "abstract": "For three decades, carrier-phase observations have been used to obtain the\nmost accurate location estimates using global navigation satellite systems\n(GNSS). These estimates are computed by minimizing a nonlinear mixed-integer\nleast-squares problem. Existing algorithms linearize the problem, orthogonally\nproject it to eliminate real variables, and then solve the integer least-square\nproblem. There is now considerable interest in developing similar localization\ntechniques for terrestrial and indoor settings. We show that algorithms that\nlinearize first fail in these settings and we propose several algorithms for\ncomputing the estimates. Some of our algorithms are elimination algorithms that\nstart by eliminating the non-linear terms in the constraints; others construct\na geometric arrangement that allows us to efficiently enumerate integer\nsolutions (in polynomial time). We focus on simplified localization problems in\nwhich the measurements are range (distance) measurements and carrier phase\nrange measurements, with no nuisance parameters. The simplified problem allows\nus to focus on the core question of untangling the nonlinearity and the integer\nnature of some parameters. We show using simulations that the new algorithms\nare effective at close ranges at which the linearize-first approach fails.",
    "pdf_url": "http://arxiv.org/pdf/2505.12980v1",
    "published": "2025-05-19T11:17:17+00:00",
    "categories": [
      "eess.SP",
      "cs.MS",
      "math.OC"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12979v1",
    "title": "Tricritical Kibble-Zurek Scaling in Rydberg Atom Ladders",
    "authors": [
      "Hanteng Wang",
      "Xingyu Li",
      "Chengshu Li"
    ],
    "abstract": "The Kibble-Zurek (KZ) mechanism is being actively explored on quantum\nsimulation platforms. In this work, we study the KZ scaling around tricritical\nphase transition points, with Rydberg atom ladders as a concrete incarnation.\nThe criticality is of Ising and Potts type for two- and three-leg ladders,\nrespectively. When slowly ramping across or near the tricritical point from the\ndisordered phase to the ordered phase, we obtain universal power-law scaling in\nagreement with conventional KZ predictions. We study a \"tangential\" KZ ramping\nthat both begins and ends in the disordered phase, a novel protocol enabled by\nthe two-dimensional phase diagram. The tangential KZ directly reveals\nsubleading critical exponents of the critical point. Finally, we explore the\nregime of intermediate-speed ramping and find a dynamical analog of the\ncelebrated Zamolodchikov's c-theorem. Practically, our work provides an\nimmediately relevant protocol for current experiments to pinpoint the elusive\ntricritical points. More broadly, tangential and intermediate-speed rampings go\nbeyond the conventional KZ paradigm and introduce new insights into critical\nquantum dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.12979v1",
    "published": "2025-05-19T11:17:05+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "cond-mat.stat-mech",
      "cond-mat.str-el",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.12978v1",
    "title": "Enhancing Diffusion-Weighted Images (DWI) for Diffusion MRI: Is it Enough without Non-Diffusion-Weighted B=0 Reference?",
    "authors": [
      "Yinzhe Wu",
      "Jiahao Huang",
      "Fanwen Wang",
      "Mengze Gao",
      "Congyu Liao",
      "Guang Yang",
      "Kawin Setsompop"
    ],
    "abstract": "Diffusion MRI (dMRI) is essential for studying brain microstructure, but\nhigh-resolution imaging remains challenging due to the inherent trade-offs\nbetween acquisition time and signal-to-noise ratio (SNR). Conventional methods\noften optimize only the diffusion-weighted images (DWIs) without considering\ntheir relationship with the non-diffusion-weighted (b=0) reference images.\nHowever, calculating diffusion metrics, such as the apparent diffusion\ncoefficient (ADC) and diffusion tensor with its derived metrics like fractional\nanisotropy (FA) and mean diffusivity (MD), relies on the ratio between each DWI\nand the b=0 image, which is crucial for clinical observation and diagnostics.\nIn this study, we demonstrate that solely enhancing DWIs using a conventional\npixel-wise mean squared error (MSE) loss is insufficient, as the error in ratio\nbetween generated DWIs and b=0 diverges. We propose a novel ratio loss, defined\nas the MSE loss between the predicted and ground-truth log of DWI/b=0 ratios.\nOur results show that incorporating the ratio loss significantly improves the\nconvergence of this ratio error, achieving lower ratio MSE and slightly\nenhancing the peak signal-to-noise ratio (PSNR) of generated DWIs. This leads\nto improved dMRI super-resolution and better preservation of b=0 ratio-based\nfeatures for the derivation of diffusion metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.12978v1",
    "published": "2025-05-19T11:16:43+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12977v2",
    "title": "Regularized Model Predictive Control",
    "authors": [
      "Komeil Nosrati",
      "Juri Belikov",
      "Aleksei Tepljakov",
      "Eduard Petlenkov"
    ],
    "abstract": "In model predictive control (MPC), the choice of cost-weighting matrices and\ndesigning the Hessian matrix directly affects the trade-off between rapid state\nregulation and minimizing the control effort. However, traditional MPC in\nquadratic programming relies on fixed design matrices across the entire\nhorizon, which can lead to suboptimal performance. This letter presents a\nRiccati equation-based method for adjusting the design matrix within the MPC\nframework, which enhances real-time performance. We employ a penalized\nleast-squares (PLS) approach to derive a quadratic cost function for a\ndiscrete-time linear system over a finite prediction horizon. Using the method\nof weighting and enforcing the constraint equation by introducing a large\npenalty parameter, we solve the constrained optimization problem and generate\ncontrol inputs for forward-shifted horizons. This process yields a recursive\nPLS-based Riccati equation that updates the design matrix as a regularization\nterm in each shift, forming the foundation of the regularized MPC (Re-MPC)\nalgorithm. To accomplish this, we provide a convergence and stability analysis\nof the developed algorithm. Numerical analysis demonstrates its superiority\nover traditional methods by allowing Riccati equation-based adjustments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12977v2",
    "published": "2025-05-19T11:16:20+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.12976v2",
    "title": "Computing the Schulze Method for Large-Scale Preference Data Sets",
    "authors": [
      "Theresa Csar",
      "Martin Lackner",
      "Reinhard Pichler"
    ],
    "abstract": "The Schulze method is a voting rule widely used in practice and enjoys many\npositive axiomatic properties. While it is computable in polynomial time, its\nstraight-forward implementation does not scale well for large elections. In\nthis paper, we develop a highly optimised algorithm for computing the Schulze\nmethod with Pregel, a framework for massively parallel computation of graph\nproblems, and demonstrate its applicability for large preference data sets. In\naddition, our theoretic analysis shows that the Schulze method is indeed\nparticularly well-suited for parallel computation, in stark contrast to the\nrelated ranked pairs method. More precisely we show that winner determination\nsubject to the Schulze method is NL-complete, whereas this problem is\nP-complete for the ranked pairs method.",
    "pdf_url": "http://arxiv.org/pdf/2505.12976v2",
    "published": "2025-05-19T11:15:03+00:00",
    "categories": [
      "cs.GT",
      "cs.DC"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12975v1",
    "title": "A Faster Parametric Search for the Integral Quickest Transshipment Problem",
    "authors": [
      "Mariia Anapolska",
      "Dario van den Boom",
      "Christina B√ºsing",
      "Timo Gersing"
    ],
    "abstract": "Algorithms for computing fractional solutions to the quickest transshipment\nproblem have been significantly improved since Hoppe and Tardos first solved\nthe problem in strongly polynomial time. For integral solutions, runtime\nimprovements are limited to general progress on submodular function\nminimization, which is an integral part of Hoppe and Tardos' algorithm. Yet, no\nstructural improvements on their algorithm itself have been proposed. We\nreplace two central subroutines in the algorithm with methods that require\nvastly fewer minimizations of submodular functions. This improves the\nstate-of-the-art runtime from $ \\tilde{O}(m^4 k^{15}) $ down to $ \\tilde{O}(m^2\nk^5 + m^4 k^2) $, where $ k $ is the number of terminals and $ m $ is the\nnumber of arcs.",
    "pdf_url": "http://arxiv.org/pdf/2505.12975v1",
    "published": "2025-05-19T11:14:07+00:00",
    "categories": [
      "cs.DS",
      "math.OC"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.12974v1",
    "title": "Countermeasure against Detector Blinding Attack with Secret Key Leakage Estimation",
    "authors": [
      "Dmitry M. Melkonian",
      "Daniil S. Bulavkin",
      "Kirill E. Bugai",
      "Kirill A. Balygin",
      "Dmitriy A. Dvoretskiy"
    ],
    "abstract": "We present a countermeasure against the detector blinding attack (DBA)\nutilizing statistical analysis of error and double-click events accumulated\nduring a quantum key distribution session under randomized modulation of\nsingle-photon avalanche diode (SPAD) detection efficiencies via gate voltage\nmanipulation. Building upon prior work demonstrating the ineffectiveness of\nthis countermeasure against continuous-wave (CW) DBA, we extend the analysis to\nevaluate its performance against pulsed DBA. Our findings reveal an\napproximately 25 dB increase in the trigger pulse energies difference between\nhigh and low gate voltage applied under pulsed DBA conditions compared to CW\nDBA. This heightened difference enables a re-evaluation of the feasibility of\nutilizing SPAD detection probability variations as a countermeasure and makes\nit possible to estimate the fraction of bits compromised by an adversary during\npulsed DBA.",
    "pdf_url": "http://arxiv.org/pdf/2505.12974v1",
    "published": "2025-05-19T11:11:39+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12973v1",
    "title": "Fast, Not Fancy: Rethinking G2P with Rich Data and Rule-Based Models",
    "authors": [
      "Mahta Fetrat Qharabagh",
      "Zahra Dehghanian",
      "Hamid R. Rabiee"
    ],
    "abstract": "Homograph disambiguation remains a significant challenge in\ngrapheme-to-phoneme (G2P) conversion, especially for low-resource languages.\nThis challenge is twofold: (1) creating balanced and comprehensive homograph\ndatasets is labor-intensive and costly, and (2) specific disambiguation\nstrategies introduce additional latency, making them unsuitable for real-time\napplications such as screen readers and other accessibility tools. In this\npaper, we address both issues. First, we propose a semi-automated pipeline for\nconstructing homograph-focused datasets, introduce the HomoRich dataset\ngenerated through this pipeline, and demonstrate its effectiveness by applying\nit to enhance a state-of-the-art deep learning-based G2P system for Persian.\nSecond, we advocate for a paradigm shift - utilizing rich offline datasets to\ninform the development of fast, rule-based methods suitable for\nlatency-sensitive accessibility applications like screen readers. To this end,\nwe improve one of the most well-known rule-based G2P systems, eSpeak, into a\nfast homograph-aware version, HomoFast eSpeak. Our results show an approximate\n30% improvement in homograph disambiguation accuracy for the deep\nlearning-based and eSpeak systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12973v1",
    "published": "2025-05-19T11:11:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12972v2",
    "title": "A Non-Interventionist Approach to Causal Reasoning based on Lewisian Counterfactuals",
    "authors": [
      "Carlos Aguilera-Ventura",
      "Xinghan Liu",
      "Emiliano Lorini",
      "Dmitry Rozplokhas"
    ],
    "abstract": "We present a computationally grounded semantics for counterfactual\nconditionals in which i) the state in a model is decomposed into two elements:\na propositional valuation and a causal base in propositional form that\nrepresents the causal information available at the state; and ii) the\ncomparative similarity relation between states is computed from the states' two\ncomponents. We show that, by means of our semantics, we can elegantly formalize\nthe notion of actual cause without recurring to the primitive notion of\nintervention. Furthermore, we provide a succinct formulation of the model\nchecking problem for a language of counterfactual conditionals in our\nsemantics. We show that this problem is PSPACE-complete and provide a reduction\nof it into QBF that can be used for automatic verification of causal\nproperties.",
    "pdf_url": "http://arxiv.org/pdf/2505.12972v2",
    "published": "2025-05-19T11:09:49+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12971v1",
    "title": "Discrete-time Markov chains with random observation times",
    "authors": [
      "Daphne Aurouet",
      "Valentin Patilea"
    ],
    "abstract": "We propose a new approach for estimating the finite dimensional transition\nmatrix of a Markov chain using a large number of independent sample paths\nobserved at random times. The sample paths may be observed as few as two times,\nand the transitions are allowed to depend on covariates. Simple and easy to\nupdate kernel estimates are proposed, and their uniform convergence rates are\nderived. Simulation experiments show that our estimation approach performs\nwell.",
    "pdf_url": "http://arxiv.org/pdf/2505.12971v1",
    "published": "2025-05-19T11:09:34+00:00",
    "categories": [
      "stat.ME",
      "62M5, 62G05"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.12970v1",
    "title": "A Structured Literature Review on Traditional Approaches in Current Natural Language Processing",
    "authors": [
      "Robin Jegan",
      "Andreas Henrich"
    ],
    "abstract": "The continued rise of neural networks and large language models in the more\nrecent past has altered the natural language processing landscape, enabling new\napproaches towards typical language tasks and achieving mainstream success.\nDespite the huge success of large language models, many disadvantages still\nremain and through this work we assess the state of the art in five application\nscenarios with a particular focus on the future perspectives and sensible\napplication scenarios of traditional and older approaches and techniques.\n  In this paper we survey recent publications in the application scenarios\nclassification, information and relation extraction, text simplification as\nwell as text summarization. After defining our terminology, i.e., which\nfeatures are characteristic for traditional techniques in our interpretation\nfor the five scenarios, we survey if such traditional approaches are still\nbeing used, and if so, in what way they are used. It turns out that all five\napplication scenarios still exhibit traditional models in one way or another,\nas part of a processing pipeline, as a comparison/baseline to the core model of\nthe respective paper, or as the main model(s) of the paper. For the complete\nstatistics, see https://zenodo.org/records/13683801",
    "pdf_url": "http://arxiv.org/pdf/2505.12970v1",
    "published": "2025-05-19T11:06:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12969v1",
    "title": "Calm-Whisper: Reduce Whisper Hallucination On Non-Speech By Calming Crazy Heads Down",
    "authors": [
      "Yingzhi Wang",
      "Anas Alhmoud",
      "Saad Alsahly",
      "Muhammad Alqurishi",
      "Mirco Ravanelli"
    ],
    "abstract": "OpenAI's Whisper has achieved significant success in Automatic Speech\nRecognition. However, it has consistently been found to exhibit hallucination\nissues, particularly in non-speech segments, which limits its broader\napplication in complex industrial settings.\n  In this paper, we introduce a novel method to reduce Whisper's hallucination\non non-speech segments without using any pre- or post-possessing techniques.\nSpecifically, we benchmark the contribution of each self-attentional head in\nthe Whisper-large-v3 decoder to the hallucination problem by performing a\nhead-wise mask. Our findings reveal that only 3 of the 20 heads account for\nover 75% of the hallucinations on the UrbanSound dataset. We then fine-tune\nthese three crazy heads using a collection of non-speech data. The results show\nthat our best fine-tuned model, namely Calm-Whisper, achieves over 80%\nreduction in non-speech hallucination with only less than 0.1% WER degradation\non LibriSpeech test-clean and test-other.",
    "pdf_url": "http://arxiv.org/pdf/2505.12969v1",
    "published": "2025-05-19T11:04:52+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12968v1",
    "title": "Lara: Lightweight Anonymous Authentication with Asynchronous Revocation Auditability",
    "authors": [
      "Claudio Correia",
      "Guilherme Santos",
      "Luis Rodrigues"
    ],
    "abstract": "Anonymous authentication is a technique that allows to combine access control\nwith privacy preservation. Typically, clients use different pseudonyms for each\naccess, hindering providers from correlating their activities. To perform the\nrevocation of pseudonyms in a privacy preserving manner is notoriously\nchallenging. When multiple pseudonyms are revoked together, an adversary may\ninfer that these pseudonyms belong to the same client and perform privacy\nbreaking correlations, in particular if these pseudonyms have already been\nused. Backward unlinkability and revocation auditability are two properties\nthat address this problem. Most systems that offer these properties rely on\nsome sort of time slots, which assume a common reference of time that must be\nshared among clients and providers; for instance, the client must be aware that\nit should not use a pseudonym after a certain time or should be able to assess\nthe freshness of a revocation list prior to perform authentication. In this\npaper we propose Lara, a Lightweight Anonymous Authentication with Asynchronous\nRevocation Auditability that does not require parties to agree on the current\ntime slot and it is not affected by the clock skew. Prior to disclosing a\npseudonym, clients are provided with a revocation list (RL) and can check that\nthe pseudonym has not been revoked. Then, they provide a proof on\nnon-revocation that cannot be used against any other (past or future) RL,\navoiding any dependency of timing assumptions. Lara can be implemented using\nefficient public-key primitives and space-efficient data structures. We have\nimplemented a prototype of Lara and have assessed experimentally its\nefficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.12968v1",
    "published": "2025-05-19T11:03:09+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12967v1",
    "title": "Augmented Regression Models using Neurochaos Learning",
    "authors": [
      "Akhila Henry",
      "Nithin Nagaraj"
    ],
    "abstract": "This study presents novel Augmented Regression Models using Neurochaos\nLearning (NL), where Tracemean features derived from the Neurochaos Learning\nframework are integrated with traditional regression algorithms : Linear\nRegression, Ridge Regression, Lasso Regression, and Support Vector Regression\n(SVR). Our approach was evaluated using ten diverse real-life datasets and a\nsynthetically generated dataset of the form $y = mx + c + \\epsilon$. Results\nshow that incorporating the Tracemean feature (mean of the chaotic neural\ntraces of the neurons in the NL architecture) significantly enhances regression\nperformance, particularly in Augmented Lasso Regression and Augmented SVR,\nwhere six out of ten real-life datasets exhibited improved predictive accuracy.\nAmong the models, Augmented Chaotic Ridge Regression achieved the highest\naverage performance boost (11.35 %). Additionally, experiments on the simulated\ndataset demonstrated that the Mean Squared Error (MSE) of the augmented models\nconsistently decreased and converged towards the Minimum Mean Squared Error\n(MMSE) as the sample size increased. This work demonstrates the potential of\nchaos-inspired features in regression tasks, offering a pathway to more\naccurate and computationally efficient prediction models.",
    "pdf_url": "http://arxiv.org/pdf/2505.12967v1",
    "published": "2025-05-19T11:02:14+00:00",
    "categories": [
      "cs.LG",
      "math.DS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12966v1",
    "title": "Multiscale Adaptive Conflict-Balancing Model For Multimedia Deepfake Detection",
    "authors": [
      "Zihan Xiong",
      "Xiaohua Wu",
      "Lei Chen",
      "Fangqi Lou"
    ],
    "abstract": "Advances in computer vision and deep learning have blurred the line between\ndeepfakes and authentic media, undermining multimedia credibility through\naudio-visual forgery. Current multimodal detection methods remain limited by\nunbalanced learning between modalities. To tackle this issue, we propose an\nAudio-Visual Joint Learning Method (MACB-DF) to better mitigate modality\nconflicts and neglect by leveraging contrastive learning to assist in\nmulti-level and cross-modal fusion, thereby fully balancing and exploiting\ninformation from each modality. Additionally, we designed an\northogonalization-multimodal pareto module that preserves unimodal information\nwhile addressing gradient conflicts in audio-video encoders caused by differing\noptimization targets of the loss functions. Extensive experiments and ablation\nstudies conducted on mainstream deepfake datasets demonstrate consistent\nperformance gains of our model across key evaluation metrics, achieving an\naverage accuracy of 95.5% across multiple datasets. Notably, our method\nexhibits superior cross-dataset generalization capabilities, with absolute\nimprovements of 8.0% and 7.7% in ACC scores over the previous best-performing\napproach when trained on DFDC and tested on DefakeAVMiT and FakeAVCeleb\ndatasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.12966v1",
    "published": "2025-05-19T11:01:49+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12965v1",
    "title": "Experimental Particle Physics Priorities 2025: A String Phenomenology Perspective",
    "authors": [
      "Jonathan DeMont",
      "Alon E. Faraggi",
      "Mark Goodsell",
      "Marco Guzzi"
    ],
    "abstract": "With the SNOWMASS 2021 process in the US and the on--going European Strategy\nReport 2025, the field of elementary particle physics is undergoing detailed\ncommunity evaluation, and the experimental particle physics program, which\nrequires substantial public investment, is under scrutiny. We offer an\nassessment of the current experimental particle physics priorities from a\nstring phenomenology point of view. String theory provides a perturbatively\nconsistent framework for quantum gravity. String phenomenology aims to connect\nbetween string theory and observational data. String theory is a consistent\ntheory of quantum gravity that contains the other fundamental constituents of\nmatter and interactions. As all forms of energy couple to gravity, string\ntheory provides a framework that reproduces the structures of the Standard\nModel of particle physics and gives rise to detailed physics scenarios beyond\nthe Standard Model, {\\it e.g.} dark matter candidates, axions, additional gauge\nsymmetries, etc. Given this breadth, we propose that from a string\nphenomenology perspective, the experimental particle physics priority is the\nnature of the Higgs boson and the electroweak symmetry breaking mechanism. An\nideal facility in the near future to study this sector is a hadron collider at\n50--60 TeV that utilises contemporary magnet technology and can be built in\n10--15 years from decision.",
    "pdf_url": "http://arxiv.org/pdf/2505.12965v1",
    "published": "2025-05-19T11:00:49+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12964v1",
    "title": "MA-COIR: Leveraging Semantic Search Index and Generative Models for Ontology-Driven Biomedical Concept Recognition",
    "authors": [
      "Shanshan Liu",
      "Noriki Nishida",
      "Rumana Ferdous Munne",
      "Narumi Tokunaga",
      "Yuki Yamagata",
      "Kouji Kozaki",
      "Yuji Matsumoto"
    ],
    "abstract": "Recognizing biomedical concepts in the text is vital for ontology refinement,\nknowledge graph construction, and concept relationship discovery. However,\ntraditional concept recognition methods, relying on explicit mention\nidentification, often fail to capture complex concepts not explicitly stated in\nthe text. To overcome this limitation, we introduce MA-COIR, a framework that\nreformulates concept recognition as an indexing-recognition task. By assigning\nsemantic search indexes (ssIDs) to concepts, MA-COIR resolves ambiguities in\nontology entries and enhances recognition efficiency. Using a pretrained\nBART-based model fine-tuned on small datasets, our approach reduces\ncomputational requirements to facilitate adoption by domain experts.\nFurthermore, we incorporate large language models (LLMs)-generated queries and\nsynthetic data to improve recognition in low-resource settings. Experimental\nresults on three scenarios (CDR, HPO, and HOIP) highlight the effectiveness of\nMA-COIR in recognizing both explicit and implicit concepts without the need for\nmention-level annotations during inference, advancing ontology-driven concept\nrecognition in biomedical domain applications. Our code and constructed data\nare available at https://github.com/sl-633/macoir-master.",
    "pdf_url": "http://arxiv.org/pdf/2505.12964v1",
    "published": "2025-05-19T11:00:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13567v1",
    "title": "Learning Dynamics of RNNs in Closed-Loop Environments",
    "authors": [
      "Yoav Ger",
      "Omri Barak"
    ],
    "abstract": "Recurrent neural networks (RNNs) trained on neuroscience-inspired tasks offer\npowerful models of brain computation. However, typical training paradigms rely\non open-loop, supervised settings, whereas real-world learning unfolds in\nclosed-loop environments. Here, we develop a mathematical theory describing the\nlearning dynamics of linear RNNs trained in closed-loop contexts. We first\ndemonstrate that two otherwise identical RNNs, trained in either closed- or\nopen-loop modes, follow markedly different learning trajectories. To probe this\ndivergence, we analytically characterize the closed-loop case, revealing\ndistinct stages aligned with the evolution of the training loss. Specifically,\nwe show that the learning dynamics of closed-loop RNNs, in contrast to\nopen-loop ones, are governed by an interplay between two competing objectives:\nshort-term policy improvement and long-term stability of the agent-environment\ninteraction. Finally, we apply our framework to a realistic motor control task,\nhighlighting its broader applicability. Taken together, our results underscore\nthe importance of modeling closed-loop dynamics in a biologically plausible\nsetting.",
    "pdf_url": "http://arxiv.org/pdf/2505.13567v1",
    "published": "2025-05-19T11:00:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12963v1",
    "title": "Segmentation of temporomandibular joint structures on mri images using neural networks for diagnosis of pathologies",
    "authors": [
      "Maksim I. Ivanov",
      "Olga E. Mendybaeva",
      "Yuri E. Karyakin",
      "Igor N. Glukhikh",
      "Aleksey V. Lebedev"
    ],
    "abstract": "This article explores the use of artificial intelligence for the diagnosis of\npathologies of the temporomandibular joint (TMJ), in particular, for the\nsegmentation of the articular disc on MRI images. The relevance of the work is\ndue to the high prevalence of TMJ pathologies, as well as the need to improve\nthe accuracy and speed of diagnosis in medical institutions. During the study,\nthe existing solutions (Diagnocat, MandSeg) were analyzed, which, as a result,\nare not suitable for studying the articular disc due to the orientation towards\nbone structures. To solve the problem, an original dataset was collected from\n94 images with the classes \"temporomandibular joint\" and \"jaw\". To increase the\namount of data, augmentation methods were used. After that, the models of\nU-Net, YOLOv8n, YOLOv11n and Roboflow neural networks were trained and\ncompared. The evaluation was carried out according to the Dice Score,\nPrecision, Sensitivity, Specificity, and Mean Average Precision metrics. The\nresults confirm the potential of using the Roboflow model for segmentation of\nthe temporomandibular joint. In the future, it is planned to develop an\nalgorithm for measuring the distance between the jaws and determining the\nposition of the articular disc, which will improve the diagnosis of TMJ\npathologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.12963v1",
    "published": "2025-05-19T10:58:02+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12962v1",
    "title": "The Importance of Layer-Dependent Molecular Twisting for the Structural Anisotropy of Interfacial Water",
    "authors": [
      "Alexander P. Fellows",
      "Louis Lehmann",
      "√Ålvaro D√≠az Duque",
      "Martin Wolf",
      "Roland R. Netz",
      "Martin Th√§mer"
    ],
    "abstract": "The unique structural properties of interfacial water are at the heart of a\nvast range of important processes in electrochemistry, climate science, and\nbiophysics. At interfaces, water molecules exhibit preferential orientations\nand an altered intermolecular H-bond connectivity. Characterising this\nlayer-dependent anisotropic structure for such a thin molecular boundary,\nhowever, is a veritable challenge, with many important details remaining\nunknown. Here, we combine a novel depth-resolved second-order spectroscopy with\nmolecular dynamics simulations to study the anisotropic structure at the\nair-water interface through the H-O-H bending vibration. We firstly show that\nthe experimental nonlinear spectrum contains a large bulk like (quadrupolar)\ncontribution that has hampered the assessment of the interfacial structure in\nprevious investigations. By subtracting this contribution, we uncover the\nelusive anisotropic interfacial response that quantitatively matches the\nsimulated prediction. Thereafter, by analysing both the vibrational line-shape\nof the interfacial spectrum and its depth-dependence, we demonstrate that both\nthe molecular tilt and twist angles of water must be highly restricted at the\ninterface, which is confirmed by the simulated orientational distribution.\nFinally, by analysing the depth and orientation dependence of the bending\nfrequency, we show substantial deviations from the expected behaviour,\nrevealing an anomalous character to the interfacial H-bond network.",
    "pdf_url": "http://arxiv.org/pdf/2505.12962v1",
    "published": "2025-05-19T10:56:36+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13566v1",
    "title": "Workflows and Principles for Collaboration and Communication in Battery Research",
    "authors": [
      "Yannick Kuhn",
      "Bhawna Rana",
      "Micha Philipp",
      "Christina Schmitt",
      "Roberto Scipioni",
      "Eibar Flores",
      "Dennis Kopljar",
      "Simon Clark",
      "Arnulf Latz",
      "Birger Horstmann"
    ],
    "abstract": "Interdisciplinary collaboration in battery science is required for rapid\nevaluation of better compositions and materials. However, diverging domain\nvocabulary and non-compatible experimental results slow down cooperation. We\ncritically assess the current state-of-the-art and develop a structured data\nmanagement and interpretation system to make data curation sustainable. The\ntechniques we utilize comprise ontologies to give a structure to knowledge,\ndatabase systems tenable to the FAIR principles, and software engineering to\nbreak down data processing into verifiable steps. To demonstrate our approach,\nwe study the applicability of the Galvanostatic Intermittent Titration\nTechnique on various electrodes. Our work is a building block in making\nautomated material science scale beyond individual laboratories to a worldwide\nconnected search for better battery materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.13566v1",
    "published": "2025-05-19T10:55:52+00:00",
    "categories": [
      "cs.DB",
      "physics.data-an"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.12961v1",
    "title": "Study of the hottest droplet of fluid through correlations and fluctuations of collective variables",
    "authors": [
      "Rupam Samanta"
    ],
    "abstract": "In this thesis, we focus on the fluctuations and correlations of the\ncollective observables such as the mean transverse momentum per particle\n($[p_T]$) and harmonic flow coefficients ($v_n$) of particles produced in the\nultrarelativistic heavy-ion collisions at RHIC and the LHC. Specifically, we\nshow that the fluctuations of harmonic flow can be probed by the\nfactorization-breaking coefficients between flow vectors in different\n$p_T$-bins. Experimental difficulty can be reduced by taking one of the flow\nvectors momentum averaged. Fluctuations cause a decorrelation between the flow\nvectors, which can be attributed to equal contributions from the flow magnitude\nand flow angle decorrelation. We study fluctuations of mean transverse momentum\nper particle ($[p_T]$) in ultra-central collisions and show that our model can\nexplain the steep fall of its variance observed by the ATLAS collaboration. We\nalso present robust predictions for the skewness and kurtosis, and highlight\nthe role of impact parameter fluctuations in ultracentral collisions. We study\nthe Pearson correlation coefficients between $[p_T]$ and $v_n^2$, which can map\nthe initial state correlations between the shape and size of the fireball. We\nshow that higher order normalized and symmetric cumulants between these\nobservables can be constructed, which put useful additional constraints on the\ninitial state properties. Furthermore, we study the momentum dependent Pearson\ncorrelation between $[p_T]$ and the transverse momentum dependent flow. It\nshows sensitivity to the Gaussian width of the nucleon at the initial state.\nFinally, we show that such correlations and fluctuations of collective\nobservables can be used to study nuclear deformation and put robust constraints\non their deformation parameters through high energy nuclear collisions.",
    "pdf_url": "http://arxiv.org/pdf/2505.12961v1",
    "published": "2025-05-19T10:55:36+00:00",
    "categories": [
      "nucl-th",
      "hep-ph"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.12960v1",
    "title": "Hardware-Adaptive and Superlinear-Capacity Memristor-based Associative Memory",
    "authors": [
      "Chengping He",
      "Mingrui Jiang",
      "Keyi Shan",
      "Szu-Hao Yang",
      "Zefan Li",
      "Shengbo Wang",
      "Giacomo Pedretti",
      "Jim Ignowski",
      "Can Li"
    ],
    "abstract": "Brain-inspired computing aims to mimic cognitive functions like associative\nmemory, the ability to recall complete patterns from partial cues. Memristor\ntechnology offers promising hardware for such neuromorphic systems due to its\npotential for efficient in-memory analog computing. Hopfield Neural Networks\n(HNNs) are a classic model for associative memory, but implementations on\nconventional hardware suffer from efficiency bottlenecks, while prior\nmemristor-based HNNs faced challenges with vulnerability to hardware defects\ndue to offline training, limited storage capacity, and difficulty processing\nanalog patterns. Here we introduce and experimentally demonstrate on integrated\nmemristor hardware a new hardware-adaptive learning algorithm for associative\nmemories that significantly improves defect tolerance and capacity, and\nnaturally extends to scalable multilayer architectures capable of handling both\nbinary and continuous patterns. Our approach achieves 3x effective capacity\nunder 50% device faults compared to state-of-the-art methods. Furthermore, its\nextension to multilayer architectures enables superlinear capacity scaling\n(\\(\\propto N^{1.49}\\ for binary patterns) and effective recalling of continuous\npatterns (\\propto N^{1.74}\\ scaling), as compared to linear capacity scaling\nfor previous HNNs. It also provides flexibility to adjust capacity by tuning\nhidden neurons for the same-sized patterns. By leveraging the massive\nparallelism of the hardware enabled by synchronous updates, it reduces energy\nby 8.8x and latency by 99.7% for 64-dimensional patterns over asynchronous\nschemes, with greater improvements at scale. This promises the development of\nmore reliable memristor-based associative memory systems and enables new\napplications research due to the significantly improved capacity, efficiency,\nand flexibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.12960v1",
    "published": "2025-05-19T10:55:09+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12959v1",
    "title": "On neutron holography, neutron interferometry and neutron orbital angular momentum",
    "authors": [
      "Wolfgang Treimer",
      "Frank Hau√üer",
      "Ingeborg Beckers",
      "Martin Suda",
      "Terrence Jach"
    ],
    "abstract": "A neutron Laue crystal interferometer has been reported by Saranac et al . to\ndemonstrate neutron holography of a spiral phase plate. Using its two coherent\nbeams as the object and reference beams, the resulting interference pattern was\ninterpreted as a hologram. This interference pattern was then reported to\nreconstruct neutron beams with various intrinsic orbital angular momenta. There\nare serious doubts about the method for generating neutron orbital angular\nmomentum with a crystal interferometer. Due to the extremely different lateral\ncoherence lengths in the interferometer, one should expect the pattern\ndescribed as a hologram to be asymmetric. In addition, a neutron crystal\ninterferometer always produces a Moire image where the beams are combined in\nthe final crystal, that appears as a one-dimensional enlargement of the\ninterference pattern. We present computer simulations showing that the images\npresented as holograms can be computed as conventional interference patterns\nassuming the phase shifts of ordinary neutrons passing through objects located\nin one or the other beam path of the interferometer. Additionally, we discuss\nthe complications of using a crystal interferometer for holography, while\nraising the question of whether the intrinsic orbital angular momentum states\nof neutrons are necessary or sufficient to explain the recorded images.",
    "pdf_url": "http://arxiv.org/pdf/2505.12959v1",
    "published": "2025-05-19T10:54:53+00:00",
    "categories": [
      "quant-ph",
      "quantum mechanics",
      "G.1"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12958v1",
    "title": "Nanoindentation simulations for copper and tungsten with adaptive-precision potentials",
    "authors": [
      "David Immel",
      "Matous Mrovec",
      "Ralf Drautz",
      "Godehard Sutmann"
    ],
    "abstract": "We perform nanoindentation simulations for both the prototypical\nface-centered cubic metal copper and the body-centered cubic metal tungsten\nwith a new adaptive-precision description of interaction potentials including\ndifferent accuracy and computational costs: We combine both a computationally\nefficient embedded atom method (EAM) potential and a precise but\ncomputationally less efficient machine learning potential based on the atomic\ncluster expansion (ACE) into an adaptive-precision (AP) potential tailored for\nthe nanoindentation. The numerically expensive ACE potential is employed\nselectively only in regions of the computational cell where large accuracy is\nrequired. The comparison with pure EAM and pure ACE simulations shows that for\nCu, all potentials yield similar dislocation morphologies under the indenter\nwith only small quantitative differences. In contrast, markedly different\nplasticity mechanisms are observed for W in simulations performed with the\ncentral-force EAM potential compared to results obtained using the ACE\npotential which is able to describe accurately the angular character of bonding\nin W due to its half-filled d-band. All ACE-specific mechanisms are reproduced\nin the AP nanoindentation simulations, however, with a significant speedup of\n20-30 times compared to the pure ACE simulations. Hence, the AP potential\novercomes the performance gap between the precise ACE and the fast EAM\npotential by combining the advantages of both potentials.",
    "pdf_url": "http://arxiv.org/pdf/2505.12958v1",
    "published": "2025-05-19T10:53:56+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.13565v1",
    "title": "Aligning Trustworthy AI with Democracy: A Dual Taxonomy of Opportunities and Risks",
    "authors": [
      "Oier Mentxaka",
      "Natalia D√≠az-Rodr√≠guez",
      "Mark Coeckelbergh",
      "Marcos L√≥pez de Prado",
      "Emilia G√≥mez",
      "David Fern√°ndez Llorca",
      "Enrique Herrera-Viedma",
      "Francisco Herrera"
    ],
    "abstract": "Artificial Intelligence (AI) poses both significant risks and valuable\nopportunities for democratic governance. This paper introduces a dual taxonomy\nto evaluate AI's complex relationship with democracy: the AI Risks to Democracy\n(AIRD) taxonomy, which identifies how AI can undermine core democratic\nprinciples such as autonomy, fairness, and trust; and the AI's Positive\nContributions to Democracy (AIPD) taxonomy, which highlights AI's potential to\nenhance transparency, participation, efficiency, and evidence-based\npolicymaking.\n  Grounded in the European Union's approach to ethical AI governance, and\nparticularly the seven Trustworthy AI requirements proposed by the European\nCommission's High-Level Expert Group on AI, each identified risk is aligned\nwith mitigation strategies based on EU regulatory and normative frameworks. Our\nanalysis underscores the transversal importance of transparency and societal\nwell-being across all risk categories and offers a structured lens for aligning\nAI systems with democratic values.\n  By integrating democratic theory with practical governance tools, this paper\noffers a normative and actionable framework to guide research, regulation, and\ninstitutional design to support trustworthy, democratic AI. It provides\nscholars with a conceptual foundation to evaluate the democratic implications\nof AI, equips policymakers with structured criteria for ethical oversight, and\nhelps technologists align system design with democratic principles. In doing\nso, it bridges the gap between ethical aspirations and operational realities,\nlaying the groundwork for more inclusive, accountable, and resilient democratic\nsystems in the algorithmic age.",
    "pdf_url": "http://arxiv.org/pdf/2505.13565v1",
    "published": "2025-05-19T10:51:08+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.12957v2",
    "title": "Thermal transport mapping in twisted double bilayer graphene",
    "authors": [
      "Roop Kumar Mech",
      "Alessandra Canetta",
      "Yubin Huang",
      "Sergio Gonzalez-Munoz",
      "Khushboo Agarwal",
      "Pauline de Crombrugghe",
      "Yuanzhuo Hong",
      "Sambit Mohapatra",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Bernard Nysten",
      "Beno√Æt Hackens",
      "Rebeca Ribeiro-Palau",
      "Oleg Kolosov",
      "Jean Sp√®ce",
      "Pascal Gehring"
    ],
    "abstract": "Two-dimensional (2D) materials have attracted significant interest due to\ntheir tunable physical properties when stacked into homo- and\nhetero-structures. Twisting adjacent layers introduces moir\\'{e} patterns that\nstrongly influence the material electronic and thermal behavior. In twisted\ngraphene systems, the twist angle critically alters phonon transport, leading\nto reduced thermal conductivity compared to Bernal-stacked configurations.\nHowever, experimental investigations into thermal transport in twisted\nstructures remain limited. Here, we study the local thermal properties of\ntwisted double bilayer graphene (TDBG) using Scanning Thermal Microscopy\n(SThM). We find an increase in thermal resistance of $0.3 \\pm 0.1 \\times 10^6\nKW^{-1}$ compared to untwisted bilayers, attributed to changes in both\nintrinsic thermal conductivity and the tip-sample interface. These results,\nsupported by analytical modeling, provide new insight into thermal transport\nmechanisms in twisted 2D systems and offer a pathway toward thermal engineering\nin twistronic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.12957v2",
    "published": "2025-05-19T10:48:01+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.12956v1",
    "title": "Variability analysis in memristors based on electrodeposited prussian blue",
    "authors": [
      "L. B. Avila",
      "A. Cantudo",
      "M. A. Villena",
      "D. Maldonado",
      "F. Abreu Araujo",
      "C. K. M√ºller",
      "J. B. Rold√°n"
    ],
    "abstract": "This work presents a comprehensive analysis of the variability and\nreliability of the resistive switching (RS) behavior in Prussian Blue (a\nmixed-valence iron(III/II) hexacyanoferrate compound) thin films, used as the\nactive layer. These films are fabricated through a simple and scalable\nelectrochemical process, and exhibit robust bipolar resistive switching, making\nthem suitable both for neuromorphic computing applications and hardware\ncryptography. A detailed statistical evaluation was conducted over 100\nconsecutive switching cycles using multiple parameter extraction techniques to\nassess cycle-to-cycle (C2C) variability in key RS parameters, including\nset/reset voltages and corresponding currents. One and two-dimensional\ncoefficients of variation (1DCV and 2DCV) were calculated to quantify\nvariability and identify application potential. Results demonstrate moderate\nvariability compatible with neuromorphic computing and cryptographic\nfunctionalities, including physical unclonable functions and true random number\ngeneration. These findings position Prussian Blue-based memristors as promising\ncandidates for low-cost, stable, and multifunctional memory.",
    "pdf_url": "http://arxiv.org/pdf/2505.12956v1",
    "published": "2025-05-19T10:48:00+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.12955v1",
    "title": "High-Q photonic crystal Fabry-Perot micro-resonator in thin-film lithium niobate",
    "authors": [
      "Hyeon Hwang",
      "Seokjoo Go",
      "Guhwan Kim",
      "Hong-Seok Kim",
      "Kiwon Moon",
      "Jung Jin Ju",
      "Hansuek Lee",
      "Min-Kyo Seo"
    ],
    "abstract": "Thin-film lithium niobate (TFLN) has emerged as a powerful platform for\nintegrated nonlinear and quantum photonics, owing to its strong optical\nnonlinearities, wide transparency window, and electro- and piezo-optic\nproperties. However, conventional traveling-wave resonators, such as\nmicro-rings, disks, and racetracks, suffer from curvature-dependent group\ndispersion and losses, limited spectral tunability, and parasitic\nnonlinearities, which constrain their performance, scalability, and operational\nstability in nonlinear photonic circuits. Here, we present photonic crystal\n(PhC) Fabry-Perot (FP) micro-resonators in TFLN that address these limitations.\nThe device features a one-dimensional straight cavity bounded by PhC reflectors\nand supports well-confined standing-wave resonant modes within an engineered\nphotonic bandgap. We achieve intrinsic quality (Q) factors of up to 1.4e6 and\ndemonstrate that both the free spectral range (FSR) and coupling strength can\nbe consistently controlled via cavity length and PhC coupler design,\nrespectively. The photonic bandgap is tunable across the S-, C-, and L-bands\nwithout degradation of resonator performance. Spectral confinement of high-Q\nresonant modes is expected to mitigate parasitic nonlinearities, such as Raman\nscattering. These advances, together with the one-dimensional geometry,\nestablish PhC FP micro-resonators as compact and scalable building blocks for\nhigh-density photonic integrated circuits targeting next-generation nonlinear\nand quantum applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.12955v1",
    "published": "2025-05-19T10:46:30+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.12954v1",
    "title": "Counting Graphlets of Size $k$ under Local Differential Privacy",
    "authors": [
      "Vorapong Suppakitpaisarn",
      "Donlapark Ponnoprat",
      "Nicha Hirankarn",
      "Quentin Hillebrand"
    ],
    "abstract": "The problem of counting subgraphs or graphlets under local differential\nprivacy is an important challenge that has attracted significant attention from\nresearchers. However, much of the existing work focuses on small graphlets like\ntriangles or $k$-stars. In this paper, we propose a non-interactive, locally\ndifferentially private algorithm capable of counting graphlets of any size $k$.\nWhen $n$ is the number of nodes in the input graph, we show that the expected\n$\\ell_2$ error of our algorithm is $O(n^{k - 1})$. Additionally, we prove that\nthere exists a class of input graphs and graphlets of size $k$ for which any\nnon-interactive counting algorithm incurs an expected $\\ell_2$ error of\n$\\Omega(n^{k - 1})$, demonstrating the optimality of our result. Furthermore,\nwe establish that for certain input graphs and graphlets, any locally\ndifferentially private algorithm must have an expected $\\ell_2$ error of\n$\\Omega(n^{k - 1.5})$. Our experimental results show that our algorithm is more\naccurate than the classical randomized response method.",
    "pdf_url": "http://arxiv.org/pdf/2505.12954v1",
    "published": "2025-05-19T10:46:21+00:00",
    "categories": [
      "cs.SI",
      "cs.CC",
      "cs.DS"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12953v1",
    "title": "Hydrogen Bond Topology Reveals Layering of LDL-like and HDL-like Water at its Liquid/Vapor Interface",
    "authors": [
      "Pal Jedlovszky",
      "Christoph Dellago",
      "Marcello Sega"
    ],
    "abstract": "The discovery of high-density liquid (HDL) and low-density liquid (LDL) water\nhas been a major success of molecular simulations, yet extending this analysis\nto interfacial water is challenging due to conventional order parameters\nassuming local homogeneity. This limitation previously prevented resolving the\ncomposition of the surface layer of the liquid/vapour interface. Here, we apply\na recently introduced topological order parameter [R. Foffi and F. Sciortino,\nJ. Phys. Chem. B 127, 378-386 (2022)] to analyze the composition of the\nwater/vapor interface across a broad temperature range. Our results reveal that\nLDL-like water dominates the outermost region at all temperatures, while\nHDL-like water accumulates beneath it, presenting a clear layering roughly\nbelow the temperature of maximum density. This structured stratification,\npreviously inaccessible, highlights the power of the topological order\nparameter in resolving interfacial molecular heterogeneity and provides new\ninsights into the structural properties of water at interfaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.12953v1",
    "published": "2025-05-19T10:45:33+00:00",
    "categories": [
      "cond-mat.soft",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.12952v1",
    "title": "LoD: Loss-difference OOD Detection by Intentionally Label-Noisifying Unlabeled Wild Data",
    "authors": [
      "Chuanxing Geng",
      "Qifei Li",
      "Xinrui Wang",
      "Dong Liang",
      "Songcan Chen",
      "Pong C. Yuen"
    ],
    "abstract": "Using unlabeled wild data containing both in-distribution (ID) and\nout-of-distribution (OOD) data to improve the safety and reliability of models\nhas recently received increasing attention. Existing methods either design\ncustomized losses for labeled ID and unlabeled wild data then perform joint\noptimization, or first filter out OOD data from the latter then learn an OOD\ndetector. While achieving varying degrees of success, two potential issues\nremain: (i) Labeled ID data typically dominates the learning of models,\ninevitably making models tend to fit OOD data as IDs; (ii) The selection of\nthresholds for identifying OOD data in unlabeled wild data usually faces\ndilemma due to the unavailability of pure OOD samples. To address these issues,\nwe propose a novel loss-difference OOD detection framework (LoD) by\n\\textit{intentionally label-noisifying} unlabeled wild data. Such operations\nnot only enable labeled ID data and OOD data in unlabeled wild data to jointly\ndominate the models' learning but also ensure the distinguishability of the\nlosses between ID and OOD samples in unlabeled wild data, allowing the classic\nclustering technique (e.g., K-means) to filter these OOD samples without\nrequiring thresholds any longer. We also provide theoretical foundation for\nLoD's viability, and extensive experiments verify its superiority.",
    "pdf_url": "http://arxiv.org/pdf/2505.12952v1",
    "published": "2025-05-19T10:44:52+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12951v1",
    "title": "DGRO: Enhancing LLM Reasoning via Exploration-Exploitation Control and Reward Variance Management",
    "authors": [
      "Xuerui Su",
      "Liya Guo",
      "Yue Wang",
      "Yi Zhu",
      "Zhiming Ma",
      "Zun Wang",
      "Yuting Liu"
    ],
    "abstract": "Inference scaling further accelerates Large Language Models (LLMs) toward\nArtificial General Intelligence (AGI), with large-scale Reinforcement Learning\n(RL) to unleash long Chain-of-Thought reasoning. Most contemporary reasoning\napproaches usually rely on handcrafted rule-based reward functions. However,\nthe tarde-offs of exploration and exploitation in RL algorithms involves\nmultiple complex considerations, and the theoretical and empirical impacts of\nmanually designed reward functions remain insufficiently explored. In this\npaper, we propose Decoupled Group Reward Optimization (DGRO), a general RL\nalgorithm for LLM reasoning. On the one hand, DGRO decouples the traditional\nregularization coefficient into two independent hyperparameters: one scales the\npolicy gradient term, and the other regulates the distance from the sampling\npolicy. This decoupling not only enables precise control over balancing\nexploration and exploitation, but also can be seamlessly extended to Online\nPolicy Mirror Descent (OPMD) algorithms in Kimi k1.5 and Direct Reward\nOptimization. On the other hand, we observe that reward variance significantly\naffects both convergence speed and final model performance. We conduct both\ntheoretical analysis and extensive empirical validation to assess DGRO,\nincluding a detailed ablation study that investigates its performance and\noptimization dynamics. Experimental results show that DGRO achieves\nstate-of-the-art performance on the Logic dataset with an average accuracy of\n96.9\\%, and demonstrates strong generalization across mathematical benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12951v1",
    "published": "2025-05-19T10:44:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12950v1",
    "title": "GuRE:Generative Query REwriter for Legal Passage Retrieval",
    "authors": [
      "Daehee Kim",
      "Deokhyung Kang",
      "Jonghwi Kim",
      "Sangwon Ryu",
      "Gary Geunbae Lee"
    ],
    "abstract": "Legal Passage Retrieval (LPR) systems are crucial as they help practitioners\nsave time when drafting legal arguments. However, it remains an underexplored\navenue. One primary reason is the significant vocabulary mismatch between the\nquery and the target passage. To address this, we propose a simple yet\neffective method, the Generative query REwriter (GuRE). We leverage the\ngenerative capabilities of Large Language Models (LLMs) by training the LLM for\nquery rewriting. \"Rewritten queries\" help retrievers to retrieve target\npassages by mitigating vocabulary mismatch. Experimental results show that GuRE\nsignificantly improves performance in a retriever-agnostic manner,\noutperforming all baseline methods. Further analysis reveals that different\ntraining objectives lead to distinct retrieval behaviors, making GuRE more\nsuitable than direct retriever fine-tuning for real-world applications. Codes\nare avaiable at github.com/daehuikim/GuRE.",
    "pdf_url": "http://arxiv.org/pdf/2505.12950v1",
    "published": "2025-05-19T10:42:36+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12949v1",
    "title": "Neural Morphological Tagging for Nguni Languages",
    "authors": [
      "Cael Marquard",
      "Simbarashe Mawere",
      "Francois Meyer"
    ],
    "abstract": "Morphological parsing is the task of decomposing words into morphemes, the\nsmallest units of meaning in a language, and labelling their grammatical roles.\nIt is a particularly challenging task for agglutinative languages, such as the\nNguni languages of South Africa, which construct words by concatenating\nmultiple morphemes. A morphological parsing system can be framed as a pipeline\nwith two separate components, a segmenter followed by a tagger. This paper\ninvestigates the use of neural methods to build morphological taggers for the\nfour Nguni languages. We compare two classes of approaches: training neural\nsequence labellers (LSTMs and neural CRFs) from scratch and finetuning\npretrained language models. We compare performance across these two categories,\nas well as to a traditional rule-based morphological parser. Neural taggers\ncomfortably outperform the rule-based baseline and models trained from scratch\ntend to outperform pretrained models. We also compare parsing results across\ndifferent upstream segmenters and with varying linguistic input features. Our\nfindings confirm the viability of employing neural taggers based on\npre-existing morphological segmenters for the Nguni languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.12949v1",
    "published": "2025-05-19T10:41:47+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12948v1",
    "title": "On Folding Calabi-Yau Diagrams in M-theory Black Brane Scenarios",
    "authors": [
      "Adil Belhaj",
      "Abderrahim Bouhouch"
    ],
    "abstract": "In this paper, we reconsider the study of five-dimensional supersymmetric\nblack branes in the context of the M-theory compactification on a special\nCalabi-Yau manifold called tetra-quadric, being realized as complete\nintersections of homogenous polynomials in the projective space $\n\\mathbb{CP}^{1}\\times\\mathbb{CP}^{1}\\times\\mathbb{CP}^{1}\\times\\mathbb{CP}^{1}$.\nCombining colored graph theory and outer-automorphism group action techniques,\nwe approach the tetra-quadric Calabi-Yau diagram leading to new features. Using\na procedure referred to as folding, we show that M-theory black branes on the\ntetra-quadric Calabi-Yau manifold can be reduced to known compactifications\nwith lower dimensional K\\\"{a}hler moduli spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.12948v1",
    "published": "2025-05-19T10:41:13+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.13564v1",
    "title": "Online Decision-Focused Learning",
    "authors": [
      "Aymeric Capitaine",
      "Maxime Haddouche",
      "Eric Moulines",
      "Michael I. Jordan",
      "Etienne Boursier",
      "Alain Durmus"
    ],
    "abstract": "Decision-focused learning (DFL) is an increasingly popular paradigm for\ntraining predictive models whose outputs are used in decision-making tasks.\nInstead of merely optimizing for predictive accuracy, DFL trains models to\ndirectly minimize the loss associated with downstream decisions. This\nend-to-end strategy holds promise for tackling complex combinatorial problems;\nhowever, existing studies focus solely on scenarios where a fixed batch of data\nis available and the objective function does not change over time. We instead\ninvestigate DFL in dynamic environments where the objective function and data\ndistribution evolve over time. This setting is challenging because the\nobjective function has zero or undefined gradients -- which prevents the use of\nstandard first-order optimization methods -- and is generally non-convex. To\naddress these difficulties, we (i) regularize the objective to make it\ndifferentiable and (ii) make use of the optimism principle, based on a\nnear-optimal oracle along with an appropriate perturbation. This leads to a\npractical online algorithm for which we establish bounds on the expected\ndynamic regret, both when the decision space is a simplex and when it is a\ngeneral bounded convex polytope. Finally, we demonstrate the effectiveness of\nour algorithm by comparing its performance with a classic prediction-focused\napproach on a simple knapsack experiment.",
    "pdf_url": "http://arxiv.org/pdf/2505.13564v1",
    "published": "2025-05-19T10:40:30+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13563v2",
    "title": "Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression",
    "authors": [
      "Xiaohui Wang",
      "Peng Ye",
      "Chenyu Huang",
      "Shenghe Zheng",
      "Bo Zhang",
      "Lei Bai",
      "Wanli Ouyang",
      "Tao Chen"
    ],
    "abstract": "With the rise of the fine-tuned--pretrained paradigm, storing numerous\nfine-tuned models for multi-tasking creates significant storage overhead. Delta\ncompression alleviates this by storing only the pretrained model and the highly\ncompressed delta weights (the differences between fine-tuned and pretrained\nmodel weights). However, existing methods fail to maintain both high\ncompression and performance, and often rely on data. To address these\nchallenges, we propose UltraDelta, the first data-free delta compression\npipeline that achieves both ultra-high compression and strong performance.\nUltraDelta is designed to minimize redundancy, maximize information, and\nstabilize performance across inter-layer, intra-layer, and global dimensions,\nusing three key components: (1) Variance-Based Mixed Sparsity Allocation\nassigns sparsity based on variance, giving lower sparsity to high-variance\nlayers to preserve inter-layer information. (2) Distribution-Aware Compression\napplies uniform quantization and then groups parameters by value, followed by\ngroup-wise pruning, to better preserve intra-layer distribution. (3)\nTrace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a\nglobal rescaling factor, improving model stability under higher compression.\nExtensive experiments across (a) large language models (fine-tuned on LLaMA-2\n7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base)\nwith up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and\n(d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that\nUltraDelta consistently outperforms existing methods, especially under\nultra-high compression.",
    "pdf_url": "http://arxiv.org/pdf/2505.13563v2",
    "published": "2025-05-19T10:37:22+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12947v1",
    "title": "Modular Chabauty: Effective S-Integral Point Computation On Curves with Elliptic Fibrations",
    "authors": [
      "Sa'ar Zehavi"
    ],
    "abstract": "We present a practical, unconditional algorithm for determining the\n$S$-integral points on any elliptic moduli problem\n$\\mathcal{Y}/\\mathbb{Z}[1/S]$ -- that is, on any geometrically connected curve\ncarrying a non-isotrivial elliptic fibration $\\mathcal{E} \\to \\mathcal{Y}$. The\nassociated map $\\Phi_M\\colon \\mathcal{Y} \\to \\mathcal{M}_{1,1}$ (the modular\nperiod map) plays the role ordinarily filled by a $p$-adic period map in\nChabauty-type methods. Our Modular Chabauty method studies the image and fibres\nof $\\Phi_M$, and proceeds in two steps: an Effective Shafarevich step, in which\nwe combine the modularity theorem with Cremona's enumeration of elliptic curves\nby conductor and list all rational elliptic curves with good reduction outside\n$S$; and a Fibre Computation step, in which we compute the $S$-integral points\nin the corresponding fibre of $\\Phi_M$. A Python/Sage implementation computes\n$\\mathcal{Y}(\\mathbb{Z}[1/S])$ for\n$\\mathcal{Y}=\\mathbb{P}^1\\setminus\\{0,1,\\infty\\}$ and for every modular curve\n$Y_1(N)$ with $4\\le N\\le 10$ or $N=12$, for all sets $S$ with $\\prod_{p\\in S}\np^{2}\\le 5\\cdot 10^{5}$, within $3.5$ seconds on a standard computer.",
    "pdf_url": "http://arxiv.org/pdf/2505.12947v1",
    "published": "2025-05-19T10:35:00+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12946v1",
    "title": "6G-Enabled Smart Railways",
    "authors": [
      "Bo Ai",
      "Yunlong Lu",
      "Yuguang Fang",
      "Dusit Niyato",
      "Ruisi He",
      "Wei Chen",
      "Jiayi Zhang",
      "Guoyu Ma",
      "Yong Niu",
      "Zhangdui Zhong"
    ],
    "abstract": "Smart railways integrate advanced information technologies into railway\noperating systems to improve efficiency and reliability. Although the\ndevelopment of 5G has enhanced railway services, future smart railways require\nultra-high speeds, ultra-low latency, ultra-high security, full coverage, and\nultra-high positioning accuracy, which 5G cannot fully meet. Therefore, 6G is\nenvisioned to provide green and efficient all-day operations, strong\ninformation security, fully automatic driving, and low-cost intelligent\nmaintenance. To achieve these requirements, we propose an integrated network\narchitecture leveraging communications, computing, edge intelligence, and\ncaching in railway systems. We have conducted in-depth investigations on key\nenabling technologies for reliable transmissions and wireless coverage. For\nhigh-speed mobile scenarios, we propose an AI-enabled cross-domain channel\nmodeling and orthogonal time-frequency space-time spread multiple access\nmechanism to alleviate the conflict between limited spectrum availability and\nmassive user access. The roles of blockchain, edge intelligence, and privacy\ntechnologies in endogenously secure rail communications are also evaluated. We\nfurther explore the application of emerging paradigms such as integrated\nsensing and communications, AI-assisted Internet of Things, semantic\ncommunications, and digital twin networks for railway maintenance, monitoring,\nprediction, and accident warning. Finally, possible future research and\ndevelopment directions are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.12946v1",
    "published": "2025-05-19T10:34:54+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.12945v1",
    "title": "gr8stars I: A homogeneous spectroscopic study of bright FGKM dwarfs and a public library of their high-resolution spectra",
    "authors": [
      "Alix Violet Freckelton",
      "Annelies Mortier",
      "Megan Bedell",
      "Sam Morrell",
      "Tim Naylor",
      "Lars A. Buchhave",
      "Guy R. Davies",
      "J. I. Gonz√°lez Hern√°ndez",
      "Baptiste Klein",
      "Ernst J. W. de Mooij",
      "Vera Maria Passegger",
      "Andreas Quirrenbach",
      "Arpita Roy",
      "Nuno C. Santos",
      "S√©rgio G. Sousa",
      "A. Su√°rez Mascare√±o",
      "Maria Tsantaki",
      "Lily L. Zhao"
    ],
    "abstract": "As the fields of stellar and exoplanetary study grow and revolutionary new\ndetection instruments are created, it is imperative that a homogeneous, precise\nsource of stellar parameters is available. This first work of the gr8stars\ncollaboration presents the all-sky magnitude limited sample of 5645 bright FGKM\ndwarfs, along with homogeneously derived spectroscopic parameters of a subset\nof 1716 targets visible from the Northern hemisphere. We have collected\nhigh-resolution archival and new spectra from several instruments.\nSpectrosocpic parameters are determined using the PAWS pipeline, employing both\nthe curve-of-growth equivalent width method, and the spectral synthesis method.\nWe achieve median uncertainties of 106K in stellar effective temperature, 0.08\ndex in surface gravity, and 0.03 dex in metallicity. This paper also presents\nphotometric stellar parameters for these dwarfs, determined using SED fitting.\nThe full gr8stars sample selection, including derived spectroscopic and\nphotometric parameters, is made available through an interactive online\ndatabase. We also perform a kinematic analysis to classify these stars\naccording to their Galactic component.",
    "pdf_url": "http://arxiv.org/pdf/2505.12945v1",
    "published": "2025-05-19T10:33:12+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12944v1",
    "title": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs",
    "authors": [
      "Jan Hagnberger",
      "Daniel Musekamp",
      "Mathias Niepert"
    ],
    "abstract": "Solving time-dependent Partial Differential Equations (PDEs) using a densely\ndiscretized spatial domain is a fundamental problem in various scientific and\nengineering disciplines, including modeling climate phenomena and fluid\ndynamics. However, performing these computations directly in the physical space\noften incurs significant computational costs. To address this issue, several\nneural surrogate models have been developed that operate in a compressed latent\nspace to solve the PDE. While these approaches reduce computational complexity,\nthey often use Transformer-based attention mechanisms to handle irregularly\nsampled domains, resulting in increased memory consumption. In contrast,\nconvolutional neural networks allow memory-efficient encoding and decoding but\nare limited to regular discretizations. Motivated by these considerations, we\npropose CALM-PDE, a model class that efficiently solves arbitrarily discretized\nPDEs in a compressed latent space. We introduce a novel continuous\nconvolution-based encoder-decoder architecture that uses an\nepsilon-neighborhood-constrained kernel and learns to apply the convolution\noperator to adaptive and optimized query points. We demonstrate the\neffectiveness of CALM-PDE on a diverse set of PDEs with both regularly and\nirregularly sampled spatial domains. CALM-PDE is competitive with or\noutperforms existing baseline methods while offering significant improvements\nin memory and inference time efficiency compared to Transformer-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.12944v1",
    "published": "2025-05-19T10:31:30+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12943v1",
    "title": "Improved Approximation Ratio for Strategyproof Facility Location on a Cycle",
    "authors": [
      "Krzysztof Rogowski",
      "Marcin Dziubi≈Ñski"
    ],
    "abstract": "We study the problem of design of strategyproof in expectation (SP)\nmechanisms for facility location on a cycle, with the objective of minimizing\nthe sum of costs of $n$ agents. We show that there exists an SP mechanism that\nattains an approximation ratio of $7/4$ with respect to the sum of costs of the\nagents, thus improving the best known upper bound of $2-2/n$ in the cases of $n\n\\geq 5$. The mechanism obtaining the bound randomizes between two mechanisms\nknown in the literature: the Random Dictator (RD) and the Proportional Circle\nDistance (PCD) mechanism of Meir (arXiv:1902.08070). To prove the result, we\npropose a cycle-cutting technique that allows for estimating the problem on a\ncycle by a problem on a line.",
    "pdf_url": "http://arxiv.org/pdf/2505.12943v1",
    "published": "2025-05-19T10:30:37+00:00",
    "categories": [
      "cs.GT",
      "91B26 (Primary) 68Q25, 91A80 (Secondary)",
      "F.2.2; I.2.11"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12942v3",
    "title": "A3 : an Analytical Low-Rank Approximation Framework for Attention",
    "authors": [
      "Jeffrey T. H. Wong",
      "Cheng Zhang",
      "Xinye Cao",
      "Pedro Gimenes",
      "George A. Constantinides",
      "Wayne Luk",
      "Yiren Zhao"
    ],
    "abstract": "Large language models have demonstrated remarkable performance; however,\ntheir massive parameter counts make deployment highly expensive. Low-rank\napproximation offers a promising compression solution, yet existing approaches\nhave two main limitations: (1) They focus on minimizing the output error of\nindividual linear layers, without considering the architectural characteristics\nof Transformers, and (2) they decompose a large weight matrix into two small\nlow-rank matrices. Consequently, these methods often fall short compared to\nother compression techniques like pruning and quantization, and introduce\nruntime overhead such as the extra GEMM kernel launches for decomposed small\nmatrices. To address these limitations, we propose $\\tt A^\\tt 3$, a\npost-training low-rank approximation framework. $\\tt A^\\tt 3$ splits a\nTransformer layer into three functional components, namely $\\tt QK$, $\\tt OV$,\nand $\\tt MLP$. For each component, $\\tt A^\\tt 3$ provides an analytical\nsolution that reduces the hidden dimension size inside each component while\nminimizing the component's functional loss ($\\it i.e.$, error in attention\nscores, attention outputs, and MLP outputs). This approach directly reduces\nmodel sizes, KV cache sizes, and FLOPs without introducing any runtime\noverheads. In addition, it provides a new narrative in advancing the\noptimization problem from singular linear layer loss optimization toward\nimproved end-to-end performance. Through extensive experiments, we show that\n$\\tt A^\\tt 3$ maintains superior performance compared to SoTAs. For example,\nunder the same reduction budget in computation and memory, our low-rank\napproximated LLaMA 3.1-70B achieves a perplexity of 4.69 on WikiText-2,\noutperforming the previous SoTA's 7.87 by 3.18. We also demonstrate the\nversatility of $\\tt A^\\tt 3$, including KV cache compression, quantization, and\nmixed-rank assignments for enhanced performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.12942v3",
    "published": "2025-05-19T10:29:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12941v3",
    "title": "A Unified Closed-Form Formula for the Multi-Peg Tower of Hanoi via Simplex Number Theory",
    "authors": [
      "Abhiram Menon"
    ],
    "abstract": "The classical three-peg Tower of Hanoi puzzle admits the well-known\nclosed-form solution \\(M(3,n)=2^n-1\\), but the general case with \\(p \\geq 4\\)\npegs has remained an open problem for over a century. In this paper, we present\na complete unified closed-form formula for the minimum number of moves\n\\(M(p,n)\\) required to solve the Tower of Hanoi problem for any number of pegs\n\\(p\\) and disks \\(n\\).\n  Building upon our previous work, which introduced Menon's Conjecture\n\\(M(p,n)=4n-2p+1\\) for the restricted domain \\(p-1 \\leq n \\leq\n\\frac{p(p-1)}{2}\\), we now extend this result to all values of \\(n\\). Our key\ninsight is that the solution naturally partitions into regimes governed by\nsimplex number boundaries, with each regime exhibiting linear growth with\nslopes that are successive powers of two. This leads to the unified expression:\n\\[ M(p,n) = 2^{i+1}n - \\sum_{k=0}^{i} 2^k \\binom{p+k-2}{k}, \\quad i = \\min\n\\left\\{ j \\geq 0 : n \\leq \\binom{p-1+j}{j+1} \\right\\}. \\]\n  We show how this formula recovers classical results, including\n\\(M(3,n)=2^n-1\\) and the four-peg Reve's Puzzle solution, as special cases.\nComputational verification across more than 1,750 test instances confirms\nperfect agreement with Frame-Stewart values. Furthermore, this closed-form\nreduces the complexity of determining \\(M(p,n)\\) from \\(O(pn^2)\\) to \\(O(p\\log\nn)\\), providing both theoretical unification and practical computational\nimprovements.",
    "pdf_url": "http://arxiv.org/pdf/2505.12941v3",
    "published": "2025-05-19T10:27:38+00:00",
    "categories": [
      "math.CO",
      "05A20 (Primary) 68Q25, 68R05 (Secondary)",
      "G.2; I.5"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12940v1",
    "title": "Multi-Level Monte Carlo Training of Neural Operators",
    "authors": [
      "James Rowbottom",
      "Stefania Fresca",
      "Pietro Lio",
      "Carola-Bibiane Sch√∂nlieb",
      "Nicolas Boull√©"
    ],
    "abstract": "Operator learning is a rapidly growing field that aims to approximate\nnonlinear operators related to partial differential equations (PDEs) using\nneural operators. These rely on discretization of input and output functions\nand are, usually, expensive to train for large-scale problems at\nhigh-resolution. Motivated by this, we present a Multi-Level Monte Carlo (MLMC)\napproach to train neural operators by leveraging a hierarchy of resolutions of\nfunction dicretization. Our framework relies on using gradient corrections from\nfewer samples of fine-resolution data to decrease the computational cost of\ntraining while maintaining a high level accuracy. The proposed MLMC training\nprocedure can be applied to any architecture accepting multi-resolution data.\nOur numerical experiments on a range of state-of-the-art models and test-cases\ndemonstrate improved computational efficiency compared to traditional\nsingle-resolution training approaches, and highlight the existence of a Pareto\ncurve between accuracy and computational time, related to the number of samples\nper resolution.",
    "pdf_url": "http://arxiv.org/pdf/2505.12940v1",
    "published": "2025-05-19T10:26:28+00:00",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12939v1",
    "title": "Anomalous persistent current in a 1D dimerized ring with aperiodic site potential: Non-interacting and interacting cases",
    "authors": [
      "Souvik Roy",
      "Santanu K. Maiti",
      "David Laroze"
    ],
    "abstract": "In this work, we investigate the magnetic response by examining flux-driven\ncircular currents in a Su-Schrieffer-Heeger (SSH) tight-binding (TB) ring\nthreaded by an Aharonov-Bohm (AB) flux, $\\phi$. We consider both\nnon-interacting and interacting electrons, where site energies are modulated by\na slowly varying cosine form. Repulsive electron-electron interaction is\nincorporated through an on-site Hubbard term, and we analyze the system using\nthe Hartree-Fock (HF) mean-field (MF) approximation. We discuss the\ncharacteristics of flux-driven circular currents to aperiodic potentials,\ndimerized hopping integrals, and Hubbard interactions. For the chosen aperiodic\npotential, both the strength and configuration play a crucial role, and we\nexplore these aspects in depth. Interestingly, we observe a counterintuitive\ndelocalizing effect as the aperiodic potential increases, unlike in\nconventional disordered rings. The effects of system size, filling factor, the\npresence of circular spin current, and the accuracy of MF results are also\ndiscussed. Finally, we provide a brief description of possible experimental\nrealizations of our chosen quantum system. This investigation can be extended\nto explore additional properties in various loop substructures, promising\nfurther insights.",
    "pdf_url": "http://arxiv.org/pdf/2505.12939v1",
    "published": "2025-05-19T10:22:22+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.dis-nn",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.12938v2",
    "title": "Leveraging LLM Inconsistency to Boost Pass@k Performance",
    "authors": [
      "Uri Dalal",
      "Meirav Segal",
      "Zvika Ben-Haim",
      "Dan Lahav",
      "Omer Nevo"
    ],
    "abstract": "Large language models (LLMs) achieve impressive abilities in numerous\ndomains, but exhibit inconsistent performance in response to minor input\nchanges. Rather than view this as a drawback, in this paper we introduce a\nnovel method for leveraging models' inconsistency to boost Pass@k performance.\nSpecifically, we present a \"Variator\" agent that generates k variants of a\ngiven task and submits one candidate solution for each one. Our variant\ngeneration approach is applicable to a wide range of domains as it is task\nagnostic and compatible with free-form inputs. We demonstrate the efficacy of\nour agent theoretically using a probabilistic model of the inconsistency\neffect, and show empirically that it outperforms the baseline on the APPS\ndataset. Furthermore, we establish that inconsistency persists even in frontier\nreasoning models across coding and cybersecurity domains, suggesting our method\nis likely to remain relevant for future model generations.",
    "pdf_url": "http://arxiv.org/pdf/2505.12938v2",
    "published": "2025-05-19T10:22:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12937v1",
    "title": "Doubling Qubits in a Trapped-Ion System via Vibrational Dual-Rail Encoding",
    "authors": [
      "Minhyeok Kang",
      "Wentao Chen",
      "Hyukjoon Kwon",
      "Kihwan Kim",
      "Joonsuk Huh"
    ],
    "abstract": "Vibrational modes of trapped ions have traditionally served as quantum buses\nto mediate internal qubits. However, with recent advances in quantum control,\nit has become possible to use these vibrational modes directly as quantum\ncomputational resources, such as bosonic qubits. Here, we propose a dual-rail\nencoding scheme in which a dual-rail qubit is encoded by two vibrational modes\nthat share a single phonon. We present the preparation, measurement, and\nimplementation of single- and two-qubit gates, enabling universal quantum\ncomputation. The dual-rail qubit system offers scalability and all-to-all\nconnectivity. Moreover, we extend the dual-rail qubit system to a logical\ninternal qubit--dual-rail qubit hybrid system by incorporating internal qubits\ninto the dual-rail qubit system as another type of logical qubit. The hybrid\nsystem nearly doubles the number of available logical qubits compared to\nconventional trapped-ion quantum computers while maintaining all-to-all\nconnectivity. Additionally, we propose a method for implementing multi-qubit\ncontrolled gates and discuss potential applications that can leverage the\nadvantages of the hybrid system. Our scheme provides a practical framework for\nan internal qubit-boson qubit hybrid system.",
    "pdf_url": "http://arxiv.org/pdf/2505.12937v1",
    "published": "2025-05-19T10:18:34+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12936v1",
    "title": "Elliptic Problems Involving Mixed Local-Nonlocal Operator in the Hyperbolic Space",
    "authors": [
      "Diksha Gupta",
      "Konijeti Sreenadh"
    ],
    "abstract": "This paper explores the existence of solutions to a class of nonlinear\nelliptic equations involving a mixed local-nonlocal operator of the form\n$-\\Delta_{\\mathbb{B}^N} + (-\\Delta_{\\mathbb{B}^N})^s$, with $0 < s < 1$, set in\nthe hyperbolic space $\\mathbb{B}^N$. By employing variational methods, we\naddress both subcritical and critical nonlinearities, establishing the\nexistence of weak solutions under appropriate conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.12936v1",
    "published": "2025-05-19T10:17:22+00:00",
    "categories": [
      "math.AP",
      "35B09, 35B38, 35J20, 35J61, 35R01"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12935v1",
    "title": "LatentINDIGO: An INN-Guided Latent Diffusion Algorithm for Image Restoration",
    "authors": [
      "Di You",
      "Daniel Siromani",
      "Pier Luigi Dragotti"
    ],
    "abstract": "There is a growing interest in the use of latent diffusion models (LDMs) for\nimage restoration (IR) tasks due to their ability to model effectively the\ndistribution of natural images. While significant progress has been made, there\nare still key challenges that need to be addressed. First, many approaches\ndepend on a predefined degradation operator, making them ill-suited for complex\nor unknown degradations that deviate from standard analytical models. Second,\nmany methods struggle to provide a stable guidance in the latent space and\nfinally most methods convert latent representations back to the pixel domain\nfor guidance at every sampling iteration, which significantly increases\ncomputational and memory overhead. To overcome these limitations, we introduce\na wavelet-inspired invertible neural network (INN) that simulates degradations\nthrough a forward transform and reconstructs lost details via the inverse\ntransform. We further integrate this design into a latent diffusion pipeline\nthrough two proposed approaches: LatentINDIGO-PixelINN, which operates in the\npixel domain, and LatentINDIGO-LatentINN, which stays fully in the latent space\nto reduce complexity. Both approaches alternate between updating intermediate\nlatent variables under the guidance of our INN and refining the INN forward\nmodel to handle unknown degradations. In addition, a regularization step\npreserves the proximity of latent variables to the natural image manifold.\nExperiments demonstrate that our algorithm achieves state-of-the-art\nperformance on synthetic and real-world low-quality images, and can be readily\nadapted to arbitrary output sizes.",
    "pdf_url": "http://arxiv.org/pdf/2505.12935v1",
    "published": "2025-05-19T10:17:16+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12934v1",
    "title": "Granular Loco-Manipulation: Repositioning Rocks Through Strategic Sand Avalanche",
    "authors": [
      "Haodi Hu",
      "Yue Wu",
      "Feifei Qian",
      "Daniel Seita"
    ],
    "abstract": "Legged robots have the potential to leverage obstacles to climb steep sand\nslopes. However, efficiently repositioning these obstacles to desired locations\nis challenging. Here we present DiffusiveGRAIN, a learning-based method that\nenables a multi-legged robot to strategically induce localized sand avalanches\nduring locomotion and indirectly manipulate obstacles. We conducted 375 trials,\nsystematically varying obstacle spacing, robot orientation, and leg actions in\n75 of them. Results show that the movement of closely-spaced obstacles exhibits\nsignificant interference, requiring joint modeling. In addition, different\nmulti-leg excavation actions could cause distinct robot state changes,\nnecessitating integrated planning of manipulation and locomotion. To address\nthese challenges, DiffusiveGRAIN includes a diffusion-based environment\npredictor to capture multi-obstacle movements under granular flow interferences\nand a robot state predictor to estimate changes in robot state from multi-leg\naction patterns. Deployment experiments (90 trials) demonstrate that by\nintegrating the environment and robot state predictors, the robot can\nautonomously plan its movements based on loco-manipulation goals, successfully\nshifting closely located rocks to desired locations in over 65% of trials. Our\nstudy showcases the potential for a locomoting robot to strategically\nmanipulate obstacles to achieve improved mobility on challenging terrains.",
    "pdf_url": "http://arxiv.org/pdf/2505.12934v1",
    "published": "2025-05-19T10:17:03+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12933v1",
    "title": "Formalising the Bruhat-Tits Tree",
    "authors": [
      "Judith Ludwig",
      "Christian Merten"
    ],
    "abstract": "In this article we describe the formalisation of the Bruhat-Tits tree - an\nimportant tool in modern number theory - in the Lean Theorem Prover. Motivated\nby the goal of connecting to ongoing research, we apply our formalisation to\nverify a result about harmonic cochains on the tree.",
    "pdf_url": "http://arxiv.org/pdf/2505.12933v1",
    "published": "2025-05-19T10:15:55+00:00",
    "categories": [
      "math.NT",
      "cs.LO"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12932v1",
    "title": "Source location and evolution of a multi-lane type II radio burst",
    "authors": [
      "P. Zucca",
      "P. Zhang",
      "K. Kozarev",
      "M. Nedal",
      "M. Mancini",
      "A. Kumari",
      "D. E. Morosan",
      "B. Dabrowski",
      "P. T. Gallagher",
      "A. Krankowski",
      "C. Vocks"
    ],
    "abstract": "Shocks in the solar corona can accelerate electrons that in turn generate\nradio emission known as type II radio bursts. The characteristics and\nmorphology of these radio bursts in the dynamic spectrum reflect the evolution\nof the shock itself, together with the properties of the local corona where it\npropagates. In this work, we study the evolution of a complex type II radio\nburst showing a multi-lane structure, to find the locations where the radio\nemission is produced and relate them to the properties of the local\nenvironment. Using radio imaging, we track separately each lane composing the\ntype II burst and relate the position of the emission to the properties of the\nambient medium such as density, Alfven speed, and magnetic field. We show that\nthe radio burst morphology in the dynamic spectrum changes with time and it is\nrelated to the complexity of the local environment. The initial stage of the\nradio emission show a single lane in the spectrum, while the latter stages of\nthe radio signature evolve in a multi-lane scenario. The radio imaging reveals\nhow the initial stage of the radio emission separates with time into different\nlocations along the shock front as the density and orientation of the magnetic\nfield change along the shock propagation. At the time where the spectrum shows\na multi-lane shape, we found a clear separation of the imaged radio sources. By\ncombining radio imaging with the properties of the local corona, we described\nthe evolution of a type II radio burst and, for the first time, identified\nthree distinct radio emission regions above the CME front. Two regions were\nlocated at the flanks, producing earlier radio emission than the central\nposition, in accordance with the complexity of density and Alfven speed values\nin the regions where radio emission is generated. This unprecedented\nobservation provides new insights into the nature of multi-lane type II bursts.",
    "pdf_url": "http://arxiv.org/pdf/2505.12932v1",
    "published": "2025-05-19T10:15:46+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12931v1",
    "title": "Classification of ill-posedness for bounded linear operators in Banach spaces",
    "authors": [
      "Bernd Hofmann",
      "Stefan Kindermann"
    ],
    "abstract": "In this article, concepts of well- and ill-posedness for linear operators in\nHilbert and Banach spaces are discussed. While these concepts are well\nunderstood in Hilbert spaces, this is not the case in Banach spaces, as there\nare several competing definitions, related to the occurrence of uncomplemented\nsubspaces. We provide an overview of the various definitions and, based on\nthis, discuss the classification of type I and type II ill-posedness in Banach\nspaces. Furthermore, a discussion of borderline (hybrid) cases in this\nclassification is given together with several example instances of operators.",
    "pdf_url": "http://arxiv.org/pdf/2505.12931v1",
    "published": "2025-05-19T10:15:33+00:00",
    "categories": [
      "math.FA",
      "47A52, 47B01, 47B02, 65J20"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12930v1",
    "title": "A Necessary Condition for Connectedness of Solutions to Integer Linear Systems",
    "authors": [
      "Takasugu Shigenobu",
      "Naoyuki Kamiyama"
    ],
    "abstract": "An integer linear system is a set of inequalities with integer constraints.\nThe solution graph of an integer linear system is an undirected graph defined\non the set of feasible solutions to the integer linear system. In this graph, a\npair of feasible solutions is connected by an edge if the Hamming distance\nbetween them is one. In this paper, we consider a condition under which the\nsolution graph is connected for any right-hand side vector. First, we prove\nthat if the solution graph is connected for any right-hand side vector, then\nthe coefficient matrix of the system does not contain some forbidden pattern as\na submatrix. Next, we prove that if at least one of (i) the number of rows is\nat most 3, (ii) the number of columns is at most 2, (iii) the number of rows is\n4 and the number of columns is 3 holds, then the condition that the coefficient\nmatrix of the system does not contain the forbidden pattern is a sufficient\ncondition under which the solution graph is connected for any right-hand side\nvector. This result is stronger than a known necessary and sufficient condition\nsince the set of coefficient matrix dimensions is strictly larger.",
    "pdf_url": "http://arxiv.org/pdf/2505.12930v1",
    "published": "2025-05-19T10:14:20+00:00",
    "categories": [
      "cs.DM",
      "math.CO"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2505.12929v1",
    "title": "Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs",
    "authors": [
      "Zhihe Yang",
      "Xufang Luo",
      "Zilong Wang",
      "Dongqi Han",
      "Zhiyuan He",
      "Dongsheng Li",
      "Yunjian Xu"
    ],
    "abstract": "Reinforcement learning (RL) has become a cornerstone for enhancing the\nreasoning capabilities of large language models (LLMs), with recent innovations\nsuch as Group Relative Policy Optimization (GRPO) demonstrating exceptional\neffectiveness. In this study, we identify a critical yet underexplored issue in\nRL training: low-probability tokens disproportionately influence model updates\ndue to their large gradient magnitudes. This dominance hinders the effective\nlearning of high-probability tokens, whose gradients are essential for LLMs'\nperformance but are substantially suppressed. To mitigate this interference, we\npropose two novel methods: Advantage Reweighting and Low-Probability Token\nIsolation (Lopti), both of which effectively attenuate gradients from\nlow-probability tokens while emphasizing parameter updates driven by\nhigh-probability tokens. Our approaches promote balanced updates across tokens\nwith varying probabilities, thereby enhancing the efficiency of RL training.\nExperimental results demonstrate that they substantially improve the\nperformance of GRPO-trained LLMs, achieving up to a 46.2% improvement in K&K\nLogic Puzzle reasoning tasks. Our implementation is available at\nhttps://github.com/zhyang2226/AR-Lopti.",
    "pdf_url": "http://arxiv.org/pdf/2505.12929v1",
    "published": "2025-05-19T10:14:08+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12927v1",
    "title": "On the superintegrability of the Gaussian $Œ≤$ ensemble and its $(q,t)$ generalisation",
    "authors": [
      "Sung-Soo Byun",
      "Peter J. Forrester"
    ],
    "abstract": "In the present context, superintegrability is a property of certain\nprobability density functions coming from matrix models, which relates to the\naverage over a distinguished basis of symmetric functions, typically the Jack\nor Macdonald polynomials. It states that the average can be computed according\na certain combination of those same polynomials, now specialised by specific\nsubstitutions when expressed in terms of the power sum basis. For a particular\n$(q,t)$ generalisation of the Gaussian $\\beta$ ensemble from random matrix\ntheory, known independently from the consideration of certain integrable gauge\ntheories, we use results developed in a theory of multivariable Al-Salam and\nCarlitz polynomials based on Macdonald polynomials to prove the\nsuperintegrability identity. This then is used to deduce a duality formula for\nthese same averages, which in turn allows for a derivation of a functional\nequation for the spectral moments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12927v1",
    "published": "2025-05-19T10:11:07+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12928v2",
    "title": "Minos: Exploiting Cloud Performance Variation with Function-as-a-Service Instance Selection",
    "authors": [
      "Trever Schirmer",
      "Valentin Carl",
      "Nils H√∂ller",
      "Tobias Pfandzelter",
      "David Bermbach"
    ],
    "abstract": "Serverless Function-as-a-Service (FaaS) is a popular cloud paradigm to\nquickly and cheaply implement complex applications. Because the function\ninstances cloud providers start to execute user code run on shared\ninfrastructure, their performance can vary. From a user perspective, slower\ninstances not only take longer to complete, but also increase cost due to the\npay-per-use model of FaaS services where execution duration is billed with\nmicrosecond accuracy. In this paper, we present Minos, a system to take\nadvantage of this performance variation by intentionally terminating instances\nthat are slow. Fast instances are not terminated, so that they can be re-used\nfor subsequent invocations. One use case for this are data processing and\nmachine learning workflows, which often download files as a first step, during\nwhich Minos can run a short benchmark. Only if the benchmark passes, the main\npart of the function is actually executed. Otherwise, the request is re-queued\nand the instance crashes itself, so that the platform has to assign the request\nto another (potentially faster) instance. In our experiments, this leads to a\nspeedup of up to 13% in the resource intensive part of a data processing\nworkflow, resulting in up to 4% faster overall performance (and consequently 4%\ncheaper prices). Longer and complex workflows lead to increased savings, as the\npool of fast instances is re-used more often. For platforms exhibiting this\nbehavior, users get better performance and save money by wasting more of the\nplatforms resources.",
    "pdf_url": "http://arxiv.org/pdf/2505.12928v2",
    "published": "2025-05-19T10:11:07+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12926v3",
    "title": "Convergence to equilibrium for density dependent Markov jump processes",
    "authors": [
      "Andrew Barbour",
      "Graham Brightwell",
      "Malwina Luczak"
    ],
    "abstract": "We investigate the convergence to (quasi--)equilibrium of a density dependent\nMarkov chain in~${\\mathbb Z}^d$, whose drift satisfies a system of ordinary\ndifferential equations having an attractive fixed point. For a sequence of such\nprocesses~${\\mathbb X}^N$, indexed by a size parameter~$N$, the time taken\nuntil the distribution of~${\\mathbb X}^N$, started in some given state,\napproaches its equilibrium distribution~$\\pi^N$ typically increases with~$N$.\nTo first order, it corresponds to the time~$t_N$ at which the solution to the\ndrift equations reaches a distance of~$\\sqrt N$ from their fixed point.\nHowever, the length of the time interval over which the total variation\ndistance between ${\\mathcal L} ({\\mathbb X}^N(t))$ and its equilibrium\ndistribution~$\\pi^N$ changes from being close to~$1$ to being close to zero is\nasymptotically of smaller order than~$t_N$. In this sense, the chains exhibit\n`cut--off', and we are able to prove that the cut-off window is of (optimal)\nconstant size.",
    "pdf_url": "http://arxiv.org/pdf/2505.12926v3",
    "published": "2025-05-19T10:09:22+00:00",
    "categories": [
      "math.PR",
      "60J75, 60C05, 60F15"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12925v1",
    "title": "CPRet: A Dataset, Benchmark, and Model for Retrieval in Competitive Programming",
    "authors": [
      "Han Deng",
      "Yuan Meng",
      "Shixiang Tang",
      "Wanli Ouyang",
      "Xinzhu Ma"
    ],
    "abstract": "Competitive programming benchmarks are widely used in scenarios such as\nprogramming contests and large language model assessments. However, the growing\npresence of duplicate or highly similar problems raises concerns not only about\ncompetition fairness, but also about the validity of competitive programming as\na benchmark for model evaluation. In this paper, we propose a new problem --\nsimilar question retrieval -- to address this issue. Due to the lack of both\ndata and models, solving this problem is challenging. To this end, we introduce\nCPRet, a retrieval-oriented benchmark suite for competitive programming,\ncovering four retrieval tasks: two code-centric (i.e., Text-to-Code and\nCode-to-Code) and two newly proposed problem-centric tasks (i.e.,\nProblem-to-Duplicate and Simplified-to-Full), built from a combination of\nautomatically crawled problem-solution data and manually curated annotations.\nOur contribution includes both high-quality training data and temporally\nseparated test sets for reliable evaluation. In addition, we develop two\ntask-specialized retrievers based on this dataset: CPRetriever-Code, trained\nwith a novel Group-InfoNCE loss for problem-code alignment, and\nCPRetriever-Prob, fine-tuned for identifying problem-level similarity. Both\nmodels achieve strong results and are open-sourced for local use. Finally, we\nanalyze LiveCodeBench and find that high-similarity problems inflate model pass\nrates and reduce differentiation, underscoring the need for similarity-aware\nevaluation in future benchmarks.\n  Code and data are available at: https://github.com/coldchair/CPRet",
    "pdf_url": "http://arxiv.org/pdf/2505.12925v1",
    "published": "2025-05-19T10:07:51+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.IR",
      "H.3.3"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.13562v1",
    "title": "Randomised Optimism via Competitive Co-Evolution for Matrix Games with Bandit Feedback",
    "authors": [
      "Shishen Lin"
    ],
    "abstract": "Learning in games is a fundamental problem in machine learning and artificial\nintelligence, with numerous\napplications~\\citep{silver2016mastering,schrittwieser2020mastering}. This work\ninvestigates two-player zero-sum matrix games with an unknown payoff matrix and\nbandit feedback, where each player observes their actions and the corresponding\nnoisy payoff. Prior studies have proposed algorithms for this\nsetting~\\citep{o2021matrix,maiti2023query,cai2024uncoupled}, with\n\\citet{o2021matrix} demonstrating the effectiveness of deterministic optimism\n(e.g., \\ucb) in achieving sublinear regret. However, the potential of\nrandomised optimism in matrix games remains theoretically unexplored.\n  We propose Competitive Co-evolutionary Bandit Learning (\\coebl), a novel\nalgorithm that integrates evolutionary algorithms (EAs) into the bandit\nframework to implement randomised optimism through EA variation operators. We\nprove that \\coebl achieves sublinear regret, matching the performance of\ndeterministic optimism-based methods. To the best of our knowledge, this is the\nfirst theoretical regret analysis of an evolutionary bandit learning algorithm\nin matrix games.\n  Empirical evaluations on diverse matrix game benchmarks demonstrate that\n\\coebl not only achieves sublinear regret but also consistently outperforms\nclassical bandit algorithms, including \\exptr~\\citep{auer2002nonstochastic},\nthe variant \\exptrni~\\citep{cai2024uncoupled}, and \\ucb~\\citep{o2021matrix}.\nThese results highlight the potential of evolutionary bandit learning,\nparticularly the efficacy of randomised optimism via evolutionary algorithms in\ngame-theoretic settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.13562v1",
    "published": "2025-05-19T10:05:55+00:00",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.12924v1",
    "title": "Principal congruence subgroups in the infinite rank case",
    "authors": [
      "Vladimir A. Tolstykh"
    ],
    "abstract": "We obtain a number of analogues of the classical results of the 1960s on the\ngeneral linear groups $\\mathrm{GL}_n(\\mathbf Z)$ and special linear groups\n$\\mathrm{SL}_n(\\mathbf Z)$ for the automorphism group\n$\\Gamma_A=\\mathrm{Aut}(A)$ of an infinitely generated free abelian group $A.$\nIn particular, we obtain a description of normal generators of the group\n$\\mathrm{Aut}(A),$ classify the maximal normal subgroups of the group\n$\\mathrm{Aut}(A),$ describe normal generators of the principal congruence\nsubgroups $\\Gamma_{\\!A}(m)$ of the group $\\mathrm{Aut}(A),$ and obtain an\nanalogue of Brenner's ladder relation for the group $\\mathrm{Aut}(A).$",
    "pdf_url": "http://arxiv.org/pdf/2505.12924v1",
    "published": "2025-05-19T10:02:06+00:00",
    "categories": [
      "math.GR",
      "20K30 (primary), 20H05, 20F28 (secondary)"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12923v1",
    "title": "The Traitors: Deception and Trust in Multi-Agent Language Model Simulations",
    "authors": [
      "Pedro M. P. Curvo"
    ],
    "abstract": "As AI systems increasingly assume roles where trust and alignment with human\nvalues are essential, understanding when and why they engage in deception has\nbecome a critical research priority. We introduce The Traitors, a multi-agent\nsimulation framework inspired by social deduction games, designed to probe\ndeception, trust formation, and strategic communication among large language\nmodel (LLM) agents under asymmetric information. A minority of agents the\ntraitors seek to mislead the majority, while the faithful must infer hidden\nidentities through dialogue and reasoning. Our contributions are: (1) we ground\nthe environment in formal frameworks from game theory, behavioral economics,\nand social cognition; (2) we develop a suite of evaluation metrics capturing\ndeception success, trust dynamics, and collective inference quality; (3) we\nimplement a fully autonomous simulation platform where LLMs reason over\npersistent memory and evolving social dynamics, with support for heterogeneous\nagent populations, specialized traits, and adaptive behaviors. Our initial\nexperiments across DeepSeek-V3, GPT-4o-mini, and GPT-4o (10 runs per model)\nreveal a notable asymmetry: advanced models like GPT-4o demonstrate superior\ndeceptive capabilities yet exhibit disproportionate vulnerability to others'\nfalsehoods. This suggests deception skills may scale faster than detection\nabilities. Overall, The Traitors provides a focused, configurable testbed for\ninvestigating LLM behavior in socially nuanced interactions. We position this\nwork as a contribution toward more rigorous research on deception mechanisms,\nalignment challenges, and the broader social reliability of AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12923v1",
    "published": "2025-05-19T10:01:35+00:00",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12922v1",
    "title": "On the outer automorphism groups of free groups",
    "authors": [
      "Vladimir A. Tolstykh"
    ],
    "abstract": "We prove that the outer automorphism group of a free group of countably\ninfinite rank is complete.",
    "pdf_url": "http://arxiv.org/pdf/2505.12922v1",
    "published": "2025-05-19T10:00:28+00:00",
    "categories": [
      "math.GR",
      "20F28 (20E05)"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12921v1",
    "title": "Capillary curvature images",
    "authors": [
      "Yingxiang Hu",
      "Mohammad N. Ivaki"
    ],
    "abstract": "In this paper, we solve the even capillary $L_p$-Minkowski problem for the\nrange $-n < p < 1$ and $\\theta \\in (0,\\frac{\\pi}{2})$. Our approach is based on\nan iterative scheme that builds on the solution to the capillary Minkowski\nproblem (i.e., the case $p = 1$) and leverages the monotonicity of a class of\nfunctionals under a family of capillary curvature image operators. These\noperators are constructed so that their fixed points, whenever they exist,\ncorrespond precisely to solutions of the capillary $L_p$-Minkowski problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.12921v1",
    "published": "2025-05-19T10:00:06+00:00",
    "categories": [
      "math.DG",
      "math.AP",
      "math.MG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12920v1",
    "title": "PyFCG: Fluid Construction Grammar in Python",
    "authors": [
      "Paul Van Eecke",
      "Katrien Beuls"
    ],
    "abstract": "We present PyFCG, an open source software library that ports Fluid\nConstruction Grammar (FCG) to the Python programming language. PyFCG enables\nits users to seamlessly integrate FCG functionality into Python programs, and\nto use FCG in combination with other libraries within Python's rich ecosystem.\nApart from a general description of the library, this paper provides three\nwalkthrough tutorials that demonstrate example usage of PyFCG in typical use\ncases of FCG: (i) formalising and testing construction grammar analyses, (ii)\nlearning usage-based construction grammars from corpora, and (iii) implementing\nagent-based experiments on emergent communication.",
    "pdf_url": "http://arxiv.org/pdf/2505.12920v1",
    "published": "2025-05-19T10:00:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12919v1",
    "title": "RGNMR: A Gauss-Newton method for robust matrix completion with theoretical guarantees",
    "authors": [
      "Eilon Vaknin Laufer",
      "Boaz Nadler"
    ],
    "abstract": "Recovering a low rank matrix from a subset of its entries, some of which may\nbe corrupted, is known as the robust matrix completion (RMC) problem. Existing\nRMC methods have several limitations: they require a relatively large number of\nobserved entries; they may fail under overparametrization, when their assumed\nrank is higher than the correct one; and many of them fail to recover even\nmildly ill-conditioned matrices. In this paper we propose a novel RMC method,\ndenoted $\\texttt{RGNMR}$, which overcomes these limitations. $\\texttt{RGNMR}$\nis a simple factorization-based iterative algorithm, which combines a\nGauss-Newton linearization with removal of entries suspected to be outliers. On\nthe theoretical front, we prove that under suitable assumptions,\n$\\texttt{RGNMR}$ is guaranteed exact recovery of the underlying low rank\nmatrix. Our theoretical results improve upon the best currently known for\nfactorization-based methods. On the empirical front, we show via several\nsimulations the advantages of $\\texttt{RGNMR}$ over existing RMC methods, and\nin particular its ability to handle a small number of observed entries,\noverparameterization of the rank and ill-conditioned matrices.",
    "pdf_url": "http://arxiv.org/pdf/2505.12919v1",
    "published": "2025-05-19T09:58:33+00:00",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12918v1",
    "title": "Complete outer automorphism groups of free nilpotent groups",
    "authors": [
      "Vladimir A. Tolstykh"
    ],
    "abstract": "We prove that the outer automorphism group $\\mathrm{Out}(N)$ of an infinitely\ngenerated free nilpotent group $N$ of class two is complete.",
    "pdf_url": "http://arxiv.org/pdf/2505.12918v1",
    "published": "2025-05-19T09:58:03+00:00",
    "categories": [
      "math.GR",
      "20F28, 20F18"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.14718v1",
    "title": "Enhancing Shape Perception and Segmentation Consistency for Industrial Image Inspection",
    "authors": [
      "Guoxuan Mao",
      "Ting Cao",
      "Ziyang Li",
      "Yuan Dong"
    ],
    "abstract": "Semantic segmentation stands as a pivotal research focus in computer vision.\nIn the context of industrial image inspection, conventional semantic\nsegmentation models fail to maintain the segmentation consistency of fixed\ncomponents across varying contextual environments due to a lack of perception\nof object contours. Given the real-time constraints and limited computing\ncapability of industrial image detection machines, it is also necessary to\ncreate efficient models to reduce computational complexity. In this work, a\nShape-Aware Efficient Network (SPENet) is proposed, which focuses on the shapes\nof objects to achieve excellent segmentation consistency by separately\nsupervising the extraction of boundary and body information from images. In\nSPENet, a novel method is introduced for describing fuzzy boundaries to better\nadapt to real-world scenarios named Variable Boundary Domain (VBD).\nAdditionally, a new metric, Consistency Mean Square Error(CMSE), is proposed to\nmeasure segmentation consistency for fixed components. Our approach attains the\nbest segmentation accuracy and competitive speed on our dataset, showcasing\nsignificant advantages in CMSE among numerous state-of-the-art real-time\nsegmentation networks, achieving a reduction of over 50% compared to the\npreviously top-performing models.",
    "pdf_url": "http://arxiv.org/pdf/2505.14718v1",
    "published": "2025-05-19T09:57:00+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12917v2",
    "title": "Temporal Query Network for Efficient Multivariate Time Series Forecasting",
    "authors": [
      "Shengsheng Lin",
      "Haojun Chen",
      "Haijie Wu",
      "Chunyun Qiu",
      "Weiwei Lin"
    ],
    "abstract": "Sufficiently modeling the correlations among variables (aka channels) is\ncrucial for achieving accurate multivariate time series forecasting (MTSF). In\nthis paper, we propose a novel technique called Temporal Query (TQ) to more\neffectively capture multivariate correlations, thereby improving model\nperformance in MTSF tasks. Technically, the TQ technique employs periodically\nshifted learnable vectors as queries in the attention mechanism to capture\nglobal inter-variable patterns, while the keys and values are derived from the\nraw input data to encode local, sample-level correlations. Building upon the TQ\ntechnique, we develop a simple yet efficient model named Temporal Query Network\n(TQNet), which employs only a single-layer attention mechanism and a\nlightweight multi-layer perceptron (MLP). Extensive experiments demonstrate\nthat TQNet learns more robust multivariate correlations, achieving\nstate-of-the-art forecasting accuracy across 12 challenging real-world\ndatasets. Furthermore, TQNet achieves high efficiency comparable to\nlinear-based methods even on high-dimensional datasets, balancing performance\nand computational cost. The code is available at:\nhttps://github.com/ACAT-SCUT/TQNet.",
    "pdf_url": "http://arxiv.org/pdf/2505.12917v2",
    "published": "2025-05-19T09:55:10+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12916v1",
    "title": "Modular Symmetry with Weighton",
    "authors": [
      "Gui-Jun Ding",
      "Stephen F. King",
      "Jun-Nan Lu",
      "Ming-Hua Weng"
    ],
    "abstract": "We systematically develop the weighton mechanism for natural quark and\ncharged lepton mass hierarchies in the framework of modular symmetry with a\nsingle modulus field $\\tau$. The weighton $\\phi$ is defined as a complete\nsinglet with unit modular weight, leading to fermion mass suppression by powers\nof $\\tilde{\\phi}$, which is the vacuum expectation value of the field scaled by\na flavour cut-off. Further mass and mixing angle suppression comes from powers\nof the small parameter, $q\\equiv e^{i2\\pi \\tau}$. Assuming some fields\ntransform as triplets under the finite modular symmetry, with general\nassignments for the other fields, we perform a complete analysis for the levels\n$N=3, 4, 5$, expressing fermion masses and mixings in terms of powers of the\nsmall parameters $\\tilde{\\phi}$ and $q$. We present two examples in detail,\nbased on the modular group $T'$, close to the CP boundary of $\\tau$, which can\naddress both fermion mass and mixing hierarchies using a weighton field.",
    "pdf_url": "http://arxiv.org/pdf/2505.12916v1",
    "published": "2025-05-19T09:52:55+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12915v1",
    "title": "Cluster tilting modules for local algebras",
    "authors": [
      "Rene Marczinzik",
      "Daniel Owens"
    ],
    "abstract": "We give the first example of a non-trivial cluster tilting module in a local\nfinite dimensional algebra. To do this, we give an explicit calculation of the\ncorresponding higher Auslander algebra by quiver and relations using the\nGAP-package QPA. We discuss related problems and conjectures for local\nfinite-dimensional algebras.",
    "pdf_url": "http://arxiv.org/pdf/2505.12915v1",
    "published": "2025-05-19T09:50:27+00:00",
    "categories": [
      "math.RT",
      "16G10, 16E10"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12914v1",
    "title": "Mechanistic Insights into the Early Stages of Oxidation at Copper Terrace: The Role of O-O Repulsion and Substrate-mediated Effects",
    "authors": [
      "E V Charan Reddy",
      "Abhijit Chatterjee"
    ],
    "abstract": "Copper-based catalysts play a crucial role in industrial oxidation reactions.\nAlthough many theoretical studies consider copper to be metallic, it is well\nestablished that copper readily oxides at ambient conditions, forming a\npassivating oxide layer. Experimental investigations spanning two decades have\nshown that in addition to the anticipated step-oxide formation, oxide can\ndirectly form at the Cu(111) terrace. The atomistically-resolved mechanism for\ndirect oxidation at flat terraces remains unknown. Using density functional\ntheory (DFT) calculations, we demonstrate that the formation of subsurface\noxide occurs through a coordinated mechanism that takes place in the presence\nof specific clusters of adsorbed oxygen atoms. Certain oxygen atoms in the\ncluster function like pincers to extract a copper atom from the surface layer\nand induce localized surface restructuring. This process creates open channels\nthat allow an oxygen atom to diffuse into the subsurface layer. The subsurface\noxide formation is barrierless. This implies that the Cu oxide surface is\nhighly dynamic. At low O coverages, subsurface oxidation is unlikely via step\noxide growth nor direct terrace oxidation as the subsurface oxygen is unstable.\nSubstrate mediated O-Cu-O adsorbate interactions govern the oxide stability.\nThese insights provide a foundation for developing a more accurate dynamic\nmodels for copper catalysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.12914v1",
    "published": "2025-05-19T09:49:14+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.12913v1",
    "title": "Active Learning on Synthons for Molecular Design",
    "authors": [
      "Tom George Grigg",
      "Mason Burlage",
      "Oliver Brook Scott",
      "Adam Taouil",
      "Dominique Sydow",
      "Liam Wilbraham"
    ],
    "abstract": "Exhaustive virtual screening is highly informative but often intractable\nagainst the expensive objective functions involved in modern drug discovery.\nThis problem is exacerbated in combinatorial contexts such as multi-vector\nexpansion, where molecular spaces can quickly become ultra-large. Here, we\nintroduce Scalable Active Learning via Synthon Acquisition (SALSA): a simple\nalgorithm applicable to multi-vector expansion which extends pool-based active\nlearning to non-enumerable spaces by factoring modeling and acquisition over\nsynthon or fragment choices. Through experiments on ligand- and structure-based\nobjectives, we highlight SALSA's sample efficiency, and its ability to scale to\nspaces of trillions of compounds. Further, we demonstrate application toward\nmulti-parameter objective design tasks on three protein targets - finding\nSALSA-generated molecules have comparable chemical property profiles to known\nbioactives, and exhibit greater diversity and higher scores over an\nindustry-leading generative approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.12913v1",
    "published": "2025-05-19T09:48:02+00:00",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12912v1",
    "title": "Uniformity First: Uniformity-aware Test-time Adaptation of Vision-language Models against Image Corruption",
    "authors": [
      "Kazuki Adachi",
      "Shin'ya Yamaguchi",
      "Tomoki Hamagami"
    ],
    "abstract": "Pre-trained vision-language models such as contrastive language-image\npre-training (CLIP) have demonstrated a remarkable generalizability, which has\nenabled a wide range of applications represented by zero-shot classification.\nHowever, vision-language models still suffer when they face datasets with large\ngaps from training ones, i.e., distribution shifts. We found that CLIP is\nespecially vulnerable to sensor degradation, a type of realistic distribution\nshift caused by sensor conditions such as weather, light, or noise. Collecting\na new dataset from a test distribution for fine-tuning highly costs since\nsensor degradation occurs unexpectedly and has a range of variety. Thus, we\ninvestigate test-time adaptation (TTA) of zero-shot classification, which\nenables on-the-fly adaptation to the test distribution with unlabeled test\ndata. Existing TTA methods for CLIP mainly focus on modifying image and text\nembeddings or predictions to address distribution shifts. Although these\nmethods can adapt to domain shifts, such as fine-grained labels spaces or\ndifferent renditions in input images, they fail to adapt to distribution shifts\ncaused by sensor degradation. We found that this is because image embeddings\nare \"corrupted\" in terms of uniformity, a measure related to the amount of\ninformation. To make models robust to sensor degradation, we propose a novel\nmethod called uniformity-aware information-balanced TTA (UnInfo). To address\nthe corruption of image embeddings, we introduce uniformity-aware confidence\nmaximization, information-aware loss balancing, and knowledge distillation from\nthe exponential moving average (EMA) teacher. Through experiments, we\ndemonstrate that our UnInfo improves accuracy under sensor degradation by\nretaining information in terms of uniformity.",
    "pdf_url": "http://arxiv.org/pdf/2505.12912v1",
    "published": "2025-05-19T09:47:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12911v1",
    "title": "HiERO: understanding the hierarchy of human behavior enhances reasoning on egocentric videos",
    "authors": [
      "Simone Alberto Peirone",
      "Francesca Pistilli",
      "Giuseppe Averta"
    ],
    "abstract": "Human activities are particularly complex and variable, and this makes\nchallenging for deep learning models to reason about them. However, we note\nthat such variability does have an underlying structure, composed of a\nhierarchy of patterns of related actions. We argue that such structure can\nemerge naturally from unscripted videos of human activities, and can be\nleveraged to better reason about their content. We present HiERO, a\nweakly-supervised method to enrich video segments features with the\ncorresponding hierarchical activity threads. By aligning video clips with their\nnarrated descriptions, HiERO infers contextual, semantic and temporal reasoning\nwith an hierarchical architecture. We prove the potential of our enriched\nfeatures with multiple video-text alignment benchmarks (EgoMCQ, EgoNLQ) with\nminimal additional training, and in zero-shot for procedure learning tasks\n(EgoProceL and Ego4D Goal-Step). Notably, HiERO achieves state-of-the-art\nperformance in all the benchmarks, and for procedure learning tasks it\noutperforms fully-supervised methods by a large margin (+12.5% F1 on EgoProceL)\nin zero shot. Our results prove the relevance of using knowledge of the\nhierarchy of human activities for multiple reasoning tasks in egocentric\nvision.",
    "pdf_url": "http://arxiv.org/pdf/2505.12911v1",
    "published": "2025-05-19T09:47:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12910v2",
    "title": "SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs",
    "authors": [
      "Le Cheng",
      "Peican Zhu",
      "Yangming Guo",
      "Chao Gao",
      "Zhen Wang",
      "Keke Tang"
    ],
    "abstract": "Source detection on graphs has demonstrated high efficacy in identifying\nrumor origins. Despite advances in machine learning-based methods, many fail to\ncapture intrinsic dynamics of rumor propagation. In this work, we present\nSourceDetMamba: A Graph-aware State Space Model for Source Detection in\nSequential Hypergraphs, which harnesses the recent success of the state space\nmodel Mamba, known for its superior global modeling capabilities and\ncomputational efficiency, to address this challenge. Specifically, we first\nemploy hypergraphs to model high-order interactions within social networks.\nSubsequently, temporal network snapshots generated during the propagation\nprocess are sequentially fed in reverse order into Mamba to infer underlying\npropagation dynamics. Finally, to empower the sequential model to effectively\ncapture propagation patterns while integrating structural information, we\npropose a novel graph-aware state update mechanism, wherein the state of each\nnode is propagated and refined by both temporal dependencies and topological\ncontext. Extensive evaluations on eight datasets demonstrate that\nSourceDetMamba consistently outperforms state-of-the-art approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.12910v2",
    "published": "2025-05-19T09:45:27+00:00",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12909v2",
    "title": "Sinusoidal Initialization, Time for a New Start",
    "authors": [
      "Alberto Fern√°ndez-Hern√°ndez",
      "Jose I. Mestre",
      "Manuel F. Dolz",
      "Jose Duato",
      "Enrique S. Quintana-Ort√≠"
    ],
    "abstract": "Initialization plays a critical role in Deep Neural Network training,\ndirectly influencing convergence, stability, and generalization. Common\napproaches such as Glorot and He initializations rely on randomness, which can\nproduce uneven weight distributions across layer connections. In this paper, we\nintroduce the Sinusoidal initialization, a novel deterministic method that\nemploys sinusoidal functions to construct structured weight matrices expressly\nto improve the spread and balance of weights throughout the network while\nsimultaneously fostering a more uniform, well-conditioned distribution of\nneuron activation states from the very first forward pass. Because Sinusoidal\ninitialization begins with weights and activations that are already evenly and\nefficiently utilized, it delivers consistently faster convergence, greater\ntraining stability, and higher final accuracy across a wide range of models,\nincluding convolutional neural networks, vision transformers, and large\nlanguage models. On average, our experiments show an increase of 4.9% in final\nvalidation accuracy and 20.9% in convergence speed. By replacing randomness\nwith structure, this initialization provides a stronger and more reliable\nfoundation for Deep Learning systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12909v2",
    "published": "2025-05-19T09:45:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2; G.3; I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12908v1",
    "title": "Dynamic Graph Induced Contour-aware Heat Conduction Network for Event-based Object Detection",
    "authors": [
      "Xiao Wang",
      "Yu Jin",
      "Lan Chen",
      "Bo Jiang",
      "Lin Zhu",
      "Yonghong Tian",
      "Jin Tang",
      "Bin Luo"
    ],
    "abstract": "Event-based Vision Sensors (EVS) have demonstrated significant advantages\nover traditional RGB frame-based cameras in low-light conditions, high-speed\nmotion capture, and low latency. Consequently, object detection based on EVS\nhas attracted increasing attention from researchers. Current event stream\nobject detection algorithms are typically built upon Convolutional Neural\nNetworks (CNNs) or Transformers, which either capture limited local features\nusing convolutional filters or incur high computational costs due to the\nutilization of self-attention. Recently proposed vision heat conduction\nbackbone networks have shown a good balance between efficiency and accuracy;\nhowever, these models are not specifically designed for event stream data. They\nexhibit weak capability in modeling object contour information and fail to\nexploit the benefits of multi-scale features. To address these issues, this\npaper proposes a novel dynamic graph induced contour-aware heat conduction\nnetwork for event stream based object detection, termed CvHeat-DET. The\nproposed model effectively leverages the clear contour information inherent in\nevent streams to predict the thermal diffusivity coefficients within the heat\nconduction model, and integrates hierarchical structural graph features to\nenhance feature learning across multiple scales. Extensive experiments on three\nbenchmark datasets for event stream-based object detection fully validated the\neffectiveness of the proposed model. The source code of this paper will be\nreleased on https://github.com/Event-AHU/OpenEvDET.",
    "pdf_url": "http://arxiv.org/pdf/2505.12908v1",
    "published": "2025-05-19T09:44:01+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22680v1",
    "title": "Exploring Holography in Neuro-Vascular Dynamics",
    "authors": [
      "Christian Kerskens"
    ],
    "abstract": "The holonomic brain theory, originally formulated to account for the need of\nnon-local memory encoding in cognitive systems, could gain new theoretical\ntraction when integrated with holographic principles from physics, most notably\nthe AdS/CFT correspondence. Recent findings in neuroscience suggest that\nconformal field theories (CFTs), emerging at critical points across\nspatiotemporal scales in neural dynamics, are essential for brain function.\nConcurrently, black-brane geometries, long studied in gravitational physics,\ncan find unexpected analogues in the interplay of active matter dynamics and\nthe brain s neuroanatomical organization. Motivated by these parallels, we\nposit a generalized holographic framework and interrogate its validity through\nthe fluid/gravity duality; a correspondence linking hydrodynamic equations to\ngravitational spacetime metrics. In this work, we explore the holographic\nprinciples at the Navier-Stokes regime, demonstrating that holography can model\nkey neurophysiological mechanisms: cerebral autoregulation (the brain s\nhemodynamic self-stabilization) and neurovascular coupling (the dynamic\nneuron-bloodflow interplay). This work bridges holography, active matter\nphysics, and neuroscience, proposing a unified framework to decode the brain s\nmultiscale organization, its resilience to perturbations, and its computational\ncapabilities. By grounding neurovascular physiology in gravitational duals, we\nopen pathways to reinterpret brain function through the lens of emergent\nspacetime geometry.",
    "pdf_url": "http://arxiv.org/pdf/2505.22680v1",
    "published": "2025-05-19T09:43:25+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12907v1",
    "title": "A generalization of the Chv√°tal-Erd≈ës theorem",
    "authors": [
      "Kun Cheng"
    ],
    "abstract": "A well-known result of Chv\\'{a}tal and Erd\\H{o}s from 1972 states that a\ngraph with connectivity not less than its independence number plus one is\nhamiltonian-connected. A graph $G$ is called an $[s,t]$-graph if any induced\nsubgraph of $G$ of order $s$ has size at least $t.$ We prove that every\n$k$-connected $[k+1,2]$-graph is hamiltonian-connected except $kK_1\\vee G_{k},$\nwhere $k\\ge 2$ and $G_{k}$ is an arbitrary graph of order $k.$ This generalizes\nthe Chv\\'{a}tal-Erd\\H{o}s theorem.",
    "pdf_url": "http://arxiv.org/pdf/2505.12907v1",
    "published": "2025-05-19T09:41:30+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12906v1",
    "title": "Efficient training for large-scale optical neural network using an evolutionary strategy and attention pruning",
    "authors": [
      "Zhiwei Yang",
      "Zeyang Fan",
      "Yihang Lai",
      "Qi Chen",
      "Tian Zhang",
      "Jian Dai",
      "Kun Xu"
    ],
    "abstract": "MZI-based block optical neural networks (BONNs), which can achieve\nlarge-scale network models, have increasingly drawn attentions. However, the\nrobustness of the current training algorithm is not high enough. Moreover,\nlarge-scale BONNs usually contain numerous trainable parameters, resulting in\nexpensive computation and power consumption. In this article, by pruning matrix\nblocks and directly optimizing the individuals in population, we propose an\non-chip covariance matrix adaptation evolution strategy and attention-based\npruning (CAP) algorithm for large-scale BONNs. The calculated results\ndemonstrate that the CAP algorithm can prune 60% and 80% of the parameters for\nMNIST and Fashion-MNIST datasets, respectively, while only degrades the\nperformance by 3.289% and 4.693%. Considering the influence of dynamic noise in\nphase shifters, our proposed CAP algorithm (performance degradation of 22.327%\nfor MNIST dataset and 24.019% for Fashion-MNIST dataset utilizing a poor\nfabricated chip and electrical control with a standard deviation of 0.5)\nexhibits strongest robustness compared with both our previously reported block\nadjoint training algorithm (43.963% and 41.074%) and the covariance matrix\nadaptation evolution strategy (25.757% and 32.871%), respectively. Moreover,\nwhen 60% of the parameters are pruned, the CAP algorithm realizes 88.5%\naccuracy in experiment for the simplified MNIST dataset, which is similar to\nthe simulation result without noise (92.1%). Additionally, we simulationally\nand experimentally demonstrate that using MZIs with only internal phase\nshifters to construct BONNs is an efficient way to reduce both the system area\nand the required trainable parameters. Notably, our proposed CAP algorithm show\nexcellent potential for larger-scale network models and more complex tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12906v1",
    "published": "2025-05-19T09:41:11+00:00",
    "categories": [
      "cs.LG",
      "physics.optics"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12905v1",
    "title": "Lecture Notes: WISPs in gamma-ray astrophysics",
    "authors": [
      "Francesca Calore",
      "Christopher Eckner"
    ],
    "abstract": "These lecture notes provide an overview of high-energy astrophysical\nprocesses involving axions, axion-like particles (ALPs), and other weakly\ninteracting slim particles (WISPs) focusing on their potential observational\nsignatures in astrophysical environments. After introducing key concepts in\nhigh-energy astrophysics, we present the fundamental properties of WISPs,\nemphasizing their phenomenological implications. Particular attention is given\nto ALP-photon conversion in strong magnetic fields and the possible decay\nsignatures of ALPs in sources such as active galactic nuclei, galaxy clusters,\nand cosmic-ray accelerators. These effects can lead to distinctive\nmodifications in astrophysical spectra, spatial distributions, and polarization\npatterns, providing unique probes of physics beyond the Standard Model. We\ndiscuss their role in dark matter scenarios and their potential impact on\nhigh-energy observations. The lecture series is supplemented by hands-on\ntutorials, including exercises on axion electrodynamics and an analysis of\ngamma-ray data from NGC 1275 to search for ALP-photon conversion signatures.",
    "pdf_url": "http://arxiv.org/pdf/2505.12905v1",
    "published": "2025-05-19T09:40:34+00:00",
    "categories": [
      "astro-ph.HE",
      "hep-ph"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12904v1",
    "title": "The Computation of Generalized Embeddings for Underwater Acoustic Target Recognition using Contrastive Learning",
    "authors": [
      "Hilde I. Hummel",
      "Arwin Gansekoele",
      "Sandjai Bhulai",
      "Rob van der Mei"
    ],
    "abstract": "The increasing level of sound pollution in marine environments poses an\nincreased threat to ocean health, making it crucial to monitor underwater\nnoise. By monitoring this noise, the sources responsible for this pollution can\nbe mapped. Monitoring is performed by passively listening to these sounds. This\ngenerates a large amount of data records, capturing a mix of sound sources such\nas ship activities and marine mammal vocalizations. Although machine learning\noffers a promising solution for automatic sound classification, current\nstate-of-the-art methods implement supervised learning. This requires a large\namount of high-quality labeled data that is not publicly available. In\ncontrast, a massive amount of lower-quality unlabeled data is publicly\navailable, offering the opportunity to explore unsupervised learning\ntechniques. This research explores this possibility by implementing an\nunsupervised Contrastive Learning approach. Here, a Conformer-based encoder is\noptimized by the so-called Variance-Invariance-Covariance Regularization loss\nfunction on these lower-quality unlabeled data and the translation to the\nlabeled data is made. Through classification tasks involving recognizing ship\ntypes and marine mammal vocalizations, our method demonstrates to produce\nrobust and generalized embeddings. This shows to potential of unsupervised\nmethods for various automatic underwater acoustic analysis tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12904v1",
    "published": "2025-05-19T09:37:46+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.12903v1",
    "title": "Towards Low-Latency Event Stream-based Visual Object Tracking: A Slow-Fast Approach",
    "authors": [
      "Shiao Wang",
      "Xiao Wang",
      "Liye Jin",
      "Bo Jiang",
      "Lin Zhu",
      "Lan Chen",
      "Yonghong Tian",
      "Bin Luo"
    ],
    "abstract": "Existing tracking algorithms typically rely on low-frame-rate RGB cameras\ncoupled with computationally intensive deep neural network architectures to\nachieve effective tracking. However, such frame-based methods inherently face\nchallenges in achieving low-latency performance and often fail in\nresource-constrained environments. Visual object tracking using bio-inspired\nevent cameras has emerged as a promising research direction in recent years,\noffering distinct advantages for low-latency applications. In this paper, we\npropose a novel Slow-Fast Tracking paradigm that flexibly adapts to different\noperational requirements, termed SFTrack. The proposed framework supports two\ncomplementary modes, i.e., a high-precision slow tracker for scenarios with\nsufficient computational resources, and an efficient fast tracker tailored for\nlatency-aware, resource-constrained environments. Specifically, our framework\nfirst performs graph-based representation learning from\nhigh-temporal-resolution event streams, and then integrates the learned\ngraph-structured information into two FlashAttention-based vision backbones,\nyielding the slow and fast trackers, respectively. The fast tracker achieves\nlow latency through a lightweight network design and by producing multiple\nbounding box outputs in a single forward pass. Finally, we seamlessly combine\nboth trackers via supervised fine-tuning and further enhance the fast tracker's\nperformance through a knowledge distillation strategy. Extensive experiments on\npublic benchmarks, including FE240, COESOT, and EventVOT, demonstrate the\neffectiveness and efficiency of our proposed method across different real-world\nscenarios. The source code has been released on\nhttps://github.com/Event-AHU/SlowFast_Event_Track.",
    "pdf_url": "http://arxiv.org/pdf/2505.12903v1",
    "published": "2025-05-19T09:37:23+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12902v1",
    "title": "Power Allocation for Delay Optimization in Device-to-Device Networks: A Graph Reinforcement Learning Approach",
    "authors": [
      "Hao Fang",
      "Kai Huang",
      "Hao Ye",
      "Chongtao Guo",
      "Le Liang",
      "Xiao Li",
      "Shi Jin"
    ],
    "abstract": "The pursuit of rate maximization in wireless communication frequently\nencounters substantial challenges associated with user fairness. This paper\naddresses these challenges by exploring a novel power allocation approach for\ndelay optimization, utilizing graph neural networks (GNNs)-based reinforcement\nlearning (RL) in device-to-device (D2D) communication. The proposed approach\nincorporates not only channel state information but also factors such as packet\ndelay, the number of backlogged packets, and the number of transmitted packets\ninto the components of the state information. We adopt a centralized RL method,\nwhere a central controller collects and processes the state information. The\ncentral controller functions as an agent trained using the proximal policy\noptimization (PPO) algorithm. To better utilize topology information in the\ncommunication network and enhance the generalization of the proposed method, we\nembed GNN layers into both the actor and critic networks of the PPO algorithm.\nThis integration allows for efficient parameter updates of GNNs and enables the\nstate information to be parameterized as a low-dimensional embedding, which is\nleveraged by the agent to optimize power allocation strategies. Simulation\nresults demonstrate that the proposed method effectively reduces average delay\nwhile ensuring user fairness, outperforms baseline methods, and exhibits\nscalability and generalization capability.",
    "pdf_url": "http://arxiv.org/pdf/2505.12902v1",
    "published": "2025-05-19T09:37:00+00:00",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.12901v1",
    "title": "Sharp estimate on the resolvent of a finite-dimensional contraction",
    "authors": [
      "Karine Fouchet"
    ],
    "abstract": "We compute an asymptotic formula for the supremum of the resolvent norm\n($\\zeta$ -T ) -1 over |$\\zeta$| $\\ge$ 1 and contractions T acting on an\nn-dimensional Hilbert space, whose spectral radius does not exceed a given r\n$\\in$ (0, 1). We prove that this supremum is achieved on the unit circle by an\nanalytic Toeplitz matrix.",
    "pdf_url": "http://arxiv.org/pdf/2505.12901v1",
    "published": "2025-05-19T09:36:26+00:00",
    "categories": [
      "math.FA",
      "math.SP"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12900v1",
    "title": "AutoGEEval: A Multimodal and Automated Framework for Geospatial Code Generation on GEE with Large Language Models",
    "authors": [
      "Shuyang Hou",
      "Zhangxiao Shen",
      "Huayi Wu",
      "Jianyuan Liang",
      "Haoyue Jiao",
      "Yaxian Qing",
      "Xiaopu Zhang",
      "Xu Li",
      "Zhipeng Gui",
      "Xuefeng Guan",
      "Longgang Xiang"
    ],
    "abstract": "Geospatial code generation is emerging as a key direction in the integration\nof artificial intelligence and geoscientific analysis. However, there remains a\nlack of standardized tools for automatic evaluation in this domain. To address\nthis gap, we propose AutoGEEval, the first multimodal, unit-level automated\nevaluation framework for geospatial code generation tasks on the Google Earth\nEngine (GEE) platform powered by large language models (LLMs). Built upon the\nGEE Python API, AutoGEEval establishes a benchmark suite (AutoGEEval-Bench)\ncomprising 1325 test cases that span 26 GEE data types. The framework\nintegrates both question generation and answer verification components to\nenable an end-to-end automated evaluation pipeline-from function invocation to\nexecution validation. AutoGEEval supports multidimensional quantitative\nanalysis of model outputs in terms of accuracy, resource consumption, execution\nefficiency, and error types. We evaluate 18 state-of-the-art LLMs-including\ngeneral-purpose, reasoning-augmented, code-centric, and geoscience-specialized\nmodels-revealing their performance characteristics and potential optimization\npathways in GEE code generation. This work provides a unified protocol and\nfoundational resource for the development and assessment of geospatial code\ngeneration models, advancing the frontier of automated natural language to\ndomain-specific code translation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12900v1",
    "published": "2025-05-19T09:35:58+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CG",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12899v3",
    "title": "Interpolation for the two-way modal mu-calculus",
    "authors": [
      "Johannes Kloibhofer",
      "Yde Venema"
    ],
    "abstract": "The two-way modal mu-calculus is the extension of the (standard) one-way\nmu-calculus with converse (backward-looking) modalities. For this logic we\nintroduce two new sequent-style proof calculi: a non-wellfounded system\nadmitting infinite branches and a finitary, cyclic version of this that employs\nannotations. As is common in sequent systems for two-way modal logics, our\ncalculi feature an analytic cut rule. What distinguishes our approach is the\nuse of so-called trace atoms, which serve to apply Vardi's two-way automata in\na proof-theoretic setting. We prove soundness and completeness for both systems\nand subsequently use the cyclic calculus to show that the two-way mu-calculus\nhas the (local) Craig interpolation property, with respect to both propositions\nand modalities. Our proof uses a version of Maehara's method adapted to cyclic\nproof systems. As a corollary we prove that the two-way mu-calculus also enjoys\nBeth's definability property.",
    "pdf_url": "http://arxiv.org/pdf/2505.12899v3",
    "published": "2025-05-19T09:35:11+00:00",
    "categories": [
      "cs.LO",
      "math.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12898v1",
    "title": "Self-consistent model for active control of wind turbine wakes",
    "authors": [
      "Zhaobin Li",
      "Xiaolei Yang"
    ],
    "abstract": "Active wake control (AWC) has emerged as a promising strategy for enhancing\nwind turbine wake recovery, but accurately modelling its underlying fluid\nmechanisms remains challenging. This study presents a computationally efficient\nwake model that provides end-to-end prediction capability from rotor actuation\nto wake recovery enhancement by capturing the coupled dynamics of wake\nmeandering and meanflow modification, requiring only two inputs: a reference\nwake without control and a user-defined AWC strategy. The model combines\nphysics-based resolvent modelling for large-scale coherent structures and an\neddy viscosity modelling for small-scale turbulence. A Reynolds stress model is\nintroduced to account for the influence of both coherent and incoherent wake\nfluctuations, so that the time-averaged wake recovery enhanced by the AWC can\nbe quantitatively predicted. Validation against large-eddy simulations (LES)\nacross various AWC approaches and actuating frequencies demonstrates the\nmodel's predictive capability, accurately capturing AWC-specific and\nfrequency-dependent mean wake recovery with less than 8% error from LES while\nreducing computational time from thousands of CPU hours to minutes. The\nefficiency and accuracy of the model makes it a promising tool for practical\nAWC design and optimization of large-scale wind farms.",
    "pdf_url": "http://arxiv.org/pdf/2505.12898v1",
    "published": "2025-05-19T09:33:56+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.01996v2",
    "title": "Unifying Framework for Amplification Mechanisms: Criticality, Resonance and Non-Normality",
    "authors": [
      "Virgile Troude",
      "Didier Sornette"
    ],
    "abstract": "We bring together three key amplification mechanisms in linear dynamical\nsystems: spectral criticality, resonance, and non-normality. We present a\nunified linear framework that both distinguishes and quantitatively links these\neffects through two fundamental parameters: (i) the spectral distance to a\nconventional bifurcation or to a resonance and (ii) a non-normal index $K$ (or\ncondition number $\\kappa$) that measures the obliqueness of the eigenvectors.\nClosed-form expressions for the system's response in the form of the variance\n$v_\\infty$ of the observable responding to both Gaussian noise and periodic\nforcing reveal a general amplification law $v_\\infty = v_0 \\left( 1 +\n\\mathcal{G}(K) \\right)$ with non-normal gain $\\mathcal{G}(K) \\propto K^2$\nrepresented in universal phase diagrams. By reanalyzing a model of remote\nearthquake triggering based on breaking of Hamiltonian symmetry, we illustrate\nhow our two-parameter framework significantly expands both the range of\nconditions under which amplification can occur and the magnitude of the\nresulting response, revealing a broad pseudo-critical regime associated with\nlarge $\\kappa$ that previous single-parameter approaches overlooked. Similarly,\nin the Non-Hermitian extensions of quantum optics provided by Forward Four-Wave\nMixing (FFWM) experiments, we show the presence of a counterintuitive\ngain-from-loss effect that directly manifests non-normal amplification in a\npropagating-wave setting. This predicts the possibility to engineer transient\noptical energy amplification without the need for true lasing or exact\n$\\mathcal{PT}$-symmetry breaking. Our framework applies to many other physical,\nnatural and social systems and offers new diagnostic tools to distinguish true\ncritical behavior from transient amplification driven by non-normality.",
    "pdf_url": "http://arxiv.org/pdf/2506.01996v2",
    "published": "2025-05-19T09:33:50+00:00",
    "categories": [
      "nlin.CD"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2505.12897v1",
    "title": "EPIC: Explanation of Pretrained Image Classification Networks via Prototype",
    "authors": [
      "Piotr Borycki",
      "Magdalena Trƒôdowicz",
      "Szymon Janusz",
      "Jacek Tabor",
      "Przemys≈Çaw Spurek",
      "Arkadiusz Lewicki",
      "≈Åukasz Struski"
    ],
    "abstract": "Explainable AI (XAI) methods generally fall into two categories. Post-hoc\napproaches generate explanations for pre-trained models and are compatible with\nvarious neural network architectures. These methods often use feature\nimportance visualizations, such as saliency maps, to indicate which input\nregions influenced the model's prediction. Unfortunately, they typically offer\na coarse understanding of the model's decision-making process. In contrast,\nante-hoc (inherently explainable) methods rely on specially designed model\narchitectures trained from scratch. A notable subclass of these methods\nprovides explanations through prototypes, representative patches extracted from\nthe training data. However, prototype-based approaches have limitations: they\nrequire dedicated architectures, involve specialized training procedures, and\nperform well only on specific datasets. In this work, we propose EPIC\n(Explanation of Pretrained Image Classification), a novel approach that bridges\nthe gap between these two paradigms. Like post-hoc methods, EPIC operates on\npre-trained models without architectural modifications. Simultaneously, it\ndelivers intuitive, prototype-based explanations inspired by ante-hoc\ntechniques. To the best of our knowledge, EPIC is the first post-hoc method\ncapable of fully replicating the core explanatory power of inherently\ninterpretable models. We evaluate EPIC on benchmark datasets commonly used in\nprototype-based explanations, such as CUB-200-2011 and Stanford Cars, alongside\nlarge-scale datasets like ImageNet, typically employed by post-hoc methods.\nEPIC uses prototypes to explain model decisions, providing a flexible and\neasy-to-understand tool for creating clear, high-quality explanations.",
    "pdf_url": "http://arxiv.org/pdf/2505.12897v1",
    "published": "2025-05-19T09:32:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.14717v1",
    "title": "Aneumo: A Large-Scale Multimodal Aneurysm Dataset with Computational Fluid Dynamics Simulations and Deep Learning Benchmarks",
    "authors": [
      "Xigui Li",
      "Yuanye Zhou",
      "Feiyang Xiao",
      "Xin Guo",
      "Chen Jiang",
      "Tan Pan",
      "Xingmeng Zhang",
      "Cenyu Liu",
      "Zeyun Miao",
      "Jianchao Ge",
      "Xiansheng Wang",
      "Qimeng Wang",
      "Yichi Zhang",
      "Wenbo Zhang",
      "Fengping Zhu",
      "Limei Han",
      "Yuan Qi",
      "Chensen Lin",
      "Yuan Cheng"
    ],
    "abstract": "Intracranial aneurysms (IAs) are serious cerebrovascular lesions found in\napproximately 5\\% of the general population. Their rupture may lead to high\nmortality. Current methods for assessing IA risk focus on morphological and\npatient-specific factors, but the hemodynamic influences on IA development and\nrupture remain unclear. While accurate for hemodynamic studies, conventional\ncomputational fluid dynamics (CFD) methods are computationally intensive,\nhindering their deployment in large-scale or real-time clinical applications.\nTo address this challenge, we curated a large-scale, high-fidelity aneurysm CFD\ndataset to facilitate the development of efficient machine learning algorithms\nfor such applications. Based on 427 real aneurysm geometries, we synthesized\n10,660 3D shapes via controlled deformation to simulate aneurysm evolution. The\nauthenticity of these synthetic shapes was confirmed by neurosurgeons. CFD\ncomputations were performed on each shape under eight steady-state mass flow\nconditions, generating a total of 85,280 blood flow dynamics data covering key\nparameters. Furthermore, the dataset includes segmentation masks, which can\nsupport tasks that use images, point clouds or other multimodal data as input.\nAdditionally, we introduced a benchmark for estimating flow parameters to\nassess current modeling methods. This dataset aims to advance aneurysm research\nand promote data-driven approaches in biofluids, biomedical engineering, and\nclinical risk assessment. The code and dataset are available at:\nhttps://github.com/Xigui-Li/Aneumo.",
    "pdf_url": "http://arxiv.org/pdf/2505.14717v1",
    "published": "2025-05-19T09:32:09+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12896v1",
    "title": "On the Thinking-Language Modeling Gap in Large Language Models",
    "authors": [
      "Chenxi Liu",
      "Yongqiang Chen",
      "Tongliang Liu",
      "James Cheng",
      "Bo Han",
      "Kun Zhang"
    ],
    "abstract": "System 2 reasoning is one of the defining characteristics of intelligence,\nwhich requires slow and logical thinking. Human conducts System 2 reasoning via\nthe language of thoughts that organizes the reasoning process as a causal\nsequence of mental language, or thoughts. Recently, it has been observed that\nSystem 2 reasoning can be elicited from Large Language Models (LLMs)\npre-trained on large-scale natural languages. However, in this work, we show\nthat there is a significant gap between the modeling of languages and thoughts.\nAs language is primarily a tool for humans to share knowledge and thinking,\nmodeling human language can easily absorb language biases into LLMs deviated\nfrom the chain of thoughts in minds. Furthermore, we show that the biases will\nmislead the eliciting of \"thoughts\" in LLMs to focus only on a biased part of\nthe premise. To this end, we propose a new prompt technique termed\nLanguage-of-Thoughts (LoT) to demonstrate and alleviate this gap. Instead of\ndirectly eliciting the chain of thoughts from partial information, LoT\ninstructs LLMs to adjust the order and token used for the expressions of all\nthe relevant information. We show that the simple strategy significantly\nreduces the language modeling biases in LLMs and improves the performance of\nLLMs across a variety of reasoning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12896v1",
    "published": "2025-05-19T09:31:52+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12895v1",
    "title": "Advanced modelling of Night Sky Background light for Imaging Atmospheric Cherenkov Telescopes",
    "authors": [
      "Gerrit Roellinghoff",
      "Samuel T. Spencer",
      "Stefan Funk"
    ],
    "abstract": "A significant source of noise for Imaging Atmospheric Cherenkov Telescopes\n(IACTs), which are designed to measure air showers caused by astrophysical\ngamma rays, is optical light emitted from the night sky. This Night Sky\nBackground (NSB) influences IACT operating times and their sensitivity. Thus,\nfor scheduling observations and instrument simulation, an accurate estimate of\nthe NSB is important. A physics-driven approach to simulating\nwavelength-dependent, per-photomultiplier-pixel NSB was developed. It includes\ncontributions from scattered moonlight, starlight, diffuse galactic light,\nzodiacal light, and airglow emission. It also accounts for the absorption and\nscattering of optical light in the atmosphere and telescope-specific factors\nsuch as mirror reflectivity, photon detection efficiency, and focal length. The\nsimulated results are corrected for pointing inaccuracies and individual pixel\nsensitivities and compared to data from the High Energy Stereoscopic System\n(H.E.S.S.) IACT array. The software package developed for this analysis will be\nmade publicly available. Validation against H.E.S.S.\\ data shows small\ndeviations from the prediction, attributable to airglow and atmospheric\nvariability. Per-Pixel predictions provide a good match to the data, with the\nrelative 90\\% error range being [-21\\%, 19\\%]. Compared to the existing\nstandard modelling approach of assuming a constant background, where the\nrelative 90\\% error range was [-64\\%, 48\\%], this is a significant improvement.",
    "pdf_url": "http://arxiv.org/pdf/2505.12895v1",
    "published": "2025-05-19T09:31:29+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.13561v1",
    "title": "Language and Thought: The View from LLMs",
    "authors": [
      "Daniel Rothschild"
    ],
    "abstract": "Daniel Dennett speculated in *Kinds of Minds* 1996: \"Perhaps the kind of mind\nyou get when you add language to it is so different from the kind of mind you\ncan have without language that calling them both minds is a mistake.\" Recent\nwork in AI can be seen as testing Dennett's thesis by exploring the performance\nof AI systems with and without linguistic training. I argue that the success of\nLarge Language Models at inferential reasoning, limited though it may be,\nsupports Dennett's radical view about the effect of language on thought. I\nsuggest it is the abstractness and efficiency of linguistic encoding that lies\nbehind the capacity of LLMs to perform inferences across a wide range of\ndomains. In a slogan, language makes inference computationally tractable. I\nassess what these results in AI indicate about the role of language in the\nworkings of our own biological minds.",
    "pdf_url": "http://arxiv.org/pdf/2505.13561v1",
    "published": "2025-05-19T09:29:32+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.08019v1",
    "title": "Gridding Forced Displacement using Semi-Supervised Learning",
    "authors": [
      "Andrew Wells",
      "Geraldine Henningsen",
      "Brice Bolane Tchinde Kengne"
    ],
    "abstract": "We present a semi-supervised approach that disaggregates refugee statistics\nfrom administrative boundaries to 0.5-degree grid cells across 25 Sub-Saharan\nAfrican countries. By integrating UNHCR's ProGres registration data with\nsatellite-derived building footprints from Google Open Buildings and location\ncoordinates from OpenStreetMap Populated Places, our label spreading algorithm\ncreates spatially explicit refugee statistics at high granularity.This\nmethodology achieves 92.9% average accuracy in placing over 10 million refugee\nobservations into appropriate grid cells, enabling the identification of\nlocalized displacement patterns previously obscured in broader regional and\nnational statistics. The resulting high-resolution dataset provides a\nfoundation for a deeper understanding of displacement drivers.",
    "pdf_url": "http://arxiv.org/pdf/2506.08019v1",
    "published": "2025-05-19T09:27:58+00:00",
    "categories": [
      "cs.LG",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12894v2",
    "title": "HyperDet: Source Detection in Hypergraphs via Interactive Relationship Construction and Feature-rich Attention Fusion",
    "authors": [
      "Le Cheng",
      "Peican Zhu",
      "Yangming Guo",
      "Keke Tang",
      "Chao Gao",
      "Zhen Wang"
    ],
    "abstract": "Hypergraphs offer superior modeling capabilities for social networks,\nparticularly in capturing group phenomena that extend beyond pairwise\ninteractions in rumor propagation. Existing approaches in rumor source\ndetection predominantly focus on dyadic interactions, which inadequately\naddress the complexity of more intricate relational structures. In this study,\nwe present a novel approach for Source Detection in Hypergraphs (HyperDet) via\nInteractive Relationship Construction and Feature-rich Attention Fusion.\nSpecifically, our methodology employs an Interactive Relationship Construction\nmodule to accurately model both the static topology and dynamic interactions\namong users, followed by the Feature-rich Attention Fusion module, which\nautonomously learns node features and discriminates between nodes using a\nself-attention mechanism, thereby effectively learning node representations\nunder the framework of accurately modeled higher-order relationships. Extensive\nexperimental validation confirms the efficacy of our HyperDet approach,\nshowcasing its superiority relative to current state-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.12894v2",
    "published": "2025-05-19T09:27:46+00:00",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12893v1",
    "title": "Quantitative Schur property and measures of weak non-compactness",
    "authors": [
      "Ond≈ôej F. K. Kalenda"
    ],
    "abstract": "We compare several versions of the quantitative Schur property of Banach\nspaces. We establish their equivalence up to multiplicative constants and\nprovide examples clarifying when the change of constants is necessary. We also\ngive exact results on preservation of the quantitative Schur property by finite\nor infinite direct sums. We further prove a sufficient condition for the\n$1$-Schur property which simplifies and generalizes previous results.\n  We study in more detail relationship of the quantitative Schur property to\nquantitative weak sequential completeness and to equivalence of measures of\nweak non-compactness. We also illustrate the difference of real and complex\nsettings. To this end we prove and use the optimal version of complex\nquantiative Rosenthal $\\ell_1$-theorem. Finally, we give two examples of\nLipschitz-free spaces over countable graphs which have quantitative Schur\nproperty, but not the $1$-Schur property.",
    "pdf_url": "http://arxiv.org/pdf/2505.12893v1",
    "published": "2025-05-19T09:27:11+00:00",
    "categories": [
      "math.FA",
      "46B04, 46A50, 40A05"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2506.05353v2",
    "title": "The geometric classification of nilpotent Lie-Yamaguti, Bol and compatible Lie algebras",
    "authors": [
      "Kobiljon Abdurasulov",
      "Abror Khudoyberdiyev",
      "Feruza Toshtemirova"
    ],
    "abstract": "The geometric classifications of complex $4$-dimensional nilpotent\nLie-Yamaguti algebras, $4$-dimensional nilpotent Bol algebras, and\n$4$-dimensional nilpotent compatible Lie algebras are given.",
    "pdf_url": "http://arxiv.org/pdf/2506.05353v2",
    "published": "2025-05-19T09:26:58+00:00",
    "categories": [
      "math.RA"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12892v4",
    "title": "\"I will never pay for this\" Perception of fairness and factors affecting behaviour on 'pay-or-ok' models",
    "authors": [
      "Victor Morel",
      "Farzaneh Karegar",
      "Cristiana Santos"
    ],
    "abstract": "The rise of cookie paywalls ('pay-or-ok' models) has prompted growing debates\naround the right to privacy and data protection, monetisation, and the\nlegitimacy of user consent. Despite their increasing use across sectors,\nlimited research has explored how users perceive these models or what shapes\ntheir decisions to either consent to tracking or pay. To address this gap, we\nconducted four focus groups (n= 14) to examine users' perceptions of cookie\npaywalls, their judgments of fairness, and the conditions under which they\nmight consider paying, alongside a legal analysis within the EU data protection\nlegal framework.\n  Participants primarily viewed cookie paywalls as profit-driven, with fairness\nperceptions varying depending on factors such as the presence of a third option\nbeyond consent or payment, transparency of data practices, and the authenticity\nor exclusivity of the paid content. Participants voiced expectations for\ngreater transparency, meaningful control over data collection, and less\ncoercive alternatives, such as contextual advertising or \"reject all\" buttons.\nAlthough some conditions, including trusted providers, exclusive content, and\nreasonable pricing, could make participants consider paying, most expressed\nreluctance or unwillingness to do so.\n  Crucially, our findings raise concerns about economic exclusion, where\nprivacy and data protection might end up becoming a privilege rather than\nfundamental rights. Consent given under financial pressure may not meet the\nstandard of being freely given, as required by the GDPR. To address these\nconcerns, we recommend user-centred approaches that enhance transparency,\nreduce coercion, ensure the value of paid content, and explore inclusive\nalternatives. These measures are essential for supporting fairness, meaningful\nchoice, and user autonomy in consent-driven digital environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12892v4",
    "published": "2025-05-19T09:23:51+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.13560v2",
    "title": "Experimental and theoretical investigation on N2 pressure-induced coefficients of the lowest rotational transitions of HCN",
    "authors": [
      "Francesca Tonolo",
      "Hubert J√≥≈∫wiak",
      "Luca Bizzocchi",
      "Mattia Melosso",
      "Piotr Wcis≈Ço",
      "Fran√ßois Lique",
      "Cristina Puzzarini"
    ],
    "abstract": "We present the first experimental determination of room-temperature N2\npressure broadening, speed dependent broadening, and pressure shift\ncoefficients of the three lowest rotational lines of HCN. The experimental\nresults served to assess the accuracy of a low-cost yet accurate computational\nstrategy, which relies on a simplified characterization of the HCN-N2\ninteraction potential, and employs a novel approximate method of solving the\nquantum scattering problem. Building on the validation of this computational\napproach, the dataset was extended to higher rotational transitions, up to\nJ(HCN)=5-4. For these transitions, we provide the temperature dependence of the\npressure broadening coefficient, its speed dependence parameter, and the Dicke\nnarrowing parameter. This new dataset can support and refine the modeling of\nHCN in both the terrestrial and Titan's atmospheres. This work constitutes an\nimportant step towards populating spectroscopic databases with accurate HCN\nline-shape parameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.13560v2",
    "published": "2025-05-19T09:22:22+00:00",
    "categories": [
      "physics.chem-ph",
      "astro-ph.EP"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12891v2",
    "title": "TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios",
    "authors": [
      "Shaohang Wei",
      "Wei Li",
      "Feifan Song",
      "Wen Luo",
      "Tianyi Zhuang",
      "Haochen Tan",
      "Zhijiang Guo",
      "Houfeng Wang"
    ],
    "abstract": "Temporal reasoning is pivotal for Large Language Models (LLMs) to comprehend\nthe real world. However, existing works neglect the real-world challenges for\ntemporal reasoning: (1) intensive temporal information, (2) fast-changing event\ndynamics, and (3) complex temporal dependencies in social interactions. To\nbridge this gap, we propose a multi-level benchmark TIME, designed for temporal\nreasoning in real-world scenarios. TIME consists of 38,522 QA pairs, covering 3\nlevels with 11 fine-grained sub-tasks. This benchmark encompasses 3\nsub-datasets reflecting different real-world challenges: TIME-Wiki, TIME-News,\nand TIME-Dial. We conduct extensive experiments on reasoning models and\nnon-reasoning models. And we conducted an in-depth analysis of temporal\nreasoning performance across diverse real-world scenarios and tasks, and\nsummarized the impact of test-time scaling on temporal reasoning capabilities.\nAdditionally, we release TIME-Lite, a human-annotated subset to foster future\nresearch and standardized evaluation in temporal reasoning. The code is\navailable at https://github.com/sylvain-wei/TIME , and the dataset is available\nat https://huggingface.co/datasets/SylvainWei/TIME .",
    "pdf_url": "http://arxiv.org/pdf/2505.12891v2",
    "published": "2025-05-19T09:22:02+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12890v2",
    "title": "Specialized Foundation Models for Intelligent Operating Rooms",
    "authors": [
      "Ege √ñzsoy",
      "Chantal Pellegrini",
      "David Bani-Harouni",
      "Kun Yuan",
      "Matthias Keicher",
      "Nassir Navab"
    ],
    "abstract": "Surgical procedures unfold in complex environments demanding coordination\nbetween surgical teams, tools, imaging and increasingly, intelligent robotic\nsystems. Ensuring safety and efficiency in ORs of the future requires\nintelligent systems, like surgical robots, smart instruments and digital\ncopilots, capable of understanding complex activities and hazards of surgeries.\nYet, existing computational approaches, lack the breadth, and generalization\nneeded for comprehensive OR understanding. We introduce ORQA, a multimodal\nfoundation model unifying visual, auditory, and structured data for holistic\nsurgical understanding. ORQA's question-answering framework empowers diverse\ntasks, serving as an intelligence core for a broad spectrum of surgical\ntechnologies. We benchmark ORQA against generalist vision-language models,\nincluding ChatGPT and Gemini, and show that while they struggle to perceive\nsurgical scenes, ORQA delivers substantially stronger, consistent performance.\nRecognizing the extensive range of deployment settings across clinical\npractice, we design, and release a family of smaller ORQA models tailored to\ndifferent computational requirements. This work establishes a foundation for\nthe next wave of intelligent surgical solutions, enabling surgical teams and\nmedical technology providers to create smarter and safer operating rooms.",
    "pdf_url": "http://arxiv.org/pdf/2505.12890v2",
    "published": "2025-05-19T09:20:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01995v1",
    "title": "Integrating computational detection and experimental validation for rapid GFRAL-specific antibody discovery",
    "authors": [
      "Maria Francesca Abbate",
      "Pierre Toxe",
      "Nicolas Maestrali",
      "Marie Gagnaire",
      "Emmanuelle Vigne",
      "Melody A. Shahsavarian",
      "Thierry Mora",
      "Aleksandra M. Walczak"
    ],
    "abstract": "The identification and validation of therapeutic antibodies is critical for\ndeveloping effective treatments for many diseases. We present a computational\napproach for identifying antibodies targeting GFRAL-specific receptors,\nreceptors implicated in appetite regulation. Using humanized Trianni mice, we\nconducted a longitudinal study with repeated blood sampling and splenic\nanalysis. We applied the STAR computational method for antibody discovery on\nbulk antibody repertoire data sampled at key time points. By mapping the output\nfrom STAR to single-cell data taken at the last time point, we successfully\nidentified a pool of antibodies, of which 50% demonstrated binding\ncapabilities. We observed convergent selection, where responding sequences with\nidentical amino acid complementarity determining regions 3 (CDR3) were found in\ndifferent mice. We provide a catalog of 67 experimentally validated antibodies\nagainst GFRAL. The potential of these antibodies as antagonists or agonists\nagainst GFRAL suggests therapeutic solutions for conditions like cancer\ncachexia, anorexia, obesity, and diabetes. This study underscores the utility\nof integrating computational methods and experimental validation for antibody\ndiscovery in therapeutic contexts by reducing time and increasing efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2506.01995v1",
    "published": "2025-05-19T09:20:17+00:00",
    "categories": [
      "q-bio.TO"
    ],
    "primary_category": "q-bio.TO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12889v1",
    "title": "Basis light-front quantization approach to deuteron",
    "authors": [
      "Chandan Mondal",
      "Satvir Kaur",
      "Jiatong Wu",
      "Siqi Xu",
      "Xingbo Zhao",
      "James P. Vary"
    ],
    "abstract": "We obtain the deuteron's wave functions as eigenstates of the light-front\nquantum chromodynamics (QCD) Hamiltonian using a fully relativistic and\nnonperturbative approach based on light-front quantization, without an explicit\nconfining potential. These eigenstates include six-quark and\nsix-quark--one-gluon components. The deuteron wave function consists of both a\nsinglet-singlet color state and additional hidden color states arising from\nnon-trivial color rearrangements. Our results reveal that while the\nsinglet-singlet state is present, the hidden color states collectively\ndominate, contributing a larger probability to the deuteron wave function. This\nhighlights the significant role of hidden color components in the QCD\ndescription of nuclear structure. Using these wave functions, we investigate\nthe deuteron's electromagnetic properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.12889v1",
    "published": "2025-05-19T09:18:55+00:00",
    "categories": [
      "hep-ph",
      "hep-th",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12888v1",
    "title": "GAP: Graph-Assisted Prompts for Dialogue-based Medication Recommendation",
    "authors": [
      "Jialun Zhong",
      "Yanzeng Li",
      "Sen Hu",
      "Yang Zhang",
      "Teng Xu",
      "Lei Zou"
    ],
    "abstract": "Medication recommendations have become an important task in the healthcare\ndomain, especially in measuring the accuracy and safety of medical dialogue\nsystems (MDS). Different from the recommendation task based on electronic\nhealth records (EHRs), dialogue-based medication recommendations require\nresearch on the interaction details between patients and doctors, which is\ncrucial but may not exist in EHRs. Recent advancements in large language models\n(LLM) have extended the medical dialogue domain. These LLMs can interpret\npatients' intent and provide medical suggestions including medication\nrecommendations, but some challenges are still worth attention. During a\nmulti-turn dialogue, LLMs may ignore the fine-grained medical information or\nconnections across the dialogue turns, which is vital for providing accurate\nsuggestions. Besides, LLMs may generate non-factual responses when there is a\nlack of domain-specific knowledge, which is more risky in the medical domain.\nTo address these challenges, we propose a \\textbf{G}raph-\\textbf{A}ssisted\n\\textbf{P}rompts (\\textbf{GAP}) framework for dialogue-based medication\nrecommendation. It extracts medical concepts and corresponding states from\ndialogue to construct an explicitly patient-centric graph, which can describe\nthe neglected but important information. Further, combined with external\nmedical knowledge graphs, GAP can generate abundant queries and prompts, thus\nretrieving information from multiple sources to reduce the non-factual\nresponses. We evaluate GAP on a dialogue-based medication recommendation\ndataset and further explore its potential in a more difficult scenario,\ndynamically diagnostic interviewing. Extensive experiments demonstrate its\ncompetitive performance when compared with strong baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.12888v1",
    "published": "2025-05-19T09:18:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13559v1",
    "title": "CS-Sum: A Benchmark for Code-Switching Dialogue Summarization and the Limits of Large Language Models",
    "authors": [
      "Sathya Krishnan Suresh",
      "Tanmay Surana",
      "Lim Zhi Hao",
      "Eng Siong Chng"
    ],
    "abstract": "Code-switching (CS) poses a significant challenge for Large Language Models\n(LLMs), yet its comprehensibility remains underexplored in LLMs. We introduce\nCS-Sum, to evaluate the comprehensibility of CS by the LLMs through CS dialogue\nto English summarization. CS-Sum is the first benchmark for CS dialogue\nsummarization across Mandarin-English (EN-ZH), Tamil-English (EN-TA), and\nMalay-English (EN-MS), with 900-1300 human-annotated dialogues per language\npair. Evaluating ten LLMs, including open and closed-source models, we analyze\nperformance across few-shot, translate-summarize, and fine-tuning (LoRA, QLoRA\non synthetic data) approaches. Our findings show that though the scores on\nautomated metrics are high, LLMs make subtle mistakes that alter the complete\nmeaning of the dialogue. To this end, we introduce 3 most common type of errors\nthat LLMs make when handling CS input. Error rates vary across CS pairs and\nLLMs, with some LLMs showing more frequent errors on certain language pairs,\nunderscoring the need for specialized training on code-switched data.",
    "pdf_url": "http://arxiv.org/pdf/2505.13559v1",
    "published": "2025-05-19T09:18:14+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12887v3",
    "title": "RetinaLogos: Fine-Grained Synthesis of High-Resolution Retinal Images Through Captions",
    "authors": [
      "Junzhi Ning",
      "Cheng Tang",
      "Kaijing Zhou",
      "Diping Song",
      "Lihao Liu",
      "Ming Hu",
      "Wei Li",
      "Huihui Xu",
      "Yanzhou Su",
      "Tianbin Li",
      "Jiyao Liu",
      "Jin Ye",
      "Sheng Zhang",
      "Yuanfeng Ji",
      "Junjun He"
    ],
    "abstract": "The scarcity of high-quality, labelled retinal imaging data, which presents a\nsignificant challenge in the development of machine learning models for\nophthalmology, hinders progress in the field. Existing methods for synthesising\nColour Fundus Photographs (CFPs) largely rely on predefined disease labels,\nwhich restricts their ability to generate images that reflect fine-grained\nanatomical variations, subtle disease stages, and diverse pathological features\nbeyond coarse class categories. To overcome these challenges, we first\nintroduce an innovative pipeline that creates a large-scale, captioned retinal\ndataset comprising 1.4 million entries, called RetinaLogos-1400k. Specifically,\nRetinaLogos-1400k uses the visual language model(VLM) to describe retinal\nconditions and key structures, such as optic disc configuration, vascular\ndistribution, nerve fibre layers, and pathological features. Building on this\ndataset, we employ a novel three-step training framework, RetinaLogos, which\nenables fine-grained semantic control over retinal images and accurately\ncaptures different stages of disease progression, subtle anatomical variations,\nand specific lesion types. Through extensive experiments, our method\ndemonstrates superior performance across multiple datasets, with 62.07% of\ntext-driven synthetic CFPs indistinguishable from real ones by\nophthalmologists. Moreover, the synthetic data improves accuracy by 5%-10% in\ndiabetic retinopathy grading and glaucoma detection. Codes are available at\nhttps://github.com/uni-medical/retina-text2cfp.",
    "pdf_url": "http://arxiv.org/pdf/2505.12887v3",
    "published": "2025-05-19T09:18:11+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12886v1",
    "title": "Detection and Mitigation of Hallucination in Large Reasoning Models: A Mechanistic Perspective",
    "authors": [
      "Zhongxiang Sun",
      "Qipeng Wang",
      "Haoyu Wang",
      "Xiao Zhang",
      "Jun Xu"
    ],
    "abstract": "Large Reasoning Models (LRMs) have shown impressive capabilities in\nmulti-step reasoning tasks. However, alongside these successes, a more\ndeceptive form of model error has emerged--Reasoning Hallucination--where\nlogically coherent but factually incorrect reasoning traces lead to persuasive\nyet faulty conclusions. Unlike traditional hallucinations, these errors are\nembedded within structured reasoning, making them more difficult to detect and\npotentially more harmful. In this work, we investigate reasoning hallucinations\nfrom a mechanistic perspective. We propose the Reasoning Score, which\nquantifies the depth of reasoning by measuring the divergence between logits\nobtained from projecting late layers of LRMs to the vocabulary space,\neffectively distinguishing shallow pattern-matching from genuine deep\nreasoning. Using this score, we conduct an in-depth analysis on the ReTruthQA\ndataset and identify two key reasoning hallucination patterns: early-stage\nfluctuation in reasoning depth and incorrect backtracking to flawed prior\nsteps. These insights motivate our Reasoning Hallucination Detection (RHD)\nframework, which achieves state-of-the-art performance across multiple domains.\nTo mitigate reasoning hallucinations, we further introduce GRPO-R, an enhanced\nreinforcement learning algorithm that incorporates step-level deep reasoning\nrewards via potential-based shaping. Our theoretical analysis establishes\nstronger generalization guarantees, and experiments demonstrate improved\nreasoning quality and reduced hallucination rates.",
    "pdf_url": "http://arxiv.org/pdf/2505.12886v1",
    "published": "2025-05-19T09:16:40+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.15847v1",
    "title": "Graph Neural Networks Based Anomalous RSSI Detection",
    "authors": [
      "Bla≈æ Bertalaniƒç",
      "Matej Vnuƒçec",
      "Carolina Fortuna"
    ],
    "abstract": "In today's world, modern infrastructures are being equipped with information\nand communication technologies to create large IoT networks.\n  It is essential to monitor these networks to ensure smooth operations by\ndetecting and correcting link failures or abnormal network behaviour\nproactively, which can otherwise cause interruptions in business operations.\n  This paper presents a novel method for detecting anomalies in wireless links\nusing graph neural networks. The proposed approach involves converting time\nseries data into graphs and training a new graph neural network architecture\nbased on graph attention networks that successfully detects anomalies at the\nlevel of individual measurements of the time series data. The model provides\ncompetitive results compared to the state of the art while being\ncomputationally more efficient with ~171 times fewer trainable parameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.15847v1",
    "published": "2025-05-19T09:16:32+00:00",
    "categories": [
      "cs.NI",
      "cs.LG"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12885v1",
    "title": "Effects of the Auto-Correlation of Delays on the Age of Information: A Gaussian Process Framework",
    "authors": [
      "Atsushi Inoie",
      "Yoshiaki Inoue"
    ],
    "abstract": "The age of information (AoI) has been studied actively in recent years as a\nperformance measure for systems that require real-time performance, such as\nremote monitoring systems via communication networks. The theoretical analysis\nof the AoI is usually formulated based on explicit system modeling, such as a\nsingle-server queueing model. However, in general, the behavior of large-scale\nsystems such as communication networks is complex, and it is usually difficult\nto express the delay using simple queueing models. In this paper, we consider a\nframework in which the sequence of delays is composed from a non-negative\ncontinuous-time stochastic process, called a virtual delay process, as a new\nmodeling approach for the theoretical analysis of the AoI. Under such a\nframework, we derive an expression for the transient probability distribution\nof the AoI and further apply the theory of stochastic orders to prove that the\nhigh dependence of the sequence of delays leads to the degradation of AoI\nperformance. We further consider a special case in which the sequence of delays\nis generated from a stationary Gaussian process, and we discuss the sensitivity\nof the AoI to second-order statistics of the delay process through numerical\nexperiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12885v1",
    "published": "2025-05-19T09:15:48+00:00",
    "categories": [
      "cs.PF"
    ],
    "primary_category": "cs.PF"
  },
  {
    "id": "http://arxiv.org/abs/2505.21510v1",
    "title": "Complexity counts: global and local perspectives on Indo-Aryan numeral systems",
    "authors": [
      "Chundra Cathcart"
    ],
    "abstract": "The numeral systems of Indo-Aryan languages such as Hindi, Gujarati, and\nBengali are highly unusual in that unlike most numeral systems (e.g., those of\nEnglish, Chinese, etc.), forms referring to 1--99 are highly non-transparent\nand are cannot be constructed using straightforward rules. As an example,\nHindi/Urdu *iky\\=anve* `91' is not decomposable into the composite elements\n*ek* `one' and *nave* `ninety' in the way that its English counterpart is. This\npaper situates Indo-Aryan languages within the typology of cross-linguistic\nnumeral systems, and explores the linguistic and non-linguistic factors that\nmay be responsible for the persistence of complex systems in these languages.\nUsing cross-linguistic data from multiple databases, we develop and employ a\nnumber of cross-linguistically applicable metrics to quantifies the complexity\nof languages' numeral systems, and demonstrate that Indo-Aryan languages have\ndecisively more complex numeral systems than the world's languages as a whole,\nthough individual Indo-Aryan languages differ from each other in terms of the\ncomplexity of the patterns they display. We investigate the factors (e.g.,\nreligion, geographic isolation, etc.) that underlie complexity in numeral\nsystems, with a focus on South Asia, in an attempt to develop an account of why\ncomplex numeral systems developed and persisted in certain Indo-Aryan languages\nbut not elsewhere. Finally, we demonstrate that Indo-Aryan numeral systems\nadhere to certain general pressures toward efficient communication found\ncross-linguistically, despite their high complexity. We call for this somewhat\noverlooked dimension of complexity to be taken seriously when discussing\ngeneral variation in cross-linguistic numeral systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.21510v1",
    "published": "2025-05-19T09:14:54+00:00",
    "categories": [
      "physics.soc-ph",
      "cs.CL"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12884v2",
    "title": "TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks",
    "authors": [
      "Yuanze Hu",
      "Zhaoxin Fan",
      "Xinyu Wang",
      "Gen Li",
      "Ye Qiu",
      "Zhichao Yang",
      "Wenjun Wu",
      "Kejian Wu",
      "Yifan Sun",
      "Xiaotie Deng",
      "Jin Dong"
    ],
    "abstract": "Lightweight Vision-Language Models (VLMs) are indispensable for\nresource-constrained applications. The prevailing approach to aligning vision\nand language models involves freezing both the vision encoder and the language\nmodel while training small connector modules. However, this strategy heavily\ndepends on the intrinsic capabilities of the language model, which can be\nsuboptimal for lightweight models with limited representational capacity. In\nthis work, we investigate this alignment bottleneck through the lens of mutual\ninformation, demonstrating that the constrained capacity of the language model\ninherently limits the Effective Mutual Information (EMI) between multimodal\ninputs and outputs, thereby compromising alignment quality. To address this\nchallenge, we propose TinyAlign, a novel framework inspired by\nRetrieval-Augmented Generation, which strategically retrieves relevant context\nfrom a memory bank to enrich multimodal inputs and enhance their alignment.\nExtensive empirical evaluations reveal that TinyAlign significantly reduces\ntraining loss, accelerates convergence, and enhances task performance.\nRemarkably, it allows models to achieve baseline-level performance with only\n40\\% of the fine-tuning data, highlighting exceptional data efficiency. Our\nwork thus offers a practical pathway for developing more capable lightweight\nVLMs while introducing a fresh theoretical lens to better understand and\naddress alignment bottlenecks in constrained multimodal systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12884v2",
    "published": "2025-05-19T09:11:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12883v1",
    "title": "Implicit numerical approximation for stochastic delay differential equations with the nonlinear diffusion term in the infinite horizon",
    "authors": [
      "Yudong Wang",
      "Hongjiong Tian"
    ],
    "abstract": "This paper investigates the approximation of stochastic delay differential\nequations (SDDEs) via the backward Euler-Maruyama (BEM) method under\ngeneralized monotonicity and Khasminskii-type conditions in the infinite\nhorizon. First, by establishing the uniform moment boundedness and finite-time\nstrong convergence of the BEM method, we prove that for sufficiently small step\nsizes, the numerical approximations strongly converge to the underlying\nsolution in the infinite horizon with a rate of $1/2$, which coincides with the\noptimal finite-time strong convergence rate.\n  Next, we establish the uniform boundedness and convergence in probability for\nthe segment processes associated with the BEM method. This analysis further\ndemonstrates that the probability measures of the numerical segment processes\nconverge to the underlying invariant measure of the SDDEs. Finally, a numerical\nexample and simulations are provided to illustrate the theoretical results.",
    "pdf_url": "http://arxiv.org/pdf/2505.12883v1",
    "published": "2025-05-19T09:11:44+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.PR",
      "60H35, 65C30, 65L20,",
      "G.1.7; G.3"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12882v1",
    "title": "PhyDA: Physics-Guided Diffusion Models for Data Assimilation in Atmospheric Systems",
    "authors": [
      "Hao Wang",
      "Jindong Han",
      "Wei Fan",
      "Weijia Zhang",
      "Hao Liu"
    ],
    "abstract": "Data Assimilation (DA) plays a critical role in atmospheric science by\nreconstructing spatially continous estimates of the system state, which serves\nas initial conditions for scientific analysis. While recent advances in\ndiffusion models have shown great potential for DA tasks, most existing\napproaches remain purely data-driven and often overlook the physical laws that\ngovern complex atmospheric dynamics. As a result, they may yield physically\ninconsistent reconstructions that impair downstream applications. To overcome\nthis limitation, we propose PhyDA, a physics-guided diffusion framework\ndesigned to ensure physical coherence in atmospheric data assimilation. PhyDA\nintroduces two key components: (1) a Physically Regularized Diffusion Objective\nthat integrates physical constraints into the training process by penalizing\ndeviations from known physical laws expressed as partial differential\nequations, and (2) a Virtual Reconstruction Encoder that bridges observational\nsparsity for structured latent representations, further enhancing the model's\nability to infer complete and physically coherent states. Experiments on the\nERA5 reanalysis dataset demonstrate that PhyDA achieves superior accuracy and\nbetter physical plausibility compared to state-of-the-art baselines. Our\nresults emphasize the importance of combining generative modeling with\ndomain-specific physical knowledge and show that PhyDA offers a promising\ndirection for improving real-world data assimilation systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12882v1",
    "published": "2025-05-19T09:10:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.06300v3",
    "title": "LT-PINN: Lagrangian Topology-conscious Physics-informed Neural Network for Boundary-focused Engineering Optimization",
    "authors": [
      "Yuanye Zhou",
      "Zhaokun Wang",
      "Kai Zhou",
      "Hui Tang",
      "Xiaofan Li"
    ],
    "abstract": "Physics-informed neural networks (PINNs) have emerged as a powerful meshless\ntool for topology optimization, capable of simultaneously determining optimal\ntopologies and physical solutions. However, conventional PINNs rely on\ndensity-based topology descriptions, which necessitate manual interpolation and\nlimit their applicability to complex geometries. To address this, we propose\nLagrangian topology-conscious PINNs (LT-PINNs), a novel framework for\nboundary-focused engineering optimization. By parameterizing the control\nvariables of topology boundary curves as learnable parameters, LT-PINNs\neliminate the need for manual interpolation and enable precise boundary\ndetermination. We further introduce specialized boundary condition loss\nfunction and topology loss function to ensure sharp and accurate boundary\nrepresentations, even for intricate topologies. The accuracy and robustness of\nLT-PINNs are validated via two types of partial differential equations (PDEs),\nincluding elastic equation with Dirichlet boundary conditions and Laplace's\nequation with Neumann boundary conditions. Furthermore, we demonstrate\neffectiveness of LT-PINNs on more complex time-dependent and time-independent\nflow problems without relying on measurement data, and showcase their\nengineering application potential in flow velocity rearrangement, transforming\na uniform upstream velocity into a sine-shaped downstream profile. The results\ndemonstrate (1) LT-PINNs achieve substantial reductions in relative L2 errors\ncompared with the state-of-art density topology-oriented PINNs (DT-PINNs), (2)\nLT-PINNs can handle arbitrary boundary conditions, making them suitable for a\nwide range of PDEs, and (3) LT-PINNs can infer clear topology boundaries\nwithout manual interpolation, especially for complex topologies.",
    "pdf_url": "http://arxiv.org/pdf/2506.06300v3",
    "published": "2025-05-19T09:10:31+00:00",
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12881v1",
    "title": "WHALES: an optimized retracker for satellite radar altimeter waveforms in sea state applications",
    "authors": [
      "Marcello Passaro",
      "Guillaume Dodet",
      "Fabrice Ardhuin",
      "Paolo Cipollini"
    ],
    "abstract": "The latest version of the European Space Agency's Sea State Climate Change\nInitiative database adopts a dedicated algorithm (retracker) to reprocess two\ndecades of satellite altimetry measurements and provide long time series of\nsignificant wave height in the global ocean. This paper describes the main\ncharacteristics of this algorithm, called WHALES, and analyzes the impact of\nalgorithm choices on measurement physics, particularly the weighted analysis of\nresiduals in the cost function. Moreover, the impact of WHALES on the sea state\ndatabase is analyzed in terms of noise reduction and scatter index with in situ\ndata, with a particular focus on the coastal zone, where WHALES primarily\nimproves data quality and quantity compared to previous approaches. We found\nthat valid data records increased by 30% at 5 km from the coast after applying\nthe retracker discussed here.",
    "pdf_url": "http://arxiv.org/pdf/2505.12881v1",
    "published": "2025-05-19T09:09:39+00:00",
    "categories": [
      "physics.ao-ph",
      "physics.data-an",
      "physics.geo-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12880v1",
    "title": "AdS-GNN -- a Conformally Equivariant Graph Neural Network",
    "authors": [
      "Maksim Zhdanov",
      "Nabil Iqbal",
      "Erik Bekkers",
      "Patrick Forr√©"
    ],
    "abstract": "Conformal symmetries, i.e.\\ coordinate transformations that preserve angles,\nplay a key role in many fields, including physics, mathematics, computer vision\nand (geometric) machine learning. Here we build a neural network that is\nequivariant under general conformal transformations. To achieve this, we lift\ndata from flat Euclidean space to Anti de Sitter (AdS) space. This allows us to\nexploit a known correspondence between conformal transformations of flat space\nand isometric transformations on the AdS space. We then build upon the fact\nthat such isometric transformations have been extensively studied on general\ngeometries in the geometric deep learning literature. We employ message-passing\nlayers conditioned on the proper distance, yielding a computationally efficient\nframework. We validate our model on tasks from computer vision and statistical\nphysics, demonstrating strong performance, improved generalization capacities,\nand the ability to extract conformal data such as scaling dimensions from the\ntrained network.",
    "pdf_url": "http://arxiv.org/pdf/2505.12880v1",
    "published": "2025-05-19T09:08:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "hep-th"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12879v2",
    "title": "Spline Dimensional Decomposition with Interpolation-based Optimal Knot Selection for Stochastic Dynamic Analysis",
    "authors": [
      "Yeonsu Kim",
      "Junhan Lee",
      "Bingran Wang",
      "John T. Hwang",
      "Dongjin Lee"
    ],
    "abstract": "Forward uncertainty quantification in dynamical systems is challenging due to\nnon-smooth or locally oscillating nonlinear behaviors. Spline dimensional\ndecomposition (SDD) addresses such nonlinearity by partitioning input\ncoordinates via knot placement, but its accuracy is highly sensitive to\ninternal knot locations. Optimizing knots using sequential quadratic\nprogramming is effective, yet computationally expensive. We propose a\ncomputationally efficient, interpolation-based method for optimal knot\nselection in SDD. The method includes: (1) interpolating input-output profiles,\n(2) defining subinterval-based reference regions, and (3) selecting knots at\nmaximum gradient points within each region. The resulting knot vector is then\napplied to SDD for accurate approximation of non-smooth and oscillatory\nresponses. A modal analysis of a lower control arm shows that SDD with the\nproposed knots yields higher accuracy than SDD with uniformly or randomly\nspaced knots and a Gaussian process model. In this example, the proposed SDD\nachieves the lowest relative variance error (2.89%) for the first natural\nfrequency distribution, compared to uniformly spaced knots (12.310%), randomly\nspaced knots (15.274%), and Gaussian process (5.319%). All surrogates are\nconstructed using the same 401 simulation datasets, and errors are evaluated\nagainst a 2000-sample Monte Carlo simulation. Scalability and applicability are\ndemonstrated through stochastic and reliability analyses of one- and\nthree-dimensional benchmark functions, and a ten-dimensional lower control arm\nmodel. Results confirm that second-moment statistics and reliability estimates\ncan be accurately obtained with only a few hundred function evaluations or\nfinite element simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.12879v2",
    "published": "2025-05-19T09:08:39+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.13558v1",
    "title": "CATS: Clustering-Aggregated and Time Series for Business Customer Purchase Intention Prediction",
    "authors": [
      "Yingjie Kuang",
      "Tianchen Zhang",
      "Zhen-Wei Huang",
      "Zhongjie Zeng",
      "Zhe-Yuan Li",
      "Ling Huang",
      "Yuefang Gao"
    ],
    "abstract": "Accurately predicting customers' purchase intentions is critical to the\nsuccess of a business strategy. Current researches mainly focus on analyzing\nthe specific types of products that customers are likely to purchase in the\nfuture, little attention has been paid to the critical factor of whether\ncustomers will engage in repurchase behavior. Predicting whether a customer\nwill make the next purchase is a classic time series forecasting task. However,\nin real-world purchasing behavior, customer groups typically exhibit imbalance\n- i.e., there are a large number of occasional buyers and a small number of\nloyal customers. This head-to-tail distribution makes traditional time series\nforecasting methods face certain limitations when dealing with such problems.\nTo address the above challenges, this paper proposes a unified Clustering and\nAttention mechanism GRU model (CAGRU) that leverages multi-modal data for\ncustomer purchase intention prediction. The framework first performs customer\nprofiling with respect to the customer characteristics and clusters the\ncustomers to delineate the different customer clusters that contain similar\nfeatures. Then, the time series features of different customer clusters are\nextracted by GRU neural network and an attention mechanism is introduced to\ncapture the significance of sequence locations. Furthermore, to mitigate the\nhead-to-tail distribution of customer segments, we train the model separately\nfor each customer segment, to adapt and capture more accurately the differences\nin behavioral characteristics between different customer segments, as well as\nthe similar characteristics of the customers within the same customer segment.\nWe constructed four datasets and conducted extensive experiments to demonstrate\nthe superiority of the proposed CAGRU approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.13558v1",
    "published": "2025-05-19T09:07:34+00:00",
    "categories": [
      "econ.EM",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2505.12878v2",
    "title": "QCP: A Practical Separation Logic-based C Program Verification Tool",
    "authors": [
      "Xiwei Wu",
      "Yueyang Feng",
      "Xiaoyang Lu",
      "Tianchuan Lin",
      "Kan Liu",
      "Zhiyi Wang",
      "Shushu Wu",
      "Lihan Xie",
      "Chengxi Yang",
      "Hongyi Zhong",
      "Naijun Zhan",
      "Zhenjiang Hu",
      "Qinxiang Cao"
    ],
    "abstract": "As software systems increase in size and complexity dramatically, ensuring\ntheir correctness, security, and reliability becomes an increasingly formidable\nchallenge. Despite significant advancements in verification techniques and\ntools, there still remain %these tools still continue to encounter substantial\ndifficulties when applying these tools to complex, real-world scenarios. To\naddress these difficulties, this paper introduces a novel verification tool,\ncalled \\textbf{Qualified C Programming Verifier (QCP)}. QCP incorporates a\nrefined front-end %syntax of assertion language to enhance user interaction.\nThe proposed assertion language aims to %syntax is designed to lower the entry\nbarrier for verification tools, improve proof efficiency by improving\nautomation, and facilitate a deeper understanding of both the program and its\nverification results.",
    "pdf_url": "http://arxiv.org/pdf/2505.12878v2",
    "published": "2025-05-19T09:04:34+00:00",
    "categories": [
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12877v1",
    "title": "Exceptional extensions of local fields and the Carlitz--Wan conjecture",
    "authors": [
      "Zhiguo Ding",
      "Wei Xiong",
      "Qifan Zhang"
    ],
    "abstract": "For any prime power $q$, a polynomial $f(X)\\in\\F_q[X]$ is ``exceptional'' if\nit induces bijections of $\\F_{q^k}$ for infinitely many $k$; this condition is\nknown to be equivalent to $f(X)$ inducing a bijection of $\\F_{q^k}$ for at\nleast one $k$ with $q^k\\ge \\deg(f)^4$. In this paper, we introduce the notion\nof an ``exceptional'' extension of local fields of any characteristic, and show\nthat if $f(X)\\in\\F_q[X]$ is exceptional in the classical sense then the field\nextension $\\F_q(X)/\\F_q(f(X))$ yields an exceptional local field extension upon\npassing to the completion at a degree-$1$ place. We describe all exceptional\nlocal field extensions of degree coprime to the residue characteristic,\ndetermine the relationship between exceptionality of a local field extension\nand exceptionality of a subextension, and give various Galois-theoretic\ncharacterizations of exceptional local field extensions. As a consequence, we\nobtain three new proofs, using quite different tools, of a theorem of Guralnick\nand M\\\"uller about ramification indices in exceptional maps between curves over\n$\\F_q$. This theorem generalizes a result of Lenstra which subsumes earlier\nconjectures of Carlitz and Wan.",
    "pdf_url": "http://arxiv.org/pdf/2505.12877v1",
    "published": "2025-05-19T09:02:06+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12876v2",
    "title": "What Price Fiber Bundle Substantivalism? On How to Avoid Holes in Fibers",
    "authors": [
      "Philipp Berghofer",
      "Jordan Fran√ßois",
      "Lucrezia Ravera"
    ],
    "abstract": "On a mathematically foundational level, our most successful physical theories\n(gauge field theories and general-relativistic theories) are formulated in a\nframework based on the differential geometry of connections on principal\nbundles. After reviewing the essentials of this framework, we articulate the\ngeneralized hole and point-coincidence arguments, examining how they weight on\na substantivalist position towards bundle spaces. This question, then, is\nconsidered in light of the Dressing Field Method, which allows a manifestly\ninvariant reformulation of gauge field theories and general-relativistic\ntheories, making their conceptual structure more transparent: it formally\nimplements the point-coincidence argument and thus allows to define (dressed)\nfields and (dressed) bundle spaces immune to hole-type arguments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12876v2",
    "published": "2025-05-19T09:01:30+00:00",
    "categories": [
      "physics.hist-ph",
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "physics.hist-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12875v1",
    "title": "3D Gaussian Adaptive Reconstruction for Fourier Light-Field Microscopy",
    "authors": [
      "Chenyu Xu",
      "Zhouyu Jin",
      "Chengkang Shen",
      "Hao Zhu",
      "Zhan Ma",
      "Bo Xiong",
      "You Zhou",
      "Xun Cao",
      "Ning Gu"
    ],
    "abstract": "Compared to light-field microscopy (LFM), which enables high-speed volumetric\nimaging but suffers from non-uniform spatial sampling, Fourier light-field\nmicroscopy (FLFM) introduces sub-aperture division at the pupil plane, thereby\nensuring spatially invariant sampling and enhancing spatial resolution.\nConventional FLFM reconstruction methods, such as Richardson-Lucy (RL)\ndeconvolution, exhibit poor axial resolution and signal degradation due to the\nill-posed nature of the inverse problem. While data-driven approaches enhance\nspatial resolution by leveraging high-quality paired datasets or imposing\nstructural priors, Neural Radiance Fields (NeRF)-based methods employ\nphysics-informed self-supervised learning to overcome these limitations, yet\nthey are hindered by substantial computational costs and memory demands.\nTherefore, we propose 3D Gaussian Adaptive Tomography (3DGAT) for FLFM, a 3D\ngaussian splatting based self-supervised learning framework that significantly\nimproves the volumetric reconstruction quality of FLFM while maintaining\ncomputational efficiency. Experimental results indicate that our approach\nachieves higher resolution and improved reconstruction accuracy, highlighting\nits potential to advance FLFM imaging and broaden its applications in 3D\noptical microscopy.",
    "pdf_url": "http://arxiv.org/pdf/2505.12875v1",
    "published": "2025-05-19T08:59:14+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13557v1",
    "title": "AMAQA: A Metadata-based QA Dataset for RAG Systems",
    "authors": [
      "Davide Bruni",
      "Marco Avvenuti",
      "Nicola Tonellotto",
      "Maurizio Tesconi"
    ],
    "abstract": "Retrieval-augmented generation (RAG) systems are widely used in\nquestion-answering (QA) tasks, but current benchmarks lack metadata\nintegration, hindering evaluation in scenarios requiring both textual data and\nexternal information. To address this, we present AMAQA, a new open-access QA\ndataset designed to evaluate tasks combining text and metadata. The integration\nof metadata is especially important in fields that require rapid analysis of\nlarge volumes of data, such as cybersecurity and intelligence, where timely\naccess to relevant information is critical. AMAQA includes about 1.1 million\nEnglish messages collected from 26 public Telegram groups, enriched with\nmetadata such as timestamps, topics, emotional tones, and toxicity indicators,\nwhich enable precise and contextualized queries by filtering documents based on\nspecific criteria. It also includes 450 high-quality QA pairs, making it a\nvaluable resource for advancing research on metadata-driven QA and RAG systems.\nTo the best of our knowledge, AMAQA is the first single-hop QA benchmark to\nincorporate metadata and labels such as topics covered in the messages. We\nconduct extensive tests on the benchmark, establishing a new standard for\nfuture research. We show that leveraging metadata boosts accuracy from 0.12 to\n0.61, highlighting the value of structured context. Building on this, we\nexplore several strategies to refine the LLM input by iterating over provided\ncontext and enriching it with noisy documents, achieving a further 3-point gain\nover the best baseline and a 14-point improvement over simple metadata\nfiltering. The dataset is available at\nhttps://anonymous.4open.science/r/AMAQA-5D0D/",
    "pdf_url": "http://arxiv.org/pdf/2505.13557v1",
    "published": "2025-05-19T08:59:08+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12874v2",
    "title": "Optimization of 3D diamond detectors with graphitized electrodes based on an innovative numerical simulation",
    "authors": [
      "Lucio Anderlini",
      "Alessandro Bombini",
      "Clarissa Buti",
      "Djunes Janssens",
      "Stefano Lagomarsino",
      "Giovanni Passaleva",
      "Michele Veltri"
    ],
    "abstract": "Future experiments at hadron colliders require an evolution of the tracking\nsensors to ensure sufficient radiation hardness as well as space and time\nresolution to handle unprecedented particle fluxes. 3D diamond sensors with\nlaser-graphitized electrodes are promising candidates due to their strong\nbinding energy, small atomic number, and high carrier mobility. However, the\nhigh resistance of the engraved electrodes delays the propagation of the\ninduced signals towards the readout electronics, thereby degrading the\nprecision of the timing measurements. So far, this effect has been the dominant\nfactor limiting the time resolution of these devices, with other contributions,\nsuch as those due to electric field inhomogeneities or electronic noise,\ntypically neglected. Recent advancements in graphitization technology, however,\nmotivate a renewed effort in modeling signal generation in 3D diamond\ndetectors, to achieve more reliable predictions. To this purpose, we apply an\nextended version of the Ramo-Shockley theorem describing the effect of signal\npropagation as a time-dependent weighting potential, obtained by solving\nnumerically the Maxwell's equations in a quasi-static approximation. We\ndeveloped a custom spectral method solver and validated it against COMSOL\nMultiPhysics. The response of the modeled sensor to a beam of particles is then\nsimulated using Garfield++ and is compared to the data acquired in a beam test\ncarried on in 2021 by the TimeSPOT Collaboration at the SPS, at CERN. Based on\nthe results obtained with this simulation workflow, we conclude that reducing\nthe resistivity of the graphitic columns remains the priority for significantly\nimproving the time resolution of 3D diamond detectors. Once achieved,\noptimization of the detector geometry and readout electronics design will\nbecome equally important steps to further enhance the timing performance of\nthese devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.12874v2",
    "published": "2025-05-19T08:58:39+00:00",
    "categories": [
      "physics.ins-det"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.12873v1",
    "title": "Quantum Algorithms for Causal Estimands",
    "authors": [
      "Rishi Goel",
      "Casey R. Myers",
      "Sally Shrapnel"
    ],
    "abstract": "Modern machine learning methods typically fail to adequately capture causal\ninformation. Consequently, such models do not handle data distributional\nshifts, are vulnerable to adversarial examples, and often learn spurious\ncorrelations. Causal machine learning, or causal inference, aims to solve these\nissues by estimating the expected outcome of counterfactual events, using\nobservational and/or interventional data, where causal relationships are\ntypically depicted as directed acyclic graphs. It is an open question as to\nwhether these causal algorithms provide opportunities for quantum enhancement.\nIn this paper we consider a recently developed family of non-parametric,\ncontinuous causal estimators and derive quantum algorithms for these tasks.\nKernel evaluation and large matrix inversion are critical sub-routines of these\nclassical algorithms, which makes them particularly amenable to a quantum\ntreatment. Unlike other quantum machine learning algorithms, closed form\nsolutions for the estimators exist, negating the need for gradient evaluation\nand variational learning. We describe several new hybrid quantum-classical\nalgorithms and show that uniform consistency of the estimators is retained.\nFurthermore, if one is satisfied with a quantum state output that is\nproportional to the true causal estimand, then these algorithms inherit the\nexponential complexity advantages given by quantum linear system solvers.",
    "pdf_url": "http://arxiv.org/pdf/2505.12873v1",
    "published": "2025-05-19T08:58:09+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12872v1",
    "title": "From Grunts to Grammar: Emergent Language from Cooperative Foraging",
    "authors": [
      "Maytus Piriyajitakonkij",
      "Rujikorn Charakorn",
      "Weicheng Tao",
      "Wei Pan",
      "Mingfei Sun",
      "Cheston Tan",
      "Mengmi Zhang"
    ],
    "abstract": "Early cavemen relied on gestures, vocalizations, and simple signals to\ncoordinate, plan, avoid predators, and share resources. Today, humans\ncollaborate using complex languages to achieve remarkable results. What drives\nthis evolution in communication? How does language emerge, adapt, and become\nvital for teamwork? Understanding the origins of language remains a challenge.\nA leading hypothesis in linguistics and anthropology posits that language\nevolved to meet the ecological and social demands of early human cooperation.\nLanguage did not arise in isolation, but through shared survival goals.\nInspired by this view, we investigate the emergence of language in multi-agent\nForaging Games. These environments are designed to reflect the cognitive and\necological constraints believed to have influenced the evolution of\ncommunication. Agents operate in a shared grid world with only partial\nknowledge about other agents and the environment, and must coordinate to\ncomplete games like picking up high-value targets or executing temporally\nordered actions. Using end-to-end deep reinforcement learning, agents learn\nboth actions and communication strategies from scratch. We find that agents\ndevelop communication protocols with hallmark features of natural language:\narbitrariness, interchangeability, displacement, cultural transmission, and\ncompositionality. We quantify each property and analyze how different factors,\nsuch as population size and temporal dependencies, shape specific aspects of\nthe emergent language. Our framework serves as a platform for studying how\nlanguage can evolve from partial observability, temporal reasoning, and\ncooperative goals in embodied multi-agent settings. We will release all data,\ncode, and models publicly.",
    "pdf_url": "http://arxiv.org/pdf/2505.12872v1",
    "published": "2025-05-19T08:57:30+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12871v1",
    "title": "Does Low Rank Adaptation Lead to Lower Robustness against Training-Time Attacks?",
    "authors": [
      "Zi Liang",
      "Haibo Hu",
      "Qingqing Ye",
      "Yaxin Xiao",
      "Ronghua Li"
    ],
    "abstract": "Low rank adaptation (LoRA) has emerged as a prominent technique for\nfine-tuning large language models (LLMs) thanks to its superb efficiency gains\nover previous methods. While extensive studies have examined the performance\nand structural properties of LoRA, its behavior upon training-time attacks\nremain underexplored, posing significant security risks. In this paper, we\ntheoretically investigate the security implications of LoRA's low-rank\nstructure during fine-tuning, in the context of its robustness against data\npoisoning and backdoor attacks. We propose an analytical framework that models\nLoRA's training dynamics, employs the neural tangent kernel to simplify the\nanalysis of the training process, and applies information theory to establish\nconnections between LoRA's low rank structure and its vulnerability against\ntraining-time attacks. Our analysis indicates that LoRA exhibits better\nrobustness to backdoor attacks than full fine-tuning, while becomes more\nvulnerable to untargeted data poisoning due to its over-simplified information\ngeometry. Extensive experimental evaluations have corroborated our theoretical\nfindings.",
    "pdf_url": "http://arxiv.org/pdf/2505.12871v1",
    "published": "2025-05-19T08:57:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12870v1",
    "title": "Solar-cycle Variability of Composite Geometry in the Solar Wind Turbulence",
    "authors": [
      "Zhan Fa",
      "H. -Q. He"
    ],
    "abstract": "The composite geometry and spectral anisotropy of the solar wind turbulence\nare very important topics in the investigations of solar wind. In this work, we\nuse the magnetic field and plasma data from Wind spacecraft measured during\n1995 January to 2023 December, which covers more than two solar cycles, to\nsystematically investigate these subjects in the context of solar-cycle\nvariability. The so-called spectrum ratio test and spectrum anisotropy test are\nemployed to determine the three-dimensional (3D) geometry of the solar wind\nturbulence. Both the tests reveal that the solar wind turbulence is dominated\nby the two-dimensional (2D) component (~80% by turbulence energy). More\ninterestingly, we find that the fraction of slab turbulence increases with the\nrising sunspot number, and the correlation coefficient between the slab\nfraction and the sunspot number is 0.61 (ratio test result) or 0.65 (anisotropy\ntest result). This phenomenon suggests that the increasing solar activity\n(signified by sunspot number) causes increasing slab component in the solar\nwind turbulence. The relationship between spectral anisotropy and solar\nactivity is discussed and explained. The enhancement of slab fraction is\nassociated with the intensified interplanetary magnetic field magnitude and the\nincreased Alfven speed during the rise phases of the solar cycles. Our findings\nwill be very helpful for achieving a better understanding of the 3D composite\ngeometry and spectral anisotropy of the solar wind turbulence, and especially\nof their solar-cycle variability.",
    "pdf_url": "http://arxiv.org/pdf/2505.12870v1",
    "published": "2025-05-19T08:56:00+00:00",
    "categories": [
      "physics.space-ph",
      "astro-ph.SR",
      "physics.plasm-ph"
    ],
    "primary_category": "physics.space-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12869v1",
    "title": "Outsourced Privacy-Preserving Feature Selection Based on Fully Homomorphic Encryption",
    "authors": [
      "Koki Wakiyama",
      "Tomohiro I",
      "Hiroshi Sakamoto"
    ],
    "abstract": "Feature selection is a technique that extracts a meaningful subset from a set\nof features in training data. When the training data is large-scale,\nappropriate feature selection enables the removal of redundant features, which\ncan improve generalization performance, accelerate the training process, and\nenhance the interpretability of the model. This study proposes a\nprivacy-preserving computation model for feature selection. Generally, when the\ndata owner and analyst are the same, there is no need to conceal the private\ninformation. However, when they are different parties or when multiple owners\nexist, an appropriate privacy-preserving framework is required. Although\nvarious private feature selection algorithms, they all require two or more\ncomputing parties and do not guarantee security in environments where no\nexternal party can be fully trusted. To address this issue, we propose the\nfirst outsourcing algorithm for feature selection using fully homomorphic\nencryption. Compared to a prior two-party algorithm, our result improves the\ntime and space complexity O(kn^2) to O(kn log^3 n) and O(kn), where k and n\ndenote the number of features and data samples, respectively. We also\nimplemented the proposed algorithm and conducted comparative experiments with\nthe naive one. The experimental result shows the efficiency of our method even\nwith small datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.12869v1",
    "published": "2025-05-19T08:55:56+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12868v1",
    "title": "Causality-Inspired Robustness for Nonlinear Models via Representation Learning",
    "authors": [
      "Marin ≈†ola",
      "Peter B√ºhlmann",
      "Xinwei Shen"
    ],
    "abstract": "Distributional robustness is a central goal of prediction algorithms due to\nthe prevalent distribution shifts in real-world data. The prediction model aims\nto minimize the worst-case risk among a class of distributions, a.k.a., an\nuncertainty set. Causality provides a modeling framework with a rigorous\nrobustness guarantee in the above sense, where the uncertainty set is\ndata-driven rather than pre-specified as in traditional distributional\nrobustness optimization. However, current causality-inspired robustness methods\npossess finite-radius robustness guarantees only in the linear settings, where\nthe causal relationships among the covariates and the response are linear. In\nthis work, we propose a nonlinear method under a causal framework by\nincorporating recent developments in identifiable representation learning and\nestablish a distributional robustness guarantee. To our best knowledge, this is\nthe first causality-inspired robustness method with such a finite-radius\nrobustness guarantee in nonlinear settings. Empirical validation of the\ntheoretical findings is conducted on both synthetic data and real-world\nsingle-cell data, also illustrating that finite-radius robustness is crucial.",
    "pdf_url": "http://arxiv.org/pdf/2505.12868v1",
    "published": "2025-05-19T08:52:15+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.12867v1",
    "title": "The Dichotomy in the Nuclear and Host Galaxy Properties of High-redshift Quasars",
    "authors": [
      "Ruancun Li",
      "Luis C. Ho",
      "Chang-Hao Chen"
    ],
    "abstract": "The early growth of high-redshift quasars and their host galaxies raises\ncritical questions about their cosmic evolution. We exploit the angular\nresolution and sensitivity of NIRCam to investigate the host galaxies of 31\nquasars at $4\\lesssim z\\lesssim7$ drawn from multiple JWST surveys. Using a new\nmulti-band forward-modeling code (\\textsc{GalfitS}) that incorporates\nphysically motivated priors, we securely detect and quantify the host emission\nin 30 objects, while simultaneously characterizing the nuclear spectral energy\ndistribution. The host galaxies of high-redshift quasars are $\\sim 0.3$~dex\nmore compact than star-forming galaxies of comparable mass. A striking\ndichotomy emerges: luminous ``blue'' quasars ($L_{5100}\\gtrsim10^{45}\\,{\\rm\nerg\\,s^{-1}}$) reside in bulge-dominated galaxies ($n \\approx 5$) and exhibit a\nnarrow range of ultraviolet nuclear slopes (median $\\beta_{\\rm UV} \\approx\n-1.4$), while fainter ``red'' quasars inhabit disk-like hosts ($n\\approx 1$)\nand display a broad range of slopes ($\\beta_{\\rm UV}\\approx-2$ to 4). These two\npopulations differ markedly in their black hole-to-stellar mass ratios, with\nhigh-luminosity quasars showing $M_{\\mathrm{BH}}/M_\\ast = 1.2\\%$ compared to\n$4.7\\%$ for lower luminosity sources, placing them collectively $\\sim$0.6~dex\nabove the local $M_{\\mathrm{BH}}-M_\\ast$ relation. This offset likely reflects\nrapid black hole growth in early gas-rich environments, where feedback from the\nactive galactic nucleus becomes effective only after substantial gas depletion.\nOur findings suggest that the observed dichotomy, whether due to intrinsic\nspectral differences or dust extinction, fundamentally shapes the coevolution\nof supermassive black holes and their host galaxies in the early Universe.",
    "pdf_url": "http://arxiv.org/pdf/2505.12867v1",
    "published": "2025-05-19T08:51:37+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.20307v2",
    "title": "Second domain variation for a product of domain functionals",
    "authors": [
      "Alfred Wagner"
    ],
    "abstract": "The second domain variation of the $p$-capacity and the $q$ - torsional\nrigidity for compact sets in $R^d, d\\geq3$ with $1<p<d$ is computed. Conditions\non $p$ and $q>1$ are given such that the ball is a local minimzer or maximizer\nof the product.",
    "pdf_url": "http://arxiv.org/pdf/2505.20307v2",
    "published": "2025-05-19T08:50:55+00:00",
    "categories": [
      "math.AP",
      "math.OC"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12866v1",
    "title": "Treewidth versus clique number. V. Further connections with tree-independence number",
    "authors": [
      "Claire Hilaire",
      "Martin Milaniƒç",
      "ƒêorƒëe Vasiƒá"
    ],
    "abstract": "We continue the study of $(tw,\\omega)$-bounded graph classes, that is,\nhereditary graph classes in which large treewidth is witnessed by the presence\nof a large clique, and the relation of this property to boundedness of the\ntree-independence number, a graph parameter introduced independently by Yolov\nin 2018 and by Dallard, Milani\\v{c}, and \\v{S}torgel in 2024. Dallard et al.\nshowed that bounded tree-independence number is sufficient for\n$(tw,\\omega)$-boundedness, and conjectured that the converse holds. While this\nconjecture has been recently disproved, it is still interesting to determine\nclasses where the conjecture holds; for example, the conjecture is still open\nfor graph classes excluding an induced star, as well as for finitely many\nforbidden induced subgraphs. In this paper, we identify further families of\ngraph classes where $(tw,\\omega)$-boundedness is equivalent to bounded\ntree-independence number. We settle a number of cases of finitely many\nforbidden induced subgraphs, obtain several equivalent characterizations of\n$(tw, \\omega)$-boundedness in subclasses of the class of complements of line\ngraphs, and give a short proof of a recent result of Ahn, Gollin, Huynh, and\nKwon [SODA 2025] establishing bounded tree-independence number for graphs\nexcluding a fixed induced star and a fixed number of independent cycles.",
    "pdf_url": "http://arxiv.org/pdf/2505.12866v1",
    "published": "2025-05-19T08:50:41+00:00",
    "categories": [
      "math.CO",
      "05C75 (Primary) 05C05, 05C69, 05C83, 05C76 (Secondary)"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12865v1",
    "title": "Entangling two levitated particles in free space via trap modulation and Bayesian feedback",
    "authors": [
      "Jinke Cao",
      "Qi Guo",
      "Huatang Tan"
    ],
    "abstract": "We propose an optimal control scheme for generating quantum entanglement\nbetween two optically-levitated nanoparticles in free space. Specifically, we\nconsider that the mechanical motion frequencies of the two levitated particles\nare modulated by adjusting the amplitude of the trapping beam. The two\nparticles are coupled through Coulomb interaction, and the particles' positions\nare continuously monitored via homodyne detection on the back-scattered light\nfrom both particles. By employing an optimal Bayesian feedback scheme, we\nachieve unconditional entanglement between the two particles in steady states.\nMore precisely, a Kalman filter is used to estimate the states of the two\nparticles and subsequently a linear quadratic regulator is applied to derive\nthe optimal feedback forces exerted on the particles. Physically, periodic\nmodulation enables significant quantum squeezing in both the common mode and\nthe differential mode of the two particles. The Coulomb coupling between the\nparticles introduces a difference in the squeezing of the two normal modes,\nthereby facilitating the entanglement of the two levitated particles. Our\nscheme allows for the realization of both conditional and unconditional\nentanglement at relatively low measurement efficiencies and with low\nrequirements for Coulomb coupling strength, significantly enhancing the\nfeasibility of implementation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12865v1",
    "published": "2025-05-19T08:48:29+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12864v3",
    "title": "LEXam: Benchmarking Legal Reasoning on 340 Law Exams",
    "authors": [
      "Yu Fan",
      "Jingwei Ni",
      "Jakob Merane",
      "Etienne Salimbeni",
      "Yang Tian",
      "Yoan Hermstr√ºwer",
      "Yinya Huang",
      "Mubashara Akhtar",
      "Florian Geering",
      "Oliver Dreyer",
      "Daniel Brunner",
      "Markus Leippold",
      "Mrinmaya Sachan",
      "Alexander Stremitzer",
      "Christoph Engel",
      "Elliott Ash",
      "Joel Niklaus"
    ],
    "abstract": "Long-form legal reasoning remains a key challenge for large language models\n(LLMs) in spite of recent advances in test-time scaling. We introduce LEXam, a\nnovel benchmark derived from 340 law exams spanning 116 law school courses\nacross a range of subjects and degree levels. The dataset comprises 4,886 law\nexam questions in English and German, including 2,841 long-form, open-ended\nquestions and 2,045 multiple-choice questions. Besides reference answers, the\nopen questions are also accompanied by explicit guidance outlining the expected\nlegal reasoning approach such as issue spotting, rule recall, or rule\napplication. Our evaluation on both open-ended and multiple-choice questions\npresent significant challenges for current LLMs; in particular, they notably\nstruggle with open questions that require structured, multi-step legal\nreasoning. Moreover, our results underscore the effectiveness of the dataset in\ndifferentiating between models with varying capabilities. Adopting an\nLLM-as-a-Judge paradigm with rigorous human expert validation, we demonstrate\nhow model-generated reasoning steps can be evaluated consistently and\naccurately. Our evaluation setup provides a scalable method to assess legal\nreasoning quality beyond simple accuracy metrics. Project page:\nhttps://lexam-benchmark.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2505.12864v3",
    "published": "2025-05-19T08:48:12+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12863v1",
    "title": "Unified Cross-modal Translation of Score Images, Symbolic Music, and Performance Audio",
    "authors": [
      "Jongmin Jung",
      "Dongmin Kim",
      "Sihun Lee",
      "Seola Cho",
      "Hyungjoon Soh",
      "Irmak Bukey",
      "Chris Donahue",
      "Dasaem Jeong"
    ],
    "abstract": "Music exists in various modalities, such as score images, symbolic scores,\nMIDI, and audio. Translations between each modality are established as core\ntasks of music information retrieval, such as automatic music transcription\n(audio-to-MIDI) and optical music recognition (score image to symbolic score).\nHowever, most past work on multimodal translation trains specialized models on\nindividual translation tasks. In this paper, we propose a unified approach,\nwhere we train a general-purpose model on many translation tasks\nsimultaneously. Two key factors make this unified approach viable: a new\nlarge-scale dataset and the tokenization of each modality. Firstly, we propose\na new dataset that consists of more than 1,300 hours of paired audio-score\nimage data collected from YouTube videos, which is an order of magnitude larger\nthan any existing music modal translation datasets. Secondly, our unified\ntokenization framework discretizes score images, audio, MIDI, and MusicXML into\na sequence of tokens, enabling a single encoder-decoder Transformer to tackle\nmultiple cross-modal translation as one coherent sequence-to-sequence task.\nExperimental results confirm that our unified multitask model improves upon\nsingle-task baselines in several key areas, notably reducing the symbol error\nrate for optical music recognition from 24.58% to a state-of-the-art 13.67%,\nwhile similarly substantial improvements are observed across the other\ntranslation tasks. Notably, our approach achieves the first successful\nscore-image-conditioned audio generation, marking a significant breakthrough in\ncross-modal music generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12863v1",
    "published": "2025-05-19T08:46:45+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.12862v1",
    "title": "Scheduling of Flexible Manufacturing Systems Based on Place-Timed Petri Nets and Basis Reachability Graphs",
    "authors": [
      "Zhou He",
      "Ning Li",
      "Ning Ran",
      "Liang Li"
    ],
    "abstract": "Scheduling is a key decision-making process to improve the performance of\nflexible manufacturing systems. Place-timed Petri nets provide a formal method\nfor graphically modeling and analyzing such systems. By generating reachability\ngraphs and combining intelligent search algorithms, operation sequences from\nthe initial state to the target state can be found for the underlying system.\nHowever, the reachability graph grows exponentially with the system size\nincreases, which is the main challenge of existing methods for scheduling large\nsystems. To this end, we develop an efficient improved beam search algorithm to\noptimize the makespan based on a compact representation of reachability graph\ncalled basis reachability graph. The key idea behind the proposed method is to\nform a state together with the basis markings and its corresponding transition\nsequences, and evaluate the cost of the state based on the resource idle time.\nExperimental results are conducted on several benchmark systems which show that\nthe developed method improves the search efficiency while ensuring the quality\nof the solution compared with existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.12862v1",
    "published": "2025-05-19T08:46:39+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.12861v2",
    "title": "RMMSS: Towards Advanced Robust Multi-Modal Semantic Segmentation with Hybrid Prototype Distillation and Feature Selection",
    "authors": [
      "Jiaqi Tan",
      "Xu Zheng",
      "Yang Liu"
    ],
    "abstract": "Multi-modal semantic segmentation (MMSS) faces significant challenges in\nreal-world applications due to incomplete, degraded, or missing sensor data.\nWhile current MMSS methods typically use self-distillation with modality\ndropout to improve robustness, they largely overlook inter-modal correlations\nand thus suffer significant performance degradation when no modalities are\nmissing. To this end, we present RMMSS, a two-stage framework designed to\nprogressively enhance model robustness under missing-modality conditions, while\nmaintaining strong performance in full-modality scenarios. It comprises two key\ncomponents: the Hybrid Prototype Distillation Module (HPDM) and the Feature\nSelection Module (FSM). In the first stage, we pre-train the teacher model with\nfull-modality data and then introduce HPDM to do cross-modal knowledge\ndistillation for obtaining a highly robust model. In the second stage, we\nfreeze both the pre-trained full-modality teacher model and the robust model\nand propose a trainable FSM that extracts optimal representations from both the\nfeature and logits layers of the models via feature score calculation. This\nprocess learns a final student model that maintains strong robustness while\nachieving high performance under full-modality conditions. Our experiments on\nthree datasets demonstrate that our method improves missing-modality\nperformance by 2.80%, 3.89%, and 0.89%, respectively, compared to the\nstate-of-the-art, while causing almost no drop in full-modality performance\n(only -0.1% mIoU). Meanwhile, different backbones (AnySeg and CMNeXt) are\nutilized to validate the generalizability of our framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.12861v2",
    "published": "2025-05-19T08:46:03+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12860v2",
    "title": "Towards a Universal Image Degradation Model via Content-Degradation Disentanglement",
    "authors": [
      "Wenbo Yang",
      "Zhongling Wang",
      "Zhou Wang"
    ],
    "abstract": "Image degradation synthesis is highly desirable in a wide variety of\napplications ranging from image restoration to simulating artistic effects.\nExisting models are designed to generate one specific or a narrow set of\ndegradations, which often require user-provided degradation parameters. As a\nresult, they lack the generalizability to synthesize degradations beyond their\ninitial design or adapt to other applications. Here we propose the first\nuniversal degradation model that can synthesize a broad spectrum of complex and\nrealistic degradations containing both homogeneous (global) and inhomogeneous\n(spatially varying) components. Our model automatically extracts and\ndisentangles homogeneous and inhomogeneous degradation features, which are\nlater used for degradation synthesis without user intervention. A\ndisentangle-by-compression method is proposed to separate degradation\ninformation from images. Two novel modules for extracting and incorporating\ninhomogeneous degradations are created to model inhomogeneous components in\ncomplex degradations. We demonstrate the model's accuracy and adaptability in\nfilm-grain simulation and blind image restoration tasks. The demo video, code,\nand dataset of this project will be released at\ngithub.com/yangwenbo99/content-degradation-disentanglement.",
    "pdf_url": "http://arxiv.org/pdf/2505.12860v2",
    "published": "2025-05-19T08:45:08+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12859v1",
    "title": "Re-identification of De-identified Documents with Autoregressive Infilling",
    "authors": [
      "Lucas Georges Gabriel Charpentier",
      "Pierre Lison"
    ],
    "abstract": "Documents revealing sensitive information about individuals must typically be\nde-identified. This de-identification is often done by masking all mentions of\npersonally identifiable information (PII), thereby making it more difficult to\nuncover the identity of the person(s) in question. To investigate the\nrobustness of de-identification methods, we present a novel, RAG-inspired\napproach that attempts the reverse process of re-identification based on a\ndatabase of documents representing background knowledge. Given a text in which\npersonal identifiers have been masked, the re-identification proceeds in two\nsteps. A retriever first selects from the background knowledge passages deemed\nrelevant for the re-identification. Those passages are then provided to an\ninfilling model which seeks to infer the original content of each text span.\nThis process is repeated until all masked spans are replaced. We evaluate the\nre-identification on three datasets (Wikipedia biographies, court rulings and\nclinical notes). Results show that (1) as many as 80% of de-identified text\nspans can be successfully recovered and (2) the re-identification accuracy\nincreases along with the level of background knowledge.",
    "pdf_url": "http://arxiv.org/pdf/2505.12859v1",
    "published": "2025-05-19T08:43:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12858v1",
    "title": "Breaking Sensitivity Barriers in Luminescence Thermometry: Synergy Between Structural Phase Transition and Luminescence Thermal Quenching",
    "authors": [
      "M. Tahir Abbas",
      "M. Szymczak",
      "M. Drozd",
      "D. Szymanski",
      "A. Owczarek",
      "A. Musialek",
      "L. Marciniak"
    ],
    "abstract": "One of the key parameters determining the performance of a luminescent\nthermometer is its relative sensitivity. In ratiometric luminescence\nthermometry, high relative sensitivity to temperature variations is typically\nachieved when the two monitored emission bands exhibit opposite thermal\nmonotonicity. However, realizing a thermal enhancement in the luminescence\nintensity of one of the emission bands remains a significant challenge. In this\nstudy, we present a novel approach that leverages the synergistic effect of two\nphenomena: (1) the high thermal sensitivity of Mn4+ ion luminescence, and (2) a\nthermally induced structural phase transition in LaGaO3, which facilitates the\nenhancement of the luminescence signal from Tb3+ ions in the high-temperature\nphase of the host material. This dual effect not only led to an increased\nmaximum relative sensitivity but also extended the temperature range over which\nthe sensitivity exceeded 1% K-1. The highest recorded sensitivity was 4.5 K-1\nat 400 K. Additionally, to the best of our knowledge, the luminescence of Mn4+\nions in the high-temperature phase of LaGaO3:Mn4+ was observed and reported\nhere for the first time. The thermally induced modifications in the emission\nprofile of LaGaO3:Mn4+,Tb3+ enabled the development of a quadruple ratiometric\nluminescence thermometer, with complementary operating ranges, offering\nenhanced versatility and accuracy across a broad temperature span.",
    "pdf_url": "http://arxiv.org/pdf/2505.12858v1",
    "published": "2025-05-19T08:43:13+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.12857v2",
    "title": "The influence of pixel cell layout on the timing performance of 3D sensors",
    "authors": [
      "Clara Lasaosa",
      "Marcos Fern√°ndez",
      "Iv√°n Vila",
      "Jordi Duarte-Campderros",
      "Gervasio G√≥mez",
      "Salvador Hidalgo",
      "Giulio Pellegrini"
    ],
    "abstract": "Three-dimensional (3D) pixel sensors are a promising technology for\nimplementing the 4D-tracking paradigm in high-radiation environments. Despite\ntheir advantages in radiation tolerance, 3D pixel sensors exhibit non-uniform\nelectric and weighting fields that can degrade timing performance. This study\nexplores the impact of pixel cell geometry on the timing characteristics of 3D\ncolumnar-electrode sensors fabricated by IMB-CNM, comparing square and\nhexagonal layouts. The sensors were characterized using the Two-Photon\nAbsorption Transient Current Technique (TPA-TCT), providing high-resolution\nthree-dimensional maps of the Time-of-Arrival (ToA) of charge carriers.\nMeasurements at multiple depths and bias voltages reveal that the square\ngeometry yields a more uniform temporal response compared to the hexagonal\nconfiguration. Additionally, a novel TPA-TCT-based method was introduced to\ndetermine the sensor jitter, relying on the analysis of the time difference\nbetween consecutive pulses in the TPA-TCT pulse train acquired under identical\nconditions. These findings underline the importance of pixel design\noptimization for future 4D-tracking detectors and confirm the TPA-TCT method as\na powerful tool for detailed timing characterization.",
    "pdf_url": "http://arxiv.org/pdf/2505.12857v2",
    "published": "2025-05-19T08:42:43+00:00",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.12856v1",
    "title": "Addressing memory bandwidth scalability in vector processors for streaming applications",
    "authors": [
      "Jordi Altayo",
      "Paul Delestrac",
      "David Novo",
      "Simey Yang",
      "Debjyoti Bhattacharjee",
      "Francky Catthoor"
    ],
    "abstract": "As the size of artificial intelligence and machine learning (AI/ML) models\nand datasets grows, the memory bandwidth becomes a critical bottleneck. The\npaper presents a novel extended memory hierarchy that addresses some major\nmemory bandwidth challenges in data-parallel AI/ML applications. While\ndata-parallel architectures like GPUs and neural network accelerators have\nimproved power performance compared to traditional CPUs, they can still be\nsignificantly bottlenecked by their memory bandwidth, especially when the data\nreuse in the loop kernels is limited. Systolic arrays (SAs) and GPUs attempt to\nmitigate the memory bandwidth bottleneck but can still become memory bandwidth\nthrottled when the amount of data reuse is not sufficient to confine data\naccess mostly to the local memories near to the processing. To mitigate this,\nthe proposed architecture introduces three levels of on-chip memory -- local,\nintermediate, and global -- with an ultra-wide register and data-shufflers to\nimprove versatility and adaptivity to varying data-parallel applications. The\npaper explains the innovations at a conceptual level and presents a detailed\ndescription of the architecture innovations. We also map a representative\ndata-parallel application, like a convolutional neural network (CNN), to the\nproposed architecture and quantify the benefits vis-a-vis GPUs and\nrepersentative accelerators based on systolic arrays and vector processors.",
    "pdf_url": "http://arxiv.org/pdf/2505.12856v1",
    "published": "2025-05-19T08:42:24+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12855v1",
    "title": "Maximal subfields in division algebras generated by images of polynomials",
    "authors": [
      "Le Qui Danh",
      "Trinh Thanh Deo"
    ],
    "abstract": "Let $D$ be a division ring with center $F$, $f(x_1,x_2,\\dots, x_m)$ a\nnon-central multilinear polynomial over $F$, and $w(x_1,x_2,\\dots,x_m)$ a\nnon-trivial word. In this paper, we investigate conditions under which there\nexists an element $a \\in D$ such that the subfield $F(a)$ generated by $a$ is a\nmaximal subfield of $D$. Specifically, we prove that there always exists an\nelement $a$ in the set \\[ \\{f(a_1,\\dots,a_m)\\mid a_1,\\dots, a_m\\in D \\} \\cup\n\\{w(a_1,\\dots,a_m)\\mid a_1,\\dots, a_m\\in D \\backslash \\{0\\} \\} \\] such that\n$F(a)$ is a maximal subfield of $D$. This result shows that maximal subfields\ncan be generated by evaluating polynomial or group word expressions at elements\nof $D$.",
    "pdf_url": "http://arxiv.org/pdf/2505.12855v1",
    "published": "2025-05-19T08:41:57+00:00",
    "categories": [
      "math.RA"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12854v1",
    "title": "The Way Up: A Dataset for Hold Usage Detection in Sport Climbing",
    "authors": [
      "Anna Maschek",
      "David C. Schedl"
    ],
    "abstract": "Detecting an athlete's position on a route and identifying hold usage are\ncrucial in various climbing-related applications. However, no climbing dataset\nwith detailed hold usage annotations exists to our knowledge. To address this\nissue, we introduce a dataset of 22 annotated climbing videos, providing\nground-truth labels for hold locations, usage order, and time of use.\nFurthermore, we explore the application of keypoint-based 2D pose-estimation\nmodels for detecting hold usage in sport climbing. We determine usage by\nanalyzing the key points of certain joints and the corresponding overlap with\nclimbing holds. We evaluate multiple state-of-the-art models and analyze their\naccuracy on our dataset, identifying and highlighting climbing-specific\nchallenges. Our dataset and results highlight key challenges in\nclimbing-specific pose estimation and establish a foundation for future\nresearch toward AI-assisted systems for sports climbing.",
    "pdf_url": "http://arxiv.org/pdf/2505.12854v1",
    "published": "2025-05-19T08:41:18+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12853v1",
    "title": "Optimization of Hybrid Quantum-Classical Algorithms",
    "authors": [
      "Lian Remme",
      "Alexander Weinert",
      "Andre Waschk"
    ],
    "abstract": "Quantum computers do not run in isolation; rather, they are embedded in\nquantum-classical hybrid architectures. In these setups, a quantum processing\nunit communicates with a classical device in near-real time. To enable\nefficient hybrid computations, it is mandatory to optimize quantum-classical\nhybrid code. To the best of our knowledge, no previous work on the optimization\nof hybrid code nor on metrics for which to optimize such code exists.\n  In this work, we take a step towards optimization of hybrid programs by\nintroducing seven optimization routines and three metrics to evaluate the\neffectiveness of the optimization. We implement these routines for the hybrid\nquantum language Quil and show that our optimizations improve programs\naccording to our metrics. This lays the foundation for new kinds of hybrid\noptimizers that enable real-time collaboration between quantum and classical\ndevices.",
    "pdf_url": "http://arxiv.org/pdf/2505.12853v1",
    "published": "2025-05-19T08:39:51+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12852v1",
    "title": "A magnetic tertiary in the most massive compact triple-star system",
    "authors": [
      "S. Hubrig",
      "A. Vigna-G√≥mez",
      "S. P. J√§rvinen",
      "M. Sch√∂ller",
      "I. Ilyin"
    ],
    "abstract": "The system TIC 470710327 is comprised of three main-sequence OB stars, with\nan inner compact 1.10 d eclipsing binary and a non-eclipsing tertiary on a\n52.04 d orbit. With the tertiary mass of 14.5-16 $M_{\\odot}$ and both\ncomponents in the inner eclipsing binary with individual masses of 6--7 and\n5.5-6.3 $M_{\\odot}$, it is currently the most massive compact system known. The\nformation scenario of such a compact triple is uncertain. It has been suggested\nthat `2 + 2' quadruple dynamics can lead to a stellar merger in the initially\nmore massive binary and finally result in a highly magnetised tertiary. Our\nstudy confirms the presence of a kG-order magnetic field in the tertiary and\nthe slow rotation typical for massive magnetic stars. We conclude that finding\nmassive merger candidates by studies of dynamics in compact, multiple-star\nsystems is an efficient way to understand the evolution of massive stellar\nmultiplicity and the generation of magnetic fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.12852v1",
    "published": "2025-05-19T08:39:25+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12851v1",
    "title": "FLTG: Byzantine-Robust Federated Learning via Angle-Based Defense and Non-IID-Aware Weighting",
    "authors": [
      "Yanhua Wen",
      "Lu Ai",
      "Gang Liu",
      "Chuang Li",
      "Jianhao Wei"
    ],
    "abstract": "Byzantine attacks during model aggregation in Federated Learning (FL)\nthreaten training integrity by manipulating malicious clients' updates.\nExisting methods struggle with limited robustness under high malicious client\nratios and sensitivity to non-i.i.d. data, leading to degraded accuracy. To\naddress this, we propose FLTG, a novel aggregation algorithm integrating\nangle-based defense and dynamic reference selection. FLTG first filters clients\nvia ReLU-clipped cosine similarity, leveraging a server-side clean dataset to\nexclude misaligned updates. It then dynamically selects a reference client\nbased on the prior global model to mitigate non-i.i.d. bias, assigns\naggregation weights inversely proportional to angular deviations, and\nnormalizes update magnitudes to suppress malicious scaling. Evaluations across\ndatasets of varying complexity under five classic attacks demonstrate FLTG's\nsuperiority over state-of-the-art methods under extreme bias scenarios and\nsustains robustness with a higher proportion(over 50%) of malicious clients.",
    "pdf_url": "http://arxiv.org/pdf/2505.12851v1",
    "published": "2025-05-19T08:39:07+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12850v1",
    "title": "Numerical Investigation on the Compressive Behavior of Hierarchical Granular Piles",
    "authors": [
      "Sota Arakawa",
      "Mikito Furuichi",
      "Daisuke Nishiura"
    ],
    "abstract": "Hierarchical granular piles composed of aggregates are key structural\nfeatures in both geoscience and planetary science, from fault gouge in seismic\nzones to the internal structures of comets. Although experimental studies have\nsuggested a multi-step evolution in their packing structure, this hypothesis\nhas lacked numerical validation. In this study, we performed large-scale\nnumerical simulations using the discrete element method to investigate the\ncompressive behavior of hierarchical granular piles. We successfully reproduced\nand confirmed a three-stage evolution process: (i) rearrangement of the\naggregate packing structure, (ii) plastic deformation of small aggregates, and\n(iii) elastic deformation of constituent particles. Additionally, we developed\na semi-analytical model for the compression curve, offering insights into the\ncompressive stages and structural dynamics. Our findings have applications in\nmodeling the internal density profiles of comets and in understanding the early\nthermal evolution of small icy bodies.",
    "pdf_url": "http://arxiv.org/pdf/2505.12850v1",
    "published": "2025-05-19T08:36:49+00:00",
    "categories": [
      "cond-mat.soft",
      "astro-ph.EP",
      "physics.geo-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.12849v1",
    "title": "Accelerate TarFlow Sampling with GS-Jacobi Iteration",
    "authors": [
      "Ben Liu",
      "Zhen Qin"
    ],
    "abstract": "Image generation models have achieved widespread applications. As an\ninstance, the TarFlow model combines the transformer architecture with\nNormalizing Flow models, achieving state-of-the-art results on multiple\nbenchmarks. However, due to the causal form of attention requiring sequential\ncomputation, TarFlow's sampling process is extremely slow. In this paper, we\ndemonstrate that through a series of optimization strategies, TarFlow sampling\ncan be greatly accelerated by using the Gauss-Seidel-Jacobi (abbreviated as\nGS-Jacobi) iteration method. Specifically, we find that blocks in the TarFlow\nmodel have varying importance: a small number of blocks play a major role in\nimage generation tasks, while other blocks contribute relatively little; some\nblocks are sensitive to initial values and prone to numerical overflow, while\nothers are relatively robust. Based on these two characteristics, we propose\nthe Convergence Ranking Metric (CRM) and the Initial Guessing Metric (IGM): CRM\nis used to identify whether a TarFlow block is \"simple\" (converges in few\niterations) or \"tough\" (requires more iterations); IGM is used to evaluate\nwhether the initial value of the iteration is good. Experiments on four TarFlow\nmodels demonstrate that GS-Jacobi sampling can significantly enhance sampling\nefficiency while maintaining the quality of generated images (measured by FID),\nachieving speed-ups of 4.53x in Img128cond, 5.32x in AFHQ, 2.96x in\nImg64uncond, and 2.51x in Img64cond without degrading FID scores or sample\nquality. Code and checkpoints are accessible on\nhttps://github.com/encoreus/GS-Jacobi_for_TarFlow",
    "pdf_url": "http://arxiv.org/pdf/2505.12849v1",
    "published": "2025-05-19T08:35:44+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12848v1",
    "title": "A Comprehensive Benchmarking Platform for Deep Generative Models in Molecular Design",
    "authors": [
      "Adarsh Singh"
    ],
    "abstract": "The development of novel pharmaceuticals represents a significant challenge\nin modern science, with substantial costs and time investments. Deep generative\nmodels have emerged as promising tools for accelerating drug discovery by\nefficiently exploring the vast chemical space. However, this rapidly evolving\nfield lacks standardized evaluation protocols, impeding fair comparison between\napproaches. This research presents an extensive analysis of the Molecular Sets\n(MOSES) platform, a comprehensive benchmarking framework designed to\nstandardize evaluation of deep generative models in molecular design. Through\nrigorous assessment of multiple generative architectures, including recurrent\nneural networks, variational autoencoders, and generative adversarial networks,\nwe examine their capabilities in generating valid, unique, and novel molecular\nstructures while maintaining specific chemical properties. Our findings reveal\nthat different architectures exhibit complementary strengths across various\nmetrics, highlighting the complex trade-offs between exploration and\nexploitation in chemical space. This study provides detailed insights into the\ncurrent state of the art in molecular generation and establishes a foundation\nfor future advancements in AI-driven drug discovery.",
    "pdf_url": "http://arxiv.org/pdf/2505.12848v1",
    "published": "2025-05-19T08:34:38+00:00",
    "categories": [
      "physics.atom-ph",
      "cs.LG"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12847v1",
    "title": "The Stefan problem with mushy region as a scaling limit of stochastic PDE with turbulent transport",
    "authors": [
      "Ioana Ciotir",
      "Franco Flandoli",
      "Dan Goreac"
    ],
    "abstract": "This work establishes a scaling limit theorem for the Stefan problem\nincorporating a mushy region, demonstrating that solutions to stochastic\nvariants with turbulent transport terms converge to the solution to a\ndeterministic partial differential equation. The analysis builds upon recent\nadvances in stochastic phase-change modeling and turbulent flow mathematics in\n[5]. In the physical interpretation of an ice melting process, our result shows\nthat turbulence accelerates ice melting.",
    "pdf_url": "http://arxiv.org/pdf/2505.12847v1",
    "published": "2025-05-19T08:33:18+00:00",
    "categories": [
      "math.AP",
      "60H15, 80A22, 76D03"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12845v1",
    "title": "Multi-Level Aware Preference Learning: Enhancing RLHF for Complex Multi-Instruction Tasks",
    "authors": [
      "Ruopei Sun",
      "Jianfeng Cai",
      "Jinhua Zhu",
      "Kangwen Zhao",
      "Dongyun Xue",
      "Wengang Zhou",
      "Li Li",
      "Houqiang Li"
    ],
    "abstract": "RLHF has emerged as a predominant approach for aligning artificial\nintelligence systems with human preferences, demonstrating exceptional and\nmeasurable efficacy in instruction following tasks; however, it exhibits\ninsufficient compliance capabilities when confronted with complex\nmulti-instruction tasks. Conventional approaches rely heavily on human\nannotation or more sophisticated large language models, thereby introducing\nsubstantial resource expenditure or potential bias concerns. Meanwhile,\nalternative synthetic methods that augment standard preference datasets often\ncompromise the model's semantic quality. Our research identifies a critical\noversight in existing techniques, which predominantly focus on comparing\nresponses while neglecting valuable latent signals embedded within prompt\ninputs, and which only focus on preference disparities at the intra-sample\nlevel, while neglecting to account for the inter-sample level preference\ndifferentials that exist among preference data. To leverage these previously\nneglected indicators, we propose a novel Multi-level Aware Preference Learning\n(MAPL) framework, capable of enhancing multi-instruction capabilities.\nSpecifically, for any given response in original preference data pairs, we\nconstruct varied prompts with a preference relation under different conditions,\nin order to learn intra-sample level preference disparities. Furthermore, for\nany given original preference pair, we synthesize multi-instruction preference\npairs to capture preference discrepancies at the inter-sample level. Building\non the two datasets constructed above, we consequently devise two sophisticated\ntraining objective functions. Subsequently, our framework integrates seamlessly\ninto both Reward Modeling and Direct Preference Optimization paradigms. Through\nrigorous evaluation across multiple benchmarks, we empirically validate the\nefficacy of our framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.12845v1",
    "published": "2025-05-19T08:33:11+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12846v1",
    "title": "The Flea on the Magnetic Elephant",
    "authors": [
      "Pavel Exner",
      "L√©o Morin"
    ],
    "abstract": "We investigate a two-dimensional magnetic Laplacian with two radially\nsymmetric magnetic wells. Its spectral properties are determined by the\ntunneling between them. If the tunneling is weak and the wells are mirror\nsymmetric, the two lowest eigenfunctions are localized in both wells being\ndistributed roughly equally. In this note we show that an exponentially small\nsymmetry violation can in this situation have a dramatic effect, making each of\nthe eigenfunctions localized dominantly in one well only. This is reminiscent\nof the `flea on the elephant' effect for Schr\\\"odinger operators; our result\nshows that it has a purely magnetic counterpart.",
    "pdf_url": "http://arxiv.org/pdf/2505.12846v1",
    "published": "2025-05-19T08:33:11+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "math.SP",
      "81U26, 35P15, 81Q20, 35Q40"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12844v2",
    "title": "AGI-Elo: How Far Are We From Mastering A Task?",
    "authors": [
      "Shuo Sun",
      "Yimin Zhao",
      "Christina Dao Wen Lee",
      "Jiawei Sun",
      "Chengran Yuan",
      "Zefan Huang",
      "Dongen Li",
      "Justin KW Yeoh",
      "Alok Prakash",
      "Thomas W. Malone",
      "Marcelo H. Ang Jr"
    ],
    "abstract": "As the field progresses toward Artificial General Intelligence (AGI), there\nis a pressing need for more comprehensive and insightful evaluation frameworks\nthat go beyond aggregate performance metrics. This paper introduces a unified\nrating system that jointly models the difficulty of individual test cases and\nthe competency of AI models (or humans) across vision, language, and action\ndomains. Unlike existing metrics that focus solely on models, our approach\nallows for fine-grained, difficulty-aware evaluations through competitive\ninteractions between models and tasks, capturing both the long-tail\ndistribution of real-world challenges and the competency gap between current\nmodels and full task mastery. We validate the generalizability and robustness\nof our system through extensive experiments on multiple established datasets\nand models across distinct AGI domains. The resulting rating distributions\noffer novel perspectives and interpretable insights into task difficulty, model\nprogression, and the outstanding challenges that remain on the path to\nachieving full AGI task mastery.",
    "pdf_url": "http://arxiv.org/pdf/2505.12844v2",
    "published": "2025-05-19T08:30:13+00:00",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12843v1",
    "title": "Bias Fitting to Mitigate Length Bias of Reward Model in RLHF",
    "authors": [
      "Kangwen Zhao",
      "Jianfeng Cai",
      "Jinhua Zhu",
      "Ruopei Sun",
      "Dongyun Xue",
      "Wengang Zhou",
      "Li Li",
      "Houqiang Li"
    ],
    "abstract": "Reinforcement Learning from Human Feedback relies on reward models to align\nlarge language models with human preferences. However, RLHF often suffers from\nreward hacking, wherein policy learning exploits flaws in the trained reward\nmodel to maximize reward scores without genuinely aligning with human\npreferences. A significant example of such reward hacking is length bias, where\nreward models usually favor longer responses irrespective of actual response\nquality. Previous works on length bias have notable limitations, these\napproaches either mitigate bias without characterizing the bias form, or simply\nassume a linear length-reward relation. To accurately model the intricate\nnature of length bias and facilitate more effective bias mitigation, we propose\nFiMi-RM (Bias Fitting to Mitigate Length Bias of Reward Model in RLHF), a\nframework that autonomously learns and corrects underlying bias patterns. Our\napproach consists of three stages: First, we train a standard reward model\nwhich inherently contains length bias. Next, we deploy a lightweight fitting\nmodel to explicitly capture the non-linear relation between length and reward.\nFinally, we incorporate this learned relation into the reward model to debias.\nExperimental results demonstrate that FiMi-RM achieves a more balanced\nlength-reward distribution. Furthermore, when applied to alignment algorithms,\nour debiased reward model improves length-controlled win rate and reduces\nverbosity without compromising its performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.12843v1",
    "published": "2025-05-19T08:29:28+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12842v3",
    "title": "GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in GUI Agents",
    "authors": [
      "Zheng Wu",
      "Pengzhou Cheng",
      "Zongru Wu",
      "Lingzhong Dong",
      "Zhuosheng Zhang"
    ],
    "abstract": "Graphical user interface (GUI) agents have recently emerged as an intriguing\nparadigm for human-computer interaction, capable of automatically executing\nuser instructions to operate intelligent terminal devices. However, when\nencountering out-of-distribution (OOD) instructions that violate environmental\nconstraints or exceed the current capabilities of agents, GUI agents may suffer\ntask breakdowns or even pose security threats. Therefore, effective OOD\ndetection for GUI agents is essential. Traditional OOD detection methods\nperform suboptimally in this domain due to the complex embedding space and\nevolving GUI environments. In this work, we observe that the in-distribution\ninput semantic space of GUI agents exhibits a clustering pattern with respect\nto the distance from the centroid. Based on the finding, we propose GEM, a\nnovel method based on fitting a Gaussian mixture model over input embedding\ndistances extracted from the GUI agent that reflect its capability boundary.\nEvaluated on eight datasets spanning smartphones, computers, and web browsers,\nour method achieves an average accuracy improvement of 23.70\\% over the\nbest-performing baseline while only increasing training time by 4.9\\% and\ntesting time by 6.5\\%. We also experimentally demonstrate that GEM can improve\nthe step-wise success rate by 9.40\\% by requesting assistance from the cloud\nmodel when encountering OOD samples. Analysis verifies the generalization\nability of our method through experiments on nine different backbones. The\ncodes are available at https://github.com/Wuzheng02/GEM-OODforGUIagents.",
    "pdf_url": "http://arxiv.org/pdf/2505.12842v3",
    "published": "2025-05-19T08:29:05+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12841v1",
    "title": "The Ozawa solution to the Davey--Stewartson II equations and surface theory",
    "authors": [
      "Yi C. Huang",
      "Iskander A. Taimanov"
    ],
    "abstract": "We describe the Ozawa solution to the Davey--Stewartson II equation from the\npoint of view of surface theory by presenting a soliton deformation of surfaces\nwhich is ruled by the Ozawa solution. The Ozawa solution blows up at certain\nmoment and we describe explicitly the corresponding singularity of the deformed\nsurface.",
    "pdf_url": "http://arxiv.org/pdf/2505.12841v1",
    "published": "2025-05-19T08:28:34+00:00",
    "categories": [
      "nlin.SI",
      "math.AP",
      "math.DG",
      "Primary: 53A05, Secondary: 35B38, 35Q51, 53C42"
    ],
    "primary_category": "nlin.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12840v1",
    "title": "Geometric Formalization of First-Order Stochastic Dominance in $N$ Dimensions: A Tractable Path to Multi-Dimensional Economic Decision Analysis",
    "authors": [
      "Jingyuan Li"
    ],
    "abstract": "This paper introduces and formally verifies a novel geometric framework for\nfirst-order stochastic dominance (FSD) in $N$ dimensions using the Lean 4\ntheorem prover. Traditional analytical approaches to multi-dimensional\nstochastic dominance rely heavily on complex measure theory and multivariate\ncalculus, creating significant barriers to formalization in proof assistants.\nOur geometric approach characterizes $N$-dimensional FSD through direct\ncomparison of survival probabilities in upper-right orthants, bypassing the\nneed for complex integration theory. We formalize key definitions and prove the\nequivalence between traditional FSD requirements and our geometric\ncharacterization. This approach achieves a more tractable and intuitive path to\nformal verification while maintaining mathematical rigor. We demonstrate how\nthis framework directly enables formal analysis of multi-dimensional economic\nproblems in portfolio selection, risk management, and welfare analysis. The\nwork establishes a foundation for further development of verified\ndecision-making tools in economics and finance, particularly for high-stakes\ndomains requiring rigorous guarantees.",
    "pdf_url": "http://arxiv.org/pdf/2505.12840v1",
    "published": "2025-05-19T08:28:25+00:00",
    "categories": [
      "cs.LO",
      "econ.TH",
      "q-fin.CP"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12839v1",
    "title": "On classification of (self-dual) higher-spin gravities in flat space",
    "authors": [
      "Mattia Serrani"
    ],
    "abstract": "There is a great number of higher-spin gravities in $3d$ that can have both\nfinite and infinite spectra of fields and can be formulated as Chern-Simons\ntheories. It was believed that this is impossible in higher dimensions, where\nhigher-spin fields do have propagating degrees of freedom. We show that there\nare infinitely many higher-spin theories in the $4d$ flat space featuring\nnontrivial local interactions that can have either a finite or infinite number\nof fields. We classify all one- and two-derivative (i.e. with gauge and\ngravitational interactions) higher-spin theories by solving the holomorphic\nconstraint in the light-cone gauge obtained by Metsaev. Therefore, these\ntheories are consistent subsectors of the higher-spin extensions of self-dual\nYang-Mills/gravity, which in turn are truncations of the chiral higher-spin\ngravity.",
    "pdf_url": "http://arxiv.org/pdf/2505.12839v1",
    "published": "2025-05-19T08:26:43+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.12838v1",
    "title": "Modified wave operators and scattering for linear wave equations with a repulsive potential",
    "authors": [
      "Boya Fan",
      "Ruipeng Shen"
    ],
    "abstract": "In this work we consider the wave equation with a repulsive potential, either\non the half line ${\\mathbb R}^+$ or the Euclidean space ${\\mathbb R}^d$ with\n$d\\geq 3$. We combine the operator theory and the inward/outward energy theory\nto deduce a modified wave operator for repulsive potentials decaying like\n$|x|^{-\\beta}$ with $\\beta>1/3$. In particular the regular wave operator\nwithout modification exists if $\\beta>1$. This implies that the asymptotic\nbehaviour of finite-energy solutions to the wave equation $u_{tt} - \\Delta u +\n|x|^{-\\beta} u =0$ is similar to that of the solutions to the classic wave\nequation if $\\beta \\in (1,2)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.12838v1",
    "published": "2025-05-19T08:26:17+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP",
      "35L05(Primary), 47B92(Secondary)"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12837v1",
    "title": "The Hidden Structure -- Improving Legal Document Understanding Through Explicit Text Formatting",
    "authors": [
      "Christian Braun",
      "Alexander Lilienbeck",
      "Daniel Mentjukov"
    ],
    "abstract": "Legal contracts possess an inherent, semantically vital structure (e.g.,\nsections, clauses) that is crucial for human comprehension but whose impact on\nLLM processing remains under-explored. This paper investigates the effects of\nexplicit input text structure and prompt engineering on the performance of\nGPT-4o and GPT-4.1 on a legal question-answering task using an excerpt of the\nCUAD. We compare model exact-match accuracy across various input formats:\nwell-structured plain-text (human-generated from CUAD), plain-text cleaned of\nline breaks, extracted plain-text from Azure OCR, plain-text extracted by\nGPT-4o Vision, and extracted (and interpreted) Markdown (MD) from GPT-4o\nVision. To give an indication of the impact of possible prompt engineering, we\nassess the impact of shifting task instructions to the system prompt and\nexplicitly informing the model about the structured nature of the input. Our\nfindings reveal that GPT-4o demonstrates considerable robustness to variations\nin input structure, but lacks in overall performance. Conversely, GPT-4.1's\nperformance is markedly sensitive; poorly structured inputs yield suboptimal\nresults (but identical with GPT-4o), while well-structured formats (original\nCUAD text, GPT-4o Vision text and GPT-4o MD) improve exact-match accuracy by\n~20 percentage points. Optimizing the system prompt to include task details and\nan advisory about structured input further elevates GPT-4.1's accuracy by an\nadditional ~10-13 percentage points, with Markdown ultimately achieving the\nhighest performance under these conditions (79 percentage points overall\nexact-match accuracy). This research empirically demonstrates that while newer\nmodels exhibit greater resilience, careful input structuring and strategic\nprompt design remain critical for optimizing the performance of LLMs, and can\nsignificantly affect outcomes in high-stakes legal applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.12837v1",
    "published": "2025-05-19T08:25:21+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12836v1",
    "title": "The Gaussian Latent Machine: Efficient Prior and Posterior Sampling for Inverse Problems",
    "authors": [
      "Muhamed Kuric",
      "Martin Zach",
      "Andreas Habring",
      "Michael Unser",
      "Thomas Pock"
    ],
    "abstract": "We consider the problem of sampling from a product-of-experts-type model that\nencompasses many standard prior and posterior distributions commonly found in\nBayesian imaging. We show that this model can be easily lifted into a novel\nlatent variable model, which we refer to as a Gaussian latent machine. This\nleads to a general sampling approach that unifies and generalizes many existing\nsampling algorithms in the literature. Most notably, it yields a highly\nefficient and effective two-block Gibbs sampling approach in the general case,\nwhile also specializing to direct sampling algorithms in particular cases.\nFinally, we present detailed numerical experiments that demonstrate the\nefficiency and effectiveness of our proposed sampling approach across a wide\nrange of prior and posterior sampling problems from Bayesian imaging.",
    "pdf_url": "http://arxiv.org/pdf/2505.12836v1",
    "published": "2025-05-19T08:21:23+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG",
      "stat.ML",
      "65C40, 65C05, 68U10, 65C60"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12835v1",
    "title": "FlightGPT: Towards Generalizable and Interpretable UAV Vision-and-Language Navigation with Vision-Language Models",
    "authors": [
      "Hengxing Cai",
      "Jinhan Dong",
      "Jingjun Tan",
      "Jingcheng Deng",
      "Sihang Li",
      "Zhifeng Gao",
      "Haidong Wang",
      "Zicheng Su",
      "Agachai Sumalee",
      "Renxin Zhong"
    ],
    "abstract": "Unmanned Aerial Vehicle (UAV) Vision-and-Language Navigation (VLN) is vital\nfor applications such as disaster response, logistics delivery, and urban\ninspection. However, existing methods often struggle with insufficient\nmultimodal fusion, weak generalization, and poor interpretability. To address\nthese challenges, we propose FlightGPT, a novel UAV VLN framework built upon\nVision-Language Models (VLMs) with powerful multimodal perception capabilities.\nWe design a two-stage training pipeline: first, Supervised Fine-Tuning (SFT)\nusing high-quality demonstrations to improve initialization and structured\nreasoning; then, Group Relative Policy Optimization (GRPO) algorithm, guided by\na composite reward that considers goal accuracy, reasoning quality, and format\ncompliance, to enhance generalization and adaptability. Furthermore, FlightGPT\nintroduces a Chain-of-Thought (CoT)-based reasoning mechanism to improve\ndecision interpretability. Extensive experiments on the city-scale dataset\nCityNav demonstrate that FlightGPT achieves state-of-the-art performance across\nall scenarios, with a 9.22\\% higher success rate than the strongest baseline in\nunseen environments. Our implementation is publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.12835v1",
    "published": "2025-05-19T08:21:20+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12834v1",
    "title": "A Study on the Refining Handwritten Font by Mixing Font Styles",
    "authors": [
      "Avinash Kumar",
      "Kyeolhee Kang",
      "Ammar ul Hassan",
      "Jaeyoung Choi"
    ],
    "abstract": "Handwritten fonts have a distinct expressive character, but they are often\ndifficult to read due to unclear or inconsistent handwriting. FontFusionGAN\n(FFGAN) is a novel method for improving handwritten fonts by combining them\nwith printed fonts. Our method implements generative adversarial network (GAN)\nto generate font that mix the desirable features of handwritten and printed\nfonts. By training the GAN on a dataset of handwritten and printed fonts, it\ncan generate legible and visually appealing font images. We apply our method to\na dataset of handwritten fonts and demonstrate that it significantly enhances\nthe readability of the original fonts while preserving their unique aesthetic.\nOur method has the potential to improve the readability of handwritten fonts,\nwhich would be helpful for a variety of applications including document\ncreation, letter writing, and assisting individuals with reading and writing\ndifficulties. In addition to addressing the difficulties of font creation for\nlanguages with complex character sets, our method is applicable to other\ntext-image-related tasks, such as font attribute control and multilingual font\nstyle transfer.",
    "pdf_url": "http://arxiv.org/pdf/2505.12834v1",
    "published": "2025-05-19T08:20:43+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12833v1",
    "title": "Reasoning BO: Enhancing Bayesian Optimization with Long-Context Reasoning Power of LLMs",
    "authors": [
      "Zhuo Yang",
      "Lingli Ge",
      "Dong Han",
      "Tianfan Fu",
      "Yuqiang Li"
    ],
    "abstract": "Many real-world scientific and industrial applications require the\noptimization of expensive black-box functions. Bayesian Optimization (BO)\nprovides an effective framework for such problems. However, traditional BO\nmethods are prone to get trapped in local optima and often lack interpretable\ninsights. To address this issue, this paper designs Reasoning BO, a novel\nframework that leverages reasoning models to guide the sampling process in BO\nwhile incorporating multi-agent systems and knowledge graphs for online\nknowledge accumulation. By integrating the reasoning and contextual\nunderstanding capabilities of Large Language Models (LLMs), we can provide\nstrong guidance to enhance the BO process. As the optimization progresses,\nReasoning BO provides real-time sampling recommendations along with critical\ninsights grounded in plausible scientific theories, aiding in the discovery of\nsuperior solutions within the search space. We systematically evaluate our\napproach across 10 diverse tasks encompassing synthetic mathematical functions\nand complex real-world applications. The framework demonstrates its capability\nto progressively refine sampling strategies through real-time insights and\nhypothesis evolution, effectively identifying higher-performing regions of the\nsearch space for focused exploration. This process highlights the powerful\nreasoning and context-learning abilities of LLMs in optimization scenarios. For\nexample, in the Direct Arylation task, our method increased the yield to 60.7%,\nwhereas traditional BO achieved only a 25.2% yield. Furthermore, our\ninvestigation reveals that smaller LLMs, when fine-tuned through reinforcement\nlearning, can attain comparable performance to their larger counterparts. This\nenhanced reasoning capability paves the way for more efficient automated\nscientific experimentation while maintaining computational feasibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.12833v1",
    "published": "2025-05-19T08:20:40+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12832v1",
    "title": "A Study on Distributed Strategies for Deep Learning Applications in GPU Clusters",
    "authors": [
      "Md Sultanul Islam Ovi"
    ],
    "abstract": "As deep learning models grow in size and complexity, training them\nefficiently on single GPUs becomes increasingly infeasible. This study\ninvestigates the effectiveness of several distributed training\nstrategies-Distributed Data Parallel (DDP), Fully Sharded Data Parallelism\n(FSDP), and Parameter Server (PS) models-for scalable deep learning on GPU\nclusters. We conduct empirical evaluations across multiple models and datasets\nto assess trade-offs in memory usage, training time, GPU utilization, and model\naccuracy. Our results show that while FSDP reduces GPU memory usage by over\n60%, it increases training time by up to 6x compared to DDP. In contrast,\nasynchronous PS training improves throughput but can lead to degraded accuracy\ndue to stale updates. Through comprehensive analysis, we provide practical\ninsights into the strengths and limitations of each strategy, offering guidance\nfor selecting suitable methods based on system constraints and training\nobjectives.",
    "pdf_url": "http://arxiv.org/pdf/2505.12832v1",
    "published": "2025-05-19T08:19:47+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12831v1",
    "title": "Contrastive Prompting Enhances Sentence Embeddings in LLMs through Inference-Time Steering",
    "authors": [
      "Zifeng Cheng",
      "Zhonghui Wang",
      "Yuchen Fu",
      "Zhiwei Jiang",
      "Yafeng Yin",
      "Cong Wang",
      "Qing Gu"
    ],
    "abstract": "Extracting sentence embeddings from large language models (LLMs) is a\npractical direction, as it requires neither additional data nor fine-tuning.\nPrevious studies usually focus on prompt engineering to guide LLMs to encode\nthe core semantic information of the sentence into the embedding of the last\ntoken. However, the last token in these methods still encodes an excess of\nnon-essential information, such as stop words, limiting its encoding capacity.\nTo this end, we propose a Contrastive Prompting (CP) method that introduces an\nextra auxiliary prompt to elicit better sentence embedding. By contrasting with\nthe auxiliary prompt, CP can steer existing prompts to encode the core\nsemantics of the sentence, rather than non-essential information. CP is a\nplug-and-play inference-time intervention method that can be combined with\nvarious prompt-based methods. Extensive experiments on Semantic Textual\nSimilarity (STS) tasks and downstream classification tasks demonstrate that our\nmethod can improve the performance of existing prompt-based methods across\ndifferent LLMs. Our code will be released at https://github.com/zifengcheng/CP.",
    "pdf_url": "http://arxiv.org/pdf/2505.12831v1",
    "published": "2025-05-19T08:19:27+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12830v1",
    "title": "2T1R Regulated Memristor Conductance Control Array Architecture for Neuromorphic Computing using 28nm CMOS Technology",
    "authors": [
      "Neethu Kuriakose",
      "Arun Ashok",
      "Christian Grewing",
      "Andr√© Zambanini",
      "Stefan van Waasen"
    ],
    "abstract": "Memristors are promising devices for scalable and low power, in-memory\ncomputing to improve the energy efficiency of a rising computational demand.\nThe crossbar array architecture with memristors is used for vector matrix\nmultiplication (VMM) and acts as kernels in neuromorphic computing. The analog\nconductance control in a memristor is achieved by applying voltage or current\nthrough it. A basic 1T1R array is suitable to avoid sneak path issues but\nsuffer from wire resistances, which affects the read and write procedures. A\nconductance control scheme with a regulated voltage source will improve the\narchitecture and reduce the possible potential divider effects. A change in\nconductance is also possible with the provision of a regulated current source\nand measuring the voltage across the memristors. A regulated 2T1R memristor\nconductance control architecture is proposed in this work, which avoids the\npotential divider effect and virtual ground scenario in a regular crossbar\nscheme, as well as conductance control by passing a regulated current through\nmemristors. The sneak path current is not allowed to pass by the provision of\nground potential to both terminals of memristors.",
    "pdf_url": "http://arxiv.org/pdf/2505.12830v1",
    "published": "2025-05-19T08:16:47+00:00",
    "categories": [
      "cs.ET",
      "cs.AR",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.12829v1",
    "title": "Algebro-combinatorial generalizations of the Victoir method for constructing weighted designs",
    "authors": [
      "Hiroshi Nozaki",
      "Masanori Sawa"
    ],
    "abstract": "A weighted $t$-design in $\\mathbb{R}^d$ is a finite weighted set that exactly\nintegrates all polynomials of degree at most $t$ with respect to a given\nprobability measure. A fundamental problem is to construct weighted $t$-designs\nwith as few points as possible. Victoir (2004) proposed a method to reduce the\nsize of weighted $t$-designs while preserving the $t$-design property by using\ncombinatorial objects such as combinatorial designs or orthogonal arrays with\ntwo levels. In this paper, we give an algebro-combinatorial generalization of\nboth Victoir's method and its variant by the present authors (2014) in the\nframework of Euclidean polynomial spaces, enabling us to reduce the size of\nweighted designs obtained from the classical product rule. Our generalization\nallows the use of orthogonal arrays with arbitrary levels, whereas Victoir only\ntreated the case of two levels. As an application, we present a construction of\nequi-weighted $5$-designs with $O(d^4)$ points for product measures such as\nGaussian measure $\\pi^{-d/2} e^{-\\sum_{i=1}^d x_i^2} dx_1 \\cdots dx_d$ on\n$\\mathbb{R}^d$ or equilibrium measure $\\pi^{-d} \\prod_{i=1}^d (1-x_i^2)^{-1/2}\ndx_1 \\cdots dx_d$ on $(-1,1)^d$, where $d$ is any integer at least 5. The\nconstruction is explicit and does not rely on numerical approximations.\nMoreover, we establish an existence theorem of Gaussian $t$-designs with $N$\npoints for any $t \\geq 2$, where $N< q^{t}d^{t-1}=O(d^{t-1})$ for fixed\nsufficiently large prime power $q$. As a corollary of this result, we give an\nimprovement of a famous theorem by Milman (1988) on isometric embeddings of the\nclassical finite-dimensional Banach spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.12829v1",
    "published": "2025-05-19T08:15:36+00:00",
    "categories": [
      "math.CO",
      "65D32, 05B15, 05E30"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12828v1",
    "title": "Exploring the spectroscopic features of double-strangeness tetraquark states",
    "authors": [
      "Xuejie Liu",
      "Haoming Zheng",
      "Dianyong Chen",
      "Hongxia Huang",
      "Jialun Ping"
    ],
    "abstract": "Since the discovery of the $T_{cc}$ double-charm tetaquark by the LHCb\ncollaboration, the field of the theoretical research on heavy quarks has\nadvanced rapidly, with increasing interest in exploring the light quark sector.\nIn this study, the quark model is employed to systematically analyze the\ndouble-strange tetraquark system. Both the meson-meson configuration and\ndiquark-antidiquark configuration are considered. The interactions between\nhadron pairs under various quantum numbers, as well as the possibilities of\nbound states and resonances, are evaluated. The results indicate the presence\nof two bound states, $ \\bar{K}^{\\ast }\\bar{K}$ and $\\bar{K}^{\\ast\n}\\bar{K}^{\\ast}$, with quantum number $I(J^{P})=0(1^{+})$ in single-channel\nestimations. Additionally, by considering the channel coupling between the two\nconfigurations, a bound state with quantum numbers $I(J^{P})=0(1^{+})$ and a\nmass of approximately $1310$ MeV is obtained. Moreover, through the application\nof Resonance Ground Method, a resonance state is identified in the\n$I(J^{P})=0(1^{+})$ $\\ssqq$ system, with an estimated mass of around 1783 MeV\nand a decay width of approximately 17 MeV.",
    "pdf_url": "http://arxiv.org/pdf/2505.12828v1",
    "published": "2025-05-19T08:13:05+00:00",
    "categories": [
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12827v3",
    "title": "Practical Equivalence Testing and Its Application in Synthetic Pre-Crash Scenario Validation",
    "authors": [
      "Jian Wu",
      "Ulrich Sander",
      "Carol Flannagan",
      "Minxiang Zhao",
      "Jonas B√§rgman"
    ],
    "abstract": "The use of representative pre-crash scenarios is critical for assessing the\nsafety impact of driving automation systems through simulation. However, a gap\nremains in the robust evaluation of the similarity between synthetic and\nreal-world pre-crash scenarios and their crash characteristics. Without proper\nvalidation, it cannot be ensured that the synthetic test scenarios adequately\nrepresent real-world driving behaviors and crash characteristics. One reason\nfor this validation gap is the lack of focus on methods to confirm that the\nsynthetic test scenarios are practically equivalent to real-world ones, given\nthe assessment scope. Traditional statistical methods, like significance\ntesting, focus on detecting differences rather than establishing equivalence;\nsince failure to detect a difference does not imply equivalence, they are of\nlimited applicability for validating synthetic pre-crash scenarios and crash\ncharacteristics. This study addresses this gap by proposing an equivalence\ntesting method based on the Bayesian Region of Practical Equivalence (ROPE)\nframework. This method is designed to assess the practical equivalence of\nscenario characteristics that are most relevant for the intended assessment,\nmaking it particularly appropriate for the domain of virtual safety\nassessments. We first review existing equivalence testing methods. Then we\npropose and demonstrate the Bayesian ROPE-based method by testing the\nequivalence of two rear-end pre-crash datasets. Our approach focuses on the\nmost relevant scenario characteristics. Our analysis provides insights into the\npracticalities and effectiveness of equivalence testing in synthetic test\nscenario validation and demonstrates the importance of testing for improving\nthe credibility of synthetic data for automated vehicle safety assessment, as\nwell as the credibility of subsequent safety impact assessments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12827v3",
    "published": "2025-05-19T08:12:35+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12826v1",
    "title": "Mitigating Hallucination in VideoLLMs via Temporal-Aware Activation Engineering",
    "authors": [
      "Jianfeng Cai",
      "Wengang Zhou",
      "Zongmeng Zhang",
      "Jiale Hong",
      "Nianji Zhan",
      "Houqiang Li"
    ],
    "abstract": "Multimodal large language models (MLLMs) have achieved remarkable progress in\nvideo understanding.However, hallucination, where the model generates plausible\nyet incorrect outputs, persists as a significant and under-addressed challenge\nin the video domain. Among existing solutions, activation engineering has\nproven successful in mitigating hallucinations in LLMs and ImageLLMs, yet its\napplicability to VideoLLMs remains largely unexplored. In this work, we are the\nfirst to systematically investigate the effectiveness and underlying mechanisms\nof activation engineering for mitigating hallucinations in VideoLLMs. We\ninitially conduct an investigation of the key factors affecting the performance\nof activation engineering and find that a model's sensitivity to hallucination\ndepends on $\\textbf{temporal variation}$ rather than task type. Moreover,\nselecting appropriate internal modules and dataset for activation engineering\nis critical for reducing hallucination. Guided by these findings, we propose a\ntemporal-aware activation engineering framework for VideoLLMs, which adaptively\nidentifies and manipulates hallucination-sensitive modules based on the\ntemporal variation characteristic, substantially mitigating hallucinations\nwithout additional LLM fine-tuning. Experiments across multiple models and\nbenchmarks demonstrate that our method markedly reduces hallucination in\nVideoLLMs, thereby validating the robustness of our findings.",
    "pdf_url": "http://arxiv.org/pdf/2505.12826v1",
    "published": "2025-05-19T08:12:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12825v1",
    "title": "Theoretical Investigation on Inductive Bias of Isolation Forest",
    "authors": [
      "Qin-Cheng Zheng",
      "Shao-Qun Zhang",
      "Shen-Huan Lyu",
      "Yuan Jiang",
      "Zhi-Hua Zhou"
    ],
    "abstract": "Isolation Forest (iForest) stands out as a widely-used unsupervised anomaly\ndetector valued for its exceptional runtime efficiency and performance on\nlarge-scale tasks. Despite its widespread adoption, a theoretical foundation\nexplaining iForest's success remains unclear. This paper theoretically\ninvestigates the conditions and extent of iForest's effectiveness by analyzing\nits inductive bias through the formulation of depth functions and growth\nprocesses. Since directly analyzing the depth function proves intractable due\nto iForest's random splitting mechanism, we model the growth process of iForest\nas a random walk, enabling us to derive the expected depth function using\ntransition probabilities. Our case studies reveal key inductive biases: iForest\nexhibits lower sensitivity to central anomalies while demonstrating greater\nparameter adaptability compared to $k$-Nearest Neighbor anomaly detectors. Our\nstudy provides theoretical understanding of the effectiveness of iForest and\nestablishes a foundation for further theoretical exploration.",
    "pdf_url": "http://arxiv.org/pdf/2505.12825v1",
    "published": "2025-05-19T08:07:43+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12824v3",
    "title": "The Modal Cube Revisited: Semantics without Worlds (Technical Report)",
    "authors": [
      "Renato Leme",
      "Carlos Olarte",
      "Elaine Pimentel",
      "Marcelo E. Coniglio"
    ],
    "abstract": "We present a non-deterministic semantic framework for all modal logics in the\nmodal cube, extending prior works by Kearns and others. Our approach introduces\nmodular and uniform multi-valued non-deterministic matrices (Nmatrices) for\neach logic, where necessitation is captured by the systematic use of level\nvaluations. The semantics is grounded in an eight-valued system and provides a\nsound and complete decision procedure for each modal logic, extending and\nrefining earlier semantics as particular cases. Additionally, we propose a\nnovel model-theoretic perspective that links our framework to relational\n(Kripke-style) semantics, addressing longstanding conjectures regarding the\ncorrespondence between modal axioms and semantic conditions within\nnon-deterministic settings. The result is a philosophically robust and\ntechnically modular alternative to standard possible-world semantics.",
    "pdf_url": "http://arxiv.org/pdf/2505.12824v3",
    "published": "2025-05-19T08:07:26+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12823v2",
    "title": "$Œª$-matchability in cubic graphs",
    "authors": [
      "Santhosh Raghul",
      "Nishad Kothari"
    ],
    "abstract": "Sch\\\"onberger (1934) showed that every 2-connected cubic graph is matching\ncovered. For a vertex $v$ of a 2-connected cubic graph $G$, a $v$-matching is a\nspanning subgraph in which $v$ has degree three whereas every other vertex has\ndegree one; we say that $v$ is $\\lambda$-matchable if $G$ admits a\n$v$-matching, and we let $\\lambda(G)$ denote the number of such vertices.\nClearly, no vertex is $\\lambda$-matchable in bipartite graphs; we instead\nconsider $\\lambda$-matchable pairs defined analogously; we let $\\rho$ denote\nthe number of such pairs.\n  Chen, Lu and Zhang [Discrete Math., 2025] studied $\\lambda$-matchability and\nshowed constants lower bounds on $\\lambda$ and $\\rho$. We establish stronger\nlower bounds that feature matching-theoretic invariants that arise from the\nwork of Lov\\'asz.\n  Lov\\'asz [J. Combin. Theory Ser. B, 1987] proved that every matching covered\ngraph $G$ admits a `unique decomposition' into special ones called `braces'\n(bipartite) and `bricks' (nonbipartite); $b(G)$ denotes the number of its\nbricks, $\\beta(G)$ denotes the sum of the orders of its bricks, $b'(G)$ denotes\nthe number of its braces of order six or more, and $\\beta'(G):=\\sum\n\\left(\\frac{n(H)}{2}\\right)^2$, wherein the sum is over all its braces $H$ of\norder six or more.\n  We prove that 3-connected cubic graphs satisfy $\\lambda \\geq \\beta$, and that\nthe bipartite ones satisfy $\\rho \\geq \\beta'+3b'-3 \\geq 3n-9$. We use the fact\nthat every 2-connected cubic graph admits a `unique decomposition' into\n3-connected ones to extend our bounds. We show that the same bound $\\lambda\n\\geq \\beta$ holds for all 2-connected cubic graphs, and we also characterize\nthose that satisfy $\\lambda=n$. Our generalized lower bounds on $\\rho$, in the\ncase of bipartite graphs, feature invariants that rely on the aforementioned\ndecomposition. For each bound, we characterize all tight examples.",
    "pdf_url": "http://arxiv.org/pdf/2505.12823v2",
    "published": "2025-05-19T08:06:30+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12822v2",
    "title": "Emergent Specialization: Rare Token Neurons in Language Models",
    "authors": [
      "Jing Liu",
      "Haozheng Wang",
      "Yueheng Li"
    ],
    "abstract": "Large language models struggle with representing and generating rare tokens\ndespite their importance in specialized domains. In this study, we identify\nneuron structures with exceptionally strong influence on language model's\nprediction of rare tokens, termed as rare token neurons, and investigate the\nmechanism for their emergence and behavior. These neurons exhibit a\ncharacteristic three-phase organization (plateau, power-law, and rapid decay)\nthat emerges dynamically during training, evolving from a homogeneous initial\nstate to a functionally differentiated architecture. In the activation space,\nrare token neurons form a coordinated subnetwork that selectively co-activates\nwhile avoiding co-activation with other neurons. This functional specialization\npotentially correlates with the development of heavy-tailed weight\ndistributions, suggesting a statistical mechanical basis for emergent\nspecialization.",
    "pdf_url": "http://arxiv.org/pdf/2505.12822v2",
    "published": "2025-05-19T08:05:13+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12821v1",
    "title": "SynDec: A Synthesize-then-Decode Approach for Arbitrary Textual Style Transfer via Large Language Models",
    "authors": [
      "Han Sun",
      "Zhen Sun",
      "Zongmin Zhang",
      "Linzhao Jia",
      "Wei Shao",
      "Min Zhang"
    ],
    "abstract": "Large Language Models (LLMs) are emerging as dominant forces for textual\nstyle transfer. However, for arbitrary style transfer, LLMs face two key\nchallenges: (1) considerable reliance on manually-constructed prompts and (2)\nrigid stylistic biases inherent in LLMs. In this paper, we propose a novel\nSynthesize-then-Decode (SynDec) approach, which automatically synthesizes\nhigh-quality prompts and amplifies their roles during decoding process.\nSpecifically, our approach synthesizes prompts by selecting representative\nfew-shot samples, conducting a four-dimensional style analysis, and reranking\nthe candidates. At LLM decoding stage, the TST effect is amplified by\nmaximizing the contrast in output probabilities between scenarios with and\nwithout the synthesized prompt, as well as between prompts and negative\nsamples. We conduct extensive experiments and the results show that SynDec\noutperforms existing state-of-the-art LLM-based methods on five out of six\nbenchmarks (e.g., achieving up to a 9\\% increase in accuracy for\nmodern-to-Elizabethan English transfer). Detailed ablation studies further\nvalidate the effectiveness of SynDec.",
    "pdf_url": "http://arxiv.org/pdf/2505.12821v1",
    "published": "2025-05-19T08:03:38+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12820v1",
    "title": "Rethinking Features-Fused-Pyramid-Neck for Object Detection",
    "authors": [
      "Hulin Li"
    ],
    "abstract": "Multi-head detectors typically employ a features-fused-pyramid-neck for\nmulti-scale detection and are widely adopted in the industry. However, this\napproach faces feature misalignment when representations from different\nhierarchical levels of the feature pyramid are forcibly fused point-to-point.\nTo address this issue, we designed an independent hierarchy pyramid (IHP)\narchitecture to evaluate the effectiveness of the features-unfused-pyramid-neck\nfor multi-head detectors. Subsequently, we introduced soft nearest neighbor\ninterpolation (SNI) with a weight downscaling factor to mitigate the impact of\nfeature fusion at different hierarchies while preserving key textures.\nFurthermore, we present a features adaptive selection method for down sampling\nin extended spatial windows (ESD) to retain spatial features and enhance\nlightweight convolutional techniques (GSConvE). These advancements culminate in\nour secondary features alignment solution (SA) for real-time detection,\nachieving state-of-the-art results on Pascal VOC and MS COCO. Code will be\nreleased at https://github.com/AlanLi1997/rethinking-fpn. This paper has been\naccepted by ECCV2024 and published on Springer Nature.",
    "pdf_url": "http://arxiv.org/pdf/2505.12820v1",
    "published": "2025-05-19T08:01:11+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12819v1",
    "title": "Theory of charge-to-spin conversion under quantum confinement",
    "authors": [
      "Alfonso Maiellaro",
      "Francesco Romeo",
      "Mattia Trama",
      "Irene Gaiardoni",
      "Jacopo Settino",
      "Claudio Guarcello",
      "Nicolas Bergeal",
      "Manuel Bibes",
      "Roberta Citro"
    ],
    "abstract": "The interplay between spin and charge degrees of freedom in low-dimensional\nsystems is a cornerstone of modern spintronics, where achieving all-electrical\ncontrol of spin currents is a major goal. Spin-orbit interactions provide a\npromising mechanism for such control, yet understanding how spin and charge\ntransport emerge from microscopic principles remains a fundamental challenge.\nHere we develop a spin-dependent scattering matrix approach to describe spin\nand charge transport in a multiterminal system in the presence of Rashba\nspin-orbit interaction. Our framework generalizes the B\\\"uttiker formalism by\noffering explicit real-space expressions for spin and charge current densities,\nalong with the corresponding linear response function. It simultaneously\ncaptures the effects of quantum confinement, the orbital response to external\nmagnetic fields, and the intrinsic (geometric) properties of the electronic\nbands, offering a comprehensive description of the spin-charge interconversion\nmechanisms at play in a Hall bar, in agreement with experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12819v1",
    "published": "2025-05-19T08:00:12+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.12818v1",
    "title": "Near-wall turbulence and transitional behavior on the rib-roughened surfaces",
    "authors": [
      "Ranjan Kushwaha",
      "S. Sarkar",
      "Gautam Biswas"
    ],
    "abstract": "This study utilizes Large Eddy Simulation (LES) to investigate the impact of\nlongitudinal triangular riblets on the laminar-to-turbulent transition in\nboundary layer flow. Five cases are examined: one involving a flat plate and\nfour with ribbed plates. Among the ribbed cases, three use a riblet aspect\nratio of two, whereas one has an aspect ratio of one. Arrays of longitudinal\ntriangular riblets are positioned on a flat plate, and the transition to\nturbulence is initiated by controlled excitation of a Tollmien-Schlichting (TS)\nwave imposed on a Blasius velocity profile in a stable region. The longitudinal\ntriangular riblets attenuate the TS wave, leading to a lower growth rate of\nturbulence. For higher riblet height ($h$) and width ($w$), with inner-scaled\ndimensions $h^+ = 25$, $w^+ = S^+ = 50$ (where $S$ is the spacing between two\nriblets), an early transition is triggered by high-frequency disturbances\ngenerated at the leading edge of the roughness elements. However, increasing\nriblet spacing to $S^+ = 75$ delays the transition by 17.5 percent. Both cases\nexhibited increased drag compared to the flat plate. For $h^+ = 12.5$ and $w^+\n= S^+ = 25$, transition was delayed by 37 percent, with a modest overall drag\nreduction of 8.8 percent. The most significant result from the considered\ncases, $h^+ = w^+ = S^+ = 12.5$, showed a 47 percent delay in transition and a\n13.69 percent reduction in overall drag. Smaller riblets cause minimal\ndisturbance at the leading edge of roughness, resulting in a transition\nmechanism similar to a flat plate, while also reducing pressure loss, secondary\nflows, and velocity fluctuations.",
    "pdf_url": "http://arxiv.org/pdf/2505.12818v1",
    "published": "2025-05-19T07:59:30+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.12817v2",
    "title": "The log-concavity of eigenfunction to complex Monge-Amp√®re operator in $\\mathbb{C}^2$",
    "authors": [
      "Wei Zhang",
      "Qi Zhou"
    ],
    "abstract": "Following the authors' recent work \\cite{Zhang-Zhou2025}, we further explore\nthe convexity properties of solutions to the Dirichlet problem for the complex\nMonge-Amp\\`ere operator. In this paper, we establish the $\\log$-concavity of\nsolutions to the Dirichlet eigenvalue problem for the complex Monge-Amp\\`ere\noperator on bounded, smooth, strictly convex domain in $\\mathbb{C}^2$. The key\ningredients consist of the constant rank theorem and the deformation method.",
    "pdf_url": "http://arxiv.org/pdf/2505.12817v2",
    "published": "2025-05-19T07:58:10+00:00",
    "categories": [
      "math.AP",
      "35B50, 32W20"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12816v1",
    "title": "The polynomial potential inflation in light of ACT observations",
    "authors": [
      "Zhi-Zhang Peng",
      "Zu-Cheng Chen",
      "Lang Liu"
    ],
    "abstract": "The recent measurements from the Atacama Cosmology Telescope (ACT) favor a\nhigher value of the scalar spectral index $n_s$ compared to the Planck data,\nchallenging many well-established inflationary models. In this work, we\ninvestigate the viability of polynomial potential inflation in light of the\nlatest ACT data, focusing on the quadratic ($n=2$) and cubic ($n=3$) models. By\nexploring the parameter space and deriving constraints on the model\ncoefficients, we find that the cubic model can provide a good fit to the data,\nwhile the quadratic model struggles to simultaneously accommodate the ACT data\nand the requirement of sufficient inflation. Our findings show that\nhigher-order polynomial potentials remain viable for describing cosmic\ninflation, demonstrating how recent precision measurements continue to refine\nour understanding of the early Universe.",
    "pdf_url": "http://arxiv.org/pdf/2505.12816v1",
    "published": "2025-05-19T07:56:29+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12815v1",
    "title": "Learning in Chaos: Efficient Autoscaling and Self-healing for Distributed Training at the Edge",
    "authors": [
      "Wenjiao Feng",
      "Rongxing Xiao",
      "Zonghang Li",
      "Hongfang Yu",
      "Gang Sun",
      "Long Luo",
      "Mohsen Guizani",
      "Qirong Ho"
    ],
    "abstract": "Frequent node and link changes in edge AI clusters disrupt distributed\ntraining, while traditional checkpoint-based recovery and cloud-centric\nautoscaling are too slow for scale-out and ill-suited to chaotic and\nself-governed edge. This paper proposes Chaos, a resilient and scalable edge\ndistributed training system with built-in self-healing and autoscaling. It\nspeeds up scale-out by using multi-neighbor replication with fast shard\nscheduling, allowing a new node to pull the latest training state from nearby\nneighbors in parallel while balancing the traffic load between them. It also\nuses a cluster monitor to track resource and topology changes to assist\nscheduler decisions, and handles scaling events through peer negotiation\nprotocols, enabling fully self-governed autoscaling without a central admin.\nExtensive experiments show that Chaos consistently achieves much lower\nscale-out delays than Pollux, EDL, and Autoscaling, and handles scale-in,\nconnect-link, and disconnect-link events within 1 millisecond, making it\nsmoother to handle node joins, exits, and failures. It also delivers the lowest\nidle time, showing superior resource use and scalability as the cluster grows.",
    "pdf_url": "http://arxiv.org/pdf/2505.12815v1",
    "published": "2025-05-19T07:52:17+00:00",
    "categories": [
      "cs.DC",
      "cs.AI",
      "68T99",
      "I.2.11"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12814v1",
    "title": "PsyMem: Fine-grained psychological alignment and Explicit Memory Control for Advanced Role-Playing LLMs",
    "authors": [
      "Xilong Cheng",
      "Yunxiao Qin",
      "Yuting Tan",
      "Zhengnan Li",
      "Ye Wang",
      "Hongjiang Xiao",
      "Yuan Zhang"
    ],
    "abstract": "Existing LLM-based role-playing methods often rely on superficial textual\ndescriptions or simplistic metrics, inadequately modeling both intrinsic and\nextrinsic character dimensions. Additionally, they typically simulate character\nmemory with implicit model knowledge or basic retrieval augment generation\nwithout explicit memory alignment, compromising memory consistency. The two\nissues weaken reliability of role-playing LLMs in several applications, such as\ntrustworthy social simulation. To address these limitations, we propose PsyMem,\na novel framework integrating fine-grained psychological attributes and\nexplicit memory control for role-playing. PsyMem supplements textual\ndescriptions with 26 psychological indicators to detailed model character.\nAdditionally, PsyMem implements memory alignment training, explicitly trains\nthe model to align character's response with memory, thereby enabling dynamic\nmemory-controlled responding during inference. By training Qwen2.5-7B-Instruct\non our specially designed dataset (including 5,414 characters and 38,962\ndialogues extracted from novels), the resulting model, termed as PsyMem-Qwen,\noutperforms baseline models in role-playing, achieving the best performance in\nhuman-likeness and character fidelity.",
    "pdf_url": "http://arxiv.org/pdf/2505.12814v1",
    "published": "2025-05-19T07:45:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12813v1",
    "title": "Arithmetic properties of MacMahon-type sums of divisors: the odd case",
    "authors": [
      "James A. Sellers",
      "Roberto Tauraso"
    ],
    "abstract": "A century ago, P. A. MacMahon introduced two families of generating\nfunctions, $$ \\sum_{1\\leq\nn_1<n_2<\\cdots<n_t}\\prod_{k=1}^t\\frac{q^{n_k}}{(1-q^{n_k})^2} \\quad\\text{ and }\n\\sum_{\\substack{1\\leq n_1<n_2<\\cdots<n_t\\\\ \\text{$n_1,n_2,\\dots,n_t$\nodd}}}\\prod_{k=1}^t\\frac{q^{n_k}}{(1-q^{n_k})^2}, $$ which connect\nsum-of-divisors functions and integer partitions. These have recently drawn\nrenewed attention. In particular, Amdeberhan, Andrews, and Tauraso extended the\nfirst family above by defining $$ U_t(a,q):=\\sum_{1\\leq\nn_1<n_2<\\cdots<n_t}\\prod_{k=1}^t\\frac{q^{n_k}}{1+aq^{n_k}+q^{2n_k}} $$ for\n$a=0, \\pm1, \\pm2$ and investigated various properties, including some\ncongruences satisfied by the coefficients of the power series representations\nfor $U_t(a,q)$. These arithmetic aspects were subsequently expanded upon by the\nauthors of the present work. Our goal here is to generalize the second family\nof generating functions, where the sums run over odd integers, and then apply\nsimilar techniques to show new infinite families of Ramanujan--like congruences\nfor the associated power series coefficients.",
    "pdf_url": "http://arxiv.org/pdf/2505.12813v1",
    "published": "2025-05-19T07:43:07+00:00",
    "categories": [
      "math.NT",
      "math.CO",
      "11P83, 11P81, 05A17"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12812v1",
    "title": "Connecting the Equinoctial Elements and Rodrigues Parameters: A New Set of Elements",
    "authors": [
      "Joseph T. A. Peterson",
      "Vishala Arya",
      "John L. Junkins"
    ],
    "abstract": "A geometric interpretation of the equinoctial elements is given with a\nconnection to orthogonal rotations and attitude dynamics in Euclidean 3-space.\nAn identification is made between the equinoctial elements and classic\nRodrigues parameters. A new set of equinoctial elements are developed using the\nmodified Rodrigues parameters, thereby removing the coordinate singularity for\nretrograde equatorial orbits present in previous versions of these elements. A\nlow-thrust trajectory optimization problem is set up using the new elements to\nnumerically verify convergence for the two-point boundary problem, as compared\nto their predecessors.",
    "pdf_url": "http://arxiv.org/pdf/2505.12812v1",
    "published": "2025-05-19T07:41:26+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.DS",
      "math.OC",
      "physics.class-ph"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.12811v1",
    "title": "Dynamic Sight Range Selection in Multi-Agent Reinforcement Learning",
    "authors": [
      "Wei-Chen Liao",
      "Ti-Rong Wu",
      "I-Chen Wu"
    ],
    "abstract": "Multi-agent reinforcement Learning (MARL) is often challenged by the sight\nrange dilemma, where agents either receive insufficient or excessive\ninformation from their environment. In this paper, we propose a novel method,\ncalled Dynamic Sight Range Selection (DSR), to address this issue. DSR utilizes\nan Upper Confidence Bound (UCB) algorithm and dynamically adjusts the sight\nrange during training. Experiment results show several advantages of using DSR.\nFirst, we demonstrate using DSR achieves better performance in three common\nMARL environments, including Level-Based Foraging (LBF), Multi-Robot Warehouse\n(RWARE), and StarCraft Multi-Agent Challenge (SMAC). Second, our results show\nthat DSR consistently improves performance across multiple MARL algorithms,\nincluding QMIX and MAPPO. Third, DSR offers suitable sight ranges for different\ntraining steps, thereby accelerating the training process. Finally, DSR\nprovides additional interpretability by indicating the optimal sight range used\nduring training. Unlike existing methods that rely on global information or\ncommunication mechanisms, our approach operates solely based on the individual\nsight ranges of agents. This approach offers a practical and efficient solution\nto the sight range dilemma, making it broadly applicable to real-world complex\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12811v1",
    "published": "2025-05-19T07:40:42+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12810v1",
    "title": "Ergodic properties of concurrent systems",
    "authors": [
      "Samy Abbes",
      "Vincent Jug√©"
    ],
    "abstract": "A concurrent system is defined as a monoid action of a trace monoid on a\nfinite set of states. Concurrent systems represent state models where the state\nis distributed and where state changes are local. Starting from a spectral\nproperty on the combinatorics of concurrent systems, we prove the existence and\nuniqueness of a Markov measure on the space of infinite trajectories relatively\nto any weight distributions. In turn, we obtain a combinatorial result by\nproving that the kernel of the associated M\\\"obius matrix has dimension 1; the\nM\\\"obius matrix extends in this context the M\\\"obius polynomial of a trace\nmonoid. We study ergodic properties of irreducible concurrent systems and we\nprove a Strong law of large numbers. It allows us to introduce the speedup as a\nmeasurement of the average amount of concurrency within infinite trajectories.\nExamples are studied.",
    "pdf_url": "http://arxiv.org/pdf/2505.12810v1",
    "published": "2025-05-19T07:40:25+00:00",
    "categories": [
      "math.PR",
      "cs.DM",
      "math.GR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12809v1",
    "title": "Koopman Autoencoders Learn Neural Representation Dynamics",
    "authors": [
      "Nishant Suresh Aswani",
      "Saif Eddin Jabari"
    ],
    "abstract": "This paper explores a simple question: can we model the internal\ntransformations of a neural network using dynamical systems theory? We\nintroduce Koopman autoencoders to capture how neural representations evolve\nthrough network layers, treating these representations as states in a dynamical\nsystem. Our approach learns a surrogate model that predicts how neural\nrepresentations transform from input to output, with two key advantages. First,\nby way of lifting the original states via an autoencoder, it operates in a\nlinear space, making editing the dynamics straightforward. Second, it preserves\nthe topologies of the original representations by regularizing the autoencoding\nobjective. We demonstrate that these surrogate models naturally replicate the\nprogressive topological simplification observed in neural networks. As a\npractical application, we show how our approach enables targeted class\nunlearning in the Yin-Yang and MNIST classification tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12809v1",
    "published": "2025-05-19T07:35:43+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12808v1",
    "title": "Decentralized Arena: Towards Democratic and Scalable Automatic Evaluation of Language Models",
    "authors": [
      "Yanbin Yin",
      "Kun Zhou",
      "Zhen Wang",
      "Xiangdong Zhang",
      "Yifei Shao",
      "Shibo Hao",
      "Yi Gu",
      "Jieyuan Liu",
      "Somanshu Singla",
      "Tianyang Liu",
      "Eric P. Xing",
      "Zhengzhong Liu",
      "Haojian Jin",
      "Zhiting Hu"
    ],
    "abstract": "The recent explosion of large language models (LLMs), each with its own\ngeneral or specialized strengths, makes scalable, reliable benchmarking more\nurgent than ever. Standard practices nowadays face fundamental trade-offs:\nclosed-ended question-based benchmarks (eg MMLU) struggle with saturation as\nnewer models emerge, while crowd-sourced leaderboards (eg Chatbot Arena) rely\non costly and slow human judges. Recently, automated methods (eg\nLLM-as-a-judge) shed light on the scalability, but risk bias by relying on one\nor a few \"authority\" models. To tackle these issues, we propose Decentralized\nArena (dearena), a fully automated framework leveraging collective intelligence\nfrom all LLMs to evaluate each other. It mitigates single-model judge bias by\ndemocratic, pairwise evaluation, and remains efficient at scale through two key\ncomponents: (1) a coarse-to-fine ranking algorithm for fast incremental\ninsertion of new models with sub-quadratic complexity, and (2) an automatic\nquestion selection strategy for the construction of new evaluation dimensions.\nAcross extensive experiments across 66 LLMs, dearena attains up to 97%\ncorrelation with human judgements, while significantly reducing the cost. Our\ncode and data will be publicly released on\nhttps://github.com/maitrix-org/de-arena.",
    "pdf_url": "http://arxiv.org/pdf/2505.12808v1",
    "published": "2025-05-19T07:34:25+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12807v1",
    "title": "A remark on the growth rate of operator semigroups under resolvent bounds",
    "authors": [
      "Filippo Dell'Oro"
    ],
    "abstract": "We provide a growth bound for the operator norm of $C_0$-semigroups on\nHilbert spaces under a corresponding growth bound on the resolvent of the\nsemigroup generator. For some super-linear resolvent growths, our estimate is\nsharper than the ones currently available in the literature.",
    "pdf_url": "http://arxiv.org/pdf/2505.12807v1",
    "published": "2025-05-19T07:33:51+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12806v1",
    "title": "Hierarchical Representations for Evolving Acyclic Vector Autoregressions (HEAVe)",
    "authors": [
      "Cameron Cornell",
      "Lewis Mitchell",
      "Matthew Roughan"
    ],
    "abstract": "Causal networks offer an intuitive framework to understand influence\nstructures within time series systems. However, the presence of cycles can\nobscure dynamic relationships and hinder hierarchical analysis. These networks\nare typically identified through multivariate predictive modelling, but\nenforcing acyclic constraints significantly increases computational and\nanalytical complexity. Despite recent advances, there remains a lack of simple,\nflexible approaches that are easily tailorable to specific problem instances.\nWe propose an evolutionary approach to fitting acyclic vector autoregressive\nprocesses and introduces a novel hierarchical representation that directly\nmodels structural elements within a time series system. On simulated datasets,\nour model retains most of the predictive accuracy of unconstrained models and\noutperforms permutation-based alternatives. When applied to a dataset of 100\ncryptocurrency return series, our method generates acyclic causal networks\ncapturing key structural properties of the unconstrained model. The acyclic\nnetworks are approximately sub-graphs of the unconstrained networks, and most\nof the removed links originate from low-influence nodes. Given the high levels\nof feature preservation, we conclude that this cryptocurrency price system\nfunctions largely hierarchically. Our findings demonstrate a flexible,\nintuitive approach for identifying hierarchical causal networks in time series\nsystems, with broad applications to fields like econometrics and social network\nanalysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.12806v1",
    "published": "2025-05-19T07:33:01+00:00",
    "categories": [
      "q-fin.ST",
      "cs.NE"
    ],
    "primary_category": "q-fin.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.12805v1",
    "title": "FedSVD: Adaptive Orthogonalization for Private Federated Learning with LoRA",
    "authors": [
      "Seanie Lee",
      "Sangwoo Park",
      "Dong Bok Lee",
      "Dominik Wagner",
      "Haebin Seong",
      "Tobias Bocklet",
      "Juho Lee",
      "Sung Ju Hwang"
    ],
    "abstract": "Low-Rank Adaptation (LoRA), which introduces a product of two trainable\nlow-rank matrices into frozen pre-trained weights, is widely used for efficient\nfine-tuning of language models in federated learning (FL). However, when\ncombined with differentially private stochastic gradient descent (DP-SGD), LoRA\nfaces substantial noise amplification: DP-SGD perturbs per-sample gradients,\nand the matrix multiplication of the LoRA update ($BA$) intensifies this\neffect. Freezing one matrix (e.g., $A$) reduces the noise but restricts model\nexpressiveness, often resulting in suboptimal adaptation. To address this, we\npropose FedSVD, a simple yet effective method that introduces a global\nreparameterization based on singular value decomposition (SVD). In our\napproach, each client optimizes only the $B$ matrix and transmits it to the\nserver. The server aggregates the $B$ matrices, computes the product $BA$ using\nthe previous $A$, and refactorizes the result via SVD. This yields a new\nadaptive $A$ composed of the orthonormal right singular vectors of $BA$, and an\nupdated $B$ containing the remaining SVD components. This reparameterization\navoids quadratic noise amplification, while allowing $A$ to better capture the\nprincipal directions of the aggregate updates. Moreover, the orthonormal\nstructure of $A$ bounds the gradient norms of $B$ and preserves more signal\nunder DP-SGD, as confirmed by our theoretical analysis. As a result, FedSVD\nconsistently improves stability and performance across a variety of privacy\nsettings and benchmarks, outperforming relevant baselines under both private\nand non-private regimes.",
    "pdf_url": "http://arxiv.org/pdf/2505.12805v1",
    "published": "2025-05-19T07:32:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12804v1",
    "title": "Magidor-like forcing and the cofinality of the Galvin number",
    "authors": [
      "Shimon Garti"
    ],
    "abstract": "We force over a model of AD to obtain the consistency of the Galvin number\nhaving countable cofinality.",
    "pdf_url": "http://arxiv.org/pdf/2505.12804v1",
    "published": "2025-05-19T07:32:53+00:00",
    "categories": [
      "math.LO",
      "03E60, 03E55"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12803v1",
    "title": "Informed Mixing -- Improving Open Set Recognition via Attribution-based Augmentation",
    "authors": [
      "Jiawen Xu",
      "Odej Kao",
      "Margret Keuper"
    ],
    "abstract": "Open set recognition (OSR) is devised to address the problem of detecting\nnovel classes during model inference. Even in recent vision models, this\nremains an open issue which is receiving increasing attention. Thereby, a\ncrucial challenge is to learn features that are relevant for unseen categories\nfrom given data, for which these features might not be discriminative. To\nfacilitate this process and \"optimize to learn\" more diverse features, we\npropose GradMix, a data augmentation method that dynamically leverages\ngradient-based attribution maps of the model during training to mask out\nalready learned concepts. Thus GradMix encourages the model to learn a more\ncomplete set of representative features from the same data source. Extensive\nexperiments on open set recognition, close set classification, and\nout-of-distribution detection reveal that our method can often outperform the\nstate-of-the-art. GradMix can further increase model robustness to corruptions\nas well as downstream classification performance for self-supervised learning,\nindicating its benefit for model generalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.12803v1",
    "published": "2025-05-19T07:32:06+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12802v1",
    "title": "Low-Metallicity Star Formation Survey in Sh2-284 (LZ-STAR). II. The inital mass function",
    "authors": [
      "M. Andersen",
      "A. Brizawasi",
      "Y. Cheng",
      "J. C. Tan",
      "R. Fedriani",
      "J. J. Armstrong",
      "M. Robberto"
    ],
    "abstract": "To fully understand the star formation process, we are compelled to study it\nin a variety of environments. Of particular interest are how star formation and\nthe resulting initial mass function (IMF) vary as a function of metallicity. We\nhave observed an embedded young cluster in Sh2-284 (hereafter S284), the HII\nregion associated with the open cluster Dolidze 25 using JWST/NIRCam with the\naim to study star formation in a metal-poor, i.e., about 1/3 of solar,\nenvironment. In particular, we aim to measure the peak of the IMF. Using JWST\nNIRCam photometry, we identified the embedded cluster S284-EC1 and resolved its\nlow-mass content. By comparison with pre-main sequence evolutionary tracks we\ndetermine the mass and extinction for the individual cluster members.\nExtinction limited samples are created based on the distribution of extinction\nand the completeness of the data. For the region with a completeness of 50% or\nhigher, we have fitted a log-normal distribution to the IMF. Adopting a\nfiducial age of 1 Myr of the members, the peak of the IMF is found to be at mc\n= 0.16+-0.02Msun, which is significantly smaller than the peak mass measured in\nlocal young clusters, such as mc = 0.26+0.11-0.07 Msun in the Orion Nebula\nCluster (Gennaro & Robberto 2020), or the local Galactic disk value of mc =\n0.25 Msun (Chabrier 2005). We have found evidence for IMF variation as a\nfunction of metallicity, i.e., the peak of the IMF shifts to lower masses as\none goes from solar to 1/3 solar metallicity. However, we caution that the\nresult is sensitive to the assumed age of the stellar population, i.e., with\npeak mass rising if an age older than 1 Myr is adopted. This study further\nmotivates the need for expanded samples of low-metallicity regions and their\ncontent to enable more comprehensive measures of the IMF in such environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12802v1",
    "published": "2025-05-19T07:32:03+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12801v1",
    "title": "Testing Identifiability and Transportability with Observational and Experimental Data",
    "authors": [
      "Konstantina Lelova",
      "Gregory F. Cooper",
      "Sofia Triantafillou"
    ],
    "abstract": "Transporting causal information learned from experiments in one population to\nanother is a critical challenge in clinical research and decision-making.\nCausal transportability uses causal graphs to model differences between the\nsource and target populations and identifies conditions under which causal\neffects learned from experiments can be reused in a different population.\nSimilarly, causal identifiability identifies conditions under which causal\neffects can be estimated from observational data. However, these approaches\nrely on knowing the causal graph, which is often unavailable in real-world\nsettings. In this work, we propose a Bayesian method for assessing whether\nZ-specific (conditional) causal effects are both identifiable and\ntransportable, without knowing the causal graph. Our method combines\nexperimental data from the source population with observational data from the\ntarget population to compute the probability that a causal effect is both\nidentifiable from observational data and transportable. When this holds, we\nleverage both observational data from the target domain and experimental data\nfrom the source domain to obtain an unbiased, efficient estimator of the causal\neffect in the target population. Using simulations, we demonstrate that our\nmethod correctly identifies transportable causal effects and improves causal\neffect estimation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12801v1",
    "published": "2025-05-19T07:31:56+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.12800v1",
    "title": "OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching",
    "authors": [
      "Hieu-Nghia Huynh-Nguyen",
      "Ngoc Son Nguyen",
      "Huynh Nguyen Dang",
      "Thieu Vo",
      "Truong-Son Hy",
      "Van Nguyen"
    ],
    "abstract": "Text-to-speech (TTS) systems have seen significant advancements in recent\nyears, driven by improvements in deep learning and neural network\narchitectures. Viewing the output speech as a data distribution, previous\napproaches often employ traditional speech representations, such as waveforms\nor spectrograms, within the Flow Matching framework. However, these methods\nhave limitations, including overlooking various speech attributes and incurring\nhigh computational costs due to additional constraints introduced during\ntraining. To address these challenges, we introduce OZSpeech, the first TTS\nmethod to explore optimal transport conditional flow matching with one-step\nsampling and a learned prior as the condition, effectively disregarding\npreceding states and reducing the number of sampling steps. Our approach\noperates on disentangled, factorized components of speech in token format,\nenabling accurate modeling of each speech attribute, which enhances the TTS\nsystem's ability to precisely clone the prompt speech. Experimental results\nshow that our method achieves promising performance over existing methods in\ncontent accuracy, naturalness, prosody generation, and speaker style\npreservation. Audio samples are available at our demo page\nhttps://ozspeech.github.io/OZSpeech_Web/.",
    "pdf_url": "http://arxiv.org/pdf/2505.12800v1",
    "published": "2025-05-19T07:31:55+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.12799v1",
    "title": "Resolving self-cavity effects in two-dimensional quantum materials",
    "authors": [
      "Marios H. Michael",
      "Gunda Kipp",
      "Alexander M. Potts",
      "Matthew W. Day",
      "Toru Matsuyama",
      "Guido Meier",
      "Hope M. Bretscher",
      "James W. McIver"
    ],
    "abstract": "Two-dimensional materials and van der Waals (vdW) heterostructures host many\nstrongly correlated and topological quantum phases on the $\\sim$ meV energy\nscale. Direct electrodynamical signatures of such states are thus expected to\nappear in the terahertz (THz) frequency range (1 THz $\\sim$ 4 meV). Because the\ntypical size of vdW heterostructures ($\\sim$10 $\\mu m$) is much smaller than\nthe diffraction limit of THz light, probing THz optical conductivities\nnecessitates the use of near-field optical probes. However, interpreting the\nresponse of such near-field probes is complicated by finite-size effects, the\npresence of electrostatic gates, and the influence of the probe itself on\nmaterial dynamics -- all of which conspire to form polaritonic self-cavities,\nin which interactions between THz electromagnetic fields and material\nexcitations form discretized standing waves. In this paper, we demonstrate the\nrelevance of self-cavity effects in 2D materials and derive an analytical\nframework to resolve these effects using the emerging experimental technique of\ntime-domain on-chip THz spectroscopy. We show that by pairing experiments with\nthe analytical theory, it is possible to extract the THz conductivity and\nresolve collective mode dynamics far outside the light cone, with $\\sim \\mu m$\nin-plane and $\\sim nm$ out-of-plane resolution. This study lays the groundwork\nfor studying quantum phases and cavity effects in vdW heterostructures and 2D\nquantum materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.12799v1",
    "published": "2025-05-19T07:31:30+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.12798v1",
    "title": "Dynamic stall reattachment revisited",
    "authors": [
      "Sahar Rezapour",
      "Karen Mulleners"
    ],
    "abstract": "Dynamic stall on airfoils is an undesirable and potentially dangerous\nphenomenon. The motto for aerodynamic systems with unsteadily moving wings,\nsuch as helicopters or wind turbines, is that prevention beats recovery. In\ncase prevention fails or is not feasible, we need to know when recovery starts,\nhow long it takes, and how we can improve it. This study revisits dynamic stall\nreattachment to identify the sequence of events during flow and load recovery\nand to characterise key observable features in the pressure, force, and flow\nfield. Our analysis is based on time-resolved velocity field and surface\npressure data obtained experimentally for a two-dimensional, sinusoidally\npitching airfoil. Stall recovery is a transient process that does not start\nimmediately when the angle of attack falls below the critical stall angle. The\nonset of recovery is delayed to angles below the critical stall angle and the\nduration of the reattachment delay decreases with increasing unsteadiness of\nthe pitching motion. An angle of attack below the critical angle is a\nnecessary, but not sufficient condition to initiate the stall recovery process.\nWe identified a critical value of the leading-edge suction parameter,\nindependent of the pitch rate, that is a threshold beyond which reattachment\nconsistently initiates. Based on prominent changes in the evolution of the\nshear layer, the leading-edge suction, and the lift deficit due to stall, we\ndivided the reattachment process into three stages: the reaction delay, wave\npropagation, and boundary layer relaxation stage, and extracted the\ncharacteristic features and time-scales for each stage.",
    "pdf_url": "http://arxiv.org/pdf/2505.12798v1",
    "published": "2025-05-19T07:31:01+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.12797v1",
    "title": "Simulation and Experimental Studies of DWDM Nonlinear Phase/Polarization/Power Crosstalk Between DFOS and Communication Channels in 27.6-Tb/s 800ZR Metro Network",
    "authors": [
      "Jingchuan Wang",
      "Maoqi Liu",
      "Liwang Lu",
      "Alan Pak Tao Lau",
      "Chao Lu"
    ],
    "abstract": "We comprehensively analyze the fiber nonlinearity crosstalks between DAS and\ncommunication channels through numerical results and 40 x 800-Gb/s 90-km\nexperimental demonstration. Our findings indicate that conventional pulse-based\nDAS is unsuitable for in-band DWDM coexistence system, whereas\npulse-compression DAS shows negligible penalties with legacy coherent\ntransceivers.",
    "pdf_url": "http://arxiv.org/pdf/2505.12797v1",
    "published": "2025-05-19T07:30:48+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.12796v5",
    "title": "Adaptive Inference through Bayesian and Inverse Bayesian Inference with Symmetry-Bias in Nonstationary Environments",
    "authors": [
      "Shuji Shinohara",
      "Daiki Morita",
      "Hayato Hirai",
      "Ryosuke Kuribayashi",
      "Nobuhito Manome",
      "Toru Moriyama",
      "Yoshihiro Nakajima",
      "Yukio-Pegio Gunji",
      "Ung-il Chung"
    ],
    "abstract": "This study proposes a novel inference framework known as Bayesian and inverse\nBayesian (BIB) inference, which incorporates symmetry bias into the Bayesian\nupdating process to perform both conventional and inverse Bayesian updates\nconcurrently. The model was evaluated in a sequential estimation task involving\nobservations drawn from a Gaussian distribution with a stochastically\ntime-varying mean. Conventional Bayesian inference is constrained by a\nfundamental trade-off between adaptability to abrupt environmental changes and\naccuracy during stable periods. The BIB framework addresses this limitation by\ndynamically modulating the learning rate via inverse Bayesian updates, thereby\nenhancing adaptive flexibility. Notably, the BIB model exhibited spontaneous\nbursts in the learning rate during environmental transitions, transiently\nentering high-sensitivity states that facilitated rapid adaptation.This\nburst-relaxation dynamic serves as a mechanism for balancing adaptability and\naccuracy. Furthermore, avalanche analysis, detrended fluctuation analysis, and\npower spectral analysis revealed that the BIB system likely operates near a\ncritical state-a property not observed in standard Bayesian inference. This\nsuggests that the BIB model uniquely achieves a coexistence of computational\nefficiency and critical dynamics, resolving the adaptability-accuracy trade-off\nwhile maintaining a scale-free behavior. These findings offer a new\ncomputational perspective on scale-free dynamics in natural systems and provide\nvaluable insights for the design of adaptive inference systems in nonstationary\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12796v5",
    "published": "2025-05-19T07:30:45+00:00",
    "categories": [
      "stat.ME",
      "cs.MA"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.15846v1",
    "title": "Two types of $q$-Gaussian distributions used to study the diffusion in a finite region",
    "authors": [
      "Won Sang Chung",
      "L. M. Nieto",
      "Soroush Zare",
      "Hassan Hassanabadi"
    ],
    "abstract": "In this work, we explore both the ordinary $q$-Gaussian distribution and a\nnew one defined here, determining both their mean and variance, and we use them\nto construct solutions of the $q$-deformed diffusion differential equation.\nThis approach allows us to realize that the standard deviation of the\ndistribution must be a function of time. In one case, we derive a linear\nFokker-Planck equation within a finite region, revealing a new form of both the\nposition- and time-dependent diffusion coefficient and the corresponding\ncontinuity equation. It is noteworthy that, in both cases, the conventional\nresult is obtained when $q$ tends to zero. Furthermore, we derive the deformed\ndiffusion-decay equation in a finite region, also determining the position- and\ntime-dependent decay coefficient. A discrete version of this diffusion-decay\nequation is addressed, in which the discrete times have a uniform interval,\nwhile for the discrete positions the interval is not uniform.",
    "pdf_url": "http://arxiv.org/pdf/2505.15846v1",
    "published": "2025-05-19T07:29:52+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.12795v3",
    "title": "UFEval: Unified Fine-grained Evaluation with Task and Aspect Generalization",
    "authors": [
      "Shibo Hong",
      "Jiahao Ying",
      "Haiyuan Liang",
      "Mengdi Zhang",
      "Jun Kuang",
      "Jiazheng Zhang",
      "Yixin Cao"
    ],
    "abstract": "Evaluating the open-ended outputs of Large Multimodal Models has become a\nbottleneck as model capabilities, task diversity, and modality rapidly expand.\nExisting \"LLM-as-a-Judge\" evaluators are typically narrow in specific tasks and\naspects. In this paper, we argue that, on one hand, based on the interconnected\nnature of aspects, learning specific aspects can generalize to unseen aspects;\non the other hand, jointly learning to assess multiple visual aspects and tasks\nmay foster a synergistic effect. To this end, we propose UFEval, the first\nunified fine-grained evaluator with task and aspect generalization for four\nevaluation tasks -- Natural Language Generation, Image Understanding, Image\nGeneration, and Interleaved Text-and-Image Generation. Specifically, (1) We\nfirst construct a hierarchical aspect taxonomy encompassing 112 distinct\naspects across the aforementioned four tasks. (2) Then, building upon this\ntaxonomy, we create FRABench, a fine-grained evaluation dataset comprising\n60.4k pairwise samples with 325k evaluation labels obtained from a combination\nof human and GPT-4o annotations. FRABench provides a large-scale, multi-modal,\nand aspect-level resource for training and testing evaluators. (3) Finally,\nleveraging FRABench, we develop UFEval, a unified fine-grained evaluator.\nExperiments show that learning on specific aspects enables UFEval to generalize\nto unseen aspects, and joint learning to assess diverse tasks and aspects can\nlead to substantial mutual benefits.",
    "pdf_url": "http://arxiv.org/pdf/2505.12795v3",
    "published": "2025-05-19T07:29:26+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12794v1",
    "title": "Evidence that Mass Loss on the Red Giant Branch Decreases with Metallicity",
    "authors": [
      "Yaguang Li"
    ],
    "abstract": "Mass loss on the red giant branch (RGB) influences stellar evolution,\nproperties of stellar populations, and Galactic chemical enrichment, yet\nremains poorly constrained observationally. Current models provide limited\ninsight into how stellar properties, particularly how metallicity and mass,\naffects RGB mass loss. Here, I introduce a new observational approach that uses\nthe age-velocity-dispersion relation and the lower-mass boundary of red giants\nas precise evolutionary markers. These markers, informed by Galactic evolution,\nallow us to construct observational isochrones for field stars. By comparing\nmasses of RGB stars and red clump (RC) stars at the same age in the Kepler\nsample, I derive empirical measurements of integrated RGB mass loss at several\npoints in age and metallicity. Combining these new observational measurements\nwith open-cluster studies, I showed that the integrated mass loss on the RGB\ndecreases with metallicity, and may also decrease with stellar mass. The\naverage mass loss rate, which accounts for RGB lifetimes and the initial mass\ndifferences between RGB and RC stars at the same age, also show a similar\ntrend. These findings challenge current mass-loss prescriptions widely adopted\nin stellar evolutionary models, since none of them is able to produce the\nobserved mass-loss trend without widely adjusting free parameters. This\nhighlights an urgent need to revise mechanisms that govern RGB mass loss.",
    "pdf_url": "http://arxiv.org/pdf/2505.12794v1",
    "published": "2025-05-19T07:28:39+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12793v1",
    "title": "Three-nucleon contact forces in the Jacobi partial-wave basis",
    "authors": [
      "Lin Zuo",
      "Hao Yang",
      "Bingwei Long"
    ],
    "abstract": "We construct the three-nucleon contact potentials in the Jacobi partial-wave\nbasis. The potentials are built in the separable form as the products of the\nantisymmetrized three-nucleon states in which the nucleons are arbitrarily\nclose to each other. We compile the three-nucleon contact potentials up to\n$\\mathcal{O}(Q^2)$. These contact potentials are by construction independent\noperators under exchanges of any nucleon pairs.",
    "pdf_url": "http://arxiv.org/pdf/2505.12793v1",
    "published": "2025-05-19T07:24:53+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.12792v1",
    "title": "EAVIT: Efficient and Accurate Human Value Identification from Text data via LLMs",
    "authors": [
      "Wenhao Zhu",
      "Yuhang Xie",
      "Guojie Song",
      "Xin Zhang"
    ],
    "abstract": "The rapid evolution of large language models (LLMs) has revolutionized\nvarious fields, including the identification and discovery of human values\nwithin text data. While traditional NLP models, such as BERT, have been\nemployed for this task, their ability to represent textual data is\nsignificantly outperformed by emerging LLMs like GPTs. However, the performance\nof online LLMs often degrades when handling long contexts required for value\nidentification, which also incurs substantial computational costs. To address\nthese challenges, we propose EAVIT, an efficient and accurate framework for\nhuman value identification that combines the strengths of both locally\nfine-tunable and online black-box LLMs. Our framework employs a value detector\n- a small, local language model - to generate initial value estimations. These\nestimations are then used to construct concise input prompts for online LLMs,\nenabling accurate final value identification. To train the value detector, we\nintroduce explanation-based training and data generation techniques\nspecifically tailored for value identification, alongside sampling strategies\nto optimize the brevity of LLM input prompts. Our approach effectively reduces\nthe number of input tokens by up to 1/6 compared to directly querying online\nLLMs, while consistently outperforming traditional NLP methods and other\nLLM-based strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.12792v1",
    "published": "2025-05-19T07:24:35+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12791v1",
    "title": "Unlearning for Federated Online Learning to Rank: A Reproducibility Study",
    "authors": [
      "Yiling Tao",
      "Shuyi Wang",
      "Jiaxi Yang",
      "Guido Zuccon"
    ],
    "abstract": "This paper reports on findings from a comparative study on the effectiveness\nand efficiency of federated unlearning strategies within Federated Online\nLearning to Rank (FOLTR), with specific attention to systematically analysing\nthe unlearning capabilities of methods in a verifiable manner.\n  Federated approaches to ranking of search results have recently garnered\nattention to address users privacy concerns. In FOLTR, privacy is safeguarded\nby collaboratively training ranking models across decentralized data sources,\npreserving individual user data while optimizing search results based on\nimplicit feedback, such as clicks.\n  Recent legislation introduced across numerous countries is establishing the\nso called \"the right to be forgotten\", according to which services based on\nmachine learning models like those in FOLTR should provide capabilities that\nallow users to remove their own data from those used to train models. This has\nsparked the development of unlearning methods, along with evaluation practices\nto measure whether unlearning of a user data successfully occurred. Current\nevaluation practices are however often controversial, necessitating the use of\nmultiple metrics for a more comprehensive assessment -- but previous proposals\nof unlearning methods only used single evaluation metrics.\n  This paper addresses this limitation: our study rigorously assesses the\neffectiveness of unlearning strategies in managing both under-unlearning and\nover-unlearning scenarios using adapted, and newly proposed evaluation metrics.\nThanks to our detailed analysis, we uncover the strengths and limitations of\nfive unlearning strategies, offering valuable insights into optimizing\nfederated unlearning to balance data privacy and system performance within\nFOLTR. We publicly release our code and complete results at\nhttps://github.com/Iris1026/Unlearning-for-FOLTR.git.",
    "pdf_url": "http://arxiv.org/pdf/2505.12791v1",
    "published": "2025-05-19T07:23:46+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13556v3",
    "title": "Learning collision risk proactively from naturalistic driving data at scale",
    "authors": [
      "Yiru Jiao",
      "Simeon C. Calvert",
      "Sander van Cranenburgh",
      "Hans van Lint"
    ],
    "abstract": "Accurately and proactively alerting drivers or automated systems to emerging\ncollisions is crucial for road safety, particularly in highly interactive and\ncomplex urban environments. However, existing approaches to identifying\npotential collisions either require labour-intensive annotation of sparse risk,\nstruggle to consider varying contextual factors, or are only useful in specific\nscenarios. To address these limits, this study introduces the Generalised\nSurrogate Safety Measure (GSSM), a new data-driven approach that learns\ncollision risk exclusively from naturalistic driving without the need for crash\nor risk labels. GSSM captures the patterns of normal driving and estimates the\nextent to which a traffic interaction deviates from the norm towards an unsafe\nstate. Diverse data from naturalistic driving, including motion kinematics,\nweather, lighting, etc., are used to train multiple GSSMs, which are tested\nwith 2,591 reconstructed real-world crashes and near-crashes. These test events\nare also released here as the largest dataset of its kind to date. A basic GSSM\nusing only instantaneous motion kinematics achieves an area under the\nprecision-recall curve of 0.9 and secures a median time advance of 2.6 seconds\nto prevent potential collisions. Additional interaction patterns and contextual\nfactors provide further performance gains. Across various types of collision\nrisk scenarios (such as rear-end, merging, and turning interactions), the\naccuracy and timeliness of GSSM consistently outperforms existing baselines.\nGSSM therefore establishes a scalable, context-aware, and generalisable\nfoundation for proactively quantifying collision risk in traffic interactions.\nThis can support and facilitate autonomous driving systems, traffic safety\nassessment, and road emergency management. Code and experiment data are openly\naccessible at https://github.com/Yiru-Jiao/GSSM.",
    "pdf_url": "http://arxiv.org/pdf/2505.13556v3",
    "published": "2025-05-19T07:22:32+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12790v1",
    "title": "A note on nonlocal discrete problems involving sign-changing Kirchhoff functions",
    "authors": [
      "Biagio Ricceri"
    ],
    "abstract": "In this note, we establish a multiplicity theorem for a nonlocal discrete\nproblem of the type\n$$\\cases{-\\left(a\\sum_{m=1}^{n+1}|x_m-x_{m-1}|^2+b\\right)(x_{k+1}-2x_k+x_{k-1})=h_k(x_k)\\hskip\n10pt k=1,...,n, \\cr & \\cr x_0=x_{n+1}=0\\cr}$$ assuming $a>0$ and (for the first\ntime) $b<0$.",
    "pdf_url": "http://arxiv.org/pdf/2505.12790v1",
    "published": "2025-05-19T07:22:26+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12789v1",
    "title": "Enhancing Transformers Through Conditioned Embedded Tokens",
    "authors": [
      "Hemanth Saratchandran",
      "Simon Lucey"
    ],
    "abstract": "Transformers have transformed modern machine learning, driving breakthroughs\nin computer vision, natural language processing, and robotics. At the core of\ntheir success lies the attention mechanism, which enables the modeling of\nglobal dependencies among input tokens. However, we reveal that the attention\nblock in transformers suffers from inherent ill-conditioning, which hampers\ngradient-based optimization and leads to inefficient training. To address this,\nwe develop a theoretical framework that establishes a direct relationship\nbetween the conditioning of the attention block and that of the embedded\ntokenized data. Building on this insight, we introduce conditioned embedded\ntokens, a method that systematically modifies the embedded tokens to improve\nthe conditioning of the attention mechanism. Our analysis demonstrates that\nthis approach significantly mitigates ill-conditioning, leading to more stable\nand efficient training. We validate our methodology across various transformer\narchitectures, achieving consistent improvements in image classification,\nobject detection, instance segmentation, and natural language processing,\nhighlighting its broad applicability and effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.12789v1",
    "published": "2025-05-19T07:21:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.14837v2",
    "title": "Spectral Theorem for Self-Adjoint Partial Integral Operators in Kaplansky-Hilbert Modules",
    "authors": [
      "K. Kudaybergenov",
      "A. Arziev",
      "P. Orinbaev"
    ],
    "abstract": "In this paper, a spectral theorem is proved for self-adjoint cyclically\ncompact partial integral operators in the space of functions with mixed norm,\nwhich is a Kaplansky--Hilbert module. The decomposition through eigenfunctions,\nintegral representation using orthogonal projectors, and functional calculus\nare established. The results generalize Mercer theorem for positive definite\nkernels. The proofs rely on the gluing of projector-valued measures, presented\nin separate lemmas. An example illustrates all assertions of the theorem for a\nspecific kernel and function.",
    "pdf_url": "http://arxiv.org/pdf/2505.14837v2",
    "published": "2025-05-19T07:21:36+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12788v1",
    "title": "Mixture Policy based Multi-Hop Reasoning over N-tuple Temporal Knowledge Graphs",
    "authors": [
      "Zhongni Hou",
      "Miao Su",
      "Xiaolong Jin",
      "Zixuan Li",
      "Long Bai",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "abstract": "Temporal Knowledge Graphs (TKGs), which utilize quadruples in the form of\n(subject, predicate, object, timestamp) to describe temporal facts, have\nattracted extensive attention. N-tuple TKGs (N-TKGs) further extend traditional\nTKGs by utilizing n-tuples to incorporate auxiliary elements alongside core\nelements (i.e., subject, predicate, and object) of facts, so as to represent\nthem in a more fine-grained manner. Reasoning over N-TKGs aims to predict\npotential future facts based on historical ones. However, existing N-TKG\nreasoning methods often lack explainability due to their black-box nature.\nTherefore, we introduce a new Reinforcement Learning-based method, named\nMT-Path, which leverages the temporal information to traverse historical\nn-tuples and construct a temporal reasoning path. Specifically, in order to\nintegrate the information encapsulated within n-tuples, i.e., the\nentity-irrelevant information within the predicate, the information about core\nelements, and the complete information about the entire n-tuples, MT-Path\nutilizes a mixture policy-driven action selector, which bases on three\nlow-level policies, namely, the predicate-focused policy, the\ncore-element-focused policy and the whole-fact-focused policy. Further, MT-Path\nutilizes an auxiliary element-aware GCN to capture the rich semantic\ndependencies among facts, thereby enabling the agent to gain a deep\nunderstanding of each n-tuple. Experimental results demonstrate the\neffectiveness and the explainability of MT-Path.",
    "pdf_url": "http://arxiv.org/pdf/2505.12788v1",
    "published": "2025-05-19T07:20:33+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12787v1",
    "title": "Dynamic programming and dimensionality in convex stochastic optimization and control",
    "authors": [
      "Teemu Pennanen",
      "Ari-Pekka Perkki√∂"
    ],
    "abstract": "This paper studies stochastic optimization problems and associated Bellman\nequations in formats that allow for reduced dimensionality of the cost-to-go\nfunctions. In particular, we study stochastic control problems in the\n``decision-hazard-decision'' form where at each stage, the system state is\ncontrolled both by predictable as well as adapted controls. Such an information\nstructure may result in a lower dimensional system state than what is required\nin more traditional ``decision-hazard'' or ``hazard-decision'' formulations.\nThe dimension is critical for the complexity of numerical dynamic programming\nalgorithms and, in particular, for cutting plane schemes such as the stochastic\ndual dynamic programming algorithm. Our main result characterizes optimal\nsolutions and optimum values in terms of solutions to generalized Bellman\nequations. Existence of solutions to the Bellman equations is established under\ngeneral conditions that do not require compactness. We allow for general\nrandomness but show that, in the Markovian case, the dimensionality of the\nBellman equations reduces with respect to randomness just like in more\ntraditional control formulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.12787v1",
    "published": "2025-05-19T07:19:37+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12786v2",
    "title": "Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks",
    "authors": [
      "Minrui Xu",
      "Jiani Fan",
      "Xinyu Huang",
      "Conghao Zhou",
      "Jiawen Kang",
      "Dusit Niyato",
      "Shiwen Mao",
      "Zhu Han",
      "Xuemin",
      "Shen",
      "Kwok-Yan Lam"
    ],
    "abstract": "With the continuous evolution of Large Language Models (LLMs), LLM-based\nagents have advanced beyond passive chatbots to become autonomous cyber\nentities capable of performing complex tasks, including web browsing, malicious\ncode and deceptive content generation, and decision-making. By significantly\nreducing the time, expertise, and resources, AI-assisted cyberattacks\norchestrated by LLM-based agents have led to a phenomenon termed Cyber Threat\nInflation, characterized by a significant reduction in attack costs and a\ntremendous increase in attack scale. To provide actionable defensive insights,\nin this survey, we focus on the potential cyber threats posed by LLM-based\nagents across diverse network systems. Firstly, we present the capabilities of\nLLM-based cyberattack agents, which include executing autonomous attack\nstrategies, comprising scouting, memory, reasoning, and action, and\nfacilitating collaborative operations with other agents or human operators.\nBuilding on these capabilities, we examine common cyberattacks initiated by\nLLM-based agents and compare their effectiveness across different types of\nnetworks, including static, mobile, and infrastructure-free paradigms.\nMoreover, we analyze threat bottlenecks of LLM-based agents across different\nnetwork infrastructures and review their defense methods. Due to operational\nimbalances, existing defense methods are inadequate against autonomous\ncyberattacks. Finally, we outline future research directions and potential\ndefensive strategies for legacy network systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12786v2",
    "published": "2025-05-19T07:19:06+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12785v1",
    "title": "Probing the 3+1 neutrino model in the SHiP experiment",
    "authors": [
      "Ki-Young Choi",
      "Yu Seon Jeong",
      "Sung Hyun Kim",
      "Yeong Gyun Kim",
      "Kang Young Lee",
      "Kyong Sei Lee",
      "Byung Do Park",
      "Jong Yoon Sohn",
      "Seong Moon Yoo",
      "Chun Sil Yoon"
    ],
    "abstract": "In this study, as an extension of our previous work, we estimate the\nsensitivity of the Search for Hidden Particles (SHiP) experiment to the 3+1\nmodel using the charged-current deep inelastic scattering event spectrum. We\nemploy the Feldman-Cousins method with a parametric bootstrap to account for\nnuisance parameters and systematic uncertainties. In the previous study, we\nproposed a dual baseline approach by suggesting Far SND (FSND) at 120 m with\nNear SND (NSND) at 27 m. We employ the same approach in this study. The\nNSND-only configuration can probe mixing parameters of $|U_{\\alpha4}|^2 \\gtrsim\n0.1$ near $\\Delta m_{41}^2 \\sim 10^3\\,\\mathrm{eV}^2$, with a reduction of\nnormalized systematic uncertainties from 20\\% to 10\\% improving sensitivity by\nroughly a factor of two. Moreover, the inclusion of FSND significantly enhances\nthe sensitivity by a factor of 2 to 10 depending on the flavor and the\nsystematic uncertainty. In two-flavor mixing scenarios, a cancellation between\nneutrino appearance and disappearance generates kinks in the sensitivity\ncurves, that are vanished in the dual-baseline approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.12785v1",
    "published": "2025-05-19T07:13:59+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12784v1",
    "title": "Counting torsors for wild abelian groups",
    "authors": [
      "Ratko Darda",
      "Takehiko Yasuda"
    ],
    "abstract": "Let $F$ be a global field of characteristic $p > 0$ and $G$ a finite abelian\n$p$-group. In this paper we treat the question of counting $G$-torsors over $F$\nfor certain heights developed in [DY25].",
    "pdf_url": "http://arxiv.org/pdf/2505.12784v1",
    "published": "2025-05-19T07:13:28+00:00",
    "categories": [
      "math.NT",
      "11S15, 11G50, 11R32, 11R45"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12783v1",
    "title": "Unimodular equations which do not preserve the derived length of a group",
    "authors": [
      "Mikhail A. Mikheenko"
    ],
    "abstract": "It is a known fact that any unimodular equation over an abelian group has a\nsolution in that group itself. It is also known that for metabelian groups this\ndoes not hold; moreover, there is a unimodular equation over some metabelian\ngroup which has no solutions in any larger metabelian group. Here we present\nthe proof of an analagous fact for solvable groups of higher derived lengths.",
    "pdf_url": "http://arxiv.org/pdf/2505.12783v1",
    "published": "2025-05-19T07:13:23+00:00",
    "categories": [
      "math.GR",
      "20F70 (Primary), 20F16 (Secondary)"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12782v1",
    "title": "AdaToken-3D: Dynamic Spatial Gating for Efficient 3D Large Multimodal-Models Reasoning",
    "authors": [
      "Kai Zhang",
      "Xingyu Chen",
      "Xiaofeng Zhang"
    ],
    "abstract": "Large Multimodal Models (LMMs) have become a pivotal research focus in deep\nlearning, demonstrating remarkable capabilities in 3D scene understanding.\nHowever, current 3D LMMs employing thousands of spatial tokens for multimodal\nreasoning suffer from critical inefficiencies: excessive computational overhead\nand redundant information flows. Unlike 2D VLMs processing single images, 3D\nLMMs exhibit inherent architectural redundancy due to the heterogeneous\nmechanisms between spatial tokens and visual tokens. To address this challenge,\nwe propose AdaToken-3D, an adaptive spatial token optimization framework that\ndynamically prunes redundant tokens through spatial contribution analysis. Our\nmethod automatically tailors pruning strategies to different 3D LMM\narchitectures by quantifying token-level information flows via attention\npattern mining. Extensive experiments on LLaVA-3D (a 7B parameter 3D-LMM)\ndemonstrate that AdaToken-3D achieves 21\\% faster inference speed and 63\\%\nFLOPs reduction while maintaining original task accuracy. Beyond efficiency\ngains, this work systematically investigates redundancy patterns in multimodal\nspatial information flows through quantitative token interaction analysis. Our\nfindings reveal that over 60\\% of spatial tokens contribute minimally ($<$5\\%)\nto the final predictions, establishing theoretical foundations for efficient 3D\nmultimodal learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.12782v1",
    "published": "2025-05-19T07:11:07+00:00",
    "categories": [
      "cs.GR",
      "cs.CV",
      "cs.IR",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12781v1",
    "title": "A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone",
    "authors": [
      "Jitai Hao",
      "Qiang Huang",
      "Hao Liu",
      "Xinyan Xiao",
      "Zhaochun Ren",
      "Jun Yu"
    ],
    "abstract": "Training high-performing Small Language Models (SLMs) remains costly, even\nwith knowledge distillation and pruning from larger teacher models. Existing\nwork often faces three key challenges: (1) information loss from hard pruning,\n(2) inefficient alignment of representations, and (3) underutilization of\ninformative activations, particularly from Feed-Forward Networks (FFNs). To\naddress these challenges, we introduce Low-Rank Clone (LRC), an efficient\npre-training method that constructs SLMs aspiring to behavioral equivalence\nwith strong teacher models. LRC trains a set of low-rank projection matrices\nthat jointly enable soft pruning by compressing teacher weights, and activation\nclone by aligning student activations, including FFN signals, with those of the\nteacher. This unified design maximizes knowledge transfer while removing the\nneed for explicit alignment modules. Extensive experiments with open-source\nteachers (e.g., Llama-3.2-3B-Instruct, Qwen2.5-3B/7B-Instruct) show that LRC\nmatches or surpasses state-of-the-art models trained on trillions of\ntokens--while using only 20B tokens, achieving over 1,000x training efficiency.\nOur codes and model checkpoints are available at\nhttps://github.com/CURRENTF/LowRankClone and\nhttps://huggingface.co/collections/JitaiHao/low-rank-clone-lrc-6828389e96a93f1d4219dfaf.",
    "pdf_url": "http://arxiv.org/pdf/2505.12781v1",
    "published": "2025-05-19T07:10:42+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12780v1",
    "title": "Beyond Individual UX: Defining Group Experience(GX) as a New Paradigm for Group-centered AI",
    "authors": [
      "Soohwan Lee",
      "Seoyeong Hwang",
      "Kyungho Lee"
    ],
    "abstract": "Recent advancements in HCI and AI have predominantly centered on individual\nuser experiences, often neglecting the emergent dynamics of group interactions.\nThis provocation introduces Group Experience(GX) to capture the collective\nperceptual, emotional, and cognitive dimensions that arise when individuals\ninteract in cohesive groups. We challenge the conventional Human-centered AI\nparadigm and propose Group-centered AI(GCAI) as a framework that actively\nmediates group dynamics, amplifies diverse voices, and fosters ethical\ncollective decision-making. Drawing on social psychology, organizational\nbehavior, and group dynamics, we outline a group-centered design approach that\nbalances individual autonomy with collective interests while developing novel\nevaluative metrics. Our analysis emphasizes rethinking traditional\nmethodologies that focus solely on individual outcomes and advocates for\ninnovative strategies to capture group collaboration. We call on researchers to\nbridge the gap between micro-level experiences and macro-level impacts,\nultimately enriching and transforming collaborative human interactions.",
    "pdf_url": "http://arxiv.org/pdf/2505.12780v1",
    "published": "2025-05-19T07:10:06+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12779v1",
    "title": "Determining $t$-motives and dual $t$-motives in Anderson's theory",
    "authors": [
      "Andreas Maurischat"
    ],
    "abstract": "Anderson t-modules are analogs of abelian varieties in positive\ncharacteristic. Associated to such a t-module, there are its t-motive and its\ndual t-motive. When dealing with these objects, several questions occur which\none would like to solve algorithmically. For example, for a given t-module one\nwould like to decide whether its t-motive is indeed finitely generated free,\nand determine a basis. Reversely, for a given object in the category of\nt-motives one would like to decide whether it is the t-motive associated to a\nt-module, and determine that t-module.\n  In this article, we positively answer such questions by providing the\ncorresponding algorithms.\n  As it turned out, the main part of all these algorithms stem from a single\nalgorithm in non-commutative algebra, and hence the first part of this article\ndoesn't deal with Anderson's objects at all, but are results on finitely\ngenerated modules over skew polynomial rings.",
    "pdf_url": "http://arxiv.org/pdf/2505.12779v1",
    "published": "2025-05-19T07:10:01+00:00",
    "categories": [
      "math.NT",
      "math.RA",
      "11G09 (Primary) 13P10, 16S36 (Secondary)"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.20306v1",
    "title": "Multi-Modal Artificial Intelligence of Embryo Grading and Pregnancy Prediction in Assisted Reproductive Technology: A Review",
    "authors": [
      "Xueqiang Ouyang",
      "Jia Wei"
    ],
    "abstract": "As a global disease, infertility has always affected human beings. The\ndevelopment of assisted reproductive technology can effectively solve this\ndisease. However, the traditional in vitro fertilization-embryo transfer\ntechnology still faces many challenges in improving the success rate of\npregnancy, such as the subjectivity of embryo grading and the inefficiency of\nintegrating multi-modal data. Therefore, the introduction of artificial\nintelligence-based technologies is particularly crucial. This article reviews\nthe application progress of multi-modal artificial intelligence in embryo\ngrading and pregnancy prediction based on different data modalities (including\nstatic images, time-lapse videos and structured table data) from a new\nperspective, and discusses the main challenges in current research, such as the\ncomplexity of multi-modal information fusion and data scarcity.",
    "pdf_url": "http://arxiv.org/pdf/2505.20306v1",
    "published": "2025-05-19T07:07:13+00:00",
    "categories": [
      "cs.AI",
      "eess.IV",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12778v2",
    "title": "Pursuit and Review of Magnetic Resonance Imaging (MRI) based Quantum Computing -- Qubit Generation, Spin Purification, Tailored RF Pulses and MRI Sequences for Quantum Computing",
    "authors": [
      "Z. H. Cho",
      "J. H. Han",
      "D. H. Suk",
      "H. J. Jeung",
      "S. Z. Lee",
      "Y. B. Kim",
      "S. H. Paek",
      "H. G. Lee"
    ],
    "abstract": "We propose a novel MRI (Magnetic Resonance Imaging) technique based quantum\nbit (qubit) generation with water proton NMR (1H-NMR), distinct from previously\nproposed NMR chemical shift or spectroscopic techniques based qubit generation.\nWe briefly review prior NMR-based techniques in the context of quantum\ncomputing, focusing on MRI-related methods. The proposed technique utilizes\nMRI-based gradient methods combined with set of local reverse gradients to\ngenerate multiple qubits. This configuration enables the creation of multiple\nlocalized constant magnetic fields, each producing a qubit with highly\nhomogeneous field, therefore, a unique single frequency. The RF electronics and\nsignal processing techniques are analogous to those used in conventional MRI\nscanners, allowing operation at room temperature, with the exception of the\nmain magnet, which remains identical to that of standard MRI systems.\nAdditional advantages of this method include the ability to leverage the\nextensive pulse techniques and hardware developed for MRI scanners over the\npast 50 years. Furthermore, the wide array of MRI pulse sequences enables\nhighly sophisticated signal processing for quantum computing applications, such\nas the spin purification.",
    "pdf_url": "http://arxiv.org/pdf/2505.12778v2",
    "published": "2025-05-19T07:05:14+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12777v2",
    "title": "Wonderful embedding for group schemes in the Bruhat--Tits theory",
    "authors": [
      "Shang Li"
    ],
    "abstract": "For a reductive group $G$ over a discretely valued Henselian field $k$, using\nvaluations of root datum and concave functions, the Bruhat--Tits theory defines\nan important class of open bounded subgroups of $G(k)$ which are essential\nobjects in representation theory and arithmetic geometry. Moreover, these\nsubgroups are uniquely determined by smooth affine group schemes whose generic\nfibers are $G$ over the ring of integers of $k$. To study these group schemes,\nwhen $G$ is adjoint and quasi-split, we systematically construct wonderful\nembedding for these group schemes which are uniquely determined by a big cell\nstructure. The way that we construct our wonderful embedding is different from\nclassical methods in the sense that we avoid embedding a group scheme into an\nambient space and taking closure. We use an intrinsic and functorial method\nwhich is a variant of Artin--Weil method of birational group laws. Beyond the\nquasi-split case, our wonderful embedding is constructed by \\'etale descent.\nMoreover our wonderful embedding behaves in a similar way to the classical\nwonderful compactification of $G$. Our results can serve as a bridge between\nthe theory of wonderful compactifications and the Bruhat--Tits theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.12777v2",
    "published": "2025-05-19T07:04:37+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12776v2",
    "title": "Independent Set Enumeration in King Graphs by Tensor Network Contractions",
    "authors": [
      "Kai Liang"
    ],
    "abstract": "This paper discusses the enumeration of independent sets in king graphs of\nsize $m \\times n$, based on the tensor network contractions algorithm given in\nreference~\\cite{tilEnum}. We transform the problem into Wang tiling enumeration\nwithin an $(m+1) \\times (n+1)$ rectangle and compute the results for all cases\nwhere $m + n \\leq 79$ using tensor network contraction algorithm, and provided\nan approximation for larger $m, n$.\n  Using the same algorithm, we also enumerated independent sets with vertex\nnumber restrictions. Based on the results, we analyzed the vertex number that\nmaximize the enumeration for each pair $(m, n)$. Additionally, we compute the\ncorresponding weighted enumeration, where each independent set is weighted by\nthe number of its vertices (i.e., the total sum of vertices over all\nindependent sets). The approximations for larger $m, n$ are given as well.\n  Our results have added thousands of new items to the OEIS sequences A089980\nand A193580. In addition, the combinatorial problems above are closely related\nto the hard-core model in physics. We estimate some important constants based\non the existing results, and the relative error between our estimation of the\nentropy constant and the existing results is less than $10^{-9}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.12776v2",
    "published": "2025-05-19T07:04:14+00:00",
    "categories": [
      "math.CO",
      "cs.DM",
      "05C30 (Primary), 68R05 (Secondary)",
      "G.2.2; F.2.2"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12775v1",
    "title": "Mean Curvature Flow of Closed Curves Evolving in Two Dimensional Manifolds",
    "authors": [
      "Miroslav Kolar",
      "Daniel Sevcovic"
    ],
    "abstract": "We investigate the motion of a family of closed curves evolving on an\nembedded or immersed manifold in three dimensional Euclidean space according to\nthe geometric evolution law. We derive a system of nonlinear parabolic\nequations describing the motion of curves belonging to a given two-dimensional\nmanifold. We consider both embedded and immersed manifolds. Using the abstract\ntheory of analytic semiflows, we prove the local existence, uniqueness of\nH\\\"older smooth solutions to the governing system of nonlinear parabolic\nequations for the position vector parametrization of evolving curves. We apply\nthe method of flowing finite volumes in combination with the methods of lines\nfor numerical approximation of the governing equations. Numerical experiments\nsupport the analytical conclusions and demonstrate the efficiency of the\nmethod.",
    "pdf_url": "http://arxiv.org/pdf/2505.12775v1",
    "published": "2025-05-19T07:02:42+00:00",
    "categories": [
      "math.AP",
      "Primary: 35K57, 35K65, 65N40, 65M08, Secondary: 53C80"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12774v1",
    "title": "UniHM: Universal Human Motion Generation with Object Interactions in Indoor Scenes",
    "authors": [
      "Zichen Geng",
      "Zeeshan Hayder",
      "Wei Liu",
      "Ajmal Mian"
    ],
    "abstract": "Human motion synthesis in complex scenes presents a fundamental challenge,\nextending beyond conventional Text-to-Motion tasks by requiring the integration\nof diverse modalities such as static environments, movable objects, natural\nlanguage prompts, and spatial waypoints. Existing language-conditioned motion\nmodels often struggle with scene-aware motion generation due to limitations in\nmotion tokenization, which leads to information loss and fails to capture the\ncontinuous, context-dependent nature of 3D human movement. To address these\nissues, we propose UniHM, a unified motion language model that leverages\ndiffusion-based generation for synthesizing scene-aware human motion. UniHM is\nthe first framework to support both Text-to-Motion and Text-to-Human-Object\nInteraction (HOI) in complex 3D scenes. Our approach introduces three key\ncontributions: (1) a mixed-motion representation that fuses continuous 6DoF\nmotion with discrete local motion tokens to improve motion realism; (2) a novel\nLook-Up-Free Quantization VAE (LFQ-VAE) that surpasses traditional VQ-VAEs in\nboth reconstruction accuracy and generative performance; and (3) an enriched\nversion of the Lingo dataset augmented with HumanML3D annotations, providing\nstronger supervision for scene-specific motion learning. Experimental results\ndemonstrate that UniHM achieves comparative performance on the OMOMO benchmark\nfor text-to-HOI synthesis and yields competitive results on HumanML3D for\ngeneral text-conditioned motion generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12774v1",
    "published": "2025-05-19T07:02:12+00:00",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12773v1",
    "title": "Holographic composite Higgs model and gravitational waves produced during first order phase transition",
    "authors": [
      "Andrey A. Shavrin"
    ],
    "abstract": "The soft-wall holographic composite Higgs model assumes first-order phase\ntransition from the dynamical inner symmetry breaking. This research focuses on\nthe implications of the semi-analytical perturbative solution of the dual\n5-dimensional theory as an effective description of the strongly coupled\ncomposite Higgs sector. We clarify the thermodynamical description and\ngravitational waves spectrum produced during the phase transition, which were\npreviously numerically estimated. Besides, we investigate the limits of the\napplicability of our solution within the thin-wall approximation and\nquasiclassical approach in terms of the dual theory, that correspond to the\nstrongly coupled regime of composite Higgs model. Our semi-analytic framework\nprovides description of the strong first-order phase transition within the\nrunaway scenario.",
    "pdf_url": "http://arxiv.org/pdf/2505.12773v1",
    "published": "2025-05-19T07:02:04+00:00",
    "categories": [
      "hep-th",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.12772v2",
    "title": "Pyramid Sparse Transformer: Enhancing Multi-Scale Feature Fusion with Dynamic Token Selection",
    "authors": [
      "Junyi Hu",
      "Tian Bai",
      "Fengyi Wu",
      "Zhenming Peng",
      "Yi Zhang"
    ],
    "abstract": "Feature fusion is critical for high-performance vision models but often\nincurs prohibitive complexity. However, prevailing attention-based fusion\nmethods often involve significant computational complexity and implementation\nchallenges, limiting their efficiency in resource-constrained environments. To\naddress these issues, we introduce the Pyramid Sparse Transformer (PST), a\nlightweight, plug-and-play module that integrates coarse-to-fine token\nselection and shared attention parameters to reduce computation while\npreserving spatial detail. PST can be trained using only coarse attention and\nseamlessly activated at inference for further accuracy gains without\nretraining. When added to state-of-the-art real-time detection models, such as\nYOLOv11-N/S/M, PST yields mAP improvements of 0.9%, 0.5%, and 0.4% on MS COCO\nwith minimal latency impact. Likewise, embedding PST into ResNet-18/50/101 as\nbackbones, boosts ImageNet top-1 accuracy by 6.5%, 1.7%, and 1.0%,\nrespectively. These results demonstrate PST's effectiveness as a simple,\nhardware-friendly enhancement for both detection and classification tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12772v2",
    "published": "2025-05-19T07:00:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12771v1",
    "title": "FireFly-T: High-Throughput Sparsity Exploitation for Spiking Transformer Acceleration with Dual-Engine Overlay Architecture",
    "authors": [
      "Tenglong Li",
      "Jindong Li",
      "Guobin Shen",
      "Dongcheng Zhao",
      "Qian Zhang",
      "Yi Zeng"
    ],
    "abstract": "Spiking transformers are emerging as a promising architecture that combines\nthe energy efficiency of Spiking Neural Networks (SNNs) with the powerful\nattention mechanisms of transformers. However, existing hardware accelerators\nlack support for spiking attention, exhibit limited throughput in exploiting\nfine-grained sparsity, and struggle with scalable parallelism in sparse\ncomputation. To address these, we propose FireFly-T, a dual-engine overlay\narchitecture that integrates a sparse engine for activation sparsity and a\nbinary engine for spiking attention. In the sparse engine, we propose a\nhighthroughput sparse decoder that exploits fine-grained sparsity by\nconcurrently extracting multiple non-zero spikes. To complement this, we\nintroduce a scalable load balancing mechanism with weight dispatch and\nout-of-order execution, eliminating bank conflicts to support scalable\nmultidimensional parallelism. In the binary engine, we leverage the byte-level\nwrite capability of SRAMs to efficiently manipulate the 3D dataflows required\nfor spiking attention with minimal resource overhead. We also optimize the core\nAND-PopCount operation in spiking attention through a LUT6-based\nimplementation, improving timing closure and reducing LUT utilization on Xilinx\nFPGAs. As an overlay architecture, FireFly-T further incorporates an\norchestrator that dynamically manipulates input dataflows with flexible\nadaptation for diverse network topologies, while ensuring efficient resource\nutilization and maintaining high throughput. Experimental results demonstrate\nthat our accelerator achieves $1.39\\times$ and $2.40\\times$ higher energy\nefficiency, as well as $4.21\\times$ and $7.10\\times$ greater DSP efficiency,\ncompared to FireFly v2 and the transformer-enabled SpikeTA, respectively. These\nresults highlight its potential as an efficient hardware platform for spiking\ntransformer.",
    "pdf_url": "http://arxiv.org/pdf/2505.12771v1",
    "published": "2025-05-19T07:00:18+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13555v1",
    "title": "Super-entropic black holes in gravity's rainbow and determining constraints on rainbow functions",
    "authors": [
      "Behzad Eslam Panah",
      "Narges Heidari",
      "Mana Soleimani",
      "Maryam Kaveh"
    ],
    "abstract": "This paper is motivated by the application of the inverse isoperimetric\ninequality to establish constraints on the parameters of gravity's rainbow. We\ninvestigate the thermodynamic (in)stability conditions for $d-$dimensional\nenergy-dependent black holes, which are recognized as $d-$ dimensional black\nholes within the framework of gravity's rainbow. To achieve this, we calculate\nthermodynamic quantities such as Hawking temperature, entropy, total mass, and\nheat capacity in both extended and non-extended phase spaces for these black\nholes. We assess the physical and stable regions by utilizing these\nthermodynamic quantities alongside the inverse isoperimetric inequality, aiming\nto determine constraints on the rainbow functions. Finally, we show that by\nconsidering a constraint on the rainbow function, these black holes satisfy the\nsuper-entropic condition.",
    "pdf_url": "http://arxiv.org/pdf/2505.13555v1",
    "published": "2025-05-19T07:00:17+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.13554v1",
    "title": "Combining the Best of Both Worlds: A Method for Hybrid NMT and LLM Translation",
    "authors": [
      "Zhanglin Wu",
      "Daimeng Wei",
      "Xiaoyu Chen",
      "Hengchao Shang",
      "Jiaxin Guo",
      "Zongyao Li",
      "Yuanchang Luo",
      "Jinlong Yang",
      "Zhiqiang Rao",
      "Hao Yang"
    ],
    "abstract": "Large language model (LLM) shows promising performances in a variety of\ndownstream tasks, such as machine translation (MT). However, using LLMs for\ntranslation suffers from high computational costs and significant latency.\nBased on our evaluation, in most cases, translations using LLMs are comparable\nto that generated by neural machine translation (NMT) systems. Only in\nparticular scenarios, LLM and NMT models show respective advantages. As a\nresult, integrating NMT and LLM for translation and using LLM only when\nnecessary seems to be a sound solution. A scheduling policy that optimizes\ntranslation result while ensuring fast speed and as little LLM usage as\npossible is thereby required. We compare several scheduling policies and\npropose a novel and straightforward decider that leverages source sentence\nfeatures. We conduct extensive experiments on multilingual test sets and the\nresult shows that we can achieve optimal translation performance with minimal\nLLM usage, demonstrating effectiveness of our decider.",
    "pdf_url": "http://arxiv.org/pdf/2505.13554v1",
    "published": "2025-05-19T06:50:52+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12770v1",
    "title": "Testing Access-Control Configuration Changes for Web Applications",
    "authors": [
      "Chengcheng Xiang",
      "Li Zhong",
      "Eric Mugnier",
      "Nathaniel Nguyen",
      "Yuanyuan Zhou",
      "Tianyin Xu"
    ],
    "abstract": "Access-control misconfigurations are among the main causes of today's data\nbreaches in web applications. However, few techniques are available to support\nautomatic and systematic testing for access-control changes and detecting risky\nchanges to prevent severe consequences. As a result, those critical security\nconfigurations often lack testing, or are tested manually in an ad hoc way.\n  This paper advocates that tests should be made available for users to test\naccess-control configuration changes. The key challenges are such tests need to\nbe run with production environments (to reason end-to-end behavior) and need to\nbe performance-efficient. We present a new approach to create such tests, as a\nmini test environment incorporating production program and data, called\nACtests. ACtests report the impacts of access-control changes, namely the\nrequests that were denied but would be allowed after a change, and vice versa.\nUsers can validate if the changed requests are intended or not and identify\npotential security vulnerabilities.\n  We evaluate ACtests with 193 public configurations of widely-used web\napplications on Dockerhub. ACtests detect 168 new vulnerabilities from 72\nconfiguration images. We report them to the image maintainers: 54 of them have\nbeen confirmed and 44 have been fixed. We also conduct in-depth experiments\nwith five real-world deployed systems, including Wikipedia and a commercial\ncompany's web proxy. Our results show that ACtests effectively and efficiently\ndetect all the change impacts.",
    "pdf_url": "http://arxiv.org/pdf/2505.12770v1",
    "published": "2025-05-19T06:50:28+00:00",
    "categories": [
      "cs.CR",
      "cs.OS",
      "cs.SE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12769v1",
    "title": "The RFD property for graph C*-algebras",
    "authors": [
      "Guillaume Bellier",
      "Tatiana Shulman"
    ],
    "abstract": "It is proved that the graph C*-algebra of a finite graph is residually\nfinite-dimensional (RFD) if and only if no cycle has an entry. To obtain this\nresult we prove that C*-algebras of graphs with finitely many vertices often\nadmit a convenient decomposition into amalgamated free products.",
    "pdf_url": "http://arxiv.org/pdf/2505.12769v1",
    "published": "2025-05-19T06:50:18+00:00",
    "categories": [
      "math.OA",
      "46L05, 46L09"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12768v2",
    "title": "ReEx-SQL: Reasoning with Execution-Aware Reinforcement Learning for Text-to-SQL",
    "authors": [
      "Yaxun Dai",
      "Wenxuan Xie",
      "Xialie Zhuang",
      "Tianyu Yang",
      "Yiying Yang",
      "Haiqin Yang",
      "Yuhang Zhao",
      "Pingfu Chao",
      "Wenhao Jiang"
    ],
    "abstract": "In Text-to-SQL, execution feedback is essential for guiding large language\nmodels (LLMs) to reason accurately and generate reliable SQL queries. However,\nexisting methods treat execution feedback solely as a post-hoc signal for\ncorrection or selection, failing to integrate it into the generation process.\nThis limitation hinders their ability to address reasoning errors as they\noccur, ultimately reducing query accuracy and robustness. To address this\nissue, we propose ReEx-SQL (Reasoning with Execution-Aware Reinforcement\nLearning), a framework for Text-to-SQL that enables models to interact with the\ndatabase during decoding and dynamically adjust their reasoning based on\nexecution feedback. ReEx-SQL introduces an execution-aware reasoning paradigm\nthat interleaves intermediate SQL execution into reasoning paths, facilitating\ncontext-sensitive revisions. It achieves this through structured prompts with\nmarkup tags and a stepwise rollout strategy that integrates execution feedback\ninto each stage of generation. To supervise policy learning, we develop a\ncomposite reward function that includes an exploration reward, explicitly\nencouraging effective database interaction. Additionally, ReEx-SQL adopts a\ntree-based decoding strategy to support exploratory reasoning, enabling dynamic\nexpansion of alternative reasoning paths. Notably, ReEx-SQL achieves 88.8% on\nSpider and 64.9% on BIRD at the 7B scale, surpassing the standard reasoning\nbaseline by 2.7% and 2.6%, respectively. It also shows robustness, achieving\n85.2% on Spider-Realistic with leading performance. In addition, its\ntree-structured decoding improves efficiency and performance over linear\ndecoding, reducing inference time by 51.9% on the BIRD development set.",
    "pdf_url": "http://arxiv.org/pdf/2505.12768v2",
    "published": "2025-05-19T06:46:47+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12767v1",
    "title": "Language Models That Walk the Talk: A Framework for Formal Fairness Certificates",
    "authors": [
      "Danqing Chen",
      "Tobias Ladner",
      "Ahmed Rayen Mhadhbi",
      "Matthias Althoff"
    ],
    "abstract": "As large language models become integral to high-stakes applications,\nensuring their robustness and fairness is critical. Despite their success,\nlarge language models remain vulnerable to adversarial attacks, where small\nperturbations, such as synonym substitutions, can alter model predictions,\nposing risks in fairness-critical areas, such as gender bias mitigation, and\nsafety-critical areas, such as toxicity detection. While formal verification\nhas been explored for neural networks, its application to large language models\nremains limited. This work presents a holistic verification framework to\ncertify the robustness of transformer-based language models, with a focus on\nensuring gender fairness and consistent outputs across different gender-related\nterms. Furthermore, we extend this methodology to toxicity detection, offering\nformal guarantees that adversarially manipulated toxic inputs are consistently\ndetected and appropriately censored, thereby ensuring the reliability of\nmoderation systems. By formalizing robustness within the embedding space, this\nwork strengthens the reliability of language models in ethical AI deployment\nand content moderation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12767v1",
    "published": "2025-05-19T06:46:17+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12766v1",
    "title": "Reasoning-OCR: Can Large Multimodal Models Solve Complex Logical Reasoning Problems from OCR Cues?",
    "authors": [
      "Haibin He",
      "Maoyuan Ye",
      "Jing Zhang",
      "Xiantao Cai",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "abstract": "Large Multimodal Models (LMMs) have become increasingly versatile,\naccompanied by impressive Optical Character Recognition (OCR) related\ncapabilities. Existing OCR-related benchmarks emphasize evaluating LMMs'\nabilities of relatively simple visual question answering, visual-text parsing,\netc. However, the extent to which LMMs can deal with complex logical reasoning\nproblems based on OCR cues is relatively unexplored. To this end, we introduce\nthe Reasoning-OCR benchmark, which challenges LMMs to solve complex reasoning\nproblems based on the cues that can be extracted from rich visual-text.\nReasoning-OCR covers six visual scenarios and encompasses 150 meticulously\ndesigned questions categorized into six reasoning challenges. Additionally,\nReasoning-OCR minimizes the impact of field-specialized knowledge. Our\nevaluation offers some insights for proprietary and open-source LMMs in\ndifferent reasoning challenges, underscoring the urgent to improve the\nreasoning performance. We hope Reasoning-OCR can inspire and facilitate future\nresearch on enhancing complex reasoning ability based on OCR cues.\nReasoning-OCR is publicly available at\nhttps://github.com/Hxyz-123/ReasoningOCR.",
    "pdf_url": "http://arxiv.org/pdf/2505.12766v1",
    "published": "2025-05-19T06:45:18+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12765v2",
    "title": "Spin-weighted spherical harmonics as massless angular momentum eigenstates and their role in obstructing spin-orbital decompositions",
    "authors": [
      "Eric Palmerduca",
      "Hong Qin"
    ],
    "abstract": "We show that for massless helicity $h$ particles, the angular momentum\neigenstates are given in an appropriate coordinate system by the spin-weighted\nspherical harmonics ${_{-h}Y_{jm}}$ of spin-weight $-h$. In particular, these\nare simultaneous eigenstates of the Hamiltonian, helicity, $J^2$, and $J_z$.\nThe appearance of the spin-weighted spherical harmonics as opposed to the\nordinary spherical harmonics reflects the nontrivial topological structure of\nmassless particles with nonzero helicity. The resultant angular momentum\nmultiplet structure is quite different than that of massive particles, with at\nmost one multiplet for each angular momentum $j$ and with $|h|$ acting as a\nlower bound on $j$. This illustrates the obstruction to a spin-orbital\ndecomposition of the angular momentum for massless particles, as such a sparse\nmultiplet structure is not consistent with any reasonable spin-orbital\nsplitting.",
    "pdf_url": "http://arxiv.org/pdf/2505.12765v2",
    "published": "2025-05-19T06:44:21+00:00",
    "categories": [
      "math-ph",
      "hep-th",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12764v2",
    "title": "Solving graph problems using permutation-invariant quantum machine learning",
    "authors": [
      "Maximilian Balthasar Mansky",
      "Tobias Rohe",
      "Gerhard Stenzel",
      "Alejandro Bravo de la Serna",
      "Santiago Londo√±o Castillo",
      "Gautham Sathish",
      "Dimitra Nikolaidou",
      "Dmytro Bondarenko",
      "Linus Menzel",
      "Claudia Linnhoff-Popien"
    ],
    "abstract": "Many computational problems are unchanged under some symmetry operation. In\nclassical machine learning, this can be reflected with the layer structure of\nthe neural network. In quantum machine learning, the ansatz can be tuned to\ncorrespond to the specific symmetry of the problem. We investigate this\nadaption of the quantum circuit to the problem symmetry on graph classification\nproblems. On random graphs, the quantum machine learning ansatz classifies\nwhether a given random graph is connected, bipartite, contains a Hamiltonian\npath or cycle, respectively. We find that if the quantum circuit reflects the\ninherent symmetry of the problem, it vastly outperforms the standard,\nunsymmetrized ansatzes. Even when the symmetry is only approximative, there is\nstill a significant performance gain over non-symmetrized ansatzes. We show how\nthe symmetry can be included in the quantum circuit in a straightforward\nconstructive method.",
    "pdf_url": "http://arxiv.org/pdf/2505.12764v2",
    "published": "2025-05-19T06:44:03+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12763v1",
    "title": "Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization",
    "authors": [
      "Sunghwan Kim",
      "Dongjin Kang",
      "Taeyoon Kwon",
      "Hyungjoo Chae",
      "Dongha Lee",
      "Jinyoung Yeo"
    ],
    "abstract": "Reward models (RMs) play a crucial role in reinforcement learning from human\nfeedback (RLHF), aligning model behavior with human preferences. However,\nexisting benchmarks for reward models show a weak correlation with the\nperformance of optimized policies, suggesting that they fail to accurately\nassess the true capabilities of RMs. To bridge this gap, we explore several\nevaluation designs through the lens of reward overoptimization\\textemdash a\nphenomenon that captures both how well the reward model aligns with human\npreferences and the dynamics of the learning signal it provides to the policy.\nThe results highlight three key findings on how to construct a reliable\nbenchmark: (i) it is important to minimize differences between chosen and\nrejected responses beyond correctness, (ii) evaluating reward models requires\nmultiple comparisons across a wide range of chosen and rejected responses, and\n(iii) given that reward models encounter responses with diverse\nrepresentations, responses should be sourced from a variety of models. However,\nwe also observe that a extremely high correlation with degree of\noveroptimization leads to comparatively lower correlation with certain\ndownstream performance. Thus, when designing a benchmark, it is desirable to\nuse the degree of overoptimization as a useful tool, rather than the end goal.",
    "pdf_url": "http://arxiv.org/pdf/2505.12763v1",
    "published": "2025-05-19T06:43:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12762v1",
    "title": "IDEAL: Data Equilibrium Adaptation for Multi-Capability Language Model Alignment",
    "authors": [
      "Chenlin Ming",
      "Chendi Qu",
      "Mengzhang Cai",
      "Qizhi Pei",
      "Zhuoshi Pan",
      "Yu Li",
      "Xiaoming Duan",
      "Lijun Wu",
      "Conghui He"
    ],
    "abstract": "Large Language Models (LLMs) have achieved impressive performance through\nSupervised Fine-tuning (SFT) on diverse instructional datasets. When training\non multiple capabilities simultaneously, the mixture training dataset, governed\nby volumes of data from different domains, is a critical factor that directly\nimpacts the final model's performance. Unlike many studies that focus on\nenhancing the quality of training datasets through data selection methods, few\nworks explore the intricate relationship between the compositional quantity of\nmixture training datasets and the emergent capabilities of LLMs. Given the\navailability of a high-quality multi-domain training dataset, understanding the\nimpact of data from each domain on the model's overall capabilities is crucial\nfor preparing SFT data and training a well-balanced model that performs\neffectively across diverse domains. In this work, we introduce IDEAL, an\ninnovative data equilibrium adaptation framework designed to effectively\noptimize volumes of data from different domains within mixture SFT datasets,\nthereby enhancing the model's alignment and performance across multiple\ncapabilities. IDEAL employs a gradient-based approach to iteratively refine the\ntraining data distribution, dynamically adjusting the volumes of\ndomain-specific data based on their impact on downstream task performance. By\nleveraging this adaptive mechanism, IDEAL ensures a balanced dataset\ncomposition, enabling the model to achieve robust generalization and consistent\nproficiency across diverse tasks. Experiments across different capabilities\ndemonstrate that IDEAL outperforms conventional uniform data allocation\nstrategies, achieving a comprehensive improvement of approximately 7% in\nmulti-task evaluation scores.",
    "pdf_url": "http://arxiv.org/pdf/2505.12762v1",
    "published": "2025-05-19T06:42:44+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12761v3",
    "title": "Enhancing Channel-Independent Time Series Forecasting via Cross-Variate Patch Embedding",
    "authors": [
      "Donghwa Shin",
      "Edwin Zhang"
    ],
    "abstract": "Transformers have recently gained popularity in time series forecasting due\nto their ability to capture long-term dependencies. However, many existing\nmodels focus only on capturing temporal dependencies while omitting intricate\nrelationships between variables. Recent models have tried tackling this by\nexplicitly modeling both cross-time and cross-variate dependencies through a\nsequential or unified attention mechanism, but they are entirely channel\ndependent (CD) across all layers, making them potentially susceptible to\noverfitting. To address this, we propose Cross-Variate Patch Embeddings (CVPE),\na lightweight CD module that injects cross-variate context into\nchannel-independent (CI) models by simply modifying the patch embedding\nprocess. We achieve this by adding a learnable positional encoding and a\nlightweight router-attention block to the vanilla patch embedding layer. We\nthen integrate CVPE into Time-LLM, a multimodal CI forecasting model, to\ndemonstrate its effectiveness in capturing cross-variate dependencies and\nenhance the CI model's performance. Extensive experimental results on seven\nreal-world datasets show that our enhanced Time-LLM outperforms the original\nbaseline model simply by incorporating the CVPE module, with no other changes.",
    "pdf_url": "http://arxiv.org/pdf/2505.12761v3",
    "published": "2025-05-19T06:41:14+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12760v2",
    "title": "Hypercontractive inequalities and Nikol'skiƒ≠-type inequalities on weighted Bergman spaces",
    "authors": [
      "Zipeng Wang",
      "Kenan Zhang"
    ],
    "abstract": "In this note, we obtianed hypercontractive inequalities between different\nweighted Bergman spaces. In addition, we establish Nikol'ski\\u{\\i}-type\ninequalities for weighted Bergman spaces with optimal constants.",
    "pdf_url": "http://arxiv.org/pdf/2505.12760v2",
    "published": "2025-05-19T06:40:33+00:00",
    "categories": [
      "math.FA",
      "math.CV",
      "32A36, 30H20, 46E15"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.14716v1",
    "title": "A Hybrid Quantum Classical Pipeline for X Ray Based Fracture Diagnosis",
    "authors": [
      "Sahil Tomar",
      "Rajeshwar Tripathi",
      "Sandeep Kumar"
    ],
    "abstract": "Bone fractures are a leading cause of morbidity and disability worldwide,\nimposing significant clinical and economic burdens on healthcare systems.\nTraditional X ray interpretation is time consuming and error prone, while\nexisting machine learning and deep learning solutions often demand extensive\nfeature engineering, large, annotated datasets, and high computational\nresources. To address these challenges, a distributed hybrid quantum classical\npipeline is proposed that first applies Principal Component Analysis (PCA) for\ndimensionality reduction and then leverages a 4 qubit quantum amplitude\nencoding circuit for feature enrichment. By fusing eight PCA derived features\nwith eight quantum enhanced features into a 16 dimensional vector and then\nclassifying with different machine learning models achieving 99% accuracy using\na public multi region X ray dataset on par with state of the art transfer\nlearning models while reducing feature extraction time by 82%.",
    "pdf_url": "http://arxiv.org/pdf/2505.14716v1",
    "published": "2025-05-19T06:38:24+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2507.18454v1",
    "title": "Sandwich: Separating Prefill-Decode Compilation for Efficient CPU LLM Serving",
    "authors": [
      "Juntao Zhao",
      "Jiuru Li",
      "Chuan Wu"
    ],
    "abstract": "Utilizing CPUs to serve large language models (LLMs) is a resource-friendly\nalternative to GPU serving. Existing CPU-based solutions ignore workload\ndifferences between the prefill and the decode phases of LLM inference,\napplying a static per-NUMA (Non-Uniform Memory Access) node model partition and\nutilizing vendor libraries for operator-level execution, which is suboptimal.\nWe propose Sandwich, a hardware-centric CPU-based LLM serving engine that uses\ndifferent execution plans for the prefill and decode phases and optimizes them\nseparately.\n  We evaluate Sandwich across diverse baselines and datasets on five CPU\nplatforms, including x86 with AVX-2 and AVX-512, as well as ARM with NEON.\nSandwich achieves an average 2.01x throughput improvement and 90% satisfactory\ntime-to-first-token (TTFT) and time-per-output-token (TPOT) latencies with up\nto 3.40x lower requirements in single sequence serving, and significant\nimprovement in Goodput in continuous-batching serving. The GEMM kernels\ngenerated by Sandwich outperform representative vendor kernels and other\ndynamic shape solutions, achieving performance comparable to static compilers\nwith three orders of magnitude less kernel tuning costs.",
    "pdf_url": "http://arxiv.org/pdf/2507.18454v1",
    "published": "2025-05-19T06:37:29+00:00",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC",
      "cs.PL"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12759v1",
    "title": "Your Offline Policy is Not Trustworthy: Bilevel Reinforcement Learning for Sequential Portfolio Optimization",
    "authors": [
      "Haochen Yuan",
      "Minting Pan",
      "Yunbo Wang",
      "Siyu Gao",
      "Philip S. Yu",
      "Xiaokang Yang"
    ],
    "abstract": "Reinforcement learning (RL) has shown significant promise for sequential\nportfolio optimization tasks, such as stock trading, where the objective is to\nmaximize cumulative returns while minimizing risks using historical data.\nHowever, traditional RL approaches often produce policies that merely memorize\nthe optimal yet impractical buying and selling behaviors within the fixed\ndataset. These offline policies are less generalizable as they fail to account\nfor the non-stationary nature of the market. Our approach, MetaTrader, frames\nportfolio optimization as a new type of partial-offline RL problem and makes\ntwo technical contributions. First, MetaTrader employs a bilevel learning\nframework that explicitly trains the RL agent to improve both in-domain profits\non the original dataset and out-of-domain performance across diverse\ntransformations of the raw financial data. Second, our approach incorporates a\nnew temporal difference (TD) method that approximates worst-case TD estimates\nfrom a batch of transformed TD targets, addressing the value overestimation\nissue that is particularly challenging in scenarios with limited offline data.\nOur empirical results on two public stock datasets show that MetaTrader\noutperforms existing methods, including both RL-based approaches and\ntraditional stock prediction models.",
    "pdf_url": "http://arxiv.org/pdf/2505.12759v1",
    "published": "2025-05-19T06:37:25+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12758v3",
    "title": "Global urban visual perception varies across demographics and personalities",
    "authors": [
      "Matias Quintana",
      "Youlong Gu",
      "Xiucheng Liang",
      "Yujun Hou",
      "Koichi Ito",
      "Yihan Zhu",
      "Mahmoud Abdelrahman",
      "Filip Biljecki"
    ],
    "abstract": "Understanding people's preferences is crucial for urban planning, yet current\napproaches often combine responses from multi-cultural populations, obscuring\ndemographic differences and risking amplifying biases. We conducted a\nlarge-scale urban visual perception survey of streetscapes worldwide using\nstreet view imagery, examining how demographics -- including gender, age,\nincome, education, race and ethnicity, and, for the first time, personality\ntraits -- shape perceptions among 1,000 participants with balanced demographics\nfrom five countries and 45 nationalities. This dataset, Street Perception\nEvaluation Considering Socioeconomics (SPECS), reveals demographic- and\npersonality-based differences across six traditional indicators (safe, lively,\nwealthy, beautiful, boring, depressing) and four new ones (live nearby, walk,\ncycle, green). Location-based sentiments further shape these preferences.\nMachine learning models trained on existing global datasets tend to\noverestimate positive indicators and underestimate negative ones compared to\nhuman responses, underscoring the need for local context. Our study aspires to\nrectify the myopic treatment of street perception, which rarely considers\ndemographics or personality traits.",
    "pdf_url": "http://arxiv.org/pdf/2505.12758v3",
    "published": "2025-05-19T06:35:11+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12757v2",
    "title": "High-Velocity Molecular Clouds in M83",
    "authors": [
      "Maki Nagata",
      "Fumi Egusa",
      "Fumiya Maeda",
      "Kazuki Tokuda",
      "Kotaro Kohno",
      "Kana Morokuma-Matsui",
      "Jin Koda"
    ],
    "abstract": "High-velocity clouds (HVCs), which are gas clouds moving at high velocity\nrelative to the galactic disk, may play a critical role in galaxy evolution,\npotentially supplying gas to the disk and triggering star formation. In this\nstudy, we focus on the nearby face-on barred spiral galaxy M83, where high\nspatial resolution, high-sensitivity CO (1-0) data are available. We identified\nmolecular clouds and searched for clouds with velocities deviating by more than\n50km/s from the disk velocity field as HVCs. A total of 10 HVCs were detected\n-- nine redshifted and one blueshifted -- clearly highlighting an asymmetry in\ntheir velocity distribution. These HVCs have radii of 30-80 pc, masses on the\norder of $10^5 M_\\odot$, and velocity dispersions of 3-20 km/s, displaying a\ntendency toward higher velocity dispersion compared to disk molecular clouds in\nM83. Most of the HVCs do not overlap with the candidates of supernova remnants,\nand the energy needed to drive HVCs at such high velocities exceeds single\nsupernova energy. Together with the asymmetry in their velocity distribution,\nwe thus conclude that most of the HVCs found in this study are inflow from\noutside the M83's disk.",
    "pdf_url": "http://arxiv.org/pdf/2505.12757v2",
    "published": "2025-05-19T06:34:27+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12756v1",
    "title": "A note on global in-time behavior for the semilinear nonlocal heat exchanger system",
    "authors": [
      "Wenhui Chen",
      "Xiaolin Li",
      "Yan Liu"
    ],
    "abstract": "We mainly study global in-time asymptotic behavior for the nonlocal\nreaction-diffusion system with fractional Laplacians which models dispersal of\nindividuals between two exchanging environments for its diffusive components\nand incorporates the Fujita-type power nonlinearities for its reactive\ncomponents. We derive a global in-time existence result in the super-critical\ncase, and large time asymptotic profiles of global in-time solutions in the\ngeneral $L^m$ framework. As a byproduct, the sharp lower bound estimates of\nlifespan for local in-time solutions in the sub-critical and critical cases are\ndetermined. These results extend the existence part of [S. Tr\\'eton, SIAM J.\nMath. Anal. (2024)].",
    "pdf_url": "http://arxiv.org/pdf/2505.12756v1",
    "published": "2025-05-19T06:33:12+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12755v1",
    "title": "Invariant algebraic D-modules over affine algebraic groups",
    "authors": [
      "Yunsong Wei"
    ],
    "abstract": "We study the invariant algebraic D-modules on an affine variety under the\naction of an algebraic group.For linear algebraic groups with the\nmultiplication action by themselves, such D-modules correspond to\nrepresentations of their Lie algebra. For unipotent algebraic groups, we show\nthat two invariant D-modules are isomorphic if and only if they lie in the same\nfiber of the GIT (Geometric Invariant Theory) quotient of the space of\nrepresentations under the action of conjugation. Additionally, we classify\ninvariant D-modules over the algebraic torus and the Borel subgroup of the\ngeneral linear group.",
    "pdf_url": "http://arxiv.org/pdf/2505.12755v1",
    "published": "2025-05-19T06:31:33+00:00",
    "categories": [
      "math.RT",
      "math.RA"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.13553v1",
    "title": "Selective Code Generation for Functional Guarantees",
    "authors": [
      "Jaewoo Jeong",
      "Taesoo Kim",
      "Sangdon Park"
    ],
    "abstract": "Large language models (LLMs) show human-level performance and their\nspecialized descendants, code generation models, play core roles in solving\ncomplex tasks, including mathematical reasoning and software development. On\nthe downside, the hallucination of LLMs mainly hinders their applicability to\nsystems requiring higher safety standards, thus drawing the attention of the AI\ncommunity. However, the hallucination of code generation models is rarely\nconsidered. One critical bottleneck in considering code hallucination is the\nintricate property of code to identify whether generated code has the intended\nfunctionality due to its un-natural form, different to natural languages.\nHandful of unit tests have been considered to address this issue, but\nscaling-up its size is extremely expensive. We address this core bottleneck by\nautomatically generating unit tests using dynamic code analysis tools, which\nleverages the \\emph{executable nature} of code. Given generated unit tests from\ntrue code for measuring functional correctness of generated code, we propose to\nlearn a \\emph{selective code generator}, which abstains from answering for\nunsure generation, to control the rate of code hallucination among\nnon-abstaining answers in terms of a false discovery rate. This learning\nalgorithm provides a controllability guarantee, providing trustworthiness of\ncode generation. Finally, we propose to use generated unit tests in evaluation\nas well as in learning for precise code evaluation, calling this evaluation\nparadigm \\emph{FuzzEval}. We demonstrate the efficacy of our selective code\ngenerator over open and closed code generators, showing clear benefit of\nleveraging generated unit tests along with the controllability of code\nhallucination and reasonable selection efficiency via our selective code\ngenerator.",
    "pdf_url": "http://arxiv.org/pdf/2505.13553v1",
    "published": "2025-05-19T06:29:16+00:00",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12754v1",
    "title": "ProDS: Preference-oriented Data Selection for Instruction Tuning",
    "authors": [
      "Wenya Guo",
      "Zhengkun Zhang",
      "Xumeng Liu",
      "Ying Zhang",
      "Ziyu Lu",
      "Haoze Zhu",
      "Xubo Liu",
      "Ruxue Yan"
    ],
    "abstract": "Instruction data selection aims to identify a high-quality subset from the\ntraining set that matches or exceeds the performance of the full dataset on\ntarget tasks. Existing methods focus on the instruction-to-response mapping,\nbut neglect the human preference for diverse responses. In this paper, we\npropose Preference-oriented Data Selection method (ProDS) that scores training\nsamples based on their alignment with preferences observed in the target set.\nOur key innovation lies in shifting the data selection criteria from merely\nestimating features for accurate response generation to explicitly aligning\ntraining samples with human preferences in target tasks. Specifically, direct\npreference optimization (DPO) is employed to estimate human preferences across\ndiverse responses. Besides, a bidirectional preference synthesis strategy is\ndesigned to score training samples according to both positive preferences and\nnegative preferences. Extensive experimental results demonstrate our\nsuperiority to existing task-agnostic and targeted methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.12754v1",
    "published": "2025-05-19T06:28:14+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12753v2",
    "title": "LiDAR MOT-DETR: A LiDAR-based Two-Stage Transformer for 3D Multiple Object Tracking",
    "authors": [
      "Martha Teiko Teye",
      "Ori Maoz",
      "Matthias Rottmann"
    ],
    "abstract": "Multi-object tracking from LiDAR point clouds presents unique challenges due\nto the sparse and irregular nature of the data, compounded by the need for\ntemporal coherence across frames. Traditional tracking systems often rely on\nhand-crafted features and motion models, which can struggle to maintain\nconsistent object identities in crowded or fast-moving scenes. We present a\nlidar-based two-staged DETR inspired transformer; a smoother and tracker. The\nsmoother stage refines lidar object detections, from any off-the-shelf\ndetector, across a moving temporal window. The tracker stage uses a DETR-based\nattention block to maintain tracks across time by associating tracked objects\nwith the refined detections using the point cloud as context. The model is\ntrained on the datasets nuScenes and KITTI in both online and offline (forward\npeeking) modes demonstrating strong performance across metrics such as\nID-switch and multiple object tracking accuracy (MOTA). The numerical results\nindicate that the online mode outperforms the lidar-only baseline and SOTA\nmodels on the nuScenes dataset, with an aMOTA of 0.722 and an aMOTP of 0.475,\nwhile the offline mode provides an additional 3 pp aMOTP.",
    "pdf_url": "http://arxiv.org/pdf/2505.12753v2",
    "published": "2025-05-19T06:25:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15845v1",
    "title": "Adaptive Tokenization: On the Hop-Overpriority Problem in Tokenized Graph Learning Models",
    "authors": [
      "Zhibiao Wang",
      "Yunlong Zhou",
      "Ziwei Zhang",
      "Mengmei Zhang",
      "Shirui Pan",
      "Chunming Hu",
      "Xiao Wang"
    ],
    "abstract": "Graph Transformers, leveraging the global attention to capture long-range\ndependencies in graph structures, have significantly advanced graph machine\nlearning, but face prohibitive computational complexity. Tokenized Graph\nLearning Models (TGLMs) address this issue by converting graphs into ordered\ntoken lists for scalable processing. Besides, TGLMs also empower Large Language\nModels (LLMs) to handle text-attributed graphs more effectively and thus are\nalso employed in Graph LLMs. However, existing TGLMs rely on hand-designed\ntoken lists and their adaptability to diverse graph learning scenarios remains\nunexplored. In this paper, we first conduct extensive empirical and theoretical\npreliminary studies for hand-designed token lists. Surprisingly, we identify an\nunexplored hop-overpriority problem: the common pre-defined token lists\noveremphasize nearby nodes and overwhelm the ability of TGLMs to balance local\nand global signals. This phenomenon is especially harmful for heterophilic\ngraphs. To address this problem, we propose the Learnable Graph Token List\n(LGTL), a plug-and-play module to replace hand-designed token lists in TGLMs.\nSpecifically, LGTL adaptively adjusts the weights across hops and prioritizes\ninformative nodes within hops through a graph attention gate module and a\nselection module, respectively. In this way, contextually informative nodes can\nbe adaptively emphasized for both homophilic and heterophilic graphs. Besides,\nwe theoretically show that LGTL can address the hop-overpriority problem.\nExtensive experiments on benchmarks validate the efficacy of LGTL across both\nGraph Transformers and Graph LLM backbones.",
    "pdf_url": "http://arxiv.org/pdf/2505.15845v1",
    "published": "2025-05-19T06:25:33+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12752v2",
    "title": "MOON: Multi-Objective Optimization-Driven Object-Goal Navigation Using a Variable-Horizon Set-Orienteering Planner",
    "authors": [
      "Daigo Nakajima",
      "Kanji Tanaka",
      "Daiki Iwata",
      "Kouki Terashima"
    ],
    "abstract": "Object-goal navigation (ON) enables autonomous robots to locate and reach\nuser-specified objects in previously unknown environments, offering promising\napplications in domains such as assistive care and disaster response. Existing\nON methods -- including training-free approaches, reinforcement learning, and\nzero-shot planners -- generally depend on active exploration to identify\nlandmark objects (e.g., kitchens or desks), followed by navigation toward\nsemantically related targets (e.g., a specific mug). However, these methods\noften lack strategic planning and do not adequately address trade-offs among\nmultiple objectives. To overcome these challenges, we propose a novel framework\nthat formulates ON as a multi-objective optimization problem (MOO), balancing\nfrontier-based knowledge exploration with knowledge exploitation over\npreviously observed landmarks; we call this framework MOON (MOO-driven ON). We\nimplement a prototype MOON system that integrates three key components: (1)\nbuilding on QOM [IROS05], a classical ON system that compactly and\ndiscriminatively encodes landmarks based on their semantic relevance to the\ntarget; (2) integrating StructNav [RSS23], a recently proposed training-free\nplanner, to enhance the navigation pipeline; and (3) introducing a\nvariable-horizon set orienteering problem formulation to enable global\noptimization over both exploration and exploitation strategies. This work\nrepresents an important first step toward developing globally optimized,\nnext-generation object-goal navigation systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12752v2",
    "published": "2025-05-19T06:20:37+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.13769v1",
    "title": "Non-planar Object Detection and Identification by Features Matching and Triangulation Growth",
    "authors": [
      "Filippo Leveni"
    ],
    "abstract": "Object detection and identification is surely a fundamental topic in the\ncomputer vision field; it plays a crucial role in many applications such as\nobject tracking, industrial robots control, image retrieval, etc. We propose a\nfeature-based approach for detecting and identifying distorted occurrences of a\ngiven template in a scene image by incremental grouping of feature matches\nbetween the image and the template. For this purpose, we consider the Delaunay\ntriangulation of template features as an useful tool through which to be guided\nin this iterative approach. The triangulation is treated as a graph and,\nstarting from a single triangle, neighboring nodes are considered and the\ncorresponding features are identified; then matches related to them are\nevaluated to determine if they are worthy to be grouped. This evaluation is\nbased on local consistency criteria derived from geometric and photometric\nproperties of local features. Our solution allows the identification of the\nobject in situations where geometric models (e.g. homography) does not hold,\nthus enable the detection of objects such that the template is non planar or\nwhen it is planar but appears distorted in the image. We show that our approach\nperforms just as well or better than application of homography-based RANSAC in\nscenarios in which distortion is nearly absent, while when the deformation\nbecomes relevant our method shows better description performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.13769v1",
    "published": "2025-05-19T06:20:07+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12751v1",
    "title": "Structure-based Anomaly Detection and Clustering",
    "authors": [
      "Filippo Leveni"
    ],
    "abstract": "Anomaly detection is a fundamental problem in domains such as healthcare,\nmanufacturing, and cybersecurity. This thesis proposes new unsupervised methods\nfor anomaly detection in both structured and streaming data settings. In the\nfirst part, we focus on structure-based anomaly detection, where normal data\nfollows low-dimensional manifolds while anomalies deviate from them. We\nintroduce Preference Isolation Forest (PIF), which embeds data into a\nhigh-dimensional preference space via manifold fitting, and isolates outliers\nusing two variants: Voronoi-iForest, based on geometric distances, and\nRuzHash-iForest, leveraging Locality Sensitive Hashing for scalability. We also\npropose Sliding-PIF, which captures local manifold information for streaming\nscenarios. Our methods outperform existing techniques on synthetic and real\ndatasets. We extend this to structure-based clustering with MultiLink, a novel\nmethod for recovering multiple geometric model families in noisy data.\nMultiLink merges clusters via a model-aware linkage strategy, enabling robust\nmulti-class structure recovery. It offers key advantages over existing\napproaches, such as speed, reduced sensitivity to thresholds, and improved\nrobustness to poor initial sampling. The second part of the thesis addresses\nonline anomaly detection in evolving data streams. We propose Online Isolation\nForest (Online-iForest), which uses adaptive, multi-resolution histograms and\ndynamically updates tree structures to track changes over time. It avoids\nretraining while achieving accuracy comparable to offline models, with superior\nefficiency for real-time applications. Finally, we tackle anomaly detection in\ncybersecurity via open-set recognition for malware classification. We enhance a\nGradient Boosting classifier with MaxLogit to detect unseen malware families, a\nmethod now integrated into Cleafy's production system.",
    "pdf_url": "http://arxiv.org/pdf/2505.12751v1",
    "published": "2025-05-19T06:20:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12750v1",
    "title": "Malware families discovery via Open-Set Recognition on Android manifest permissions",
    "authors": [
      "Filippo Leveni",
      "Matteo Mistura",
      "Francesco Iubatti",
      "Carmine Giangregorio",
      "Nicol√≤ Pastore",
      "Cesare Alippi",
      "Giacomo Boracchi"
    ],
    "abstract": "Malware are malicious programs that are grouped into families based on their\npenetration technique, source code, and other characteristics. Classifying\nmalware programs into their respective families is essential for building\neffective defenses against cyber threats. Machine learning models have a huge\npotential in malware detection on mobile devices, as malware families can be\nrecognized by classifying permission data extracted from Android manifest\nfiles. Still, the malware classification task is challenging due to the\nhigh-dimensional nature of permission data and the limited availability of\ntraining samples. In particular, the steady emergence of new malware families\nmakes it impossible to acquire a comprehensive training set covering all the\nmalware classes. In this work, we present a malware classification system that,\non top of classifying known malware, detects new ones. In particular, we\ncombine an open-set recognition technique developed within the computer vision\ncommunity, namely MaxLogit, with a tree-based Gradient Boosting classifier,\nwhich is particularly effective in classifying high-dimensional data. Our\nsolution turns out to be very practical, as it can be seamlessly employed in a\nstandard classification workflow, and efficient, as it adds minimal\ncomputational overhead. Experiments on public and proprietary datasets\ndemonstrate the potential of our solution, which has been deployed in a\nbusiness environment.",
    "pdf_url": "http://arxiv.org/pdf/2505.12750v1",
    "published": "2025-05-19T06:19:54+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12749v1",
    "title": "Diagonal orbits in the wonderful compactification",
    "authors": [
      "Yunsong Wei"
    ],
    "abstract": "The various types of compactifications of symmetric spaces and locally\nsymmetric spaces are well-studied. Among them, the De Concini-Procesi\ncompactification, also known as the wonderful compactification, of symmetric\nvarieties has been found to have many applications. Intuitively, this\ncompactification provides information at infinity. The diagonal action also\nextends the conjugation action on semisimple groups, which has received\nconsiderable attention. In this work, we will first describe the classification\nof certain diagonal orbits in the wonderful compactification of a semisimple\nadjoint group $ G $. We will then study the compactification of the maximal\ntorus through representations of the simply connected cover $ \\tilde{G} $,\nwhich, in a sense, parameterizes these diagonal orbits. Finally, we will focus\non constructing the family of closures of the Steinberg fiber. We will examine\nthe limit of this family and show that it is a union of He-Lusztig's $ G\n$-stable pieces.",
    "pdf_url": "http://arxiv.org/pdf/2505.12749v1",
    "published": "2025-05-19T06:11:49+00:00",
    "categories": [
      "math.RT",
      "math.AG"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12748v1",
    "title": "TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation",
    "authors": [
      "Hangyu Li",
      "Qin Zhao",
      "Haoran Xu",
      "Xinyu Jiang",
      "Qingwei Ben",
      "Feiyu Jia",
      "Haoyu Zhao",
      "Liang Xu",
      "Jia Zeng",
      "Hanqing Wang",
      "Bo Dai",
      "Junting Dong",
      "Jiangmiao Pang"
    ],
    "abstract": "Teleoperation is a cornerstone of embodied-robot learning, and bimanual\ndexterous teleoperation in particular provides rich demonstrations that are\ndifficult to obtain with fully autonomous systems. While recent studies have\nproposed diverse hardware pipelines-ranging from inertial motion-capture gloves\nto exoskeletons and vision-based interfaces-there is still no unified benchmark\nthat enables fair, reproducible comparison of these systems. In this paper, we\nintroduce TeleOpBench, a simulator-centric benchmark tailored to bimanual\ndexterous teleoperation. TeleOpBench contains 30 high-fidelity task\nenvironments that span pick-and-place, tool use, and collaborative\nmanipulation, covering a broad spectrum of kinematic and force-interaction\ndifficulty. Within this benchmark we implement four representative\nteleoperation modalities-(i) MoCap, (ii) VR device, (iii) arm-hand\nexoskeletons, and (iv) monocular vision tracking-and evaluate them with a\ncommon protocol and metric suite. To validate that performance in simulation is\npredictive of real-world behavior, we conduct mirrored experiments on a\nphysical dual-arm platform equipped with two 6-DoF dexterous hands. Across 10\nheld-out tasks we observe a strong correlation between simulator and hardware\nperformance, confirming the external validity of TeleOpBench. TeleOpBench\nestablishes a common yardstick for teleoperation research and provides an\nextensible platform for future algorithmic and hardware innovation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12748v1",
    "published": "2025-05-19T06:08:53+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12747v2",
    "title": "Temporal SU(1,1) Interferometer with Broadband Squeezed Light Injection",
    "authors": [
      "Zepeng Liu",
      "Tianyu Liu",
      "Hongmei Ma",
      "Chun-Hua Yuan"
    ],
    "abstract": "Temporal optics has attracted much attention due to its ability for lossless\nstretching of ultrafast temporal pulses. At the same time, spatial SU(1,1)\ninterferometers have been widely used because of their high sensitivity to\nphase changes. On this basis, we studied a temporal SU(1,1) interferometer\nbased on a temporal Fourier transform system and injected broadband squeezing\nlight into the interferometer for research. The results show that the output\nspectral characteristics of the interferometer depend on the ratio of the focal\ngroup velocity dispersion (GDD) of the two temporal lenses (this ratio is\ndefined as the scaling factor $M$) and the phase derivative of the applied\nphase. The scaling factor $M$ significantly affects the bandwidth and squeezing\ndegree of the output spectrum. The phase derivative induces a frequency-shift\neffect, and the magnitude of the shift exhibits a linear relationship to the\nphase derivative. Furthermore, in the output squeezed-state spectrum, the\ndistribution of squeezing degree concentrates at the center frequency and at\npositions where frequency shifts occur. As the value of scaling factor $M$\nincreases, the proportion of squeezing degree allocated at the center frequency\ncorrespondingly increases. This temporal SU(1,1) interferometer architecture\nopens new avenues for the control of non-classical fields in the time-frequency\ndomain and quantum information processing applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.12747v2",
    "published": "2025-05-19T06:03:41+00:00",
    "categories": [
      "physics.optics",
      "quant-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.12746v2",
    "title": "Correspondence of high-dimensional emotion structures elicited by video clips between humans and Multimodal LLMs",
    "authors": [
      "Haruka Asanuma",
      "Naoko Koide-Majima",
      "Ken Nakamura",
      "Takato Horii",
      "Shinji Nishimoto",
      "Masafumi Oizumi"
    ],
    "abstract": "Recent studies have revealed that human emotions exhibit a high-dimensional,\ncomplex structure. A full capturing of this complexity requires new approaches,\nas conventional models that disregard high dimensionality risk overlooking key\nnuances of human emotions. Here, we examined the extent to which the latest\ngeneration of rapidly evolving Multimodal Large Language Models (MLLMs) capture\nthese high-dimensional, intricate emotion structures, including capabilities\nand limitations. Specifically, we compared self-reported emotion ratings from\nparticipants watching videos with model-generated estimates (e.g., Gemini or\nGPT). We evaluated performance not only at the individual video level but also\nfrom emotion structures that account for inter-video relationships. At the\nlevel of simple correlation between emotion structures, our results\ndemonstrated strong similarity between human and model-inferred emotion\nstructures. To further explore whether the similarity between humans and models\nis at the signle item level or the coarse-categorical level, we applied Gromov\nWasserstein Optimal Transport. We found that although performance was not\nnecessarily high at the strict, single-item level, performance across video\ncategories that elicit similar emotions was substantial, indicating that the\nmodel could infer human emotional experiences at the category level. Our\nresults suggest that current state-of-the-art MLLMs broadly capture the complex\nhigh-dimensional emotion structures at the category level, as well as their\napparent limitations in accurately capturing entire structures at the\nsingle-item level.",
    "pdf_url": "http://arxiv.org/pdf/2505.12746v2",
    "published": "2025-05-19T06:03:22+00:00",
    "categories": [
      "cs.AI",
      "I.2.7; I.2.10; I.5.1"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12745v1",
    "title": "PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization",
    "authors": [
      "Dong Kyu Cho",
      "Inwoo Hwang",
      "Sanghack Lee"
    ],
    "abstract": "Data augmentation is a popular tool for single source domain generalization,\nwhich expands the source domain by generating simulated ones, improving\ngeneralization on unseen target domains. In this work, we show that the\nperformance of such augmentation-based methods in the target domains\nuniversally fluctuates during training, posing challenges in model selection\nunder realistic scenarios. We argue that the fluctuation stems from the\ninability of the model to accumulate the knowledge learned from diverse\naugmentations, exacerbating feature distortion during training. Based on this\nobservation, we propose a novel generalization method, coined Parameter-Space\nEnsemble with Entropy Regularization (PEER), that uses a proxy model to learn\nthe augmented data on behalf of the main model. The main model is updated by\naveraging its parameters with the proxy model, progressively accumulating\nknowledge over the training steps. Maximizing the mutual information between\nthe output representations of the two models guides the learning process of the\nproxy model, mitigating feature distortion during training. Experimental\nresults demonstrate the effectiveness of PEER in reducing the OOD performance\nfluctuation and enhancing generalization across various datasets, including\nPACS, Digits, Office-Home, and VLCS. Notably, our method with simple random\naugmentation achieves state-of-the-art performance, surpassing prior approaches\non sDG that utilize complex data augmentation strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.12745v1",
    "published": "2025-05-19T06:01:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12744v1",
    "title": "Incentivizing Multimodal Reasoning in Large Models for Direct Robot Manipulation",
    "authors": [
      "Weiliang Tang",
      "Dong Jing",
      "Jia-Hui Pan",
      "Zhiwu Lu",
      "Yun-Hui Liu",
      "Li Erran Li",
      "Mingyu Ding",
      "Chi-Wing Fu"
    ],
    "abstract": "Recent Large Multimodal Models have demonstrated remarkable reasoning\ncapabilities, especially in solving complex mathematical problems and realizing\naccurate spatial perception. Our key insight is that these emerging abilities\ncan naturally extend to robotic manipulation by enabling LMMs to directly infer\nthe next goal in language via reasoning, rather than relying on a separate\naction head. However, this paradigm meets two main challenges: i) How to make\nLMMs understand the spatial action space, and ii) How to fully exploit the\nreasoning capacity of LMMs in solving these tasks. To tackle the former\nchallenge, we propose a novel task formulation, which inputs the current states\nof object parts and the gripper, and reformulates rotation by a new axis\nrepresentation instead of traditional Euler angles. This representation is more\ncompatible with spatial reasoning and easier to interpret within a unified\nlanguage space. For the latter challenge, we design a pipeline to utilize\ncutting-edge LMMs to generate a small but high-quality reasoning dataset of\nmulti-round dialogues that successfully solve manipulation tasks for supervised\nfine-tuning. Then, we perform reinforcement learning by trial-and-error\ninteractions in simulation to further enhance the model's reasoning abilities\nfor robotic manipulation. Our resulting reasoning model built upon a 7B\nbackbone, named ReasonManip, demonstrates three notable advantages driven by\nits system-2 level reasoning capabilities: i) exceptional generalizability to\nout-of-distribution environments, objects, and tasks; ii) inherent sim-to-real\ntransfer ability enabled by the unified language representation shared across\ndomains; iii) transparent interpretability connecting high-level reasoning and\nlow-level control. Extensive experiments demonstrate the effectiveness of the\nproposed paradigm and its potential to advance LMM-driven robotic manipulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12744v1",
    "published": "2025-05-19T06:00:14+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12743v2",
    "title": "Deep Generative Modeling with Spatial and Network Images: An Explainable AI (XAI) Approach",
    "authors": [
      "Yeseul Jeon",
      "Rajarshi Guhaniyogi",
      "Aaron Scheffler"
    ],
    "abstract": "This article addresses the challenge of modeling the amplitude of spatially\nindexed low frequency fluctuations (ALFF) in resting state functional MRI as a\nfunction of cortical structural features and a multi-task coactivation network\nin the Adolescent Brain Cognitive Development (ABCD) Study. It proposes a\ngenerative model that integrates effects of spatially-varying inputs and a\nnetwork-valued input using deep neural networks to capture complex non-linear\nand spatial associations with the output. The method models spatial smoothness,\naccounts for subject heterogeneity and complex associations between network and\nspatial images at different scales, enables accurate inference of each images\neffect on the output image, and allows prediction with uncertainty\nquantification via Monte Carlo dropout, contributing to one of the first\nExplainable AI (XAI) frameworks for heterogeneous imaging data. The model is\nhighly scalable to high-resolution data without the heavy pre-processing or\nsummarization often required by Bayesian methods. Empirical results demonstrate\nits strong performance compared to existing statistical and deep learning\nmethods. We applied the XAI model to the ABCD data which revealed associations\nbetween cortical features and ALFF throughout the entire brain. Our model\nperformed comparably to existing methods in predictive accuracy but provided\nsuperior uncertainty quantification and faster computation, demonstrating its\neffectiveness for large-scale neuroimaging analysis. Open-source software in\nPython for XAI is available.",
    "pdf_url": "http://arxiv.org/pdf/2505.12743v2",
    "published": "2025-05-19T05:57:55+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.12742v1",
    "title": "MVAR: Visual Autoregressive Modeling with Scale and Spatial Markovian Conditioning",
    "authors": [
      "Jinhua Zhang",
      "Wei Long",
      "Minghao Han",
      "Weiyi You",
      "Shuhang Gu"
    ],
    "abstract": "Essential to visual generation is efficient modeling of visual data priors.\nConventional next-token prediction methods define the process as learning the\nconditional probability distribution of successive tokens. Recently, next-scale\nprediction methods redefine the process to learn the distribution over\nmulti-scale representations, significantly reducing generation latency.\nHowever, these methods condition each scale on all previous scales and require\neach token to consider all preceding tokens, exhibiting scale and spatial\nredundancy. To better model the distribution by mitigating redundancy, we\npropose Markovian Visual AutoRegressive modeling (MVAR), a novel autoregressive\nframework that introduces scale and spatial Markov assumptions to reduce the\ncomplexity of conditional probability modeling. Specifically, we introduce a\nscale-Markov trajectory that only takes as input the features of adjacent\npreceding scale for next-scale prediction, enabling the adoption of a parallel\ntraining strategy that significantly reduces GPU memory consumption.\nFurthermore, we propose spatial-Markov attention, which restricts the attention\nof each token to a localized neighborhood of size k at corresponding positions\non adjacent scales, rather than attending to every token across these scales,\nfor the pursuit of reduced modeling complexity. Building on these improvements,\nwe reduce the computational complexity of attention calculation from O(N^2) to\nO(Nk), enabling training with just eight NVIDIA RTX 4090 GPUs and eliminating\nthe need for KV cache during inference. Extensive experiments on ImageNet\ndemonstrate that MVAR achieves comparable or superior performance with both\nsmall model trained from scratch and large fine-tuned models, while reducing\nthe average GPU memory footprint by 3.0x.",
    "pdf_url": "http://arxiv.org/pdf/2505.12742v1",
    "published": "2025-05-19T05:56:44+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12741v1",
    "title": "Dense Communication between Language Models",
    "authors": [
      "Shiguang Wu",
      "Yaqing Wang",
      "Quanming Yao"
    ],
    "abstract": "As higher-level intelligence emerges from the combination of modular\ncomponents with lower-level intelligence, many works combines Large Language\nModels (LLMs) for collective intelligence. Such combination is achieved by\nbuilding communications among LLMs. While current systems primarily facilitate\nsuch communication through natural language, this paper proposes a novel\nparadigm of direct dense vector communication between LLMs. Our approach\neliminates the unnecessary embedding and de-embedding steps when LLM interact\nwith another, enabling more efficient information transfer, fully\ndifferentiable optimization pathways, and exploration of capabilities beyond\nhuman heuristics. We use such stripped LLMs as vertexes and optimizable seq2seq\nmodules as edges to construct LMNet, with similar structure as MLPs. By\nutilizing smaller pre-trained LLMs as vertexes, we train a LMNet that achieves\ncomparable performance with LLMs in similar size with only less than 0.1%\ntraining cost. This offers a new perspective on scaling for general\nintelligence rather than training a monolithic LLM from scratch. Besides, the\nproposed method can be used for other applications, like customizing LLM with\nlimited data, showing its versatility.",
    "pdf_url": "http://arxiv.org/pdf/2505.12741v1",
    "published": "2025-05-19T05:56:06+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12740v1",
    "title": "Multi-Reference and Adaptive Nonlinear Transform Source-Channel Coding for Wireless Image Semantic Transmission",
    "authors": [
      "Cheng Yuan",
      "Yufei Jiang",
      "Xu Zhu"
    ],
    "abstract": "We propose a multi-reference and adaptive nonlinear transform source-channel\ncoding (MA-NTSCC) system for wireless image semantic transmission to improve\nrate-distortion (RD) performance by introducing multi-dimensional contexts into\nthe entropy model of the state-of-the-art (SOTA) NTSCC system. Improvements in\nRD performance of the proposed MA-NTSCC system are particularly significant in\nhigh-resolution image transmission under low bandwidth constraints. The\nproposed multi-reference entropy model leverages correlations within the latent\nrepresentation in both spatial and channel dimensions. In the spatial\ndimension, the latent representation is divided into anchors and non-anchors in\na checkerboard pattern, where anchors serve as reference to estimate the mutual\ninformation between anchors and non-anchors. In the channel dimension, the\nlatent representation is partitioned into multiple groups, and features in\nprevious groups are analyzed to estimate the mutual information between\nfeatures in previous and current groups. Taking mutual information into\naccount, the entropy model provides an accurate estimation on the entropy,\nwhich enables efficient bandwidth allocation and enhances RD performance.\nAdditionally, the proposed lightweight adaptation modules enable the proposed\nMA-NTSCC model to achieve transmission quality comparable to separately trained\nmodels across various channel conditions and bandwidth requirements. In\ncontrast, traditional NTSCC models provide signal-to-noise ratio\n(SNR)-distortion performance degrading with channel quality deviating from the\nfixed training SNR, and consume inflexible bandwidth to transmit an image.\nComprehensive experiments are conducted to verify the peak signal-to-noise\nratio (PSNR) performance and adaptability of the proposed MA-NTSCC model\nsuperior to SOTA methods over both additive white Gaussian noise channel and\nRayleigh fading channel.",
    "pdf_url": "http://arxiv.org/pdf/2505.12740v1",
    "published": "2025-05-19T05:55:06+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12739v1",
    "title": "Secrecy Capacity of Hybrid VLC-RF Systems with Light Energy Harvesting",
    "authors": [
      "Tuan A. Hoang",
      "Thanh V. Pham",
      "Chuyen T. Nguyen"
    ],
    "abstract": "This paper studies the performance of physical layer security (PLS) in a\nmulti-user hybrid heterogeneous visible light communication (VLC) and radio\nfrequency (RF) wireless communication system with simultaneous lightwave\ninformation and power transfer (SLIPT). In the considered system, VLC is used\nfor downlink (DL) while RF is employed for uplink (UL) transmission. In\naddition, to support multiple users, time division multiple access (TDMA) is\nassumed for both DL and UL channels. In the DL, each user receives information\nduring its allocated time slot of the TDMA frame and harvests energy from the\nreceived signal outside the time slot. The harvested energy is then used for\ntransmitting the signal over the UL channel, which is subject to eavesdropping\nby an unauthorized user. Therefore, PLS is employed to protect the\nconfidentiality of the UL information. Then, an optimization problem is\nformulated to solve the optimal DL and UL time slots that maximize the PLS\nperformance given a target sum rate of the DL. We show that the problem can be\ncast as a difference of convex functions (DC) program, which can be solved\nefficiently using the DC algorithm (DCA).",
    "pdf_url": "http://arxiv.org/pdf/2505.12739v1",
    "published": "2025-05-19T05:53:29+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "eess.SP"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.12738v1",
    "title": "EpiLLM: Unlocking the Potential of Large Language Models in Epidemic Forecasting",
    "authors": [
      "Chenghua Gong",
      "Rui Sun",
      "Yuhao Zheng",
      "Juyuan Zhang",
      "Tianjun Gu",
      "Liming Pan",
      "Linyuan Lv"
    ],
    "abstract": "Advanced epidemic forecasting is critical for enabling precision containment\nstrategies, highlighting its strategic importance for public health security.\nWhile recent advances in Large Language Models (LLMs) have demonstrated\neffectiveness as foundation models for domain-specific tasks, their potential\nfor epidemic forecasting remains largely unexplored. In this paper, we\nintroduce EpiLLM, a novel LLM-based framework tailored for spatio-temporal\nepidemic forecasting. Considering the key factors in real-world epidemic\ntransmission: infection cases and human mobility, we introduce a dual-branch\narchitecture to achieve fine-grained token-level alignment between such complex\nepidemic patterns and language tokens for LLM adaptation. To unleash the\nmulti-step forecasting and generalization potential of LLM architectures, we\npropose an autoregressive modeling paradigm that reformulates the epidemic\nforecasting task into next-token prediction. To further enhance LLM perception\nof epidemics, we introduce spatio-temporal prompt learning techniques, which\nstrengthen forecasting capabilities from a data-driven perspective. Extensive\nexperiments show that EpiLLM significantly outperforms existing baselines on\nreal-world COVID-19 datasets and exhibits scaling behavior characteristic of\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.12738v1",
    "published": "2025-05-19T05:53:25+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12737v1",
    "title": "Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning",
    "authors": [
      "Hongjoon Ahn",
      "Heewoong Choi",
      "Jisu Han",
      "Taesup Moon"
    ],
    "abstract": "Offline goal-conditioned reinforcement learning (GCRL) offers a practical\nlearning paradigm where goal-reaching policies are trained from abundant\nunlabeled (reward-free) datasets without additional environment interaction.\nHowever, offline GCRL still struggles with long-horizon tasks, even with recent\nadvances that employ hierarchical policy structures, such as HIQL. By\nidentifying the root cause of this challenge, we observe the following\ninsights: First, performance bottlenecks mainly stem from the high-level\npolicy's inability to generate appropriate subgoals. Second, when learning the\nhigh-level policy in the long-horizon regime, the sign of the advantage signal\nfrequently becomes incorrect. Thus, we argue that improving the value function\nto produce a clear advantage signal for learning the high-level policy is\nessential. In this paper, we propose a simple yet effective solution:\nOption-aware Temporally Abstracted value learning, dubbed OTA, which\nincorporates temporal abstraction into the temporal-difference learning\nprocess. By modifying the value update to be option-aware, the proposed\nlearning scheme contracts the effective horizon length, enabling better\nadvantage estimates even in long-horizon regimes. We experimentally show that\nthe high-level policy extracted using the OTA value function achieves strong\nperformance on complex tasks from OGBench, a recently proposed offline GCRL\nbenchmark, including maze navigation and visual robotic manipulation\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12737v1",
    "published": "2025-05-19T05:51:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12736v1",
    "title": "Deep Unfolding with Kernel-based Quantization in MIMO Detection",
    "authors": [
      "Zeyi Ren",
      "Jingreng Lei",
      "Yichen Jin",
      "Ermo Hua",
      "Qingfeng Lin",
      "Chen Zhang",
      "Bowen Zhou",
      "Yik-Chung Wu"
    ],
    "abstract": "The development of edge computing places critical demands on energy-efficient\nmodel deployment for multiple-input multiple-output (MIMO) detection tasks.\nDeploying deep unfolding models such as PGD-Nets and ADMM-Nets into\nresource-constrained edge devices using quantization methods is challenging.\nExisting quantization methods based on quantization aware training (QAT) suffer\nfrom performance degradation due to their reliance on parametric distribution\nassumption of activations and static quantization step sizes. To address these\nchallenges, this paper proposes a novel kernel-based adaptive quantization\n(KAQ) framework for deep unfolding networks. By utilizing a joint kernel\ndensity estimation (KDE) and maximum mean discrepancy (MMD) approach to align\nactivation distributions between full-precision and quantized models, the need\nfor prior distribution assumptions is eliminated. Additionally, a dynamic step\nsize updating method is introduced to adjust the quantization step size based\non the channel conditions of wireless networks. Extensive simulations\ndemonstrate that the accuracy of proposed KAQ framework outperforms traditional\nmethods and successfully reduces the model's inference latency.",
    "pdf_url": "http://arxiv.org/pdf/2505.12736v1",
    "published": "2025-05-19T05:50:24+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12735v1",
    "title": "Metric pairs and tuples in theory and applications",
    "authors": [
      "Andr√©s Ahumada G√≥mez",
      "Mauricio Che",
      "Manuel Cuerno"
    ],
    "abstract": "We present theoretical properties of the space of metric pairs equipped with\nthe Gromov--Hausdorff distance. First, we establish the classical metric\nseparability and the geometric geodesicity of this space. Second, we prove an\nArzel\\`a--Ascoli-type theorem for metric pairs. Third, extending a result by\nCassorla, we show that the set of pairs consisting of a $2$-dimensional compact\nRiemannian manifold and a $2$-dimensional submanifold with boundary that can be\nisometrically embedded in $\\mathbb{R}^3$ is dense in the space of compact\nmetric pairs. Finally, to broaden the scope of potential applications, we\ndescribe scenarios where the Gromov--Hausdorff distance between metric pairs or\ntuples naturally arises.",
    "pdf_url": "http://arxiv.org/pdf/2505.12735v1",
    "published": "2025-05-19T05:50:22+00:00",
    "categories": [
      "math.MG",
      "30L15, 53C23, 53C20, 55N31"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12734v1",
    "title": "SounDiT: Geo-Contextual Soundscape-to-Landscape Generation",
    "authors": [
      "Junbo Wang",
      "Haofeng Tan",
      "Bowen Liao",
      "Albert Jiang",
      "Teng Fei",
      "Qixing Huang",
      "Zhengzhong Tu",
      "Shan Ye",
      "Yuhao Kang"
    ],
    "abstract": "We present a novel and practically significant problem-Geo-Contextual\nSoundscape-to-Landscape (GeoS2L) generation-which aims to synthesize\ngeographically realistic landscape images from environmental soundscapes. Prior\naudio-to-image generation methods typically rely on general-purpose datasets\nand overlook geographic and environmental contexts, resulting in unrealistic\nimages that are misaligned with real-world environmental settings. To address\nthis limitation, we introduce a novel geo-contextual computational framework\nthat explicitly integrates geographic knowledge into multimodal generative\nmodeling. We construct two large-scale geo-contextual multimodal datasets,\nSoundingSVI and SonicUrban, pairing diverse soundscapes with real-world\nlandscape images. We propose SounDiT, a novel Diffusion Transformer (DiT)-based\nmodel that incorporates geo-contextual scene conditioning to synthesize\ngeographically coherent landscape images. Furthermore, we propose a\npractically-informed geo-contextual evaluation framework, the Place Similarity\nScore (PSS), across element-, scene-, and human perception-levels to measure\nconsistency between input soundscapes and generated landscape images. Extensive\nexperiments demonstrate that SounDiT outperforms existing baselines in both\nvisual fidelity and geographic settings. Our work not only establishes\nfoundational benchmarks for GeoS2L generation but also highlights the\nimportance of incorporating geographic domain knowledge in advancing multimodal\ngenerative models, opening new directions at the intersection of generative AI,\ngeography, urban planning, and environmental sciences.",
    "pdf_url": "http://arxiv.org/pdf/2505.12734v1",
    "published": "2025-05-19T05:47:13+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.GR",
      "cs.HC",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.12733v1",
    "title": "Unifying Strain-driven and Pressure-driven Superconductivity in La$_{3}$Ni$_{2}$O$_{7}$: Suppressed charge/spin density waves and enhanced interlayer coupling",
    "authors": [
      "Xin-Wei Yi",
      "Wei Li",
      "Jing-Yang You",
      "Bo Gu",
      "Gang Su"
    ],
    "abstract": "Recent strain-stabilized superconductivity at ambient pressure in\nLa$_3$Ni$_2$O$_{7}$ films opens new avenues for nickelates research, in\nparallel with its pressure-induced counterpart. Using density functional theory\ncalculations, we elucidate the critical factors bridging strain- and\npressure-driven superconductivity in La$_3$Ni$_2$O$_{7}$ by comprehensively\nanalyzing structural, electronic, magnetic, and density wave characteristics.\nConsistent with recent scanning transmission electron microscopy observations,\nwe find an $I4/mmm$ structural transition at $-0.9\\%$ strain, preceding\nsuperconductivity onset. Electronic analysis shows compressive strain lowers\nNi-$d_{z^2}$ orbital energy levels, while interfacial Sr diffusion effectively\nreconstructs the $d_{z^2}$ pockets, quantitatively matching angle-resolved\nphotoemission spectroscopy experiments. The interlayer antiferromagnetic\ncoupling $J_\\perp$ under pressure or strain closely tracks experimental\nsuperconducting $T_c$ variation. The dome-shaped pressure dependence and\nmonotonic strain dependence of $J_\\perp$ mainly arise from modulations in the\napical oxygen $p_z$ energy levels. Moreover, compressive strain suppresses both\ncharge density waves (CDW) and spin density waves (SDW) instabilities analogous\nto pressure effects, with SDW vanishing concurrently with the structural\ntransition and CDW disappearing at $\\sim-3.3\\%$ strain. Our results indicate\nthat suppressed density waves and enhanced $J_\\perp$ are crucial for both\nstrain- and pressure-driven superconductivity. Accordingly, we propose several\ncandidate substrates capable of achieving greater compressive strain, thereby\npotentially increasing $T_c$.",
    "pdf_url": "http://arxiv.org/pdf/2505.12733v1",
    "published": "2025-05-19T05:46:04+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.12732v1",
    "title": "Terrain-aware Deep Learning for Wind Energy Applications: From Kilometer-scale Forecasts to Fine Wind Fields",
    "authors": [
      "Chensen Lin",
      "Ruian Tie",
      "Shihong Yi",
      "Xiaohui Zhong",
      "Hao Li"
    ],
    "abstract": "High-resolution wind information is essential for wind energy planning and\npower forecasting, particularly in regions with complex terrain. However, most\nAI-based weather forecasting models operate at kilometer-scale resolution,\nconstrained by the reanalysis datasets they are trained on. Here we introduce\nFuXi-CFD, an AI-based downscaling framework designed to generate detailed\nthree-dimensional wind fields at 30-meter horizontal resolution, using only\ncoarse-resolution atmospheric inputs. The model is trained on a large-scale\ndataset generated via computational fluid dynamics (CFD), encompassing a wide\nrange of terrain types, surface roughness, and inflow conditions. Remarkably,\nFuXi-CFD predicts full 3D wind structures -- including vertical wind and\nturbulent kinetic energy -- based solely on horizontal wind input at 10 meters\nabove ground, the typical output of AI-based forecast systems. It achieves\nCFD-comparable accuracy while reducing inference time from hours to seconds. By\nbridging the resolution gap between regional forecasts and site-specific wind\ndynamics, FuXi-CFD offers a scalable and operationally efficient solution to\nsupport the growing demands of renewable energy deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.12732v1",
    "published": "2025-05-19T05:45:03+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12731v2",
    "title": "Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps",
    "authors": [
      "Jie Ou",
      "Jinyu Guo",
      "Shuaihong Jiang",
      "Zhaokun Wang",
      "Libo Qin",
      "Shunyu Yao",
      "Wenhong Tian"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has emerged as a pivotal method for\nexpanding the knowledge of large language models. To handle complex queries\nmore effectively, researchers developed Adaptive-RAG (A-RAG) to enhance the\ngenerated quality through multiple interactions with external knowledge bases.\nDespite its effectiveness, A-RAG exacerbates the pre-existing efficiency\nchallenges inherent in RAG, which are attributable to its reliance on multiple\niterations of generation. Existing A-RAG approaches process all retrieved\ncontents from scratch. However, they ignore the situation where there is a\nsignificant overlap in the content of the retrieval results across rounds. The\noverlapping content is redundantly represented, which leads to a large\nproportion of repeated computations, thus affecting the overall efficiency. To\naddress this issue, this paper introduces a model-agnostic approach that can be\ngenerally applied to A-RAG methods, which is dedicated to reducing the\nredundant representation process caused by the overlapping of retrieval\nresults. Specifically, we use cache access and parallel generation to speed up\nthe prefilling and decoding stages respectively. Additionally, we also propose\nan instruction-driven module to further guide the model to more effectively\nattend to each part of the content in a more suitable way for LLMs. Experiments\nshow that our approach achieves 2.79 and 2.33 times significant acceleration on\naverage for prefilling and decoding respectively while maintaining equal\ngeneration quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.12731v2",
    "published": "2025-05-19T05:39:38+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12730v1",
    "title": "Leveraging Large Reconfigurable Intelligent Surfaces as Anchors for Near-Field Positioning",
    "authors": [
      "Zeyu Huang",
      "Markus Rupp",
      "Stefan Schwarz"
    ],
    "abstract": "In this work, we present a recent investigation on leveraging large\nreconfigurable intelligent surfaces (RIS) as anchors for positioning in\nwireless communication systems. Unlike existing approaches, we explicitly\naddress the uncertainty arising from the substantial physical size of the RIS,\nparticularly relevant when a user equipment resides in the near field, and\npropose a method that ensures accurate positioning under these conditions. We\nderive the corresponding Cramer-Rao bound for our scheme and validate the\neffectiveness of our scheme through numerical experiments, highlighting both\nthe feasibility and potential of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.12730v1",
    "published": "2025-05-19T05:37:01+00:00",
    "categories": [
      "cs.ET",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.12729v1",
    "title": "Bridging the Modality Gap: Enhancing Channel Prediction with Semantically Aligned LLMs and Knowledge Distillation",
    "authors": [
      "Zhaoyang Li",
      "Qianqian Yang",
      "Zehui Xiong",
      "Zhiguo Shi",
      "Tony Q. S. Quek"
    ],
    "abstract": "Accurate channel prediction is essential in massive multiple-input\nmultiple-output (m-MIMO) systems to improve precoding effectiveness and reduce\nthe overhead of channel state information (CSI) feedback. However, existing\nmethods often suffer from accumulated prediction errors and poor generalization\nto dynamic wireless environments. Large language models (LLMs) have\ndemonstrated remarkable modeling and generalization capabilities in tasks such\nas time series prediction, making them a promising solution. Nevertheless, a\nsignificant modality gap exists between the linguistic knowledge embedded in\npretrained LLMs and the intrinsic characteristics of CSI, posing substantial\nchallenges for their direct application to channel prediction. Moreover, the\nlarge parameter size of LLMs hinders their practical deployment in real-world\ncommunication systems with stringent latency constraints. To address these\nchallenges, we propose a novel channel prediction framework based on\nsemantically aligned large models, referred to as CSI-ALM, which bridges the\nmodality gap between natural language and channel information. Specifically, we\ndesign a cross-modal fusion module that aligns CSI representations .\nAdditionally, we maximize the cosine similarity between word embeddings and CSI\nembeddings to construct semantic cues. To reduce complexity and enable\npractical implementation, we further introduce a lightweight version of the\nproposed approach, called CSI-ALM-Light. This variant is derived via a\nknowledge distillation strategy based on attention matrices. Extensive\nexperimental results demonstrate that CSI-ALM achieves a 1 dB gain over\nstate-of-the-art deep learning methods. Moreover, under limited training data\nconditions, CSI-ALM-Light, with only 0.34M parameters, attains performance\ncomparable to CSI-ALM and significantly outperforms conventional deep learning\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.12729v1",
    "published": "2025-05-19T05:35:35+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12728v2",
    "title": "FLASH: Latent-Aware Semi-Autoregressive Speculative Decoding for Multimodal Tasks",
    "authors": [
      "Zihua Wang",
      "Ruibo Li",
      "Haozhe Du",
      "Joey Tianyi Zhou",
      "Yu Zhang",
      "Xu Yang"
    ],
    "abstract": "Large language and multimodal models (LLMs and LMMs) exhibit strong inference\ncapabilities but are often limited by slow decoding speeds. This challenge is\nespecially acute in LMMs, where visual inputs typically comprise more tokens\nwith lower information density than text -- an issue exacerbated by recent\ntrends toward finer-grained visual tokenizations to boost performance.\nSpeculative decoding has been effective in accelerating LLM inference by using\na smaller draft model to generate candidate tokens, which are then selectively\nverified by the target model, improving speed without sacrificing output\nquality. While this strategy has been extended to LMMs, existing methods\nlargely overlook the unique properties of visual inputs and depend solely on\ntext-based draft models. In this work, we propose \\textbf{FLASH} (Fast\nLatent-Aware Semi-Autoregressive Heuristics), a speculative decoding framework\ndesigned specifically for LMMs, which leverages two key properties of\nmultimodal data to design the draft model. First, to address redundancy in\nvisual tokens, we propose a lightweight latent-aware token compression\nmechanism. Second, recognizing that visual objects often co-occur within a\nscene, we employ a semi-autoregressive decoding strategy to generate multiple\ntokens per forward pass. These innovations accelerate draft decoding while\nmaintaining high acceptance rates, resulting in faster overall inference.\nExperiments show that FLASH significantly outperforms prior speculative\ndecoding approaches in both unimodal and multimodal settings, achieving up to\n\\textbf{2.68$\\times$} speed-up on video captioning and \\textbf{2.55$\\times$} on\nvisual instruction tuning tasks compared to the original LMM. Our code is\navailable \\href{https://github.com/ZihuaEvan/FlashSD/}{[here]}.",
    "pdf_url": "http://arxiv.org/pdf/2505.12728v2",
    "published": "2025-05-19T05:35:30+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12727v2",
    "title": "What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma",
    "authors": [
      "Han Meng",
      "Yancan Chen",
      "Yunan Li",
      "Yitian Yang",
      "Jungup Lee",
      "Renwen Zhang",
      "Yi-Chieh Lee"
    ],
    "abstract": "Mental-health stigma remains a pervasive social problem that hampers\ntreatment-seeking and recovery. Existing resources for training neural models\nto finely classify such stigma are limited, relying primarily on social-media\nor synthetic data without theoretical underpinnings. To remedy this gap, we\npresent an expert-annotated, theory-informed corpus of human-chatbot\ninterviews, comprising 4,141 snippets from 684 participants with documented\nsocio-cultural backgrounds. Our experiments benchmark state-of-the-art neural\nmodels and empirically unpack the challenges of stigma detection. This dataset\ncan facilitate research on computationally detecting, neutralizing, and\ncounteracting mental-health stigma. Our corpus is openly available at\nhttps://github.com/HanMeng2004/Mental-Health-Stigma-Interview-Corpus.",
    "pdf_url": "http://arxiv.org/pdf/2505.12727v2",
    "published": "2025-05-19T05:31:42+00:00",
    "categories": [
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12726v2",
    "title": "Characterization of phospholipid-cholesterol bilayers as self-assembled amphiphile block polymers that contain headgroups",
    "authors": [
      "Xiaoyuan Wang",
      "Fredric S. Cohen",
      "Shixin Xu",
      "Yongqiang Cai"
    ],
    "abstract": "Cholesterol is known to modulate the structure and function of biological\nmembranes. In this study, we use self-consistent field theory (SCFT) to\ninvestigate phospholipid/cholesterol bilayer membranes modeled with two types\nof diblock copolymers. These copolymer-based bilayers serve as biomimetic\nplatforms with applications in areas such as drug delivery. Our simulations\nidentify a minimum free energy configuration characterized by phospholipid\ntails tilted relative to the membrane normal. The model quantitatively captures\nthe well-known area condensation effect as cholesterol concentration increases,\nalong with membrane thickening and reduced tilt angle. Thermodynamically, we\nobserve a linear dependence between cholesterol's chemical potential and its\nconcentration within the 37-50% range, consistent with experimental results.\nAdditionally, we analyze the effects of block copolymer length and headgroup\ninteractions on bilayer structure. Interactions between phospholipid headgroups\nand the solvent emerge as the most influential. This work provides a\ntheoretical framework for understanding cholesterol's regulatory role in\nmembrane structure and mechanics.",
    "pdf_url": "http://arxiv.org/pdf/2505.12726v2",
    "published": "2025-05-19T05:31:31+00:00",
    "categories": [
      "cond-mat.soft",
      "physics.bio-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.12725v1",
    "title": "A Control Oriented Fractional-Order Model of Lithium-ion Batteries Based on Caputo Definition",
    "authors": [
      "Yangyang Xu",
      "Hongyu Zhao",
      "Chengzhong Zhang",
      "Chenglin Liao"
    ],
    "abstract": "This letter proposes a fractional-order battery model based on the Caputo\ndefinition. A closed-form time-domain solution is derived, enabling a simple\nrecursive expression for discrete-time implementation. The model requires only\nthe current and previous time-step states in each iteration, significantly\nreducing memory usage compared to the conventional Gr\\\"{u}nwald--Letnikov (G-L)\nmethod. This recursive structure is highly compatible with filter design and\nonline parameter identification. Experimental validation on a 40.2~Ah NCM622\ncell shows that the proposed first-order model achieves voltage prediction\naccuracy comparable to a second-order integer-order model. The results\ndemonstrate that the Caputo-based model offers a practical balance between\naccuracy and computational efficiency, making it well suited for real-time\nbattery management systems (BMS).",
    "pdf_url": "http://arxiv.org/pdf/2505.12725v1",
    "published": "2025-05-19T05:31:04+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.12724v1",
    "title": "Josephson Junctions in the Age of Quantum Discovery",
    "authors": [
      "Hyunseong Kim",
      "Gyunghyun Jang",
      "Seungwon Jin",
      "Dongbin Shin",
      "Hyeon-Jin Shin",
      "Jie Luo",
      "Irfan Siddiqi",
      "Yosep Kim",
      "Hoon Hahn Yoon",
      "Long B. Nguyen"
    ],
    "abstract": "The unique combination of energy conservation and nonlinear behavior\nexhibited by Josephson junctions has driven transformative advances in modern\nquantum technologies based on superconducting circuits. These superconducting\ndevices underpin essential developments across quantum computing, quantum\nsensing, and quantum communication and open pathways to innovative applications\nin nonreciprocal electronics. These developments are enabled by recent\nbreakthroughs in nanofabrication and characterization methodologies,\nsubstantially enhancing device performance and scalability. The resulting\ninnovations reshape our understanding of quantum systems and enable practical\napplications. This perspective explores the foundational role of Josephson\njunctions research in propelling quantum technologies forward. We underscore\nthe critical importance of synergistic progress in material science, device\ncharacterization, and nanofabrication to catalyze the next wave of\nbreakthroughs and accelerate the transition from fundamental discoveries to\nindustrial-scale quantum utilities. Drawing parallels with the transformative\nimpact of transistor-based integrated circuits during the Information Age, we\nenvision Josephson junction-based circuits as central to driving a similar\nrevolution in the emerging Quantum Age.",
    "pdf_url": "http://arxiv.org/pdf/2505.12724v1",
    "published": "2025-05-19T05:27:16+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "cond-mat.supr-con",
      "physics.app-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13552v2",
    "title": "New Sorting Algorithm Wave Sort (W-Sort)",
    "authors": [
      "Jia Xu Wei"
    ],
    "abstract": "Modern comparison sorts like quicksort suffer from performance\ninconsistencies due to suboptimal pivot selection, leading to $O(N^2)$\nworst-case complexity, while in-place merge sort variants face challenges with\ndata movement overhead. We introduce Wave Sort, a novel in-place sorting\nalgorithm that addresses these limitations through a dynamic pivot selection\nstrategy. Wave Sort iteratively expands a sorted region and selects pivots from\nthis growing sorted portion to partition adjacent unsorted data. This approach\nensures robust pivot selection irrespective of dataset size, guarantees a\nlogarithmic recursion stack depth, and enables efficient in-place sorting. Our\nanalysis shows a worst-case comparison complexity bounded by $O(N(\\log N)^2)$\nwith a small constant factor. Experimental results demonstrate that Wave Sort\nrequires significantly fewer comparisons than quicksort on average\n(approximately 24% less) and performs close to the theoretical minimum, while\nalso incorporating adaptive techniques for efficient handling of presorted\nsequences. Wave Sort offers a compelling alternative for applications demanding\nconsistent, predictable, and in-place sorting performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.13552v2",
    "published": "2025-05-19T05:26:31+00:00",
    "categories": [
      "cs.DS",
      "F.2.2"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.12723v2",
    "title": "On-Policy Optimization with Group Equivalent Preference for Multi-Programming Language Understanding",
    "authors": [
      "Haoyuan Wu",
      "Rui Ming",
      "Jilong Gao",
      "Hangyu Zhao",
      "Xueyi Chen",
      "Yikai Yang",
      "Haisheng Zheng",
      "Zhuolun He",
      "Bei Yu"
    ],
    "abstract": "Large language models (LLMs) achieve remarkable performance in code\ngeneration tasks. However, a significant performance disparity persists between\npopular programming languages (e.g., Python, C++) and others. To address this\ncapability gap, we leverage the code translation task to train LLMs, thereby\nfacilitating the transfer of coding proficiency across diverse programming\nlanguages. Moreover, we introduce OORL for training, a novel reinforcement\nlearning (RL) framework that integrates on-policy and off-policy strategies.\nWithin OORL, on-policy RL is applied during code translation, guided by a\nrule-based reward signal derived from unit tests. Complementing this\ncoarse-grained rule-based reward, we propose Group Equivalent Preference\nOptimization (GEPO), a novel preference optimization method. Specifically, GEPO\ntrains the LLM using intermediate representations (IRs) groups. LLMs can be\nguided to discern IRs equivalent to the source code from inequivalent ones,\nwhile also utilizing signals about the mutual equivalence between IRs within\nthe group. This process allows LLMs to capture nuanced aspects of code\nfunctionality. By employing OORL for training with code translation tasks, LLMs\nimprove their recognition of code functionality and their understanding of the\nrelationships between code implemented in different languages. Extensive\nexperiments demonstrate that our OORL for LLMs training with code translation\ntasks achieves significant performance improvements on code benchmarks across\nmultiple programming languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.12723v2",
    "published": "2025-05-19T05:25:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12722v1",
    "title": "Knot Logic and Arborescent Links",
    "authors": [
      "Louis H Kauffman"
    ],
    "abstract": "This paper introduces a new algebra, the crossing algebra, that is applied to\ncount the number of components for arborescent knots, links, tangles or states\n(of a state polynomial expansion such as the Kauffman bracket). This algebra is\nfoundational, and it is related to generalisations of boolean logic and to\naspects of foundations based in diagrams and networks. Applications are given\nto rational knots, links and tangles and to the structure of the bracket\npolynomial and the beginnings of Khovanov homology.",
    "pdf_url": "http://arxiv.org/pdf/2505.12722v1",
    "published": "2025-05-19T05:24:40+00:00",
    "categories": [
      "math.GT",
      "57 M25"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12721v1",
    "title": "On the existence of stable contract systems",
    "authors": [
      "V. I. Danilov"
    ],
    "abstract": "In 1962, Gale and Shapley \\cite{GS} introduced the concept of stable\nmarriages and proved their existence. Since then, the statement of the\nstability problem has been highly generalized. And a lot of proofs has emerged\nfor the existence in these more general statements. It's time to review them\nand identify the similarities and differences. First, we will briefly discuss\nthe classical case, because the existence proofs in the general case grew out\nof it. Or rather, from the idea of \"deferred acceptance\". When the best of the\nproposed contracts is temporarily retained until a better offer is received.",
    "pdf_url": "http://arxiv.org/pdf/2505.12721v1",
    "published": "2025-05-19T05:24:32+00:00",
    "categories": [
      "econ.TH",
      "math.CO"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.12720v2",
    "title": "Cluster optical depth and pairwise velocity estimation using machine learning",
    "authors": [
      "Yulin Gong",
      "Rachel Bean"
    ],
    "abstract": "We apply two machine learning methods, a CNN deep-leaning model and a\ngradient-boosting decision tree, to estimate individual cluster optical depths\nfrom observed properties derived from multiple complementary datasets. The\nmodels are trained and tested with simulated N-body derived halo catalogs and\nsynthetic full-sky CMB maps designed to mirror data from the DESI and Simons\nObservatory experiments. Specifically, the thermal Sunyaev-Zel'dovich (tSZ) and\nCMB lensing convergence, along with cluster virial mass estimates are used as\nfeatures to train the machine learning models. The predicted optical depths are\ncombined with kinematic Sunyaev-Zel'dovich (kSZ) measurements to estimate\nindividual cluster radial peculiar velocities. The method is shown to recover\nan unbiased estimate of the pairwise velocity statistics of the simulated\ncluster sample. The model's efficacy is demonstrated for halos with mass range\n$10^{13} M_{\\odot} < M_{200} < 10^{15} M_{\\odot}$ over a redshift range\n$0<z<1$, and validated in the presence of primary CMB, instrument noise,\nlensing convergence noise, and potential uncertainties in halo virial mass\nestimates. We apply the method to ACT CMB data, using ACT DR4\ncomponent-separated maps for tSZ and CMB lensing and ACT DR5 maps for kSZ, in\nconjunction with galaxy clusters observed in the SDSS DR15 spectroscopic\nsurvey. We demonstrate that the machine learning approach is an effective one\nto analyze data from current and upcoming CMB experiments such as Simons\nObservatory and CCAT, and galaxy surveys, such as DESI and Roman, for which the\npairwise velocity statistics can provide valuable insights into the properties\nof neutrinos and gravity on cosmic scales.",
    "pdf_url": "http://arxiv.org/pdf/2505.12720v2",
    "published": "2025-05-19T05:22:09+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12719v1",
    "title": "The Composite Spectrum of the Little Red Dots from an Inner Standard Disk and an Outer Gravitationally Unstable Disk",
    "authors": [
      "Chenxuan Zhang",
      "Qingwen Wu",
      "Xiao Fan",
      "Luis C. Ho",
      "Jiancheng Wu",
      "Huanian Zhang",
      "Bing Lyu",
      "Xinwu Cao",
      "Jianmin Wang"
    ],
    "abstract": "One of the most mysterious results from observations of the James Webb Space\nTelescope (JWST) is the detection of numerous, high-redshift, very red,\nextremely compact, broad-line sources termed ``little red dots'' (LRDs). It is\nunclear whether the LRDs belong to an active galactic nucleus (AGN) or simply a\ncollection of very compact star clusters. We build spectral energy\ndistributions (SEDs) for 29 LRDs at $z \\approx 3-8.5$ based on JWST photometric\nand spectroscopic observations. We find that the V-shaped SEDs of these LRDs\nexhibit a roughly similar break frequency at $\\nu_{\\rm b}=10^{14.96\\pm0.06}$\nHz, which corresponds to $\\lambda_{\\rm b}=3287_{-424}^{+487} \\text{\\AA}$ in the\nrest frame. We propose that this unique SED can be explained by the combination\nof an inner standard disk and an outer gravitationally unstable accretion disk\nwith Toomre parameter $Q\\sim1$. The outer disk has a temperature of\n$\\sim2000-4000$ K for typical AGN parameters, which can well reproduce the\nnear-infrared to optical bump as observed in LRDs. This model can naturally\nexplain the strong infrared to optical emission and the V-shaped SED with a\nsimilar break frequency $\\simeq 10^{15}$ Hz for LRDs without invoking strong\ndust extinction or unusual stellar contribution from a host galaxy. Most LRDs\nstay in sub-Eddington state based on the SED modeling, which are intrinsically\nweak in X-rays.",
    "pdf_url": "http://arxiv.org/pdf/2505.12719v1",
    "published": "2025-05-19T05:21:44+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12718v1",
    "title": "Automated Bias Assessment in AI-Generated Educational Content Using CEAT Framework",
    "authors": [
      "Jingyang Peng",
      "Wenyuan Shen",
      "Jiarui Rao",
      "Jionghao Lin"
    ],
    "abstract": "Recent advances in Generative Artificial Intelligence (GenAI) have\ntransformed educational content creation, particularly in developing tutor\ntraining materials. However, biases embedded in AI-generated content--such as\ngender, racial, or national stereotypes--raise significant ethical and\neducational concerns. Despite the growing use of GenAI, systematic methods for\ndetecting and evaluating such biases in educational materials remain limited.\nThis study proposes an automated bias assessment approach that integrates the\nContextualized Embedding Association Test with a prompt-engineered word\nextraction method within a Retrieval-Augmented Generation framework. We applied\nthis method to AI-generated texts used in tutor training lessons. Results show\na high alignment between the automated and manually curated word sets, with a\nPearson correlation coefficient of r = 0.993, indicating reliable and\nconsistent bias assessment. Our method reduces human subjectivity and enhances\nfairness, scalability, and reproducibility in auditing GenAI-produced\neducational content.",
    "pdf_url": "http://arxiv.org/pdf/2505.12718v1",
    "published": "2025-05-19T05:19:26+00:00",
    "categories": [
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12717v1",
    "title": "ToTRL: Unlock LLM Tree-of-Thoughts Reasoning Potential through Puzzles Solving",
    "authors": [
      "Haoyuan Wu",
      "Xueyi Chen",
      "Rui Ming",
      "Jilong Gao",
      "Shoubo Hu",
      "Zhuolun He",
      "Bei Yu"
    ],
    "abstract": "Large language models (LLMs) demonstrate significant reasoning capabilities,\nparticularly through long chain-of-thought (CoT) processes, which can be\nelicited by reinforcement learning (RL). However, prolonged CoT reasoning\npresents limitations, primarily verbose outputs due to excessive introspection.\nThe reasoning process in these LLMs often appears to follow a trial-and-error\nmethodology rather than a systematic, logical deduction. In contrast,\ntree-of-thoughts (ToT) offers a conceptually more advanced approach by modeling\nreasoning as an exploration within a tree structure. This reasoning structure\nfacilitates the parallel generation and evaluation of multiple reasoning\nbranches, allowing for the active identification, assessment, and pruning of\nunproductive paths. This process can potentially lead to improved performance\nand reduced token costs. Building upon the long CoT capability of LLMs, we\nintroduce tree-of-thoughts RL (ToTRL), a novel on-policy RL framework with a\nrule-based reward. ToTRL is designed to guide LLMs in developing the parallel\nToT strategy based on the sequential CoT strategy. Furthermore, we employ LLMs\nas players in a puzzle game during the ToTRL training process. Solving puzzle\ngames inherently necessitates exploring interdependent choices and managing\nmultiple constraints, which requires the construction and exploration of a\nthought tree, providing challenging tasks for cultivating the ToT reasoning\ncapability. Our empirical evaluations demonstrate that our ToTQwen3-8B model,\ntrained with our ToTRL, achieves significant improvement in performance and\nreasoning efficiency on complex reasoning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12717v1",
    "published": "2025-05-19T05:18:58+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12716v2",
    "title": "Shadow-FT: Tuning Instruct via Base",
    "authors": [
      "Taiqiang Wu",
      "Runming Yang",
      "Jiayi Li",
      "Pengfei Hu",
      "Ngai Wong",
      "Yujiu Yang"
    ],
    "abstract": "Large language models (LLMs) consistently benefit from further fine-tuning on\nvarious tasks. However, we observe that directly tuning the INSTRUCT (i.e.,\ninstruction tuned) models often leads to marginal improvements and even\nperformance degeneration. Notably, paired BASE models, the foundation for these\nINSTRUCT variants, contain highly similar weight values (i.e., less than 2% on\naverage for Llama 3.1 8B). Therefore, we propose a novel Shadow-FT framework to\ntune the INSTRUCT models by leveraging the corresponding BASE models. The key\ninsight is to fine-tune the BASE model, and then directly graft the learned\nweight updates to the INSTRUCT model. Our proposed Shadow-FT introduces no\nadditional parameters, is easy to implement, and significantly improves\nperformance. We conduct extensive experiments on tuning mainstream LLMs, such\nas Qwen 3 and Llama 3 series, and evaluate them across 19 benchmarks covering\ncoding, reasoning, and mathematical tasks. Experimental results demonstrate\nthat Shadow-FT consistently outperforms conventional full-parameter and\nparameter-efficient tuning approaches. Further analyses indicate that Shadow-FT\ncan be applied to multimodal large language models (MLLMs) and combined with\ndirect preference optimization (DPO). Codes and weights are available at\n\\href{https://github.com/wutaiqiang/Shadow-FT}{Github}.",
    "pdf_url": "http://arxiv.org/pdf/2505.12716v2",
    "published": "2025-05-19T05:16:21+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12715v1",
    "title": "VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection",
    "authors": [
      "Aditya Taparia",
      "Noel Ngu",
      "Mario Leiva",
      "Joshua Shay Kricheli",
      "John Corcoran",
      "Nathaniel D. Bastian",
      "Gerardo Simari",
      "Paulo Shakarian",
      "Ransalu Senanayake"
    ],
    "abstract": "Although fusing multiple sensor modalities can enhance object detection\nperformance, existing fusion approaches often overlook subtle variations in\nenvironmental conditions and sensor inputs. As a result, they struggle to\nadaptively weight each modality under such variations. To address this\nchallenge, we introduce Vision-Language Conditioned Fusion (VLC Fusion), a\nnovel fusion framework that leverages a Vision-Language Model (VLM) to\ncondition the fusion process on nuanced environmental cues. By capturing\nhigh-level environmental context such as as darkness, rain, and camera\nblurring, the VLM guides the model to dynamically adjust modality weights based\non the current scene. We evaluate VLC Fusion on real-world autonomous driving\nand military target detection datasets that include image, LIDAR, and mid-wave\ninfrared modalities. Our experiments show that VLC Fusion consistently\noutperforms conventional fusion baselines, achieving improved detection\naccuracy in both seen and unseen scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.12715v1",
    "published": "2025-05-19T05:13:17+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12714v1",
    "title": "IA-MVS: Instance-Focused Adaptive Depth Sampling for Multi-View Stereo",
    "authors": [
      "Yinzhe Wang",
      "Yiwen Xiao",
      "Hu Wang",
      "Yiping Xu",
      "Yan Tian"
    ],
    "abstract": "Multi-view stereo (MVS) models based on progressive depth hypothesis\nnarrowing have made remarkable advancements. However, existing methods haven't\nfully utilized the potential that the depth coverage of individual instances is\nsmaller than that of the entire scene, which restricts further improvements in\ndepth estimation precision. Moreover, inevitable deviations in the initial\nstage accumulate as the process advances. In this paper, we propose\nInstance-Adaptive MVS (IA-MVS). It enhances the precision of depth estimation\nby narrowing the depth hypothesis range and conducting refinement on each\ninstance. Additionally, a filtering mechanism based on intra-instance depth\ncontinuity priors is incorporated to boost robustness. Furthermore, recognizing\nthat existing confidence estimation can degrade IA-MVS performance on point\nclouds. We have developed a detailed mathematical model for confidence\nestimation based on conditional probability. The proposed method can be widely\napplied in models based on MVSNet without imposing extra training burdens. Our\nmethod achieves state-of-the-art performance on the DTU benchmark. The source\ncode is available at https://github.com/KevinWang73106/IA-MVS.",
    "pdf_url": "http://arxiv.org/pdf/2505.12714v1",
    "published": "2025-05-19T05:11:39+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12713v1",
    "title": "Identifiability of Nonnegative Tucker Decompositions -- Part I: Theory",
    "authors": [
      "Subhayan Saha",
      "Giovanni Barbarino",
      "Nicolas Gillis"
    ],
    "abstract": "Tensor decompositions have become a central tool in data science, with\napplications in areas such as data analysis, signal processing, and machine\nlearning. A key property of many tensor decompositions, such as the canonical\npolyadic decomposition, is identifiability: the factors are unique, up to\ntrivial scaling and permutation ambiguities. This allows one to recover the\ngroundtruth sources that generated the data. The Tucker decomposition (TD) is a\ncentral and widely used tensor decomposition model. However, it is in general\nnot identifiable. In this paper, we study the identifiability of the\nnonnegative TD (nTD). By adapting and extending identifiability results of\nnonnegative matrix factorization (NMF), we provide uniqueness results for nTD.\nOur results require the nonnegative matrix factors to have some degree of\nsparsity (namely, satisfy the separability condition, or the sufficiently\nscattered condition), while the core tensor only needs to have some slices (or\nlinear combinations of them) or unfoldings with full column rank (but does not\nneed to be nonnegative). Under such conditions, we derive several procedures,\nusing either unfoldings or slices of the input tensor, to obtain identifiable\nnTDs by minimizing the volume of unfoldings or slices of the core tensor.",
    "pdf_url": "http://arxiv.org/pdf/2505.12713v1",
    "published": "2025-05-19T05:08:37+00:00",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "eess.SP",
      "stat.ML"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12712v1",
    "title": "Statistical inference in SEM for diffusion processes with jumps based on high-frequency data",
    "authors": [
      "Shogo Kusano",
      "Masayuki Uchida"
    ],
    "abstract": "We study structural equation modeling (SEM) for diffusion processes with\njumps. Based on high-frequency data, we consider the parameter estimation and\nthe goodness-of-fit test in the SEM. Using a threshold method, we propose the\nquasi-likelihood of the SEM and prove that the quasi-maximum likelihood\nestimator has consistency and asymptotic normality. To examine whether a\nspecified parametric model is correct or not, we also construct the\nquasi-likelihood ratio test statistics and investigate the asymptotic\nproperties. Furthermore, numerical simulations are conducted.",
    "pdf_url": "http://arxiv.org/pdf/2505.12712v1",
    "published": "2025-05-19T05:07:51+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.12711v2",
    "title": "Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining",
    "authors": [
      "Qichen Sun",
      "Zhengrui Guo",
      "Rui Peng",
      "Hao Chen",
      "Jinzhuo Wang"
    ],
    "abstract": "Recent advances in computational pathology and artificial intelligence have\nsignificantly enhanced the utilization of gigapixel whole-slide images and and\nadditional modalities (e.g., genomics) for pathological diagnosis. Although\ndeep learning has demonstrated strong potential in pathology, several key\nchallenges persist: (1) fusing heterogeneous data types requires sophisticated\nstrategies beyond simple concatenation due to high computational costs; (2)\ncommon scenarios of missing modalities necessitate flexible strategies that\nallow the model to learn robustly in the absence of certain modalities; (3) the\ndownstream tasks in CPath are diverse, ranging from unimodal to multimodal,\ncnecessitating a unified model capable of handling all modalities. To address\nthese challenges, we propose ALTER, an any-to-any tri-modal pretraining\nframework that integrates WSIs, genomics, and pathology reports. The term \"any\"\nemphasizes ALTER's modality-adaptive design, enabling flexible pretraining with\nany subset of modalities, and its capacity to learn robust, cross-modal\nrepresentations beyond WSI-centric approaches. We evaluate ALTER across\nextensive clinical tasks including survival prediction, cancer subtyping, gene\nmutation prediction, and report generation, achieving superior or comparable\nperformance to state-of-the-art baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.12711v2",
    "published": "2025-05-19T05:07:34+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12710v1",
    "title": "Confidence-Regulated Generative Diffusion Models for Reliable AI Agent Migration in Vehicular Metaverses",
    "authors": [
      "Yingkai Kang",
      "Jiawen Kang",
      "Jinbo Wen",
      "Tao Zhang",
      "Zhaohui Yang",
      "Dusit Niyato",
      "Yan Zhang"
    ],
    "abstract": "Vehicular metaverses are an emerging paradigm that merges intelligent\ntransportation systems with virtual spaces, leveraging advanced digital twin\nand Artificial Intelligence (AI) technologies to seamlessly integrate vehicles,\nusers, and digital environments. In this paradigm, vehicular AI agents are\nendowed with environment perception, decision-making, and action execution\ncapabilities, enabling real-time processing and analysis of multi-modal data to\nprovide users with customized interactive services. Since vehicular AI agents\nrequire substantial resources for real-time decision-making, given vehicle\nmobility and network dynamics conditions, the AI agents are deployed in\nRoadSide Units (RSUs) with sufficient resources and dynamically migrated among\nthem. However, AI agent migration requires frequent data exchanges, which may\nexpose vehicular metaverses to potential cyber attacks. To this end, we propose\na reliable vehicular AI agent migration framework, achieving reliable dynamic\nmigration and efficient resource scheduling through cooperation between\nvehicles and RSUs. Additionally, we design a trust evaluation model based on\nthe theory of planned behavior to dynamically quantify the reputation of RSUs,\nthereby better accommodating the personalized trust preferences of users. We\nthen model the vehicular AI agent migration process as a partially observable\nmarkov decision process and develop a Confidence-regulated Generative Diffusion\nModel (CGDM) to efficiently generate AI agent migration decisions. Numerical\nresults demonstrate that the CGDM algorithm significantly outperforms baseline\nmethods in reducing system latency and enhancing robustness against cyber\nattacks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12710v1",
    "published": "2025-05-19T05:04:48+00:00",
    "categories": [
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13551v2",
    "title": "Counter-Inferential Behavior in Natural and Artificial Cognitive Systems",
    "authors": [
      "Serge Dolgikh"
    ],
    "abstract": "This study explores the emergence of counter-inferential behavior in natural\nand artificial cognitive systems, that is, patterns in which agents\nmisattribute empirical success or suppress adaptation, leading to epistemic\nrigidity or maladaptive stability. We analyze archetypal scenarios in which\nsuch behavior arises: reinforcement of stability through reward imbalance,\nmeta-cognitive attribution of success to internal superiority, and protective\nreframing under perceived model fragility. Rather than arising from noise or\nflawed design, these behaviors emerge through structured interactions between\ninternal information models, empirical feedback, and higher-order evaluation\nmechanisms. Drawing on evidence from artificial systems, biological cognition,\nhuman psychology, and social dynamics, we identify counter-inferential behavior\nas a general cognitive vulnerability that can manifest even in otherwise\nwell-adapted systems. The findings highlight the importance of preserving\nminimal adaptive activation under stable conditions and suggest design\nprinciples for cognitive architectures that can resist rigidity under\ninformational stress.",
    "pdf_url": "http://arxiv.org/pdf/2505.13551v2",
    "published": "2025-05-19T05:04:07+00:00",
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.SI",
      "68T27, 94A15",
      "F.2.2; I.2.6"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12709v1",
    "title": "Pave Your Own Path: Graph Gradual Domain Adaptation on Fused Gromov-Wasserstein Geodesics",
    "authors": [
      "Zhichen Zeng",
      "Ruizhong Qiu",
      "Wenxuan Bao",
      "Tianxin Wei",
      "Xiao Lin",
      "Yuchen Yan",
      "Tarek F. Abdelzaher",
      "Jiawei Han",
      "Hanghang Tong"
    ],
    "abstract": "Graph neural networks, despite their impressive performance, are highly\nvulnerable to distribution shifts on graphs. Existing graph domain adaptation\n(graph DA) methods often implicitly assume a \\textit{mild} shift between source\nand target graphs, limiting their applicability to real-world scenarios with\n\\textit{large} shifts. Gradual domain adaptation (GDA) has emerged as a\npromising approach for addressing large shifts by gradually adapting the source\nmodel to the target domain via a path of unlabeled intermediate domains.\nExisting GDA methods exclusively focus on independent and identically\ndistributed (IID) data with a predefined path, leaving their extension to\n\\textit{non-IID graphs without a given path} an open challenge. To bridge this\ngap, we present Gadget, the first GDA framework for non-IID graph data. First\n(\\textit{theoretical foundation}), the Fused Gromov-Wasserstein (FGW) distance\nis adopted as the domain discrepancy for non-IID graphs, based on which, we\nderive an error bound revealing that the target domain error is proportional to\nthe length of the path. Second (\\textit{optimal path}), guided by the error\nbound, we identify the FGW geodesic as the optimal path, which can be\nefficiently generated by our proposed algorithm. The generated path can be\nseamlessly integrated with existing graph DA methods to handle large shifts on\ngraphs, improving state-of-the-art graph DA methods by up to 6.8\\% in node\nclassification accuracy on real-world datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.12709v1",
    "published": "2025-05-19T05:03:58+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12708v1",
    "title": "A Charged and Neutral Spin-$4$ Currents in the Grassmannian-like Coset Model",
    "authors": [
      "Changhyun Ahn",
      "Minsu Kang"
    ],
    "abstract": "By calculating the second order pole in the operator product expansion (OPE)\nbetween the charged spin-$3$ current and the neutral spin-$3$ current, we\ndetermine the primary charged spin-$4$ current. Similarly by computing the\nsecond order pole in the OPE between the neutral spin-$3$ current and itself,\nwe obtain the primary neutral spin-$4$ current. We determine the OPE between\nthe charged spin-$2$ current and the charged spin-$3$ current for generic\nparameters and the infinity limit of the level $k$ (one of the parameters) is\nalso given for this OPE. In particular, the above primary charged spin-$4$\ncurrent occurs at the first order pole of this OPE for generic parameters. We\nalso check that the above primary charged and neutral spin-$4$ currents occur\nat the second order pole of the OPE between the charged spin-$3$ current and\nitself for fixed parameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.12708v1",
    "published": "2025-05-19T05:01:58+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.12707v1",
    "title": "PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for Embodied AI",
    "authors": [
      "Yingchen He",
      "Christian D. Weilbach",
      "Martyna E. Wojciechowska",
      "Yuxuan Zhang",
      "Frank Wood"
    ],
    "abstract": "Advances in deep generative modelling have made it increasingly plausible to\ntrain human-level embodied agents. Yet progress has been limited by the absence\nof large-scale, real-time, multi-modal, and socially interactive datasets that\nreflect the sensory-motor complexity of natural environments. To address this,\nwe present PLAICraft, a novel data collection platform and dataset capturing\nmultiplayer Minecraft interactions across five time-aligned modalities: video,\ngame output audio, microphone input audio, mouse, and keyboard actions. Each\nmodality is logged with millisecond time precision, enabling the study of\nsynchronous, embodied behaviour in a rich, open-ended world. The dataset\ncomprises over 10,000 hours of gameplay from more than 10,000 global\nparticipants.\\footnote{We have done a privacy review for the public release of\nan initial 200-hour subset of the dataset, with plans to release most of the\ndataset over time.} Alongside the dataset, we provide an evaluation suite for\nbenchmarking model capabilities in object recognition, spatial awareness,\nlanguage grounding, and long-term memory. PLAICraft opens a path toward\ntraining and evaluating agents that act fluently and purposefully in real time,\npaving the way for truly embodied artificial intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2505.12707v1",
    "published": "2025-05-19T05:00:47+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12706v1",
    "title": "Efficient computation of complementary set partitions, with applications to an extension and estimation of generalized cumulants",
    "authors": [
      "Elvira Di Nardo",
      "Giuseppe Guarino"
    ],
    "abstract": "This paper develops new combinatorial approaches to analyze and compute\nspecial set partitions, called complementary set partitions, which are\nfundamental in the study of generalized cumulants. Moving away from traditional\ngraph-based and algebraic methods, a simple and fast algorithm is proposed to\nlist complementary set partitions based on two-block partitions, making the\ncomputation more accessible and implementable also in non-symbolic programming\nlanguages like R. Computational comparisons in Maple demonstrate the efficiency\nof the proposal. Additionally the notion of generalized cumulant is extended\nusing multiset subdivisions and multi-index partitions to include scenarios\nwith repeated variables and to address more sophisticated dependence\nstructures. A formula is provided that expresses generalized multivariate\ncumulants as linear combinations of multivariate cumulants, weighted by\ncoefficients that admit a natural combinatorial interpretation. Finally, the\nintroduction of dummy variables and specialized multi-index partitions enables\nan efficient procedure for estimating generalized multivariate cumulants with a\nsubstantial reduction in data power sums involved.",
    "pdf_url": "http://arxiv.org/pdf/2505.12706v1",
    "published": "2025-05-19T04:58:09+00:00",
    "categories": [
      "math.ST",
      "math.CO",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.12705v2",
    "title": "DreamGen: Unlocking Generalization in Robot Learning through Video World Models",
    "authors": [
      "Joel Jang",
      "Seonghyeon Ye",
      "Zongyu Lin",
      "Jiannan Xiang",
      "Johan Bjorck",
      "Yu Fang",
      "Fengyuan Hu",
      "Spencer Huang",
      "Kaushil Kundalia",
      "Yen-Chen Lin",
      "Loic Magne",
      "Ajay Mandlekar",
      "Avnish Narayan",
      "You Liang Tan",
      "Guanzhi Wang",
      "Jing Wang",
      "Qi Wang",
      "Yinzhen Xu",
      "Xiaohui Zeng",
      "Kaiyuan Zheng",
      "Ruijie Zheng",
      "Ming-Yu Liu",
      "Luke Zettlemoyer",
      "Dieter Fox",
      "Jan Kautz",
      "Scott Reed",
      "Yuke Zhu",
      "Linxi Fan"
    ],
    "abstract": "We introduce DreamGen, a simple yet highly effective 4-stage pipeline for\ntraining robot policies that generalize across behaviors and environments\nthrough neural trajectories - synthetic robot data generated from video world\nmodels. DreamGen leverages state-of-the-art image-to-video generative models,\nadapting them to the target robot embodiment to produce photorealistic\nsynthetic videos of familiar or novel tasks in diverse environments. Since\nthese models generate only videos, we recover pseudo-action sequences using\neither a latent action model or an inverse-dynamics model (IDM). Despite its\nsimplicity, DreamGen unlocks strong behavior and environment generalization: a\nhumanoid robot can perform 22 new behaviors in both seen and unseen\nenvironments, while requiring teleoperation data from only a single\npick-and-place task in one environment. To evaluate the pipeline\nsystematically, we introduce DreamGen Bench, a video generation benchmark that\nshows a strong correlation between benchmark performance and downstream policy\nsuccess. Our work establishes a promising new axis for scaling robot learning\nwell beyond manual data collection. Code available at\nhttps://github.com/NVIDIA/GR00T-Dreams.",
    "pdf_url": "http://arxiv.org/pdf/2505.12705v2",
    "published": "2025-05-19T04:55:39+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12704v1",
    "title": "Itinerant ferromagnetism in an SU(3) Fermi-Hubbard model at finite temperature: A DMFT study",
    "authors": [
      "Juntaro Fujii",
      "Kazuki Yamamoto",
      "Akihisa Koga"
    ],
    "abstract": "We investigate an SU(3) Fermi-Hubbard model on a hypercubic lattice at finite\ntemperatures, combining dynamical mean-field theory with continuous-time\nquantum Monte Carlo simulations. Taking strong correlations into account\ncarefully, we find a ferromagnetically ordered state, in which one of the three\ncomponents becomes dominant, when holes are doped away from one-third filling.\nFurthermore, we demonstrate that this ferromagnetically ordered phase undergoes\na first-order transition to a paramagnetic state. We clarify the stability of\nthe ferromagnetically ordered state against interaction strength, hole doping,\nand temperatures. The relevance of generalized Nagaoka ferromagnetism is also\naddressed, by comparing the results on the Bethe lattice.",
    "pdf_url": "http://arxiv.org/pdf/2505.12704v1",
    "published": "2025-05-19T04:53:56+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.12703v1",
    "title": "SpatialLLM: From Multi-modality Data to Urban Spatial Intelligence",
    "authors": [
      "Jiabin Chen",
      "Haiping Wang",
      "Jinpeng Li",
      "Yuan Liu",
      "Zhen Dong",
      "Bisheng Yang"
    ],
    "abstract": "We propose SpatialLLM, a novel approach advancing spatial intelligence tasks\nin complex urban scenes. Unlike previous methods requiring geographic analysis\ntools or domain expertise, SpatialLLM is a unified language model directly\naddressing various spatial intelligence tasks without any training,\nfine-tuning, or expert intervention. The core of SpatialLLM lies in\nconstructing detailed and structured scene descriptions from raw spatial data\nto prompt pre-trained LLMs for scene-based analysis. Extensive experiments show\nthat, with our designs, pretrained LLMs can accurately perceive spatial\ndistribution information and enable zero-shot execution of advanced spatial\nintelligence tasks, including urban planning, ecological analysis, traffic\nmanagement, etc. We argue that multi-field knowledge, context length, and\nreasoning ability are key factors influencing LLM performances in urban\nanalysis. We hope that SpatialLLM will provide a novel viable perspective for\nurban intelligent analysis and management. The code and dataset are available\nat https://github.com/WHU-USI3DV/SpatialLLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.12703v1",
    "published": "2025-05-19T04:53:41+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12702v1",
    "title": "Long-RVOS: A Comprehensive Benchmark for Long-term Referring Video Object Segmentation",
    "authors": [
      "Tianming Liang",
      "Haichao Jiang",
      "Yuting Yang",
      "Chaolei Tan",
      "Shuai Li",
      "Wei-Shi Zheng",
      "Jian-Fang Hu"
    ],
    "abstract": "Referring video object segmentation (RVOS) aims to identify, track and\nsegment the objects in a video based on language descriptions, which has\nreceived great attention in recent years. However, existing datasets remain\nfocus on short video clips within several seconds, with salient objects visible\nin most frames. To advance the task towards more practical scenarios, we\nintroduce \\textbf{Long-RVOS}, a large-scale benchmark for long-term referring\nvideo object segmentation. Long-RVOS contains 2,000+ videos of an average\nduration exceeding 60 seconds, covering a variety of objects that undergo\nocclusion, disappearance-reappearance and shot changing. The objects are\nmanually annotated with three different types of descriptions to individually\nevaluate the understanding of static attributes, motion patterns and\nspatiotemporal relationships. Moreover, unlike previous benchmarks that rely\nsolely on the per-frame spatial evaluation, we introduce two new metrics to\nassess the temporal and spatiotemporal consistency. We benchmark 6\nstate-of-the-art methods on Long-RVOS. The results show that current approaches\nstruggle severely with the long-video challenges. To address this, we further\npropose ReferMo, a promising baseline method that integrates motion information\nto expand the temporal receptive field, and employs a local-to-global\narchitecture to capture both short-term dynamics and long-term dependencies.\nDespite simplicity, ReferMo achieves significant improvements over current\nmethods in long-term scenarios. We hope that Long-RVOS and our baseline can\ndrive future RVOS research towards tackling more realistic and long-form\nvideos.",
    "pdf_url": "http://arxiv.org/pdf/2505.12702v1",
    "published": "2025-05-19T04:52:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13550v1",
    "title": "JIR-Arena: The First Benchmark Dataset for Just-in-time Information Recommendation",
    "authors": [
      "Ke Yang",
      "Kevin Ros",
      "Shankar Kumar Senthil Kumar",
      "ChengXiang Zhai"
    ],
    "abstract": "Just-in-time Information Recommendation (JIR) is a service designed to\ndeliver the most relevant information precisely when users need it, ,\naddressing their knowledge gaps with minimal effort and boosting\ndecision-making and efficiency in daily life. Advances in device-efficient\ndeployment of foundation models and the growing use of intelligent wearable\ndevices have made always-on JIR assistants feasible. However, there has been no\nsystematic effort to formally define JIR tasks or establish evaluation\nframeworks. To bridge this gap, we present the first mathematical definition of\nJIR tasks and associated evaluation metrics. Additionally, we introduce\nJIR-Arena, a multimodal benchmark dataset featuring diverse,\ninformation-request-intensive scenarios to evaluate JIR systems across critical\ndimensions: i) accurately inferring user information needs, ii) delivering\ntimely and relevant recommendations, and iii) avoiding irrelevant content that\nmay distract users.\n  Developing a JIR benchmark dataset poses challenges due to subjectivity in\nestimating user information needs and uncontrollable system variables affecting\nreproducibility. To address these, JIR-Arena: i) combines input from multiple\nhumans and large AI models to approximate information need distributions; ii)\nassesses JIR quality through information retrieval outcomes using static\nknowledge base snapshots; and iii) employs a multi-turn, multi-entity\nvalidation framework to improve objectivity and generality. Furthermore, we\nimplement a baseline JIR system capable of processing real-time information\nstreams aligned with user inputs. Our evaluation of this baseline system on\nJIR-Arena indicates that while foundation model-based JIR systems simulate user\nneeds with reasonable precision, they face challenges in recall and effective\ncontent retrieval. To support future research in this new area, we fully\nrelease our code and data.",
    "pdf_url": "http://arxiv.org/pdf/2505.13550v1",
    "published": "2025-05-19T04:49:47+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01994v1",
    "title": "Re-experiment Smart: a Novel Method to Enhance Data-driven Prediction of Mechanical Properties of Epoxy Polymers",
    "authors": [
      "Wanshan Cui",
      "Yejin Jeong",
      "Inwook Song",
      "Gyuri Kim",
      "Minsang Kwon",
      "Donghun Lee"
    ],
    "abstract": "Accurate prediction of polymer material properties through data-driven\napproaches greatly accelerates novel material development by reducing redundant\nexperiments and trial-and-error processes. However, inevitable outliers in\nempirical measurements can severely skew machine learning results, leading to\nerroneous prediction models and suboptimal material designs. To address this\nlimitation, we propose a novel approach to enhance dataset quality efficiently\nby integrating multi-algorithm outlier detection with selective\nre-experimentation of unreliable outlier cases. To validate the empirical\neffectiveness of the approach, we systematically construct a new dataset\ncontaining 701 measurements of three key mechanical properties: glass\ntransition temperature ($T_g$), tan $\\delta$ peak, and crosslinking density\n($v_{c}$). To demonstrate its general applicability, we report the performance\nimprovements across multiple machine learning models, including Elastic Net,\nSVR, Random Forest, and TPOT, to predict the three key properties. Our method\nreliably reduces prediction error (RMSE) and significantly improves accuracy\nwith minimal additional experimental work, requiring only about 5% of the\ndataset to be re-measured. These findings highlight the importance of data\nquality enhancement in achieving reliable machine learning applications in\npolymer science and present a scalable strategy for improving predictive\nreliability in materials science.",
    "pdf_url": "http://arxiv.org/pdf/2506.01994v1",
    "published": "2025-05-19T04:42:18+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.12701v1",
    "title": "Counterfactual Explanations for Continuous Action Reinforcement Learning",
    "authors": [
      "Shuyang Dong",
      "Shangtong Zhang",
      "Lu Feng"
    ],
    "abstract": "Reinforcement Learning (RL) has shown great promise in domains like\nhealthcare and robotics but often struggles with adoption due to its lack of\ninterpretability. Counterfactual explanations, which address \"what if\"\nscenarios, provide a promising avenue for understanding RL decisions but remain\nunderexplored for continuous action spaces. We propose a novel approach for\ngenerating counterfactual explanations in continuous action RL by computing\nalternative action sequences that improve outcomes while minimizing deviations\nfrom the original sequence. Our approach leverages a distance metric for\ncontinuous actions and accounts for constraints such as adhering to predefined\npolicies in specific states. Evaluations in two RL domains, Diabetes Control\nand Lunar Lander, demonstrate the effectiveness, efficiency, and generalization\nof our approach, enabling more interpretable and trustworthy RL applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.12701v1",
    "published": "2025-05-19T04:41:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12700v1",
    "title": "Writing a Good Security Paper for ISSCC (2025)",
    "authors": [
      "Utsav Banerjee",
      "Chiraag Juvekar",
      "Yong Ki Lee",
      "Leibo Liu",
      "Sanu Mathew",
      "Thomas Poeppelmann",
      "Shreyas Sen",
      "Takeshi Sugawara",
      "Ingrid Verbauwhede",
      "Rabia Tugce Yazicigil"
    ],
    "abstract": "Security is increasingly more important in designing chips and systems based\non them, and the International Solid-State Circuits Conference (ISSCC), the\nleading conference for presenting advances in solid-state circuits and\nsemiconductor technology, is committed to hardware security by establishing the\nsecurity subcommittee since 2024. In the past two years, the authors of this\npaper reviewed submissions as members of the Security Subcommittee, a part of\nInternational Technical Program Committee (ITPC). This paper aims to encourage\nhigh-quality submissions to grow this field in the overall scope of the ISSCC.",
    "pdf_url": "http://arxiv.org/pdf/2505.12700v1",
    "published": "2025-05-19T04:41:49+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12699v2",
    "title": "More Efforts Towards Fixed-Parameter Approximability of Multiwinner Rules",
    "authors": [
      "Sushmita Gupta",
      "Pallavi Jain",
      "Souvik Saha",
      "Saket Saurabh",
      "Anannya Upasana"
    ],
    "abstract": "Multiwinner Elections have emerged as a prominent area of research with\nnumerous practical applications. We contribute to this area by designing\nparameterized approximation algorithms and also resolving an open question by\nYang and Wang [AAMAS'18]. More formally, given a set of candidates,\n\\mathcal{C}, a set of voters,\\mathcal{V}, approving a subset of candidates\n(called approval set of a voter), and an integer $k$, we consider the problem\nof selecting a ``good'' committee using Thiele rules. This problem is\ncomputationally challenging for most Thiele rules with monotone submodular\nsatisfaction functions, as there is no (1-\\frac{1}{e}-\\epsilon)\\footnote{Here,\n$e$ denotes the base of the natural logarithm.}-approximation algorithm in\nf(k)(|\\mathcal{C}| + |\\mathcal{V}|)^{o(k)} time for any fixed $\\epsilon > 0$\nand any computable function $f$, and no {\\sf PTAS} even when the length of\napproval set is two. Skowron [WINE'16] designed an approximation scheme running\nin FPT time parameterized by the combined parameter, size of the approval set\nand $k$. In this paper, we consider a parameter $d+k$ (no $d$ voters approve\nthe same set of $d$ candidates), where $d$ is upper bounded by the size of the\napproval set (thus, can be much smaller).\n  With respect to this parameter, we design parameterized approximation\nschemes, a lossy polynomial-time preprocessing method, and show that an extra\ncommittee member suffices to achieve the desired score (i.e., $1$-additive\napproximation). Additionally, we resolve an open question by Yang and\nWang~[AAMAS'18] regarding the fixed-parameter tractability of the problem under\nthe PAV rule with the total score as the parameter, demonstrating that it\nadmits an FPT algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.12699v2",
    "published": "2025-05-19T04:41:47+00:00",
    "categories": [
      "cs.GT",
      "cs.DS"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12698v1",
    "title": "A Deep Learning Potential for Accurate Shock Response Simulations in Tin",
    "authors": [
      "Yixin Chen",
      "Xiaoyang Wang",
      "Wanghui Li",
      "Mohan Chen",
      "Han Wang"
    ],
    "abstract": "Tin (Sn) plays a crucial role in studying the dynamic mechanical responses of\nductile metals under shock loading. Atomistic simulations serves to unveil the\nnano-scale mechanisms for critical behaviors of dynamic responses. However,\nexisting empirical potentials for Sn often lack sufficient accuracy when\napplied in such simulation. Particularly, the solid-solid phase transition\nbehavior of Sn poses significant challenges to the accuracy of interatomic\npotentials. To address these challenges, this study introduces a\nmachine-learning potential model for Sn, specifically optimized for\nshock-response simulations. The model is trained using a dataset constructed\nthrough a concurrent learning framework and is designed for molecular\nsimulations across thermodynamic conditions ranging from 0 to 100 GPa and 0 to\n5000 K, encompassing both solid and liquid phases as well as structures with\nfree surfaces. It accurately reproduces density functional theory (DFT)-derived\nbasic properties, experimental melting curves, solid-solid phase boundaries,\nand shock Hugoniot results. This demonstrates the model's potential to bridge\nab initio precision with large-scale dynamic simulations of Sn.",
    "pdf_url": "http://arxiv.org/pdf/2505.12698v1",
    "published": "2025-05-19T04:39:39+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.12697v1",
    "title": "Towards A Generalist Code Embedding Model Based On Massive Data Synthesis",
    "authors": [
      "Chaofan Li",
      "Jianlyu Chen",
      "Yingxia Shao",
      "Defu Lian",
      "Zheng Liu"
    ],
    "abstract": "Code embedding models attract increasing attention due to the widespread\npopularity of retrieval-augmented generation (RAG) in software development.\nThese models are expected to capture the rich semantic relationships inherent\nto code, which differ significantly from those found in text. However, existing\nmodels remain severely limited due to the scarcity of high-quality training\ndata. In this work, we introduce \\textbf{CodeR} (\\underline{Code}\n\\underline{R}etrieval), a state-of-the-art embedding model for general-purpose\ncode retrieval. The superior performance of CodeR is built upon CodeR-Pile, a\nlarge-scale synthetic dataset constructed under the DRU (Diversity,\nReliability, Usability) principle via a novel data synthesis pipeline. To\noptimize training effectiveness, we propose Annealing, a curriculum learning\nstrategy that enables effective knowledge transfer across heterogeneous sources\nof data. We evaluate CodeR based on 16 diverse code retrieval tasks, where it\nsignificantly outperforms existing baselines and exhibits strong out-of-domain\ngeneralization performance. We have publicly released our code and the\nwell-trained model to facilitate further research in this critical area.\nhttps://github.com/FlagOpen/FlagEmbedding/tree/master/research/BGE_Coder.",
    "pdf_url": "http://arxiv.org/pdf/2505.12697v1",
    "published": "2025-05-19T04:37:53+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12696v1",
    "title": "Phase Transitions in Open Dicke Model: a degenerate perturbation theory approach",
    "authors": [
      "Wenqi Tong",
      "H. Alaeian",
      "F. Robicheaux"
    ],
    "abstract": "We study the steady-state behavior of the open Dicke model, which describes\nthe collective interaction of $N$ spin-$1/2$ particles with a lossy, quantized\ncavity mode and exhibits a superradiant phase transition above a critical\nlight-matter coupling. While the standard model conserves total spin, Kirton\nand Keeling \\cite{PhysRevLett.118.123602} demonstrated that even infinitesimal\nhomogeneous local dephasing destroys this phase transition, and that local\natomic decay can restore it. We analyze this interplay using degenerate\nperturbation theory across subspaces of fixed total spin, $S$. For coupling\nstrengths above the threshold, we identify a critical spin value $S_c$ such\nthat the superradiant phase transition occurs only for $S>S_c$. Our\nperturbative approach captures how weak dephasing and decay induce mixing\nbetween different $S$-subspaces, yielding a steady-state spin distribution\nwhose width scales as $1/\\sqrt{N}$. This framework requires only the first and\nsecond moments and can be implemented via the 2nd-cumulant approach,\ncircumventing the need for full density matrix calculations. Our results bridge\nthe quantum Rabi model and Dicke physics, elucidate the roles of dephasing and\ndecay in collective quantum effects, and apply broadly to open quantum systems\nwith degenerate steady states.",
    "pdf_url": "http://arxiv.org/pdf/2505.12696v1",
    "published": "2025-05-19T04:33:30+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12695v1",
    "title": "Pseudo-Likelihood Ratio Screening based on Network Data with Applications",
    "authors": [
      "Wei Hu",
      "Danyang Huang",
      "Bo Zhang"
    ],
    "abstract": "Social network platforms today generate vast amounts of data, including\nnetwork structures and a large number of user-defined tags, which reflect\nusers' interests. The dimensionality of these personalized tags can be\nultra-high, posing challenges for model analysis in targeted preference\nanalysis. Traditional categorical feature screening methods overlook the\nnetwork structure, which can lead to incorrect feature set and suboptimal\nprediction accuracy. This study focuses on feature screening for\nnetwork-involved preference analysis based on ultra-high-dimensional\ncategorical tags. We introduce the concepts of self-related features and\nnetwork-related features, defined as those directly related to the response and\nthose related to the network structure, respectively. We then propose a\npseudo-likelihood ratio feature screening procedure that identifies both types\nof features. Theoretical properties of this procedure under different scenarios\nare thoroughly investigated. Extensive simulations and real data analysis on\nSina Weibo validate our findings.",
    "pdf_url": "http://arxiv.org/pdf/2505.12695v1",
    "published": "2025-05-19T04:33:18+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.12694v1",
    "title": "LLM-based Query Expansion Fails for Unfamiliar and Ambiguous Queries",
    "authors": [
      "Kenya Abe",
      "Kunihiro Takeoka",
      "Makoto P. Kato",
      "Masafumi Oyamada"
    ],
    "abstract": "Query expansion (QE) enhances retrieval by incorporating relevant terms, with\nlarge language models (LLMs) offering an effective alternative to traditional\nrule-based and statistical methods. However, LLM-based QE suffers from a\nfundamental limitation: it often fails to generate relevant knowledge,\ndegrading search performance. Prior studies have focused on hallucination, yet\nits underlying cause--LLM knowledge deficiencies--remains underexplored. This\npaper systematically examines two failure cases in LLM-based QE: (1) when the\nLLM lacks query knowledge, leading to incorrect expansions, and (2) when the\nquery is ambiguous, causing biased refinements that narrow search coverage. We\nconduct controlled experiments across multiple datasets, evaluating the effects\nof knowledge and query ambiguity on retrieval performance using sparse and\ndense retrieval models. Our results reveal that LLM-based QE can significantly\ndegrade the retrieval effectiveness when knowledge in the LLM is insufficient\nor query ambiguity is high. We introduce a framework for evaluating QE under\nthese conditions, providing insights into the limitations of LLM-based\nretrieval augmentation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12694v1",
    "published": "2025-05-19T04:33:09+00:00",
    "categories": [
      "cs.IR",
      "H.3.3"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12693v1",
    "title": "TACOcc:Target-Adaptive Cross-Modal Fusion with Volume Rendering for 3D Semantic Occupancy",
    "authors": [
      "Luyao Lei",
      "Shuo Xu",
      "Yifan Bai",
      "Xing Wei"
    ],
    "abstract": "The performance of multi-modal 3D occupancy prediction is limited by\nineffective fusion, mainly due to geometry-semantics mismatch from fixed fusion\nstrategies and surface detail loss caused by sparse, noisy annotations. The\nmismatch stems from the heterogeneous scale and distribution of point cloud and\nimage features, leading to biased matching under fixed neighborhood fusion. To\naddress this, we propose a target-scale adaptive, bidirectional symmetric\nretrieval mechanism. It expands the neighborhood for large targets to enhance\ncontext awareness and shrinks it for small ones to improve efficiency and\nsuppress noise, enabling accurate cross-modal feature alignment. This mechanism\nexplicitly establishes spatial correspondences and improves fusion accuracy.\nFor surface detail loss, sparse labels provide limited supervision, resulting\nin poor predictions for small objects. We introduce an improved volume\nrendering pipeline based on 3D Gaussian Splatting, which takes fused features\nas input to render images, applies photometric consistency supervision, and\njointly optimizes 2D-3D consistency. This enhances surface detail\nreconstruction while suppressing noise propagation. In summary, we propose\nTACOcc, an adaptive multi-modal fusion framework for 3D semantic occupancy\nprediction, enhanced by volume rendering supervision. Experiments on the\nnuScenes and SemanticKITTI benchmarks validate its effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.12693v1",
    "published": "2025-05-19T04:32:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13549v1",
    "title": "TD-GRPC: Temporal Difference Learning with Group Relative Policy Constraint for Humanoid Locomotion",
    "authors": [
      "Khang Nguyen",
      "Khai Nguyen",
      "An T. Le",
      "Jan Peters",
      "Manfred Huber",
      "Ngo Anh Vien",
      "Minh Nhat Vu"
    ],
    "abstract": "Robot learning in high-dimensional control settings, such as humanoid\nlocomotion, presents persistent challenges for reinforcement learning (RL)\nalgorithms due to unstable dynamics, complex contact interactions, and\nsensitivity to distributional shifts during training. Model-based methods,\n\\textit{e.g.}, Temporal-Difference Model Predictive Control (TD-MPC), have\ndemonstrated promising results by combining short-horizon planning with\nvalue-based learning, enabling efficient solutions for basic locomotion tasks.\nHowever, these approaches remain ineffective in addressing policy mismatch and\ninstability introduced by off-policy updates. Thus, in this work, we introduce\nTemporal-Difference Group Relative Policy Constraint (TD-GRPC), an extension of\nthe TD-MPC framework that unifies Group Relative Policy Optimization (GRPO)\nwith explicit Policy Constraints (PC). TD-GRPC applies a trust-region\nconstraint in the latent policy space to maintain consistency between the\nplanning priors and learned rollouts, while leveraging group-relative ranking\nto assess and preserve the physical feasibility of candidate trajectories.\nUnlike prior methods, TD-GRPC achieves robust motions without modifying the\nunderlying planner, enabling flexible planning and policy learning. We validate\nour method across a locomotion task suite ranging from basic walking to highly\ndynamic movements on the 26-DoF Unitree H1-2 humanoid robot. Through simulation\nresults, TD-GRPC demonstrates its improvements in stability and policy\nrobustness with sampling efficiency while training for complex humanoid control\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.13549v1",
    "published": "2025-05-19T04:32:14+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12692v1",
    "title": "Bullying the Machine: How Personas Increase LLM Vulnerability",
    "authors": [
      "Ziwei Xu",
      "Udit Sanghi",
      "Mohan Kankanhalli"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly deployed in interactions where\nthey are prompted to adopt personas. This paper investigates whether such\npersona conditioning affects model safety under bullying, an adversarial\nmanipulation that applies psychological pressures in order to force the victim\nto comply to the attacker. We introduce a simulation framework in which an\nattacker LLM engages a victim LLM using psychologically grounded bullying\ntactics, while the victim adopts personas aligned with the Big Five personality\ntraits. Experiments using multiple open-source LLMs and a wide range of\nadversarial goals reveal that certain persona configurations -- such as\nweakened agreeableness or conscientiousness -- significantly increase victim's\nsusceptibility to unsafe outputs. Bullying tactics involving emotional or\nsarcastic manipulation, such as gaslighting and ridicule, are particularly\neffective. These findings suggest that persona-driven interaction introduces a\nnovel vector for safety risks in LLMs and highlight the need for persona-aware\nsafety evaluation and alignment strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.12692v1",
    "published": "2025-05-19T04:32:02+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12691v1",
    "title": "Law of iterated logarithm for supercritical symmetric branching Markov process",
    "authors": [
      "Haojie Hou",
      "Yan-Xia Ren",
      "Renming Song"
    ],
    "abstract": "Let $\\{(X_t)_{t\\geq 0}, \\mathbb{P}_x, x\\in E\\}$ be a supercritical symmetric\nbranching Markov process on a locally compact metric measure space $(E,\\mu)$\nwith spatially dependent local branching mechanism. Under some assumptions on\nthe semigroup of the spatial motion, we first prove law of iterated logarithm\ntype results for $\\langle f, X_t\\rangle$ under the second moment condition,\nwhere $f$ is a linear combination of eigenfunctions of the mean semigroup\n$\\{T_t, t\\geq0\\}$ of $X$. Then we prove law of iterated logarithm type results\nfor $\\langle f, X_t\\rangle$ under the fourth moment condition, where $f\\in\nT_r(L^2(E, \\mu))$ for some $r>0$.",
    "pdf_url": "http://arxiv.org/pdf/2505.12691v1",
    "published": "2025-05-19T04:30:58+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12690v1",
    "title": "An Automated Blackbox Noncompliance Checker for QUIC Server Implementations",
    "authors": [
      "Kian Kai Ang",
      "Guy Farrelly",
      "Cheryl Pope",
      "Damith C. Ranasinghe"
    ],
    "abstract": "We develop QUICtester, an automated approach for uncovering non-compliant\nbehaviors in the ratified QUIC protocol implementations (RFC 9000/9001).\nQUICtester leverages active automata learning to abstract the behavior of a\nQUIC implementation into a finite state machine (FSM) representation. Unlike\nprior noncompliance checking methods, to help uncover state dependencies on\nevent timing, QUICtester introduces the idea of state learning with event\ntiming variations, adopting both valid and invalid input configurations, and\ncombinations of security and transport layer parameters during learning. We use\npairwise differential analysis of learned behaviour models of tested QUIC\nimplementations to identify non-compliance instances as behaviour deviations in\na property-agnostic way. This exploits the existence of the many different QUIC\nimplementations, removing the need for validated, formal models. The diverse\nimplementations act as cross-checking test oracles to discover non-compliance.\nWe used QUICtester to analyze analyze 186 learned models from 19 QUIC\nimplementations under the five security settings and discovered 55\nimplementation errors. Significantly, the tool uncovered a QUIC specification\nambiguity resulting in an easily exploitable DoS vulnerability, led to 5 CVE\nassignments from developers, and two bug bounties thus far.",
    "pdf_url": "http://arxiv.org/pdf/2505.12690v1",
    "published": "2025-05-19T04:28:49+00:00",
    "categories": [
      "cs.CR",
      "cs.NI",
      "cs.SE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12689v1",
    "title": "Formation of a Possible Black-hole Ultracompact X-ray Binary with the Shortest Orbital Period",
    "authors": [
      "Xing-Peng Yang",
      "Kun Xu",
      "Zhi-Fu Gao",
      "Long Jiang",
      "Wen-Cong Chen"
    ],
    "abstract": "In the bulge of M31, the Chandra observations discovered a possible black\nhole (BH) ultracompact X-ray binary (UCXB) Seq.1 with an orbital period of 7.7\nminutes and a maximum X-ray luminosity $L_{\\rm\nX}=1.09^{+0.02}_{-0.01}\\times10^{38}~ \\rm erg\\,s^{-1}$ in the $0.5-8$ keV band.\nThe minimum orbital period of the BH UCXBs predicted by the standard magnetic\nbraking (MB) model is longer than 8.3 minutes. In this work, we investigate\nwhether the convection- and rotation-boosted (CARB) MB prescription can account\nfor the formation of a BH UCXB like Seq.1. Our detailed stellar evolution\nmodels indicate that the CARB MB law can drive isolated BH-main sequence (MS)\nbinaries to evolve toward BH UCXBs with an orbital period of $7.7~ \\rm\nminutes$, in which a low-mass white dwarf transfers the material onto a BH in a\nshort-term mass transfer episode, producing an X-ray luminosity of $10^{38}~\\rm\nerg\\,s^{-1}$. We also obtain an initial parameter space of BH-MS binaries as\nthe progenitors of Seq.1 in the donor-star masses and orbital periods plane,\nwhich can be applied to future population synthesis simulations. If Seq.1 is\nindeed a BH UCXB, future spaceborne gravitational wave (GW) detectors can\ndetect the low-frequency GW signals from this source, and a tidal disruption\nevent will be expected after 0.12 Myr.",
    "pdf_url": "http://arxiv.org/pdf/2505.12689v1",
    "published": "2025-05-19T04:25:16+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12688v1",
    "title": "Shielding Latent Face Representations From Privacy Attacks",
    "authors": [
      "Arjun Ramesh Kaushik",
      "Bharat Chandra Yalavarthi",
      "Arun Ross",
      "Vishnu Boddeti",
      "Nalini Ratha"
    ],
    "abstract": "In today's data-driven analytics landscape, deep learning has become a\npowerful tool, with latent representations, known as embeddings, playing a\ncentral role in several applications. In the face analytics domain, such\nembeddings are commonly used for biometric recognition (e.g., face\nidentification). However, these embeddings, or templates, can inadvertently\nexpose sensitive attributes such as age, gender, and ethnicity. Leaking such\ninformation can compromise personal privacy and affect civil liberty and human\nrights. To address these concerns, we introduce a multi-layer protection\nframework for embeddings. It consists of a sequence of operations: (a)\nencrypting embeddings using Fully Homomorphic Encryption (FHE), and (b) hashing\nthem using irreversible feature manifold hashing. Unlike conventional\nencryption methods, FHE enables computations directly on encrypted data,\nallowing downstream analytics while maintaining strong privacy guarantees. To\nreduce the overhead of encrypted processing, we employ embedding compression.\nOur proposed method shields latent representations of sensitive data from\nleaking private attributes (such as age and gender) while retaining essential\nfunctional capabilities (such as face identification). Extensive experiments on\ntwo datasets using two face encoders demonstrate that our approach outperforms\nseveral state-of-the-art privacy protection methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.12688v1",
    "published": "2025-05-19T04:23:16+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12687v1",
    "title": "A partial result towards the Chowla--Milnor conjecture",
    "authors": [
      "Li Lai",
      "Jia Li"
    ],
    "abstract": "The Chowla--Milnor conjecture predicts the linear independence of certain\nHurwitz zeta values. In this paper, we prove that for any fixed integer $k\n\\geqslant 2$, the dimension of the $\\mathbb{Q}$-linear span of\n$\\zeta(k,a/q)-(-1)^{k}\\zeta(k,1-a/q)$ ($1 \\leqslant a < q/2$, $\\gcd(a,q)=1$) is\nat least $(c_k -o(1)) \\cdot \\log q$ as the positive integer $q \\to +\\infty$ for\nsome constant $c_k>0$ depending only on $k$. It is well known that\n$\\zeta(k,a/q)+(-1)^{k}\\zeta(k,1-a/q) \\in \\overline{\\mathbb{Q}}\\pi^k$, but much\nless is known previously for $\\zeta(k,a/q)-(-1)^{k}\\zeta(k,1-a/q)$. Our proof\nis similar to those of Ball--Rivoal (2001) and Zudilin (2002) concerning the\nlinear independence of Riemann zeta values. However, we use a new type of\nrational functions to construct linear forms.",
    "pdf_url": "http://arxiv.org/pdf/2505.12687v1",
    "published": "2025-05-19T04:17:27+00:00",
    "categories": [
      "math.NT",
      "11J72 (primary), 11M35, 33C20 (secondary)"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12686v1",
    "title": "RoVo: Robust Voice Protection Against Unauthorized Speech Synthesis with Embedding-Level Perturbations",
    "authors": [
      "Seungmin Kim",
      "Sohee Park",
      "Donghyun Kim",
      "Jisu Lee",
      "Daeseon Choi"
    ],
    "abstract": "With the advancement of AI-based speech synthesis technologies such as Deep\nVoice, there is an increasing risk of voice spoofing attacks, including voice\nphishing and fake news, through unauthorized use of others' voices. Existing\ndefenses that inject adversarial perturbations directly into audio signals have\nlimited effectiveness, as these perturbations can easily be neutralized by\nspeech enhancement methods. To overcome this limitation, we propose RoVo\n(Robust Voice), a novel proactive defense technique that injects adversarial\nperturbations into high-dimensional embedding vectors of audio signals,\nreconstructing them into protected speech. This approach effectively defends\nagainst speech synthesis attacks and also provides strong resistance to speech\nenhancement models, which represent a secondary attack threat.\n  In extensive experiments, RoVo increased the Defense Success Rate (DSR) by\nover 70% compared to unprotected speech, across four state-of-the-art speech\nsynthesis models. Specifically, RoVo achieved a DSR of 99.5% on a commercial\nspeaker-verification API, effectively neutralizing speech synthesis attack.\nMoreover, RoVo's perturbations remained robust even under strong speech\nenhancement conditions, outperforming traditional methods. A user study\nconfirmed that RoVo preserves both naturalness and usability of protected\nspeech, highlighting its effectiveness in complex and evolving threat\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.12686v1",
    "published": "2025-05-19T04:14:58+00:00",
    "categories": [
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12685v1",
    "title": "Mamba-Adaptor: State Space Model Adaptor for Visual Recognition",
    "authors": [
      "Fei Xie",
      "Jiahao Nie",
      "Yujin Tang",
      "Wenkang Zhang",
      "Hongshen Zhao"
    ],
    "abstract": "Recent State Space Models (SSM), especially Mamba, have demonstrated\nimpressive performance in visual modeling and possess superior model\nefficiency. However, the application of Mamba to visual tasks suffers inferior\nperformance due to three main constraints existing in the sequential model: 1)\nCasual computing is incapable of accessing global context; 2) Long-range\nforgetting when computing the current hidden states; 3) Weak spatial structural\nmodeling due to the transformed sequential input. To address these issues, we\ninvestigate a simple yet powerful vision task Adaptor for Mamba models, which\nconsists of two functional modules: Adaptor-T and Adaptor-S. When solving the\nhidden states for SSM, we apply a lightweight prediction module Adaptor-T to\nselect a set of learnable locations as memory augmentations to ease long-range\nforgetting issues. Moreover, we leverage Adapator-S, composed of multi-scale\ndilated convolutional kernels, to enhance the spatial modeling and introduce\nthe image inductive bias into the feature output. Both modules can enlarge the\ncontext modeling in casual computing, as the output is enhanced by the\ninaccessible features. We explore three usages of Mamba-Adaptor: A general\nvisual backbone for various vision tasks; A booster module to raise the\nperformance of pretrained backbones; A highly efficient fine-tuning module that\nadapts the base model for transfer learning tasks. Extensive experiments verify\nthe effectiveness of Mamba-Adaptor in three settings. Notably, our\nMamba-Adaptor achieves state-of the-art performance on the ImageNet and COCO\nbenchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12685v1",
    "published": "2025-05-19T04:14:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13548v1",
    "title": "Alternative Action for Generalized Unimodular Gravity",
    "authors": [
      "Dmitry Nesterov"
    ],
    "abstract": "We present an alternative formulation of generalized unimodular gravity\n(GUMG), a class of modifications to general relativity characterized by a\nspecial partial breaking of general coordinate covariance. The action for this\nformulation is derived constructively through a sequence of equivalent\nrepresentations, starting from the original GUMG setup and extending the\nconfiguration space and gauge structure by introducing time parametrization.\nOur approach, based on a canonical formalism, parallels the method used by\nHenneaux and Teitelboim to covariantize the action of unimodular gravity (UMG),\nwhich was generalized to consistently accommodate a parameterization via local\nfields for the entire GUMG family. For completeness, we explore the dynamical\nstructure of the theory and provide a detailed account of its gauge properties.\nA notable consequence of the consistent parametrization is the emergence of\nexplicit spatial delocalization in the action, manifestations of which we\ncarefully examine. Within the GUMG family, we identify a subfamily of models\ndescribed by a local action. While preserving the essential structural\nfeatures, these models avoid the complications of spatial nonlocality allowing\na clearer analysis. The dynamical and constraint structures of GUMG family\nmodels are different from those of UMG, however the latter appears as an\nexceptional special case within the family, providing valuable comparative\ninsights.",
    "pdf_url": "http://arxiv.org/pdf/2505.13548v1",
    "published": "2025-05-19T04:08:41+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "83D05 (Primary) 70H45 (Secondary)"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.12684v1",
    "title": "Towards Effective Federated Graph Foundation Model via Mitigating Knowledge Entanglement",
    "authors": [
      "Yinlin Zhu",
      "Xunkai Li",
      "Jishuo Jia",
      "Miao Hu",
      "Di Wu",
      "Meikang Qiu"
    ],
    "abstract": "Recent advances in graph machine learning have shifted to data-centric\nparadigms, driven by two emerging fields: (1) Federated graph learning (FGL)\nenables multi-client collaboration but faces challenges from data and task\nheterogeneity, limiting its practicality; (2) Graph foundation models (GFM)\noffer strong domain generalization but are usually trained on single machines,\nmissing out on cross-silo data and resources.\n  These paradigms are complementary, and their integration brings notable\nbenefits. Motivated by this, we propose FedGFM, a novel decentralized GFM\ntraining paradigm. However, a key challenge is knowledge entanglement, where\nmulti-domain knowledge merges into indistinguishable representations, hindering\ndownstream adaptation.\n  To address this, we present FedGFM+, an enhanced framework with two core\nmodules to reduce knowledge entanglement: (1) AncDAI: A global anchor-based\ndomain-aware initialization strategy. Before pre-training, each client encodes\nits local graph into domain-specific prototypes that serve as semantic anchors.\nSynthetic embeddings around these anchors initialize the global model. We\ntheoretically prove these prototypes are distinguishable across domains,\nproviding a strong inductive bias to disentangle domain-specific knowledge. (2)\nAdaDPP: A local adaptive domain-sensitive prompt pool. Each client learns a\nlightweight graph prompt capturing domain semantics during pre-training. During\nfine-tuning, prompts from all clients form a pool from which the GFM selects\nrelevant prompts to augment target graph attributes, improving downstream\nadaptation.\n  FedGFM+ is evaluated on 8 diverse benchmarks across multiple domains and\ntasks, outperforming 20 baselines from supervised learning, FGL, and federated\nGFM variants.",
    "pdf_url": "http://arxiv.org/pdf/2505.12684v1",
    "published": "2025-05-19T04:06:32+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12683v1",
    "title": "DimGrow: Memory-Efficient Field-level Embedding Dimension Search",
    "authors": [
      "Yihong Huang",
      "Chen Chu"
    ],
    "abstract": "Key feature fields need bigger embedding dimensionality, others need smaller.\nThis demands automated dimension allocation. Existing approaches, such as\npruning or Neural Architecture Search (NAS), require training a\nmemory-intensive SuperNet that enumerates all possible dimension combinations,\nwhich is infeasible for large feature spaces. We propose DimGrow, a lightweight\napproach that eliminates the SuperNet requirement. Starting training model from\none dimension per feature field, DimGrow can progressively expand/shrink\ndimensions via importance scoring. Dimensions grow only when their importance\nconsistently exceed a threshold, ensuring memory efficiency. Experiments on\nthree recommendation datasets verify the effectiveness of DimGrow while it\nreduces training memory compared to SuperNet-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.12683v1",
    "published": "2025-05-19T04:06:22+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12682v1",
    "title": "RoFL: Robust Fingerprinting of Language Models",
    "authors": [
      "Yun-Yun Tsai",
      "Chuan Guo",
      "Junfeng Yang",
      "Laurens van der Maaten"
    ],
    "abstract": "AI developers are releasing large language models (LLMs) under a variety of\ndifferent licenses. Many of these licenses restrict the ways in which the\nmodels or their outputs may be used. This raises the question how license\nviolations may be recognized. In particular, how can we identify that an API or\nproduct uses (an adapted version of) a particular LLM? We present a new method\nthat enable model developers to perform such identification via fingerprints:\nstatistical patterns that are unique to the developer's model and robust to\ncommon alterations of that model. Our method permits model identification in a\nblack-box setting using a limited number of queries, enabling identification of\nmodels that can only be accessed via an API or product. The fingerprints are\nnon-invasive: our method does not require any changes to the model during\ntraining, hence by design, it does not impact model quality. Empirically, we\nfind our method provides a high degree of robustness to common changes in the\nmodel or inference settings. In our experiments, it substantially outperforms\nprior art, including invasive methods that explicitly train watermarks into the\nmodel.",
    "pdf_url": "http://arxiv.org/pdf/2505.12682v1",
    "published": "2025-05-19T04:00:23+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12681v1",
    "title": "On the Mechanisms of Adversarial Data Augmentation for Robust and Adaptive Transfer Learning",
    "authors": [
      "Hana Satou",
      "Alan Mitkiy"
    ],
    "abstract": "Transfer learning across domains with distribution shift remains a\nfundamental challenge in building robust and adaptable machine learning\nsystems. While adversarial perturbations are traditionally viewed as threats\nthat expose model vulnerabilities, recent studies suggest that they can also\nserve as constructive tools for data augmentation. In this work, we\nsystematically investigate the role of adversarial data augmentation (ADA) in\nenhancing both robustness and adaptivity in transfer learning settings. We\nanalyze how adversarial examples, when used strategically during training,\nimprove domain generalization by enriching decision boundaries and reducing\noverfitting to source-domain-specific features. We further propose a unified\nframework that integrates ADA with consistency regularization and\ndomain-invariant representation learning. Extensive experiments across multiple\nbenchmark datasets -- including VisDA, DomainNet, and Office-Home --\ndemonstrate that our method consistently improves target-domain performance\nunder both unsupervised and few-shot domain adaptation settings. Our results\nhighlight a constructive perspective of adversarial learning, transforming\nperturbation from a destructive attack into a regularizing force for\ncross-domain transferability.",
    "pdf_url": "http://arxiv.org/pdf/2505.12681v1",
    "published": "2025-05-19T03:56:51+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12680v1",
    "title": "Ineq-Comp: Benchmarking Human-Intuitive Compositional Reasoning in Automated Theorem Proving on Inequalities",
    "authors": [
      "Haoyu Zhao",
      "Yihan Geng",
      "Shange Tang",
      "Yong Lin",
      "Bohan Lyu",
      "Hongzhou Lin",
      "Chi Jin",
      "Sanjeev Arora"
    ],
    "abstract": "LLM-based formal proof assistants (e.g., in Lean) hold great promise for\nautomating mathematical discovery. But beyond syntactic correctness, do these\nsystems truly understand mathematical structure as humans do? We investigate\nthis question through the lens of mathematical inequalities -- a fundamental\ntool across many domains. While modern provers can solve basic inequalities, we\nprobe their ability to handle human-intuitive compositionality. We introduce\nIneq-Comp, a benchmark built from elementary inequalities through systematic\ntransformations, including variable duplication, algebraic rewriting, and\nmulti-step composition. Although these problems remain easy for humans, we find\nthat most provers -- including Goedel, STP, and Kimina-7B -- struggle\nsignificantly. DeepSeek-Prover-V2-7B shows relative robustness -- possibly\nbecause it is trained to decompose the problems into sub-problems -- but still\nsuffers a 20\\% performance drop (pass@32). Strikingly, performance remains poor\nfor all models even when formal proofs of the constituent parts are provided in\ncontext, revealing that the source of weakness is indeed in compositional\nreasoning. Our results expose a persisting gap between the generalization\nbehavior of current AI provers and human mathematical intuition.",
    "pdf_url": "http://arxiv.org/pdf/2505.12680v1",
    "published": "2025-05-19T03:56:05+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12679v1",
    "title": "Dribble Master: Learning Agile Humanoid Dribbling Through Legged Locomotion",
    "authors": [
      "Zhuoheng Wang",
      "Jinyin Zhou",
      "Qi Wu"
    ],
    "abstract": "Humanoid soccer dribbling is a highly challenging task that demands dexterous\nball manipulation while maintaining dynamic balance. Traditional rule-based\nmethods often struggle to achieve accurate ball control due to their reliance\non fixed walking patterns and limited adaptability to real-time ball dynamics.\nTo address these challenges, we propose a two-stage curriculum learning\nframework that enables a humanoid robot to acquire dribbling skills without\nexplicit dynamics or predefined trajectories. In the first stage, the robot\nlearns basic locomotion skills; in the second stage, we fine-tune the policy\nfor agile dribbling maneuvers. We further introduce a virtual camera model in\nsimulation and design heuristic rewards to encourage active sensing, promoting\na broader visual range for continuous ball perception. The policy is trained in\nsimulation and successfully transferred to a physical humanoid robot.\nExperimental results demonstrate that our method enables effective ball\nmanipulation, achieving flexible and visually appealing dribbling behaviors\nacross multiple environments. This work highlights the potential of\nreinforcement learning in developing agile humanoid soccer robots. Additional\ndetails, video demonstrations, and code are available at\nhttps://zhuoheng0910.github.io/dribble-master/.",
    "pdf_url": "http://arxiv.org/pdf/2505.12679v1",
    "published": "2025-05-19T03:55:43+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12678v3",
    "title": "Measuring the cosmic dipole with golden dark sirens in the era of next-generation ground-based gravitational wave detectors",
    "authors": [
      "Anson Chen"
    ],
    "abstract": "The tensions between cosmological parameter measurements from the\nearly-universe and the late-universe datasets offer an exciting opportunity to\nexplore new physics, if not accounted for unknown systematics. Apart from the\nwell-known Hubble tension, a tension up to $4.9 \\sigma$ in the cosmic dipole\nhas also been reported. While the cosmic dipole is mainly induced by the\nobserver's kinetic motion, an intrinsic dipole arising from the anisotropy of\nthe universe could also play an import role. Such an intrinsic anisotropy can\nbe a dark energy mimicker that causes the observed accelerating expansion of\nthe universe. As a new and powerful tool, gravitational waves can serve as an\nindependent probe to the cosmic dipole. A useful type of events to achieve this\nis the \"golden dark sirens\", which are near-by well-localized compact binary\ncoalescences whose host galaxies can be identified directly due to precise\nlocalization. By forecasting golden dark sirens obtained from 10-year\nobservations using different possible detector networks in the future, we find\nthat the standard LIGO-Virgo-KAGRA detectors are not able to detect a\nmeaningful amount of golden dark sirens, and hence next-generation ground-based\ndetectors are essential to obtain a strong constraint on the cosmic dipole. In\nparticular, we find that a three-detector network consisting of more than one\nnext-generation detectors can yield a constraint on the cosmic dipole at an\norder of $10^{-3}$ when jointly measured with $H_0$. Moreover, a constraint on\nthe cosmic dipole at an order of $10^{-4}$ can be achieved when fixing $H_0$.",
    "pdf_url": "http://arxiv.org/pdf/2505.12678v3",
    "published": "2025-05-19T03:53:26+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.12677v1",
    "title": "CURE: Concept Unlearning via Orthogonal Representation Editing in Diffusion Models",
    "authors": [
      "Shristi Das Biswas",
      "Arani Roy",
      "Kaushik Roy"
    ],
    "abstract": "As Text-to-Image models continue to evolve, so does the risk of generating\nunsafe, copyrighted, or privacy-violating content. Existing safety\ninterventions - ranging from training data curation and model fine-tuning to\ninference-time filtering and guidance - often suffer from incomplete concept\nremoval, susceptibility to jail-breaking, computational inefficiency, or\ncollateral damage to unrelated capabilities. In this paper, we introduce CURE,\na training-free concept unlearning framework that operates directly in the\nweight space of pre-trained diffusion models, enabling fast, interpretable, and\nhighly specific suppression of undesired concepts. At the core of our method is\nthe Spectral Eraser, a closed-form, orthogonal projection module that\nidentifies discriminative subspaces using Singular Value Decomposition over\ntoken embeddings associated with the concepts to forget and retain.\nIntuitively, the Spectral Eraser identifies and isolates features unique to the\nundesired concept while preserving safe attributes. This operator is then\napplied in a single step update to yield an edited model in which the target\nconcept is effectively unlearned - without retraining, supervision, or\niterative optimization. To balance the trade-off between filtering toxicity and\npreserving unrelated concepts, we further introduce an Expansion Mechanism for\nspectral regularization which selectively modulates singular vectors based on\ntheir relative significance to control the strength of forgetting. All the\nprocesses above are in closed-form, guaranteeing extremely efficient erasure in\nonly $2$ seconds. Benchmarking against prior approaches, CURE achieves a more\nefficient and thorough removal for targeted artistic styles, objects,\nidentities, or explicit content, with minor damage to original generation\nability and demonstrates enhanced robustness against red-teaming.",
    "pdf_url": "http://arxiv.org/pdf/2505.12677v1",
    "published": "2025-05-19T03:53:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12676v2",
    "title": "Understanding and Detecting Peer Dependency Resolving Loop in npm Ecosystem",
    "authors": [
      "Xingyu Wang",
      "Mingsen Wang",
      "Wenbo Shen",
      "Rui Chang"
    ],
    "abstract": "As the default package manager for Node.js, npm has become one of the largest\npackage management systems in the world. To facilitate dependency management\nfor developers, npm supports a special type of dependency, Peer Dependency,\nwhose installation and usage differ from regular dependencies. However,\nconflicts between peer dependencies can trap the npm client into infinite\nloops, leading to resource exhaustion and system crashes. We name this problem\nPeerSpin. Although PeerSpin poses a severe risk to ecosystems, it was\noverlooked by previous studies, and its impacts have not been explored.\n  To bridge this gap, this paper conducts the first in-depth study to\nunderstand and detect PeerSpin in the npm ecosystem. First, by systematically\nanalyzing the npm dependency resolution, we identify the root cause of PeerSpin\nand characterize two peer dependency patterns to guide detection. Second, we\npropose a novel technique called Node-Replacement-Conflict based PeerSpin\nDetection, which leverages the state of the directory tree during dependency\nresolution to achieve accurate and efficient PeerSpin detection. Based on this\ntechnique, we developed a tool called PeerChecker to detect PeerSpin. Finally,\nwe apply PeerChecker to the entire NPM ecosystem and find that 5,662 packages,\ntotaling 72,968 versions, suffer from PeerSpin. Up until now, we confirmed 28\nreal PeerSpin problems by reporting them to the package maintainer. We also\nopen source all PeerSpin analysis implementations, tools, and data sets to the\npublic to help the community detect PeerSpin issues and enhance the reliability\nof the npm ecosystem.",
    "pdf_url": "http://arxiv.org/pdf/2505.12676v2",
    "published": "2025-05-19T03:47:45+00:00",
    "categories": [
      "cs.SE",
      "D.2"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12675v2",
    "title": "Quantum Statistics of Two Identical Particles and Modified Hong-Ou-Mandel Interferometer",
    "authors": [
      "Won-Young Hwang",
      "Kicheon Kang"
    ],
    "abstract": "We propose an experimental scheme to probe the quantum statistics of two\nidentical particles. The transition between the quantum and classical\nstatistics of two identical particles is described by the particles having\nidentical multiple internal energy levels. We show that effective\ndistinguishability emerges as the thermal energy increases with respect to the\nenergy level spacing, and the mesoscopic regime bridges quantum\nindistinguishability and classical distinguishability. A realistic experimental\napproach is proposed using a two-particle interferometer, where the particles\nreach statistical equilibrium before the two-particle distribution is measured.\nThe unitarity of the scattering/separation process ensures the preservation of\nthe equilibrium distribution and allows a direct measurement of the\ntwo-particle statistical distribution. Our results show the transition between\nquantum and classical behavior of the two-particle distribution, which can be\ndirectly probed by a realistic experiment.",
    "pdf_url": "http://arxiv.org/pdf/2505.12675v2",
    "published": "2025-05-19T03:47:13+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall",
      "cond-mat.stat-mech",
      "physics.atom-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12674v1",
    "title": "Few-Step Diffusion via Score identity Distillation",
    "authors": [
      "Mingyuan Zhou",
      "Yi Gu",
      "Zhendong Wang"
    ],
    "abstract": "Diffusion distillation has emerged as a promising strategy for accelerating\ntext-to-image (T2I) diffusion models by distilling a pretrained score network\ninto a one- or few-step generator. While existing methods have made notable\nprogress, they often rely on real or teacher-synthesized images to perform well\nwhen distilling high-resolution T2I diffusion models such as Stable Diffusion\nXL (SDXL), and their use of classifier-free guidance (CFG) introduces a\npersistent trade-off between text-image alignment and generation diversity. We\naddress these challenges by optimizing Score identity Distillation (SiD) -- a\ndata-free, one-step distillation framework -- for few-step generation. Backed\nby theoretical analysis that justifies matching a uniform mixture of outputs\nfrom all generation steps to the data distribution, our few-step distillation\nalgorithm avoids step-specific networks and integrates seamlessly into existing\npipelines, achieving state-of-the-art performance on SDXL at 1024x1024\nresolution. To mitigate the alignment-diversity trade-off when real text-image\npairs are available, we introduce a Diffusion GAN-based adversarial loss\napplied to the uniform mixture and propose two new guidance strategies:\nZero-CFG, which disables CFG in the teacher and removes text conditioning in\nthe fake score network, and Anti-CFG, which applies negative CFG in the fake\nscore network. This flexible setup improves diversity without sacrificing\nalignment. Comprehensive experiments on SD1.5 and SDXL demonstrate\nstate-of-the-art performance in both one-step and few-step generation settings,\nalong with robustness to the absence of real images. Our efficient PyTorch\nimplementation, along with the resulting one- and few-step distilled\ngenerators, will be released publicly as a separate branch at\nhttps://github.com/mingyuanzhou/SiD-LSG.",
    "pdf_url": "http://arxiv.org/pdf/2505.12674v1",
    "published": "2025-05-19T03:45:16+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12673v1",
    "title": "Correlated Dirac semimetal states in nonsymmorphic MIrO$_3$ (M=Sr, Ba and Ca)",
    "authors": [
      "Zhi-Ming Yang",
      "Huan Li"
    ],
    "abstract": "Nonsymmorphic symmetries can give rise to Dirac semimetal (DSM) states.\nHowever, few studies have been conducted on DSMs in interacting systems. Here,\nwe induce interacting DSM states in nonsymmorphic iridium oxides SrIrO$_3$,\nBaIrO$_3$ and CaIrO$_3$, and contend that the interaction of electron-electron\ncorrelations, strong spin-orbital coupling, and symmetry protection can drive\nrobust and exotic DSM states. Based on the density functional theory combined\nwith dynamical mean-field theory (DFT + DMFT), with the Coulomb interaction\nparameters computed through doubly screened Coulomb correction approach, we\ndiscover that the Dirac fermions are constituted by the strongly spin-orbital\ncoupled $J_{\\mathrm{eff}} = 1/2$ states resulting from $t_{2g}$ orbits of Ir,\nwith significant mass enhancement. Moreover, the nonsymmorphic symmetries\ninduce topological surface bands and Fermi arcs on the (001) surface, which are\nwell separated from bulk states. Our findings establish nonsymmorphic iridium\noxides as correlated DSMs under strong electron-electron and spin-orbital\ninteractions.",
    "pdf_url": "http://arxiv.org/pdf/2505.12673v1",
    "published": "2025-05-19T03:42:27+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.13547v1",
    "title": "Exploring Federated Pruning for Large Language Models",
    "authors": [
      "Pengxin Guo",
      "Yinong Wang",
      "Wei Li",
      "Mengting Liu",
      "Ming Li",
      "Jinkai Zheng",
      "Liangqiong Qu"
    ],
    "abstract": "LLM pruning has emerged as a promising technology for compressing LLMs,\nenabling their deployment on resource-limited devices. However, current\nmethodologies typically require access to public calibration samples, which can\nbe challenging to obtain in privacy-sensitive domains. To address this issue,\nwe introduce FedPrLLM, a comprehensive federated pruning framework designed for\nthe privacy-preserving compression of LLMs. In FedPrLLM, each client only needs\nto calculate a pruning mask matrix based on its local calibration data and\nshare it with the server to prune the global model. This approach allows for\ncollaborative pruning of the global model with the knowledge of each client\nwhile maintaining local data privacy. Additionally, we conduct extensive\nexperiments to explore various possibilities within the FedPrLLM framework,\nincluding different comparison groups, pruning strategies, and the decision to\nscale weights. Our extensive evaluation reveals that one-shot pruning with\nlayer comparison and no weight scaling is the optimal choice within the\nFedPrLLM framework. We hope our work will help guide future efforts in pruning\nLLMs in privacy-sensitive fields. Our code is available at\nhttps://github.com/Pengxin-Guo/FedPrLLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.13547v1",
    "published": "2025-05-19T03:41:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12672v1",
    "title": "TransferTraj: A Vehicle Trajectory Learning Model for Region and Task Transferability",
    "authors": [
      "Tonglong Wei",
      "Yan Lin",
      "Zeyu Zhou",
      "Haomin Wen",
      "Jilin Hu",
      "Shengnan Guo",
      "Youfang Lin",
      "Gao Cong",
      "Huaiyu Wan"
    ],
    "abstract": "Vehicle GPS trajectories provide valuable movement information that supports\nvarious downstream tasks and applications. A desirable trajectory learning\nmodel should be able to transfer across regions and tasks without retraining,\navoiding the need to maintain multiple specialized models and subpar\nperformance with limited training data. However, each region has its unique\nspatial features and contexts, which are reflected in vehicle movement patterns\nand difficult to generalize. Additionally, transferring across different tasks\nfaces technical challenges due to the varying input-output structures required\nfor each task. Existing efforts towards transferability primarily involve\nlearning embedding vectors for trajectories, which perform poorly in region\ntransfer and require retraining of prediction modules for task transfer.\n  To address these challenges, we propose TransferTraj, a vehicle GPS\ntrajectory learning model that excels in both region and task transferability.\nFor region transferability, we introduce RTTE as the main learnable module\nwithin TransferTraj. It integrates spatial, temporal, POI, and road network\nmodalities of trajectories to effectively manage variations in spatial context\ndistribution across regions. It also introduces a TRIE module for incorporating\nrelative information of spatial features and a spatial context MoE module for\nhandling movement patterns in diverse contexts. For task transferability, we\npropose a task-transferable input-output scheme that unifies the input-output\nstructure of different tasks into the masking and recovery of modalities and\ntrajectory points. This approach allows TransferTraj to be pre-trained once and\ntransferred to different tasks without retraining. Extensive experiments on\nthree real-world vehicle trajectory datasets under task transfer, zero-shot,\nand few-shot region transfer, validating TransferTraj's effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.12672v1",
    "published": "2025-05-19T03:40:34+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12671v1",
    "title": "Idealized Global Models of Accretion Disks with Strong Toroidal Magnetic Fields",
    "authors": [
      "Minghao Guo",
      "Eliot Quataert",
      "Jonathan Squire",
      "Philip F. Hopkins",
      "James M. Stone"
    ],
    "abstract": "We present global magnetohydrodynamic (MHD) simulations of accretion disks\nwith a strong toroidal magnetic field using an equation of state that fixes the\ngas thermal scale height. The disk forms from the inflow of a rotating\nmagnetized gas cloud with a toroidal magnetic field. We find that the system\nmaintains a moderately strong mean azimuthal field in the midplane, with\nplasma-$\\beta\\sim1$, trans-Alfv\\'enic fluctuations, and large accretion\nstresses $\\alpha\\sim0.1$. The azimuthal field in the disk is continuously\nescaping along the vertical direction but is also replenished via a local\ndynamo. The inflowing gas initially forms a strongly magnetized Keplerian disk\nwith $\\beta\\ll1$ and $\\alpha \\gg 1$. The disk gradually collapses from the\ninside out over $\\sim 50-80$ orbits to form a moderately magnetized disk with\n$\\beta\\sim1$ and $\\alpha\\sim0.1$. Radial advection of azimuthal magnetic field\ncan maintain $\\beta\\lesssim1$ exterior to the circularization radius but not\ninside of it. Inclusion of a net initial vertical magnetic field can lead to an\neven more strongly magnetized disk midplane, consistent with previous work.\nWhen the gas thermal scale is not resolved ($\\lesssim 4$ cells per thermal\nscale height), however, the disk remains highly magnetized with $\\beta \\ll 1 $.\nWe discuss our results in the context of related shearing box simulations and\nother global disk simulations. The level of angular momentum transport found\nhere is consistent with that inferred observationally in dwarf novae and X-ray\ntransient outbursts, unlike simulations of weakly magnetized accretion disks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12671v1",
    "published": "2025-05-19T03:38:08+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12670v1",
    "title": "TS-VLM: Text-Guided SoftSort Pooling for Vision-Language Models in Multi-View Driving Reasoning",
    "authors": [
      "Lihong Chen",
      "Hossein Hassani",
      "Soodeh Nikan"
    ],
    "abstract": "Vision-Language Models (VLMs) have shown remarkable potential in advancing\nautonomous driving by leveraging multi-modal fusion in order to enhance scene\nperception, reasoning, and decision-making. Despite their potential, existing\nmodels suffer from computational overhead and inefficient integration of\nmulti-view sensor data that make them impractical for real-time deployment in\nsafety-critical autonomous driving applications. To address these shortcomings,\nthis paper is devoted to designing a lightweight VLM called TS-VLM, which\nincorporates a novel Text-Guided SoftSort Pooling (TGSSP) module. By resorting\nto semantics of the input queries, TGSSP ranks and fuses visual features from\nmultiple views, enabling dynamic and query-aware multi-view aggregation without\nreliance on costly attention mechanisms. This design ensures the query-adaptive\nprioritization of semantically related views, which leads to improved\ncontextual accuracy in multi-view reasoning for autonomous driving. Extensive\nevaluations on the DriveLM benchmark demonstrate that, on the one hand, TS-VLM\noutperforms state-of-the-art models with a BLEU-4 score of 56.82, METEOR of\n41.91, ROUGE-L of 74.64, and CIDEr of 3.39. On the other hand, TS-VLM reduces\ncomputational cost by up to 90%, where the smallest version contains only 20.1\nmillion parameters, making it more practical for real-time deployment in\nautonomous vehicles.",
    "pdf_url": "http://arxiv.org/pdf/2505.12670v1",
    "published": "2025-05-19T03:37:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12669v1",
    "title": "Text2midi-InferAlign: Improving Symbolic Music Generation with Inference-Time Alignment",
    "authors": [
      "Abhinaba Roy",
      "Geeta Puri",
      "Dorien Herremans"
    ],
    "abstract": "We present Text2midi-InferAlign, a novel technique for improving symbolic\nmusic generation at inference time. Our method leverages text-to-audio\nalignment and music structural alignment rewards during inference to encourage\nthe generated music to be consistent with the input caption. Specifically, we\nintroduce two objectives scores: a text-audio consistency score that measures\nrhythmic alignment between the generated music and the original text caption,\nand a harmonic consistency score that penalizes generated music containing\nnotes inconsistent with the key. By optimizing these alignment-based objectives\nduring the generation process, our model produces symbolic music that is more\nclosely tied to the input captions, thereby improving the overall quality and\ncoherence of the generated compositions. Our approach can extend any existing\nautoregressive model without requiring further training or fine-tuning. We\nevaluate our work on top of Text2midi - an existing text-to-midi generation\nmodel, demonstrating significant improvements in both objective and subjective\nevaluation metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.12669v1",
    "published": "2025-05-19T03:36:06+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS",
      "68T07",
      "I.2.1"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.12668v1",
    "title": "Decompile-Bench: Million-Scale Binary-Source Function Pairs for Real-World Binary Decompilation",
    "authors": [
      "Hanzhuo Tan",
      "Xiaolong Tian",
      "Hanrui Qi",
      "Jiaming Liu",
      "Zuchen Gao",
      "Siyi Wang",
      "Qi Luo",
      "Jing Li",
      "Yuqun Zhang"
    ],
    "abstract": "Recent advances in LLM-based decompilers have been shown effective to convert\nlow-level binaries into human-readable source code. However, there still lacks\na comprehensive benchmark that provides large-scale binary-source function\npairs, which is critical for advancing the LLM decompilation technology.\nCreating accurate binary-source mappings incurs severe issues caused by complex\ncompilation settings and widespread function inlining that obscure the\ncorrespondence between binaries and their original source code. Previous\nefforts have either relied on used contest-style benchmarks, synthetic\nbinary-source mappings that diverge significantly from the mappings in real\nworld, or partially matched binaries with only code lines or variable names,\ncompromising the effectiveness of analyzing the binary functionality. To\nalleviate these issues, we introduce Decompile-Bench, the first open-source\ndataset comprising two million binary-source function pairs condensed from 100\nmillion collected function pairs, i.e., 450GB of binaries compiled from\npermissively licensed GitHub projects. For the evaluation purposes, we also\ndeveloped a benchmark Decompile-Bench-Eval including manually crafted binaries\nfrom the well-established HumanEval and MBPP, alongside the compiled GitHub\nrepositories released after 2025 to mitigate data leakage issues. We further\nexplore commonly-used evaluation metrics to provide a thorough assessment of\nthe studied LLM decompilers and find that fine-tuning with Decompile-Bench\ncauses a 20% improvement over previous benchmarks in terms of the\nre-executability rate. Our code and data has been released in HuggingFace and\nGithub. https://github.com/albertan017/LLM4Decompile",
    "pdf_url": "http://arxiv.org/pdf/2505.12668v1",
    "published": "2025-05-19T03:34:33+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12667v1",
    "title": "Safe-Sora: Safe Text-to-Video Generation via Graphical Watermarking",
    "authors": [
      "Zihan Su",
      "Xuerui Qiu",
      "Hongbin Xu",
      "Tangyu Jiang",
      "Junhao Zhuang",
      "Chun Yuan",
      "Ming Li",
      "Shengfeng He",
      "Fei Richard Yu"
    ],
    "abstract": "The explosive growth of generative video models has amplified the demand for\nreliable copyright preservation of AI-generated content. Despite its popularity\nin image synthesis, invisible generative watermarking remains largely\nunderexplored in video generation. To address this gap, we propose Safe-Sora,\nthe first framework to embed graphical watermarks directly into the video\ngeneration process. Motivated by the observation that watermarking performance\nis closely tied to the visual similarity between the watermark and cover\ncontent, we introduce a hierarchical coarse-to-fine adaptive matching\nmechanism. Specifically, the watermark image is divided into patches, each\nassigned to the most visually similar video frame, and further localized to the\noptimal spatial region for seamless embedding. To enable spatiotemporal fusion\nof watermark patches across video frames, we develop a 3D wavelet\ntransform-enhanced Mamba architecture with a novel spatiotemporal local\nscanning strategy, effectively modeling long-range dependencies during\nwatermark embedding and retrieval. To the best of our knowledge, this is the\nfirst attempt to apply state space models to watermarking, opening new avenues\nfor efficient and robust watermark protection. Extensive experiments\ndemonstrate that Safe-Sora achieves state-of-the-art performance in terms of\nvideo quality, watermark fidelity, and robustness, which is largely attributed\nto our proposals. We will release our code upon publication.",
    "pdf_url": "http://arxiv.org/pdf/2505.12667v1",
    "published": "2025-05-19T03:31:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12666v1",
    "title": "Adapting to LLMs: How Insiders and Outsiders Reshape Scientific Knowledge Production",
    "authors": [
      "Huimin Xu",
      "Houjiang Liu",
      "Yan Leng",
      "Ying Ding"
    ],
    "abstract": "CSCW has long examined how emerging technologies reshape the ways researchers\ncollaborate and produce knowledge, with scientific knowledge production as a\ncentral area of focus. As AI becomes increasingly integrated into scientific\nresearch, understanding how researchers adapt to it reveals timely\nopportunities for CSCW research -- particularly in supporting new forms of\ncollaboration, knowledge practices, and infrastructure in AI-driven science.\n  This study quantifies LLM impacts on scientific knowledge production based on\nan evaluation workflow that combines an insider-outsider perspective with a\nknowledge production framework. Our findings reveal how LLMs catalyze both\ninnovation and reorganization in scientific communities, offering insights into\nthe broader transformation of knowledge production in the age of generative AI\nand sheds light on new research opportunities in CSCW.",
    "pdf_url": "http://arxiv.org/pdf/2505.12666v1",
    "published": "2025-05-19T03:30:10+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.13546v1",
    "title": "Prompt Stability Matters: Evaluating and Optimizing Auto-Generated Prompt in General-Purpose Systems",
    "authors": [
      "Ke Chen",
      "Yufei Zhou",
      "Xitong Zhang",
      "Haohan Wang"
    ],
    "abstract": "Automatic prompt generation plays a crucial role in enabling general-purpose\nmulti-agent systems to perform diverse tasks autonomously. Existing methods\ntypically evaluate prompts based on their immediate task performance,\noverlooking the intrinsic qualities that determine their reliability. This\noutcome-centric view not only limits interpretability but also fails to account\nfor the inherent stochasticity of large language models (LLMs). In this work,\nwe bring attention to prompt stability-the consistency of model responses\nacross repeated executions-as a key factor for building robust and effective\nprompt generation systems. To quantify this, we propose semantic stability as a\ncriterion for assessing the response consistency of prompts, and fine-tune a\nLLaMA-based evaluator to measure it automatically across tasks. These\ncomponents have enabled us to develop the first stability-aware general-purpose\nprompt generation system that leverages stability feedback to iteratively\nenhance both prompt quality and system-level performance. Furthermore, we\nestablish a logical chain between prompt stability and task success by\nanalyzing the structural dependencies within our system, proving stability as a\nnecessary condition for effective system-level execution. Empirical results\nacross general and domain-specific tasks demonstrate that our stability-aware\nframework improves both accuracy and output consistency. By shifting the focus\nfrom one-off results to persistent reliability, our work offers a new\nperspective on prompt design and contributes practical tools for building more\ntrustworthy general-purpose systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13546v1",
    "published": "2025-05-19T03:28:33+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12665v1",
    "title": "Audio-Visual Contact Classification for Tree Structures in Agriculture",
    "authors": [
      "Ryan Spears",
      "Moonyoung Lee",
      "George Kantor",
      "Oliver Kroemer"
    ],
    "abstract": "Contact-rich manipulation tasks in agriculture, such as pruning and\nharvesting, require robots to physically interact with tree structures to\nmaneuver through cluttered foliage. Identifying whether the robot is contacting\nrigid or soft materials is critical for the downstream manipulation policy to\nbe safe, yet vision alone is often insufficient due to occlusion and limited\nviewpoints in this unstructured environment. To address this, we propose a\nmulti-modal classification framework that fuses vibrotactile (audio) and visual\ninputs to identify the contact class: leaf, twig, trunk, or ambient. Our key\ninsight is that contact-induced vibrations carry material-specific signals,\nmaking audio effective for detecting contact events and distinguishing material\ntypes, while visual features add complementary semantic cues that support more\nfine-grained classification. We collect training data using a hand-held sensor\nprobe and demonstrate zero-shot generalization to a robot-mounted probe\nembodiment, achieving an F1 score of 0.82. These results underscore the\npotential of audio-visual learning for manipulation in unstructured,\ncontact-rich environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12665v1",
    "published": "2025-05-19T03:28:02+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12664v1",
    "title": "Multi-View Wireless Sensing via Conditional Generative Learning: Framework and Model Design",
    "authors": [
      "Ziqing Xing",
      "Zhaoyang Zhang",
      "Zirui Chen",
      "Hongning Ruan",
      "Zhaohui Yang"
    ],
    "abstract": "In this paper, we incorporate physical knowledge into learning-based\nhigh-precision target sensing using the multi-view channel state information\n(CSI) between multiple base stations (BSs) and user equipment (UEs). Such kind\nof multi-view sensing problem can be naturally cast into a conditional\ngeneration framework. To this end, we design a bipartite neural network\narchitecture, the first part of which uses an elaborately designed encoder to\nfuse the latent target features embedded in the multi-view CSI, and then the\nsecond uses them as conditioning inputs of a powerful generative model to guide\nthe target's reconstruction. Specifically, the encoder is designed to capture\nthe physical correlation between the CSI and the target, and also be adaptive\nto the numbers and positions of BS-UE pairs. Therein the view-specific nature\nof CSI is assimilated by introducing a spatial positional embedding scheme,\nwhich exploits the structure of electromagnetic(EM)-wave propagation channels.\nFinally, a conditional diffusion model with a weighted loss is employed to\ngenerate the target's point cloud from the fused features. Extensive numerical\nresults demonstrate that the proposed generative multi-view (Gen-MV) sensing\nframework exhibits excellent flexibility and significant performance\nimprovement on the reconstruction quality of target's shape and EM properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.12664v1",
    "published": "2025-05-19T03:27:24+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12663v1",
    "title": "MTGRBoost: Boosting Large-scale Generative Recommendation Models in Meituan",
    "authors": [
      "Yuxiang Wang",
      "Xiao Yan",
      "Chi Ma",
      "Mincong Huang",
      "Xiaoguang Li",
      "Lei Yu",
      "Chuan Liu",
      "Ruidong Han",
      "He Jiang",
      "Bin Yin",
      "Shangyu Chen",
      "Fei Jiang",
      "Xiang Li",
      "Wei Lin",
      "Haowei Han",
      "Bo Du",
      "Jiawei Jiang"
    ],
    "abstract": "Recommendation is crucial for both user experience and company revenue, and\ngenerative recommendation models (GRMs) are shown to produce quality\nrecommendations recently. However, existing systems are limited by insufficient\nfunctionality support and inefficient implementations for training GRMs in\nindustrial scenarios. As such, we introduce MTGRBoost as an efficient and\nscalable system for GRM training. Specifically, to handle the real-time\ninsert/delete of sparse embedding entries, MTGRBoost employs dynamic hash\ntables to replace static tables. To improve efficiency, MTGRBoost conducts\ndynamic sequence balancing to address the computation load imbalances among\nGPUs and adopts embedding ID deduplication alongside automatic table merging to\naccelerate embedding lookup. MTGRBoost also incorporates implementation\noptimizations including checkpoint resuming, mixed precision training, gradient\naccumulation, and operator fusion. Extensive experiments show that MTGRBoost\nimproves training throughput by $1.6 \\times$ -- $2.4\\times$ while achieving\ngood scalability when running over 100 GPUs. MTGRBoost has been deployed for\nmany applications in Meituan and is now handling hundreds of millions of\nrequests on a daily basis.",
    "pdf_url": "http://arxiv.org/pdf/2505.12663v1",
    "published": "2025-05-19T03:26:18+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12662v1",
    "title": "Know3-RAG: A Knowledge-aware RAG Framework with Adaptive Retrieval, Generation, and Filtering",
    "authors": [
      "Xukai Liu",
      "Ye Liu",
      "Shiwen Wu",
      "Yanghai Zhang",
      "Yihao Yuan",
      "Kai Zhang",
      "Qi Liu"
    ],
    "abstract": "Recent advances in large language models (LLMs) have led to impressive\nprogress in natural language generation, yet their tendency to produce\nhallucinated or unsubstantiated content remains a critical concern. To improve\nfactual reliability, Retrieval-Augmented Generation (RAG) integrates external\nknowledge during inference. However, existing RAG systems face two major\nlimitations: (1) unreliable adaptive control due to limited external knowledge\nsupervision, and (2) hallucinations caused by inaccurate or irrelevant\nreferences. To address these issues, we propose Know3-RAG, a knowledge-aware\nRAG framework that leverages structured knowledge from knowledge graphs (KGs)\nto guide three core stages of the RAG process, including retrieval, generation,\nand filtering. Specifically, we introduce a knowledge-aware adaptive retrieval\nmodule that employs KG embedding to assess the confidence of the generated\nanswer and determine retrieval necessity, a knowledge-enhanced reference\ngeneration strategy that enriches queries with KG-derived entities to improve\ngenerated reference relevance, and a knowledge-driven reference filtering\nmechanism that ensures semantic alignment and factual accuracy of references.\nExperiments on multiple open-domain QA benchmarks demonstrate that Know3-RAG\nconsistently outperforms strong baselines, significantly reducing\nhallucinations and enhancing answer reliability.",
    "pdf_url": "http://arxiv.org/pdf/2505.12662v1",
    "published": "2025-05-19T03:25:18+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12661v1",
    "title": "Digital Twins in the Cloud: A Modular, Scalable and Interoperable Framework for Accelerating Verification and Validation of Autonomous Driving Solutions",
    "authors": [
      "Tanmay Vilas Samak",
      "Chinmay Vilas Samak",
      "Giovanni Martino",
      "Pranav Nair",
      "Venkat Krovi"
    ],
    "abstract": "Verification and validation (V&V) of autonomous vehicles (AVs) typically\nrequires exhaustive testing across a variety of operating environments and\ndriving scenarios including rare, extreme, or hazardous situations that might\nbe difficult or impossible to capture in reality. Additionally, physical V&V\nmethods such as track-based evaluations or public-road testing are often\nconstrained by time, cost, and safety, which motivates the need for virtual\nproving grounds. However, the fidelity and scalability of simulation-based V&V\nmethods can quickly turn into a bottleneck. In such a milieu, this work\nproposes a virtual proving ground that flexibly scales digital twins within\nhigh-performance computing clusters (HPCCs) and automates the V&V process.\nHere, digital twins enable high-fidelity virtual representation of the AV and\nits operating environments, allowing extensive scenario-based testing.\nMeanwhile, HPCC infrastructure brings substantial advantages in terms of\ncomputational power and scalability, enabling rapid iterations of simulations,\nprocessing and storage of massive amounts of data, and deployment of\nlarge-scale test campaigns, thereby reducing the time and cost associated with\nthe V&V process. We demonstrate the efficacy of this approach through a case\nstudy that focuses on the variability analysis of a candidate autonomy\nalgorithm to identify potential vulnerabilities in its perception, planning,\nand control sub-systems. The modularity, scalability, and interoperability of\nthe proposed framework are demonstrated by deploying a test campaign comprising\n256 test cases on two different HPCC architectures to ensure continuous\noperation in a publicly shared resource setting. The findings highlight the\nability of the proposed framework to accelerate and streamline the V&V process,\nthereby significantly compressing (~30x) the timeline.",
    "pdf_url": "http://arxiv.org/pdf/2505.12661v1",
    "published": "2025-05-19T03:23:48+00:00",
    "categories": [
      "cs.RO",
      "cs.DC"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12660v1",
    "title": "Predicting Reaction Time to Comprehend Scenes with Foveated Scene Understanding Maps",
    "authors": [
      "Ziqi Wen",
      "Jonathan Skaza",
      "Shravan Murlidaran",
      "William Y. Wang",
      "Miguel P. Eckstein"
    ],
    "abstract": "Although models exist that predict human response times (RTs) in tasks such\nas target search and visual discrimination, the development of image-computable\npredictors for scene understanding time remains an open challenge. Recent\nadvances in vision-language models (VLMs), which can generate scene\ndescriptions for arbitrary images, combined with the availability of\nquantitative metrics for comparing linguistic descriptions, offer a new\nopportunity to model human scene understanding. We hypothesize that the primary\nbottleneck in human scene understanding and the driving source of variability\nin response times across scenes is the interaction between the foveated nature\nof the human visual system and the spatial distribution of task-relevant visual\ninformation within an image. Based on this assumption, we propose a novel\nimage-computable model that integrates foveated vision with VLMs to produce a\nspatially resolved map of scene understanding as a function of fixation\nlocation (Foveated Scene Understanding Map, or F-SUM), along with an aggregate\nF-SUM score. This metric correlates with average (N=17) human RTs (r=0.47) and\nnumber of saccades (r=0.51) required to comprehend a scene (across 277 scenes).\nThe F-SUM score also correlates with average (N=16) human description accuracy\n(r=-0.56) in time-limited presentations. These correlations significantly\nexceed those of standard image-based metrics such as clutter, visual\ncomplexity, and scene ambiguity based on language entropy. Together, our work\nintroduces a new image-computable metric for predicting human response times in\nscene understanding and demonstrates the importance of foveated visual\nprocessing in shaping comprehension difficulty.",
    "pdf_url": "http://arxiv.org/pdf/2505.12660v1",
    "published": "2025-05-19T03:23:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12659v1",
    "title": "Two-sided Gaussian estimates for fundamental solutions of second-order parabolic equations in non-divergence form",
    "authors": [
      "Seick Kim",
      "Sungjin Lee",
      "Georgios Sakellaris"
    ],
    "abstract": "We establish two-sided Gaussian bounds for the fundamental solution of\nsecond-order parabolic operators in non-divergence form under minimal\nregularity assumptions. Specifically, we show that the upper and lower bounds\nfollow from the local boundedness property and the weak Harnack inequality for\nthe adjoint operator $P^*$, respectively. This provides a simpler and more\ndirect proof of the Gaussian estimates when the coefficients have Dini mean\noscillation in $x$, avoiding the use of normalized adjoint solutions required\nin previous works.",
    "pdf_url": "http://arxiv.org/pdf/2505.12659v1",
    "published": "2025-05-19T03:20:28+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13545v2",
    "title": "Know Or Not: a library for evaluating out-of-knowledge base robustness",
    "authors": [
      "Jessica Foo",
      "Pradyumna Shyama Prasad",
      "Shaun Khoo"
    ],
    "abstract": "While the capabilities of large language models (LLMs) have progressed\nsignificantly, their use in high-stakes applications have been limited due to\nrisks of hallucination. One key approach in reducing hallucination is\nretrieval-augmented generation (RAG), but even in such setups, LLMs may still\nhallucinate when presented with questions outside of the knowledge base. Such\nbehavior is unacceptable in high-stake applications where LLMs are expected to\nabstain from answering queries it does not have sufficient context on. In this\nwork, we present a novel methodology for systematically evaluating\nout-of-knowledge base (OOKB) robustness of LLMs (whether LLMs know or do not\nknow) in the RAG setting, without the need for manual annotation of gold\nstandard answers. We implement our methodology in knowornot, an open-source\nlibrary that enables users to develop their own customized evaluation data and\npipelines for OOKB robustness. knowornot comprises four main features. Firstly,\nit provides a unified, high-level API that streamlines the process of setting\nup and running robustness benchmarks. Secondly, its modular architecture\nemphasizes extensibility and flexibility, allowing users to easily integrate\ntheir own LLM clients and RAG settings. Thirdly, its rigorous data modeling\ndesign ensures experiment reproducibility, reliability and traceability.\nLastly, it implements a comprehensive suite of tools for users to customize\ntheir pipelines. We demonstrate the utility of knowornot by developing a\nchallenging benchmark, PolicyBench, which spans four Question-Answer (QA)\nchatbots on government policies, and analyze its OOKB robustness. The source\ncode of knowornot is available\nhttps://github.com/govtech-responsibleai/KnowOrNot.",
    "pdf_url": "http://arxiv.org/pdf/2505.13545v2",
    "published": "2025-05-19T03:17:41+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12658v1",
    "title": "HydraInfer: Hybrid Disaggregated Scheduling for Multimodal Large Language Model Serving",
    "authors": [
      "Xianzhe Dong",
      "Tongxuan Liu",
      "Yuting Zeng",
      "Liangyu Liu",
      "Yang Liu",
      "Siyu Wu",
      "Yu Wu",
      "Hailong Yang",
      "Ke Zhang",
      "Jing Li"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have been rapidly advancing,\nenabling cross-modal understanding and generation, and propelling artificial\nintelligence towards artificial general intelligence. However, existing MLLM\ninference systems are typically designed based on the architecture of language\nmodels, integrating image processing and language processing as a single\nscheduling unit. This design struggles to accommodate the heterogeneous demands\nof different stages in terms of computational resources, memory access\npatterns, and service-level objectives (SLOs), leading to low resource\nutilization and high request latency, ultimately failing to meet the service\nrequirements of diverse inference scenarios.\n  To address these challenges, we propose HydraInfer, an efficient MLLM\ninference system that adopts a Hybrid Encode-Prefill-Decode (EPD)\nDisaggregation architecture. By scheduling the three stages - encode, prefill,\nand decode - onto separate heterogeneous inference instances, the system\nflexibly reallocates resources across stages, significantly reducing idle\ncomputation, alleviating resource bottlenecks, and improving overall system\nthroughput and scalability. In addition, HydraInfer supports a stage-level\nbatching strategy that enhances load balancing, enables parallel execution of\nvisual and language models, and further optimizes inference performance.\nExperiments under real multimodal inference workloads demonstrate that\nHydraInfer can achieve up to 4x higher inference throughput compared to\nstate-of-the-art systems (e.g., vLLM) on a single-node 8xH800 GPU cluster,\nwhile meeting the 90th percentile request SLO.",
    "pdf_url": "http://arxiv.org/pdf/2505.12658v1",
    "published": "2025-05-19T03:16:22+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12657v1",
    "title": "Transmission Neural Networks: Approximation and Optimal Control",
    "authors": [
      "Shuang Gao",
      "Peter E. Caines"
    ],
    "abstract": "Transmission Neural Networks (TransNNs) introduced by Gao and Caines (2022)\nconnect virus spread models over networks and neural networks with tuneable\nactivation functions. This paper presents the approximation technique and the\nunderlying assumptions employed by TransNNs in relation to the corresponding\nMarkovian Susceptible-Infected-Susceptible (SIS) model with 2^n states, where n\nis the number of nodes in the network. The underlying infection paths are\nassumed to be stochastic with heterogeneous and time-varying transmission\nprobabilities. We obtain the conditional probability of infection in the\nstochastic 2^n-state SIS epidemic model corresponding to each state\nconfiguration under mild assumptions, which enables control solutions based on\nMarkov decision processes (MDP). Finally, MDP control with 2^n-state SIS\nepidemic models and optimal control with TransNNs are compared in terms of\nmitigating virus spread over networks through vaccination, and it is shown that\nTranNNs enable the generation of control laws with significant computational\nsavings, albeit with more conservative control actions.",
    "pdf_url": "http://arxiv.org/pdf/2505.12657v1",
    "published": "2025-05-19T03:14:32+00:00",
    "categories": [
      "eess.SY",
      "cs.SI",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.12656v2",
    "title": "SPKLIP: Aligning Spike Video Streams with Natural Language",
    "authors": [
      "Yongchang Gao",
      "Meiling Jin",
      "Zhaofei Yu",
      "Tiejun Huang",
      "Guozhang Chen"
    ],
    "abstract": "Spike cameras offer unique sensing capabilities but their sparse,\nasynchronous output challenges semantic understanding, especially for Spike\nVideo-Language Alignment (Spike-VLA) where models like CLIP underperform due to\nmodality mismatch. We introduce SPKLIP, the first architecture specifically for\nSpike-VLA. SPKLIP employs a hierarchical spike feature extractor that\nadaptively models multi-scale temporal dynamics in event streams, and uses\nspike-text contrastive learning to directly align spike video with language,\nenabling effective few-shot learning. A full-spiking visual encoder variant,\nintegrating SNN components into our pipeline, demonstrates enhanced energy\nefficiency. Experiments show state-of-the-art performance on benchmark spike\ndatasets and strong few-shot generalization on a newly contributed real-world\ndataset. SPKLIP's energy efficiency highlights its potential for neuromorphic\ndeployment, advancing event-based multimodal research. The source code and\ndataset are available at [link removed for anonymity].",
    "pdf_url": "http://arxiv.org/pdf/2505.12656v2",
    "published": "2025-05-19T03:14:22+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12655v2",
    "title": "Web Intellectual Property at Risk: Preventing Unauthorized Real-Time Retrieval by Large Language Models",
    "authors": [
      "Yisheng Zhong",
      "Yizhu Wen",
      "Junfeng Guo",
      "Mehran Kafai",
      "Heng Huang",
      "Hanqing Guo",
      "Zhuangdi Zhu"
    ],
    "abstract": "The protection of cyber Intellectual Property (IP) such as web content is an\nincreasingly critical concern. The rise of large language models (LLMs) with\nonline retrieval capabilities enables convenient access to information but\noften undermines the rights of original content creators. As users increasingly\nrely on LLM-generated responses, they gradually diminish direct engagement with\noriginal information sources, which will significantly reduce the incentives\nfor IP creators to contribute, and lead to a saturating cyberspace with more\nAI-generated content. In response, we propose a novel defense framework that\nempowers web content creators to safeguard their web-based IP from unauthorized\nLLM real-time extraction and redistribution by leveraging the semantic\nunderstanding capability of LLMs themselves. Our method follows principled\nmotivations and effectively addresses an intractable black-box optimization\nproblem. Real-world experiments demonstrated that our methods improve defense\nsuccess rates from 2.5% to 88.6% on different LLMs, outperforming traditional\ndefenses such as configuration-based restrictions.",
    "pdf_url": "http://arxiv.org/pdf/2505.12655v2",
    "published": "2025-05-19T03:14:08+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12654v2",
    "title": "Predicting Turn-Taking and Backchannel in Human-Machine Conversations Using Linguistic, Acoustic, and Visual Signals",
    "authors": [
      "Yuxin Lin",
      "Yinglin Zheng",
      "Ming Zeng",
      "Wangzheng Shi"
    ],
    "abstract": "This paper addresses the gap in predicting turn-taking and backchannel\nactions in human-machine conversations using multi-modal signals (linguistic,\nacoustic, and visual). To overcome the limitation of existing datasets, we\npropose an automatic data collection pipeline that allows us to collect and\nannotate over 210 hours of human conversation videos. From this, we construct a\nMulti-Modal Face-to-Face (MM-F2F) human conversation dataset, including over\n1.5M words and corresponding turn-taking and backchannel annotations from\napproximately 20M frames. Additionally, we present an end-to-end framework that\npredicts the probability of turn-taking and backchannel actions from\nmulti-modal signals. The proposed model emphasizes the interrelation between\nmodalities and supports any combination of text, audio, and video inputs,\nmaking it adaptable to a variety of realistic scenarios. Our experiments show\nthat our approach achieves state-of-the-art performance on turn-taking and\nbackchannel prediction tasks, achieving a 10% increase in F1-score on\nturn-taking and a 33% increase on backchannel prediction. Our dataset and code\nare publicly available online to ease of subsequent research.",
    "pdf_url": "http://arxiv.org/pdf/2505.12654v2",
    "published": "2025-05-19T03:08:30+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12653v1",
    "title": "High-dimensional structure underlying individual differences in naturalistic visual experience",
    "authors": [
      "Chihye Han",
      "Michael F. Bonner"
    ],
    "abstract": "How do different brains create unique visual experiences from identical\nsensory input? While neural representations vary across individuals, the\nfundamental architecture underlying these differences remains poorly\nunderstood. Here, we reveal that individual visual experience emerges from a\nhigh-dimensional neural geometry across the visual cortical hierarchy. Using\nspectral decomposition of fMRI responses during naturalistic movie viewing, we\nfind that idiosyncratic neural patterns persist across multiple orders of\nmagnitude of latent dimensions. Remarkably, each dimensional range encodes\nqualitatively distinct aspects of individual processing, and this\nmultidimensional neural geometry predicts subsequent behavioral differences in\nmemory recall. These fine-grained patterns of inter-individual variability\ncannot be reduced to those detected by conventional intersubject correlation\nmeasures. Our findings demonstrate that subjective visual experience arises\nfrom information integrated across an expansive multidimensional manifold. This\ngeometric framework offers a powerful new lens for understanding how diverse\nbrains construct unique perceptual worlds from shared experiences.",
    "pdf_url": "http://arxiv.org/pdf/2505.12653v1",
    "published": "2025-05-19T03:07:59+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12652v1",
    "title": "Determination of Jupiter's Primordial Physical State",
    "authors": [
      "Konstantin Batygin",
      "Fred C. Adams"
    ],
    "abstract": "The formation and early evolution of Jupiter played a pivotal role in\nsculpting the large-scale architecture of the solar system, intertwining the\nnarrative of Jovian early years with the broader story of the solar system's\norigins. The details and chronology of Jupiter's formation, however, remain\nelusive, primarily due to the inherent uncertainties of accretionary models,\nhighlighting the need for independent constraints. Here we show that by\nanalyzing the dynamics of Jupiter's satellites concurrently with its angular\nmomentum budget, we can infer Jupiter's radius and interior state at the time\nof proto-solar nebula's dissipation. In particular, our calculations reveal\nthat Jupiter was $2$ to $2.5$ times as large as it is today, 3.8 million years\nafter the formation of the first solids in the solar system. Our model further\nindicates that young Jupiter possessed a magnetic field of approximately\n$B_{\\rm{J}}^{\\dagger} \\approx 21$ mT (a factor of $\\sim50$ higher than its\npresent-day value) and was accreting material through a circum-Jovian disk at a\nrate of $\\dot{M} = 1.2-2.4$ Jupiter masses per million years. Our findings are\nfully consistent with the core-accretion theory of giant planet formation and\nprovide an evolutionary snapshot that pins down properties of the Jovian system\nat the end of the protosolar nebula's lifetime.",
    "pdf_url": "http://arxiv.org/pdf/2505.12652v1",
    "published": "2025-05-19T03:06:56+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12651v1",
    "title": "$\\texttt{DIAMONDs}$: A Dataset for $\\mathbb{D}$ynamic $\\mathbb{I}$nformation $\\mathbb{A}$nd $\\mathbb{M}$ental modeling $\\mathbb{O}$f $\\mathbb{N}$umeric $\\mathbb{D}$iscussions",
    "authors": [
      "Sayontan Ghosh",
      "Mahnaz Koupaee",
      "Yash Kumar Lal",
      "Pegah Alipoormolabashi",
      "Mohammad Saqib Hasan",
      "Jun Seok Kang",
      "Niranjan Balasubramanian"
    ],
    "abstract": "Understanding multiparty conversations demands robust Theory of Mind (ToM)\ncapabilities, including the ability to track dynamic information, manage\nknowledge asymmetries, and distinguish relevant information across extended\nexchanges. To advance ToM evaluation in such settings, we present a carefully\ndesigned scalable methodology for generating high-quality benchmark\nconversation-question pairs with these characteristics. Using this methodology,\nwe create $\\texttt{DIAMONDs}$, a new conversational QA dataset covering common\nbusiness, financial or other group interactions. In these goal-oriented\nconversations, participants often have to track certain numerical quantities\n(say $\\textit{expected profit}$) of interest that can be derived from other\nvariable quantities (like $\\textit{marketing expenses, expected sales,\nsalary}$, etc.), whose values also change over the course of the conversation.\n$\\texttt{DIAMONDs}$ questions pose simple numerical reasoning problems over\nsuch quantities of interest (e.g., $\\textit{funds required for charity events,\nexpected company profit next quarter}$, etc.) in the context of the information\nexchanged in conversations. This allows for precisely evaluating ToM\ncapabilities for carefully tracking and reasoning over participants' knowledge\nstates.\n  Our evaluation of state-of-the-art language models reveals significant\nchallenges in handling participant-centric reasoning, specifically in\nsituations where participants have false beliefs. Models also struggle with\nconversations containing distractors and show limited ability to identify\nscenarios with insufficient information. These findings highlight current\nmodels' ToM limitations in handling real-world multi-party conversations.",
    "pdf_url": "http://arxiv.org/pdf/2505.12651v1",
    "published": "2025-05-19T03:05:13+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.12650v1",
    "title": "AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use",
    "authors": [
      "Yaotian Yang",
      "Yiwen Tang",
      "Yizhe Chen",
      "Xiao Chen",
      "Jiangjie Qiu",
      "Hao Xiong",
      "Haoyu Yin",
      "Zhiyao Luo",
      "Yifei Zhang",
      "Sijia Tao",
      "Wentao Li",
      "Qinghua Zhang",
      "Yuqiang Li",
      "Wanli Ouyang",
      "Bin Zhao",
      "Xiaonan Wang",
      "Fei Wei"
    ],
    "abstract": "Machine learning-based interatomic potentials and force fields depend\ncritically on accurate atomic structures, yet such data are scarce due to the\nlimited availability of experimentally resolved crystals. Although\natomic-resolution electron microscopy offers a potential source of structural\ndata, converting these images into simulation-ready formats remains\nlabor-intensive and error-prone, creating a bottleneck for model training and\nvalidation. We introduce AutoMat, an end-to-end, agent-assisted pipeline that\nautomatically transforms scanning transmission electron microscopy (STEM)\nimages into atomic crystal structures and predicts their physical properties.\nAutoMat combines pattern-adaptive denoising, physics-guided template retrieval,\nsymmetry-aware atomic reconstruction, fast relaxation and property prediction\nvia MatterSim, and coordinated orchestration across all stages. We propose the\nfirst dedicated STEM2Mat-Bench for this task and evaluate performance using\nlattice RMSD, formation energy MAE, and structure-matching success rate. By\norchestrating external tool calls, AutoMat enables a text-only LLM to\noutperform vision-language models in this domain, achieving closed-loop\nreasoning throughout the pipeline. In large-scale experiments over 450\nstructure samples, AutoMat substantially outperforms existing multimodal large\nlanguage models and tools. These results validate both AutoMat and\nSTEM2Mat-Bench, marking a key step toward bridging microscopy and atomistic\nsimulation in materials science.The code and dataset are publicly available at\nhttps://github.com/yyt-2378/AutoMat and\nhttps://huggingface.co/datasets/yaotianvector/STEM2Mat.",
    "pdf_url": "http://arxiv.org/pdf/2505.12650v1",
    "published": "2025-05-19T03:04:50+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.17067v5",
    "title": "Unveil Multi-Picture Descriptions for Multilingual Mild Cognitive Impairment Detection via Contrastive Learning",
    "authors": [
      "Kristin Qi",
      "Jiali Cheng",
      "Youxiang Zhu",
      "Hadi Amiri",
      "Xiaohui Liang"
    ],
    "abstract": "Detecting Mild Cognitive Impairment from picture descriptions is critical yet\nchallenging, especially in multilingual and multiple picture settings. Prior\nwork has primarily focused on English speakers describing a single picture\n(e.g., the 'Cookie Theft'). The TAUKDIAL-2024 challenge expands this scope by\nintroducing multilingual speakers and multiple pictures, which presents new\nchallenges in analyzing picture-dependent content. To address these challenges,\nwe propose a framework with three components: (1) enhancing discriminative\nrepresentation learning via supervised contrastive learning, (2) involving\nimage modality rather than relying solely on speech and text modalities, and\n(3) applying a Product of Experts (PoE) strategy to mitigate spurious\ncorrelations and overfitting. Our framework improves MCI detection performance,\nachieving a +7.1% increase in Unweighted Average Recall (UAR) (from 68.1% to\n75.2%) and a +2.9% increase in F1 score (from 80.6% to 83.5%) compared to the\ntext unimodal baseline. Notably, the contrastive learning component yields\ngreater gains for the text modality compared to speech. These results highlight\nour framework's effectiveness in multilingual and multi-picture MCI detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.17067v5",
    "published": "2025-05-19T03:03:08+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12649v1",
    "title": "The Robot of Theseus: A modular robotic testbed for legged locomotion",
    "authors": [
      "Karthik Urs",
      "Jessica Carlson",
      "Aditya Srinivas Manohar",
      "Michael Rakowiecki",
      "Abdulhadi Alkayyali",
      "John E. Saunders",
      "Faris Tulbah",
      "Talia Y. Moore"
    ],
    "abstract": "Robotic models are useful for independently varying specific features, but\nmost quadrupedal robots differ so greatly from animal morphologies that they\nhave minimal biomechanical relevance. Commercially available quadrupedal robots\nare also prohibitively expensive for biological research programs and difficult\nto customize. Here, we present a low-cost quadrupedal robot with modular legs\nthat can match a wide range of animal morphologies for biomechanical hypothesis\ntesting. The Robot Of Theseus (TROT) costs approximately $4000 to build out of\n3D printed parts and standard off-the-shelf supplies. Each limb consists of 2\nor 3 rigid links; the proximal joint can be rotated to become a knee or elbow.\nTelescoping mechanisms vary the length of each limb link. The open-source\nsoftware accommodates user-defined gaits and morphology changes. Effective leg\nlength, or crouch, is determined by the four-bar linkage actuating each joint.\nThe backdrivable motors can vary virtual spring stiffness and range of motion.\nFull descriptions of the TROT hardware and software are freely available\nonline. We demonstrate the use of TROT to compare locomotion among extant,\nextinct, and theoretical morphologies. In addition to biomechanical hypothesis\ntesting, we envision a variety of different applications for this low-cost,\nmodular, legged robotic platform, including developing novel control\nstrategies, clearing land mines, or remote exploration. All CAD and code is\navailable for download on the TROT project page.",
    "pdf_url": "http://arxiv.org/pdf/2505.12649v1",
    "published": "2025-05-19T03:01:54+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12648v1",
    "title": "SafeMove-RL: A Certifiable Reinforcement Learning Framework for Dynamic Motion Constraints in Trajectory Planning",
    "authors": [
      "Tengfei Liu",
      "Haoyang Zhong",
      "Jiazheng Hu",
      "Tan Zhang"
    ],
    "abstract": "This study presents a dynamic safety margin-based reinforcement learning\nframework for local motion planning in dynamic and uncertain environments. The\nproposed planner integrates real-time trajectory optimization with adaptive gap\nanalysis, enabling effective feasibility assessment under partial observability\nconstraints. To address safety-critical computations in unknown scenarios, an\nenhanced online learning mechanism is introduced, which dynamically corrects\nspatial trajectories by forming dynamic safety margins while maintaining\ncontrol invariance. Extensive evaluations, including ablation studies and\ncomparisons with state-of-the-art algorithms, demonstrate superior success\nrates and computational efficiency. The framework's effectiveness is further\nvalidated on both simulated and physical robotic platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.12648v1",
    "published": "2025-05-19T03:00:44+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12647v1",
    "title": "Spiking Neural Network: a low power solution for physical layer authentication",
    "authors": [
      "Jung Hoon Lee",
      "Sujith Vijayan"
    ],
    "abstract": "Deep learning (DL) is a powerful tool that can solve complex problems, and\nthus, it seems natural to assume that DL can be used to enhance the security of\nwireless communication. However, deploying DL models to edge devices in\nwireless networks is challenging, as they require significant amounts of\ncomputing and power resources. Notably, Spiking Neural Networks (SNNs) are\nknown to be efficient in terms of power consumption, meaning they can be an\nalternative platform for DL models for edge devices. In this study, we ask if\nSNNs can be used in physical layer authentication. Our evaluation suggests that\nSNNs can learn unique physical properties (i.e., `fingerprints') of RF\ntransmitters and use them to identify individual devices. Furthermore, we find\nthat SNNs are also vulnerable to adversarial attacks and that an autoencoder\ncan be used clean out adversarial perturbations to harden SNNs against them.",
    "pdf_url": "http://arxiv.org/pdf/2505.12647v1",
    "published": "2025-05-19T03:00:28+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12646v1",
    "title": "Implicit differentiation with second-order derivatives and benchmarks in finite-element-based differentiable physics",
    "authors": [
      "Tianju Xue"
    ],
    "abstract": "Differentiable programming is revolutionizing computational science by\nenabling automatic differentiation (AD) of numerical simulations. While\nfirst-order gradients are well-established, second-order derivatives (Hessians)\nfor implicit functions in finite-element-based differentiable physics remain\nunderexplored. This work bridges this gap by deriving and implementing a\nframework for implicit Hessian computation in PDE-constrained optimization\nproblems. We leverage primitive AD tools (Jacobian-vector\nproduct/vector-Jacobian product) to build an algorithm for Hessian-vector\nproducts and validate the accuracy against finite difference approximations.\nFour benchmarks spanning linear/nonlinear, 2D/3D, and single/coupled-variable\nproblems demonstrate the utility of second-order information. Results show that\nthe Newton-CG method with exact Hessians accelerates convergence for nonlinear\ninverse problems (e.g., traction force identification, shape optimization),\nwhile the L-BFGS-B method suffices for linear cases. Our work provides a robust\nfoundation for integrating second-order implicit differentiation into\ndifferentiable physics engines, enabling faster and more reliable optimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.12646v1",
    "published": "2025-05-19T02:59:26+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12645v1",
    "title": "An improved guess for the variational calculation of charge-transfer excitations in large systems",
    "authors": [
      "Nicola Bogo",
      "Zeyi Zhang",
      "Martin Head-Gordon",
      "Christopher J. Stein"
    ],
    "abstract": "Charge-transfer excited states are highly relevant for applications in\nmolecular electronics. However, the accurate calculation of these states in\nlarge systems is challenging since wave function methods are prohibitively\nexpensive, time-dependent density functional theory with typical functionals is\nnot precise, and the complicated topology of the electronic hypersurface makes\nthe variational convergence to the targeted excited states a difficult task. We\naddress the latter aspect by providing suitable initial guesses which we obtain\nby two separate constrained algorithms. Combined with subsequent\nsquared-gradient minimization schemes, we demonstrate that OO-DFT calculations\ncan reliably converge to the charge-transfer states of interest even for large\nmolecular systems. We test this approach on two chemically very different\nsupramolecular structures and also analyze the performance of two recently\nproposed methods for the tuning of the range-separation parameter in\ntime-dependent DFT with range-separated hybrid functionals. Our results\ndemonstrate that with the methods presented here, reliable convergence of\ncharge-transfer excited states can be achieved with variational excited-state\nDFT methods, while time-dependent DFT calculations with an adequate tuning\nprocedure for the range-separation parameter can provide a computationally\nefficient initial estimate of the corresponding energies.",
    "pdf_url": "http://arxiv.org/pdf/2505.12645v1",
    "published": "2025-05-19T02:58:53+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12644v1",
    "title": "Use as Many Surrogates as You Want: Selective Ensemble Attack to Unleash Transferability without Sacrificing Resource Efficiency",
    "authors": [
      "Bo Yang",
      "Hengwei Zhang",
      "Jindong Wang",
      "Yuchen Ren",
      "Chenhao Lin",
      "Chao Shen",
      "Zhengyu Zhao"
    ],
    "abstract": "In surrogate ensemble attacks, using more surrogate models yields higher\ntransferability but lower resource efficiency. This practical trade-off between\ntransferability and efficiency has largely limited existing attacks despite\nmany pre-trained models are easily accessible online. In this paper, we argue\nthat such a trade-off is caused by an unnecessary common assumption, i.e., all\nmodels should be identical across iterations. By lifting this assumption, we\ncan use as many surrogates as we want to unleash transferability without\nsacrificing efficiency. Concretely, we propose Selective Ensemble Attack (SEA),\nwhich dynamically selects diverse models (from easily accessible pre-trained\nmodels) across iterations based on our new interpretation of decoupling\nwithin-iteration and cross-iteration model diversity.In this way, the number of\nwithin-iteration models is fixed for maintaining efficiency, while only\ncross-iteration model diversity is increased for higher transferability.\nExperiments on ImageNet demonstrate the superiority of SEA in various\nscenarios. For example, when dynamically selecting 4 from 20 accessible models,\nSEA yields 8.5% higher transferability than existing attacks under the same\nefficiency. The superiority of SEA also generalizes to real-world systems, such\nas commercial vision APIs and large vision-language models. Overall, SEA opens\nup the possibility of adaptively balancing transferability and efficiency\naccording to specific resource requirements.",
    "pdf_url": "http://arxiv.org/pdf/2505.12644v1",
    "published": "2025-05-19T02:56:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12643v1",
    "title": "Thermodynamic analysis of diverse percolation transitions",
    "authors": [
      "Seonghyeon Moon",
      "Young Sul Cho"
    ],
    "abstract": "This work extends the thermodynamic analysis of random bond percolation to\nexplosive and hybrid percolation models. We show that this thermodynamic\nanalysis is well applicable to both explosive and hybrid percolation models by\nusing the critical exponents $\\alpha$ and $\\delta$ obtained from scaling\nrelations with previously measured values of $\\beta$ and $\\gamma$ within the\nerror range. As a result, Rushbrooke inequality holds as an equality, $\\alpha +\n2\\beta + \\gamma = 2$, in both explosive and hybrid percolation models, where\n$\\alpha > 0$ leads to the divergence of specific heats at the critical points.\nRemarkably, entropy clearly reveals a continuous decrease even in a\nfinite-sized explosive percolation model, unlike the order parameter. In\ncontrast, entropy decreases discontinuously during a discontinuous transition\nin a hybrid percolation model, resembling the heat outflow during discontinuous\ntransitions in thermal systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12643v1",
    "published": "2025-05-19T02:51:01+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.12642v1",
    "title": "Two out of Three (ToT): using self-consistency to make robust predictions",
    "authors": [
      "Jung Hoon Lee",
      "Sujith Vijayan"
    ],
    "abstract": "Deep learning (DL) can automatically construct intelligent agents, deep\nneural networks (alternatively, DL models), that can outperform humans in\ncertain tasks. However, the operating principles of DL remain poorly\nunderstood, making its decisions incomprehensible. As a result, it poses a\ngreat risk to deploy DL in high-stakes domains in which mistakes or errors may\nlead to critical consequences. Here, we aim to develop an algorithm that can\nhelp DL models make more robust decisions by allowing them to abstain from\nanswering when they are uncertain. Our algorithm, named `Two out of Three\n(ToT)', is inspired by the sensitivity of the human brain to conflicting\ninformation. ToT creates two alternative predictions in addition to the\noriginal model prediction and uses the alternative predictions to decide\nwhether it should provide an answer or not.",
    "pdf_url": "http://arxiv.org/pdf/2505.12642v1",
    "published": "2025-05-19T02:50:19+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12641v1",
    "title": "Single Image Reflection Removal via inter-layer Complementarity",
    "authors": [
      "Yue Huang",
      "Zi'ang Li",
      "Tianle Hu",
      "Jie Wen",
      "Guanbin Li",
      "Jinglin Zhang",
      "Guoxu Zhou",
      "Xiaozhao Fang"
    ],
    "abstract": "Although dual-stream architectures have achieved remarkable success in single\nimage reflection removal, they fail to fully exploit inter-layer\ncomplementarity in their physical modeling and network design, which limits the\nquality of image separation. To address this fundamental limitation, we propose\ntwo targeted improvements to enhance dual-stream architectures: First, we\nintroduce a novel inter-layer complementarity model where low-frequency\ncomponents extracted from the residual layer interact with the transmission\nlayer through dual-stream architecture to enhance inter-layer complementarity.\nMeanwhile, high-frequency components from the residual layer provide inverse\nmodulation to both streams, improving the detail quality of the transmission\nlayer. Second, we propose an efficient inter-layer complementarity attention\nmechanism which first cross-reorganizes dual streams at the channel level to\nobtain reorganized streams with inter-layer complementary structures, then\nperforms attention computation on the reorganized streams to achieve better\ninter-layer separation, and finally restores the original stream structure for\noutput. Experimental results demonstrate that our method achieves\nstate-of-the-art separation quality on multiple public datasets while\nsignificantly reducing both computational cost and model complexity.",
    "pdf_url": "http://arxiv.org/pdf/2505.12641v1",
    "published": "2025-05-19T02:50:15+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12640v2",
    "title": "GDPRShield: AI-Powered GDPR Support for Software Developers in Small and Medium-Sized Enterprises",
    "authors": [
      "Tharaka Wijesundara",
      "Mathew Warren",
      "Nalin Arachchilage"
    ],
    "abstract": "With the rapid increase in privacy violations in modern software development,\nregulatory frameworks such as the General Data Protection Regulation (GDPR)\nhave been established to enforce strict data protection practices. However,\ninsufficient privacy awareness among SME software developers contributes to\nfailure in GDPR compliance. For instance, a developer unfamiliar with data\nminimization may build a system that collects excessive data, violating GDPR\nand risking fines. One reason for this lack of awareness is that developers in\nSMEs often take on multidisciplinary roles (e.g., front-end, back-end, database\nmanagement, and privacy compliance), which limits specialization in privacy.\nThis lack of awareness may lead to poor privacy attitudes, ultimately hindering\nthe development of a strong organizational privacy culture. However, SMEs that\nachieve GDPR compliance may gain competitive advantages, such as increased user\ntrust and marketing value, compared to others that do not.\n  Therefore, in this paper, we introduce a novel AI-powered framework called\n\"GDPRShield,\" specifically designed to enhance the GDPR awareness of SME\nsoftware developers and, through this, improve their privacy attitudes.\nSimultaneously, GDPRShield boosts developers' motivation to comply with GDPR\nfrom the early stages of software development. It leverages functional\nrequirements written as user stories to provide comprehensive GDPR-based\nprivacy descriptions tailored to each requirement. Alongside improving\nawareness, GDPRShield strengthens motivation by presenting real-world\nconsequences of noncompliance, such as heavy fines, reputational damage, and\nloss of user trust, aligned with each requirement. This dual focus on awareness\nand motivation leads developers to engage with GDPRShield, improving their GDPR\ncompliance and privacy attitudes, which will help SMEs build a stronger privacy\nculture over time.",
    "pdf_url": "http://arxiv.org/pdf/2505.12640v2",
    "published": "2025-05-19T02:47:44+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12639v3",
    "title": "Emergence of the electronic states by quantum charge fluctuations in electron-doped high-$T_c$ cuprate superconductors",
    "authors": [
      "Hiroshi Yamaguchi",
      "Yudai Miyai",
      "Yuki. Tsubota",
      "Masashi Atira",
      "Hitoshi Sato",
      "Dongjoon Song",
      "Kiyoshia Tanakae",
      "Kenya Shimada",
      "Shin-ichiro Ideta"
    ],
    "abstract": "The origin of electron-boson interactions is a key to understanding the\nmechanism of high-$T_c$ superconductivity in cuprates. While interactions with\nphonons and magnetic fluctuations are widely considered to mediate electron\npairing in cuprates, the role of charge fluctuations, which is one of the\nfundamental degrees of freedom, remains unclear. Here, we performed\nangle-resolved photoemission spectroscopy (ARPES) and angle-resolved inverse\nphotoemission spectroscopy (AR-IPES) to investigate the electronic structure of\nthe occupied and unoccupied states, respectively, in the electron-doped\nhigh-$T_c$ cuprate superconductor Nd$_{2-x}$Ce$_x$CuO$_4$. We found emergent\nspectral features in both the occupied (ARPES) and unoccupied states (AR-IPES),\nwhich are likely induced by charge fluctuations. The present study paves the\nway for a deeper understanding of the relationship between quantum charge\nfluctuations and superconductivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.12639v3",
    "published": "2025-05-19T02:46:16+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.12638v2",
    "title": "ChromFound: Towards A Universal Foundation Model for Single-Cell Chromatin Accessibility Data",
    "authors": [
      "Yifeng Jiao",
      "Yuchen Liu",
      "Yu Zhang",
      "Xin Guo",
      "Yushuai Wu",
      "Chen Jiang",
      "Jiyang Li",
      "Hongwei Zhang",
      "Limei Han",
      "Xin Gao",
      "Yuan Qi",
      "Yuan Cheng"
    ],
    "abstract": "The advent of single-cell Assay for Transposase-Accessible Chromatin using\nsequencing (scATAC-seq) offers an innovative perspective for deciphering\nregulatory mechanisms by assembling a vast repository of single-cell chromatin\naccessibility data. While foundation models have achieved significant success\nin single-cell transcriptomics, there is currently no foundation model for\nscATAC-seq that supports zero-shot high-quality cell identification and\ncomprehensive multi-omics analysis simultaneously. Key challenges lie in the\nhigh dimensionality and sparsity of scATAC-seq data, as well as the lack of a\nstandardized schema for representing open chromatin regions (OCRs). Here, we\npresent ChromFound, a foundation model tailored for scATAC-seq. ChromFound\nutilizes a hybrid architecture and genome-aware tokenization to effectively\ncapture genome-wide long contexts and regulatory signals from dynamic chromatin\nlandscapes. Pretrained on 1.97 million cells from 30 tissues and 6 disease\nconditions, ChromFound demonstrates broad applicability across 6 diverse tasks.\nNotably, it achieves robust zero-shot performance in generating universal cell\nrepresentations and exhibits excellent transferability in cell type annotation\nand cross-omics prediction. By uncovering enhancer-gene links undetected by\nexisting computational methods, ChromFound offers a promising framework for\nunderstanding disease risk variants in the noncoding genome.",
    "pdf_url": "http://arxiv.org/pdf/2505.12638v2",
    "published": "2025-05-19T02:45:42+00:00",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.12637v1",
    "title": "Claus Michael Ringel's main contributions to Gorenstein-projective modules",
    "authors": [
      "Nan Gao",
      "Xue-Song Lu",
      "Pu Zhang"
    ],
    "abstract": "In this article we try to recall Claus Michael Ringel's works on the\nGorenstein-projective modules. This will involve but not limited to his\nfundamental contributions, such as in, the solution to the independence problem\nof totally reflexivity conditions; the technique of $\\mho$-quivers; a fast\nalgorithm to obtain the Gorenstein-projective modules over the Nakayama\nalgebras; the one to one correspondence between the indecomposable\nnon-projective perfect differential modules of a quiver and the indecomposable\nrepresentations of this quiver; the description of the module category of the\npreprojective algebras of type $\\mathbb A_n$ via submodule category;\nsemi-Gorenstein-projective modules, reflexive modules, Koszul modules, as well\nas the $\\Omega$-growth of modules, over short local algebras; and his negative\nanswer to the question whether an algebra has to be self-injective in case all\nthe simple modules are reflexive.",
    "pdf_url": "http://arxiv.org/pdf/2505.12637v1",
    "published": "2025-05-19T02:45:37+00:00",
    "categories": [
      "math.RT"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12636v1",
    "title": "Revealing the Deceptiveness of Knowledge Editing: A Mechanistic Analysis of Superficial Editing",
    "authors": [
      "Jiakuan Xie",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ],
    "abstract": "Knowledge editing, which aims to update the knowledge encoded in language\nmodels, can be deceptive. Despite the fact that many existing knowledge editing\nalgorithms achieve near-perfect performance on conventional metrics, the models\nedited by them are still prone to generating original knowledge. This paper\nintroduces the concept of \"superficial editing\" to describe this phenomenon.\nOur comprehensive evaluation reveals that this issue presents a significant\nchallenge to existing algorithms. Through systematic investigation, we identify\nand validate two key factors contributing to this issue: (1) the residual\nstream at the last subject position in earlier layers and (2) specific\nattention modules in later layers. Notably, certain attention heads in later\nlayers, along with specific left singular vectors in their output matrices,\nencapsulate the original knowledge and exhibit a causal relationship with\nsuperficial editing. Furthermore, we extend our analysis to the task of\nsuperficial unlearning, where we observe consistent patterns in the behavior of\nspecific attention heads and their corresponding left singular vectors, thereby\ndemonstrating the robustness and broader applicability of our methodology and\nconclusions. Our code is available here.",
    "pdf_url": "http://arxiv.org/pdf/2505.12636v1",
    "published": "2025-05-19T02:44:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12635v1",
    "title": "MVPainter: Accurate and Detailed 3D Texture Generation via Multi-View Diffusion with Geometric Control",
    "authors": [
      "Mingqi Shao",
      "Feng Xiong",
      "Zhaoxu Sun",
      "Mu Xu"
    ],
    "abstract": "Recently, significant advances have been made in 3D object generation.\nBuilding upon the generated geometry, current pipelines typically employ image\ndiffusion models to generate multi-view RGB images, followed by UV texture\nreconstruction through texture baking. While 3D geometry generation has\nimproved significantly, supported by multiple open-source frameworks, 3D\ntexture generation remains underexplored. In this work, we systematically\ninvestigate 3D texture generation through the lens of three core dimensions:\nreference-texture alignment, geometry-texture consistency, and local texture\nquality. To tackle these issues, we propose MVPainter, which employs data\nfiltering and augmentation strategies to enhance texture fidelity and detail,\nand introduces ControlNet-based geometric conditioning to improve\ntexture-geometry alignment. Furthermore, we extract physically-based rendering\n(PBR) attributes from the generated views to produce PBR meshes suitable for\nreal-world rendering applications. MVPainter achieves state-of-the-art results\nacross all three dimensions, as demonstrated by human-aligned evaluations. To\nfacilitate further research and reproducibility, we also release our full\npipeline as an open-source system, including data construction, model\narchitecture, and evaluation tools.",
    "pdf_url": "http://arxiv.org/pdf/2505.12635v1",
    "published": "2025-05-19T02:40:24+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12634v2",
    "title": "MSCEKF-MIO: Magnetic-Inertial Odometry Based on Multi-State Constraint Extended Kalman Filter",
    "authors": [
      "Jiazhu Li",
      "Jian Kuang",
      "Xiaoji Niu"
    ],
    "abstract": "To overcome the limitation of existing indoor odometry technologies which\noften cannot simultaneously meet requirements for accuracy cost-effectiveness,\nand robustness-this paper proposes a novel magnetometer array-aided inertial\nodometry approach, MSCEKF-MIO (Multi-State Constraint Extended Kalman\nFilter-based Magnetic-Inertial Odometry). We construct a magnetic field model\nby fitting measurements from the magnetometer array and then use temporal\nvariations in this model-extracted from continuous observations-to estimate the\ncarrier's absolute velocity. Furthermore, we implement the MSCEKF framework to\nfuse observed magnetic field variations with position and attitude estimates\nfrom inertial navigation system (INS) integration, thereby enabling autonomous,\nhigh-precision indoor relative positioning. Experimental results demonstrate\nthat the proposed algorithm achieves superior velocity estimation accuracy and\nhorizontal positioning precision relative to state-of-the-art magnetic\narray-aided INS algorithms (MAINS). On datasets with trajectory lengths of\n150-250m, the proposed method yields an average horizontal position RMSE of\napproximately 2.5m. In areas with distinctive magnetic features, the\nmagneto-inertial odometry achieves a velocity estimation accuracy of 0.07m/s.\nConsequently, the proposed method offers a novel positioning solution\ncharacterized by low power consumption, cost-effectiveness, and high\nreliability in complex indoor environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.12634v2",
    "published": "2025-05-19T02:39:18+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SP",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12633v2",
    "title": "Asymptotics for a class of planar orthogonal polynomials and truncated unitary matrices",
    "authors": [
      "Alfredo Dea√±o",
      "Kenneth T-R McLaughlin",
      "Leslie Molag",
      "Nick Simm"
    ],
    "abstract": "We carry out the asymptotic analysis as $n \\to \\infty$ of a class of\northogonal polynomials $p_{n}(z)$ of degree $n$, defined with respect to the\nplanar measure \\begin{equation*} d\\mu(z) =\n(1-|z|^{2})^{\\alpha-1}|z-x|^{\\gamma}\\mathbf{1}_{|z| < 1}d^{2}z, \\end{equation*}\nwhere $d^{2}z$ is the two dimensional area measure, $\\alpha$ is a parameter\nthat can grow with $n$, while $\\gamma>-2$ and $x>0$ are fixed. This measure\narises naturally in the study of characteristic polynomials of non-Hermitian\nensembles and generalises the example of a Gaussian weight that was recently\nstudied by several authors. We obtain asymptotics in all regions of the complex\nplane and via an appropriate differential identity, we obtain the asymptotic\nexpansion of the partition function. The main approach is to convert the planar\northogonality to one defined on suitable contours in the complex plane. Then\nthe asymptotic analysis is performed using the Deift-Zhou steepest descent\nmethod for the associated Riemann-Hilbert problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.12633v2",
    "published": "2025-05-19T02:39:17+00:00",
    "categories": [
      "math-ph",
      "math.CA",
      "math.CV",
      "math.MP",
      "math.PR",
      "33C45, 33E17, 60B20, 41A60"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12632v1",
    "title": "Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents",
    "authors": [
      "Yunseok Jang",
      "Yeda Song",
      "Sungryull Sohn",
      "Lajanugen Logeswaran",
      "Tiange Luo",
      "Dong-Ki Kim",
      "Kyunghoon Bae",
      "Honglak Lee"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have sparked significant interest in developing GUI visual\nagents. We introduce MONDAY (Mobile OS Navigation Task Dataset for Agents from\nYouTube), a large-scale dataset of 313K annotated frames from 20K instructional\nvideos capturing diverse real-world mobile OS navigation across multiple\nplatforms. Models that include MONDAY in their pre-training phases demonstrate\nrobust cross-platform generalization capabilities, consistently outperforming\nmodels trained on existing single OS datasets while achieving an average\nperformance gain of 18.11%p on an unseen mobile OS platform. To enable\ncontinuous dataset expansion as mobile platforms evolve, we present an\nautomated framework that leverages publicly available video content to create\ncomprehensive task datasets without manual annotation. Our framework comprises\nrobust OCR-based scene detection (95.04% F1score), near-perfect UI element\ndetection (99.87% hit ratio), and novel multi-step action identification to\nextract reliable action sequences across diverse interface configurations. We\ncontribute both the MONDAY dataset and our automated collection framework to\nfacilitate future research in mobile OS navigation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12632v1",
    "published": "2025-05-19T02:39:03+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12631v1",
    "title": "Multi-Resolution Haar Network: Enhancing human motion prediction via Haar transform",
    "authors": [
      "Li Lin"
    ],
    "abstract": "The 3D human pose is vital for modern computer vision and computer graphics,\nand its prediction has drawn attention in recent years. 3D human pose\nprediction aims at forecasting a human's future motion from the previous\nsequence. Ignoring that the arbitrariness of human motion sequences has a firm\norigin in transition in both temporal and spatial axes limits the performance\nof state-of-the-art methods, leading them to struggle with making precise\npredictions on complex cases, e.g., arbitrarily posing or greeting. To\nalleviate this problem, a network called HaarMoDic is proposed in this paper,\nwhich utilizes the 2D Haar transform to project joints to higher resolution\ncoordinates where the network can access spatial and temporal information\nsimultaneously. An ablation study proves that the significant contributing\nmodule within the HaarModic Network is the Multi-Resolution Haar (MR-Haar)\nblock. Instead of mining in one of two axes or extracting separately, the\nMR-Haar block projects whole motion sequences to a mixed-up coordinate in\nhigher resolution with 2D Haar Transform, allowing the network to give scope to\ninformation from both axes in different resolutions. With the MR-Haar block,\nthe HaarMoDic network can make predictions referring to a broader range of\ninformation. Experimental results demonstrate that HaarMoDic surpasses\nstate-of-the-art methods in every testing interval on the Human3.6M dataset in\nthe Mean Per Joint Position Error (MPJPE) metric.",
    "pdf_url": "http://arxiv.org/pdf/2505.12631v1",
    "published": "2025-05-19T02:38:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12630v1",
    "title": "Degradation-Aware Feature Perturbation for All-in-One Image Restoration",
    "authors": [
      "Xiangpeng Tian",
      "Xiangyu Liao",
      "Xiao Liu",
      "Meng Li",
      "Chao Ren"
    ],
    "abstract": "All-in-one image restoration aims to recover clear images from various\ndegradation types and levels with a unified model. Nonetheless, the significant\nvariations among degradation types present challenges for training a universal\nmodel, often resulting in task interference, where the gradient update\ndirections of different tasks may diverge due to shared parameters. To address\nthis issue, motivated by the routing strategy, we propose DFPIR, a novel\nall-in-one image restorer that introduces Degradation-aware Feature\nPerturbations(DFP) to adjust the feature space to align with the unified\nparameter space. In this paper, the feature perturbations primarily include\nchannel-wise perturbations and attention-wise perturbations. Specifically,\nchannel-wise perturbations are implemented by shuffling the channels in\nhigh-dimensional space guided by degradation types, while attention-wise\nperturbations are achieved through selective masking in the attention space. To\nachieve these goals, we propose a Degradation-Guided Perturbation Block (DGPB)\nto implement these two functions, positioned between the encoding and decoding\nstages of the encoder-decoder architecture. Extensive experimental results\ndemonstrate that DFPIR achieves state-of-the-art performance on several\nall-in-one image restoration tasks including image denoising, image dehazing,\nimage deraining, motion deblurring, and low-light image enhancement. Our codes\nare available at https://github.com/TxpHome/DFPIR.",
    "pdf_url": "http://arxiv.org/pdf/2505.12630v1",
    "published": "2025-05-19T02:37:11+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.5"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12629v1",
    "title": "Enhancing Latent Computation in Transformers with Latent Tokens",
    "authors": [
      "Yuchang Sun",
      "Yanxi Chen",
      "Yaliang Li",
      "Bolin Ding"
    ],
    "abstract": "Augmenting large language models (LLMs) with auxiliary tokens has emerged as\na promising strategy for enhancing model performance. In this work, we\nintroduce a lightweight method termed latent tokens; these are dummy tokens\nthat may be non-interpretable in natural language but steer the autoregressive\ndecoding process of a Transformer-based LLM via the attention mechanism. The\nproposed latent tokens can be seamlessly integrated with a pre-trained\nTransformer, trained in a parameter-efficient manner, and applied flexibly at\ninference time, while adding minimal complexity overhead to the existing\ninfrastructure of standard Transformers. We propose several hypotheses about\nthe underlying mechanisms of latent tokens and design synthetic tasks\naccordingly to verify them. Numerical results confirm that the proposed method\nnoticeably outperforms the baselines, particularly in the out-of-distribution\ngeneralization scenarios, highlighting its potential in improving the\nadaptability of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.12629v1",
    "published": "2025-05-19T02:35:53+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18188v2",
    "title": "Improving Generative Inverse Design of Rectangular Patch Antennas with Test Time Optimization",
    "authors": [
      "Beck LaBash",
      "Shahriar Khushrushahi",
      "Fabian Ruehle"
    ],
    "abstract": "We propose a two-stage deep learning framework for the inverse design of\nrectangular patch antennas. Our approach leverages generative modeling to learn\na latent representation of antenna frequency response curves and conditions a\nsubsequent generative model on these responses to produce feasible antenna\ngeometries. We further demonstrate that leveraging search and optimization\ntechniques at test-time improves the accuracy of the generated designs and\nenables consideration of auxiliary objectives such as manufacturability. Our\napproach generalizes naturally to different design criteria, and can be easily\nadapted to more complex geometric design spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.18188v2",
    "published": "2025-05-19T02:24:28+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12628v1",
    "title": "Dual-Agent Reinforcement Learning for Automated Feature Generation",
    "authors": [
      "Wanfu Gao",
      "Zengyao Man",
      "Hanlin Pan",
      "Kunpeng Liu"
    ],
    "abstract": "Feature generation involves creating new features from raw data to capture\ncomplex relationships among the original features, improving model robustness\nand machine learning performance. Current methods using reinforcement learning\nfor feature generation have made feature exploration more flexible and\nefficient. However, several challenges remain: first, during feature expansion,\na large number of redundant features are generated. When removing them, current\nmethods only retain the best features each round, neglecting those that perform\npoorly initially but could improve later. Second, the state representation used\nby current methods fails to fully capture complex feature relationships. Third,\nthere are significant differences between discrete and continuous features in\ntabular data, requiring different operations for each type. To address these\nchallenges, we propose a novel dual-agent reinforcement learning method for\nfeature generation. Two agents are designed: the first generates new features,\nand the second determines whether they should be preserved. A self-attention\nmechanism enhances state representation, and diverse operations distinguish\ninteractions between discrete and continuous features. The experimental results\non multiple datasets demonstrate that the proposed method is effective. The\ncode is available at https://github.com/extess0/DARL.",
    "pdf_url": "http://arxiv.org/pdf/2505.12628v1",
    "published": "2025-05-19T02:24:16+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12627v2",
    "title": "Efficient Heuristics Generation for Solving Combinatorial Optimization Problems Using Large Language Models",
    "authors": [
      "Xuan Wu",
      "Di Wang",
      "Chunguo Wu",
      "Lijie Wen",
      "Chunyan Miao",
      "Yubin Xiao",
      "You Zhou"
    ],
    "abstract": "Recent studies exploited Large Language Models (LLMs) to autonomously\ngenerate heuristics for solving Combinatorial Optimization Problems (COPs), by\nprompting LLMs to first provide search directions and then derive heuristics\naccordingly. However, the absence of task-specific knowledge in prompts often\nleads LLMs to provide unspecific search directions, obstructing the derivation\nof well-performing heuristics. Moreover, evaluating the derived heuristics\nremains resource-intensive, especially for those semantically equivalent ones,\noften requiring omissible resource expenditure. To enable LLMs to provide\nspecific search directions, we propose the Hercules algorithm, which leverages\nour designed Core Abstraction Prompting (CAP) method to abstract the core\ncomponents from elite heuristics and incorporate them as prior knowledge in\nprompts. We theoretically prove the effectiveness of CAP in reducing\nunspecificity and provide empirical results in this work. To reduce computing\nresources required for evaluating the derived heuristics, we propose few-shot\nPerformance Prediction Prompting (PPP), a first-of-its-kind method for the\nHeuristic Generation (HG) task. PPP leverages LLMs to predict the fitness\nvalues of newly derived heuristics by analyzing their semantic similarity to\npreviously evaluated ones. We further develop two tailored mechanisms for PPP\nto enhance predictive accuracy and determine unreliable predictions,\nrespectively. The use of PPP makes Hercules more resource-efficient and we name\nthis variant Hercules-P. Extensive experiments across four HG tasks, five COPs,\nand eight LLMs demonstrate that Hercules outperforms the state-of-the-art\nLLM-based HG algorithms, while Hercules-P excels at minimizing required\ncomputing resources. In addition, we illustrate the effectiveness of CAP, PPP,\nand the other proposed mechanisms by conducting relevant ablation studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.12627v2",
    "published": "2025-05-19T02:20:46+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12626v1",
    "title": "scSiameseClu: A Siamese Clustering Framework for Interpreting single-cell RNA Sequencing Data",
    "authors": [
      "Ping Xu",
      "Zhiyuan Ning",
      "Pengjiang Li",
      "Wenhao Liu",
      "Pengyang Wang",
      "Jiaxu Cui",
      "Yuanchun Zhou",
      "Pengfei Wang"
    ],
    "abstract": "Single-cell RNA sequencing (scRNA-seq) reveals cell heterogeneity, with cell\nclustering playing a key role in identifying cell types and marker genes.\nRecent advances, especially graph neural networks (GNNs)-based methods, have\nsignificantly improved clustering performance. However, the analysis of\nscRNA-seq data remains challenging due to noise, sparsity, and high\ndimensionality. Compounding these challenges, GNNs often suffer from\nover-smoothing, limiting their ability to capture complex biological\ninformation. In response, we propose scSiameseClu, a novel Siamese Clustering\nframework for interpreting single-cell RNA-seq data, comprising of 3 key steps:\n(1) Dual Augmentation Module, which applies biologically informed perturbations\nto the gene expression matrix and cell graph relationships to enhance\nrepresentation robustness; (2) Siamese Fusion Module, which combines\ncross-correlation refinement and adaptive information fusion to capture complex\ncellular relationships while mitigating over-smoothing; and (3) Optimal\nTransport Clustering, which utilizes Sinkhorn distance to efficiently align\ncluster assignments with predefined proportions while maintaining balance.\nComprehensive evaluations on seven real-world datasets demonstrate\nthat~\\methodname~outperforms state-of-the-art methods in single-cell\nclustering, cell type annotation, and cell type classification, providing a\npowerful tool for scRNA-seq data interpretation.",
    "pdf_url": "http://arxiv.org/pdf/2505.12626v1",
    "published": "2025-05-19T02:17:09+00:00",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.12625v1",
    "title": "R1dacted: Investigating Local Censorship in DeepSeek's R1 Language Model",
    "authors": [
      "Ali Naseh",
      "Harsh Chaudhari",
      "Jaechul Roh",
      "Mingshi Wu",
      "Alina Oprea",
      "Amir Houmansadr"
    ],
    "abstract": "DeepSeek recently released R1, a high-performing large language model (LLM)\noptimized for reasoning tasks. Despite its efficient training pipeline, R1\nachieves competitive performance, even surpassing leading reasoning models like\nOpenAI's o1 on several benchmarks. However, emerging reports suggest that R1\nrefuses to answer certain prompts related to politically sensitive topics in\nChina. While existing LLMs often implement safeguards to avoid generating\nharmful or offensive outputs, R1 represents a notable shift - exhibiting\ncensorship-like behavior on politically charged queries. In this paper, we\ninvestigate this phenomenon by first introducing a large-scale set of heavily\ncurated prompts that get censored by R1, covering a range of politically\nsensitive topics, but are not censored by other models. We then conduct a\ncomprehensive analysis of R1's censorship patterns, examining their\nconsistency, triggers, and variations across topics, prompt phrasing, and\ncontext. Beyond English-language queries, we explore censorship behavior in\nother languages. We also investigate the transferability of censorship to\nmodels distilled from the R1 language model. Finally, we propose techniques for\nbypassing or removing this censorship. Our findings reveal possible additional\ncensorship integration likely shaped by design choices during training or\nalignment, raising concerns about transparency, bias, and governance in\nlanguage model deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.12625v1",
    "published": "2025-05-19T02:16:56+00:00",
    "categories": [
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12624v1",
    "title": "EndoForce: Development of an Intuitive Axial Force Measurement Device for Endoscopic Robotic Systems",
    "authors": [
      "Hansoul Kim",
      "Dong-Ho Lee",
      "Dukyoo Kong",
      "Dong-Soo Kwon",
      "Byungsik Cheon"
    ],
    "abstract": "Robotic endoscopic systems provide intuitive control and eliminate radiation\nexposure, making them a promising alternative to conventional methods. However,\nthe lack of axial force measurement from the robot remains a major challenge,\nas it can lead to excessive colonic elongation, perforation, or ureteral\ncomplications. Although various methods have been proposed in previous studies,\nlimitations such as model dependency, bulkiness, and environmental sensitivity\nremain challenges that should be addressed before clinical application. In this\nstudy, we propose EndoForce, a device designed for intuitive and accurate axial\nforce measurement in endoscopic robotic systems. Inspired by the insertion\nmotion performed by medical doctors during ureteroscopy and gastrointestinal\n(GI) endoscopy, EndoForce ensures precise force measuring while maintaining\ncompatibility with clinical environments. The device features a streamlined\ndesign, allowing for the easy attachment and detachment of a sterile cover, and\nincorporates a commercial load cell to enhance cost-effectiveness and\nfacilitate practical implementation in real medical applications. To validate\nthe effectiveness of the proposed EndoForce, physical experiments were\nperformed using a testbed that simulates the ureter. We show that the axial\nforce generated during insertion was measured with high accuracy, regardless of\nwhether the pathway was straight or curved, in a testbed simulating the human\nureter.",
    "pdf_url": "http://arxiv.org/pdf/2505.12624v1",
    "published": "2025-05-19T02:15:14+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12623v1",
    "title": "Lightweight and Effective Preference Construction in PIBT for Large-Scale Multi-Agent Pathfinding",
    "authors": [
      "Keisuke Okumura",
      "Hiroki Nagai"
    ],
    "abstract": "PIBT is a computationally lightweight algorithm that can be applied to a\nvariety of multi-agent pathfinding (MAPF) problems, generating the next\ncollision-free locations of agents given another. Because of its simplicity and\nscalability, it is becoming a popular underlying scheme for recent large-scale\nMAPF methods involving several hundreds or thousands of agents. Vanilla PIBT\nmakes agents behave greedily towards their assigned goals, while agents\ntypically have multiple best actions, since the graph shortest path is not\nalways unique. Consequently, tiebreaking about how to choose between these\nactions significantly affects resulting solutions. This paper studies two\nsimple yet effective techniques for tiebreaking in PIBT, without compromising\nits computational advantage. The first technique allows an agent to\nintelligently dodge another, taking into account whether each action will\nhinder the progress of the next timestep. The second technique is to learn,\nthrough multiple PIBT runs, how an action causes regret in others and to use\nthis information to minimise regret collectively. Our empirical results\ndemonstrate that these techniques can reduce the solution cost of one-shot MAPF\nand improve the throughput of lifelong MAPF. For instance, in densely populated\none-shot cases, the combined use of these tiebreaks achieves improvements of\naround 10-20% in sum-of-costs, without significantly compromising the speed of\na PIBT-based planner.",
    "pdf_url": "http://arxiv.org/pdf/2505.12623v1",
    "published": "2025-05-19T02:12:29+00:00",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12622v1",
    "title": "Unconventional band splitting of CeSb in the devil's staircase transition",
    "authors": [
      "Tongrui Li",
      "Zhanfeng Liu",
      "Peng Li",
      "Yuzhe Wang",
      "Zhisheng Zhao",
      "Shiwu Su",
      "Zhicheng Jiang",
      "Yuhao Hong",
      "Hui Tian",
      "Xin Zheng",
      "Yi Liu",
      "Yilin Wang",
      "Zhengtai Liu",
      "Dawei Shen",
      "Zhe Sun",
      "Yang Liu",
      "Juan Jiang",
      "Donglai Feng"
    ],
    "abstract": "The interplay between magnetism and electronic band structure is a central\ntheme in condensed matter physics. CeSb, with its complex devil's staircase\nantiferromagnetic transition, offers a unique opportunity to explore this\ninterplay. Using angle-resolved photoemission spectroscopy (ARPES), we\ninvestigate the electronic structure evolution across the devil's staircase\ntransition. Upon entering the antiferromagnetic phase, we observe an intriguing\nband splitting of the electron pocket around the X point. The energy separation\nbetween the split bands changes abruptly with temperature, consistent with the\ncharacteristics of the first-order phase transition. However, their respective\nspectral weights behave gradually with temperature. Combined with our density\nfunctional theory (DFT) calculations, we suggest that this atypical behavior\ndeviates from conventional magnetically induced band splitting and potentially\narises from the intricate modulation of paramagnetic and antiferromagnetic\nlayers within the devil's staircase transition. Our results provide insights\ninto the complex relationship between electronic structure and magnetism in\ncorrelated electron systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12622v1",
    "published": "2025-05-19T02:12:07+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.13544v2",
    "title": "Multi-head Temporal Latent Attention",
    "authors": [
      "Keqi Deng",
      "Philip C. Woodland"
    ],
    "abstract": "While Transformer self-attention offers strong parallelism, the Key-Value\n(KV) cache grows linearly with sequence length and becomes a bottleneck for\ninference efficiency. Multi-head latent attention was recently developed to\ncompress the KV cache into a low-rank latent space. This paper proposes\nMulti-head Temporal Latent Attention (MTLA), which further reduces the KV cache\nsize along the temporal dimension, greatly lowering the memory footprint of\nself-attention inference. MTLA employs a hyper-network to dynamically merge\ntemporally adjacent KV cache vectors. To address the mismatch between the\ncompressed KV cache and processed sequence lengths, a stride-aware causal mask\nis proposed to ensure efficient parallel training and consistency with\ninference behaviour. Experiments across tasks, including speech translation,\nspeech recognition, speech understanding and text summarisation, demonstrate\nthat MTLA achieves competitive performance compared to standard Multi-Head\nAttention (MHA), while greatly improving inference speed and GPU memory usage.\nFor example, on a English-German speech translation task, MTLA achieves a 5.3x\nspeedup and a reduction in GPU memory usage by a factor of 8.3 compared to MHA,\nwhile maintaining translation quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.13544v2",
    "published": "2025-05-19T02:09:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12621v1",
    "title": "Think Before You Attribute: Improving the Performance of LLMs Attribution Systems",
    "authors": [
      "Jo√£o Eduardo Batista",
      "Emil Vatai",
      "Mohamed Wahib"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly applied in various science\ndomains, yet their broader adoption remains constrained by a critical\nchallenge: the lack of trustworthy, verifiable outputs. Current LLMs often\ngenerate answers without reliable source attribution, or worse, with incorrect\nattributions, posing a barrier to their use in scientific and high-stakes\nsettings, where traceability and accountability are non-negotiable. To be\nreliable, attribution systems need high accuracy and retrieve data with short\nlengths, i.e., attribute to a sentence within a document rather than a whole\ndocument. We propose a sentence-level pre-attribution step for\nRetrieve-Augmented Generation (RAG) systems that classify sentences into three\ncategories: not attributable, attributable to a single quote, and attributable\nto multiple quotes. By separating sentences before attribution, a proper\nattribution method can be selected for the type of sentence, or the attribution\ncan be skipped altogether. Our results indicate that classifiers are\nwell-suited for this task. In this work, we propose a pre-attribution step to\nreduce the computational complexity of attribution, provide a clean version of\nthe HAGRID dataset, and provide an end-to-end attribution system that works out\nof the box.",
    "pdf_url": "http://arxiv.org/pdf/2505.12621v1",
    "published": "2025-05-19T02:08:20+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12620v5",
    "title": "BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation",
    "authors": [
      "Haiquan Wen",
      "Yiwei He",
      "Zhenglin Huang",
      "Tianxiao Li",
      "Zihan Yu",
      "Xingru Huang",
      "Lu Qi",
      "Baoyuan Wu",
      "Xiangtai Li",
      "Guangliang Cheng"
    ],
    "abstract": "Advances in AI generative models facilitate super-realistic video synthesis,\namplifying misinformation risks via social media and eroding trust in digital\ncontent. Several research works have explored new deepfake detection methods on\nAI-generated images to alleviate these risks. However, with the fast\ndevelopment of video generation models, such as Sora and WanX, there is\ncurrently a lack of large-scale, high-quality AI-generated video datasets for\nforgery detection. In addition, existing detection approaches predominantly\ntreat the task as binary classification, lacking explainability in model\ndecision-making and failing to provide actionable insights or guidance for the\npublic. To address these challenges, we propose \\textbf{GenBuster-200K}, a\nlarge-scale AI-generated video dataset featuring 200K high-resolution video\nclips, diverse latest generative techniques, and real-world scenes. We further\nintroduce \\textbf{BusterX}, a novel AI-generated video detection and\nexplanation framework leveraging multimodal large language model (MLLM) and\nreinforcement learning for authenticity determination and explainable\nrationale. To our knowledge, GenBuster-200K is the {\\it \\textbf{first}}\nlarge-scale, high-quality AI-generated video dataset that incorporates the\nlatest generative techniques for real-world scenarios. BusterX is the {\\it\n\\textbf{first}} framework to integrate MLLM with reinforcement learning for\nexplainable AI-generated video detection. Extensive comparisons with\nstate-of-the-art methods and ablation studies validate the effectiveness and\ngeneralizability of BusterX. The code, models, and datasets will be released.",
    "pdf_url": "http://arxiv.org/pdf/2505.12620v5",
    "published": "2025-05-19T02:06:43+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12619v1",
    "title": "HIL: Hybrid Imitation Learning of Diverse Parkour Skills from Videos",
    "authors": [
      "Jiashun Wang",
      "Yifeng Jiang",
      "Haotian Zhang",
      "Chen Tessler",
      "Davis Rempe",
      "Jessica Hodgins",
      "Xue Bin Peng"
    ],
    "abstract": "Recent data-driven methods leveraging deep reinforcement learning have been\nan effective paradigm for developing controllers that enable physically\nsimulated characters to produce natural human-like behaviors. However, these\ndata-driven methods often struggle to adapt to novel environments and compose\ndiverse skills coherently to perform more complex tasks. To address these\nchallenges, we propose a hybrid imitation learning (HIL) framework that\ncombines motion tracking, for precise skill replication, with adversarial\nimitation learning, to enhance adaptability and skill composition. This hybrid\nlearning framework is implemented through parallel multi-task environments and\na unified observation space, featuring an agent-centric scene representation to\nfacilitate effective learning from the hybrid parallel environments. Our\nframework trains a unified controller on parkour data sourced from Internet\nvideos, enabling a simulated character to traverse through new environments\nusing diverse and life-like parkour skills. Evaluations across challenging\nparkour environments demonstrate that our method improves motion quality,\nincreases skill diversity, and achieves competitive task completion compared to\nprevious learning-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.12619v1",
    "published": "2025-05-19T02:04:54+00:00",
    "categories": [
      "cs.GR"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12618v1",
    "title": "Electric fields and waves in the Venus nightside magnetosphere",
    "authors": [
      "Forrest Mozer",
      "Oleksiy Agapitov",
      "Stuart Bale",
      "John Bonnell",
      "Marc Pulupa",
      "Tim Quinn",
      "Andrii Voschchepynets"
    ],
    "abstract": "On November 6, 2024, the Parker Solar Probe flew past Venus to make the first\naccurate electric field measurement in the nightside Venusian magnetosphere. To\nachieve this result, the electric field antennas were current biased in a way\nnever before experienced by an electric field detector. This biasing\nrequirement, that the positive bias current in the Venus shadow be about equal\nto the electron thermal current, is discussed and illustrated. About one minute\nof useful electric f ield data in the eight-minute nightside magnetosphere\ncrossing was obtained, during which the only feature observed was a few Hz\nsignal. This result, along with the magnetic field measurements, showed that\nthere were few if any electromagnetic waves, such as low-frequency\nelectromagnetic turbulence or whistlers, in the nightside crossing. Instead, a\nfew Hertz, purely electrostatic signal was found. This suggests that the\ninteraction of the solar wind with an unmagnetized body having an ionosphere\nmay be different from that of previously studied magnetized bodies. In the\nsunlit flanks, many electromagnetic wave modes were observed. These results\ndescribe the first step in the proper technique for future measurements of\nelectric fields in shadow.",
    "pdf_url": "http://arxiv.org/pdf/2505.12618v1",
    "published": "2025-05-19T02:03:40+00:00",
    "categories": [
      "physics.space-ph",
      "astro-ph.EP",
      "astro-ph.SR",
      "physics.plasm-ph"
    ],
    "primary_category": "physics.space-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12617v1",
    "title": "Double machine learning to estimate the effects of multiple treatments and their interactions",
    "authors": [
      "Qingyan Xiang",
      "Yubai Yuan",
      "Dongyuan Song",
      "Usman J. Wudil",
      "Muktar H. Aliyu",
      "C. William Wester",
      "Bryan E. Shepherd"
    ],
    "abstract": "Causal inference literature has extensively focused on binary treatments,\nwith relatively fewer methods developed for multi-valued treatments. In\nparticular, methods for multiple simultaneously assigned treatments remain\nunderstudied despite their practical importance. This paper introduces two\nsettings: (1) estimating the effects of multiple treatments of different types\n(binary, categorical, and continuous) and the effects of treatment\ninteractions, and (2) estimating the average treatment effect across categories\nof multi-valued regimens. To obtain robust estimates for both settings, we\npropose a class of methods based on the Double Machine Learning (DML)\nframework. Our methods are well-suited for complex settings of multiple\ntreatments/regimens, using machine learning to model confounding relationships\nwhile overcoming regularization and overfitting biases through Neyman\northogonality and cross-fitting. To our knowledge, this work is the first to\napply machine learning for robust estimation of interaction effects in the\npresence of multiple treatments. We further establish the asymptotic\ndistribution of our estimators and derive variance estimators for statistical\ninference. Extensive simulations demonstrate the performance of our methods.\nFinally, we apply the methods to study the effect of three treatments on\nHIV-associated kidney disease in an adult HIV cohort of 2455 participants in\nNigeria.",
    "pdf_url": "http://arxiv.org/pdf/2505.12617v1",
    "published": "2025-05-19T02:02:43+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.12616v1",
    "title": "Duluth at SemEval-2025 Task 7: TF-IDF with Optimized Vector Dimensions for Multilingual Fact-Checked Claim Retrieval",
    "authors": [
      "Shujauddin Syed",
      "Ted Pedersen"
    ],
    "abstract": "This paper presents the Duluth approach to the SemEval-2025 Task 7 on\nMultilingual and Crosslingual Fact-Checked Claim Retrieval. We implemented a\nTF-IDF-based retrieval system with experimentation on vector dimensions and\ntokenization strategies. Our best-performing configuration used word-level\ntokenization with a vocabulary size of 15,000 features, achieving an average\nsuccess@10 score of 0.78 on the development set and 0.69 on the test set across\nten languages. Our system showed stronger performance on higher-resource\nlanguages but still lagged significantly behind the top-ranked system, which\nachieved 0.96 average success@10. Our findings suggest that though advanced\nneural architectures are increasingly dominant in multilingual retrieval tasks,\nproperly optimized traditional methods like TF-IDF remain competitive\nbaselines, especially in limited compute resource scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.12616v1",
    "published": "2025-05-19T01:58:22+00:00",
    "categories": [
      "cs.CL",
      "68T50"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12615v1",
    "title": "Inverse nonlinear fast Fourier transform on SU(2) with applications to quantum signal processing",
    "authors": [
      "Hongkang Ni",
      "Rahul Sarkar",
      "Lexing Ying",
      "Lin Lin"
    ],
    "abstract": "The nonlinear Fourier transform (NLFT) extends the classical Fourier\ntransform by replacing addition with matrix multiplication. While the NLFT on\n$\\mathrm{SU}(1,1)$ has been widely studied, its $\\mathrm{SU}(2)$ variant has\nonly recently attracted attention due to emerging applications in quantum\nsignal processing (QSP) and quantum singular value transformation (QSVT). In\nthis paper, we investigate the inverse NLFT on $\\mathrm{SU}(2)$ and establish\nthe numerical stability of the layer stripping algorithm for the first time\nunder suitable conditions. Furthermore, we develop a fast and numerically\nstable algorithm, called inverse nonlinear fast Fourier transform, for\nperforming inverse NLFT with near-linear complexity. This algorithm is\napplicable to computing phase factors for both QSP and the generalized QSP\n(GQSP).",
    "pdf_url": "http://arxiv.org/pdf/2505.12615v1",
    "published": "2025-05-19T01:57:04+00:00",
    "categories": [
      "quant-ph",
      "cs.NA",
      "math.NA",
      "65T50, 68W40 (Primary) 65Y20, 68Q12, 81P68, 43A50 (Secondary)"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.12614v1",
    "title": "Adaptive Graph Unlearning",
    "authors": [
      "Pengfei Ding",
      "Yan Wang",
      "Guanfeng Liu",
      "Jiajie Zhu"
    ],
    "abstract": "Graph unlearning, which deletes graph elements such as nodes and edges from\ntrained graph neural networks (GNNs), is crucial for real-world applications\nwhere graph data may contain outdated, inaccurate, or privacy-sensitive\ninformation. However, existing methods often suffer from (1) incomplete or over\nunlearning due to neglecting the distinct objectives of different unlearning\ntasks, and (2) inaccurate identification of neighbors affected by deleted\nelements across various GNN architectures. To address these limitations, we\npropose AGU, a novel Adaptive Graph Unlearning framework that flexibly adapts\nto diverse unlearning tasks and GNN architectures. AGU ensures the complete\nforgetting of deleted elements while preserving the integrity of the remaining\ngraph. It also accurately identifies affected neighbors for each GNN\narchitecture and prioritizes important ones to enhance unlearning performance.\nExtensive experiments on seven real-world graphs demonstrate that AGU\noutperforms existing methods in terms of effectiveness, efficiency, and\nunlearning capability.",
    "pdf_url": "http://arxiv.org/pdf/2505.12614v1",
    "published": "2025-05-19T01:56:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12613v1",
    "title": "Towards Centralized Orchestration of Cyber Protection Condition (CPCON)",
    "authors": [
      "Mark Timmons",
      "Daniel Lukaszewski",
      "Geoffrey Xie",
      "Thomas Mayo",
      "Donald McCanless"
    ],
    "abstract": "The United States Cyber Command (USCYBERCOM) Cyber Protection Condition\n(CPCON) framework mandates graduated security postures across Department of\nDefense (DoD) networks, but current implementation remains largely manual,\ninconsistent, and error-prone. This paper presents a prototype system for\ncentralized orchestration of CPCON directives, enabling automated policy\nenforcement and real-time threat response across heterogeneous network\nenvironments. Building on prior work in host-based intrusion response, our\nsystem leverages a policy-driven orchestrator to standardize security actions,\nisolate compromised subnets, and verify enforcement status. We validate the\nsystem through emulated attack scenarios, demonstrating improved speed,\naccuracy, and verifiability in CPCON transitions with human-in-the-loop\noversight.",
    "pdf_url": "http://arxiv.org/pdf/2505.12613v1",
    "published": "2025-05-19T01:53:28+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12612v2",
    "title": "EPSpatial: Achieving Efficient and Private Statistical Analytics of Geospatial Data",
    "authors": [
      "Chuan Zhang",
      "Xuhao Ren",
      "Zhangcheng Huang",
      "Jinwen Liang",
      "Jianzong Wang",
      "Liehuang Zhu"
    ],
    "abstract": "Geospatial data statistics involve the aggregation and analysis of location\ndata to derive the distribution of clients within geospatial. The need for\nprivacy protection in geospatial data analysis has become paramount due to\nconcerns over the misuse or unauthorized access of client location information.\nHowever, existing private geospatial data statistics mainly rely on privacy\ncomputing techniques such as cryptographic tools and differential privacy,\nwhich leads to significant overhead and inaccurate results. In practical\napplications, geospatial data is frequently generated by mobile devices such as\nsmartphones and IoT sensors. The continuous mobility of clients and the need\nfor real-time updates introduce additional complexity. To address these issues,\nwe first design \\textit{spatially distributed point functions (SDPF)}, which\ncombines a quad-tree structure with distributed point functions, allowing\nclients to succinctly secret-share values on the nodes of an exponentially\nlarge quad-tree. Then, we use Gray code to partition the region and combine\nSDPF with it to propose $\\mathtt{EPSpatial}$, a scheme for accurate, efficient,\nand private statistical analytics of geospatial data. Moreover, considering\nclients' frequent movement requires continuous location updates, we leverage\nthe region encoding property to present an efficient update algorithm.Security\nanalysis shows that $\\mathtt{EPSpatial}$ effectively protects client location\nprivacy. Theoretical analysis and experimental results on real datasets\ndemonstrate that $\\mathtt{EPSpatial}$ reduces computational and communication\noverhead by at least $50\\%$ compared to existing statistical schemes.",
    "pdf_url": "http://arxiv.org/pdf/2505.12612v2",
    "published": "2025-05-19T01:51:30+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12611v1",
    "title": "Action-Dependent Optimality-Preserving Reward Shaping",
    "authors": [
      "Grant C. Forbes",
      "Jianxun Wang",
      "Leonardo Villalobos-Arias",
      "Arnav Jhala",
      "David L. Roberts"
    ],
    "abstract": "Recent RL research has utilized reward shaping--particularly complex shaping\nrewards such as intrinsic motivation (IM)--to encourage agent exploration in\nsparse-reward environments. While often effective, ``reward hacking'' can lead\nto the shaping reward being optimized at the expense of the extrinsic reward,\nresulting in a suboptimal policy. Potential-Based Reward Shaping (PBRS)\ntechniques such as Generalized Reward Matching (GRM) and Policy-Invariant\nExplicit Shaping (PIES) have mitigated this. These methods allow for\nimplementing IM without altering optimal policies. In this work we show that\nthey are effectively unsuitable for complex, exploration-heavy environments\nwith long-duration episodes. To remedy this, we introduce Action-Dependent\nOptimality Preserving Shaping (ADOPS), a method of converting intrinsic rewards\nto an optimality-preserving form that allows agents to utilize IM more\neffectively in the extremely sparse environment of Montezuma's Revenge. We also\nprove ADOPS accommodates reward shaping functions that cannot be written in a\npotential-based form: while PBRS-based methods require the cumulative\ndiscounted intrinsic return be independent of actions, ADOPS allows for\nintrinsic cumulative returns to be dependent on agents' actions while still\npreserving the optimal policy set. We show how action-dependence enables\nADOPS's to preserve optimality while learning in complex, sparse-reward\nenvironments where other methods struggle.",
    "pdf_url": "http://arxiv.org/pdf/2505.12611v1",
    "published": "2025-05-19T01:50:48+00:00",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12610v1",
    "title": "hChain: Blockchain Based Large Scale EHR Data Sharing with Enhanced Security and Privacy",
    "authors": [
      "Musharraf Alruwaill",
      "Saraju Mohanty",
      "Elias Kougianos"
    ],
    "abstract": "Concerns regarding privacy and data security in conventional healthcare\nprompted alternative technologies. In smart healthcare, blockchain technology\naddresses existing concerns with security, privacy, and electronic healthcare\ntransmission. Integration of Blockchain Technology with the Internet of Medical\nThings (IoMT) allows real-time monitoring of protected healthcare data.\nUtilizing edge devices with IoMT devices is very advantageous for addressing\nsecurity, computing, and storage challenges. Encryption using symmetric and\nasymmetric keys is used to conceal sensitive information from unauthorized\nparties. SHA256 is an algorithm for one-way hashing. It is used to verify that\nthe data has not been altered, since if it had, the hash value would have\nchanged. This article offers a blockchain-based smart healthcare system using\nIoMT devices for continuous patient monitoring. In addition, it employs edge\nresources in addition to IoMT devices to have extra computing power and storage\nto hash and encrypt incoming data before sending it to the blockchain.\nSymmetric key is utilized to keep the data private even in the blockchain,\nallowing the patient to safely communicate the data through smart contracts\nwhile preventing unauthorized physicians from seeing the data. Through the use\nof a verification node and blockchain, an asymmetric key is used for the\nsigning and validation of patient data in the healthcare provider system. In\naddition to other security measures, location-based authentication is\nrecommended to guarantee that data originates from the patient area. Through\nthe edge device, SHA256 is utilized to secure the data's integrity and a secret\nkey is used to maintain its secrecy. The hChain architecture improves the\ncomputing power of IoMT environments, the security of EHR sharing through smart\ncontracts, and the privacy and authentication procedures.",
    "pdf_url": "http://arxiv.org/pdf/2505.12610v1",
    "published": "2025-05-19T01:47:01+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12609v2",
    "title": "The Hamiltonian of Poly-matrix Zero-sum Games",
    "authors": [
      "Toshihiro Ota",
      "Yuma Fujimoto"
    ],
    "abstract": "Understanding a dynamical system fundamentally relies on establishing an\nappropriate Hamiltonian function and elucidating its symmetries. By formulating\nagents' strategies and cumulative payoffs as canonically conjugate variables,\nwe identify the Hamiltonian function that generates the dynamics of poly-matrix\nzero-sum games. We reveal the symmetries of our Hamiltonian and derive the\nassociated conserved quantities, showing how the conservation of probability\nand the invariance of the Fenchel coupling are intrinsically encoded within the\nsystem. Furthermore, we propose the dissipation FTRL (DFTRL) dynamics by\nintroducing a perturbation that dissipates the Fenchel coupling, proving\nconvergence to the Nash equilibrium and linking DFTRL to last-iterate\nconvergent algorithms. Our results highlight the potential of Hamiltonian\ndynamics in uncovering the structural properties of learning dynamics in games,\nand pave the way for broader applications of Hamiltonian dynamics in game\ntheory and machine learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.12609v2",
    "published": "2025-05-19T01:46:29+00:00",
    "categories": [
      "cs.GT",
      "cs.LG",
      "cs.MA",
      "nlin.CD"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.12608v2",
    "title": "Quantum Modeling of Spatial Contiguity Constraints",
    "authors": [
      "Yunhan Chang",
      "Amr Magdy",
      "Federico M. Spedalieri"
    ],
    "abstract": "Quantum computing has demonstrated potential for solving complex optimization\nproblems; however, its application to spatial regionalization remains\nunderexplored. Spatial contiguity, a fundamental constraint requiring spatial\nentities to form connected components, significantly increases the complexity\nof regionalization problems, which are typically challenging for quantum\nmodeling. This paper proposes novel quantum formulations based on a flow model\nthat enforces spatial contiguity constraints. Our scale-aware approach employs\na Discrete Quadratic Model (DQM), solvable directly on quantum annealing\nhardware for small-scale datasets. In addition, it designs a hybrid\nquantum-classical approach to manage larger-scale problems within existing\nhardware limitations. This work establishes a foundational framework for\nintegrating quantum methods into practical spatial optimization tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12608v2",
    "published": "2025-05-19T01:44:23+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12607v1",
    "title": "Seismic analysis based on a new interval method with incomplete information",
    "authors": [
      "Shizhong Liang",
      "Yuxiang Yang",
      "Chen Li",
      "Feng Wu"
    ],
    "abstract": "For seismic analysis in engineering structures, it is essential to consider\nthe dynamic responses under seismic excitation, necessitating the description\nof seismic accelerations. Limit seismics samples lead to incomplete uncertainty\ninformation, which is described by the non-probabilistic method reasonable.\nThis study employs the minimum interval radius-based interval process (MRIP)\nbased on the convex model to describe the time-variant uncertain seismic\nacceleration, subsequently conducting uncertainty analysis for seismic\nstructures. However, the Monte Carlo simulation for uncertainty analysis\nrequires extensive deterministic computations to ensure accuracy, exhibiting\npoor computational efficiency. To address this issue, this paper first improves\nthe covariance matrix adaptation evolution strategy (CMA-ES) through the\ndynamic evolution sequence, proposing DES-ES, whose efficiency is validated to\nbe higher than that of CMA-ES. Furthermore, leveraging the dependency of the\nresponses, a computational framework named DES-ES-SS is proposed. Numerical\nexperiments demonstrate that DES-ES-SS improves computational efficiency while\nmaintaining the accuracy of the interval uncertainty analysis of the seismic\nstructures whether the seismic acceleration is stationary or non-stationary.",
    "pdf_url": "http://arxiv.org/pdf/2505.12607v1",
    "published": "2025-05-19T01:42:19+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.12606v1",
    "title": "Diff-MM: Exploring Pre-trained Text-to-Image Generation Model for Unified Multi-modal Object Tracking",
    "authors": [
      "Shiyu Xuan",
      "Zechao Li",
      "Jinhui Tang"
    ],
    "abstract": "Multi-modal object tracking integrates auxiliary modalities such as depth,\nthermal infrared, event flow, and language to provide additional information\nbeyond RGB images, showing great potential in improving tracking stabilization\nin complex scenarios. Existing methods typically start from an RGB-based\ntracker and learn to understand auxiliary modalities only from training data.\nConstrained by the limited multi-modal training data, the performance of these\nmethods is unsatisfactory. To alleviate this limitation, this work proposes a\nunified multi-modal tracker Diff-MM by exploiting the multi-modal understanding\ncapability of the pre-trained text-to-image generation model. Diff-MM leverages\nthe UNet of pre-trained Stable Diffusion as a tracking feature extractor\nthrough the proposed parallel feature extraction pipeline, which enables\npairwise image inputs for object tracking. We further introduce a multi-modal\nsub-module tuning method that learns to gain complementary information between\ndifferent modalities. By harnessing the extensive prior knowledge in the\ngeneration model, we achieve a unified tracker with uniform parameters for\nRGB-N/D/T/E tracking. Experimental results demonstrate the promising\nperformance of our method compared with recently proposed trackers, e.g., its\nAUC outperforms OneTracker by 8.3% on TNL2K.",
    "pdf_url": "http://arxiv.org/pdf/2505.12606v1",
    "published": "2025-05-19T01:42:13+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12605v1",
    "title": "Temporal-Oriented Recipe for Transferring Large Vision-Language Model to Video Understanding",
    "authors": [
      "Thong Nguyen",
      "Zhiyuan Hu",
      "Xu Lin",
      "Cong-Duy Nguyen",
      "See-Kiong Ng",
      "Luu Anh Tuan"
    ],
    "abstract": "Recent years have witnessed outstanding advances of large vision-language\nmodels (LVLMs). In order to tackle video understanding, most of them depend\nupon their implicit temporal understanding capacity. As such, they have not\ndeciphered important components that contribute to temporal understanding\nability, which might limit the potential of these LVLMs for video\nunderstanding. In this work, we conduct a thorough empirical study to demystify\ncrucial components that influence the temporal understanding of LVLMs. Our\nempirical study reveals that significant impacts are centered around the\nintermediate interface between the visual encoder and the large language model.\nBuilding on these insights, we propose a temporal-oriented recipe that\nencompasses temporal-oriented training schemes and an upscaled interface. Our\nfinal model developed using our recipe significantly enhances previous LVLMs on\nstandard video understanding tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.12605v1",
    "published": "2025-05-19T01:40:25+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12604v3",
    "title": "Isolated singularities of solutions of certain quasi-linear elliptic inequalities",
    "authors": [
      "Shiguang Ma",
      "Shengyang Zang"
    ],
    "abstract": "We provide a complete classification of the asymptotic behavior of isolated\nsingularities for solutions satisfying \\[ 0\\le-\\Delta_{p}u(x)\\le \\tau\nu^{\\frac{n(p-1)}{n-p}} (x),\\,\\,u(x)\\ge0,\\,\\,1<p<n,\\,\\,n\\ge2, \\]where $u(x)\\in\nC^2(B(0,1)\\backslash\\{0\\})$ and $B(0,1)\\subset \\mathbb R^n$.",
    "pdf_url": "http://arxiv.org/pdf/2505.12604v3",
    "published": "2025-05-19T01:36:40+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.13543v2",
    "title": "Origin-Destination Pattern Effects on Large-Scale Mixed Traffic Control via Multi-Agent Reinforcement Learning",
    "authors": [
      "Muyang Fan",
      "Songyang Liu",
      "Shuai Li",
      "Weizi Li"
    ],
    "abstract": "Traffic congestion remains a major challenge for modern urban transportation,\ndiminishing both efficiency and quality of life. While autonomous driving\ntechnologies and reinforcement learning (RL) have shown promise for improving\ntraffic control, most prior work has focused on small-scale networks or\nisolated intersections. Large-scale mixed traffic control, involving both\nhuman-driven and robotic vehicles, remains underexplored. In this study, we\npropose a decentralized multi-agent reinforcement learning framework for\nmanaging large-scale mixed traffic networks, where intersections are controlled\neither by traditional traffic signals or by robotic vehicles. We evaluate our\napproach on a real-world network of 14 intersections in Colorado Springs,\nColorado, USA, using average vehicle waiting time as the primary measure of\ntraffic efficiency. We are exploring a problem that has not been sufficiently\naddressed: Is large-scale Multi-Agent Traffic Control (MTC) still feasible when\nfacing time-varying Origin-Destination (OD) patterns?",
    "pdf_url": "http://arxiv.org/pdf/2505.13543v2",
    "published": "2025-05-19T01:36:05+00:00",
    "categories": [
      "cs.MA",
      "cs.CY"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12603v1",
    "title": "Superconductivity and phase diagram in Sr-doped La$_{3-x}$Sr$_{x}$Ni$_2$O$_7$ thin films",
    "authors": [
      "Bo Hao",
      "Maosen Wang",
      "Wenjie Sun",
      "Yang Yang",
      "Zhangwen Mao",
      "Shengjun Yan",
      "Haoying Sun",
      "Hongyi Zhang",
      "Lu Han",
      "Zhengbin Gu",
      "Jian Zhou",
      "Dianxiang Ji",
      "Yuefeng Nie"
    ],
    "abstract": "Recent studies have demonstrated ambient pressure superconductivity in\ncompressively strained La$_{3}$Ni$_{2}$O$_{7}$ thin films, yet the phase\ndiagram of heterovalent doping$-$critical for advancing the field$-$remains\nunexplored. Here, we report superconductivity in Sr$^{2+}$-doped\nLa$_{3-x}$Sr$_{x}$Ni$_2$O$_7$ films synthesized via molecular beam epitaxy with\nozone-assisted post-annealing. The superconducting transition temperature\n($T_{\\mathrm{c}}$) follows an asymmetric dome-like profile, persisting across a\nwide doping range ($0 \\leq x \\leq 0.21$) before diminishing at $x \\approx\n0.38$. Optimally doped films ($x = 0.09$) achieve $T_{\\mathrm{c}}$ of $\\sim$ 42\nK, with high critical current ($J_{\\mathrm{c}} > 1.4$ $\\mathrm{kA/cm^{2}}$ at 2\nK) and upper critical fields ($\\mu_{0}H_{\\mathrm{c,\\parallel}}(0)= 83.7$\n$\\mathrm{T}$, $\\mu_{0}H_{\\mathrm{c,\\perp}}(0)= 110.3$ $\\mathrm{T}$), comparable\nto reported La$_{3-x}$Pr$_{x}$Ni$_2$O$_7$ films. Scanning transmission electron\nmicroscopy reveals oxygen vacancies predominantly occupy at planar NiO$_{2}$\nsites$-$unlike apical-site vacancies in bulk samples$-$due to Coulomb repulsion\ndestabilizing planar oxygen under compressive strain. Additionally, the\nelongated out-of-plane Ni-O bonds, exceeding those in pressurized bulk samples\nby $4\\%$, likely weaken the interlayer $d_{z^2}$ coupling, thus contributing to\nthe reduced $T_{\\mathrm{c}}$ in strained films. This work establishes\nheterovalent Sr$^{2+}$ doping as a robust tuning parameter for nickelate\nsuperconductivity, unveiling a unique phase diagram topology.",
    "pdf_url": "http://arxiv.org/pdf/2505.12603v1",
    "published": "2025-05-19T01:35:18+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.12602v1",
    "title": "Critical points of the Moser-Trudinger functional on conical singular surfaces, I: compactness",
    "authors": [
      "Zhijie Chen",
      "Houwang Li"
    ],
    "abstract": "Let $(\\Sigma, g_1)$ be a compact Riemann surface with conical singularites of\nangles in $(0, 2\\pi)$, and $f: \\Sigma\\to\\mathbb R$ be a positive smooth\nfunction. In this paper, by establishing a sharp quantization result, we prove\nthe compactness of the set of positive critical points for the Moser-Trudinger\nfunctional\n  \\[F_1(u)=\\int_{\\Sigma}(e^{u^2}-1)f dv_{g_1}\\] constrained to $u\\in\\mathcal\nE_\\beta:=\\{u\\in H^1(\\Sigma,g_1) : \\|u\\|_{H^1(\\Sigma,g_1)}^2=\\beta\\}$ for any\n$\\beta>0$. This result is a generalization of the compactness result for the\nMoser-Trudinger functional on regular compact surfaces, proved by De\nMarchis-Malchiodi-Martinazzi-Thizy (Inventiones Mathematicae, 2022, 230:\n1165-1248). The presence of conical singularities brings many additional\ndifficulties and we need to develop different ideas and techniques. The\ncompactness lays the foundation for proving the existence of critical points of\nthe Moser-Trudinger functional on conical singular surfaces in a sequel work.",
    "pdf_url": "http://arxiv.org/pdf/2505.12602v1",
    "published": "2025-05-19T01:34:51+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12601v1",
    "title": "Rethinking Predictive Modeling for LLM Routing: When Simple kNN Beats Complex Learned Routers",
    "authors": [
      "Yang Li"
    ],
    "abstract": "As large language models (LLMs) grow in scale and specialization,\nrouting--selecting the best model for a given input--has become essential for\nefficient and effective deployment. While recent methods rely on complex\nlearned routing strategies, their dependence on disparate training data and\nevaluation setups makes comparison and generalization difficult. In this work,\nwe revisit LLM routing through the lens of simplicity. We show that a\nwell-tuned k-Nearest Neighbors (kNN) approach not only matches but often\noutperforms state-of-the-art learned routers across diverse tasks. To support\nsystematic evaluation, we introduce a suite of standardized routing benchmarks\nspanning instruction-following, question-answering, and reasoning tasks, as\nwell as the first multi-modal routing dataset involving visual inputs. Our\nfindings reveal that the locality properties of model performance in embedding\nspace enable simple non-parametric methods to achieve strong routing decisions\nwith lower sample complexity than parametric approaches. This challenges the\nprevailing trend toward sophisticated architectures and highlights the\nimportance of thoroughly evaluating simple baselines before investing in\ncomplex solutions. To support reproducibility and further exploration, we will\nrelease all benchmarks and code upon publication.",
    "pdf_url": "http://arxiv.org/pdf/2505.12601v1",
    "published": "2025-05-19T01:33:41+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12600v1",
    "title": "Fast and Simple Densest Subgraph with Predictions",
    "authors": [
      "Thai Bui",
      "Hoa T. Vu"
    ],
    "abstract": "We study the densest subgraph problem and its variants through the lens of\nlearning-augmented algorithms. For this problem, the greedy algorithm by\nCharikar (APPROX 2000) provides a linear-time $ 1/2 $-approximation, while\ncomputing the exact solution typically requires solving a linear program or\nperforming maximum flow computations.We show that given a partial solution,\ni.e., one produced by a machine learning classifier that captures at least a $\n(1 - \\epsilon) $-fraction of nodes in the optimal subgraph, it is possible to\ndesign an extremely simple linear-time algorithm that achieves a provable $ (1\n- \\epsilon) $-approximation. Our approach also naturally extends to the\ndirected densest subgraph problem and several NP-hard variants.An experiment on\nthe Twitch Ego Nets dataset shows that our learning-augmented algorithm\noutperforms Charikar's greedy algorithm and a baseline that directly returns\nthe predicted densest subgraph without additional algorithmic processing.",
    "pdf_url": "http://arxiv.org/pdf/2505.12600v1",
    "published": "2025-05-19T01:32:03+00:00",
    "categories": [
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.12599v1",
    "title": "Accelerated Markov Chain Monte Carlo Algorithms on Discrete States",
    "authors": [
      "Bohan Zhou",
      "Shu Liu",
      "Xinzhe Zuo",
      "Wuchen Li"
    ],
    "abstract": "We propose a class of discrete state sampling algorithms based on Nesterov's\naccelerated gradient method, which extends the classical Metropolis-Hastings\n(MH) algorithm. The evolution of the discrete states probability distribution\ngoverned by MH can be interpreted as a gradient descent direction of the\nKullback--Leibler (KL) divergence, via a mobility function and a score\nfunction. Specifically, this gradient is defined on a probability simplex\nequipped with a discrete Wasserstein-2 metric with a mobility function. This\nmotivates us to study a momentum-based acceleration framework using damped\nHamiltonian flows on the simplex set, whose stationary distribution matches the\ndiscrete target distribution. Furthermore, we design an interacting particle\nsystem to approximate the proposed accelerated sampling dynamics. The extension\nof the algorithm with a general choice of potentials and mobilities is also\ndiscussed. In particular, we choose the accelerated gradient flow of the\nrelative Fisher information, demonstrating the advantages of the algorithm in\nestimating discrete score functions without requiring the normalizing constant\nand keeping positive probabilities. Numerical examples, including sampling on a\nGaussian mixture supported on lattices or a distribution on a hypercube,\ndemonstrate the effectiveness of the proposed discrete-state sampling\nalgorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.12599v1",
    "published": "2025-05-19T01:29:49+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "stat.CO",
      "65C05, 60J22, 82M31, 49Q22, 65K10"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.12598v1",
    "title": "Weak solutions to the parabolic $p$-Laplace equation in a moving domain under a Neumann type boundary condition",
    "authors": [
      "Tatsu-Hiko Miura"
    ],
    "abstract": "This paper studies the parabolic $p$-Laplace equation with $p>2$ in a moving\ndomain under a Neumann type boundary condition corresponding to the total mass\nconservation. We establish the existence and uniqueness of a weak solution by\nthe Galerkin method in evolving Bochner spaces and a monotonicity argument. The\nmain difficulty is in characterizing the weak limit of the nonlinear gradient\nterm, where we need to deal with a term which comes from the boundary condition\nand cannot be absorbed into a monotone operator. To overcome this difficulty,\nwe prove a uniform-in-time Friedrichs type inequality on a moving domain with\ntime-dependent basis functions and make use of it to get the strong convergence\nof approximate solutions. We also show that the time derivative exists in the\n$L^2$ sense when given data have a better regularity.",
    "pdf_url": "http://arxiv.org/pdf/2505.12598v1",
    "published": "2025-05-19T01:29:37+00:00",
    "categories": [
      "math.AP",
      "35K20, 35K92, 35R37"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.12597v1",
    "title": "Chain-Talker: Chain Understanding and Rendering for Empathetic Conversational Speech Synthesis",
    "authors": [
      "Yifan Hu",
      "Rui Liu",
      "Yi Ren",
      "Xiang Yin",
      "Haizhou Li"
    ],
    "abstract": "Conversational Speech Synthesis (CSS) aims to align synthesized speech with\nthe emotional and stylistic context of user-agent interactions to achieve\nempathy. Current generative CSS models face interpretability limitations due to\ninsufficient emotional perception and redundant discrete speech coding. To\naddress the above issues, we present Chain-Talker, a three-stage framework\nmimicking human cognition: Emotion Understanding derives context-aware emotion\ndescriptors from dialogue history; Semantic Understanding generates compact\nsemantic codes via serialized prediction; and Empathetic Rendering synthesizes\nexpressive speech by integrating both components. To support emotion modeling,\nwe develop CSS-EmCap, an LLM-driven automated pipeline for generating precise\nconversational speech emotion captions. Experiments on three benchmark datasets\ndemonstrate that Chain-Talker produces more expressive and empathetic speech\nthan existing methods, with CSS-EmCap contributing to reliable emotion\nmodeling. The code and demos are available at:\nhttps://github.com/AI-S2-Lab/Chain-Talker.",
    "pdf_url": "http://arxiv.org/pdf/2505.12597v1",
    "published": "2025-05-19T01:24:52+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.12596v1",
    "title": "Heterodimensional cycles derived from homoclinic tangencies via Hopf bifurcations",
    "authors": [
      "Shuntaro Tomizawa"
    ],
    "abstract": "We analyze three-dimensional $C^{r}$ diffeomorphisms ($r\\ge 5$) exhibiting a\nquadratic focus-saddle homoclinic tangency whose multipliers satisfy\n$|\\lambda\\gamma| = 1$. For a proper three-parameter unfolding that splits the\ntangency, varies the argument of the stable multipliers, and controls the\nmodulus $|\\lambda\\gamma|$, we show that a Hopf bifurcation occurs on this curve\nand that a homoclinic point to the bifurcating periodic orbit is present. As a\nconsequence, the original map $f$ can be $C^{r}$-approximated by a\ndiffeomorphism exhibiting a coindex-one heterodimensional cycle in the saddle\ncase.",
    "pdf_url": "http://arxiv.org/pdf/2505.12596v1",
    "published": "2025-05-19T01:19:46+00:00",
    "categories": [
      "math.DS",
      "37G25, 37C29, 37G15, 37D30, 37C20"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.12595v1",
    "title": "Driven Critical Dynamics in Tricitical Point",
    "authors": [
      "Ting-Long Wang",
      "Yi-Fan Jiang",
      "Shuai Yin"
    ],
    "abstract": "The conventional Kibble-Zurek (KZ) mechanism, describing driven dynamics\nacross critical points based on the adiabatic-impulse scenario (AIS), have\nattracted broad attentions. However, the driven dynamics in tricritical point\nwith two independent relevant directions has not been adequately studied. Here,\nwe employ time dependent variational principle to study the driven critical\ndynamics at a one-dimensional supersymmetric Ising tricritical point. For the\nrelevant direction along the Ising critical line, the AIS apparently breaks\ndown. Nevertheless, we find that the critical dynamics can still be described\nby the KZ scaling in which the driving rate has the dimension of\n$r=z+1/\\nu_\\mu$ with $z$ and $\\nu_\\mu$ being the dynamic exponent and\ncorrelation length exponent in this direction, respectively. For driven\ndynamics along other direction, the driving rate has the dimension\n$r=z+1/\\nu_p$ with $\\nu_p$ being the other correlation length exponent. Our\nwork brings new fundamental perspective into the nonequilibrium critical\ndynamics near the tricritical point, which could be realized in programmable\nquantum processors in Rydberg atomic systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.12595v1",
    "published": "2025-05-19T01:17:24+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.quant-gas",
      "cond-mat.str-el",
      "quant-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.12594v1",
    "title": "AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection",
    "authors": [
      "Tiankai Yang",
      "Junjun Liu",
      "Wingchun Siu",
      "Jiahang Wang",
      "Zhuangzhuang Qian",
      "Chanjuan Song",
      "Cheng Cheng",
      "Xiyang Hu",
      "Yue Zhao"
    ],
    "abstract": "Anomaly detection (AD) is essential in areas such as fraud detection, network\nmonitoring, and scientific research. However, the diversity of data modalities\nand the increasing number of specialized AD libraries pose challenges for\nnon-expert users who lack in-depth library-specific knowledge and advanced\nprogramming skills. To tackle this, we present AD-AGENT, an LLM-driven\nmulti-agent framework that turns natural-language instructions into fully\nexecutable AD pipelines. AD-AGENT coordinates specialized agents for intent\nparsing, data preparation, library and model selection, documentation mining,\nand iterative code generation and debugging. Using a shared short-term\nworkspace and a long-term cache, the agents integrate popular AD libraries like\nPyOD, PyGOD, and TSLib into a unified workflow. Experiments demonstrate that\nAD-AGENT produces reliable scripts and recommends competitive models across\nlibraries. The system is open-sourced to support further research and practical\napplications in AD.",
    "pdf_url": "http://arxiv.org/pdf/2505.12594v1",
    "published": "2025-05-19T01:14:57+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12593v2",
    "title": "Learning Cross-Spectral Point Features with Task-Oriented Training",
    "authors": [
      "Mia Thomas",
      "Trevor Ablett",
      "Jonathan Kelly"
    ],
    "abstract": "Unmanned aerial vehicles (UAVs) enable operations in remote and hazardous\nenvironments, yet the visible-spectrum, camera-based navigation systems often\nrelied upon by UAVs struggle in low-visibility conditions. Thermal cameras,\nwhich capture long-wave infrared radiation, are able to function effectively in\ndarkness and smoke, where visible-light cameras fail. This work explores\nlearned cross-spectral (thermal-visible) point features as a means to integrate\nthermal imagery into established camera-based navigation systems. Existing\nmethods typically train a feature network's detection and description outputs\ndirectly, which often focuses training on image regions where thermal and\nvisible-spectrum images exhibit similar appearance. Aiming to more fully\nutilize the available data, we propose a method to train the feature network on\nthe tasks of matching and registration. We run our feature network on\nthermal-visible image pairs, then feed the network response into a\ndifferentiable registration pipeline. Losses are applied to the matching and\nregistration estimates of this pipeline. Our selected model, trained on the\ntask of matching, achieves a registration error (corner error) below 10 pixels\nfor more than 75% of estimates on the MultiPoint dataset. We further\ndemonstrate that our model can also be used with a classical pipeline for\nmatching and registration.",
    "pdf_url": "http://arxiv.org/pdf/2505.12593v2",
    "published": "2025-05-19T01:09:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12592v1",
    "title": "PromptPrism: A Linguistically-Inspired Taxonomy for Prompts",
    "authors": [
      "Sullam Jeoung",
      "Yueyan Chen",
      "Yi Zhang",
      "Shuai Wang",
      "Haibo Ding",
      "Lin Lee Cheong"
    ],
    "abstract": "Prompts are the interface for eliciting the capabilities of large language\nmodels (LLMs). Understanding their structure and components is critical for\nanalyzing LLM behavior and optimizing performance. However, the field lacks a\ncomprehensive framework for systematic prompt analysis and understanding. We\nintroduce PromptPrism, a linguistically-inspired taxonomy that enables prompt\nanalysis across three hierarchical levels: functional structure, semantic\ncomponent, and syntactic pattern. We show the practical utility of PromptPrism\nby applying it to three applications: (1) a taxonomy-guided prompt refinement\napproach that automatically improves prompt quality and enhances model\nperformance across a range of tasks; (2) a multi-dimensional dataset profiling\nmethod that extracts and aggregates structural, semantic, and syntactic\ncharacteristics from prompt datasets, enabling comprehensive analysis of prompt\ndistributions and patterns; (3) a controlled experimental framework for prompt\nsensitivity analysis by quantifying the impact of semantic reordering and\ndelimiter modifications on LLM performance. Our experimental results validate\nthe effectiveness of our taxonomy across these applications, demonstrating that\nPromptPrism provides a foundation for refining, profiling, and analyzing\nprompts.",
    "pdf_url": "http://arxiv.org/pdf/2505.12592v1",
    "published": "2025-05-19T01:08:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12591v1",
    "title": "First Light And Reionization Epoch Simulations (FLARES) -- XIX: Supermassive black hole mergers in the early Universe and their environmental dependence",
    "authors": [
      "Shihong Liao",
      "Dimitrios Irodotou",
      "Maxwell G. A. Maltz",
      "Christopher C. Lovell",
      "Zhen Jiang",
      "Sophie L. Newman",
      "Aswin P. Vijayan",
      "Paurush Punyasheel",
      "William J. Roper",
      "Louise T. C. Seeyave",
      "Sonja Soininen",
      "Peter A. Thomas",
      "Stephen M. Wilkins"
    ],
    "abstract": "The upcoming space-based gravitational wave (GW) observatory, LISA, is\nexpected to detect GW signals from supermassive black hole (SMBH) mergers\noccurring at high redshifts. However, understanding the origin and growth of\nSMBHs in the early Universe remains an open problem in astrophysics. In this\nwork, we utilize the First Light And Reionization Epoch Simulations (FLARES), a\nsuite of cosmological hydrodynamical zoom-in simulations, to study SMBH mergers\nat $5 \\lesssim z \\lesssim 10$ across a wide range of environments. Most mergers\nin FLARES involve secondary SMBHs near the seed mass ($m_{seed} \\approx 1.5\n\\times 10^{5} M_{\\odot}$) while primary SMBHs span up to $10^{9} M_{\\odot}$,\nresulting in mass ratios from $q \\sim 10^{-4}$ to $1$, with a peak at $q \\sim\n1$. The number of mergers increases rapidly towards lower redshifts, and the\ncomoving total number density scales with overdensity as $n_{merger} =\n10^{-3.80} (1 + \\delta)^{4.56}$. Denser regions host more massive mergers, with\nhigher merger redshifts and lower mass ratios. Within the FLARES redshift\nrange, LISA is expected to detect mergers with $10^{5} \\lesssim M_{tot} /\nM_{\\odot} \\lesssim 10^{8}$ and $q \\gtrsim 10^{-2}$, corresponding to a\ndetection rate of 0.030 $yr^{-1}$ for events with signal-to-noise ratio $SNR\n\\geq 10$. Our study demonstrates the sensitivity of GW predictions at high\nredshifts to SMBH seed models and merger time delays, highlighting the need for\nimproved modeling in future cosmological simulations to maximize LISA's\nscientific return.",
    "pdf_url": "http://arxiv.org/pdf/2505.12591v1",
    "published": "2025-05-19T01:06:45+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.12590v1",
    "title": "Vortex Mass in Superfluid Fermi Gases along the BEC--BCS Crossover",
    "authors": [
      "Lucas Levrouw",
      "Hiromitsu Takeuchi",
      "Jacques Tempere"
    ],
    "abstract": "Vortex mass is a key concept in the study of superfluid dynamics, referring\nto the inertia of vortices in a superfluid, which affects their motion and\nbehavior. Despite being an important quantity, the vortex mass has never been\nobserved experimentally, and remains an unresolved issue in this field. As of\nnow, a large body of research assumes that the vortex mass is a local\nparameter. In contrast, we present a calculation that suggests a logarithmic\ndependence on the system size, agreeing with some earlier predictions in the\ncontext of Bose gases. We analyze the problem using an effective field theory\nthat describes ultracold atomic Fermi gases over the BEC--BCS crossover at both\nzero and nonzero temperatures. Our study reveals a strong dependence of the\nvortex mass on the scattering length; in particular, the vortex mass grows\nrapidly when moving towards the BCS side. Furthermore, we find that the\nsystem-size dependence of the vortex mass results in values an order of\nmagnitude larger than those predicted by other models for realistic system\nsizes. This implies that the vortex mass could be observable in a wider\nparameter range than was previously expected. This is particularly relevant\nconsidering recent advances in experimental techniques that place the\nobservation of vortex mass in superfluid Fermi gases within reach.",
    "pdf_url": "http://arxiv.org/pdf/2505.12590v1",
    "published": "2025-05-19T00:57:17+00:00",
    "categories": [
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.12589v1",
    "title": "SurveillanceVQA-589K: A Benchmark for Comprehensive Surveillance Video-Language Understanding with Large Models",
    "authors": [
      "Bo Liu",
      "Pengfei Qiao",
      "Minhan Ma",
      "Xuange Zhang",
      "Yinan Tang",
      "Peng Xu",
      "Kun Liu",
      "Tongtong Yuan"
    ],
    "abstract": "Understanding surveillance video content remains a critical yet underexplored\nchallenge in vision-language research, particularly due to its real-world\ncomplexity, irregular event dynamics, and safety-critical implications. In this\nwork, we introduce SurveillanceVQA-589K, the largest open-ended video question\nanswering benchmark tailored to the surveillance domain. The dataset comprises\n589,380 QA pairs spanning 12 cognitively diverse question types, including\ntemporal reasoning, causal inference, spatial understanding, and anomaly\ninterpretation, across both normal and abnormal video scenarios. To construct\nthe benchmark at scale, we design a hybrid annotation pipeline that combines\ntemporally aligned human-written captions with Large Vision-Language\nModel-assisted QA generation using prompt-based techniques. We also propose a\nmulti-dimensional evaluation protocol to assess contextual, temporal, and\ncausal comprehension. We evaluate eight LVLMs under this framework, revealing\nsignificant performance gaps, especially in causal and anomaly-related tasks,\nunderscoring the limitations of current models in real-world surveillance\ncontexts. Our benchmark provides a practical and comprehensive resource for\nadvancing video-language understanding in safety-critical applications such as\nintelligent monitoring, incident analysis, and autonomous decision-making.",
    "pdf_url": "http://arxiv.org/pdf/2505.12589v1",
    "published": "2025-05-19T00:57:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12588v1",
    "title": "Event-based Star Tracking under Spacecraft Jitter: the e-STURT Dataset",
    "authors": [
      "Samya Bagchi",
      "Peter Anastasiou",
      "Matthew Tetlow",
      "Tat-Jun Chin",
      "Yasir Latif"
    ],
    "abstract": "Jitter degrades a spacecraft's fine-pointing ability required for optical\ncommunication, earth observation, and space domain awareness. Development of\njitter estimation and compensation algorithms requires high-fidelity sensor\nobservations representative of on-board jitter. In this work, we present the\nEvent-based Star Tracking Under Jitter (e-STURT) dataset -- the first event\ncamera based dataset of star observations under controlled jitter conditions.\nSpecialized hardware employed for the dataset emulates an event-camera\nundergoing on-board jitter. While the event camera provides asynchronous, high\ntemporal resolution star observations, systematic and repeatable jitter is\nintroduced using a micrometer accurate piezoelectric actuator. Various jitter\nsources are simulated using distinct frequency bands and utilizing both axes of\nmotion. Ground-truth jitter is captured in hardware from the piezoelectric\nactuator. The resulting dataset consists of 200 sequences and is made publicly\navailable. This work highlights the dataset generation process, technical\nchallenges and the resulting limitations. To serve as a baseline, we propose a\nhigh-frequency jitter estimation algorithm that operates directly on the event\nstream. The e-STURT dataset will enable the development of jitter aware\nalgorithms for mission critical event-based space sensing applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.12588v1",
    "published": "2025-05-19T00:55:40+00:00",
    "categories": [
      "cs.CV",
      "eess.SP"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12587v1",
    "title": "CMLFormer: A Dual Decoder Transformer with Switching Point Learning for Code-Mixed Language Modeling",
    "authors": [
      "Aditeya Baral",
      "Allen George Ajith",
      "Roshan Nayak",
      "Mrityunjay Abhijeet Bhanja"
    ],
    "abstract": "Code-mixed languages, characterized by frequent within-sentence language\ntransitions, present structural challenges that standard language models fail\nto address. In this work, we propose CMLFormer, an enhanced multi-layer\ndual-decoder Transformer with a shared encoder and synchronized decoder\ncross-attention, designed to model the linguistic and semantic dynamics of\ncode-mixed text. CMLFormer is pre-trained on an augmented Hinglish corpus with\nswitching point and translation annotations with multiple new objectives\nspecifically aimed at capturing switching behavior, cross-lingual structure,\nand code-mixing complexity. Our experiments show that CMLFormer improves F1\nscore, precision, and accuracy over other approaches on the HASOC-2021\nbenchmark under select pre-training setups. Attention analyses further show\nthat it can identify and attend to switching points, validating its sensitivity\nto code-mixed structure. These results demonstrate the effectiveness of\nCMLFormer's architecture and multi-task pre-training strategy for modeling\ncode-mixed languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.12587v1",
    "published": "2025-05-19T00:50:49+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12586v4",
    "title": "A Few Large Shifts: Layer-Inconsistency Based Minimal Overhead Adversarial Example Detection",
    "authors": [
      "Sanggeon Yun",
      "Ryozo Masukawa",
      "Hyunwoo Oh",
      "Nathaniel D. Bastian",
      "Mohsen Imani"
    ],
    "abstract": "Deep neural networks (DNNs) are highly susceptible to adversarial\nexamples--subtle, imperceptible perturbations that can lead to incorrect\npredictions. While detection-based defenses offer a practical alternative to\nadversarial training, many existing methods depend on external models, complex\narchitectures, heavy augmentations, or adversarial data, limiting their\nefficiency and generalizability. We introduce a lightweight, plug-in detection\nframework that leverages internal layer-wise inconsistencies within the target\nmodel itself, requiring only benign data for calibration. Our approach is\ngrounded in the A Few Large Shifts Assumption, which posits that adversarial\nperturbations typically induce large representation shifts in a small subset of\nlayers. Building on this, we propose two complementary strategies--Recovery\nTesting (RT) and Logit-layer Testing (LT)--to expose internal disruptions\ncaused by adversaries. Evaluated on CIFAR-10, CIFAR-100, and ImageNet under\nboth standard and adaptive threat models, our method achieves state-of-the-art\ndetection performance with negligible computational overhead and no compromise\nto clean accuracy. The code is available here:\nhttps://github.com/c0510gy/AFLS-AED.",
    "pdf_url": "http://arxiv.org/pdf/2505.12586v4",
    "published": "2025-05-19T00:48:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12585v1",
    "title": "Learning Robust Spectral Dynamics for Temporal Domain Generalization",
    "authors": [
      "En Yu",
      "Jie Lu",
      "Xiaoyu Yang",
      "Guangquan Zhang",
      "Zhen Fang"
    ],
    "abstract": "Modern machine learning models struggle to maintain performance in dynamic\nenvironments where temporal distribution shifts, \\emph{i.e., concept drift},\nare prevalent. Temporal Domain Generalization (TDG) seeks to enable model\ngeneralization across evolving domains, yet existing approaches typically\nassume smooth incremental changes, struggling with complex real-world drifts\ninvolving long-term structure (incremental evolution/periodicity) and local\nuncertainties. To overcome these limitations, we introduce FreKoo, which\ntackles these challenges via a novel frequency-domain analysis of parameter\ntrajectories. It leverages the Fourier transform to disentangle parameter\nevolution into distinct spectral bands. Specifically, low-frequency component\nwith dominant dynamics are learned and extrapolated using the Koopman operator,\nrobustly capturing diverse drift patterns including both incremental and\nperiodicity. Simultaneously, potentially disruptive high-frequency variations\nare smoothed via targeted temporal regularization, preventing overfitting to\ntransient noise and domain uncertainties. In addition, this dual spectral\nstrategy is rigorously grounded through theoretical analysis, providing\nstability guarantees for the Koopman prediction, a principled Bayesian\njustification for the high-frequency regularization, and culminating in a\nmultiscale generalization bound connecting spectral dynamics to improved\ngeneralization. Extensive experiments demonstrate FreKoo's significant\nsuperiority over SOTA TDG approaches, particularly excelling in real-world\nstreaming scenarios with complex drifts and uncertainties.",
    "pdf_url": "http://arxiv.org/pdf/2505.12585v1",
    "published": "2025-05-19T00:38:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13542v1",
    "title": "GANCompress: GAN-Enhanced Neural Image Compression with Binary Spherical Quantization",
    "authors": [
      "Karthik Sivakoti"
    ],
    "abstract": "The exponential growth of visual data in digital communications has\nintensified the need for efficient compression techniques that balance\nrate-distortion performance with computational feasibility. While recent neural\ncompression approaches have shown promise, they still struggle with fundamental\nchallenges: preserving perceptual quality at high compression ratios,\ncomputational efficiency, and adaptability to diverse visual content. This\npaper introduces GANCompress, a novel neural compression framework that\nsynergistically combines Binary Spherical Quantization (BSQ) with Generative\nAdversarial Networks (GANs) to address these challenges. Our approach employs a\ntransformer-based autoencoder with an enhanced BSQ bottleneck that projects\nlatent representations onto a hypersphere, enabling efficient discretization\nwith bounded quantization error. This is followed by a specialized GAN\narchitecture incorporating frequency-domain attention and color consistency\noptimization. Experimental results demonstrate that GANCompress achieves\nsubstantial improvement in compression efficiency -- reducing file sizes by up\nto 100x with minimal visual distortion. Our method outperforms traditional\ncodecs like H.264 by 12-15% in perceptual metrics while maintaining comparable\nPSNR/SSIM values, with 2.4x faster encoding and decoding speeds. On standard\nbenchmarks including ImageNet-1k and COCO2017, GANCompress sets a new\nstate-of-the-art, reducing FID from 0.72 to 0.41 (43% improvement) compared to\nprevious methods while maintaining higher throughput. This work presents a\nsignificant advancement in neural compression technology with promising\napplications for real-time visual communication systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.13542v1",
    "published": "2025-05-19T00:18:27+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.12584v2",
    "title": "Improving Multilingual Language Models by Aligning Representations through Steering",
    "authors": [
      "Omar Mahmoud",
      "Buddhika Laknath Semage",
      "Thommen George Karimpanal",
      "Santu Rana"
    ],
    "abstract": "This paper investigates how Large Language Models (LLMs) represent\nnon-English tokens -- a question that remains underexplored despite recent\nprogress. We propose a lightweight intervention method using representation\nsteering, where a learned vector is added to the residual stream at a single\nmodel layer to enhance multilingual performance. Through extensive experiments\nacross seven competitive baselines -- including prompt optimization, supervised\nfine-tuning (SFT), in-context learning, cross-lingual transfer, and\ntranslation-based methods-we show that our approach consistently outperforms\nmost alternatives. In particular, it achieves performance on par with\nproduction-grade translation systems while requiring far fewer resources. We\nfurther explore the complementarity between our method and SFT, demonstrating\nthat steering offers a direct, efficient way to realign internal\nrepresentations. These findings underscore the potential of activation-level\ninterventions as a powerful tool for improving the multilingual capabilities of\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.12584v2",
    "published": "2025-05-19T00:14:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.12583v2",
    "title": "A Comprehensive Survey on Physical Risk Control in the Era of Foundation Model-enabled Robotics",
    "authors": [
      "Takeshi Kojima",
      "Yaonan Zhu",
      "Yusuke Iwasawa",
      "Toshinori Kitamura",
      "Gang Yan",
      "Shu Morikuni",
      "Ryosuke Takanami",
      "Alfredo Solano",
      "Tatsuya Matsushima",
      "Akiko Murakami",
      "Yutaka Matsuo"
    ],
    "abstract": "Recent Foundation Model-enabled robotics (FMRs) display greatly improved\ngeneral-purpose skills, enabling more adaptable automation than conventional\nrobotics. Their ability to handle diverse tasks thus creates new opportunities\nto replace human labor. However, unlike general foundation models, FMRs\ninteract with the physical world, where their actions directly affect the\nsafety of humans and surrounding objects, requiring careful deployment and\ncontrol. Based on this proposition, our survey comprehensively summarizes robot\ncontrol approaches to mitigate physical risks by covering all the lifespan of\nFMRs ranging from pre-deployment to post-accident stage. Specifically, we\nbroadly divide the timeline into the following three phases: (1) pre-deployment\nphase, (2) pre-incident phase, and (3) post-incident phase. Throughout this\nsurvey, we find that there is much room to study (i) pre-incident risk\nmitigation strategies, (ii) research that assumes physical interaction with\nhumans, and (iii) essential issues of foundation models themselves. We hope\nthat this survey will be a milestone in providing a high-resolution analysis of\nthe physical risks of FMRs and their control, contributing to the realization\nof a good human-robot relationship.",
    "pdf_url": "http://arxiv.org/pdf/2505.12583v2",
    "published": "2025-05-19T00:11:42+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.12582v2",
    "title": "Compile-Time Fully Homomorphic Encryption of Vectors: Eliminating Online Encryption via Algebraic Basis Synthesis",
    "authors": [
      "Dongfang Zhao"
    ],
    "abstract": "We propose a framework for compile-time ciphertext synthesis in fully\nhomomorphic encryption (FHE) systems, where ciphertexts are constructed from\nprecomputed encrypted basis vectors combined with a runtime-scaled encryption\nof zero. This design eliminates online encryption and instead relies solely on\nciphertext-level additions and scalar multiplications, enabling efficient data\ningestion and algebraic reuse. We formalize the method as a randomized\n$\\mathbb{Z}_t$-module morphism and prove that it satisfies IND-CPA security\nunder standard assumptions. The proof uses a hybrid game reduction, showing\nthat adversarial advantage in distinguishing synthesized ciphertexts is\nnegligible if the underlying FHE scheme is IND-CPA secure. Unlike prior designs\nthat require a pool of random encryptions of zero, our construction achieves\nequivalent security using a single zero ciphertext multiplied by a fresh scalar\nat runtime, reducing memory overhead while preserving ciphertext randomness.\nThe resulting primitive supports efficient integration with standard FHE APIs\nand maintains compatibility with batching, rotation, and aggregation, making it\nwell-suited for encrypted databases, streaming pipelines, and secure compiler\nbackends.",
    "pdf_url": "http://arxiv.org/pdf/2505.12582v2",
    "published": "2025-05-19T00:05:18+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.12581v1",
    "title": "An approach based on class activation maps for investigating the effects of data augmentation on neural networks for image classification",
    "authors": [
      "Lucas M. Dorneles",
      "Luan Fonseca Garcia",
      "Joel Lu√≠s Carbonera"
    ],
    "abstract": "Neural networks have become increasingly popular in the last few years as an\neffective tool for the task of image classification due to the impressive\nperformance they have achieved on this task. In image classification tasks, it\nis common to use data augmentation strategies to increase the robustness of\ntrained networks to changes in the input images and to avoid overfitting.\nAlthough data augmentation is a widely adopted technique, the literature lacks\na body of research analyzing the effects data augmentation methods have on the\npatterns learned by neural network models working on complex datasets. The\nprimary objective of this work is to propose a methodology and set of metrics\nthat may allow a quantitative approach to analyzing the effects of data\naugmentation in convolutional networks applied to image classification. An\nimportant tool used in the proposed approach lies in the concept of class\nactivation maps for said models, which allow us to identify and measure the\nimportance these models assign to each individual pixel in an image when\nexecuting the classification task. From these maps, we may then extract metrics\nover the similarities and differences between maps generated by these models\ntrained on a given dataset with different data augmentation strategies.\nExperiments made using this methodology suggest that the effects of these data\naugmentation techniques not only can be analyzed in this way but also allow us\nto identify different impact profiles over the trained models.",
    "pdf_url": "http://arxiv.org/pdf/2505.12581v1",
    "published": "2025-05-19T00:03:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.12580v1",
    "title": "Coarse Attribute Prediction with Task Agnostic Distillation for Real World Clothes Changing ReID",
    "authors": [
      "Priyank Pathak",
      "Yogesh S Rawat"
    ],
    "abstract": "This work focuses on Clothes Changing Re-IDentification (CC-ReID) for the\nreal world. Existing works perform well with high-quality (HQ) images, but\nstruggle with low-quality (LQ) where we can have artifacts like pixelation,\nout-of-focus blur, and motion blur. These artifacts introduce noise to not only\nexternal biometric attributes (e.g. pose, body shape, etc.) but also corrupt\nthe model's internal feature representation. Models usually cluster LQ image\nfeatures together, making it difficult to distinguish between them, leading to\nincorrect matches. We propose a novel framework Robustness against Low-Quality\n(RLQ) to improve CC-ReID model on real-world data. RLQ relies on Coarse\nAttributes Prediction (CAP) and Task Agnostic Distillation (TAD) operating in\nalternate steps in a novel training mechanism. CAP enriches the model with\nexternal fine-grained attributes via coarse predictions, thereby reducing the\neffect of noisy inputs. On the other hand, TAD enhances the model's internal\nfeature representation by bridging the gap between HQ and LQ features, via an\nexternal dataset through task-agnostic self-supervision and distillation. RLQ\noutperforms the existing approaches by 1.6%-2.9% Top-1 on real-world datasets\nlike LaST, and DeepChange, while showing consistent improvement of 5.3%-6%\nTop-1 on PRCC with competitive performance on LTCC. *The code will be made\npublic soon.*",
    "pdf_url": "http://arxiv.org/pdf/2505.12580v1",
    "published": "2025-05-19T00:03:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  }
]