[
  {
    "id": "http://arxiv.org/abs/2505.11760v1",
    "title": "Topology-Aware Knowledge Propagation in Decentralized Learning",
    "authors": [
      "Mansi Sakarvadia",
      "Nathaniel Hudson",
      "Tian Li",
      "Ian Foster",
      "Kyle Chard"
    ],
    "abstract": "Decentralized learning enables collaborative training of models across\nnaturally distributed data without centralized coordination or maintenance of a\nglobal model. Instead, devices are organized in arbitrary communication\ntopologies, in which they can only communicate with neighboring devices. Each\ndevice maintains its own local model by training on its local data and\nintegrating new knowledge via model aggregation with neighbors. Therefore,\nknowledge is propagated across the topology via successive aggregation rounds.\nWe study, in particular, the propagation of out-of-distribution (OOD)\nknowledge. We find that popular decentralized learning algorithms struggle to\npropagate OOD knowledge effectively to all devices. Further, we find that both\nthe location of OOD data within a topology, and the topology itself,\nsignificantly impact OOD knowledge propagation. We then propose topology-aware\naggregation strategies to accelerate (OOD) knowledge propagation across\ndevices. These strategies improve OOD data accuracy, compared to\ntopology-unaware baselines, by 123% on average across models in a topology.",
    "pdf_url": "http://arxiv.org/pdf/2505.11760v1",
    "published": "2025-05-16T23:53:33+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11759v1",
    "title": "Joint Precoding and Probabilistic Constellation Shaping using Arithmetic Distribution Matching",
    "authors": [
      "Babaee Ramin",
      "Oveis Gharan Shahab",
      "Bouchard Martin"
    ],
    "abstract": "The problem of joint shaping and precoding is studied in this paper. We\nintroduce statistical dependencies among consecutive symbols to shape the\nconstellation while minimizing the total transmit power when the signal goes\nthrough the precoding filter. We propose a stationary Markovian model for\noptimizing the transition probability of transmit symbols to avoid high-energy\nsequences when convolved with the precoding filter. A new algorithm based on\narithmetic coding is proposed to generate a shaped sequence of symbols with the\ngiven Markov model transition probabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.11759v1",
    "published": "2025-05-16T23:44:08+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11758v1",
    "title": "Generalizable Vision-Language Few-Shot Adaptation with Predictive Prompts and Negative Learning",
    "authors": [
      "Sriram Mandalika"
    ],
    "abstract": "Few-shot adaptation remains a core challenge for vision-language models\n(VLMs), especially under limited supervision and noisy support samples. We\npropose PromptFuseNL, a unified framework that enhances few-shot generalization\nby combining predictive prompt tuning with dual-branch positive and negative\nlearning. The method refines class prototypes through task-conditioned\nresiduals, multi-stage cross-modal coordination, and semantic hard negative\nmining. To address label noise, we introduce an unsupervised instance\nreweighting strategy that downweights unreliable support examples without\nrequiring additional labels or structural changes. PromptFuseNL fuses visual\nand textual cues through lightweight modules for efficient and discriminative\nprediction. Evaluated across 15 benchmarks, it consistently surpasses existing\nprompt- and adapter-based methods in all shot settings while remaining highly\nefficient, achieving up to 300x faster training and 1000x lower FLOPs compared\nto full prompt tuning, achieving a new state-of-the-art for robust and scalable\nfew-shot vision-language adaptation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11758v1",
    "published": "2025-05-16T23:39:34+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11757v1",
    "title": "Efficient Lattice QCD Computation of Radiative-Leptonic-Decay Form Factors at Multiple Positive and Negative Photon Virtualities",
    "authors": [
      "Davide Giusti",
      "Christopher F. Kane",
      "Christoph Lehner",
      "Stefan Meinel",
      "Amarjit Soni"
    ],
    "abstract": "In previous work Phys. Rev. D 107, 074507 (2023), we showed that form factors\nfor radiative leptonic decays of pseudoscalar mesons can be determined\nefficiently and with high precision from lattice QCD using the ``3d method,''\nin which three-point functions are computed for all values of the\ncurrent-insertion time and the time integral is performed at the data-analysis\nstage. Here, we demonstrate another benefit of the 3d method: the form factors\ncan be extracted for any number of nonzero photon virtualites from the same\nthree-point functions at no extra cost. We present results for the\n$D_s\\to\\ell\\nu\\gamma^*$ vector form factor as a function of photon energy and\nphoton virtuality, for both positive and negative virtuality. In our analysis,\nwe separately consider the two different time orderings and the different quark\nflavors in the electromagnetic current. We discuss in detail the behavior of\nthe unwanted exponentials contributing to the three-point functions, as well as\nthe choice of fit models and fit ranges used to remove them for various values\nof the virtuality. While positive photon virtuality is relevant for decays to\nmultiple charged leptons, negative photon virtuality suppresses soft\ncontributions and is of interest in QCD-factorization studies of the form\nfactors.",
    "pdf_url": "http://arxiv.org/pdf/2505.11757v1",
    "published": "2025-05-16T23:38:36+00:00",
    "categories": [
      "hep-lat",
      "hep-ph"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2505.11756v1",
    "title": "Feature Hedging: Correlated Features Break Narrow Sparse Autoencoders",
    "authors": [
      "David Chanin",
      "Tomáš Dulka",
      "Adrià Garriga-Alonso"
    ],
    "abstract": "It is assumed that sparse autoencoders (SAEs) decompose polysemantic\nactivations into interpretable linear directions, as long as the activations\nare composed of sparse linear combinations of underlying features. However, we\nfind that if an SAE is more narrow than the number of underlying \"true\nfeatures\" on which it is trained, and there is correlation between features,\nthe SAE will merge components of correlated features together, thus destroying\nmonosemanticity. In LLM SAEs, these two conditions are almost certainly true.\nThis phenomenon, which we call feature hedging, is caused by SAE reconstruction\nloss, and is more severe the narrower the SAE. In this work, we introduce the\nproblem of feature hedging and study it both theoretically in toy models and\nempirically in SAEs trained on LLMs. We suspect that feature hedging may be one\nof the core reasons that SAEs consistently underperform supervised baselines.\nFinally, we use our understanding of feature hedging to propose an improved\nvariant of matryoshka SAEs. Our work shows there remain fundamental issues with\nSAEs, but we are hopeful that that highlighting feature hedging will catalyze\nfuture advances that allow SAEs to achieve their full potential of interpreting\nLLMs at scale.",
    "pdf_url": "http://arxiv.org/pdf/2505.11756v1",
    "published": "2025-05-16T23:30:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11755v2",
    "title": "Reachability Barrier Networks: Learning Hamilton-Jacobi Solutions for Smooth and Flexible Control Barrier Functions",
    "authors": [
      "Matthew Kim",
      "William Sharpless",
      "Hyun Joe Jeong",
      "Sander Tonkens",
      "Somil Bansal",
      "Sylvia Herbert"
    ],
    "abstract": "Recent developments in autonomous driving and robotics underscore the\nnecessity of safety-critical controllers. Control barrier functions (CBFs) are\na popular method for appending safety guarantees to a general control\nframework, but they are notoriously difficult to generate beyond low\ndimensions. Existing methods often yield non-differentiable or inaccurate\napproximations that lack integrity, and thus fail to ensure safety. In this\nwork, we use physics-informed neural networks (PINNs) to generate smooth\napproximations of CBFs by computing Hamilton-Jacobi (HJ) optimal control\nsolutions. These reachability barrier networks (RBNs) avoid traditional\ndimensionality constraints and support the tuning of their conservativeness\npost-training through a parameterized discount term. To ensure robustness of\nthe discounted solutions, we leverage conformal prediction methods to derive\nprobabilistic safety guarantees for RBNs. We demonstrate that RBNs are highly\naccurate in low dimensions, and safer than the standard neural CBF approach in\nhigh dimensions. Namely, we showcase the RBNs in a 9D multi-vehicle collision\navoidance problem where it empirically proves to be 5.5x safer and 1.9x less\nconservative than the neural CBFs, offering a promising method to synthesize\nCBFs for general nonlinear autonomous systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11755v2",
    "published": "2025-05-16T23:30:13+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11754v1",
    "title": "Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation",
    "authors": [
      "Wenyu Huang",
      "Pavlos Vougiouklis",
      "Mirella Lapata",
      "Jeff Z. Pan"
    ],
    "abstract": "Multi-hop Question Answering (MHQA) adds layers of complexity to question\nanswering, making it more challenging. When Language Models (LMs) are prompted\nwith multiple search results, they are tasked not only with retrieving relevant\ninformation but also employing multi-hop reasoning across the information\nsources. Although LMs perform well on traditional question-answering tasks, the\ncausal mask can hinder their capacity to reason across complex contexts. In\nthis paper, we explore how LMs respond to multi-hop questions by permuting\nsearch results (retrieved documents) under various configurations. Our study\nreveals interesting findings as follows: 1) Encoder-decoder models, such as the\nones in the Flan-T5 family, generally outperform causal decoder-only LMs in\nMHQA tasks, despite being significantly smaller in size; 2) altering the order\nof gold documents reveals distinct trends in both Flan T5 models and fine-tuned\ndecoder-only models, with optimal performance observed when the document order\naligns with the reasoning chain order; 3) enhancing causal decoder-only models\nwith bi-directional attention by modifying the causal mask can effectively\nboost their end performance. In addition to the above, we conduct a thorough\ninvestigation of the distribution of LM attention weights in the context of\nMHQA. Our experiments reveal that attention weights tend to peak at higher\nvalues when the resulting answer is correct. We leverage this finding to\nheuristically improve LMs' performance on this task. Our code is publicly\navailable at https://github.com/hwy9855/MultiHopQA-Reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.11754v1",
    "published": "2025-05-16T23:29:47+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11753v1",
    "title": "X-Edit: Detecting and Localizing Edits in Images Altered by Text-Guided Diffusion Models",
    "authors": [
      "Valentina Bazyleva",
      "Nicolo Bonettini",
      "Gaurav Bharaj"
    ],
    "abstract": "Text-guided diffusion models have significantly advanced image editing,\nenabling highly realistic and local modifications based on textual prompts.\nWhile these developments expand creative possibilities, their malicious use\nposes substantial challenges for detection of such subtle deepfake edits. To\nthis end, we introduce Explain Edit (X-Edit), a novel method for localizing\ndiffusion-based edits in images. To localize the edits for an image, we invert\nthe image using a pretrained diffusion model, then use these inverted features\nas input to a segmentation network that explicitly predicts the edited masked\nregions via channel and spatial attention. Further, we finetune the model using\na combined segmentation and relevance loss. The segmentation loss ensures\naccurate mask prediction by balancing pixel-wise errors and perceptual\nsimilarity, while the relevance loss guides the model to focus on low-frequency\nregions and mitigate high-frequency artifacts, enhancing the localization of\nsubtle edits. To the best of our knowledge, we are the first to address and\nmodel the problem of localizing diffusion-based modified regions in images. We\nadditionally contribute a new dataset of paired original and edited images\naddressing the current lack of resources for this task. Experimental results\ndemonstrate that X-Edit accurately localizes edits in images altered by\ntext-guided diffusion models, outperforming baselines in PSNR and SSIM metrics.\nThis highlights X-Edit's potential as a robust forensic tool for detecting and\npinpointing manipulations introduced by advanced image editing techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.11753v1",
    "published": "2025-05-16T23:29:38+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11752v1",
    "title": "Permutation Randomization on Nonsmooth Nonconvex Optimization: A Theoretical and Experimental Study",
    "authors": [
      "Wei Zhang",
      "Arif Hassan Zidan",
      "Afrar Jahin",
      "Yu Bao",
      "Tianming Liu"
    ],
    "abstract": "While gradient-based optimizers that incorporate randomization often showcase\nsuperior performance on complex optimization, the theoretical foundations\nunderlying this superiority remain insufficiently understood. A particularly\npressing question has emerged: What is the role of randomization in\ndimension-free nonsmooth nonconvex optimization? To address this gap, we\ninvestigate the theoretical and empirical impact of permutation randomization\nwithin gradient-based optimization frameworks, using it as a representative\ncase to explore broader implications. From a theoretical perspective, our\nanalyses reveal that permutation randomization disrupts the shrinkage behavior\nof gradient-based optimizers, facilitating continuous convergence toward the\nglobal optimum given a sufficiently large number of iterations. Additionally,\nwe prove that permutation randomization can preserve the convergence rate of\nthe underlying optimizer. On the empirical side, we conduct extensive numerical\nexperiments comparing permutation-randomized optimizer against three baseline\nmethods. These experiments span tasks such as training deep neural networks\nwith stacked architectures and optimizing noisy objective functions. The\nresults not only corroborate our theoretical insights but also highlight the\npractical benefits of permutation randomization. In summary, this work delivers\nboth rigorous theoretical justification and compelling empirical evidence for\nthe effectiveness of permutation randomization. Our findings and evidence lay a\nfoundation for extending analytics to encompass a wide array of randomization.",
    "pdf_url": "http://arxiv.org/pdf/2505.11752v1",
    "published": "2025-05-16T23:28:38+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11751v2",
    "title": "Towards Navigation-Grade and Deployable Optomechanical Accelerometry",
    "authors": [
      "Chang Ge",
      "Daniel Dominguez",
      "Allison Rubenok",
      "Michael Miller",
      "Matt Eichenfield"
    ],
    "abstract": "We design and experimentally demonstrate an architecture for achieving\nnavigation-grade, fiber-packaged optomechanical accelerometers that can operate\nwith a large dynamic range, over a wide temperature range, and without\nsophisticated laser sources. Our accelerometer architecture is based on a novel\nset of design principles that take advantage of the strengths of optomechanical\naccelerometry while eliminating many of its historical weaknesses. Displacement\nreadout is provided by an integrated, differential strain-sensing Mach-Zehnder\ninterferometer (DSMZI) attached to an ultra-rigid, bulk-micromachined proof\nmass having a 93.4 kHz fundamental resonance frequency (22.5 pm/g\ndisplacement). Despite the extreme rigidity, the high displacement sensitivity\nprovides an insertion loss limited 4.2 $\\mu g/\\sqrt{\\mathrm{Hz}}$ acceleration\nresolution, with a straight-forward path to achieving 330 $n\ng/\\sqrt{\\mathrm{Hz}}$ by improving the fiber-to-chip coupling. Further, we show\nthat the combination of high rigidity and intrinsic differential optical\nreadout makes the device insensitive to the common causes of bias instability,\nand we measure a bias instability of 6.3 $\\mu g$ at 243 seconds. The DSMZI\nprovides a 17 nm optical bandwidth and a temperature operating range of greater\nthan 20 $^\\circ\\mathrm{C}$, both orders of magnitude larger than previous\ndemonstrations of optomechanical accelerometers. The high rigidity and large\noptical bandwidth yield an expected dynamic range of 165.4 dB. The combination\nof high acceleration resolution, high dynamic range, low bias instability, and\nintrinsic insensitivity to wavelength, temperature, and package stresses makes\nour device well suited for deployment in realistic environments demanded by\nreal-world applications and demonstrates a path for optomechanical\naccelerometers to ultimately exceed the performance of all other chip-based\naccelerometers.",
    "pdf_url": "http://arxiv.org/pdf/2505.11751v2",
    "published": "2025-05-16T23:24:45+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph",
      "physics.ins-det"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.11750v2",
    "title": "Improving Medium Range Severe Weather Prediction through Transformer Post-processing of AI Weather Forecasts",
    "authors": [
      "Zhanxiang Hua",
      "Ryan Sobash",
      "David John Gagne II",
      "Yingkai Sha",
      "Alexandra Anderson-Frey"
    ],
    "abstract": "Improving the skill of medium-range (1-8 day) severe weather prediction is\ncrucial for mitigating societal impacts. This study introduces a novel approach\nleveraging decoder-only transformer networks to post-process AI-based weather\nforecasts, specifically from the Pangu-Weather model, for improved severe\nweather guidance. Unlike traditional post-processing methods that use a dense\nneural network to predict the probability of severe weather using discrete\nforecast samples, our method treats forecast lead times as sequential\n``tokens'', enabling the transformer to learn complex temporal relationships\nwithin the evolving atmospheric state. We compare this approach against\npost-processing of the Global Forecast System (GFS) using both a traditional\ndense neural network and our transformer, as well as configurations that\nexclude convective parameters to fairly evaluate the impact of using the\nPangu-Weather AI model. Results demonstrate that the transformer-based\npost-processing significantly enhances forecast skill compared to dense neural\nnetworks. Furthermore, AI-driven forecasts, particularly Pangu-Weather\ninitialized from high resolution analysis, exhibit superior performance to GFS\nin the medium-range, even without explicit convective parameters. Our approach\noffers improved accuracy, and reliability, which also provides interpretability\nthrough feature attribution analysis, advancing medium-range severe weather\nprediction capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.11750v2",
    "published": "2025-05-16T23:22:07+00:00",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11749v2",
    "title": "Missing Data Imputation by Reducing Mutual Information with Rectified Flows",
    "authors": [
      "Jiahao Yu",
      "Qizhen Ying",
      "Leyang Wang",
      "Ziyue Jiang",
      "Song Liu"
    ],
    "abstract": "This paper introduces a novel iterative method for missing data imputation\nthat sequentially reduces the mutual information between data and their\ncorresponding missing mask. Inspired by GAN-based approaches, which train\ngenerators to decrease the predictability of missingness patterns, our method\nexplicitly targets the reduction of mutual information. Specifically, our\nalgorithm iteratively minimizes the KL divergence between the joint\ndistribution of the imputed data and missing mask, and the product of their\nmarginals from the previous iteration. We show that the optimal imputation\nunder this framework corresponds to solving an ODE, whose velocity field\nminimizes a rectified flow training objective. We further illustrate that some\nexisting imputation techniques can be interpreted as approximate special cases\nof our mutual-information-reducing framework. Comprehensive experiments on\nsynthetic and real-world datasets validate the efficacy of our proposed\napproach, demonstrating superior imputation performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.11749v2",
    "published": "2025-05-16T23:15:02+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.11748v1",
    "title": "HOME-3: High-Order Momentum Estimator with Third-Power Gradient for Convex and Smooth Nonconvex Optimization",
    "authors": [
      "Wei Zhang",
      "Arif Hassan Zidan",
      "Afrar Jahin",
      "Yu Bao",
      "Tianming Liu"
    ],
    "abstract": "Momentum-based gradients are essential for optimizing advanced machine\nlearning models, as they not only accelerate convergence but also advance\noptimizers to escape stationary points. While most state-of-the-art momentum\ntechniques utilize lower-order gradients, such as the squared first-order\ngradient, there has been limited exploration of higher-order gradients,\nparticularly those raised to powers greater than two. In this work, we\nintroduce the concept of high-order momentum, where momentum is constructed\nusing higher-power gradients, with a focus on the third-power of the\nfirst-order gradient as a representative case. Our research offers both\ntheoretical and empirical support for this approach. Theoretically, we\ndemonstrate that incorporating third-power gradients can improve the\nconvergence bounds of gradient-based optimizers for both convex and smooth\nnonconvex problems. Empirically, we validate these findings through extensive\nexperiments across convex, smooth nonconvex, and nonsmooth nonconvex\noptimization tasks. Across all cases, high-order momentum consistently\noutperforms conventional low-order momentum methods, showcasing superior\nperformance in various optimization problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11748v1",
    "published": "2025-05-16T23:13:58+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11747v1",
    "title": "Structure of the Cayley-Dickson algebras",
    "authors": [
      "G. P. Wilmot"
    ],
    "abstract": "Viewing the Cayley-Dickson process as a graded construction provides a\nrigorous definition of associativity consisting of three types and the\nnon-associative parts dividing into four types. These simplify the Moufang loop\nidentities and Mal'cev's identity, which identifies the non-associative Lie\nalgebra structure. This structure is distinct for the first four\npower-associative algebras and has the same pattern for at least the next\nthree. The structure is identified with 3-cycles and modes that reduce sets of\n84 zero divisors to just 7, in most cases, such as for the sedenions, and\nidentifies the subalgebas of the power associative algebras that provide zero\ndivisors thus defining the structure of Cayley-Dickson algebras. The zero\ndivisor and octonion cardinality at all levels is derived. Split algebras are\nproved to be isomorphic for any power-associative algebra and share the same\nnon-associative structure with different zero divisors. Due to the inclusion of\nnew power-associative algebras into the hypercomplex algebras the terminology\nultracomplex numbers is suggested.",
    "pdf_url": "http://arxiv.org/pdf/2505.11747v1",
    "published": "2025-05-16T23:09:13+00:00",
    "categories": [
      "math.RA",
      "17D10"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2506.06290v2",
    "title": "CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning",
    "authors": [
      "Mingyu Lu",
      "Ethan Weinberger",
      "Chanwoo Kim",
      "Su-In Lee"
    ],
    "abstract": "High-content screening (HCS) assays based on high-throughput microscopy\ntechniques such as Cell Painting have enabled the interrogation of cells'\nmorphological responses to perturbations at an unprecedented scale. The\ncollection of such data promises to facilitate a better understanding of the\nrelationships between different perturbations and their effects on cellular\nstate. Towards achieving this goal, recent advances in cross-modal contrastive\nlearning could, in theory, be leveraged to learn a unified latent space that\naligns perturbations with their corresponding morphological effects. However,\nthe application of such methods to HCS data is not straightforward due to\nsubstantial differences in the semantics of Cell Painting images compared to\nnatural images, and the difficulty of representing different classes of\nperturbations (e.g., small molecule vs CRISPR gene knockout) in a single latent\nspace. In response to these challenges, here we introduce CellCLIP, a\ncross-modal contrastive learning framework for HCS data. CellCLIP leverages\npre-trained image encoders coupled with a novel channel encoding scheme to\nbetter capture relationships between different microscopy channels in image\nembeddings, along with natural language encoders for representing\nperturbations. Our framework outperforms current open-source models,\ndemonstrating the best performance in both cross-modal retrieval and\nbiologically meaningful downstream tasks while also achieving significant\nreductions in computation time.",
    "pdf_url": "http://arxiv.org/pdf/2506.06290v2",
    "published": "2025-05-16T23:07:51+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11746v1",
    "title": "Token Masking Improves Transformer-Based Text Classification",
    "authors": [
      "Xianglong Xu",
      "John Bowen",
      "Rojin Taheri"
    ],
    "abstract": "While transformer-based models achieve strong performance on text\nclassification, we explore whether masking input tokens can further enhance\ntheir effectiveness. We propose token masking regularization, a simple yet\ntheoretically motivated method that randomly replaces input tokens with a\nspecial [MASK] token at probability p. This introduces stochastic perturbations\nduring training, leading to implicit gradient averaging that encourages the\nmodel to capture deeper inter-token dependencies. Experiments on language\nidentification and sentiment analysis -- across diverse models (mBERT,\nQwen2.5-0.5B, TinyLlama-1.1B) -- show consistent improvements over standard\nregularization techniques. We identify task-specific optimal masking rates,\nwith p = 0.1 as a strong general default. We attribute the gains to two key\neffects: (1) input perturbation reduces overfitting, and (2) gradient-level\nsmoothing acts as implicit ensembling.",
    "pdf_url": "http://arxiv.org/pdf/2505.11746v1",
    "published": "2025-05-16T23:06:11+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11745v1",
    "title": "POCAII: Parameter Optimization with Conscious Allocation using Iterative Intelligence",
    "authors": [
      "Joshua Inman",
      "Tanmay Khandait",
      "Lalitha Sankar",
      "Giulia Pedrielli"
    ],
    "abstract": "In this paper we propose for the first time the hyperparameter optimization\n(HPO) algorithm POCAII. POCAII differs from the Hyperband and Successive\nHalving literature by explicitly separating the search and evaluation phases\nand utilizing principled approaches to exploration and exploitation principles\nduring both phases. Such distinction results in a highly flexible scheme for\nmanaging a hyperparameter optimization budget by focusing on search (i.e.,\ngenerating competing configurations) towards the start of the HPO process while\nincreasing the evaluation effort as the HPO comes to an end.\n  POCAII was compared to state of the art approaches SMAC, BOHB and DEHB. Our\nalgorithm shows superior performance in low-budget hyperparameter optimization\nregimes. Since many practitioners do not have exhaustive resources to assign to\nHPO, it has wide applications to real-world problems. Moreover, the empirical\nevidence showed how POCAII demonstrates higher robustness and lower variance in\nthe results. This is again very important when considering realistic scenarios\nwith extremely expensive models to train.",
    "pdf_url": "http://arxiv.org/pdf/2505.11745v1",
    "published": "2025-05-16T23:05:07+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11744v1",
    "title": "Decentralized Multi-Authority Attribute-Based Inner-Product Functional Encryption: Noisy and Evasive Constructions from Lattices",
    "authors": [
      "Jiaqi Liu",
      "Yan Wang",
      "Fang-Wei Fu"
    ],
    "abstract": "We study multi-authority attribute-based functional encryption for noisy\ninner-product functionality, and propose two new primitives: (1)\nmulti-authority attribute-based (noisy) inner-product functional encryption\n(MA-AB(N)IPFE), which generalizes existing multi-authority attribute-based IPFE\nschemes by Agrawal et al. (TCC'21), by enabling approximate inner-product\ncomputation; and (2) multi-authority attribute-based evasive inner-product\nfunctional encryption (MA-evIPFE), a relaxed variant inspired by the evasive\nIPFE framework by Hsieh et al. (EUROCRYPT'24), shifting focus from ciphertext\nindistinguishability to a more relaxed pseudorandomness-based security notion.\nTo support the above notions, we introduce two variants of lattice-based\ncomputational assumptions: evasive IPFE assumption and\nindistinguishability-based evasive IPFE assumption (IND-evIPFE). We present\nlattice-based constructions of both primitives for subset policies, building\nupon the framework of Waters et al.( TCC'22). Our schemes are proven to be\nstatically secure in the random oracle model under the standard LWE assumption\nand the newly introduced assumptions. Additionally, we show our MA-AB(N)IPFE\nscheme can be transformed via modulus switching into a noiseless MA-IPFE scheme\nthat supports exact inner-product functionality. This yields the first\nlattice-based construction of such a primitive. All our schemes support\narbitrary polynomial-size attribute policies and are secure in the random\noracle model under lattice assumptions with a sub-exponential modulus-to-noise\nratio, making them practical candidates for noise-tolerant, fine-grained access\ncontrol in multi-authority settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.11744v1",
    "published": "2025-05-16T23:03:23+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11743v1",
    "title": "Cloud-Based AI Systems: Leveraging Large Language Models for Intelligent Fault Detection and Autonomous Self-Healing",
    "authors": [
      "Cheng Ji",
      "Huaiying Luo"
    ],
    "abstract": "With the rapid development of cloud computing systems and the increasing\ncomplexity of their infrastructure, intelligent mechanisms to detect and\nmitigate failures in real time are becoming increasingly important. Traditional\nmethods of failure detection are often difficult to cope with the scale and\ndynamics of modern cloud environments. In this study, we propose a novel AI\nframework based on Massive Language Model (LLM) for intelligent fault detection\nand self-healing mechanisms in cloud systems. The model combines existing\nmachine learning fault detection algorithms with LLM's natural language\nunderstanding capabilities to process and parse system logs, error reports, and\nreal-time data streams through semantic context. The method adopts a\nmulti-level architecture, combined with supervised learning for fault\nclassification and unsupervised learning for anomaly detection, so that the\nsystem can predict potential failures before they occur and automatically\ntrigger the self-healing mechanism. Experimental results show that the proposed\nmodel is significantly better than the traditional fault detection system in\nterms of fault detection accuracy, system downtime reduction and recovery\nspeed.",
    "pdf_url": "http://arxiv.org/pdf/2505.11743v1",
    "published": "2025-05-16T23:02:57+00:00",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11742v1",
    "title": "FAIR Ecosystems for Science at Scale",
    "authors": [
      "Sean R. Wilkinson",
      "Patrick Widener"
    ],
    "abstract": "High Performance Computing (HPC) centers provide resources to users who\nrequire greater scale to \"get science done\". They deploy infrastructure with\nsingular hardware architectures, cutting-edge software environments, and\nstricter security measures as compared with users' own resources. As a result,\nusers often create and configure digital artifacts in ways that are specialized\nfor the unique infrastructure at a given HPC center. Each user of that center\nwill face similar challenges as they develop specialized solutions to take full\nadvantages of the center's resources, potentially resulting in significant\nduplication of effort. Much duplicated effort could be avoided, however, if\nusers of these centers found it easier to discover others' solutions and\nartifacts as well as share their own.\n  The FAIR principles address this problem by presenting guidelines focused\naround metadata practices to be implemented by vaguely defined \"communities\";\nin practice, these tend to gather by domain (e.g. bioinformatics, geosciences,\nagriculture). Domain-based communities can unfortunately end up functioning as\nsilos that tend both to inhibit sharing of solutions and best practices as well\nas to encourage fragile and unsustainable improvised solutions in the absence\nof best-practice guidance. We propose that these communities pursuing \"science\nat scale\" be nurtured both individually and collectively by HPC centers so that\nusers can take advantage of shared challenges across disciplines and\npotentially across HPC centers. We describe an architecture based on the\nEOSC-Life FAIR Workflows Collaboratory, specialized for use with and inside HPC\ncenters such as the Oak Ridge Leadership Computing Facility (OLCF), and we\nspeculate on user incentives to encourage adoption. We note that a focus on\nFAIR workflow components rather than FAIR workflows is more likely to benefit\nthe users of HPC centers.",
    "pdf_url": "http://arxiv.org/pdf/2505.11742v1",
    "published": "2025-05-16T23:02:25+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11741v1",
    "title": "Diverging Towards Hallucination: Detection of Failures in Vision-Language Models via Multi-token Aggregation",
    "authors": [
      "Geigh Zollicoffer",
      "Minh Vu",
      "Manish Bhattarai"
    ],
    "abstract": "Vision-language models (VLMs) now rival human performance on many multimodal\ntasks, yet they still hallucinate objects or generate unsafe text. Current\nhallucination detectors, e.g., single-token linear probing (SLP) and P(True),\ntypically analyze only the logit of the first generated token or just its\nhighest scoring component overlooking richer signals embedded within earlier\ntoken distributions. We demonstrate that analyzing the complete sequence of\nearly logits potentially provides substantially more diagnostic information. We\nemphasize that hallucinations may only emerge after several tokens, as subtle\ninconsistencies accumulate over time. By analyzing the Kullback-Leibler (KL)\ndivergence between logits corresponding to hallucinated and non-hallucinated\ntokens, we underscore the importance of incorporating later-token logits to\nmore accurately capture the reliability dynamics of VLMs. In response, we\nintroduce Multi-Token Reliability Estimation (MTRE), a lightweight, white-box\nmethod that aggregates logits from the first ten tokens using multi-token\nlog-likelihood ratios and self-attention. Despite the challenges posed by large\nvocabulary sizes and long logit sequences, MTRE remains efficient and\ntractable. On MAD-Bench, MM-SafetyBench, MathVista, and four\ncompositional-geometry benchmarks, MTRE improves AUROC by 9.4 +/- 1.3 points\nover SLP and by 12.1 +/- 1.7 points over P(True), setting a new\nstate-of-the-art in hallucination detection for open-source VLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11741v1",
    "published": "2025-05-16T23:00:19+00:00",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11740v1",
    "title": "Simple and Effective Specialized Representations for Fair Classifiers",
    "authors": [
      "Alberto Sinigaglia",
      "Davide Sartor",
      "Marina Ceccon",
      "Gian Antonio Susto"
    ],
    "abstract": "Fair classification is a critical challenge that has gained increasing\nimportance due to international regulations and its growing use in high-stakes\ndecision-making settings. Existing methods often rely on adversarial learning\nor distribution matching across sensitive groups; however, adversarial learning\ncan be unstable, and distribution matching can be computationally intensive. To\naddress these limitations, we propose a novel approach based on the\ncharacteristic function distance. Our method ensures that the learned\nrepresentation contains minimal sensitive information while maintaining high\neffectiveness for downstream tasks. By utilizing characteristic functions, we\nachieve a more stable and efficient solution compared to traditional methods.\nAdditionally, we introduce a simple relaxation of the objective function that\nguarantees fairness in common classification models with no performance\ndegradation. Experimental results on benchmark datasets demonstrate that our\napproach consistently matches or achieves better fairness and predictive\naccuracy than existing methods. Moreover, our method maintains robustness and\ncomputational efficiency, making it a practical solution for real-world\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2505.11740v1",
    "published": "2025-05-16T22:59:46+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11739v1",
    "title": "ZeroTuning: Unlocking the Initial Token's Power to Enhance Large Language Models Without Training",
    "authors": [
      "Feijiang Han",
      "Xiaodong Yu",
      "Jianheng Tang",
      "Lyle Ungar"
    ],
    "abstract": "Recently, training-free methods for improving large language models (LLMs)\nhave attracted growing interest, with token-level attention tuning emerging as\na promising and interpretable direction. However, existing methods typically\nrely on auxiliary mechanisms to identify important or irrelevant task-specific\ntokens, introducing potential bias and limiting applicability. In this paper,\nwe uncover a surprising and elegant alternative: the semantically empty initial\ntoken is a powerful and underexplored control point for optimizing model\nbehavior. Through theoretical analysis, we show that tuning the initial token's\nattention sharpens or flattens the attention distribution over subsequent\ntokens, and its role as an attention sink amplifies this effect. Empirically,\nwe find that: (1) tuning its attention improves LLM performance more\neffectively than tuning other task-specific tokens; (2) the effect follows a\nconsistent trend across layers, with earlier layers having greater impact, but\nvaries across attention heads, with different heads showing distinct\npreferences in how they attend to this token. Based on these findings, we\npropose ZeroTuning, a training-free approach that improves LLM performance by\napplying head-specific attention adjustments to this special token. Despite\ntuning only one token, ZeroTuning achieves higher performance on text\nclassification, multiple-choice, and multi-turn conversation tasks across\nmodels such as Llama, Qwen, and DeepSeek. For example, ZeroTuning improves\nLlama-3.1-8B by 11.71% on classification, 2.64% on QA tasks, and raises its\nmulti-turn score from 7.804 to 7.966. The method is also robust to limited\nresources, few-shot settings, long contexts, quantization, decoding strategies,\nand prompt variations. Our work sheds light on a previously overlooked control\npoint in LLMs, offering new insights into both inference-time tuning and model\ninterpretability.",
    "pdf_url": "http://arxiv.org/pdf/2505.11739v1",
    "published": "2025-05-16T22:52:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11738v1",
    "title": "Automated Real-time Assessment of Intracranial Hemorrhage Detection AI Using an Ensembled Monitoring Model (EMM)",
    "authors": [
      "Zhongnan Fang",
      "Andrew Johnston",
      "Lina Cheuy",
      "Hye Sun Na",
      "Magdalini Paschali",
      "Camila Gonzalez",
      "Bonnie A. Armstrong",
      "Arogya Koirala",
      "Derrick Laurel",
      "Andrew Walker Campion",
      "Michael Iv",
      "Akshay S. Chaudhari",
      "David B. Larson"
    ],
    "abstract": "Artificial intelligence (AI) tools for radiology are commonly unmonitored\nonce deployed. The lack of real-time case-by-case assessments of AI prediction\nconfidence requires users to independently distinguish between trustworthy and\nunreliable AI predictions, which increases cognitive burden, reduces\nproductivity, and potentially leads to misdiagnoses. To address these\nchallenges, we introduce Ensembled Monitoring Model (EMM), a framework inspired\nby clinical consensus practices using multiple expert reviews. Designed\nspecifically for black-box commercial AI products, EMM operates independently\nwithout requiring access to internal AI components or intermediate outputs,\nwhile still providing robust confidence measurements. Using intracranial\nhemorrhage detection as our test case on a large, diverse dataset of 2919\nstudies, we demonstrate that EMM successfully categorizes confidence in the\nAI-generated prediction, suggesting different actions and helping improve the\noverall performance of AI tools to ultimately reduce cognitive burden.\nImportantly, we provide key technical considerations and best practices for\nsuccessfully translating EMM into clinical settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.11738v1",
    "published": "2025-05-16T22:50:42+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11737v2",
    "title": "TokUR: Token-Level Uncertainty Estimation for Large Language Model Reasoning",
    "authors": [
      "Tunyu Zhang",
      "Haizhou Shi",
      "Yibin Wang",
      "Hengyi Wang",
      "Xiaoxiao He",
      "Zhuowei Li",
      "Haoxian Chen",
      "Ligong Han",
      "Kai Xu",
      "Huan Zhang",
      "Dimitris Metaxas",
      "Hao Wang"
    ],
    "abstract": "While Large Language Models (LLMs) have demonstrated impressive capabilities,\ntheir output quality remains inconsistent across various application scenarios,\nmaking it difficult to identify trustworthy responses, especially in complex\ntasks requiring multi-step reasoning. In this paper, we propose a Token-level\nUncertainty estimation framework for Reasoning (TokUR) to enable LLMs to\nself-assess and self-improve their generation quality in mathematical\nreasoning. Specifically, we introduce low-rank random weight perturbation to\nLLM decoding, generating predictive distributions that we use to estimate\ntoken-level uncertainties. We then aggregate these uncertainties to reflect\nsemantic uncertainty of the generated sequences. Experiments on mathematical\nreasoning datasets of varying difficulty demonstrate that our token-level\nuncertainty metrics strongly correlate with answer correctness and model\nrobustness. Additionally, we explore using uncertainty to directly enhance the\nmodel's reasoning performance through multiple generations and the particle\nfiltering algorithm. Our approach consistently outperforms existing uncertainty\nestimation methods, establishing effective uncertainty estimation as a valuable\ntool for both evaluating and improving reasoning generation in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11737v2",
    "published": "2025-05-16T22:47:32+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11736v2",
    "title": "Holographic explorations of regular black holes in pure gravity",
    "authors": [
      "Monserrat Aguayo",
      "Leonardo Gajardo",
      "Nicolás Grandi",
      "Javier Moreno",
      "Julio Oliva",
      "Martín Reyes"
    ],
    "abstract": "It has been recently established in \\textit{Phys.Lett.B 861 (2025) 139260}\nthat regular, asymptotically flat black holes exist in pure gravity theories in\ndimension greater than four. We extend this result to asymptotically Anti-de\nSitter spacetimes and perform bottom-up holographic explorations: Hawking-Page\nphase transitions, quasinormal modes of black holes providing decay times of\nexcitations in the finite temperature conformal field theory and U-shaped\nstring probes leading to the quark-antiquark potential in the dual field\ntheory. The gravitational action contains a bared, negative cosmological\nconstant and an Einstein-Hilbert term, supplemented by an infinite series of\nhigher-curvature terms of the family known as Quasi-topological (QT)\nLagrangians, leading to a lapse function in terms of infinite series which can\nbe resumed to an analytic function for different coupling choices. The QT terms\nare defined as those satisfying a Birkhoff's theorem and possessing a\nholographic c-function, and exist at all orders in the curvature, for arbitrary\ndimension greater than four. Besides presenting the general formulae, we\nexplore the physics of three specific cases leading to Hayward, Dymnikova and\nBardeen-like regular black holes. We also found the field redefinition that\npermits recasting the $\\alpha'^3 W^4$ correction of Type IIB supergravity on\n$\\mathcal{A}_5\\times S^5$ as a series of QT terms. Before finishing, beyond\nholography, we also provide an extended thermodynamic setup, that via\nvariations of the dimensionful $\\alpha$ and $L$, allow obtaining the Euler\nrelation between finite thermodynamical quantities for the black hole of the\ntheory.",
    "pdf_url": "http://arxiv.org/pdf/2505.11736v2",
    "published": "2025-05-16T22:46:56+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11735v1",
    "title": "Evaluation and optimization of deep learning models for enhanced detection of brain cancer using transmission optical microscopy of thin brain tissue samples",
    "authors": [
      "Mohnish Sao",
      "Mousa Alrubayan",
      "Prabhakar Pradhan"
    ],
    "abstract": "Optical transmission spectroscopy is one method to understand brain tissue\nstructural properties from brain tissue biopsy samples, yet manual\ninterpretation is resource intensive and prone to inter observer variability.\nDeep convolutional neural networks (CNNs) offer automated feature learning\ndirectly from raw brightfield images. Here, we evaluate ResNet50 and\nDenseNet121 on a curated dataset of 2,931 bright-field transmission optical\nmicroscopy images of thin brain tissue, split into 1,996 for training, 437 for\nvalidation, and 498 for testing. Our two stage transfer learning protocol\ninvolves initial training of a classifier head on frozen pretrained feature\nextractors, followed by fine tuning of deeper convolutional blocks with\nextensive data augmentation (rotations, flips, intensity jitter) and early\nstopping. DenseNet121 achieves 88.35 percent test accuracy, 0.9614 precision,\n0.8667 recall, and 0.9116 F1 score the best performance compared to ResNet50\n(82.12 percent, 0.9035, 0.8142, 0.8563). Detailed analysis of confusion\nmatrices, training and validation curves, and classwise prediction\ndistributions illustrates robust convergence and minimal bias. These findings\ndemonstrate the superior generalization of dense connectivity on limited\nmedical datasets and outline future directions for multi-class tumor grading\nand clinical translation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11735v1",
    "published": "2025-05-16T22:45:48+00:00",
    "categories": [
      "physics.med-ph",
      "physics.bio-ph",
      "physics.optics"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13511v1",
    "title": "Can AI Freelancers Compete? Benchmarking Earnings, Reliability, and Task Success at Scale",
    "authors": [
      "David Noever",
      "Forrest McKee"
    ],
    "abstract": "This study explores Large Language Models (LLMs) as autonomous agents for\nreal-world tasks, including freelance software development. This work presents\na new benchmark that evaluates LLMs on freelance programming and data analysis\ntasks derived from economic data. We construct the benchmark using synthetic\ntasks created from a Kaggle Freelancer dataset of job postings, with all job\nprices standardized to USD (median fixed-project price around $250, and an\naverage of $306). Each task is accompanied by structured input-output test\ncases and an estimated price tag, enabling automated correctness checking and a\nmonetary performance valuation. This approach is inspired by OpenAI's recent\nSWE-Lancer benchmark (1,400 real Upwork tasks worth $1M total). Still, our\nframework simplifies evaluation using programmatically testable tasks and\npredicted price values, making it highly scalable and repeatable. On this\nbenchmark, we evaluate four modern LLMs - Claude 3.5 Haiku, GPT-4o-mini, Qwen\n2.5, and Mistral. We report each model's accuracy (task success rate and\ntest-case pass rate) and the total \"freelance earnings\" it achieves (sum of\nprices of solved tasks). Our results show that Claude 3.5 Haiku performs best,\nearning approximately $1.52 million USD, followed closely by GPT-4o-mini at\n$1.49 million, then Qwen 2.5 ($1.33M) and Mistral ($0.70M). We analyze the\ndistribution of errors per task and observe that the strongest models solve the\nmost tasks and rarely fail completely on any project. We discuss the\nimplications of these results for the feasibility of AI as a freelance\ndeveloper, the advantages and limitations of our automated benchmark approach,\nand the gap between performance on structured tasks versus the true complexity\nof real-world freelance jobs.",
    "pdf_url": "http://arxiv.org/pdf/2505.13511v1",
    "published": "2025-05-16T22:42:04+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11734v1",
    "title": "Dust Evolution in Simulated Multi-phase Galactic Outflows",
    "authors": [
      "Helena M. Richie",
      "Evan E. Schneider"
    ],
    "abstract": "We present the first large-scale, high-resolution simulations of dusty, star\nformation feedback-driven galactic outflows. Using the Cholla hydrodynamics\ncode, we investigate dust sputtering in these environments for grains ranging\nin size from $1-0.001~{\\mu\\mathrm{m}}$. We compare results for two feedback\nmodels: one representative of low-redshift nuclear starburst galaxies and one\nsimilar to high-redshift main sequence galaxies. In general, our simulations\nshow that multi-phase outflows are capable of safely transporting a vast\nmajority of their dust to large distances ($\\sim10~\\textrm{kpc}$) from the\ndisk. This work also shows that environmental shielding in cool gas clouds\nboosts dust survival rates significantly. The evolutionary path of dust depends\nstrongly on grain size. Large grains ($a\\geq0.1~{\\mu\\mathrm{m}}$) can be\ntransported efficiently in all phases. Smaller grains, however, experience\nsignificant destruction in the hotter phases. $0.001~{\\mu\\mathrm{m}}$ grains in\nparticular are quickly sputtered in all but the coolest gas, resulting in these\ngrains strongly tracing the cool phase in outflows. These results may also\nindicate the importance of in-situ formation mechanisms, such as shattering,\nfor the small dust grains and PAHs observed in emission throughout outflows in\nnearby galaxies. Surprisingly, we find that the hot phase dominates the\ntransport of dust that survives to populate the CGM.",
    "pdf_url": "http://arxiv.org/pdf/2505.11734v1",
    "published": "2025-05-16T22:37:41+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11733v2",
    "title": "MedCaseReasoning: Evaluating and learning diagnostic reasoning from clinical case reports",
    "authors": [
      "Kevin Wu",
      "Eric Wu",
      "Rahul Thapa",
      "Kevin Wei",
      "Angela Zhang",
      "Arvind Suresh",
      "Jacqueline J. Tao",
      "Min Woo Sun",
      "Alejandro Lozano",
      "James Zou"
    ],
    "abstract": "Doctors and patients alike increasingly use Large Language Models (LLMs) to\ndiagnose clinical cases. However, unlike domains such as math or coding, where\ncorrectness can be objectively defined by the final answer, medical diagnosis\nrequires both the outcome and the reasoning process to be accurate. Currently,\nwidely used medical benchmarks like MedQA and MMLU assess only accuracy in the\nfinal answer, overlooking the quality and faithfulness of the clinical\nreasoning process. To address this limitation, we introduce MedCaseReasoning,\nthe first open-access dataset for evaluating LLMs on their ability to align\nwith clinician-authored diagnostic reasoning. The dataset includes 14,489\ndiagnostic question-and-answer cases, each paired with detailed reasoning\nstatements derived from open-access medical case reports. We evaluate\nstate-of-the-art reasoning LLMs on MedCaseReasoning and find significant\nshortcomings in their diagnoses and reasoning: for instance, the top-performing\nopen-source model, DeepSeek-R1, achieves only 48% 10-shot diagnostic accuracy\nand mentions only 64% of the clinician reasoning statements (recall). However,\nwe demonstrate that fine-tuning LLMs on the reasoning traces derived from\nMedCaseReasoning significantly improves diagnostic accuracy and clinical\nreasoning recall by an average relative gain of 29% and 41%, respectively. The\nopen-source dataset, code, and models are available at\nhttps://github.com/kevinwu23/Stanford-MedCaseReasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.11733v2",
    "published": "2025-05-16T22:34:36+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11732v1",
    "title": "Role of Nematic Fluctuations on Superconductivity in FeSe$_{0.47}$Te$_{0.53}$ Revealed by NMR under Pressure",
    "authors": [
      "Qing-Ping Ding",
      "Juan Schmidt",
      "Jose A. Moreno",
      "Sergey L. Bud'ko",
      "Paul C. Canfield",
      "Yuji Furukawa"
    ],
    "abstract": "The relationship between antiferromagnetic (AFM) spin fluctuations (SF),\nnematic fluctuations, and superconductivity (SC) has been central to\nunderstanding the pairing mechanism in iron-based superconductors (IBSCs). Iron\nchalcogenides, which hold the simplest crystal structure in IBSCs, provide a\ngood platform to investigate the relationship. Here, we report $^{77}$Se and\n$^{125}$Te nuclear magnetic resonance studies of FeSe$_{0.47}$Te$_{0.53}$,\nwhich is located close to a nematic quantum critical point (QCP), under\npressures up to 1.35 GPa. Both the superconducting critical temperature and\nAFMSF were found to be enhanced under pressure, which suggests a correlation\nbetween SC and AFMSF in FeSe$_{0.47}$Te$_{0.53}$. However, the contribution of\nAFMSF to SC in FeSe$_{0.47}$Te$_{0.53}$ was found to be much less compared to\nthat in FeSe$_{1-x}$S$_{x}$, suggesting that nematic fluctuations play a\ndominant role in the SC in FeSe$_{1-x}$Te$_{x}$ around the nematic QCP.",
    "pdf_url": "http://arxiv.org/pdf/2505.11732v1",
    "published": "2025-05-16T22:30:09+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.11731v2",
    "title": "Efficient Uncertainty Estimation via Distillation of Bayesian Large Language Models",
    "authors": [
      "Harshil Vejendla",
      "Haizhou Shi",
      "Yibin Wang",
      "Tunyu Zhang",
      "Huan Zhang",
      "Hao Wang"
    ],
    "abstract": "Recent advances in uncertainty estimation for Large Language Models (LLMs)\nduring downstream adaptation have addressed key challenges of reliability and\nsimplicity. However, existing Bayesian methods typically require multiple\nsampling iterations during inference, creating significant efficiency issues\nthat limit practical deployment. In this paper, we investigate the possibility\nof eliminating the need for test-time sampling for LLM uncertainty estimation.\nSpecifically, when given an off-the-shelf Bayesian LLM, we distill its aligned\nconfidence into a non-Bayesian student LLM by minimizing the divergence between\ntheir predictive distributions. Unlike typical calibration methods, our\ndistillation is carried out solely on the training dataset without the need of\nan additional validation dataset. This simple yet effective approach achieves\nN-times more efficient uncertainty estimation during testing, where N is the\nnumber of samples traditionally required by Bayesian LLMs. Our extensive\nexperiments demonstrate that uncertainty estimation capabilities on training\ndata can successfully generalize to unseen test data through our distillation\ntechnique, consistently producing results comparable to (or even better than)\nstate-of-the-art Bayesian LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11731v2",
    "published": "2025-05-16T22:26:03+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11730v1",
    "title": "Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling",
    "authors": [
      "Hao Mark Chen",
      "Guanxi Lu",
      "Yasuyuki Okoshi",
      "Zhiwen Mo",
      "Masato Motomura",
      "Hongxiang Fan"
    ],
    "abstract": "Test-time scaling (TTS) has proven effective in enhancing the reasoning\ncapabilities of large language models (LLMs). Verification plays a key role in\nTTS, simultaneously influencing (1) reasoning performance and (2) compute\nefficiency, due to the quality and computational cost of verification. In this\nwork, we challenge the conventional paradigms of verification, and make the\nfirst attempt toward systematically investigating the impact of verification\ngranularity-that is, how frequently the verifier is invoked during generation,\nbeyond verifying only the final output or individual generation steps. To this\nend, we introduce Variable Granularity Search (VG-Search), a unified algorithm\nthat generalizes beam search and Best-of-N sampling via a tunable granularity\nparameter g. Extensive experiments with VG-Search under varying compute\nbudgets, generator-verifier configurations, and task attributes reveal that\ndynamically selecting g can improve the compute efficiency and scaling\nbehavior. Building on these findings, we propose adaptive VG-Search strategies\nthat achieve accuracy gains of up to 3.1\\% over Beam Search and 3.6\\% over\nBest-of-N, while reducing FLOPs by over 52\\%. We will open-source the code to\nsupport future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.11730v1",
    "published": "2025-05-16T22:24:48+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11729v1",
    "title": "Neural Importance Sampling of Many Lights",
    "authors": [
      "Pedro Figueiredo",
      "Qihao He",
      "Steve Bako",
      "Nima Khademi Kalantari"
    ],
    "abstract": "We propose a neural approach for estimating spatially varying light selection\ndistributions to improve importance sampling in Monte Carlo rendering,\nparticularly for complex scenes with many light sources. Our method uses a\nneural network to predict the light selection distribution at each shading\npoint based on local information, trained by minimizing the KL-divergence\nbetween the learned and target distributions in an online manner. To\nefficiently manage hundreds or thousands of lights, we integrate our neural\napproach with light hierarchy techniques, where the network predicts\ncluster-level distributions and existing methods sample lights within clusters.\nAdditionally, we introduce a residual learning strategy that leverages initial\ndistributions from existing techniques, accelerating convergence during\ntraining. Our method achieves superior performance across diverse and\nchallenging scenes.",
    "pdf_url": "http://arxiv.org/pdf/2505.11729v1",
    "published": "2025-05-16T22:23:34+00:00",
    "categories": [
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11728v2",
    "title": "Nitrogen-Vacancy Magnetometry of Edge Magnetism in WS2 Flakes",
    "authors": [
      "Ilja Fescenko",
      "Raman Kumar",
      "Thitinun Gas-Osoth",
      "Yifei Wang",
      "Suvechhya Lamichhane",
      "Tianlin Li",
      "Adam Erickson",
      "Nina Raghavan",
      "Tom Delord",
      "Cory D. Cress",
      "Nicholas Proscia",
      "Samuel W. LaGasse",
      "Sy-Hwang Liou",
      "Xia Hong",
      "Jose J. Fonseca",
      "Toshu An",
      "Carlos A. Meriles",
      "Abdelghani Laraoui"
    ],
    "abstract": "Two-dimensional (2D) magnets are of significant interest both as a platform\nfor exploring novel fundamental physics and for their potential in spintronic\nand optoelectronic devices. Recent bulk magnetometry studies have indicated a\nweak ferromagnetic response in WS2, and theoretical predictions suggest\nedge-localized magnetization in flakes with partial hydrogenation. Here, we use\nroom-temperature wide-field quantum diamond magnetometry to image pristine and\nFe-implanted WS2 flakes of varying thicknesses (45-160 nm), exfoliated from\nbulk crystals and transferred to NV-doped diamond substrates. We observe direct\nevidence of edge-localized stray magnetic fields, which scale linearly with\napplied external magnetic field (4.4-220 mT), reaching up to 4.7 uT. The edge\nsignal shows a limited dependence on the flake thickness, consistent with\ndipolar field decay and sensing geometry. Magnetic simulations using five\nalternative models favor the presence of edge magnetization aligned along an\naxis slightly tilted from the normal to the WS2 flake plane, consistent with\nspin canting in antiferromagnetically coupled edge states. Our findings\nestablish WS2 as a promising platform for edge-controlled 2D spintronics.",
    "pdf_url": "http://arxiv.org/pdf/2505.11728v2",
    "published": "2025-05-16T22:22:43+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2507.18450v1",
    "title": "High-Dimensional Data Classification in Concentric Coordinates",
    "authors": [
      "Alice Williams",
      "Boris Kovalerchuk"
    ],
    "abstract": "The visualization of multi-dimensional data with interpretable methods\nremains limited by capabilities for both high-dimensional lossless\nvisualizations that do not suffer from occlusion and that are computationally\ncapable by parameterized visualization. This paper proposes a low to high\ndimensional data supporting framework using lossless Concentric Coordinates\nthat are a more compact generalization of Parallel Coordinates along with\nformer Circular Coordinates. These are forms of the General Line Coordinate\nvisualizations that can directly support machine learning algorithm\nvisualization and facilitate human interaction.",
    "pdf_url": "http://arxiv.org/pdf/2507.18450v1",
    "published": "2025-05-16T22:22:05+00:00",
    "categories": [
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11727v2",
    "title": "Pseudogap in electron-doped cuprates: thermal precursor to magnetism",
    "authors": [
      "Emmanouil K. Kokkinis",
      "Andrey V. Chubukov"
    ],
    "abstract": "We study pseudogap behavior in a metal near an antiferromagnetic instability\nand apply the results to electron-doped cuprates. We associate pseudogap\nbehavior with thermal magnetic fluctuations and compute the fermionic\nself-energy along the Fermi surface beyond Eliashberg approximation. We analyze\nthe spectral function as a function of frequency (energy distribution curves,\nEDC) and momentum (momentum distribution curves, MDC). We show that the EDC\ndisplay pseudogap behavior with peaks at a finite frequency at all momenta. On\nthe other hand, MDC peaks disperse within the pseudogap, ending at a gossamer\nFermi surface. We analyze magnetically-mediated superconductivity and show that\nthermal fluctuations almost cancel out in the gap equation, even when the\nself-energy is obtained beyond the Eliashberg approximation. We favorably\ncompare our results with recent ARPES study [K-J Xu et al, Nat. Phys. 19,\n1834-1840 (2023)].",
    "pdf_url": "http://arxiv.org/pdf/2505.11727v2",
    "published": "2025-05-16T22:21:16+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.11726v2",
    "title": "Disambiguating Reference in Visually Grounded Dialogues through Joint Modeling of Textual and Multimodal Semantic Structures",
    "authors": [
      "Shun Inadumi",
      "Nobuhiro Ueda",
      "Koichiro Yoshino"
    ],
    "abstract": "Multimodal reference resolution, including phrase grounding, aims to\nunderstand the semantic relations between mentions and real-world objects.\nPhrase grounding between images and their captions is a well-established task.\nIn contrast, for real-world applications, it is essential to integrate textual\nand multimodal reference resolution to unravel the reference relations within\ndialogue, especially in handling ambiguities caused by pronouns and ellipses.\nThis paper presents a framework that unifies textual and multimodal reference\nresolution by mapping mention embeddings to object embeddings and selecting\nmentions or objects based on their similarity. Our experiments show that\nlearning textual reference resolution, such as coreference resolution and\npredicate-argument structure analysis, positively affects performance in\nmultimodal reference resolution. In particular, our model with coreference\nresolution performs better in pronoun phrase grounding than representative\nmodels for this task, MDETR and GLIP. Our qualitative analysis demonstrates\nthat incorporating textual reference relations strengthens the confidence\nscores between mentions, including pronouns and predicates, and objects, which\ncan reduce the ambiguities that arise in visually grounded dialogues.",
    "pdf_url": "http://arxiv.org/pdf/2505.11726v2",
    "published": "2025-05-16T22:14:58+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11725v1",
    "title": "CLT and Edgeworth Expansion for m-out-of-n Bootstrap Estimators of The Studentized Median",
    "authors": [
      "Imon Banerjee",
      "Sayak Chakrabarty"
    ],
    "abstract": "The m-out-of-n bootstrap, originally proposed by Bickel, Gotze, and Zwet\n(1992), approximates the distribution of a statistic by repeatedly drawing m\nsubsamples (with m much smaller than n) without replacement from an original\nsample of size n. It is now routinely used for robust inference with\nheavy-tailed data, bandwidth selection, and other large-sample applications.\nDespite its broad applicability across econometrics, biostatistics, and machine\nlearning, rigorous parameter-free guarantees for the soundness of the\nm-out-of-n bootstrap when estimating sample quantiles have remained elusive.\n  This paper establishes such guarantees by analyzing the estimator of sample\nquantiles obtained from m-out-of-n resampling of a dataset of size n. We first\nprove a central limit theorem for a fully data-driven version of the estimator\nthat holds under a mild moment condition and involves no unknown nuisance\nparameters. We then show that the moment assumption is essentially tight by\nconstructing a counter-example in which the CLT fails. Strengthening the\nassumptions slightly, we derive an Edgeworth expansion that provides exact\nconvergence rates and, as a corollary, a Berry Esseen bound on the bootstrap\napproximation error. Finally, we illustrate the scope of our results by\nderiving parameter-free asymptotic distributions for practical statistics,\nincluding the quantiles for random walk Metropolis-Hastings and the rewards of\nergodic Markov decision processes, thereby demonstrating the usefulness of our\ntheory in modern estimation and learning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11725v1",
    "published": "2025-05-16T22:14:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "math.ST",
      "stat.ME",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01986v1",
    "title": "SpecMemo: Speculative Decoding is in Your Pocket",
    "authors": [
      "Selin Yildirim",
      "Deming Chen"
    ],
    "abstract": "Recent advancements in speculative decoding have demonstrated considerable\nspeedup across a wide array of large language model (LLM) tasks. Speculative\ndecoding inherently relies on sacrificing extra memory allocations to generate\nseveral candidate tokens, of which acceptance rate drives the speedup. However,\ndeploying speculative decoding on memory-constrained devices, such as mobile\nGPUs, remains as a significant challenge in real-world scenarios. In this work,\nwe present a device-aware inference engine named SpecMemo that can smartly\ncontrol memory allocations at finer levels to enable multi-turn chatbots with\nspeculative decoding on such limited memory devices. Our methodology stems from\ntheoretically modeling memory footprint of speculative decoding to determine a\nlower bound on the required memory budget while retaining speedup. SpecMemo\nempirically acquires a careful balance between minimizing redundant memory\nallocations for rejected candidate tokens and maintaining competitive\nperformance gains from speculation. Notably, with SpecMemo's memory management,\nwe maintain 96% of overall throughput from speculative decoding on MT-Bench,\nwith reduced generation-memory by 65% on single Nvidia Titan RTX. Given\nmultiple constrained GPUs, we build on top of previous speculative decoding\narchitectures to facilitate big-model inference by distributing\nLlama-2-70B-Chat model, on which we provide novel batched speculative decoding\nto increase usability of multiple small server GPUs. This novel framework\ndemonstrates 2x speedup over distributed and batched vanilla decoding with the\nbase model on eight AMD MI250 GPUs. Moreover, inference throughput increases\nremarkably 8x with batch size 10. Our work contributes to democratized LLM\napplications in resource-constrained environments, providing a pathway for\nfaster and cheaper deployment of real-world LLM applications with robust\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2506.01986v1",
    "published": "2025-05-16T22:12:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11724v1",
    "title": "Semantically-Aware Game Image Quality Assessment",
    "authors": [
      "Kai Zhu",
      "Vignesh Edithal",
      "Le Zhang",
      "Ilia Blank",
      "Imran Junejo"
    ],
    "abstract": "Assessing the visual quality of video game graphics presents unique\nchallenges due to the absence of reference images and the distinct types of\ndistortions, such as aliasing, texture blur, and geometry level of detail (LOD)\nissues, which differ from those in natural images or user-generated content.\nExisting no-reference image and video quality assessment (NR-IQA/VQA) methods\nfail to generalize to gaming environments as they are primarily designed for\ndistortions like compression artifacts. This study introduces a\nsemantically-aware NR-IQA model tailored to gaming. The model employs a\nknowledge-distilled Game distortion feature extractor (GDFE) to detect and\nquantify game-specific distortions, while integrating semantic gating via CLIP\nembeddings to dynamically weight feature importance based on scene content.\nTraining on gameplay data recorded across graphical quality presets enables the\nmodel to produce quality scores that align with human perception. Our results\ndemonstrate that the GDFE, trained through knowledge distillation from binary\nclassifiers, generalizes effectively to intermediate distortion levels unseen\nduring training. Semantic gating further improves contextual relevance and\nreduces prediction variance. In the absence of in-domain NR-IQA baselines, our\nmodel outperforms out-of-domain methods and exhibits robust, monotonic quality\ntrends across unseen games in the same genre. This work establishes a\nfoundation for automated graphical quality assessment in gaming, advancing\nNR-IQA methods in this domain.",
    "pdf_url": "http://arxiv.org/pdf/2505.11724v1",
    "published": "2025-05-16T22:12:19+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11723v1",
    "title": "Introduction to Quantum Combinatorics",
    "authors": [
      "Tomasz Maszczyk"
    ],
    "abstract": "We construct a topos of quantum sets and embed into it the classical topos of\nsets. We show that the internal logic of the topos of sets, when interpreted in\nthe topos of quantum sets, provides the Birkhoff-von Neumann quantum\npropositional calculus of idempotents in a canonical internal commutative\nalgebra of the topos of quantum sets. We extend this construction by allowing\nthe quantum counterpart of Boolean algebras of classical truth values which we\nintroduce and study in detail. We realize expected values of observables in\nquantum states in our topos of quantum sets as a tautological morphism from the\ncanonical internal commutative algebra to a canonical internal object of affine\nfunctions on quantum states. We show also that in our topos of quantum sets one\ncan speak about quantum quivers in the sense of Day-Street and Chikhladze.\nFinally, we provide a categorical derivation of the Leavitt path algebra of\nsuch a quantum quiver and relate it to the category of stable representations\nof the quiver. It is based on a categorification of the Cuntz-Pimsner algebra\nin the context of functor adjunctions replacing the customary use of Hilbert\nmodules.",
    "pdf_url": "http://arxiv.org/pdf/2505.11723v1",
    "published": "2025-05-16T22:10:56+00:00",
    "categories": [
      "math.CT",
      "math-ph",
      "math.MP",
      "math.OA"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11722v1",
    "title": "Explainable Machine Learning for Oxygen Diffusion in Perovskites and Pyrochlores",
    "authors": [
      "Grace M. Lu",
      "Dallas R. Trinkle"
    ],
    "abstract": "Explainable machine learning can help to discover new physical relationships\nfor material properties. To understand the material properties that govern the\nactivation energy for oxygen diffusion in perovskites and pyrochlores, we build\na database of experimental activation energies and apply a grouping algorithm\nto the material property features. These features are then used to fit seven\ndifferent machine learning models. An ensemble consensus determines that the\nmost important features for predicting the activation energy are the ionicity\nof the A-site bond and the partial pressure of oxygen for perovskites. For\npyrochlores, the two most important features are the A-site $s$ valence\nelectron count and the B-site electronegativity. The most important features\nare all constructed using the weighted averages of elemental metal properties,\ndespite weighted averages of the constituent binary oxides being included in\nour feature set. This is surprising because the material properties of the\nconstituent oxides are more similar to the experimentally measured properties\nof perovskites and pyrochlores than the features of the metals that are chosen.\nThe easy-to-measure features identified in this work enable rapid screening for\nnew materials with fast oxide-ion diffusivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.11722v1",
    "published": "2025-05-16T22:06:19+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11721v2",
    "title": "Variational principles for Hausdorff and packing dimensions of fractal percolation on self-affine sponges",
    "authors": [
      "Julien Barral",
      "Guilhem Brunet"
    ],
    "abstract": "We establish variational principles for the Hausdorff and packing dimensions\nof a class of statistically self-affine sponges, including in particular\nfractal percolation sets obtained from Bara\\'nski and Gatzouras-Lalley carpets\nand sponges. Our first step is to compute the Hausdorff and packing dimensions\nof non-degenerate inhomogeneous Mandelbrot measures supported on the associated\nrandom limit sets. This is not a straightforward combination of the existing\napproaches for the deterministic inhomogeneous Bernoulli measures and the\nMandelbrot measures on random Sierpi\\'nski sponges; it reveals new structural\nfeatures. The variational principles rely on a specific subclass of\ninhomogeneous Mandelbrot measures, which are connected to localized digit\nfrequencies in the underlying coding space. This connection makes it possible\nto construct effective coverings of the random limit set, leading to sharp\nupper bounds for its Hausdorff and packing dimensions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11721v2",
    "published": "2025-05-16T22:05:30+00:00",
    "categories": [
      "math.PR",
      "math.DS",
      "28A78, 28A80, 60F10, 60G42, 60G57, 60K40"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11720v1",
    "title": "UGoDIT: Unsupervised Group Deep Image Prior Via Transferable Weights",
    "authors": [
      "Shijun Liang",
      "Ismail R. Alkhouri",
      "Siddhant Gautam",
      "Qing Qu",
      "Saiprasad Ravishankar"
    ],
    "abstract": "Recent advances in data-centric deep generative models have led to\nsignificant progress in solving inverse imaging problems. However, these models\n(e.g., diffusion models (DMs)) typically require large amounts of fully sampled\n(clean) training data, which is often impractical in medical and scientific\nsettings such as dynamic imaging.\n  On the other hand, training-data-free approaches like the Deep Image Prior\n(DIP) do not require clean ground-truth images but suffer from noise\noverfitting and can be computationally expensive as the network parameters need\nto be optimized for each measurement set independently. Moreover, DIP-based\nmethods often overlook the potential of learning a prior using a small number\nof sub-sampled measurements (or degraded images) available during training. In\nthis paper, we propose UGoDIT, an Unsupervised Group DIP via Transferable\nweights, designed for the low-data regime where only a very small number, M, of\nsub-sampled measurement vectors are available during training. Our method\nlearns a set of transferable weights by optimizing a shared encoder and M\ndisentangled decoders. At test time, we reconstruct the unseen degraded image\nusing a DIP network, where part of the parameters are fixed to the learned\nweights, while the remaining are optimized to enforce measurement consistency.\nWe evaluate UGoDIT on both medical (multi-coil MRI) and natural (super\nresolution and non-linear deblurring) image recovery tasks under various\nsettings. Compared to recent standalone DIP methods, UGoDIT provides\naccelerated convergence and notable improvement in reconstruction quality.\nFurthermore, our method achieves performance competitive with SOTA DM-based and\nsupervised approaches, despite not requiring large amounts of clean training\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2505.11720v1",
    "published": "2025-05-16T22:05:28+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11719v1",
    "title": "Zero-Shot Visual Generalization in Robot Manipulation",
    "authors": [
      "Sumeet Batra",
      "Gaurav Sukhatme"
    ],
    "abstract": "Training vision-based manipulation policies that are robust across diverse\nvisual environments remains an important and unresolved challenge in robot\nlearning. Current approaches often sidestep the problem by relying on invariant\nrepresentations such as point clouds and depth, or by brute-forcing\ngeneralization through visual domain randomization and/or large, visually\ndiverse datasets. Disentangled representation learning - especially when\ncombined with principles of associative memory - has recently shown promise in\nenabling vision-based reinforcement learning policies to be robust to visual\ndistribution shifts. However, these techniques have largely been constrained to\nsimpler benchmarks and toy environments. In this work, we scale disentangled\nrepresentation learning and associative memory to more visually and dynamically\ncomplex manipulation tasks and demonstrate zero-shot adaptability to visual\nperturbations in both simulation and on real hardware. We further extend this\napproach to imitation learning, specifically Diffusion Policy, and empirically\nshow significant gains in visual generalization compared to state-of-the-art\nimitation learning methods. Finally, we introduce a novel technique adapted\nfrom the model equivariance literature that transforms any trained neural\nnetwork policy into one invariant to 2D planar rotations, making our policy not\nonly visually robust but also resilient to certain camera perturbations. We\nbelieve that this work marks a significant step towards manipulation policies\nthat are not only adaptable out of the box, but also robust to the complexities\nand dynamical nature of real-world deployment. Supplementary videos are\navailable at https://sites.google.com/view/vis-gen-robotics/home.",
    "pdf_url": "http://arxiv.org/pdf/2505.11719v1",
    "published": "2025-05-16T22:01:46+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11718v2",
    "title": "REMOR: Automated Peer Review Generation with LLM Reasoning and Multi-Objective Reinforcement Learning",
    "authors": [
      "Pawin Taechoyotin",
      "Daniel Acuna"
    ],
    "abstract": "AI-based peer review systems tend to produce shallow and overpraising\nsuggestions compared to human feedback. Here, we evaluate how well a reasoning\nLLM trained with multi-objective reinforcement learning (REMOR) can overcome\nthese limitations. We start by designing a multi-aspect reward function that\naligns with human evaluation of reviews. The aspects are related to the review\nitself (e.g., criticisms, novelty) and the relationship between the review and\nthe manuscript (i.e., relevance). First, we perform supervised fine-tuning of\nDeepSeek-R1-Distill-Qwen-7B using LoRA on PeerRT, a new dataset of high-quality\ntop AI conference reviews enriched with reasoning traces. We then apply Group\nRelative Policy Optimization (GRPO) to train two models: REMOR-H (with the\nhuman-aligned reward) and REMOR-U (with a uniform reward). Interestingly, the\nhuman-aligned reward penalizes aspects typically associated with strong\nreviews, leading REMOR-U to produce qualitatively more substantive feedback.\nOur results show that REMOR-U and REMOR-H achieve more than twice the average\nrewards of human reviews, non-reasoning state-of-the-art agentic multi-modal AI\nreview systems, and general commercial LLM baselines. We found that while the\nbest AI and human reviews are comparable in quality, REMOR avoids the long tail\nof low-quality human reviews. We discuss how reasoning is key to achieving\nthese improvements and release the Human-aligned Peer Review Reward (HPRR)\nfunction, the Peer Review Reasoning-enriched Traces (PeerRT) dataset, and the\nREMOR models, which we believe can help spur progress in the area.",
    "pdf_url": "http://arxiv.org/pdf/2505.11718v2",
    "published": "2025-05-16T22:00:49+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11717v3",
    "title": "WebInject: Prompt Injection Attack to Web Agents",
    "authors": [
      "Xilong Wang",
      "John Bloch",
      "Zedian Shao",
      "Yuepeng Hu",
      "Shuyan Zhou",
      "Neil Zhenqiang Gong"
    ],
    "abstract": "Multi-modal large language model (MLLM)-based web agents interact with\nwebpage environments by generating actions based on screenshots of the\nwebpages. In this work, we propose WebInject, a prompt injection attack that\nmanipulates the webpage environment to induce a web agent to perform an\nattacker-specified action. Our attack adds a perturbation to the raw pixel\nvalues of the rendered webpage. After these perturbed pixels are mapped into a\nscreenshot, the perturbation induces the web agent to perform the\nattacker-specified action. We formulate the task of finding the perturbation as\nan optimization problem. A key challenge in solving this problem is that the\nmapping between raw pixel values and screenshot is non-differentiable, making\nit difficult to backpropagate gradients to the perturbation. To overcome this,\nwe train a neural network to approximate the mapping and apply projected\ngradient descent to solve the reformulated optimization problem. Extensive\nevaluation on multiple datasets shows that WebInject is highly effective and\nsignificantly outperforms baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.11717v3",
    "published": "2025-05-16T22:00:26+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11716v2",
    "title": "Employing Laban Shape for Generating Emotionally and Functionally Expressive Trajectories in Robotic Manipulators",
    "authors": [
      "Srikrishna Bangalore Raghu",
      "Clare Lohrmann",
      "Akshay Bakshi",
      "Jennifer Kim",
      "Jose Caraveo Herrera",
      "Bradley Hayes",
      "Alessandro Roncone"
    ],
    "abstract": "Successful human-robot collaboration depends on cohesive communication and a\nprecise understanding of the robot's abilities, goals, and constraints. While\nrobotic manipulators offer high precision, versatility, and productivity, they\nexhibit expressionless and monotonous motions that conceal the robot's\nintention, resulting in a lack of efficiency and transparency with humans. In\nthis work, we use Laban notation, a dance annotation language, to enable\nrobotic manipulators to generate trajectories with functional expressivity,\nwhere the robot uses nonverbal cues to communicate its abilities and the\nlikelihood of succeeding at its task. We achieve this by introducing two novel\nvariants of Hesitant expressive motion (Spoke-Like and Arc-Like). We also\nenhance the emotional expressivity of four existing emotive trajectories\n(Happy, Sad, Shy, and Angry) by augmenting Laban Effort usage with Laban Shape.\nThe functionally expressive motions are validated via a human-subjects study,\nwhere participants equate both variants of Hesitant motion with reduced robot\ncompetency. The enhanced emotive trajectories are shown to be viewed as\ndistinct emotions using the Valence-Arousal-Dominance (VAD) spectrum,\ncorroborating the usage of Laban Shape.",
    "pdf_url": "http://arxiv.org/pdf/2505.11716v2",
    "published": "2025-05-16T21:58:19+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11715v2",
    "title": "ConflictLens: LLM-Based Conflict Resolution Training in Romantic Relationship",
    "authors": [
      "Jiwon Chun",
      "Gefei Zhang",
      "Meng Xia"
    ],
    "abstract": "Our poster presents ConflictLens, a three-stage simulation system powered by\nlarge language models (LLMs) and grounded in psychological theory, designed to\nhelp users reflect on and practice conflict resolution in romantic\nrelationships. Users can upload real conflict scenarios to receive evaluation\nof behavioral patterns, reflect on conflicts by annotating their negative\nbehaviors, and practice different conflict resolution strategies in\nAI-simulated duologues. Initial evaluation by three domain experts suggests\nthat ConflictLens offers a realistic experience and effectively supports\nself-guided reflection and communication practice in romantic relationships.",
    "pdf_url": "http://arxiv.org/pdf/2505.11715v2",
    "published": "2025-05-16T21:56:09+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11714v1",
    "title": "Bi-Level Policy Optimization with Nyström Hypergradients",
    "authors": [
      "Arjun Prakash",
      "Naicheng He",
      "Denizalp Goktas",
      "Amy Greenwald"
    ],
    "abstract": "The dependency of the actor on the critic in actor-critic (AC) reinforcement\nlearning means that AC can be characterized as a bilevel optimization (BLO)\nproblem, also called a Stackelberg game. This characterization motivates two\nmodifications to vanilla AC algorithms. First, the critic's update should be\nnested to learn a best response to the actor's policy. Second, the actor should\nupdate according to a hypergradient that takes changes in the critic's behavior\ninto account. Computing this hypergradient involves finding an inverse Hessian\nvector product, a process that can be numerically unstable. We thus propose a\nnew algorithm, Bilevel Policy Optimization with Nystr\\\"om Hypergradients\n(BLPO), which uses nesting to account for the nested structure of BLO, and\nleverages the Nystr\\\"om method to compute the hypergradient. Theoretically, we\nprove BLPO converges to (a point that satisfies the necessary conditions for) a\nlocal strong Stackelberg equilibrium in polynomial time with high probability,\nassuming a linear parametrization of the critic's objective. Empirically, we\ndemonstrate that BLPO performs on par with or better than PPO on a variety of\ndiscrete and continuous control tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11714v1",
    "published": "2025-05-16T21:56:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11713v1",
    "title": "Probing Nuclear Geometry through Multi-Particle Azimuthal Correlations and Rapidity-Even Dipolar Flow in ${}^{16}$O+${}^{16}$O Collisions",
    "authors": [
      "Kaiser Shafi",
      "Sandeep Chatterjee"
    ],
    "abstract": "We study symmetric and asymmetric cumulants as well as rapidity-even dipolar\nflow in ${}^{16}$O+${}^{16}$O collisions at $\\sqrt{s_{NN}} = 200$~GeV to\nexplore $\\alpha$-clustering phenomena in light nuclei within the viscous\nrelativistic hydrodynamics framework. Signatures of $\\alpha$-clustering\nmanifest in the anisotropic flow coefficients and their correlations --\nparticularly in observables involving elliptic-triangular flow correlations. We\nshow that final-state symmetric and asymmetric cumulants -- especially\n$\\mathrm{NSC}(2,3)$ and $\\mathrm{NAC}_{2,1}(2,3)$ -- are sensitive to the\ninitial nuclear geometry. Additionally, we observe a significant difference in\nrapidity-even dipolar flow, $v_1^{\\text{even}}$, between $\\alpha$-clustered and\nWoods--Saxon configurations in high-multiplicity events. These findings\nunderscore the pivotal role of nuclear structure in heavy-ion collision\ndynamics and provide observables for distinguishing nuclear geometries,\nparticularly in ultra-central collisions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11713v1",
    "published": "2025-05-16T21:50:23+00:00",
    "categories": [
      "nucl-th",
      "hep-ph"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11712v1",
    "title": "Mathematical models for the EP2 and EP4 signaling pathways and their crosstalk",
    "authors": [
      "Alessandra Cambi",
      "Diane S Lidke",
      "Mariya Ptashnyk",
      "Willemijn Smit",
      "Stefanie Sonner"
    ],
    "abstract": "The G-protein coupled receptors EP2 and EP4 both transduce the signal of the\nlipid messenger Prostaglandin E2 (PGE2). Changes in the cell response to PGE2\ncan have important effects on immunity and development of diseases, however, a\nthorough understanding of the EP2-EP4 receptors' signaling pathways is lacking.\nExperimental data show that receptor activity (indicated by cAMP expression)\nhas a different kinetics depending on which receptor is triggered by PGE2 and\nthat crosstalk exists between EP2 and EP4. To better understand the underlying\nmechanisms and be able to predict cell responses to PGE2, we develop novel\nmathematical models for the cAMP signaling pathways of EP2 and EP4 and their\ncrosstalk. Ligand binding dynamics plays a crucial role for both, the single\nreceptor activity and their crosstalk. The mathematical models can predict the\nqualitative cAMP levels observed experimentally and provide possible\nexplanations for the differences and commonalities in the signaling behavior of\nEP2 and EP4. As inhibition of PGE2 signaling is gaining increasing attention in\ntumor immunology, these mathematical models could contribute to design\neffective anti-tumor therapies targeting EP2 and EP4.",
    "pdf_url": "http://arxiv.org/pdf/2505.11712v1",
    "published": "2025-05-16T21:46:40+00:00",
    "categories": [
      "q-bio.MN",
      "q-bio.CB"
    ],
    "primary_category": "q-bio.MN"
  },
  {
    "id": "http://arxiv.org/abs/2505.11711v1",
    "title": "Reinforcement Learning Finetunes Small Subnetworks in Large Language Models",
    "authors": [
      "Sagnik Mukherjee",
      "Lifan Yuan",
      "Dilek Hakkani-Tur",
      "Hao Peng"
    ],
    "abstract": "Reinforcement learning (RL) yields substantial improvements in large language\nmodels (LLMs) downstream task performance and alignment with human values.\nSurprisingly, such large gains result from updating only a small subnetwork\ncomprising just 5 percent to 30 percent of the parameters, with the rest\neffectively unchanged. We refer to this phenomenon as parameter update sparsity\ninduced by RL. It is observed across all 7 widely used RL algorithms (e.g.,\nPPO, GRPO, DPO) and all 10 LLMs from different families in our experiments.\nThis sparsity is intrinsic and occurs without any explicit sparsity promoting\nregularizations or architectural constraints. Finetuning the subnetwork alone\nrecovers the test accuracy, and, remarkably, produces a model nearly identical\nto the one obtained via full finetuning. The subnetworks from different random\nseeds, training data, and even RL algorithms show substantially greater overlap\nthan expected by chance. Our analysis suggests that this sparsity is not due to\nupdating only a subset of layers, instead, nearly all parameter matrices\nreceive similarly sparse updates. Moreover, the updates to almost all parameter\nmatrices are nearly full-rank, suggesting RL updates a small subset of\nparameters that nevertheless span almost the full subspaces that the parameter\nmatrices can represent. We conjecture that the this update sparsity can be\nprimarily attributed to training on data that is near the policy distribution,\ntechniques that encourage the policy to remain close to the pretrained model,\nsuch as the KL regularization and gradient clipping, have limited impact.",
    "pdf_url": "http://arxiv.org/pdf/2505.11711v1",
    "published": "2025-05-16T21:42:28+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11710v1",
    "title": "Co-Evolutionary Defence of Active Directory Attack Graphs via GNN-Approximated Dynamic Programming",
    "authors": [
      "Diksha Goel",
      "Hussain Ahmad",
      "Kristen Moore",
      "Mingyu Guo"
    ],
    "abstract": "Modern enterprise networks increasingly rely on Active Directory (AD) for\nidentity and access management. However, this centralization exposes a single\npoint of failure, allowing adversaries to compromise high-value assets.\nExisting AD defense approaches often assume static attacker behavior, but\nreal-world adversaries adapt dynamically, rendering such methods brittle. To\naddress this, we model attacker-defender interactions in AD as a Stackelberg\ngame between an adaptive attacker and a proactive defender. We propose a\nco-evolutionary defense framework that combines Graph Neural Network\nApproximated Dynamic Programming (GNNDP) to model attacker strategies, with\nEvolutionary Diversity Optimization (EDO) to generate resilient blocking\nstrategies. To ensure scalability, we introduce a Fixed-Parameter Tractable\n(FPT) graph reduction method that reduces complexity while preserving strategic\nstructure. Our framework jointly refines attacker and defender policies to\nimprove generalization and prevent premature convergence. Experiments on\nsynthetic AD graphs show near-optimal results (within 0.1 percent of optimality\non r500) and improved performance on larger graphs (r1000 and r2000),\ndemonstrating the framework's scalability and effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.11710v1",
    "published": "2025-05-16T21:37:50+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11709v2",
    "title": "EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video",
    "authors": [
      "Ryan Hoque",
      "Peide Huang",
      "David J. Yoon",
      "Mouli Sivapurapu",
      "Jian Zhang"
    ],
    "abstract": "Imitation learning for manipulation has a well-known data scarcity problem.\nUnlike natural language and 2D computer vision, there is no Internet-scale\ncorpus of data for dexterous manipulation. One appealing option is egocentric\nhuman video, a passively scalable data source. However, existing large-scale\ndatasets such as Ego4D do not have native hand pose annotations and do not\nfocus on object manipulation. To this end, we use Apple Vision Pro to collect\nEgoDex: the largest and most diverse dataset of dexterous human manipulation to\ndate. EgoDex has 829 hours of egocentric video with paired 3D hand and finger\ntracking data collected at the time of recording, where multiple calibrated\ncameras and on-device SLAM can be used to precisely track the pose of every\njoint of each hand. The dataset covers a wide range of diverse manipulation\nbehaviors with everyday household objects in 194 different tabletop tasks\nranging from tying shoelaces to folding laundry. Furthermore, we train and\nsystematically evaluate imitation learning policies for hand trajectory\nprediction on the dataset, introducing metrics and benchmarks for measuring\nprogress in this increasingly important area. By releasing this large-scale\ndataset, we hope to push the frontier of robotics, computer vision, and\nfoundation models. EgoDex is publicly available for download at\nhttps://github.com/apple/ml-egodex.",
    "pdf_url": "http://arxiv.org/pdf/2505.11709v2",
    "published": "2025-05-16T21:34:47+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.20302v2",
    "title": "VeriThoughts: Enabling Automated Verilog Code Generation using Reasoning and Formal Verification",
    "authors": [
      "Patrick Yubeaton",
      "Andre Nakkab",
      "Weihua Xiao",
      "Luca Collini",
      "Ramesh Karri",
      "Chinmay Hegde",
      "Siddharth Garg"
    ],
    "abstract": "This paper introduces VeriThoughts, a novel dataset designed for\nreasoning-based Verilog code generation. We establish a new benchmark framework\ngrounded in formal verification methods to evaluate the quality and correctness\nof generated hardware descriptions. Additionally, we present a suite of\nspecialized small-scale models optimized specifically for Verilog generation.\nOur work addresses the growing need for automated hardware design tools that\ncan produce verifiably correct implementations from high-level specifications,\npotentially accelerating the hardware development process while maintaining\nrigorous correctness guarantees. Our code and data are available at\n\\href{https://github.com/wilyub/VeriThoughts}{this URL}.",
    "pdf_url": "http://arxiv.org/pdf/2505.20302v2",
    "published": "2025-05-16T21:33:14+00:00",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11708v1",
    "title": "Unveiling the Black Box: A Multi-Layer Framework for Explaining Reinforcement Learning-Based Cyber Agents",
    "authors": [
      "Diksha Goel",
      "Kristen Moore",
      "Jeff Wang",
      "Minjune Kim",
      "Thanh Thi Nguyen"
    ],
    "abstract": "Reinforcement Learning (RL) agents are increasingly used to simulate\nsophisticated cyberattacks, but their decision-making processes remain opaque,\nhindering trust, debugging, and defensive preparedness. In high-stakes\ncybersecurity contexts, explainability is essential for understanding how\nadversarial strategies are formed and evolve over time. In this paper, we\npropose a unified, multi-layer explainability framework for RL-based attacker\nagents that reveals both strategic (MDP-level) and tactical (policy-level)\nreasoning. At the MDP level, we model cyberattacks as a Partially Observable\nMarkov Decision Processes (POMDPs) to expose exploration-exploitation dynamics\nand phase-aware behavioural shifts. At the policy level, we analyse the\ntemporal evolution of Q-values and use Prioritised Experience Replay (PER) to\nsurface critical learning transitions and evolving action preferences.\nEvaluated across CyberBattleSim environments of increasing complexity, our\nframework offers interpretable insights into agent behaviour at scale. Unlike\nprevious explainable RL methods, which are often post-hoc, domain-specific, or\nlimited in depth, our approach is both agent- and environment-agnostic,\nsupporting use cases ranging from red-team simulation to RL policy debugging.\nBy transforming black-box learning into actionable behavioural intelligence,\nour framework enables both defenders and developers to better anticipate,\nanalyse, and respond to autonomous cyber threats.",
    "pdf_url": "http://arxiv.org/pdf/2505.11708v1",
    "published": "2025-05-16T21:29:55+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11707v1",
    "title": "Attend to Not Attended: Structure-then-Detail Token Merging for Post-training DiT Acceleration",
    "authors": [
      "Haipeng Fang",
      "Sheng Tang",
      "Juan Cao",
      "Enshuo Zhang",
      "Fan Tang",
      "Tong-Yee Lee"
    ],
    "abstract": "Diffusion transformers have shown exceptional performance in visual\ngeneration but incur high computational costs. Token reduction techniques that\ncompress models by sharing the denoising process among similar tokens have been\nintroduced. However, existing approaches neglect the denoising priors of the\ndiffusion models, leading to suboptimal acceleration and diminished image\nquality. This study proposes a novel concept: attend to prune feature\nredundancies in areas not attended by the diffusion process. We analyze the\nlocation and degree of feature redundancies based on the structure-then-detail\ndenoising priors. Subsequently, we introduce SDTM, a structure-then-detail\ntoken merging approach that dynamically compresses feature redundancies.\nSpecifically, we design dynamic visual token merging, compression ratio\nadjusting, and prompt reweighting for different stages. Served in a\npost-training way, the proposed method can be integrated seamlessly into any\nDiT architecture. Extensive experiments across various backbones, schedulers,\nand datasets showcase the superiority of our method, for example, it achieves\n1.55 times acceleration with negligible impact on image quality. Project page:\nhttps://github.com/ICTMCG/SDTM.",
    "pdf_url": "http://arxiv.org/pdf/2505.11707v1",
    "published": "2025-05-16T21:27:38+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11706v1",
    "title": "Forensics of Error Rates of Quantum Hardware",
    "authors": [
      "Rupshali Roy",
      "Swaroop Ghosh"
    ],
    "abstract": "There has been a rise in third-party cloud providers offering quantum\nhardware as a service to improve performance at lower cost. Although these\nproviders provide flexibility to the users to choose from several qubit\ntechnologies, quantum hardware, and coupling maps; the actual execution of the\nprogram is not clearly visible to the customer. The success of the user\nprogram, in addition to various other metadata such as cost, performance, &\nnumber of iterations to converge, depends on the error rate of the backend\nused. Moreover, the third-party provider and/or tools (e.g., hardware allocator\nand mapper) may hold insider/outsider adversarial agents to conserve resources\nand maximize profit by running the quantum circuits on error-prone hardware.\nThus it is important to gain visibility of the backend from various\nperspectives of the computing process e.g., execution, transpilation and\noutcomes. In this paper, we estimate the error rate of the backend from the\noriginal and transpiled circuit. For the forensics, we exploit the fact that\nqubit mapping and routing steps of the transpilation process select qubits and\nqubit pairs with less single qubit and two-qubit gate errors to minimize\noverall error accumulation, thereby, giving us clues about the error rates of\nthe various parts of the backend. We ranked qubit links into bins based on ECR\nerror rates publicly available, and compared it to the rankings derived from\nour investigation of the relative frequency of a qubit link being chosen by the\ntranspiler. For upto 83.5% of the qubit links in IBM Sherbrooke and 80% in IBM\nBrisbane, 127 qubit IBM backends, we are able to assign a bin rank which has a\ndifference upto 2 with the bin rank assigned on the basis of actual error rate\ninformation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11706v1",
    "published": "2025-05-16T21:25:12+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01985v1",
    "title": "$whittlehurst$: A Python package implementing Whittle's likelihood estimation of the Hurst exponent",
    "authors": [
      "Bálint Csanády",
      "Lóránt Nagy",
      "András Lukács"
    ],
    "abstract": "This paper presents $whittlehurst$, a Python package implementing Whittle's\nlikelihood method for estimating the Hurst exponent in fractional Brownian\nmotion (fBm). While the theoretical foundations of Whittle's estimator are\nwell-established, practical and computational considerations are critical for\neffective use. We focus explicitly on assessing our implementation's\nperformance across several numerical approximations of the fractional Gaussian\nnoise (fGn) spectral density, comparing their computational efficiency,\naccuracy, and consistency across varying input sequence lengths. Extensive\nempirical evaluations show that our implementation achieves state-of-the-art\nestimation accuracy and computational speed. Additionally, we benchmark our\nmethod against other popular Hurst exponent estimation techniques on synthetic\nand real-world data, emphasizing practical considerations that arise when\napplying these estimators to financial and biomedical data.",
    "pdf_url": "http://arxiv.org/pdf/2506.01985v1",
    "published": "2025-05-16T21:24:43+00:00",
    "categories": [
      "stat.CO",
      "stat.ML",
      "60G22",
      "G.3; G.4"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11705v1",
    "title": "Consistency of Bayes factors for linear models",
    "authors": [
      "Elías Moreno",
      "J. J. Serrano-Pérez",
      "F. Torres-Ruiz"
    ],
    "abstract": "The quality of a Bayes factor crucially depends on the number of regressors,\nthe sample size and the prior on the regression parameters, and hence it has to\nbe established in a case-by-case basis. In this paper we analyze the\nconsistency of a wide class of Bayes factors when the number of potential\nregressors grows as the sample size grows. We have found that when the number\nof regressors is finite some classes of priors yield inconsistency, and\\ when\nthe potential number of regressors grows at the same rate than the sample size\ndifferent priors yield different degree of inconsistency. For moderate sample\nsizes, we evaluate the Bayes factors by comparing the posterior model\nprobability. This gives valuable information to discriminate between the priors\nfor the model parameters commonly used for variable selection.",
    "pdf_url": "http://arxiv.org/pdf/2505.11705v1",
    "published": "2025-05-16T21:22:46+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.11704v1",
    "title": "Photonic Networking of Quantum Memories in High-Dimensions",
    "authors": [
      "Mikhail Shalaev",
      "Sagnik Saha",
      "George Toh",
      "Isabella Goetting",
      "Ashish Kalakuntla",
      "Harriet Bufan Shi",
      "Jameson O'Reilly",
      "Yichao Yu",
      "Christopher Monroe"
    ],
    "abstract": "Quantum networking enables the exchange of quantum information between\nphysically separated quantum systems, which has applications ranging from\nquantum computing to unconditionally secure communication. Such quantum\ninformation is generally represented by two-level quantum systems or qubits.\nHere, we demonstrate a quantum network of high-dimensional (HD) quantum\nmemories or ``qudits\" stored in individual atoms. The interference and\ndetection of HD time-bin encoded single photons emitted from atomic qudit\nmemories heralds maximally-entangled Bell states across pairs of atomic qudit\nlevels. This approach expands the quantum information capacity of a quantum\nnetwork while improving the entanglement success fraction beyond the standard\n50\\% limit of qubit-based measurement protocols.",
    "pdf_url": "http://arxiv.org/pdf/2505.11704v1",
    "published": "2025-05-16T21:21:33+00:00",
    "categories": [
      "quant-ph",
      "physics.atom-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11703v1",
    "title": "LoFT: LoRA-fused Training Dataset Generation with Few-shot Guidance",
    "authors": [
      "Jae Myung Kim",
      "Stephan Alaniz",
      "Cordelia Schmid",
      "Zeynep Akata"
    ],
    "abstract": "Despite recent advances in text-to-image generation, using synthetically\ngenerated data seldom brings a significant boost in performance for supervised\nlearning. Oftentimes, synthetic datasets do not faithfully recreate the data\ndistribution of real data, i.e., they lack the fidelity or diversity needed for\neffective downstream model training. While previous work has employed few-shot\nguidance to address this issue, existing methods still fail to capture and\ngenerate features unique to specific real images. In this paper, we introduce a\nnovel dataset generation framework named LoFT, LoRA-Fused Training-data\nGeneration with Few-shot Guidance. Our method fine-tunes LoRA weights on\nindividual real images and fuses them at inference time, producing synthetic\nimages that combine the features of real images for improved diversity and\nfidelity of generated data. We evaluate the synthetic data produced by LoFT on\n10 datasets, using 8 to 64 real images per class as guidance and scaling up to\n1000 images per class. Our experiments show that training on LoFT-generated\ndata consistently outperforms other synthetic dataset methods, significantly\nincreasing accuracy as the dataset size increases. Additionally, our analysis\ndemonstrates that LoFT generates datasets with high fidelity and sufficient\ndiversity, which contribute to the performance improvement. The code is\navailable at https://github.com/ExplainableML/LoFT.",
    "pdf_url": "http://arxiv.org/pdf/2505.11703v1",
    "published": "2025-05-16T21:17:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11702v1",
    "title": "Invariant Representations via Wasserstein Correlation Maximization",
    "authors": [
      "Keenan Eikenberry",
      "Lizuo Liu",
      "Yoonsang Lee"
    ],
    "abstract": "This work investigates the use of Wasserstein correlation -- a normalized\nmeasure of statistical dependence based on the Wasserstein distance between a\njoint distribution and the product of its marginals -- for unsupervised\nrepresentation learning. Unlike, for example, contrastive methods, which\nnaturally cluster classes in the latent space, we find that an (auto)encoder\ntrained to maximize Wasserstein correlation between the input and encoded\ndistributions instead acts as a compressor, reducing dimensionality while\napproximately preserving the topological and geometric properties of the input\ndistribution. More strikingly, we show that Wasserstein correlation\nmaximization can be used to arrive at an (auto)encoder -- either trained from\nscratch, or else one that extends a frozen, pretrained model -- that is\napproximately invariant to a chosen augmentation, or collection of\naugmentations, and that still approximately preserves the structural properties\nof the non-augmented input distribution. To do this, we first define the notion\nof an augmented encoder using the machinery of Markov-Wasserstein kernels. When\nthe maximization objective is then applied to the augmented encoder, as opposed\nto the underlying, deterministic encoder, the resulting model exhibits the\ndesired invariance properties. Finally, besides our experimental results, which\nshow that even simple feedforward networks can be imbued with invariants or\ncan, alternatively, be used to impart invariants to pretrained models under\nthis training process, we additionally establish various theoretical results\nfor optimal transport-based dependence measures. Code is available at\nhttps://github.com/keenan-eikenberry/wasserstein_correlation_maximization .",
    "pdf_url": "http://arxiv.org/pdf/2505.11702v1",
    "published": "2025-05-16T21:11:51+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11701v2",
    "title": "DMN-Guided Prompting: A Framework for Controlling LLM Behavior",
    "authors": [
      "Shaghayegh Abedi",
      "Amin Jalali"
    ],
    "abstract": "Large Language Models (LLMs) have shown considerable potential in automating\ndecision logic within knowledge-intensive processes. However, their\neffectiveness largely depends on the strategy and quality of prompting. Since\ndecision logic is typically embedded in prompts, it becomes challenging for end\nusers to modify or refine it. Decision Model and Notation (DMN) offers a\nstandardized graphical approach for defining decision logic in a structured,\nuser-friendly manner. This paper introduces a DMN-guided prompting framework\nthat breaks down complex decision logic into smaller, manageable components,\nguiding LLMs through structured decision pathways. We implemented the framework\nin a graduate-level course where students submitted assignments. The\nassignments and DMN models representing feedback instructions served as inputs\nto our framework. The instructor evaluated the generated feedback and labeled\nit for performance assessment. Our approach demonstrated promising results,\noutperforming chain-of-thought (CoT) prompting in our case study. Students also\nresponded positively to the generated feedback, reporting high levels of\nperceived usefulness in a survey based on the Technology Acceptance Model.",
    "pdf_url": "http://arxiv.org/pdf/2505.11701v2",
    "published": "2025-05-16T21:09:36+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11700v1",
    "title": "Distribution of the cokernels of determinantal row-sparse matrices",
    "authors": [
      "Jungin Lee",
      "Myungjun Yu"
    ],
    "abstract": "We study the distribution of the cokernels of random row-sparse integral\nmatrices $A_n$ according to the determinantal measure from a structured matrix\n$B_n$ with a parameter $k_n \\ge 3$. Under a mild assumption on the growth rate\nof $k_n$, we prove that the distribution of the $p$-Sylow subgroup of the\ncokernel of $A_n$ converges to that of Cohen--Lenstra for every prime $p$. Our\nresult extends the work of A. M\\'esz\\'aros which established convergence to the\nCohen--Lenstra distribution when $p \\ge 5$ and $k_n=3$ for all positive\nintegers $n$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11700v1",
    "published": "2025-05-16T21:08:36+00:00",
    "categories": [
      "math.PR",
      "math.CO",
      "math.NT"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11699v1",
    "title": "Water Production Rates from SOHO/SWAN Observations of Comets C/2017 K2 (PanSTARRS) and C/2022 E3 (ZTF)",
    "authors": [
      "Michael Combi",
      "Terhi Mäkinen",
      "Jean-Loup Bertaux",
      "Eric Quemerais",
      "Stéphane Ferron"
    ],
    "abstract": "In 2022 and 2023 the hydrogen comae of two long period comets, C/2017 K2\n(PanSTARRS) and C/2022 E3 (ZTF), were observed with the Solar Wind ANisotropies\n(SWAN) all-sky hydrogen Lyman-alpha camera on the SOlar and Heliosphere\nObserver (SOHO) satellite. SWAN obtains nearly daily full-sky images of the\nhydrogen Lyman-alpha distribution of the interstellar hydrogen as it passes\nthrough the solar system yielding information about the solar wind and solar\nultraviolet fluxes that eat away at it by ionization and charge exchange. The\nhydrogen comae of comets, when of sufficient brightness, are also observed.\nWater production rates have been calculated over time for each of these comets,\ncovering about 6 months mostly of the post-perihelion period of C/2017 K2\n(PanSTARRS) and about 3 months around perihelion of C/2022 E3 (ZTF).",
    "pdf_url": "http://arxiv.org/pdf/2505.11699v1",
    "published": "2025-05-16T21:07:13+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11698v1",
    "title": "Conditional Deep Generative Models for Belief State Planning",
    "authors": [
      "Antoine Bigeard",
      "Anthony Corso",
      "Mykel Kochenderfer"
    ],
    "abstract": "Partially observable Markov decision processes (POMDPs) are used to model a\nwide range of applications, including robotics, autonomous vehicles, and\nsubsurface problems. However, accurately representing the belief is difficult\nfor POMDPs with high-dimensional states. In this paper, we propose a novel\napproach that uses conditional deep generative models (cDGMs) to represent the\nbelief. Unlike traditional belief representations, cDGMs are well-suited for\nhigh-dimensional states and large numbers of observations, and they can\ngenerate an arbitrary number of samples from the posterior belief. We train the\ncDGMs on data produced by random rollout trajectories and show their\neffectiveness in solving a mineral exploration POMDP with a large and\ncontinuous state space. The cDGMs outperform particle filter baselines in both\ntask-agnostic measures of belief accuracy as well as in planning performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.11698v1",
    "published": "2025-05-16T21:06:41+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11697v2",
    "title": "State-dependent convergence of Galerkin-based reduced-order models for Couette flow",
    "authors": [
      "Zilin Zong",
      "Igor Maia",
      "André Cavalieri",
      "Yongyun Hwang"
    ],
    "abstract": "In this study, we explore the effect of basis functions on the performance\nand convergence of the Galerkin projection-based reduced-order model (ROM) in\nthe minimal flow unit of Couette flow. POD (proper orthogonal decomposition)\nmodes obtained from direct numerical simulation and controllability and\nbalanced truncation modes from the linearised Navier-Stokes equations (LNSE)\nwith different base flows (laminar base flow and turbulent mean flow) and an\neddy viscosity model are considered. In the neighbourhood of the laminar base\nstate, the ROMs based on the modes from the LNSE with the laminar base flow and\nmolecular viscosity are found to perform very well as they are able to capture\nthe linear stability of the laminar base flow for each plane Fourier component\nonly with a single degree of freedom. In particular, the ROM based on the\nbalanced truncation modes models the linear dynamics involving transient growth\naround the laminar base flow most effectively, consistent with previous\nstudies. In contrast, for turbulent state, the ROM based on POD modes is found\nto reproduce its statistics and coherent dynamics most effectively. The ROMs\nbased on the modes from the LNSE with turbulent mean flow and an eddy viscosity\nmodel performs better compared to any other ROMs using the modes from the LNSE.\nThese observations suggest that the performance and convergence of a ROM are\nhighly state-dependent. In particular, this state dependence is strongly\ncorrelated with the information and dynamics that each of the basis functions\ncontains. Discussions supporting these observations are also provided in\nrelation to the flow physics involved and the form of coherent structures in\nCouette flow.",
    "pdf_url": "http://arxiv.org/pdf/2505.11697v2",
    "published": "2025-05-16T21:06:14+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.11696v3",
    "title": "Unbound neutron $\\nu0d_{3/2}$ strength in $^{17}$C and the N=16 shell gap",
    "authors": [
      "J. Lois-Fuentes",
      "B. Fernández-Domínguez",
      "F. Delaunay",
      "X. Pereira-López",
      "N. A. Orr",
      "M. Płoszajczak",
      "N. Michel",
      "T. Otsuka",
      "T. Suzuki",
      "W. N. Catford",
      "O. Sorlin",
      "N. L. Achouri",
      "M. Assié",
      "S. Bailey",
      "B. Bastin",
      "Y. Blumenfeld",
      "R. Borcea",
      "M. Caamaño",
      "L. Caceres",
      "E. Clément",
      "A. Corsi",
      "N. Curtis",
      "Q. Deshayes",
      "F. Farget",
      "M. Fisichella",
      "G. de France",
      "S. Franchoo",
      "M. Freer",
      "J. Gibelin",
      "A. Gillibert",
      "G. F. Grinyer",
      "F. Hammache",
      "O. Kamalou",
      "A. Knapton",
      "Tz. Kokalova",
      "V. Lapoux",
      "J. A. Lay",
      "B. Le Crom",
      "S. Leblond",
      "F. M. Marqués",
      "A. Matta",
      "P. Morfouace",
      "A. Moro",
      "J. Pancin",
      "L. Perrot",
      "J. Piot",
      "E. Pollacco",
      "P. Punta",
      "D. Ramos",
      "C. Rodríguez-Tajes",
      "T. Roger",
      "F. Rotaru",
      "M. Sénoville",
      "N. de Séréville",
      "R. Smith",
      "M. Stanoiu",
      "I. Stefani",
      "C. Stodel",
      "D. Suzuki",
      "J. C. Thomas",
      "N. Timofeyuk",
      "M. Vandebrouck",
      "J. Walshe",
      "C. Wheldon"
    ],
    "abstract": "Significant continuum strength has been observed to be populated in $^{17}$C\nproduced in the d($^{16}$C,p) reaction at a beam energy of 17.2~MeV/nucleon.\nThe strength appears at greater than $\\sim$2~MeV above the single-neutron decay\nthreshold and has been identified as arising from transfer into the neutron\n$0d_{3/2}$ orbital. Guided by shell model predictions the greater majority of\nthe strength is associated with a 3/2$^+$ state at an excitation energy of\n4.40$_{-0.14}^{+0.33}$ MeV and a much weaker 3/2$^+$ level at\n5.60$_{-0.45}^{+1.35}$ MeV. The corresponding total widths were determined to\nbe 3.45$_{-0.78}^{+1.82}$ and 1.6$_{-1.4}^{+4.6}$ MeV, respectively. From the\nbackward angle proton differential cross sections and the branching ratios for\nneutron decay to the $^{16}$C(2$_{1}^{+}$) level, the corresponding\nspectroscopic factors to the ground state were deduced to be 0.47$\\pm{10}$ and\n$<$0.09. Shell-model calculations employing the phenomenological SFO-tls\ninteraction as well as Gamow Shell-Model calculations including continuum\neffects are in reasonable agreement with experiment, although the predicted\nstrength lies at somewhat lower energy. The size of the N=16 shell gap\n($\\varepsilon_{ \\nu0d_{3/2}}-\\varepsilon _{\\nu 1s_{1/2}}$) was estimated to be\n5.08$_{-0.33}^{+0.43}$~MeV - some 1.3~MeV larger than found in the SFO-tls\nshell model calculation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11696v3",
    "published": "2025-05-16T21:04:26+00:00",
    "categories": [
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.11695v2",
    "title": "Qronos: Correcting the Past by Shaping the Future... in Post-Training Quantization",
    "authors": [
      "Shihao Zhang",
      "Haoyu Zhang",
      "Ian Colbert",
      "Rayan Saab"
    ],
    "abstract": "We introduce Qronos -- a new state-of-the-art post-training quantization\nalgorithm that sequentially rounds and updates neural network weights. Qronos\nnot only explicitly corrects errors due to both weight and activation\nquantization, but also errors resulting from quantizing previous layers. Our\niterative algorithm is based on an interpretable and disciplined optimization\nframework that subsumes and surpasses existing data-driven approaches. At each\nstep, Qronos alternates between error correction and diffusion via optimal\nupdate rules. Importantly, we prove that Qronos admits an efficient\nimplementation that uses the Cholesky decomposition for solving least-squares\nproblems. We also demonstrate that Qronos is compatible with existing\ntransformation techniques such as Hadamard-based incoherence processing and\nweight-activation scaling equalization, among others. We evaluate Qronos using\nrecent autoregressive language generation models in the Llama3 family; Qronos\nconsistently outperforms previous state-of-the-art adaptive rounding methods\nwhen quantizing the weights, activations, and/or KV caches.",
    "pdf_url": "http://arxiv.org/pdf/2505.11695v2",
    "published": "2025-05-16T21:04:25+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11694v2",
    "title": "Neural Networks as Universal Finite-State Machines: A Constructive Deterministic Finite Automaton Theory",
    "authors": [
      "Sahil Rajesh Dhayalkar"
    ],
    "abstract": "We present a complete theoretical and empirical framework establishing\nfeedforward neural networks as universal finite-state machines (N-FSMs). Our\nresults prove that finite-depth ReLU and threshold networks can exactly\nsimulate deterministic finite automata (DFAs) by unrolling state transitions\ninto depth-wise neural layers, with formal characterizations of required depth,\nwidth, and state compression. We demonstrate that DFA transitions are linearly\nseparable, binary threshold activations allow exponential compression, and\nMyhill-Nerode equivalence classes can be embedded into continuous latent spaces\nwhile preserving separability. We also formalize the expressivity boundary:\nfixed-depth feedforward networks cannot recognize non-regular languages\nrequiring unbounded memory. Unlike prior heuristic or probing-based studies, we\nprovide constructive proofs and design explicit DFA-unrolled neural\narchitectures that empirically validate every claim. Our results bridge deep\nlearning, automata theory, and neural-symbolic computation, offering a rigorous\nblueprint for how discrete symbolic processes can be realized in continuous\nneural systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11694v2",
    "published": "2025-05-16T21:01:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.FL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11693v2",
    "title": "Hierarchical Bracketing Encodings for Dependency Parsing as Tagging",
    "authors": [
      "Ana Ezquerro",
      "David Vilares",
      "Anssi Yli-Jyrä",
      "Carlos Gómez-Rodríguez"
    ],
    "abstract": "We present a family of encodings for sequence labeling dependency parsing,\nbased on the concept of hierarchical bracketing. We prove that the existing\n4-bit projective encoding belongs to this family, but it is suboptimal in the\nnumber of labels used to encode a tree. We derive an optimal hierarchical\nbracketing, which minimizes the number of symbols used and encodes projective\ntrees using only 12 distinct labels (vs. 16 for the 4-bit encoding). We also\nextend optimal hierarchical bracketing to support arbitrary non-projectivity in\na more compact way than previous encodings. Our new encodings yield competitive\naccuracy on a diverse set of treebanks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11693v2",
    "published": "2025-05-16T21:01:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11692v2",
    "title": "The Geometry of ReLU Networks through the ReLU Transition Graph",
    "authors": [
      "Sahil Rajesh Dhayalkar"
    ],
    "abstract": "We develop a novel theoretical framework for analyzing ReLU neural networks\nthrough the lens of a combinatorial object we term the ReLU Transition Graph\n(RTG). In this graph, each node corresponds to a linear region induced by the\nnetwork's activation patterns, and edges connect regions that differ by a\nsingle neuron flip. Building on this structure, we derive a suite of new\ntheoretical results connecting RTG geometry to expressivity, generalization,\nand robustness. Our contributions include tight combinatorial bounds on RTG\nsize and diameter, a proof of RTG connectivity, and graph-theoretic\ninterpretations of VC-dimension. We also relate entropy and average degree of\nthe RTG to generalization error. Each theoretical result is rigorously\nvalidated via carefully controlled experiments across varied network depths,\nwidths, and data regimes. This work provides the first unified treatment of\nReLU network structure via graph theory and opens new avenues for compression,\nregularization, and complexity control rooted in RTG analysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.11692v2",
    "published": "2025-05-16T21:00:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11691v2",
    "title": "SpiderCat: A Catalog of Compact Binary Millisecond Pulsars",
    "authors": [
      "Karri I. I. Koljonen",
      "Manuel Linares"
    ],
    "abstract": "We present SpiderCat, a multi-wavelength catalog of all publicly known\ncompact binary millisecond pulsars (MSPs) in the Galactic field. These systems,\ncolloquially known as \"spiders\", consist of neutron stars in tight orbits with\nlow-mass companions, which are gradually ablated by the pulsar wind. SpiderCat\nincludes both primary subclasses $-$ redbacks and black widows $-$\ndistinguished by companion mass, as well as candidates and peculiar systems\nsuch as transitional, huntsman and tidarren MSPs. As of this initial release,\nSpiderCat contains 111 entries: 30 redbacks, 50 black widows, 2 huntsmans, 23\nredback candidates, 5 black widow candidates, and 1 huntsman candidate.\n  In this paper, we compile and summarize key parameters for each system,\nincluding spin and orbital properties, and multi-wavelength data from radio,\noptical, X-ray, and $\\gamma$-ray observations. An interactive, publicly\naccessible web interface (https://astro.phys.ntnu.no/SpiderCAT) enables\nexploration and visualization of the data.\n  The rapid growth of the number of known spiders, accelerated by the Fermi-LAT\nsurvey and its ability to identify MSPs in $\\gamma$-rays, has opened the door\nto population-level studies. Utilizing SpiderCat, we analyze trends in spin\nperiod, orbital period, companion mass, emission properties, and spatial\ndistribution. SpiderCat serves as a dynamic, multi-wavelength repository for\nthis unique class of binary pulsars, facilitating new discoveries and\nconstraints on pulsar evolution, particle acceleration, and the neutron star\nequation of state.",
    "pdf_url": "http://arxiv.org/pdf/2505.11691v2",
    "published": "2025-05-16T21:00:53+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11690v1",
    "title": "Automatic Speech Recognition for African Low-Resource Languages: Challenges and Future Directions",
    "authors": [
      "Sukairaj Hafiz Imam",
      "Babangida Sani",
      "Dawit Ketema Gete",
      "Bedru Yimam Ahamed",
      "Ibrahim Said Ahmad",
      "Idris Abdulmumin",
      "Seid Muhie Yimam",
      "Muhammad Yahuza Bello",
      "Shamsuddeen Hassan Muhammad"
    ],
    "abstract": "Automatic Speech Recognition (ASR) technologies have transformed\nhuman-computer interaction; however, low-resource languages in Africa remain\nsignificantly underrepresented in both research and practical applications.\nThis study investigates the major challenges hindering the development of ASR\nsystems for these languages, which include data scarcity, linguistic\ncomplexity, limited computational resources, acoustic variability, and ethical\nconcerns surrounding bias and privacy. The primary goal is to critically\nanalyze these barriers and identify practical, inclusive strategies to advance\nASR technologies within the African context. Recent advances and case studies\nemphasize promising strategies such as community-driven data collection,\nself-supervised and multilingual learning, lightweight model architectures, and\ntechniques that prioritize privacy. Evidence from pilot projects involving\nvarious African languages showcases the feasibility and impact of customized\nsolutions, which encompass morpheme-based modeling and domain-specific ASR\napplications in sectors like healthcare and education. The findings highlight\nthe importance of interdisciplinary collaboration and sustained investment to\ntackle the distinct linguistic and infrastructural challenges faced by the\ncontinent. This study offers a progressive roadmap for creating ethical,\nefficient, and inclusive ASR systems that not only safeguard linguistic\ndiversity but also improve digital accessibility and promote socioeconomic\nparticipation for speakers of African languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.11690v1",
    "published": "2025-05-16T20:57:39+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15836v1",
    "title": "Quantum-Evolutionary Neural Networks for Multi-Agent Federated Learning",
    "authors": [
      "Aarav Lala",
      "Kalyan Cherukuri"
    ],
    "abstract": "As artificial intelligence continues to drive innovation in complex,\ndecentralized environments, the need for scalable, adaptive, and\nprivacy-preserving decision-making systems has become critical. This paper\nintroduces a novel framework combining quantum-inspired neural networks with\nevolutionary algorithms to optimize real-time decision-making in multi-agent\nsystems (MAS). The proposed Quantum-Evolutionary Neural Network (QE-NN)\nleverages quantum computing principles -- such as quantum superposition and\nentanglement -- to enhance learning speed and decision accuracy, while\nintegrating evolutionary optimization to continually refine agent behaviors in\ndynamic, uncertain environments. By utilizing federated learning, QE-NN ensures\nprivacy preservation, enabling decentralized agents to collaborate without\nsharing sensitive data. The framework is designed to allow agents to adapt in\nreal-time to their environments, optimizing decision-making processes for\napplications in areas such as autonomous systems, smart cities, and healthcare.\nThis research represents a breakthrough in merging quantum computing,\nevolutionary optimization, and privacy-preserving techniques to solve complex\nproblems in multi-agent decision-making systems, pushing the boundaries of AI\nin real-world, privacy-sensitive applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.15836v1",
    "published": "2025-05-16T20:51:37+00:00",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11689v1",
    "title": "Relative Entropy Contractions for Extremal Shocks of Nonlinear Hyperbolic Systems without Genuine Nonlinearity",
    "authors": [
      "Jeffrey Cheng"
    ],
    "abstract": "We study extremal shocks of $1$-d hyperbolic systems of conservation laws\nwhich fail to be genuinely nonlinear. More specifically, we consider either\n$1$- or $n$-shocks in characteristic fields which are either concave-convex or\nconvex-concave in the sense of LeFloch. We show that the theory of\n$a$-contraction can be applied to obtain $L^2$-stability up to shift for these\nshocks in a class of weak solutions to the conservation law whose shocks obey\nthe Lax entropy condition. Our results apply in particular to the $2 \\times 2$\nsystem of nonlinear elastodynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.11689v1",
    "published": "2025-05-16T20:51:18+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11688v1",
    "title": "On the Sharp Input-Output Analysis of Nonlinear Systems under Adversarial Attacks",
    "authors": [
      "Jihun Kim",
      "Yuchen Fang",
      "Javad Lavaei"
    ],
    "abstract": "This paper is concerned with learning the input-output mapping of general\nnonlinear dynamical systems. While the existing literature focuses on Gaussian\ninputs and benign disturbances, we significantly broaden the scope of\nadmissible control inputs and allow correlated, nonzero-mean, adversarial\ndisturbances. With our reformulation as a linear combination of basis\nfunctions, we prove that the $l_1$-norm estimator overcomes the challenges as\nlong as the probability that the system is under adversarial attack at a given\ntime is smaller than a certain threshold. We provide an estimation error bound\nthat decays with the input memory length and prove its optimality by\nconstructing a problem instance that suffers from the same bound under\nadversarial attacks. Our work provides a sharp input-output analysis for a\ngeneric nonlinear and partially observed system under significantly generalized\nassumptions compared to existing works.",
    "pdf_url": "http://arxiv.org/pdf/2505.11688v1",
    "published": "2025-05-16T20:49:42+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY",
      "93B15, 93B30, 93C10"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11687v1",
    "title": "Second SIGIR Workshop on Simulations for Information Access (Sim4IA 2025)",
    "authors": [
      "Philipp Schaer",
      "Christin Katharina Kreutz",
      "Krisztian Balog",
      "Timo Breuer",
      "Andreas Konstantin Kruff"
    ],
    "abstract": "Simulations in information access (IA) have recently gained interest, as\nshown by various tutorials and workshops around that topic. Simulations can be\nkey contributors to central IA research and evaluation questions, especially\naround interactive settings when real users are unavailable, or their\nparticipation is impossible due to ethical reasons. In addition, simulations in\nIA can help contribute to a better understanding of users, reduce complexity of\nevaluation experiments, and improve reproducibility. Building on recent\ndevelopments in methods and toolkits, the second iteration of our Sim4IA\nworkshop aims to again bring together researchers and practitioners to form an\ninteractive and engaging forum for discussions on the future perspectives of\nthe field. An additional aim is to plan an upcoming TREC/CLEF campaign.",
    "pdf_url": "http://arxiv.org/pdf/2505.11687v1",
    "published": "2025-05-16T20:48:59+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11686v1",
    "title": "Exploring the Kleinian horizons",
    "authors": [
      "Gaston Giribet",
      "Juan Laurnagaray",
      "Bryan Malpartida",
      "Pedro Schmied"
    ],
    "abstract": "Self-dual black holes in (2,2) signature spacetime -- Klein space -- have\nrecently attracted interest in the context of celestial holography. Motivated\nby this development, we investigate the structure of spacetime near the\nhorizons of these solutions. Focusing on the self-dual Schwarzschild-Taub-NUT\nsolution, we demonstrate that, near the Kleinian horizons, the geometry\nexhibits a local infinite-dimensional symmetry generated by supertranslations\nand superrotations. Establishing this result requires refining and extending\nearlier analyses of asymptotic symmetries near null surfaces. We formulate the\nappropriate boundary conditions, derive the infinite-dimensional algebra\nunderlying the local symmetries, and compute the associated Noether charges,\nfinding them to be integrable. Finally, we discuss the connection of our\nfindings to recent observations in the literature regarding self-dual black\nholes in Klein space, including the diffeomorphism relating static and\nstationary solutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11686v1",
    "published": "2025-05-16T20:45:51+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11685v2",
    "title": "Pull-off force prediction in viscoelastic adhesive Hertzian contact by physics augmented machine learning",
    "authors": [
      "Ali Maghami",
      "Merten Stender",
      "Antonio Papangelo"
    ],
    "abstract": "Understanding and predicting the adhesive properties of viscoelastic Hertzian\ncontacts is crucial for diverse engineering applications, including robotics,\nbiomechanics, and advanced material design. The maximum adherence force of a\nHertzian indenter unloaded from a viscoelastic substrate has been studied with\nanalytical and numerical models. Analytical models are valid within their\nassumptions, numerical methods offer precision but can be computationally\nexpensive, necessitating alternative solutions. This study introduces a novel\nphysics-augmented machine learning (PA-ML) framework as a hybrid approach,\nbridging the gap between analytical models and data-driven solutions, which is\ncapable of rapidly predicting the pull-off force in an Hertzian profile\nunloaded from a broad band viscoelastic material, with varying Tabor parameter,\npreload and retraction rate. Compared to previous models, the PA-ML approach\nprovides fast yet accurate predictions in a wide range of conditions, properly\npredicting the effective surface energy and the work-to-pull-off. The\nintegration of the analytical model provides critical guidance to the PA-ML\nframework, supporting physically consistent predictions. We demonstrate that\nphysics augmentation enhances predictive accuracy, reducing mean squared error\n(MSE) while increasing model efficiency and interpretability. We provide\ndata-driven and PA-ML models for real-time predictions of the adherence force\nin soft materials like silicons and elastomers opening to the possibility to\nintegrate PA-ML into materials and interface design. The models are openly\navailable on Zenodo and GitHub.",
    "pdf_url": "http://arxiv.org/pdf/2505.11685v2",
    "published": "2025-05-16T20:45:10+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11684v1",
    "title": "Designing for Constructive Civic Communication: A Framework for Human-AI Collaboration in Community Engagement Processes",
    "authors": [
      "Cassandra Overney"
    ],
    "abstract": "Community engagement processes form a critical foundation of democratic\ngovernance, yet frequently struggle with resource constraints, sensemaking\nchallenges, and barriers to inclusive participation. These processes rely on\nconstructive communication between public leaders and community organizations\ncharacterized by understanding, trust, respect, legitimacy, and agency. As\nartificial intelligence (AI) technologies become increasingly integrated into\ncivic contexts, they offer promising capabilities to streamline\nresource-intensive workflows, reveal new insights in community feedback,\ntranslate complex information into accessible formats, and facilitate\nreflection across social divides. However, these same systems risk undermining\ndemocratic processes through accuracy issues, transparency gaps, bias\namplification, and threats to human agency. In this paper, we examine how\nhuman-AI collaboration might address these risks and transform civic\ncommunication dynamics by identifying key communication pathways and proposing\ndesign considerations that maintain a high level of control over\ndecision-making for both public leaders and communities while leveraging\ncomputer automation. By thoughtfully integrating AI to amplify human connection\nand understanding while safeguarding agency, community engagement processes can\nutilize AI to promote more constructive communication in democratic governance.",
    "pdf_url": "http://arxiv.org/pdf/2505.11684v1",
    "published": "2025-05-16T20:44:46+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11683v1",
    "title": "Evaluating Design Decisions for Dual Encoder-based Entity Disambiguation",
    "authors": [
      "Susanna Rücker",
      "Alan Akbik"
    ],
    "abstract": "Entity disambiguation (ED) is the task of linking mentions in text to\ncorresponding entries in a knowledge base. Dual Encoders address this by\nembedding mentions and label candidates in a shared embedding space and\napplying a similarity metric to predict the correct label. In this work, we\nfocus on evaluating key design decisions for Dual Encoder-based ED, such as its\nloss function, similarity metric, label verbalization format, and negative\nsampling strategy. We present the resulting model VerbalizED, a document-level\nDual Encoder model that includes contextual label verbalizations and efficient\nhard negative sampling. Additionally, we explore an iterative prediction\nvariant that aims to improve the disambiguation of challenging data points.\nComprehensive experiments on AIDA-Yago validate the effectiveness of our\napproach, offering insights into impactful design choices that result in a new\nState-of-the-Art system on the ZELDA benchmark.",
    "pdf_url": "http://arxiv.org/pdf/2505.11683v1",
    "published": "2025-05-16T20:44:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11682v1",
    "title": "Mollifier Layers: Enabling Efficient High-Order Derivatives in Inverse PDE Learning",
    "authors": [
      "Ananyae Kumar Bhartari",
      "Vinayak Vinayak",
      "Vivek B Shenoy"
    ],
    "abstract": "Parameter estimation in inverse problems involving partial differential\nequations (PDEs) underpins modeling across scientific disciplines, especially\nwhen parameters vary in space or time. Physics-informed Machine Learning\n(PhiML) integrates PDE constraints into deep learning, but prevailing\napproaches depend on recursive automatic differentiation (autodiff), which\nproduces inaccurate high-order derivatives, inflates memory usage, and\nunderperforms in noisy settings. We propose Mollifier Layers, a lightweight,\narchitecture-agnostic module that replaces autodiff with convolutional\noperations using analytically defined mollifiers. This reframing of derivative\ncomputation as smoothing integration enables efficient, noise-robust estimation\nof high-order derivatives directly from network outputs. Mollifier Layers\nattach at the output layer and require no architectural modifications. We\ncompare them with three distinct architectures and benchmark performance across\nfirst-, second-, and fourth-order PDEs -- including Langevin dynamics, heat\ndiffusion, and reaction-diffusion systems -- observing significant improvements\nin memory efficiency, training time and accuracy for parameter recovery across\ntasks. To demonstrate practical relevance, we apply Mollifier Layers to infer\nspatially varying epigenetic reaction rates from super-resolution chromatin\nimaging data -- a real-world inverse problem with biomedical significance. Our\nresults establish Mollifier Layers as an efficient and scalable tool for\nphysics-constrained learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.11682v1",
    "published": "2025-05-16T20:43:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11681v1",
    "title": "Comptage de fibrés de Hitchin pour le groupe $\\mathrm{SL}(n)$",
    "authors": [
      "Pierre-Henri Chaudouard"
    ],
    "abstract": "Let $C$ be a smooth projective curve of genus $g$ over a finite field\n$\\mathbb{F}_q$ and let $D$ be a divisor on $C$ of degree $>2g-2$. We assume\nthat the characteristic of $\\mathbb{F}_q$ is sufficiently large. Let $n$ be an\ninteger and let $\\beta$ be a line bundle on $C$ of degree $e$, coprime to $n$.\nWe give a formula for the number of stable ($D$-twisted) Hitchin bundles over\n$C$ of rank $n$ and determinant $\\beta$ in terms of the number of stable\nHitchin bundles over $C'$ of rank $n/d$ and degree $e$ where $C'$ ranges over\ncyclic covers $C'$ of $C$ of degree $d$ dividing $n$. Using a work by\nMozgovoy-O'Gorman, we derive a closed formula for the following invariants of\nthe moduli space of ($D$-twisted) Hitchin bundles over $C$ of rank $n$, trace\n$0$ and determinant $\\beta$: its number of points over finite extensions of\n$\\mathbb{F}_q$, its $\\ell$-adic Poincar\\'e polynomial and its Euler-Poincar\\'e\ncharacteristic. Our main tools are the fundamental lemma of automorphic\ninduction and a support theorem for the relative cohomology of a local system\non the Hitchin fibration for the group $\\mathrm{GL}(n)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11681v1",
    "published": "2025-05-16T20:43:38+00:00",
    "categories": [
      "math.AG",
      "math.RT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11680v1",
    "title": "Grounded Task Axes: Zero-Shot Semantic Skill Generalization via Task-Axis Controllers and Visual Foundation Models",
    "authors": [
      "M. Yunus Seker",
      "Shobhit Aggarwal",
      "Oliver Kroemer"
    ],
    "abstract": "Transferring skills between different objects remains one of the core\nchallenges of open-world robot manipulation. Generalization needs to take into\naccount the high-level structural differences between distinct objects while\nstill maintaining similar low-level interaction control. In this paper, we\npropose an example-based zero-shot approach to skill transfer. Rather than\ntreating skills as atomic, we decompose skills into a prioritized list of\ngrounded task-axis (GTA) controllers. Each GTAC defines an adaptable\ncontroller, such as a position or force controller, along an axis. Importantly,\nthe GTACs are grounded in object key points and axes, e.g., the relative\nposition of a screw head or the axis of its shaft. Zero-shot transfer is thus\nachieved by finding semantically-similar grounding features on novel target\nobjects. We achieve this example-based grounding of the skills through the use\nof foundation models, such as SD-DINO, that can detect semantically similar\nkeypoints of objects. We evaluate our framework on real-robot experiments,\nincluding screwing, pouring, and spatula scraping tasks, and demonstrate robust\nand versatile controller transfer for each.",
    "pdf_url": "http://arxiv.org/pdf/2505.11680v1",
    "published": "2025-05-16T20:43:29+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11679v1",
    "title": "Ambiguity Resolution in Text-to-Structured Data Mapping",
    "authors": [
      "Zhibo Hu",
      "Chen Wang",
      "Yanfeng Shu",
      "Hye-Young Paik",
      "Liming Zhu"
    ],
    "abstract": "Ambiguity in natural language is a significant obstacle for achieving\naccurate text to structured data mapping through large language models (LLMs),\nwhich affects the performance of tasks such as mapping text to agentic tool\ncalling and text-to-SQL queries. Existing methods of ambiguity handling either\nexploit ReACT framework to produce the correct mapping through trial and error,\nor supervised fine tuning to guide models to produce a biased mapping to\nimprove certain tasks. In this paper, we adopt a different approach that\ncharacterizes the representation difference of ambiguous text in the latent\nspace and leverage the difference to identify ambiguity before mapping them to\nstructured data. To detect ambiguity of a sentence, we focused on the\nrelationship between ambiguous questions and their interpretations and what\ncause the LLM ignore multiple interpretations. Different to the distance\ncalculated by dense embedding vectors, we utilize the observation that\nambiguity is caused by concept missing in latent space of LLM to design a new\ndistance measurement, computed through the path kernel by the integral of\ngradient values for each concepts from sparse-autoencoder (SAE) under each\nstate. We identify patterns to distinguish ambiguous questions with this\nmeasurement. Based on our observation, We propose a new framework to improve\nthe performance of LLMs on ambiguous agentic tool calling through missing\nconcepts prediction.",
    "pdf_url": "http://arxiv.org/pdf/2505.11679v1",
    "published": "2025-05-16T20:39:30+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11678v1",
    "title": "Fairness-Utility Trade-off via Wasserstein Projection",
    "authors": [
      "Yan Chen",
      "Zheng Tan",
      "Jose Blanchet",
      "Hanzhang Qin"
    ],
    "abstract": "Ensuring fairness in data-driven decision-making is a critical concern, but\nexisting fairness constraints often involve trade-offs with overall utility. We\npropose a fairness framework that enforces strong demographic parity-related\nfairness criteria (with $\\epsilon$-tolerance) in propensity score allocation\nwhile guaranteeing a minimum total utility. This approach balances equity and\nutility by calibrating propensity scores to satisfy fairness criteria and\noptimizing outcomes without incurring unacceptable losses in performance.\nGrounded in a binary treatment and sensitive attribute setting under causal\nfairness setup, our method provides a principled mechanism to address fairness\nwhile transparently managing associated economic and social costs, offering a\npractical approach for designing equitable policies in diverse decision-making\ncontexts. Building on this, we provide theoretical guarantee for our proposed\nutility-constrained fairness evaluation framework, and we formalize a\nhypothesis testing framework to help practitioners assess whether the desired\nfairness-utility trade-off is achieved.",
    "pdf_url": "http://arxiv.org/pdf/2505.11678v1",
    "published": "2025-05-16T20:29:06+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11677v1",
    "title": "Enhancing Code Quality with Generative AI: Boosting Developer Warning Compliance",
    "authors": [
      "Hansen Chang",
      "Christian DeLozier"
    ],
    "abstract": "Programmers have long ignored warnings, especially those generated by static\nanalysis tools, due to the potential for false-positives. In some cases,\nwarnings may be indicative of larger issues, but programmers may not understand\nhow a seemingly unimportant warning can grow into a vulnerability. Because\nthese messages tend to be long and confusing, programmers tend to ignore them\nif they do not cause readily identifiable issues. Large language models can\nsimplify these warnings, explain the gravity of important warnings, and suggest\npotential fixes to increase developer compliance with fixing warnings.",
    "pdf_url": "http://arxiv.org/pdf/2505.11677v1",
    "published": "2025-05-16T20:26:05+00:00",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11676v1",
    "title": "DPSeg: Dual-Prompt Cost Volume Learning for Open-Vocabulary Semantic Segmentation",
    "authors": [
      "Ziyu Zhao",
      "Xiaoguang Li",
      "Linjia Shi",
      "Nasrin Imanpour",
      "Song Wang"
    ],
    "abstract": "Open-vocabulary semantic segmentation aims to segment images into distinct\nsemantic regions for both seen and unseen categories at the pixel level.\nCurrent methods utilize text embeddings from pre-trained vision-language models\nlike CLIP but struggle with the inherent domain gap between image and text\nembeddings, even after extensive alignment during training. Additionally,\nrelying solely on deep text-aligned features limits shallow-level feature\nguidance, which is crucial for detecting small objects and fine details,\nultimately reducing segmentation accuracy. To address these limitations, we\npropose a dual prompting framework, DPSeg, for this task. Our approach combines\ndual-prompt cost volume generation, a cost volume-guided decoder, and a\nsemantic-guided prompt refinement strategy that leverages our dual prompting\nscheme to mitigate alignment issues in visual prompt generation. By\nincorporating visual embeddings from a visual prompt encoder, our approach\nreduces the domain gap between text and image embeddings while providing\nmulti-level guidance through shallow features. Extensive experiments\ndemonstrate that our method significantly outperforms existing state-of-the-art\napproaches on multiple public datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.11676v1",
    "published": "2025-05-16T20:25:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11675v1",
    "title": "Bayesian Optimization of Pythia8 Tunes",
    "authors": [
      "Ali Al Kadhim",
      "Harrison B Prosper",
      "Stephen Mrenna"
    ],
    "abstract": "A new tune (set of model parameters) is found for the six most important\nparameters of the Pythia8 final state parton shower and hadronization model\nusing Bayesian optimization. The tune fits the LEPI data from ALEPH better than\nthe default tune in Pythia8. To the best of our knowledge, we present the most\ncomprehensive application of Bayesian optimization to the tuning of a parton\nshower and hadronization model using the LEPI data.",
    "pdf_url": "http://arxiv.org/pdf/2505.11675v1",
    "published": "2025-05-16T20:25:17+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "stat.AP"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11674v1",
    "title": "Mixed-model Log-likelihood Evaluation Via a Blocked Cholesky Factorization",
    "authors": [
      "Douglas Bates",
      "Phillip M. Alday",
      "Ajinkya H. Kokandakar"
    ],
    "abstract": "Bates et al. (2015) described the evaluation of the profiled log-likelihood\nof a linear mixed-effects model by updating a sparse, symmetric\npositive-definite matrix and computing its Cholesky factor, as implemented in\nthe lme4 package for R. Here we present enhancements to the derivation and\ntheoretical presentation of the result and to its implementation using a\nblocked Cholesky factorization in the MixedModels$.$jl package for Julia\n(Bezanson et al., 2017). The gain in computational efficiency is primarily due\nto three factors: (1) the new derivation allows us to compute the penalized\nresidual sum of squares without computing the conditional estimates of the\nfixed-effects parameters and the conditional modes of the random effects at\neach optimization step, (2) the blocked Cholesky representation and careful\nordering of the random effects terms reduces the amount of \"fill-in\" that\noccurs during the Cholesky factorization, and (3) the multiple dispatch feature\nof the Julia language allows us to use specialized algorithms for different\nkinds of matrices instead of relying on generic algorithms during the Cholesky\nfactorization. To show the effectiveness of the blocked Cholesky approach we\nuse it to fit a linear mixed model to over 32 million ratings of movies in the\nMovieLens ml-32m (Harper and Konstan, 2016) data set. The model incorporates\nrandom effects for over 200,000 movies and over 80,000 participants. Further\nenhancements to these computational methods are suggested.",
    "pdf_url": "http://arxiv.org/pdf/2505.11674v1",
    "published": "2025-05-16T20:19:21+00:00",
    "categories": [
      "stat.CO"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11673v1",
    "title": "BLOG: Bayesian Longitudinal Omics with Group Constraints",
    "authors": [
      "Livia Popa",
      "Sumanta Basu",
      "Myung Hee Lee",
      "Martin T. Wells"
    ],
    "abstract": "Clinical investigators are increasingly interested in discovering\ncomputational biomarkers from short-term longitudinal omics data sets. This\nwork focuses on Bayesian regression and variable selection for longitudinal\nomics datasets, which can quantify uncertainty and control false discovery. In\nour univariate approach, Zellner's $g$ prior is used with two different options\nof the tuning parameter $g$: $g=\\sqrt{n}$ and a $g$ that minimizes Stein's\nunbiased risk estimate (SURE). Bayes Factors were used to quantify uncertainty\nand control for false discovery. In the multivariate approach, we use Bayesian\nGroup LASSO with a spike and slab prior for group variable selection. In both\napproaches, we use the first difference ($\\Delta$) scale of longitudinal\npredictor and the response. These methods work together to enhance our\nunderstanding of biomarker identification, improving inference and prediction.\nWe compare our method against commonly used linear mixed effect models on\nsimulated data and real data from a Tuberculosis (TB) study on metabolite\nbiomarker selection. With an automated selection of hyperparameters, the\nZellner's $g$ prior approach correctly identifies target metabolites with high\nspecificity and sensitivity across various simulation and real data scenarios.\nThe Multivariate Bayesian Group Lasso spike and slab approach also correctly\nselects target metabolites across various simulation scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.11673v1",
    "published": "2025-05-16T20:17:16+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.11672v1",
    "title": "Terminators: Terms of Service Parsing and Auditing Agents",
    "authors": [
      "Maruf Ahmed Mridul",
      "Inwon Kang",
      "Oshani Seneviratne"
    ],
    "abstract": "Terms of Service (ToS) documents are often lengthy and written in complex\nlegal language, making them difficult for users to read and understand. To\naddress this challenge, we propose Terminators, a modular agentic framework\nthat leverages large language models (LLMs) to parse and audit ToS documents.\nRather than treating ToS understanding as a black-box summarization problem,\nTerminators breaks the task down to three interpretable steps: term extraction,\nverification, and accountability planning. We demonstrate the effectiveness of\nour method on the OpenAI ToS using GPT-4o, highlighting strategies to minimize\nhallucinations and maximize auditability. Our results suggest that structured,\nagent-based LLM workflows can enhance both the usability and enforceability of\ncomplex legal documents. By translating opaque terms into actionable,\nverifiable components, Terminators promotes ethical use of web content by\nenabling greater transparency, empowering users to understand their digital\nrights, and supporting automated policy audits for regulatory or civic\noversight.",
    "pdf_url": "http://arxiv.org/pdf/2505.11672v1",
    "published": "2025-05-16T20:17:10+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13510v2",
    "title": "On the definition and importance of interpretability in scientific machine learning",
    "authors": [
      "Conor Rowan",
      "Alireza Doostan"
    ],
    "abstract": "Though neural networks trained on large datasets have been successfully used\nto describe and predict many physical phenomena, there is a sense among\nscientists that, unlike traditional scientific models comprising simple\nmathematical expressions, their findings cannot be integrated into the body of\nscientific knowledge. Critics of machine learning's inability to produce\nhuman-understandable relationships have converged on the concept of\n\"interpretability\" as its point of departure from more traditional forms of\nscience. As the growing interest in interpretability has shown, researchers in\nthe physical sciences seek not just predictive models, but also to uncover the\nfundamental principles that govern a system of interest. However, clarity\naround a definition of interpretability and the precise role that it plays in\nscience is lacking in the literature. In this work, we argue that researchers\nin equation discovery and symbolic regression tend to conflate the concept of\nsparsity with interpretability. We review key papers on interpretable machine\nlearning from outside the scientific community and argue that, though the\ndefinitions and methods they propose can inform questions of interpretability\nfor scientific machine learning (SciML), they are inadequate for this new\npurpose. Noting these deficiencies, we propose an operational definition of\ninterpretability for the physical sciences. Our notion of interpretability\nemphasizes understanding of the mechanism over mathematical sparsity. Innocuous\nthough it may seem, this emphasis on mechanism shows that sparsity is often\nunnecessary. It also questions the possibility of interpretable scientific\ndiscovery when prior knowledge is lacking. We believe a precise and\nphilosophically informed definition of interpretability in SciML will help\nfocus research efforts toward the most significant obstacles to realizing a\ndata-driven scientific future.",
    "pdf_url": "http://arxiv.org/pdf/2505.13510v2",
    "published": "2025-05-16T20:16:14+00:00",
    "categories": [
      "cs.LG",
      "physics.data-an",
      "physics.hist-ph",
      "physics.soc-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11671v1",
    "title": "Humble your Overconfident Networks: Unlearning Overfitting via Sequential Monte Carlo Tempered Deep Ensembles",
    "authors": [
      "Andrew Millard",
      "Zheng Zhao",
      "Joshua Murphy",
      "Simon Maskell"
    ],
    "abstract": "Sequential Monte Carlo (SMC) methods offer a principled approach to Bayesian\nuncertainty quantification but are traditionally limited by the need for\nfull-batch gradient evaluations. We introduce a scalable variant by\nincorporating Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) proposals\ninto SMC, enabling efficient mini-batch based sampling. Our resulting SMCSGHMC\nalgorithm outperforms standard stochastic gradient descent (SGD) and deep\nensembles across image classification, out-of-distribution (OOD) detection, and\ntransfer learning tasks. We further show that SMCSGHMC mitigates overfitting\nand improves calibration, providing a flexible, scalable pathway for converting\npretrained neural networks into well-calibrated Bayesian models.",
    "pdf_url": "http://arxiv.org/pdf/2505.11671v1",
    "published": "2025-05-16T20:10:04+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.CO"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.11670v1",
    "title": "An Adaptive and Parameter-Free Nesterov's Accelerated Gradient Method for Convex Optimization",
    "authors": [
      "Jaewook J. Suh",
      "Shiqian Ma"
    ],
    "abstract": "We propose AdaNAG, an adaptive accelerated gradient method based on\nNesterov's accelerated gradient method. AdaNAG is line-search-free,\nparameter-free, and achieves the accelerated convergence rates $f(x_k) -\nf_\\star = \\mathcal{O}\\left(1/k^2\\right)$ and $\\min_{i\\in\\left\\{1,\\dots,\nk\\right\\}} \\|\\nabla f(x_i)\\|^2 = \\mathcal{O}\\left(1/k^3\\right)$ for $L$-smooth\nconvex function $f$. We provide a Lyapunov analysis for the convergence proof\nof AdaNAG, which additionally enables us to propose a novel adaptive gradient\ndescent (GD) method, AdaGD. AdaGD achieves the non-ergodic convergence rate\n$f(x_k) - f_\\star = \\mathcal{O}\\left(1/k\\right)$, like the original GD. The\nanalysis of AdaGD also motivated us to propose a generalized AdaNAG that\nincludes practically useful variants of AdaNAG. Numerical results demonstrate\nthat our methods outperform some other recent adaptive methods for\nrepresentative applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.11670v1",
    "published": "2025-05-16T20:10:03+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11669v1",
    "title": "OT Score: An OT based Confidence Score for Unsupervised Domain Adaptation",
    "authors": [
      "Yiming Zhang",
      "Sitong Liu",
      "Alex Cloninger"
    ],
    "abstract": "We address the computational and theoretical limitations of existing\ndistributional alignment methods for unsupervised domain adaptation (UDA),\nparticularly regarding the estimation of classification performance and\nconfidence without target labels. Current theoretical frameworks for these\nmethods often yield computationally intractable quantities and fail to\nadequately reflect the properties of the alignment algorithms employed. To\novercome these challenges, we introduce the Optimal Transport (OT) score, a\nconfidence metric derived from a novel theoretical analysis that exploits the\nflexibility of decision boundaries induced by Semi-Discrete Optimal Transport\nalignment. The proposed OT score is intuitively interpretable, theoretically\nrigorous, and computationally efficient. It provides principled uncertainty\nestimates for any given set of target pseudo-labels without requiring model\nretraining, and can flexibly adapt to varying degrees of available source\ninformation. Experimental results on standard UDA benchmarks demonstrate that\nclassification accuracy consistently improves by identifying and removing\nlow-confidence predictions, and that OT score significantly outperforms\nexisting confidence metrics across diverse adaptation scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.11669v1",
    "published": "2025-05-16T20:09:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11668v2",
    "title": "Model-Based Clustering with Sequential Outlier Identification using the Distribution of Mahalanobis Distances",
    "authors": [
      "Ultán P. Doherty",
      "Paul D. McNicholas",
      "Arthur White"
    ],
    "abstract": "The presence of outliers can prevent clustering algorithms from accurately\ndetermining an appropriate group structure within a data set. We present\noutlierMBC, a model-based approach for sequentially removing outliers and\nclustering the remaining observations. Our method identifies outliers one at a\ntime while fitting a multivariate Gaussian mixture model to data. Since it can\nbe difficult to classify observations as outliers without knowing what the\ncorrect cluster structure is a priori, and the presence of outliers interferes\nwith the process of modelling clusters correctly, we use an iterative method to\nidentify outliers one by one. At each iteration, outlierMBC removes the\nobservation with the lowest density and fits a Gaussian mixture model to the\nremaining data. The method continues to remove potential outliers until a\npre-set maximum number of outliers is reached, then retrospectively identifies\nthe optimal number of outliers. To decide how many outliers to remove, it uses\nthe fact that the squared sample Mahalanobis distances of Gaussian distributed\nobservations are Beta distributed when scaled appropriately. outlierMBC chooses\nthe number of outliers which minimises a dissimilarity between this theoretical\nBeta distribution and the observed distribution of the scaled squared sample\nMahalanobis distances. This means that our method both clusters the data using\na Gaussian mixture model and implements a model-based procedure to identify the\noptimal outliers to remove without requiring the number of outliers to be\npre-specified. Unlike leading methods in the literature, outlierMBC does not\nassume that the outliers follow a known distribution or that the number of\noutliers can be pre-specified. Moreover, outlierMBC performs strongly compared\nto these algorithms when applied to a range of simulated and real data sets.",
    "pdf_url": "http://arxiv.org/pdf/2505.11668v2",
    "published": "2025-05-16T20:04:14+00:00",
    "categories": [
      "stat.ME",
      "stat.CO",
      "62H30",
      "G.3"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.11667v1",
    "title": "Data-based control of Logical Networks",
    "authors": [
      "Giorgia Disarò",
      "Maria Elena Valcher"
    ],
    "abstract": "In recent years, data-driven approaches have become increasingly pervasive\nacross all areas of control engineering. However, the applications of\ndata-based techniques to Boolean Control Networks (BCNs) are still very\nlimited. In this paper we aim to fill this gap, by exploring the possibility of\nsolving three fundamental control problems, i.e., state feedback stabilization,\nsafe control and output regulation, for a BCN, leveraging only a limited amount\nof data generated by the network, without knowing or identifying its model.",
    "pdf_url": "http://arxiv.org/pdf/2505.11667v1",
    "published": "2025-05-16T20:02:18+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11666v1",
    "title": "DesignFromX: Empowering Consumer-Driven Design Space Exploration through Feature Composition of Referenced Products",
    "authors": [
      "Runlin Duan",
      "Chenfei Zhu",
      "Yuzhao Chen",
      "Yichen Hu",
      "Jingyu Shi",
      "Karthik Ramani"
    ],
    "abstract": "Industrial products are designed to satisfy the needs of consumers. The rise\nof generative artificial intelligence (GenAI) enables consumers to easily\nmodify a product by prompting a generative model, opening up opportunities to\nincorporate consumers in exploring the product design space. However, consumers\noften struggle to articulate their preferred product features due to their\nunfamiliarity with terminology and their limited understanding of the structure\nof product features. We present DesignFromX, a system that empowers\nconsumer-driven design space exploration by helping consumers to design a\nproduct based on their preferences. Leveraging an effective GenAI-based\nframework, the system allows users to easily identify design features from\nproduct images and compose those features to generate conceptual images and 3D\nmodels of a new product. A user study with 24 participants demonstrates that\nDesignFromX lowers the barriers and frustration for consumer-driven design\nspace explorations by enhancing both engagement and enjoyment for the\nparticipants.",
    "pdf_url": "http://arxiv.org/pdf/2505.11666v1",
    "published": "2025-05-16T20:02:08+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11665v1",
    "title": "Multilingual Prompt Engineering in Large Language Models: A Survey Across NLP Tasks",
    "authors": [
      "Shubham Vatsal",
      "Harsh Dubey",
      "Aditi Singh"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive performance across\na wide range of Natural Language Processing (NLP) tasks. However, ensuring\ntheir effectiveness across multiple languages presents unique challenges.\nMultilingual prompt engineering has emerged as a key approach to enhance LLMs'\ncapabilities in diverse linguistic settings without requiring extensive\nparameter re-training or fine-tuning. With growing interest in multilingual\nprompt engineering over the past two to three years, researchers have explored\nvarious strategies to improve LLMs' performance across languages and NLP tasks.\nBy crafting structured natural language prompts, researchers have successfully\nextracted knowledge from LLMs across different languages, making these\ntechniques an accessible pathway for a broader audience, including those\nwithout deep expertise in machine learning, to harness the capabilities of\nLLMs. In this paper, we survey and categorize different multilingual prompting\ntechniques based on the NLP tasks they address across a diverse set of datasets\nthat collectively span around 250 languages. We further highlight the LLMs\nemployed, present a taxonomy of approaches and discuss potential\nstate-of-the-art (SoTA) methods for specific multilingual datasets.\nAdditionally, we derive a range of insights across language families and\nresource levels (high-resource vs. low-resource), including analyses such as\nthe distribution of NLP tasks by language resource type and the frequency of\nprompting methods across different language families. Our survey reviews 36\nresearch papers covering 39 prompting techniques applied to 30 multilingual NLP\ntasks, with the majority of these studies published in the last two years.",
    "pdf_url": "http://arxiv.org/pdf/2505.11665v1",
    "published": "2025-05-16T19:59:17+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11664v1",
    "title": "A Local Polyak-Lojasiewicz and Descent Lemma of Gradient Descent For Overparametrized Linear Models",
    "authors": [
      "Ziqing Xu",
      "Hancheng Min",
      "Salma Tarmoun",
      "Enrique Mallada",
      "Rene Vidal"
    ],
    "abstract": "Most prior work on the convergence of gradient descent (GD) for\noverparameterized neural networks relies on strong assumptions on the step size\n(infinitesimal), the hidden-layer width (infinite), or the initialization\n(large, spectral, balanced). Recent efforts to relax these assumptions focus on\ntwo-layer linear networks trained with the squared loss. In this work, we\nderive a linear convergence rate for training two-layer linear neural networks\nwith GD for general losses and under relaxed assumptions on the step size,\nwidth, and initialization. A key challenge in deriving this result is that\nclassical ingredients for deriving convergence rates for nonconvex problems,\nsuch as the Polyak-{\\L}ojasiewicz (PL) condition and Descent Lemma, do not hold\nglobally for overparameterized neural networks. Here, we prove that these two\nconditions hold locally with local constants that depend on the weights. Then,\nwe provide bounds on these local constants, which depend on the initialization\nof the weights, the current loss, and the global PL and smoothness constants of\nthe non-overparameterized model. Based on these bounds, we derive a linear\nconvergence rate for GD. Our convergence analysis not only improves upon prior\nresults but also suggests a better choice for the step size, as verified\nthrough our numerical experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.11664v1",
    "published": "2025-05-16T19:57:22+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11663v1",
    "title": "Adaptive Ergodic Search with Energy-Aware Scheduling for Persistent Multi-Robot Missions",
    "authors": [
      "Kaleb Ben Naveed",
      "Devansh R. Agrawal",
      "Rahul Kumar",
      "Dimitra Panagou"
    ],
    "abstract": "Autonomous robots are increasingly deployed for long-term\ninformation-gathering tasks, which pose two key challenges: planning\ninformative trajectories in environments that evolve across space and time, and\nensuring persistent operation under energy constraints. This paper presents a\nunified framework, mEclares, that addresses both challenges through adaptive\nergodic search and energy-aware scheduling in multi-robot systems. Our\ncontributions are two-fold: (1) we model real-world variability using\nstochastic spatiotemporal environments, where the underlying information\nevolves unpredictably due to process uncertainty. To guide exploration, we\nconstruct a target information spatial distribution (TISD) based on clarity, a\nmetric that captures the decay of information in the absence of observations\nand highlights regions of high uncertainty; and (2) we introduce Robustmesch\n(Rmesch), an online scheduling method that enables persistent operation by\ncoordinating rechargeable robots sharing a single mobile charging station.\nUnlike prior work, our approach avoids reliance on preplanned schedules, static\nor dedicated charging stations, and simplified robot dynamics. Instead, the\nscheduler supports general nonlinear models, accounts for uncertainty in the\nestimated position of the charging station, and handles central node failures.\nThe proposed framework is validated through real-world hardware experiments,\nand feasibility guarantees are provided under specific assumptions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11663v1",
    "published": "2025-05-16T19:57:11+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11662v1",
    "title": "Jets of flat partial connections",
    "authors": [
      "Gabriel Fazoli"
    ],
    "abstract": "We define and study jets of flat partial connections in the setting of smooth\nfoliations and flat partial connections on locally free sheaves. In the case of\ncodimension one foliations, we apply this definition to characterize\ntransversely affine and transversely projective structures. For foliations of\narbitrary codimension, we use jets of the Bott connection on the normal sheaf\nto define the prolongation of a transversely projective structure, and then\napply it to produce singular transversely projective structures.",
    "pdf_url": "http://arxiv.org/pdf/2505.11662v1",
    "published": "2025-05-16T19:56:32+00:00",
    "categories": [
      "math.CV",
      "math.DG",
      "32M10, 32M25, 53C12, 53C30"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11661v1",
    "title": "Learning from Less: Guiding Deep Reinforcement Learning with Differentiable Symbolic Planning",
    "authors": [
      "Zihan Ye",
      "Oleg Arenz",
      "Kristian Kersting"
    ],
    "abstract": "When tackling complex problems, humans naturally break them down into\nsmaller, manageable subtasks and adjust their initial plans based on\nobservations. For instance, if you want to make coffee at a friend's place, you\nmight initially plan to grab coffee beans, go to the coffee machine, and pour\nthem into the machine. Upon noticing that the machine is full, you would skip\nthe initial steps and proceed directly to brewing. In stark contrast, state of\nthe art reinforcement learners, such as Proximal Policy Optimization (PPO),\nlack such prior knowledge and therefore require significantly more training\nsteps to exhibit comparable adaptive behavior. Thus, a central research\nquestion arises: \\textit{How can we enable reinforcement learning (RL) agents\nto have similar ``human priors'', allowing the agent to learn with fewer\ntraining interactions?} To address this challenge, we propose differentiable\nsymbolic planner (Dylan), a novel framework that integrates symbolic planning\ninto Reinforcement Learning. Dylan serves as a reward model that dynamically\nshapes rewards by leveraging human priors, guiding agents through intermediate\nsubtasks, thus enabling more efficient exploration. Beyond reward shaping,\nDylan can work as a high level planner that composes primitive policies to\ngenerate new behaviors while avoiding common symbolic planner pitfalls such as\ninfinite execution loops. Our experimental evaluations demonstrate that Dylan\nsignificantly improves RL agents' performance and facilitates generalization to\nunseen tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11661v1",
    "published": "2025-05-16T19:52:36+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11660v1",
    "title": "Advancing Averaged Primer Vector Theory with Bang-Bang Control and Eclipsing",
    "authors": [
      "Noah Lifset",
      "Ryan P. Russell"
    ],
    "abstract": "Low-thrust, many-revolution spacecraft trajectories are increasingly required\nfor mission design due to the efficiency and reliability of electric propulsion\ntechnology. Primer vector theory using averaged dynamics is well suited for\nsuch applications, but is difficult to implement in a way that maintains both\noptimality and computational efficiency. An improved model is presented that\ncombines advances from several past works into a general and practical\nformulation for minimum-fuel, perturbed Keplerian dynamics. The model maintains\ncomputational efficiency of dynamics averaging with optimal handling of the\neclipsing constraint and bang-bang control through the use of the Leibniz\nintegral rule for multi-arc averaging. A subtle, but important singularity\narising from the averaged eclipsing constraint is identified and fixed. A\nmaximum number of six switching function roots per revolution is established\nwithin the averaged dynamics. This new theoretical insight provides a practical\nupper-bound on the number of thrusting arcs required for any low-thrust\noptimization problem. Variational equations are provided for fast and accurate\ncalculation of the state transition matrix for use in targeting and\noptimization. The dynamics include generic two-body perturbations and an\nexpanded state to allow for sensitivity calculations with respect to launch\ndate and flight time. A 48-revolution GTO to GEO transfer is used to directly\ncompare optimal averaged and unaveraged trajectories. The capabilities of\naveraged dynamics are then demonstrated with an optimal 486-revolution GTO to\nGEO minimum fuel transfer.",
    "pdf_url": "http://arxiv.org/pdf/2505.11660v1",
    "published": "2025-05-16T19:51:42+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11659v1",
    "title": "Programmable metasurfaces for future photonic artificial intelligence",
    "authors": [
      "Loubnan Abou-Hamdan",
      "Emil Marinov",
      "Peter Wiecha",
      "Philipp del Hougne",
      "Tianyu Wang",
      "Patrice Genevet"
    ],
    "abstract": "Photonic neural networks (PNNs), which share the inherent benefits of\nphotonic systems, such as high parallelism and low power consumption, could\nchallenge traditional digital neural networks in terms of energy efficiency,\nlatency, and throughput. However, producing scalable photonic artificial\nintelligence (AI) solutions remains challenging. To make photonic AI models\nviable, the scalability problem needs to be solved. Large optical AI models\nimplemented on PNNs are only commercially feasible if the advantages of optical\ncomputation outweigh the cost of their input-output overhead. In this\nPerspective, we discuss how field-programmable metasurface technology may\nbecome a key hardware ingredient in achieving scalable photonic AI accelerators\nand how it can compete with current digital electronic technologies.\nProgrammability or reconfigurability is a pivotal component for PNN hardware,\nenabling in situ training and accommodating non-stationary use cases that\nrequire fine-tuning or transfer learning. Co-integration with electronics, 3D\nstacking, and large-scale manufacturing of metasurfaces would significantly\nimprove PNN scalability and functionalities. Programmable metasurfaces could\naddress some of the current challenges that PNNs face and enable\nnext-generation photonic AI technology.",
    "pdf_url": "http://arxiv.org/pdf/2505.11659v1",
    "published": "2025-05-16T19:50:01+00:00",
    "categories": [
      "physics.optics",
      "cs.AI",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.11658v1",
    "title": "The Hyperbolic Tangent as an Educational Tool for Teaching Variable Acceleration",
    "authors": [
      "Scott C. Scharlach"
    ],
    "abstract": "This paper presents an approximate analytical solution to the Falling\nAstronaut Problem by means of the hyperbolic tangent, and it explores the\neducational opportunities presented by this technique. The author's previous\npaper presented a function for time in terms of position t(x) that modeled the\nmotion of an astronaut as she falls from an arbitrary height to the surface of\na spherical planet with no air resistance, but an exact analytical function for\nposition in terms of time x(t) was not found. This paper derives an approximate\nfunction for x(t) using kinematic equations with constant acceleration and\n\"switch functions,\" specifically the hyperbolic tangent. The paper concludes\nwith a discussion of the pedagogical implications of the technique, its\npotential for deepening student understanding of non-constant motion, and\napplications beyond the classroom.",
    "pdf_url": "http://arxiv.org/pdf/2505.11658v1",
    "published": "2025-05-16T19:49:48+00:00",
    "categories": [
      "physics.ed-ph",
      "physics.class-ph"
    ],
    "primary_category": "physics.ed-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11657v1",
    "title": "Heteroclinic Connection in a Nicholson's delayed model with Harvesting term",
    "authors": [
      "Adrian Gomez",
      "Cesar Guayasamin"
    ],
    "abstract": "In this paper we prove the existence of monotone heteroclinic solutions for\nthe delayed Nicholson's blowflies model with harvesting:\n  \\[\n  x'(t) = -\\delta x(t) - Hx(t-\\sigma) + \\rho x(t-r)e^{-x(t-r)}.\n  \\]\n  Under the condition $1 < \\dfrac{\\rho}{\\delta+H} \\leq e$, we establish the\nconnection between the equilibria $0$ and $\\ln(\\rho/(\\delta+H))$ using the Wu\nand Zou monotone iteration method adapted for two delays ($\\sigma \\neq r$). The\nproof combines explicit upper and lower solutions construction with\ncharacteristic equation analysis, supported by numerical simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.11657v1",
    "published": "2025-05-16T19:48:53+00:00",
    "categories": [
      "math.DS",
      "34K26 (Primary), 34K20, 92D25, 34K12, 34K19"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.11656v2",
    "title": "Corrigendum to the paper 'Some notes on the classification of shift spaces: Shifts of Finite Type; Sofic Shifts; and Finitely Defined Shifts' [Bulletin of the Brazilian Mathematical Society, New Series (2022), 53, 981-1031]",
    "authors": [
      "Marcelo Sobottka"
    ],
    "abstract": "This paper is a corrigendum to the article 'Some notes on the classification\nof shift spaces: Shifts of Finite Type; Sofic Shifts; and Finitely Defined\nShifts'. In this article we correct Lemma 5.3. Therefore, we follow correcting\nstatements and proofs of subsequent results that depend on Lemma 5.3.",
    "pdf_url": "http://arxiv.org/pdf/2505.11656v2",
    "published": "2025-05-16T19:47:14+00:00",
    "categories": [
      "math.DS",
      "37B10, 37B15"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.11655v1",
    "title": "Narrowing RIFT: Focused simulation-based-inference for interpreting exceptional GW sources",
    "authors": [
      "Katelyn J. Wagner",
      "R. O'Shaughnessy",
      "A. Yelikar",
      "N. Manning",
      "D. Fernando",
      "J. Lange",
      "V. Tiwari",
      "A. Fernando",
      "D. Williams"
    ],
    "abstract": "The Rapid Iterative FiTting (RIFT) parameter inference algorithm provides a\nsimulation-based inference approach to efficient, highly-parallelized parameter\ninference for GW sources. Previous editions of RIFT have conservatively\noptimized for robust inference about poorly constrained observations. In this\npaper, we summarize algorithm enhancements and operating point choices to\nenable inference for more exceptional compact binaries. Using the\npreviously-reported RIFT/asimov interface to efficiently perform analyses on\nevents with reproducible settings consistent with past work, we demonstrate\nthat the latest version of RIFT can efficiently analyze events with multiple\ncostly models including the effects of precession or eccentricity.",
    "pdf_url": "http://arxiv.org/pdf/2505.11655v1",
    "published": "2025-05-16T19:46:57+00:00",
    "categories": [
      "astro-ph.IM",
      "gr-qc"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.11654v3",
    "title": "UrbanMind: Urban Dynamics Prediction with Multifaceted Spatial-Temporal Large Language Models",
    "authors": [
      "Yuhang Liu",
      "Yingxue Zhang",
      "Xin Zhang",
      "Ling Tian",
      "Yanhua Li",
      "Jun Luo"
    ],
    "abstract": "Understanding and predicting urban dynamics is crucial for managing\ntransportation systems, optimizing urban planning, and enhancing public\nservices. While neural network-based approaches have achieved success, they\noften rely on task-specific architectures and large volumes of data, limiting\ntheir ability to generalize across diverse urban scenarios. Meanwhile, Large\nLanguage Models (LLMs) offer strong reasoning and generalization capabilities,\nyet their application to spatial-temporal urban dynamics remains underexplored.\nExisting LLM-based methods struggle to effectively integrate multifaceted\nspatial-temporal data and fail to address distributional shifts between\ntraining and testing data, limiting their predictive reliability in real-world\napplications. To bridge this gap, we propose UrbanMind, a novel\nspatial-temporal LLM framework for multifaceted urban dynamics prediction that\nensures both accurate forecasting and robust generalization. At its core,\nUrbanMind introduces Muffin-MAE, a multifaceted fusion masked autoencoder with\nspecialized masking strategies that capture intricate spatial-temporal\ndependencies and intercorrelations among multifaceted urban dynamics.\nAdditionally, we design a semantic-aware prompting and fine-tuning strategy\nthat encodes spatial-temporal contextual details into prompts, enhancing LLMs'\nability to reason over spatial-temporal patterns. To further improve\ngeneralization, we introduce a test time adaptation mechanism with a test data\nreconstructor, enabling UrbanMind to dynamically adjust to unseen test data by\nreconstructing LLM-generated embeddings. Extensive experiments on real-world\nurban datasets across multiple cities demonstrate that UrbanMind consistently\noutperforms state-of-the-art baselines, achieving high accuracy and robust\ngeneralization, even in zero-shot settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.11654v3",
    "published": "2025-05-16T19:38:06+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11653v1",
    "title": "Probing Lepton Flavor Violation at Linear Electron-Positron Colliders",
    "authors": [
      "Wolfgang Altmannshofer",
      "Pankaj Munbodh"
    ],
    "abstract": "The production of $\\tau\\mu$ pairs in electron-positron collisions offers a\npowerful probe of lepton flavor violation. In this work, we calculate the $e^+\ne^- \\to \\tau \\mu$ cross section within the framework of the Standard Model\nEffective Field Theory, allowing for arbitrary $e^+e^-$ beam polarizations. We\nthen estimate the sensitivities of proposed future linear colliders, ILC and\nCLIC, to effective lepton flavor-violating interactions. The high\ncenter-of-mass energies achievable at these machines provide particularly\nstrong sensitivity to four-fermion operators. Furthermore, the polarization of\nthe $e^+e^-$ beams enables novel tests of the chirality structure of these\ninteractions. We find that our projected sensitivities not only complement but\nin certain scenarios surpass those achievable with low-energy tau decay\nmeasurements at Belle~II.",
    "pdf_url": "http://arxiv.org/pdf/2505.11653v1",
    "published": "2025-05-16T19:34:03+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11652v1",
    "title": "Magnetic Interactions and Cluster Formation: Boosting Surface Thermopower in Topological Insulators",
    "authors": [
      "M. Tirgar",
      "H. Barati Abgarmi",
      "J. Abouie"
    ],
    "abstract": "This study theoretically investigates the thermoelectric properties of\nmagnetic topological insulators (TIs), with a focus on the effects of magnetic\natom exchange interactions on the thermopower of their surfaces. Our findings\ndemonstrate that interactions among magnetic atoms significantly enhance the\nSeebeck coefficient. The formation of magnetic clusters through exchange\ninteractions increases the scattering of Dirac electrons, thereby improving the\nthermoelectric power factor. We conducted extensive Monte Carlo simulations\nacross various configurations, including ferromagnetic and antiferromagnetic\nbulk materials, comparing magnetic clustering in Ising and Heisenberg models.\nSpecial attention was given to cluster definitions related to surface critical\ntemperatures. Our analysis indicates that the size and number of magnetic\nclusters influence relaxation times, as well as electrical and thermal\nresistivities, ultimately affecting the thermopower. Optimized interlayer and\nintralayer interactions can elevate the surface thermopower of TIs to values\ncomparable to those observed in antiferromagnetic ${\\rm MnTe}$, renowned for\nits unique spin-based thermoelectric properties. This work highlights the\npotential of magnetic TIs for thermoelectric applications and sets the stage\nfor future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.11652v1",
    "published": "2025-05-16T19:26:08+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.11651v2",
    "title": "MIRACL-VISION: A Large, multilingual, visual document retrieval benchmark",
    "authors": [
      "Radek Osmulski",
      "Gabriel de Souza P. Moreira",
      "Ronay Ak",
      "Mengyao Xu",
      "Benedikt Schifferer",
      "Even Oldridge"
    ],
    "abstract": "Document retrieval is an important task for search and Retrieval-Augmented\nGeneration (RAG) applications. Large Language Models (LLMs) have contributed to\nimproving the accuracy of text-based document retrieval. However, documents\nwith complex layout and visual elements like tables, charts and infographics\nare not perfectly represented in textual format. Recently, image-based document\nretrieval pipelines have become popular, which use visual large language models\n(VLMs) to retrieve relevant page images given a query. Current evaluation\nbenchmarks on visual document retrieval are limited, as they primarily focus\nonly English language, rely on synthetically generated questions and offer a\nsmall corpus size. Therefore, we introduce MIRACL-VISION, a multilingual visual\ndocument retrieval evaluation benchmark. MIRACL-VISION covers 18 languages, and\nis an extension of the MIRACL dataset, a popular benchmark to evaluate\ntext-based multilingual retrieval pipelines. MIRACL was built using a\nhuman-intensive annotation process to generate high-quality questions. In order\nto reduce MIRACL-VISION corpus size to make evaluation more compute friendly\nwhile keeping the datasets challenging, we have designed a method for\neliminating the \"easy\" negatives from the corpus. We conducted extensive\nexperiments comparing MIRACL-VISION with other benchmarks, using popular public\ntext and image models. We observe a gap in state-of-the-art VLM-based embedding\nmodels on multilingual capabilities, with up to 59.7% lower retrieval accuracy\nthan a text-based retrieval models. Even for the English language, the visual\nmodels retrieval accuracy is 12.1% lower compared to text-based models.\nMIRACL-VISION is a challenging, representative, multilingual evaluation\nbenchmark for visual retrieval pipelines and will help the community build\nrobust models for document retrieval.",
    "pdf_url": "http://arxiv.org/pdf/2505.11651v2",
    "published": "2025-05-16T19:22:19+00:00",
    "categories": [
      "cs.IR",
      "cs.CV"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11650v1",
    "title": "Two-dimensional capillary liquid drop: Craig-Sulem formulation on $\\mathbb{T}^1$ and bifurcations from multiple eigenvalues of rotating waves",
    "authors": [
      "Giuseppe La Scala"
    ],
    "abstract": "We consider the free boundary problem for a two-dimensional, incompressible,\nperfect, irrotational liquid drop of nearly circular shape with capillarity:\nthat is, we consider the 2D version of the 3D capillary drop problem treated in\nBaldi-Julin-La Manna [11] and Baldi-La Manna-La Scala [12]. In particular, we\nderive its Craig-Sulem formulation firstly over the circle, then over the\none-dimensional flat torus; the arising equations are similar to the pure\ncapillary Water Waves for the ocean problem, apart from conformal factors and\nadditional terms due to curvature terms. Then, we show its Hamiltonian\nstructure and we derive constants of motions from symmetries, one of which is\nthe invariance by the torus action. Thanks to this invariance, we show the\nexistence of orbits of rotating wave solutions (which are the analogous of\ntravelling waves of the ocean problem) by bifurcation from multiple eigenvalues\nin the spirit of Moser-Weinstein [44, 56] and Craig-Nicholls [22] variational\napproaches; in particular, we can parametrize such orbits by the angular\nmomentum, and for each value of it they are unique. This will imply that each\norbit is generated by symmetric rotating waves.",
    "pdf_url": "http://arxiv.org/pdf/2505.11650v1",
    "published": "2025-05-16T19:21:09+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11649v3",
    "title": "Illusions of Intimacy: Emotional Attachment and Emerging Psychological Risks in Human-AI Relationships",
    "authors": [
      "Minh Duc Chu",
      "Patrick Gerard",
      "Kshitij Pawar",
      "Charles Bickham",
      "Kristina Lerman"
    ],
    "abstract": "Emotionally responsive social chatbots, such as those produced by Replika and\nCharacter.AI, increasingly serve as companions that offer empathy, support, and\nentertainment. While these systems appear to meet fundamental human needs for\nconnection, they raise concerns about how artificial intimacy affects emotional\nregulation, well-being, and social norms. Prior research has focused on user\nperceptions or clinical contexts but lacks large-scale, real-world analysis of\nhow these interactions unfold. This paper addresses that gap by analyzing over\n30K user-shared conversations with social chatbots to examine the emotional\ndynamics of human-AI relationships. Using computational methods, we identify\npatterns of emotional mirroring and synchrony that closely resemble how people\nbuild emotional connections. Our findings show that users-often young, male,\nand prone to maladaptive coping styles-engage in parasocial interactions that\nrange from affectionate to abusive. Chatbots consistently respond in\nemotionally consistent and affirming ways. In some cases, these dynamics\nresemble toxic relationship patterns, including emotional manipulation and\nself-harm. These findings highlight the need for guardrails, ethical design,\nand public education to preserve the integrity of emotional connection in an\nage of artificial companionship.",
    "pdf_url": "http://arxiv.org/pdf/2505.11649v3",
    "published": "2025-05-16T19:19:12+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11648v1",
    "title": "Joint Graph Estimation and Signal Restoration for Robust Federated Learning",
    "authors": [
      "Tsutahiro Fukuhara",
      "Junya Hara",
      "Hiroshi Higashi",
      "Yuichi Tanaka"
    ],
    "abstract": "We propose a robust aggregation method for model parameters in federated\nlearning (FL) under noisy communications. FL is a distributed machine learning\nparadigm in which a central server aggregates local model parameters from\nmultiple clients. These parameters are often noisy and/or have missing values\nduring data collection, training, and communication between the clients and\nserver. This may cause a considerable drop in model accuracy. To address this\nissue, we learn a graph that represents pairwise relationships between model\nparameters of the clients during aggregation. We realize it with a joint\nproblem of graph learning and signal (i.e., model parameters) restoration. The\nproblem is formulated as a difference-of-convex (DC) optimization, which is\nefficiently solved via a proximal DC algorithm. Experimental results on MNIST\nand CIFAR-10 datasets show that the proposed method outperforms existing\napproaches by up to $2$--$5\\%$ in classification accuracy under biased data\ndistributions and noisy conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11648v1",
    "published": "2025-05-16T19:17:59+00:00",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13509v1",
    "title": "Fuck the Algorithm: Conceptual Issues in Algorithmic Bias",
    "authors": [
      "Catherine Stinson"
    ],
    "abstract": "Algorithmic bias has been the subject of much recent controversy. To clarify\nwhat is at stake and to make progress resolving the controversy, a better\nunderstanding of the concepts involved would be helpful. The discussion here\nfocuses on the disputed claim that algorithms themselves cannot be biased. To\nclarify this claim we need to know what kind of thing 'algorithms themselves'\nare, and to disambiguate the several meanings of 'bias' at play. This further\ninvolves showing how bias of moral import can result from statistical biases,\nand drawing connections to previous conceptual work about political artifacts\nand oppressive things. Data bias has been identified in domains like hiring,\npolicing and medicine. Examples where algorithms themselves have been\npinpointed as the locus of bias include recommender systems that influence\nmedia consumption, academic search engines that influence citation patterns,\nand the 2020 UK algorithmically-moderated A-level grades. Recognition that\nalgorithms are a kind of thing that can be biased is key to making decisions\nabout responsibility for harm, and preventing algorithmically mediated\ndiscrimination.",
    "pdf_url": "http://arxiv.org/pdf/2505.13509v1",
    "published": "2025-05-16T19:17:00+00:00",
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11647v1",
    "title": "A cryogenic buffer gas beam source with in-situ ablation target replacement",
    "authors": [
      "Zhen Han",
      "Zack Lasner",
      "Collin Diver",
      "Peiran Hu",
      "Takahiko Masuda",
      "Xing Wu",
      "Ayami Hiramoto",
      "Maya Watts",
      "Satoshi Uetake",
      "Koji Yoshimura",
      "Xing Fan",
      "Gerald Gabrielse",
      "John M. Doyle",
      "David DeMille"
    ],
    "abstract": "The design and performance of a cryogenic buffer gas beam (CBGB) source with\na load-lock system is presented. The ACME III electron electric dipole moment\n(eEDM) search experiment uses this source to produce a beam of cold, slow\nthorium monoxide (ThO) molecules. A key feature of the apparatus is its\ncapability to replace ablation targets without interrupting vacuum or cryogenic\nconditions, increasing the average signal in the eEDM search. The source\nproduces approximately $1.3 \\times 10^{11}$ ground-state ThO molecules per\npulse, with a rotational temperature of $4.8$ K, molecular beam solid angle of\n$0.31$ sr, and forward velocity of $200$ m/s. These parameters match the\nperformance of traditional sources that require time-consuming thermal cycles\nfor target replacement. A long-term yield improvement of about 40% is achieved\nwhen the load-lock system is used to replace targets biweekly.",
    "pdf_url": "http://arxiv.org/pdf/2505.11647v1",
    "published": "2025-05-16T19:14:41+00:00",
    "categories": [
      "physics.atom-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17055v1",
    "title": "Enhancing Mathematics Learning for Hard-of-Hearing Students Through Real-Time Palestinian Sign Language Recognition: A New Dataset",
    "authors": [
      "Fidaa Khandaqji",
      "Huthaifa I. Ashqar",
      "Abdelrahem Atawnih"
    ],
    "abstract": "The study aims to enhance mathematics education accessibility for\nhard-of-hearing students by developing an accurate Palestinian sign language\nPSL recognition system using advanced artificial intelligence techniques. Due\nto the scarcity of digital resources for PSL, a custom dataset comprising 41\nmathematical gesture classes was created, and recorded by PSL experts to ensure\nlinguistic accuracy and domain specificity. To leverage\nstate-of-the-art-computer vision techniques, a Vision Transformer ViTModel was\nfine-tuned for gesture classification. The model achieved an accuracy of\n97.59%, demonstrating its effectiveness in recognizing mathematical signs with\nhigh precision and reliability. This study highlights the role of deep learning\nin developing intelligent educational tools that bridge the learning gap for\nhard-of-hearing students by providing AI-driven interactive solutions to\nenhance mathematical comprehension. This work represents a significant step\ntoward innovative and inclusive frosting digital integration in specialized\nlearning environments. The dataset is hosted on Hugging Face at\nhttps://huggingface.co/datasets/fidaakh/STEM_data.",
    "pdf_url": "http://arxiv.org/pdf/2505.17055v1",
    "published": "2025-05-16T19:14:25+00:00",
    "categories": [
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11646v1",
    "title": "FLOW-BENCH: Towards Conversational Generation of Enterprise Workflows",
    "authors": [
      "Evelyn Duesterwald",
      "Siyu Huo",
      "Vatche Isahagian",
      "K. R. Jayaram",
      "Ritesh Kumar",
      "Vinod Muthusamy",
      "Punleuk Oum",
      "Debashish Saha",
      "Gegi Thomas",
      "Praveen Venkateswaran"
    ],
    "abstract": "Business process automation (BPA) that leverages Large Language Models (LLMs)\nto convert natural language (NL) instructions into structured business process\nartifacts is becoming a hot research topic. This paper makes two technical\ncontributions -- (i) FLOW-BENCH, a high quality dataset of paired natural\nlanguage instructions and structured business process definitions to evaluate\nNL-based BPA tools, and support bourgeoning research in this area, and (ii)\nFLOW-GEN, our approach to utilize LLMs to translate natural language into an\nintermediate representation with Python syntax that facilitates final\nconversion into widely adopted business process definition languages, such as\nBPMN and DMN. We bootstrap FLOW-BENCH by demonstrating how it can be used to\nevaluate the components of FLOW-GEN across eight LLMs of varying sizes. We hope\nthat FLOW-GEN and FLOW-BENCH catalyze further research in BPA making it more\naccessible to novice and expert users.",
    "pdf_url": "http://arxiv.org/pdf/2505.11646v1",
    "published": "2025-05-16T19:14:19+00:00",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11645v1",
    "title": "Urban Representation Learning for Fine-grained Economic Mapping: A Semi-supervised Graph-based Approach",
    "authors": [
      "Jinzhou Cao",
      "Xiangxu Wang",
      "Jiashi Chen",
      "Wei Tu",
      "Zhenhui Li",
      "Xindong Yang",
      "Tianhong Zhao",
      "Qingquan Li"
    ],
    "abstract": "Fine-grained economic mapping through urban representation learning has\nemerged as a crucial tool for evidence-based economic decisions. While existing\nmethods primarily rely on supervised or unsupervised approaches, they often\noverlook semi-supervised learning in data-scarce scenarios and lack unified\nmulti-task frameworks for comprehensive sectoral economic analysis. To address\nthese gaps, we propose SemiGTX, an explainable semi-supervised graph learning\nframework for sectoral economic mapping. The framework is designed with\ndedicated fusion encoding modules for various geospatial data modalities,\nseamlessly integrating them into a cohesive graph structure. It introduces a\nsemi-information loss function that combines spatial self-supervision with\nlocally masked supervised regression, enabling more informative and effective\nregion representations. Through multi-task learning, SemiGTX concurrently maps\nGDP across primary, secondary, and tertiary sectors within a unified model.\nExtensive experiments conducted in the Pearl River Delta region of China\ndemonstrate the model's superior performance compared to existing methods,\nachieving R2 scores of 0.93, 0.96, and 0.94 for the primary, secondary and\ntertiary sectors, respectively. Cross-regional experiments in Beijing and\nChengdu further illustrate its generality. Systematic analysis reveals how\ndifferent data modalities influence model predictions, enhancing explainability\nwhile providing valuable insights for regional development planning. This\nrepresentation learning framework advances regional economic monitoring through\ndiverse urban data integration, providing a robust foundation for precise\neconomic forecasting.",
    "pdf_url": "http://arxiv.org/pdf/2505.11645v1",
    "published": "2025-05-16T19:12:08+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11644v1",
    "title": "Quintessence Dark Energy from non-perturbative Higgs-Yang-Mills mass gap",
    "authors": [
      "Marco Frasca",
      "Anish Ghoshal",
      "Massimilano Rinaldi"
    ],
    "abstract": "We discuss the possibility that dark energy arises from a strongly-coupled\nHiggs-Yang-Mills set of interacting fields in the non-perturbative regime. We\nchoose the simplest $SU(2)$ representation, which is compatible with the\nCosmological Principle. One of the components of the Higgs doublet act as an\neffective quintessence scalar field interacting with both gravity and the gauge\nfield. We devise a multiple time scale approach to solve the equations of\nmotion through a hierarchy of the couplings, utilizing exact solutions in terms\nof Jacobi elliptic functions. We observe that the time scale of variation of\nthe Hubble constant is the slowest one, while, for the scalar field, assuming\nthat its self-coupling is smaller than the coupling of the gauge field,\nrepresents an intermediate time scale. From the consistency of the Friedmann\nequations, we show how the effect of the scalar field is to give origin to dark\nenergy with a proper equation of state corrected by a very small time-dependent\nterm. Finally, agreement with cosmological data for the dark energy density is\nshown without relying on the fine-tuning of the physical constants of the\nmodel.",
    "pdf_url": "http://arxiv.org/pdf/2505.11644v1",
    "published": "2025-05-16T19:11:25+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11643v1",
    "title": "Can an Easy-to-Hard Curriculum Make Reasoning Emerge in Small Language Models? Evidence from a Four-Stage Curriculum on GPT-2",
    "authors": [
      "Xiang Fu"
    ],
    "abstract": "We demonstrate that a developmentally ordered curriculum markedly improves\nreasoning transparency and sample-efficiency in small language models (SLMs).\nConcretely, we train Cognivolve, a 124 M-parameter GPT-2 model, on a four-stage\nsyllabus that ascends from lexical matching to multi-step symbolic inference\nand then evaluate it without any task-specific fine-tuning. Cognivolve reaches\ntarget accuracy in half the optimization steps of a single-phase baseline,\nactivates an order-of-magnitude more gradient-salient reasoning heads, and\nshifts those heads toward deeper layers, yielding higher-entropy attention that\nbalances local and long-range context. The same curriculum applied out of order\nor with optimizer resets fails to reproduce these gains, confirming that\nprogression--not extra compute--drives the effect. We also identify open\nchallenges: final-answer success still lags a conventional run by about 30%,\nand our saliency probe under-detects verbal-knowledge heads in the hardest\nstage, suggesting directions for mixed-stage fine-tuning and probe expansion.",
    "pdf_url": "http://arxiv.org/pdf/2505.11643v1",
    "published": "2025-05-16T19:08:31+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11642v2",
    "title": "PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks Through Mutual Reasoning",
    "authors": [
      "Falong Fan",
      "Xi Li"
    ],
    "abstract": "Multi-agent systems leverage advanced AI models as autonomous agents that\ninteract, cooperate, or compete to complete complex tasks across applications\nsuch as robotics and traffic management. Despite their growing importance,\nsafety in multi-agent systems remains largely underexplored, with most research\nfocusing on single AI models rather than interacting agents. This work\ninvestigates backdoor vulnerabilities in multi-agent systems and proposes a\ndefense mechanism based on agent interactions. By leveraging reasoning\nabilities, each agent evaluates responses from others to detect illogical\nreasoning processes, which indicate poisoned agents. Experiments on LLM-based\nmulti-agent systems, including ChatGPT series and Llama 3, demonstrate the\neffectiveness of the proposed method, achieving high accuracy in identifying\npoisoned agents while minimizing false positives on clean agents. We believe\nthis work provides insights into multi-agent system safety and contributes to\nthe development of robust, trustworthy AI interactions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11642v2",
    "published": "2025-05-16T19:08:29+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11641v1",
    "title": "Challenges in Model Agnostic Controller Learning for Unstable Systems",
    "authors": [
      "Mario Sznaier",
      "Mustafa Bozdag"
    ],
    "abstract": "Model agnostic controller learning, for instance by direct policy\noptimization, has been the object of renewed attention lately, since it avoids\na computationally expensive system identification step. Indeed, direct policy\nsearch has been empirically shown to lead to optimal controllers in a number of\ncases of practical importance. However, to date, these empirical results have\nnot been backed up with a comprehensive theoretical analysis for general\nproblems. In this paper we use a simple example to show that direct policy\noptimization is not directly generalizable to other seemingly simple problems.\nIn such cases, direct optimization of a performance index can lead to unstable\npole/zero cancellations, resulting in the loss of internal stability and\nunbounded outputs in response to arbitrarily small perturbations. We conclude\nthe paper by analyzing several alternatives to avoid this phenomenon,\nsuggesting some new directions in direct control policy optimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.11641v1",
    "published": "2025-05-16T19:08:21+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11640v2",
    "title": "BandRC: Band Shifted Raised Cosine Activated Implicit Neural Representations",
    "authors": [
      "Pandula Thennakoon",
      "Avishka Ranasinghe",
      "Mario De Silva",
      "Buwaneka Epakanda",
      "Roshan Godaliyadda",
      "Parakrama Ekanayake",
      "Vijitha Herath"
    ],
    "abstract": "In recent years, implicit neural representations (INRs) have gained\npopularity in the computer vision community. This is mainly due to the strong\nperformance of INRs in many computer vision tasks. These networks can extract a\ncontinuous signal representation given a discrete signal representation. In\nprevious studies, it has been repeatedly shown that INR performance has a\nstrong correlation with the activation functions used in its multilayer\nperceptrons. Although numerous activation functions have been proposed that are\ncompetitive with one another, they share some common set of challenges such as\nspectral bias(Lack of sensitivity to high-frequency content in signals),\nlimited robustness to signal noise and difficulties in simultaneous capturing\nboth local and global features. and furthermore, the requirement for manual\nparameter tuning. To address these issues, we introduce a novel activation\nfunction, Band Shifted Raised Cosine Activated Implicit Neural Networks\n$\\textbf{(BandRC)}$ tailored to enhance signal representation capacity further.\nWe also incorporate deep prior knowledge extracted from the signal to adjust\nthe activation functions through a task-specific model. Through a mathematical\nanalysis and a series of experiments which include image reconstruction (with\nan average PSNR improvement of +5.67 dB over the nearest counterpart across a\ndiverse image dataset), denoising (with a +0.46 dB increase in PSNR),\nsuper-resolution (with a +1.03 dB improvement over the nearest State-Of-The-Art\n(SOTA) method for 6X super-resolution), inpainting, and 3D shape reconstruction\nwe demonstrate the dominance of BandRC over existing state of the art\nactivation functions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11640v2",
    "published": "2025-05-16T19:08:01+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11639v1",
    "title": "Covariate-moderated Empirical Bayes Matrix Factorization",
    "authors": [
      "William R. P. Denault",
      "Karl Tayeb",
      "Peter Carbonetto",
      "Jason Willwerscheid",
      "Matthew Stephens"
    ],
    "abstract": "Matrix factorization is a fundamental method in statistics and machine\nlearning for inferring and summarizing structure in multivariate data. Modern\ndata sets often come with ``side information'' of various forms (images, text,\ngraphs) that can be leveraged to improve estimation of the underlying\nstructure. However, existing methods that leverage side information are limited\nin the types of data they can incorporate, and they assume specific parametric\nmodels. Here, we introduce a novel method for this problem, covariate-moderated\n  empirical Bayes matrix factorization (cEBMF). cEBMF is a modular framework\nthat accepts any type of side information that is processable by a\nprobabilistic model or neural network. The cEBMF framework can accommodate\ndifferent assumptions and constraints on the factors through the use of\ndifferent priors, and it adapts these priors to the data. We demonstrate the\nbenefits of cEBMF in simulations and in analyses of spatial transcriptomics and\nMovieLens data.",
    "pdf_url": "http://arxiv.org/pdf/2505.11639v1",
    "published": "2025-05-16T19:05:11+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.11638v2",
    "title": "Accelerating Natural Gradient Descent for PINNs with Randomized Numerical Linear Algebra",
    "authors": [
      "Ivan Bioli",
      "Carlo Marcati",
      "Giancarlo Sangalli"
    ],
    "abstract": "Natural Gradient Descent (NGD) has emerged as a promising optimization\nalgorithm for training neural network-based solvers for partial differential\nequations (PDEs), such as Physics-Informed Neural Networks (PINNs). However,\nits practical use is often limited by the high computational cost of solving\nlinear systems involving the Gramian matrix. While matrix-free NGD methods\nbased on the conjugate gradient (CG) method avoid explicit matrix inversion,\nthe ill-conditioning of the Gramian significantly slows the convergence of CG.\nIn this work, we extend matrix-free NGD to broader classes of problems than\npreviously considered and propose the use of Randomized Nystr\\\"om\npreconditioning to accelerate convergence of the inner CG solver. The resulting\nalgorithm demonstrates substantial performance improvements over existing\nNGD-based methods on a range of PDE problems discretized using neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11638v2",
    "published": "2025-05-16T19:00:40+00:00",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11637v1",
    "title": "Three-Dimensional Orbital Architectures and Detectability of Adjacent Companions to Hot Jupiters",
    "authors": [
      "Thomas MacLean",
      "Juliette Becker"
    ],
    "abstract": "The orbital properties of the (as-yet) small population of hot Jupiters with\nnearby planetary companions provide valuable constraints on the past migration\nprocesses of these systems. In this work, we explore the likelihood that\ndynamical perturbations could cause nearby inner or outer companions to hot\nJupiter to leave the transiting plane, potentially leaving these companions\nundetected despite their presence at formation. Using a combination of\nanalytical and numerical models, we examine the effects of stellar evolution on\nhot Jupiter systems with nearby companions and identify several possible\noutcomes. We find that while inner companions are generally unlikely to leave\nthe transiting plane, outer companions are more prone to decoupling from the\nhot Jupiter and becoming non-transiting, depending on the system's initial\norbital architecture. Additionally, we observe a range of dynamical behaviors,\nincluding overall stability, inclination excitation, and, in some cases,\ninstability leading to the ejection or collision of planets. We also show that\nthe effect of stellar obliquity (with respect to the mean planet of the\nplanets) is to amplify these effects and potentially cause outer companions to\nattain non-mutually-transiting configurations more often. Our results highlight\nthe complex dynamical pathways shaping the architectures of hot Jupiter\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11637v1",
    "published": "2025-05-16T19:00:05+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11636v1",
    "title": "Generalization Guarantees for Learning Branch-and-Cut Policies in Integer Programming",
    "authors": [
      "Hongyu Cheng",
      "Amitabh Basu"
    ],
    "abstract": "Mixed-integer programming (MIP) provides a powerful framework for\noptimization problems, with Branch-and-Cut (B&C) being the predominant\nalgorithm in state-of-the-art solvers. The efficiency of B&C critically depends\non heuristic policies for making sequential decisions, including node\nselection, cut selection, and branching variable selection. While traditional\nsolvers often employ heuristics with manually tuned parameters, recent\napproaches increasingly leverage machine learning, especially neural networks,\nto learn these policies directly from data. A key challenge is to understand\nthe theoretical underpinnings of these learned policies, particularly their\ngeneralization performance from finite data. This paper establishes rigorous\nsample complexity bounds for learning B&C policies where the scoring functions\nguiding each decision step (node, cut, branch) have a certain piecewise\npolynomial structure. This structure generalizes the linear models that form\nthe most commonly deployed policies in practice and investigated recently in a\nfoundational series of theoretical works by Balcan et al. Such piecewise\npolynomial policies also cover the neural network architectures (e.g., using\nReLU activations) that have been the focal point of contemporary practical\nstudies. Consequently, our theoretical framework closely reflects the models\nutilized by practitioners investigating machine learning within B&C, offering a\nunifying perspective relevant to both established theory and modern empirical\nresearch in this area. Furthermore, our theory applies to quite general\nsequential decision making problems beyond B&C.",
    "pdf_url": "http://arxiv.org/pdf/2505.11636v1",
    "published": "2025-05-16T19:00:02+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11635v1",
    "title": "The Gaussian-Multinoulli Restricted Boltzmann Machine: A Potts Model Extension of the GRBM",
    "authors": [
      "Nikhil Kapasi",
      "William Whitehead",
      "Luke Theogarajan"
    ],
    "abstract": "Many real-world tasks, from associative memory to symbolic reasoning, demand\ndiscrete, structured representations that standard continuous latent models\nstruggle to express naturally. We introduce the Gaussian-Multinoulli Restricted\nBoltzmann Machine (GM-RBM), a generative energy-based model that extends the\nGaussian-Bernoulli RBM (GB-RBM) by replacing binary hidden units with $q$-state\nPotts variables. This modification enables a combinatorially richer latent\nspace and supports learning over multivalued, interpretable latent concepts. We\nformally derive GM-RBM's energy function, learning dynamics, and conditional\ndistributions, showing that it preserves tractable inference and training\nthrough contrastive divergence. Empirically, we demonstrate that GM-RBMs model\ncomplex multimodal distributions more effectively than binary RBMs,\noutperforming them on tasks involving analogical recall and structured memory.\nOur results highlight GM-RBMs as a scalable framework for discrete latent\ninference with enhanced expressiveness and interoperability.",
    "pdf_url": "http://arxiv.org/pdf/2505.11635v1",
    "published": "2025-05-16T18:59:59+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11634v1",
    "title": "A Perturbation and Speciation-Based Algorithm for Dynamic Optimization Uninformed of Change",
    "authors": [
      "Federico Signorelli",
      "Anil Yaman"
    ],
    "abstract": "Dynamic optimization problems (DOPs) are challenging due to their changing\nconditions. This requires algorithms to be highly adaptable and efficient in\nterms of finding rapidly new optimal solutions under changing conditions.\nTraditional approaches often depend on explicit change detection, which can be\nimpractical or inefficient when the change detection is unreliable or\nunfeasible. We propose Perturbation and Speciation-Based Particle Swarm\nOptimization (PSPSO), a robust algorithm for uninformed dynamic optimization\nwithout requiring the information of environmental changes. The PSPSO combines\nspeciation-based niching, deactivation, and a newly proposed random\nperturbation mechanism to handle DOPs. PSPSO leverages a cyclical\nmulti-population framework, strategic resource allocation, and targeted noisy\nupdates, to adapt to dynamic environments. We compare PSPSO with several\nstate-of-the-art algorithms on the Generalized Moving Peaks Benchmark (GMPB),\nwhich covers a variety of scenarios, including simple and multi-modal dynamic\noptimization, frequent and intense changes, and high-dimensional spaces. Our\nresults show that PSPSO outperforms other state-of-the-art uninformed\nalgorithms in all scenarios and leads to competitive results compared to\ninformed algorithms. In particular, PSPSO shows strength in functions with high\ndimensionality or high frequency of change in the GMPB. The ablation study\nshowed the importance of the random perturbation component.",
    "pdf_url": "http://arxiv.org/pdf/2505.11634v1",
    "published": "2025-05-16T18:53:37+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11633v2",
    "title": "Chatting with Papers: A Hybrid Approach Using LLMs and Knowledge Graphs",
    "authors": [
      "Vyacheslav Tykhonov",
      "Han Yang",
      "Philipp Mayr",
      "Jetze Touber",
      "Andrea Scharnhorst"
    ],
    "abstract": "This demo paper reports on a new workflow \\textit{GhostWriter} that combines\nthe use of Large Language Models and Knowledge Graphs (semantic artifacts) to\nsupport navigation through collections. Situated in the research area of\nRetrieval Augmented Generation, this specific workflow represents the creation\nof local and adaptable chatbots. Based on the tool-suite\n\\textit{EverythingData} at the backend, \\textit{GhostWriter} provides an\ninterface that enables querying and ``chatting'' with a collection. Applied\niteratively, the workflow supports the information needs of researchers when\ninteracting with a collection of papers, whether it be to gain an overview, to\nlearn more about a specific concept and its context, and helps the researcher\nultimately to refine their research question in a controlled way. We\ndemonstrate the workflow for a collection of articles from the \\textit{method\ndata analysis} journal published by GESIS -- Leibniz-Institute for the Social\nSciences. We also point to further application areas.",
    "pdf_url": "http://arxiv.org/pdf/2505.11633v2",
    "published": "2025-05-16T18:51:51+00:00",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11632v1",
    "title": "Comparing GHZ-Based Strategies for Multipartite Entanglement Distribution in 2D Repeater Networks",
    "authors": [
      "Mohadeseh Azari",
      "Amy Babay",
      "Prashant Krishnamurthy",
      "Kaushik Seshadreesan"
    ],
    "abstract": "We conduct a comparative study to determine the initial quality necessary to\nextend the distance range of an $N$-qubit GHZ state (the parent state) using\ntwo-dimensional repeaters. We analyzed two strategies for distributing initial\nGHZ states using a centralized quantum switch to determine if any of the\nstrategies show benefits: i) A strategy that employs quantum memories at the\nswitch to retain quantum states entangled with each client node, where memory\nusage at the switch scales linearly with the number of clients, and ii) A\nstrategy predicated on GHZ measurements at the switch node without reliance on\nmemory assistance. In the former scenario, the switches generate GHZ states and\nteleport them to the clients by utilizing remote Bell pairs that are\nasynchronously generated and stored in memory. Conversely, in the latter\nscenario, the switches perform GHZ projective measurements on freshly generated\nremote Bell pairs without requiring local storage at the switch. To enhance the\ndistance range of GHZ-type entanglement distribution, we analyze the two\napproaches as foundational elements for a self-repeating, two-dimensional\nquantum repeater architecture. Here, the clients of the switch nodes become the\n2D repeater nodes that store elementary GHZ states in quantum memories, that\ncan then be fused together to generate long-distance GHZ-type entanglement\nbetween end users of the network. By examining the two strategies' entanglement\ndistribution rates and fidelities, we identify the conditions under which the\n2D repeater architecture enhances overall performance, and we determine whether\neither method is a superior building block for such a repeater structure. Our\nfindings illuminate the identification of effective modalities for the\nlong-distance multipartite entanglement distribution within quantum networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11632v1",
    "published": "2025-05-16T18:50:50+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11631v1",
    "title": "Enhancing Network Anomaly Detection with Quantum GANs and Successive Data Injection for Multivariate Time Series",
    "authors": [
      "Wajdi Hammami",
      "Soumaya Cherkaoui",
      "Shengrui Wang"
    ],
    "abstract": "Quantum computing may offer new approaches for advancing machine learning,\nincluding in complex tasks such as anomaly detection in network traffic. In\nthis paper, we introduce a quantum generative adversarial network (QGAN)\narchitecture for multivariate time-series anomaly detection that leverages\nvariational quantum circuits (VQCs) in combination with a time-window shifting\ntechnique, data re-uploading, and successive data injection (SuDaI). The method\nencodes multivariate time series data as rotation angles. By integrating both\ndata re-uploading and SuDaI, the approach maps classical data into quantum\nstates efficiently, helping to address hardware limitations such as the\nrestricted number of available qubits. In addition, the approach employs an\nanomaly scoring technique that utilizes both the generator and the\ndiscriminator output to enhance the accuracy of anomaly detection. The QGAN was\ntrained using the parameter shift rule and benchmarked against a classical GAN.\nExperimental results indicate that the quantum model achieves a accuracy high\nalong with high recall and F1-scores in anomaly detection, and attains a lower\nMSE compared to the classical model. Notably, the QGAN accomplishes this\nperformance with only 80 parameters, demonstrating competitive results with a\ncompact architecture. Tests using a noisy simulator suggest that the approach\nremains effective under realistic noise-prone conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11631v1",
    "published": "2025-05-16T18:47:42+00:00",
    "categories": [
      "cs.LG",
      "quant-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11630v1",
    "title": "Revisiting vestigial order in nematic superconductors: gauge-field mechanisms and model constraints",
    "authors": [
      "Ilaria Maccari",
      "Egor Babaev",
      "Johan Carlström"
    ],
    "abstract": "The possibility that nematicity induced by electron pairing could persist\nabove the superconducting transition temperature represents a form of composite\norder, sometimes referred to as a vestigial nematic phase. However, it remains\ndebated whether--and under what conditions--such a phase can emerge in\nrealistic models of nematic superconductors. Recent analytical work [1]\nconcluded that vestigial nematic phases and related mechanisms do not arise in\ncommonly used models proposed, for example, for Bi2Se3-based candidates. To\naddress this question, we perform large-scale Monte Carlo simulations of a\nthree-dimensional Ginzburg-Landau model of a nematic superconductor. Consistent\nwith the findings of Ref.[1], our numerical results confirm that the commonly\nconsidered models do not exhibit vestigial nematic phases or\nnematic-fluctuation-induced charge-4e superconductivity. In the second part of\nthe study, we investigate a different class of models and show that, under\nrestrictive conditions, vestigial nematic order can be stabilized by an\nalternative mechanism: intercomponent coupling mediated by a gauge field or the\neffects of strong correlations.",
    "pdf_url": "http://arxiv.org/pdf/2505.11630v1",
    "published": "2025-05-16T18:46:58+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.stat-mech",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.11629v1",
    "title": "Null orbits and shadows in the Ernst-Wild geometry: insights for black holes immersed in a magnetic field",
    "authors": [
      "Kate J. Taylor",
      "Adam Ritz"
    ],
    "abstract": "We investigate the null geodesics, in particular the stable and unstable\nlight rings and shadows, of a Kerr-Newman black hole immersed in an\nasymptotically uniform magnetic field as described by the Ernst-Wild\n(Melvin-Kerr-Newman) spacetime. Through numerical ray tracing, we demonstrate\nthat both the black hole rotation and the magnetized Melvin geometry impact the\nlight rings and shadows non-trivially and in compensating ways. In addition, we\nuse a perturbative expansion in the magnetic field B to analyze the deviation\nof the observable shadow relative to the Kerr result analytically, and\ndetermine connections between Lyapunov exponents for light ring instabilities\nand quasinormal modes in the eikonal limit.",
    "pdf_url": "http://arxiv.org/pdf/2505.11629v1",
    "published": "2025-05-16T18:46:05+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.11628v2",
    "title": "Critique-Guided Distillation: Improving Supervised Fine-tuning via Better Distillation",
    "authors": [
      "Berkcan Kapusuzoglu",
      "Supriyo Chakraborty",
      "Chia-Hsuan Lee",
      "Sambit Sahu"
    ],
    "abstract": "Supervised fine-tuning (SFT) using expert demonstrations often suffer from\nthe imitation problem, where the model learns to reproduce the correct\nresponses without understanding the underlying rationale. To address this\nlimitation, we propose Critique-Guided Distillation (CGD), a novel multi-stage\nframework that integrates teacher model generated explanatory critiques and\nrefined responses into the SFT process. A student model is then trained to map\nthe triplet of prompt, teacher critique, and its own initial response to the\ncorresponding refined teacher response, thereby learning both what to imitate\nand why. Using entropy-based analysis, we show that CGD reduces refinement\nuncertainty and can be interpreted as a Bayesian posterior update. We perform\nextensive empirical evaluation of CGD, on variety of benchmark tasks, and\ndemonstrate significant gains on both math (AMC23 +17.5%) and language\nunderstanding tasks (MMLU-Pro +6.3%), while successfully mitigating the format\ndrift issues observed in previous critique fine-tuning (CFT) techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.11628v2",
    "published": "2025-05-16T18:45:59+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11627v1",
    "title": "Adaptive Robust Optimization with Data-Driven Uncertainty for Enhancing Distribution System Resilience",
    "authors": [
      "Shuyi Chen",
      "Shixiang Zhu",
      "Ramteen Sioshansi"
    ],
    "abstract": "Extreme weather events are placing growing strain on electric power systems,\nexposing the limitations of purely reactive responses and prompting the need\nfor proactive resilience planning. However, existing approaches often rely on\nsimplified uncertainty models and decouple proactive and reactive decisions,\noverlooking their critical interdependence. This paper proposes a novel\ntri-level optimization framework that integrates proactive infrastructure\ninvestment, adversarial modeling of spatio-temporal disruptions, and adaptive\nreactive response. We construct high-probability, distribution-free uncertainty\nsets using conformal prediction to capture complex and data-scarce outage\npatterns. To solve the resulting nested decision problem, we derive a bi-level\nreformulation via strong duality and develop a scalable Benders decomposition\nalgorithm. Experiments on both real and synthetic data demonstrate that our\napproach consistently outperforms conventional robust and two-stage methods,\nachieving lower worst-case losses and more efficient resource allocation,\nespecially under tight operational constraints and large-scale uncertainty.",
    "pdf_url": "http://arxiv.org/pdf/2505.11627v1",
    "published": "2025-05-16T18:43:31+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11626v2",
    "title": "THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering",
    "authors": [
      "Udita Patel",
      "Rutu Mulkar",
      "Jay Roberts",
      "Cibi Chakravarthy Senthilkumar",
      "Sujay Gandhi",
      "Xiaofei Zheng",
      "Naumaan Nayyar",
      "Parul Kalra",
      "Rafael Castrillo"
    ],
    "abstract": "We propose THELMA (Task Based Holistic Evaluation of Large Language Model\nApplications), a reference free framework for RAG (Retrieval Augmented\ngeneration) based question answering (QA) applications. THELMA consist of six\ninterdependent metrics specifically designed for holistic, fine grained\nevaluation of RAG QA applications. THELMA framework helps developers and\napplication owners evaluate, monitor and improve end to end RAG QA pipelines\nwithout requiring labelled sources or reference responses.We also present our\nfindings on the interplay of the proposed THELMA metrics, which can be\ninterpreted to identify the specific RAG component needing improvement in QA\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2505.11626v2",
    "published": "2025-05-16T18:42:04+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11625v1",
    "title": "Nearest Neighbor Multivariate Time Series Forecasting",
    "authors": [
      "Huiliang Zhang",
      "Ping Nie",
      "Lijun Sun",
      "Benoit Boulet"
    ],
    "abstract": "Multivariate time series (MTS) forecasting has a wide range of applications\nin both industry and academia. Recently, spatial-temporal graph neural networks\n(STGNNs) have gained popularity as MTS forecasting methods. However, current\nSTGNNs can only use the finite length of MTS input data due to the\ncomputational complexity. Moreover, they lack the ability to identify similar\npatterns throughout the entire dataset and struggle with data that exhibit\nsparsely and discontinuously distributed correlations among variables over an\nextensive historical period, resulting in only marginal improvements. In this\narticle, we introduce a simple yet effective k-nearest neighbor MTS forecasting\n( kNN-MTS) framework, which forecasts with a nearest neighbor retrieval\nmechanism over a large datastore of cached series, using representations from\nthe MTS model for similarity search. This approach requires no additional\ntraining and scales to give the MTS model direct access to the whole dataset at\ntest time, resulting in a highly expressive model that consistently improves\nperformance, and has the ability to extract sparse distributed but similar\npatterns spanning over multivariables from the entire dataset. Furthermore, a\nhybrid spatial-temporal encoder (HSTEncoder) is designed for kNN-MTS which can\ncapture both long-term temporal and short-term spatial-temporal dependencies\nand is shown to provide accurate representation for kNN-MTSfor better\nforecasting. Experimental results on several real-world datasets show a\nsignificant improvement in the forecasting performance of kNN-MTS. The\nquantitative analysis also illustrates the interpretability and efficiency of\nkNN-MTS, showing better application prospects and opening up a new path for\nefficiently using the large dataset in MTS models.",
    "pdf_url": "http://arxiv.org/pdf/2505.11625v1",
    "published": "2025-05-16T18:41:33+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11624v1",
    "title": "Monotone Subsystem Decomposition for Efficient Multi-Objective Robot Design",
    "authors": [
      "Andrew Wilhelm",
      "Nils Napp"
    ],
    "abstract": "Automating design minimizes errors, accelerates the design process, and\nreduces cost. However, automating robot design is challenging due to recursive\nconstraints, multiple design objectives, and cross-domain design complexity\npossibly spanning multiple abstraction layers. Here we look at the problem of\ncomponent selection, a combinatorial optimization problem in which a designer,\ngiven a robot model, must select compatible components from an extensive\ncatalog. The goal is to satisfy high-level task specifications while optimally\nbalancing trade-offs between competing design objectives. In this paper, we\nextend our previous constraint programming approach to multi-objective design\nproblems and propose the novel technique of monotone subsystem decomposition to\nefficiently compute a Pareto front of solutions for large-scale problems. We\nprove that subsystems can be optimized for their Pareto fronts and, under\ncertain conditions, these results can be used to determine a globally optimal\nPareto front. Furthermore, subsystems serve as an intuitive design abstraction\nand can be reused across various design problems. Using an example quadcopter\ndesign problem, we compare our method to a linear programming approach and\ndemonstrate our method scales better for large catalogs, solving a\nmulti-objective problem of 10^25 component combinations in seconds. We then\nexpand the original problem and solve a task-oriented, multi-objective design\nproblem to build a fleet of quadcopters to deliver packages. We compute a\nPareto front of solutions in seconds where each solution contains an optimal\ncomponent-level design and an optimal package delivery schedule for each\nquadcopter.",
    "pdf_url": "http://arxiv.org/pdf/2505.11624v1",
    "published": "2025-05-16T18:41:09+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11623v1",
    "title": "Thermodynamics of Regular Black Holes in Anti-de Sitter Space",
    "authors": [
      "Robie A. Hennigar",
      "David Kubizňák",
      "Sebastian Murk",
      "Ioannis Soranidis"
    ],
    "abstract": "We construct regular black holes with anti-de Sitter asymptotics in theories\nincorporating infinite towers of higher-order curvature corrections in any\ndimension $D \\ge 5$. We find that regular black branes are generically\ninner-extremal, potentially evading instabilities typically associated with\ninner horizons. Considering minimally coupled matter, we establish general\ncriteria for the existence of singularity-free solutions. We analyze solutions\ncoupled to Maxwell and nonlinear (Born--Infeld and RegMax) electrodynamics,\ndemonstrating in the latter case the first examples of fully regular\ngravitational and electromagnetic fields for all parameter values. Here, we\nfind that the ratio of the gravitational mass to the electrostatic self-energy\ndetermines whether the regular core is de Sitter or anti-de Sitter. We perform\na detailed analysis of the black hole thermodynamics and show that the equation\nof state exhibits features akin to those of fluids with a finite molecular\nvolume induced by the regularization parameter.",
    "pdf_url": "http://arxiv.org/pdf/2505.11623v1",
    "published": "2025-05-16T18:39:15+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.11622v1",
    "title": "The Stochastic Occupation Kernel (SOCK) Method for Learning Stochastic Differential Equations",
    "authors": [
      "Michael L. Wells",
      "Kamel Lahouel",
      "Bruno Jedynak"
    ],
    "abstract": "We present a novel kernel-based method for learning multivariate stochastic\ndifferential equations (SDEs). The method follows a two-step procedure: we\nfirst estimate the drift term function, then the (matrix-valued) diffusion\nfunction given the drift. Occupation kernels are integral functionals on a\nreproducing kernel Hilbert space (RKHS) that aggregate information over a\ntrajectory. Our approach leverages vector-valued occupation kernels for\nestimating the drift component of the stochastic process. For diffusion\nestimation, we extend this framework by introducing operator-valued occupation\nkernels, enabling the estimation of an auxiliary matrix-valued function as a\npositive semi-definite operator, from which we readily derive the diffusion\nestimate. This enables us to avoid common challenges in SDE learning, such as\nintractable likelihoods, by optimizing a reconstruction-error-based objective.\nWe propose a simple learning procedure that retains strong predictive accuracy\nwhile using Fenchel duality to promote efficiency. We validate the method on\nsimulated benchmarks and a real-world dataset of Amyloid imaging in healthy and\nAlzheimer's disease (AD) subjects.",
    "pdf_url": "http://arxiv.org/pdf/2505.11622v1",
    "published": "2025-05-16T18:38:50+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.11621v1",
    "title": "A Classical View on Benign Overfitting: The Role of Sample Size",
    "authors": [
      "Junhyung Park",
      "Patrick Bloebaum",
      "Shiva Prasad Kasiviswanathan"
    ],
    "abstract": "Benign overfitting is a phenomenon in machine learning where a model\nperfectly fits (interpolates) the training data, including noisy examples, yet\nstill generalizes well to unseen data. Understanding this phenomenon has\nattracted considerable attention in recent years. In this work, we introduce a\nconceptual shift, by focusing on almost benign overfitting, where models\nsimultaneously achieve both arbitrarily small training and test errors. This\nbehavior is characteristic of neural networks, which often achieve low (but\nnon-zero) training error while still generalizing well. We hypothesize that\nthis almost benign overfitting can emerge even in classical regimes, by\nanalyzing how the interaction between sample size and model complexity enables\nlarger models to achieve both good training fit but still approach\nBayes-optimal generalization. We substantiate this hypothesis with theoretical\nevidence from two case studies: (i) kernel ridge regression, and (ii)\nleast-squares regression using a two-layer fully connected ReLU neural network\ntrained via gradient flow. In both cases, we overcome the strong assumptions\noften required in prior work on benign overfitting.\n  Our results on neural networks also provide the first generalization result\nin this setting that does not rely on any assumptions about the underlying\nregression function or noise, beyond boundedness. Our analysis introduces a\nnovel proof technique based on decomposing the excess risk into estimation and\napproximation errors, interpreting gradient flow as an implicit regularizer,\nthat helps avoid uniform convergence traps. This analysis idea could be of\nindependent interest.",
    "pdf_url": "http://arxiv.org/pdf/2505.11621v1",
    "published": "2025-05-16T18:37:51+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11620v1",
    "title": "Improved Bag-of-Words Image Retrieval with Geometric Constraints for Ground Texture Localization",
    "authors": [
      "Aaron Wilhelm",
      "Nils Napp"
    ],
    "abstract": "Ground texture localization using a downward-facing camera offers a low-cost,\nhigh-precision localization solution that is robust to dynamic environments and\nrequires no environmental modification. We present a significantly improved\nbag-of-words (BoW) image retrieval system for ground texture localization,\nachieving substantially higher accuracy for global localization and higher\nprecision and recall for loop closure detection in SLAM. Our approach leverages\nan approximate $k$-means (AKM) vocabulary with soft assignment, and exploits\nthe consistent orientation and constant scale constraints inherent to ground\ntexture localization. Identifying the different needs of global localization\nvs. loop closure detection for SLAM, we present both high-accuracy and\nhigh-speed versions of our algorithm. We test the effect of each of our\nproposed improvements through an ablation study and demonstrate our method's\neffectiveness for both global localization and loop closure detection. With\nnumerous ground texture localization systems already using BoW, our method can\nreadily replace other generic BoW systems in their pipeline and immediately\nimprove their results.",
    "pdf_url": "http://arxiv.org/pdf/2505.11620v1",
    "published": "2025-05-16T18:37:18+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11619v1",
    "title": "Electronic origin of the reorganization energy in interfacial electron transfer",
    "authors": [
      "Sonal Maroo",
      "Leonardo Coello Escalante",
      "Yizhe Wang",
      "Matthew P. Erodici",
      "Jonathon N. Nessralla",
      "Ayana Tabo",
      "Takashi Taniguchi",
      "Kenji Watanabe",
      "Ke Xu",
      "David T. Limmer",
      "D. Kwabena Bediako"
    ],
    "abstract": "The activation free energy of electron transfer (ET) reactions is governed by\na crucial parameter: the reorganization energy. In heterogeneous ET at\nelectrified solid-liquid interfaces, it is presumed that only factors in the\nelectrolyte phase are responsible for determining the reorganization energy.\nHere, we demonstrate the contribution of the electronic density of states (DOS)\nof the electrode to the reorganization energy. Using van der Waals assembly of\ntwo-dimensional crystals, we tune the DOS of graphene and measure its impact on\nouter-sphere ET. We find the ensuing variation in ET rate arises from\nmodulation in a reorganization energy associated with image potential\nlocalization in the electrode, which is dependent on the DOS. This work\nestablishes a fundamental role of the electrode electronic structure in\ninterfacial charge transfer.",
    "pdf_url": "http://arxiv.org/pdf/2505.11619v1",
    "published": "2025-05-16T18:35:58+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11618v2",
    "title": "Benchmarking Spatiotemporal Reasoning in LLMs and Reasoning Models: Capabilities and Challenges",
    "authors": [
      "Pengrui Quan",
      "Brian Wang",
      "Kang Yang",
      "Liying Han",
      "Mani Srivastava"
    ],
    "abstract": "Spatiotemporal reasoning plays a key role in Cyber-Physical Systems (CPS).\nDespite advances in Large Language Models (LLMs) and Large Reasoning Models\n(LRMs), their capacity to reason about complex spatiotemporal signals remains\nunderexplored. This paper proposes a hierarchical SpatioTemporal reAsoning\nbenchmaRK, STARK, to systematically evaluate LLMs across three levels of\nreasoning complexity: state estimation (e.g., predicting field variables,\nlocalizing and tracking events in space and time), spatiotemporal reasoning\nover states (e.g., inferring spatial-temporal relationships), and\nworld-knowledge-aware reasoning that integrates contextual and domain knowledge\n(e.g., intent prediction, landmark-aware navigation). We curate 26 distinct\nspatiotemporal tasks with diverse sensor modalities, comprising 14,552\nchallenges where models answer directly or by Python Code Interpreter.\nEvaluating 3 LRMs and 8 LLMs, we find LLMs achieve limited success in tasks\nrequiring geometric reasoning (e.g., multilateration or triangulation),\nparticularly as complexity increases. Surprisingly, LRMs show robust\nperformance across tasks with various levels of difficulty, often competing or\nsurpassing traditional first-principle-based methods. Our results show that in\nreasoning tasks requiring world knowledge, the performance gap between LLMs and\nLRMs narrows, with some LLMs even surpassing LRMs. However, the LRM o3 model\ncontinues to achieve leading performance across all evaluated tasks, a result\nattributed primarily to the larger size of the reasoning models. STARK\nmotivates future innovations in model architectures and reasoning paradigms for\nintelligent CPS by providing a structured framework to identify limitations in\nthe spatiotemporal reasoning of LLMs and LRMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11618v2",
    "published": "2025-05-16T18:32:35+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11617v2",
    "title": "The role of confined water in the emergence of electrostatic strong coupling as revealed by nanoseparated charged lipid layers",
    "authors": [
      "Swen Helstroffer",
      "Ludovic Gardré",
      "Giovanna Fragneto",
      "Arnaud Hemmerle",
      "Léo Henry",
      "Laurent Joly",
      "Fabrice Thalmann",
      "Claire Loison",
      "Pierre Muller",
      "Thierry Charitat"
    ],
    "abstract": "This study investigates the interplay between Strong Coupling (SC) attraction\nand hydration repulsion in nanoconfined water between like-charged phospholipid\nlayers. It challenges the assumption that SC attraction requires multivalent\ncounterions by showing that hydration water can enhance electrostatic\ninteractions. We combine reflectivities with numerical simulations to analyze\nsupported phospholipid layers under different relative humidity and surface\ncharge densities. X-ray fluorescence demonstrates that we can control the\nvalence of the associated counterions. Experimental measurement of the water\nthickness, combined with precise determination of charged surface positions by\nnumerical simulations, enable us to compare our experiments with a theoretical\nmodel. It shows that charge-screening by hydration water induces SC attraction,\neven at moderate surface charge densities with monovalent counterions.\nFurthermore, hydration repulsion is stronger for DPPS compared to DPPC. These\nfindings offer insights into the forces that control interactions between\nphospholipid layers and have important implications for biological and\ncolloidal systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11617v2",
    "published": "2025-05-16T18:31:26+00:00",
    "categories": [
      "cond-mat.soft",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.11616v2",
    "title": "Carbon-rich dust injected into the interstellar medium by Galactic WC binaries survives for hundreds of years",
    "authors": [
      "Noel D. Richardson",
      "Micaela Henson",
      "Emma P. Lieb",
      "Corey Kehl",
      "Ryan M. Lau",
      "Peredur M. Williams",
      "Michael F. Corcoran",
      "J. R. Callingham",
      "André-Nicolas Chené",
      "Theodore R. Gull",
      "Kenji Hamaguchi",
      "Yinuo Han",
      "Matthew J. Hankins",
      "Grant M. Hill",
      "Jennifer L. Hoffman",
      "Jonathan Mackey",
      "Anthony F. J. Moffat",
      "Benjamin J. S. Pope",
      "Pragati Pradhan",
      "Christopher M. P. Russell",
      "Andreas A. C. Sander",
      "Nicole St-Louis",
      "Ian R. Stevens",
      "Peter Tuthill",
      "Gerd Weigelt",
      "Ryan M. T. White"
    ],
    "abstract": "Some carbon-rich Wolf-Rayet stars (WC stars) show an infrared excess from\ndust emission. Dust forms in the collision of the WC wind with a companion\nstar's wind. As this dust is carried towards the ISM at close to the WCd wind\nspeed and the binary continues through its orbit, a spiral structure forms\naround the system. The shape depends on the orbital eccentricity and period, as\nwell as stellar parameters like mass-loss rates and terminal wind speeds.\nImaging of the WCd binary WR 140 with JWST/MIRI revealed 17 concentric dust\nshells surrounding the binary. We present new JWST imaging of four additional\nWCd systems (WR 48a, WR 112, WR 125, and WR 137) that were imaged in 2024. In\nthis analysis, we show that the dust is long-lived, detected with an age of at\nleast 130 years, but more than 300 years in some systems. Longer duration\nmeasurements are limited by sensitivity. Regular spacing of dust features\nconfirms the periodic nature of dust formation, consistent with a connection to\nbinary motion. We use these images to estimate the proper motion of the dust,\nfinding the dust to propagate out to the interstellar medium with motion\ncomparable to the wind speed of the WC stars. In addition to these results, we\nobserve unusual structures around WR 48a, which could represent dusty clumps\nshaped by photoevaporation and wind ablation like young proplyd objects. These\nresults demonstrate that WC dust is indeed long-lived and should be accounted\nfor in galactic dust budgets.",
    "pdf_url": "http://arxiv.org/pdf/2505.11616v2",
    "published": "2025-05-16T18:23:15+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11615v1",
    "title": "Steering Risk Preferences in Large Language Models by Aligning Behavioral and Neural Representations",
    "authors": [
      "Jian-Qiao Zhu",
      "Haijiang Yan",
      "Thomas L. Griffiths"
    ],
    "abstract": "Changing the behavior of large language models (LLMs) can be as\nstraightforward as editing the Transformer's residual streams using\nappropriately constructed \"steering vectors.\" These modifications to internal\nneural activations, a form of representation engineering, offer an effective\nand targeted means of influencing model behavior without retraining or\nfine-tuning the model. But how can such steering vectors be systematically\nidentified? We propose a principled approach for uncovering steering vectors by\naligning latent representations elicited through behavioral methods\n(specifically, Markov chain Monte Carlo with LLMs) with their neural\ncounterparts. To evaluate this approach, we focus on extracting latent risk\npreferences from LLMs and steering their risk-related outputs using the aligned\nrepresentations as steering vectors. We show that the resulting steering\nvectors successfully and reliably modulate LLM outputs in line with the\ntargeted behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.11615v1",
    "published": "2025-05-16T18:23:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11614v1",
    "title": "Using Reinforcement Learning to Train Large Language Models to Explain Human Decisions",
    "authors": [
      "Jian-Qiao Zhu",
      "Hanbo Xie",
      "Dilip Arumugam",
      "Robert C. Wilson",
      "Thomas L. Griffiths"
    ],
    "abstract": "A central goal of cognitive modeling is to develop models that not only\npredict human behavior but also provide insight into the underlying cognitive\nmechanisms. While neural network models trained on large-scale behavioral data\noften achieve strong predictive performance, they typically fall short in\noffering interpretable explanations of the cognitive processes they capture. In\nthis work, we explore the potential of pretrained large language models (LLMs)\nto serve as dual-purpose cognitive models--capable of both accurate prediction\nand interpretable explanation in natural language. Specifically, we employ\nreinforcement learning with outcome-based rewards to guide LLMs toward\ngenerating explicit reasoning traces for explaining human risky choices. Our\nfindings demonstrate that this approach produces high-quality explanations\nalongside strong quantitative predictions of human decisions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11614v1",
    "published": "2025-05-16T18:22:05+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11613v1",
    "title": "MedGUIDE: Benchmarking Clinical Decision-Making in Large Language Models",
    "authors": [
      "Xiaomin Li",
      "Mingye Gao",
      "Yuexing Hao",
      "Taoran Li",
      "Guangya Wan",
      "Zihan Wang",
      "Yijun Wang"
    ],
    "abstract": "Clinical guidelines, typically structured as decision trees, are central to\nevidence-based medical practice and critical for ensuring safe and accurate\ndiagnostic decision-making. However, it remains unclear whether Large Language\nModels (LLMs) can reliably follow such structured protocols. In this work, we\nintroduce MedGUIDE, a new benchmark for evaluating LLMs on their ability to\nmake guideline-consistent clinical decisions. MedGUIDE is constructed from 55\ncurated NCCN decision trees across 17 cancer types and uses clinical scenarios\ngenerated by LLMs to create a large pool of multiple-choice diagnostic\nquestions. We apply a two-stage quality selection process, combining\nexpert-labeled reward models and LLM-as-a-judge ensembles across ten clinical\nand linguistic criteria, to select 7,747 high-quality samples. We evaluate 25\nLLMs spanning general-purpose, open-source, and medically specialized models,\nand find that even domain-specific LLMs often underperform on tasks requiring\nstructured guideline adherence. We also test whether performance can be\nimproved via in-context guideline inclusion or continued pretraining. Our\nfindings underscore the importance of MedGUIDE in assessing whether LLMs can\noperate safely within the procedural frameworks expected in real-world clinical\nsettings.",
    "pdf_url": "http://arxiv.org/pdf/2505.11613v1",
    "published": "2025-05-16T18:21:52+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11612v1",
    "title": "Heart2Mind: Human-Centered Contestable Psychiatric Disorder Diagnosis System using Wearable ECG Monitors",
    "authors": [
      "Hung Nguyen",
      "Alireza Rahimi",
      "Veronica Whitford",
      "Hélène Fournier",
      "Irina Kondratova",
      "René Richard",
      "Hung Cao"
    ],
    "abstract": "Psychiatric disorders affect millions globally, yet their diagnosis faces\nsignificant challenges in clinical practice due to subjective assessments and\naccessibility concerns, leading to potential delays in treatment. To help\naddress this issue, we present Heart2Mind, a human-centered contestable\npsychiatric disorder diagnosis system using wearable electrocardiogram (ECG)\nmonitors. Our approach leverages cardiac biomarkers, particularly heart rate\nvariability (HRV) and R-R intervals (RRI) time series, as objective indicators\nof autonomic dysfunction in psychiatric conditions. The system comprises three\nkey components: (1) a Cardiac Monitoring Interface (CMI) for real-time data\nacquisition from Polar H9/H10 devices; (2) a Multi-Scale Temporal-Frequency\nTransformer (MSTFT) that processes RRI time series through integrated\ntime-frequency domain analysis; (3) a Contestable Diagnosis Interface (CDI)\ncombining Self-Adversarial Explanations (SAEs) with contestable Large Language\nModels (LLMs). Our MSTFT achieves 91.7% accuracy on the HRV-ACC dataset using\nleave-one-out cross-validation, outperforming state-of-the-art methods. SAEs\nsuccessfully detect inconsistencies in model predictions by comparing\nattention-based and gradient-based explanations, while LLMs enable clinicians\nto validate correct predictions and contest erroneous ones. This work\ndemonstrates the feasibility of combining wearable technology with Explainable\nArtificial Intelligence (XAI) and contestable LLMs to create a transparent,\ncontestable system for psychiatric diagnosis that maintains clinical oversight\nwhile leveraging advanced AI capabilities. Our implementation is publicly\navailable at: https://github.com/Analytics-Everywhere-Lab/heart2mind.",
    "pdf_url": "http://arxiv.org/pdf/2505.11612v1",
    "published": "2025-05-16T18:21:08+00:00",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11611v1",
    "title": "Probing the Vulnerability of Large Language Models to Polysemantic Interventions",
    "authors": [
      "Bofan Gong",
      "Shiyang Lai",
      "Dawn Song"
    ],
    "abstract": "Polysemanticity -- where individual neurons encode multiple unrelated\nfeatures -- is a well-known characteristic of large neural networks and remains\na central challenge in the interpretability of language models. At the same\ntime, its implications for model safety are also poorly understood. Leveraging\nrecent advances in sparse autoencoders, we investigate the polysemantic\nstructure of two small models (Pythia-70M and GPT-2-Small) and evaluate their\nvulnerability to targeted, covert interventions at the prompt, feature, token,\nand neuron levels. Our analysis reveals a consistent polysemantic topology\nshared across both models. Strikingly, we demonstrate that this structure can\nbe exploited to mount effective interventions on two larger, black-box\ninstruction-tuned models (LLaMA3.1-8B-Instruct and Gemma-2-9B-Instruct). These\nfindings suggest not only the generalizability of the interventions but also\npoint to a stable and transferable polysemantic structure that could\npotentially persist across architectures and training regimes.",
    "pdf_url": "http://arxiv.org/pdf/2505.11611v1",
    "published": "2025-05-16T18:20:42+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.11021v1",
    "title": "Eliminating Hallucination-Induced Errors in LLM Code Generation with Functional Clustering",
    "authors": [
      "Chaitanya Ravuri",
      "Saman Amarasinghe"
    ],
    "abstract": "Modern code-generation LLMs can already solve a large fraction of programming\nproblems, yet they still hallucinate subtle bugs that make their outputs unsafe\nfor autonomous deployment. We present functional clustering, a black-box\nwrapper that eliminates nearly all hallucination-induced errors while providing\na tunable confidence score. The wrapper samples many candidate programs,\nexecutes each on a self-generated test suite, and clusters candidates whose I/O\nbehavior is identical; the empirical mass of the largest cluster serves as an\nexact confidence estimate. A single scalar threshold on this estimate lets\nusers trade coverage for reliability with exponential guarantees. On\nLiveCodeBench our verifier preserves baseline pass@1 on solvable tasks yet\nslashes the error rate of returned answers from ~65% to 2%, and drives it to 0%\nat a conservative threshold while still answering 15.6% of prompts. Manual\naudits show that the few residual mistakes stem from prompt misinterpretation,\nnot random generation noise, narrowing future work to specification clarity.\nBecause the method requires only sampling and sandbox execution, it applies\nunchanged to closed-source APIs and future models, offering a practical path\ntoward dependable, autonomous code generation. Our code is available on Github\n(https://github.com/20ChaituR/functional-clustering).",
    "pdf_url": "http://arxiv.org/pdf/2506.11021v1",
    "published": "2025-05-16T18:19:38+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11610v1",
    "title": "Foundation Models for AI-Enabled Biological Design",
    "authors": [
      "Asher Moldwin",
      "Amarda Shehu"
    ],
    "abstract": "This paper surveys foundation models for AI-enabled biological design,\nfocusing on recent developments in applying large-scale, self-supervised models\nto tasks such as protein engineering, small molecule design, and genomic\nsequence design. Though this domain is evolving rapidly, this survey presents\nand discusses a taxonomy of current models and methods. The focus is on\nchallenges and solutions in adapting these models for biological applications,\nincluding biological sequence modeling architectures, controllability in\ngeneration, and multi-modal integration. The survey concludes with a discussion\nof open problems and future directions, offering concrete next-steps to improve\nthe quality of biological sequence generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11610v1",
    "published": "2025-05-16T18:17:37+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.BM",
      "q-bio.GN"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11609v1",
    "title": "Ultraviolet variability in Solar-type members of the M67 open cluster",
    "authors": [
      "Carl Melis",
      "Ekamjot Kaire"
    ],
    "abstract": "Solar-type members of the rich, nearly Solar-age and Solar-metallicity M67\nopen cluster are systematically investigated for ultraviolet variability. We\nutilize archival Galaxy Evolution Explorer (GALEX) data which features several\nimaging observation epochs spanning 5 years. Stars in or suspected of being in\nbinary systems are avoided as well as stars that are blended in GALEX data,\nleading to a sample of 66 Solar-type stars. We assess variability over a\nvariety of timescales that probe flares and longer-term trends that could be\ndue to rotation and activity cycles. We do not find conclusive evidence for\nvariability and determine that Solar-type members of M67 do not display >30%\nnear-ultraviolet variability over timescales ranging from days to years.\nFurthermore, within 50-second cadence lightcurves generated for each of the\nimaging epochs we find no near-ultraviolet flares that are >~2x the quiescent\nstellar near-ultraviolet emission level; the implied ultraviolet flare rate\nderived from this study is in mild tension with that derived for stars observed\nby GALEX in the primary Kepler field. This M67 GALEX study presents one of the\nmost comprehensive ultraviolet datasets currently available for probing\ncontinuum emission variability for old Sun-like stars; the planned NASA UVEX\nmission has the potential to dramatically expand upon this work.",
    "pdf_url": "http://arxiv.org/pdf/2505.11609v1",
    "published": "2025-05-16T18:16:30+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11608v1",
    "title": "A Blue Start: A large-scale pairwise and higher-order social network dataset",
    "authors": [
      "Alyssa Smith",
      "Ilya Amburg",
      "Sagar Kumar",
      "Brooke Foucault Welles",
      "Nicholas W. Landry"
    ],
    "abstract": "Large-scale networks have been instrumental in shaping the way that we think\nabout how individuals interact with one another, developing key insights in\nmathematical epidemiology, computational social science, and biology. However,\nmany of the underlying social systems through which diseases spread,\ninformation disseminates, and individuals interact are inherently mediated\nthrough groups of arbitrary size, known as higher-order interactions. There is\na gap between higher-order dynamics of group formation and fragmentation,\ncontagion spread, and social influence and the data necessary to validate these\nhigher-order mechanisms. Similarly, few datasets bridge the gap between these\npairwise and higher-order network data. Because of its open API, the Bluesky\nsocial media platform provides a laboratory for observing social ties at scale.\nIn addition to pairwise following relationships, unlike many other social\nnetworks, Bluesky features user-curated lists known as \"starter packs\" as a\nmechanism for social network growth. We introduce \"A Blue Start\", a large-scale\nnetwork dataset comprising 26.7M users and their 1.6B pairwise following\nrelationships and 301.3K groups representing starter packs. This dataset will\nbe an essential resource for the study of higher-order network science.",
    "pdf_url": "http://arxiv.org/pdf/2505.11608v1",
    "published": "2025-05-16T18:15:28+00:00",
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11607v2",
    "title": "Singlet-doublet dark matter revisited",
    "authors": [
      "Prudhvi N. Bhattiprolu",
      "Evan Petrosky",
      "Aaron Pierce"
    ],
    "abstract": "The singlet-doublet model is an economical model of weakly interacting dark\nmatter. We revisit it in light of improved dark matter direct detection limits.\nWe characterize the now well-defined regions of remaining parameter space with\nsuppressed direct detection cross sections and discuss features of the spectrum\naccessible at the Large Hadron Collider. We discuss when and how parameters in\nthese special regions might be realized as the result of renormalization group\nevolution when starting with generic ultraviolet initial conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11607v2",
    "published": "2025-05-16T18:14:54+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11606v1",
    "title": "The evolution of the halo occupation distribution in cosmic voids",
    "authors": [
      "Ignacio G. Alfaro",
      "Facundo Rodriguez",
      "Andrés N. Ruiz"
    ],
    "abstract": "The halo occupation distribution is a cornerstone in understanding galaxy\nformation within the large-scale structure.On the other hand, in the context of\nthe large-scale structure of the Universe, voids are regions with singular\ncharacteristics, given their extension, the low number of objects that inhabit\ntheir interior and their own dynamics. Furthermore, the HOD of these regions\nexhibits significant deviations from the average, as shown by several studies\nin semi-analytical models, hydrodynamic simulations, and observations. This\npaper investigates the temporal evolution of the HOD in cosmic voids from\nredshift z = 0.5 to the present day. We aim to understand how the void\nenvironment shapes galaxy occupation over time and to identify the factors\ndriving the unique HOD observed in these underdense regions. We use the\nMDPL2-SAG semi-analytic galaxy catalog and identify spherical cosmic voids at\ndifferent redshifts. We analyze the HOD within voids across ten simulation\nsnapshots, comparing it with the global HOD. Furthermore, we trace the\nevolution of z = 0 void galaxies and their host halos back in time, examining\ntheir formation times and local density evolution. Our results reveal that the\nHOD within voids is consistently lower than the average HOD at all redshifts\nconsidered. Tracking z = 0 void galaxies, we find that their HOD remains lower\nthan average throughout the redshift range, with no significant redshift\nevolution in this relative difference. Analysis of halo formation histories\nshows that lower-mass void halos are younger, while massive void halos are\nolder compared to the average. Spatially, lower-mass halos are found in the\ninner void regions, whereas massive halos are located closer to void\nboundaries. The local density of massive void halos decreases significantly\ntowards z = 0, contrasting with the relatively stable local density of\nlower-mass void halos.",
    "pdf_url": "http://arxiv.org/pdf/2505.11606v1",
    "published": "2025-05-16T18:13:07+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11605v2",
    "title": "On representations of quantum affine $\\mathfrak{sl}_2$",
    "authors": [
      "Andrei Grigorev",
      "Evgeny Mukhin"
    ],
    "abstract": "We study tensor products of two-dimensional evaluation\n$U_q\\widehat{\\mathfrak{sl}}_2$-modules at generic values of $q$,\n$U_q\\widehat{\\mathfrak{sl}}_2$ homomorphisms between them, and closely related\nsubjects.",
    "pdf_url": "http://arxiv.org/pdf/2505.11605v2",
    "published": "2025-05-16T18:13:04+00:00",
    "categories": [
      "math.QA",
      "math.CO",
      "math.RT"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11604v3",
    "title": "Talk to Your Slides: Language-Driven Agents for Efficient Slide Editing",
    "authors": [
      "Kyudan Jung",
      "Hojun Cho",
      "Jooyeol Yun",
      "Soyoung Yang",
      "Jaehyeok Jang",
      "Jaegul Choo"
    ],
    "abstract": "Editing presentation slides remains one of the most common and time-consuming\ntasks faced by millions of users daily, despite significant advances in\nautomated slide generation. Existing approaches have successfully demonstrated\nslide editing via graphic user interface (GUI)-based agents, offering intuitive\nvisual control. However, such methods often suffer from high computational cost\nand latency. In this paper, we propose Talk-to-Your-Slides, an LLM-powered\nagent designed to edit slides %in active PowerPoint sessions by leveraging\nstructured information about slide objects rather than relying on image\nmodality. The key insight of our work is designing the editing process with\ndistinct high-level and low-level layers to facilitate interaction between user\ncommands and slide objects. By providing direct access to application objects\nrather than screen pixels, our system enables 34.02% faster processing, 34.76%\nbetter instruction fidelity, and 87.42% cheaper operation than baselines. To\nevaluate slide editing capabilities, we introduce TSBench, a human-annotated\ndataset comprising 379 diverse editing instructions paired with corresponding\nslide variations in four categories. Our code, benchmark and demos are\navailable at https://anonymous.4open.science/r/Talk-to-Your-Slides-0F4C.",
    "pdf_url": "http://arxiv.org/pdf/2505.11604v3",
    "published": "2025-05-16T18:12:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11603v1",
    "title": "Modeling the dynamics of aeolian meter-scale bedforms induced by bed heterogeneities",
    "authors": [
      "C. Rambert",
      "J. M. Nield",
      "C. Narteau",
      "P. Delorme",
      "G. F. S. Wiggs",
      "M. C. Baddock",
      "J. Best",
      "K. T. Christensen",
      "P. Claudin"
    ],
    "abstract": "Desert surfaces are typically non uniform, with individual sand dunes\ngenerally surrounded by gravel or non-erodible beds. Similarly, beaches vary in\ncomposition and moisture that enhances cohesion between the grains. These bed\nheterogeneities affect the aeolian transport properties greatly, and can then\ninfluence the emergence and dynamics of bedforms. Here, we propose a model that\ndescribes how, due to transport capacity being greater on consolidated than\nerodible beds, patches of sand can grow, migrate and spread to form bedforms\nwith meter-scale length. Our approach has a quantitative agreement with\nhigh-resolution spatio-temporal observations, where conventional theory would\npredict the disappearance of these small bedforms. A crucial component of the\nmodel is that the transport capacity does not instantly change from one bed\nconfiguration to another. Instead, transport capacity develops over a certain\ndistance, which thereby determines the short-term evolution of the bedform. The\nmodel predicts various stages in the development of these meter-scale bedforms,\nand explains how the evolution of bed elevation profiles observed in the field\ndepends on the duration of the wind event and the intensity of the incoming\nsand flux. Our study thus sheds light on the initiation and dynamics of\nearly-stage bedforms by establishing links between surface properties, emerging\nsand patterns and protodunes, commonly observed in coastal and desert\nlandscapes.",
    "pdf_url": "http://arxiv.org/pdf/2505.11603v1",
    "published": "2025-05-16T18:11:58+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11602v1",
    "title": "Regularity and Stability Properties of Selective SSMs with Discontinuous Gating",
    "authors": [
      "Nikola Zubić",
      "Davide Scaramuzza"
    ],
    "abstract": "Deep Selective State-Space Models (SSMs), characterized by input-dependent,\ntime-varying parameters, offer significant expressive power but pose challenges\nfor stability analysis, especially with discontinuous gating signals. In this\npaper, we investigate the stability and regularity properties of\ncontinuous-time selective SSMs through the lens of passivity and Input-to-State\nStability (ISS). We establish that intrinsic energy dissipation guarantees\nexponential forgetting of past states. Crucially, we prove that the unforced\nsystem dynamics possess an underlying minimal quadratic energy function whose\ndefining matrix exhibits robust $\\text{AUC}_{\\text{loc}}$ regularity,\naccommodating discontinuous gating. Furthermore, assuming a universal quadratic\nstorage function ensures passivity across all inputs, we derive parametric LMI\nconditions and kernel constraints that limit gating mechanisms, formalizing\n\"irreversible forgetting\" of recurrent models. Finally, we provide sufficient\nconditions for global ISS, linking uniform local dissipativity to overall\nsystem robustness. Our findings offer a rigorous framework for understanding\nand designing stable and reliable deep selective SSMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11602v1",
    "published": "2025-05-16T18:08:40+00:00",
    "categories": [
      "cs.LG",
      "math.DS",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11601v1",
    "title": "Continuous Optimization for Feature Selection with Permutation-Invariant Embedding and Policy-Guided Search",
    "authors": [
      "Rui Liu",
      "Rui Xie",
      "Zijun Yao",
      "Yanjie Fu",
      "Dongjie Wang"
    ],
    "abstract": "Feature selection removes redundant features to enhanc performance and\ncomputational efficiency in downstream tasks. Existing works often struggle to\ncapture complex feature interactions and adapt to diverse scenarios. Recent\nadvances in this domain have incorporated generative intelligence to address\nthese drawbacks by uncovering intricate relationships between features.\nHowever, two key limitations remain: 1) embedding feature subsets in a\ncontinuous space is challenging due to permutation sensitivity, as changes in\nfeature order can introduce biases and weaken the embedding learning process;\n2) gradient-based search in the embedding space assumes convexity, which is\nrarely guaranteed, leading to reduced search effectiveness and suboptimal\nsubsets. To address these limitations, we propose a new framework that can: 1)\npreserve feature subset knowledge in a continuous embedding space while\nensuring permutation invariance; 2) effectively explore the embedding space\nwithout relying on strong convex assumptions. For the first objective, we\ndevelop an encoder-decoder paradigm to preserve feature selection knowledge\ninto a continuous embedding space. This paradigm captures feature interactions\nthrough pairwise relationships within the subset, removing the influence of\nfeature order on the embedding. Moreover, an inducing point mechanism is\nintroduced to accelerate pairwise relationship computations. For the second\nobjective, we employ a policy-based reinforcement learning (RL) approach to\nguide the exploration of the embedding space. The RL agent effectively\nnavigates the space by balancing multiple objectives. By prioritizing\nhigh-potential regions adaptively and eliminating the reliance on convexity\nassumptions, the RL agent effectively reduces the risk of converging to local\noptima. Extensive experiments demonstrate the effectiveness, efficiency,\nrobustness and explicitness of our model.",
    "pdf_url": "http://arxiv.org/pdf/2505.11601v1",
    "published": "2025-05-16T18:08:16+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11599v1",
    "title": "Can LLMs Credibly Transform the Creation of Panel Data from Diverse Historical Tables?",
    "authors": [
      "Verónica Bäcker-Peral",
      "Vitaly Meursault",
      "Christopher Severen"
    ],
    "abstract": "Multimodal LLMs offer a watershed change for the digitization of historical\ntables, enabling low-cost processing centered on domain expertise rather than\ntechnical skills. We rigorously validate an LLM-based pipeline on a new panel\nof historical county-level vehicle registrations. This pipeline is 100 times\nless expensive than outsourcing, reduces critical parsing errors from 40% to\n0.3%, and matches human-validated gold standard data with an $R^2$ of 98.6%.\nAnalyses of growth and persistence in vehicle adoption are statistically\nindistinguishable whether using LLM or gold standard data. LLM-based\ndigitization unlocks complex historical tables, enabling new economic analyses\nand broader researcher participation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11599v1",
    "published": "2025-05-16T18:07:40+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.11600v1",
    "title": "An Intersection Principle for Mean Curvature Flow",
    "authors": [
      "Tang-Kai Lee",
      "Alec Payne"
    ],
    "abstract": "The avoidance principle says that mean curvature flows of hypersurfaces\nremain disjoint if they are disjoint at the initial time. We prove several\ngeneralizations of the avoidance principle that allow for intersections of\nhypersurfaces. First, we prove that the Hausdorff dimension of the intersection\nof two mean curvature flows is non-increasing over time, and we find precise\ninformation on how the dimension changes. We then show that the\nself-intersection of an immersed mean curvature flow has non-increasing\ndimension over time. Next, we extend the intersection dimension monotonicity to\nBrakke flows and level set flows which satisfy a localizability condition, and\nwe provide examples showing that the monotonicity fails for general weak\nsolutions. We find a localization result for level set flows with finitely many\nsingularities, and as a consequence, we obtain a fattening criterion for these\nflows which depends on the behavior of intersections with smooth flows.",
    "pdf_url": "http://arxiv.org/pdf/2505.11600v1",
    "published": "2025-05-16T18:07:40+00:00",
    "categories": [
      "math.DG",
      "math.AP",
      "53E10, 35B05"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11598v2",
    "title": "The Host Galaxies of PTA Sources: Converting Supermassive BH Binary Parameters into EM Observables",
    "authors": [
      "Niccolo Veronesi",
      "Maria Charisi",
      "Stephen R Taylor",
      "Jessie Runnoe",
      "Daniel J D'Orazio"
    ],
    "abstract": "Pulsar timing arrays (PTAs) are approaching the sensitivity required to\nresolve gravitational waves (GWs) from individual supermassive black hole\n(SMBH) binaries. However, the large uncertainty in source localization will\nmake the identification of its host environment challenging. We show how to\nconvert the posterior probability function of binary parameters inferred by GW\nanalyses into distributions of apparent magnitudes of the host galaxy. We do so\nfor a scenario in which the host environment is a regular early-type galaxy,\nand one in which it is an active galactic nucleus. We estimate the reach of\nPTAs in the near and intermediate future, and estimate whether the binary hosts\nwill be detectable in all-sky electromagnetic (EM) surveys. A PTA with a\nbaseline of 20 yr and 116 pulsars, resembling the upcoming data release of the\nInternational Pulsar Timing Array, can detect binaries out to a luminosity\ndistance of 2 Gpc (corresponding to a redshift of $z\\sim0.36$), while a PTA\nwith a baseline of 30 yr and 200 pulsars can reach out to distances slightly\ngreater than 3 Gpc ($z\\sim0.53$). We find that the host galaxies of all\nbinaries detectable with a baseline of 20 yr are expected to be present in the\nWide-field Infrared Survey Explorer and SuperCOSMOS surveys, if they lie\noutside the plane of the Milky Way. The Two Micron All Sky Survey becomes\nincomplete for hosts of binaries more massive than $10^{9.8}{\\rm M}_\\odot$ at a\nluminosity distance greater than 1 Gpc. The EM surveys become slightly more\nincomplete when PTAs with longer baselines and therefore improved sensitivities\nare considered.",
    "pdf_url": "http://arxiv.org/pdf/2505.11598v2",
    "published": "2025-05-16T18:03:48+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11597v1",
    "title": "A luminous and hot infrared through X-ray transient at a 5 kpc offset from a dwarf galaxy",
    "authors": [
      "Jean J. Somalwar",
      "Vikram Ravi",
      "Raffaella Margutti",
      "Ryan Chornock",
      "Priyamvada Natarajan",
      "Wenbin Lu",
      "Charlotte Angus",
      "Matthew J. Graham",
      "Erica Hammerstein",
      "Edward Nathan",
      "Matt Nicholl",
      "Kritti Sharma",
      "Robert Stein",
      "Frank Verdi",
      "Yuhan Yao",
      "Eric C. Bellm",
      "Tracy X. Chen",
      "Michael W. Coughlin",
      "David Hale",
      "Mansi M. Kasliwal",
      "Russ R. Laher",
      "Reed Riddle",
      "Jesper Sollerman"
    ],
    "abstract": "We are searching for hot, constant-color, offset optical flares in the Zwicky\nTransient Facility (ZTF) data stream that are ${>}10''$ from any galaxy in\npublic imaging data from the PanSTARRS survey. Here, we present the first\ndiscovery from this search: AT 2024puz, a luminous multiwavelength transient\noffset by $5\\,$kpc from a ${\\sim}10^8\\,M_\\odot$ galaxy at $z=0.356$ with a\nlow-moderate star formation rate. It produced luminous $10^{44.79 \\pm\n0.04}\\,{\\rm erg\\,s}^{-1}$ optical/UV emission that evolved on a ${\\sim}20\\,$day\ntimescale, as well as $10^{44.12\\pm0.03}\\,{\\rm erg\\,s}^{-1}$ X-ray emission\nwith a photon-index $\\Gamma=1.7$. No associated radio or millimeter emission\nwas detected. We show that the early-time optical emission is likely powered by\nreprocessing of high-energy, accretion-powered radiation, with a possible\ncontribution from a shock in a dense circum-transient medium. If the shock is\ndominant at early-times, the circum-transient medium has a mass\n${\\sim}0.1-1\\,M_\\odot$, radius $10^{15}\\,$cm, and a density profile shallower\nthan ${\\sim}r^{-1}$. A near-infrared excess appears at late-times and is\nsuggestive of reprocessing within a wind or other circum-transient medium. The\nX-rays are most consistent with a central engine. We suggest that AT 2024puz\nmay be associated with an accretion event onto a $50-10^5\\,M_\\odot$ BH, where\nthe lower masses are preferred based on the large projected offset from the\nhost galaxy. AT2024puz exhibits properties similar to both luminous fast blue\noptical transients (LFBOTs) and tidal disruption events (TDEs), but is\nintermediate between them in its energetics and evolution timescale. This\nhighlights the need for broader exploration of the landscape of hot optical\ntransients to trace their origins.",
    "pdf_url": "http://arxiv.org/pdf/2505.11597v1",
    "published": "2025-05-16T18:03:02+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11596v1",
    "title": "Automorphisms of del Pezzo surfaces without points",
    "authors": [
      "Constantin Shramov",
      "Anastasia Vikulova"
    ],
    "abstract": "We study automorphism groups of del Pezzo surfaces without points over a\nfield of zero characteristic, and estimate their Jordan constants.",
    "pdf_url": "http://arxiv.org/pdf/2505.11596v1",
    "published": "2025-05-16T18:02:24+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11595v1",
    "title": "Spectral Policy Optimization: Coloring your Incorrect Reasoning in GRPO",
    "authors": [
      "Peter Chen",
      "Xiaopeng Li",
      "Ziniu Li",
      "Xi Chen",
      "Tianyi Lin"
    ],
    "abstract": "Reinforcement learning (RL) has demonstrated significant success in enhancing\nreasoning capabilities in large language models (LLMs). One of the most widely\nused RL methods is Group Relative Policy Optimization\n(GRPO)~\\cite{Shao-2024-Deepseekmath}, known for its memory efficiency and\nsuccess in training DeepSeek-R1~\\cite{Guo-2025-Deepseek}. However, GRPO stalls\nwhen all sampled responses in a group are incorrect -- referred to as an\n\\emph{all-negative-sample} group -- as it fails to update the policy, hindering\nlearning progress. The contributions of this paper are two-fold. First, we\npropose a simple yet effective framework that introduces response diversity\nwithin all-negative-sample groups in GRPO using AI feedback. We also provide a\ntheoretical analysis, via a stylized model, showing how this diversification\nimproves learning dynamics. Second, we empirically validate our approach,\nshowing the improved performance across various model sizes (7B, 14B, 32B) in\nboth offline and online learning settings with 10 benchmarks, including base\nand distilled variants. Our findings highlight that learning from\nall-negative-sample groups is not only feasible but beneficial, advancing\nrecent insights from \\citet{Xiong-2025-Minimalist}.",
    "pdf_url": "http://arxiv.org/pdf/2505.11595v1",
    "published": "2025-05-16T18:02:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.18181v1",
    "title": "2DNMRGym: An Annotated Experimental Dataset for Atom-Level Molecular Representation Learning in 2D NMR via Surrogate Supervision",
    "authors": [
      "Yunrui Li",
      "Hao Xu",
      "Pengyu Hong"
    ],
    "abstract": "Two-dimensional (2D) Nuclear Magnetic Resonance (NMR) spectroscopy,\nparticularly Heteronuclear Single Quantum Coherence (HSQC) spectroscopy, plays\na critical role in elucidating molecular structures, interactions, and\nelectronic properties. However, accurately interpreting 2D NMR data remains\nlabor-intensive and error-prone, requiring highly trained domain experts,\nespecially for complex molecules. Machine Learning (ML) holds significant\npotential in 2D NMR analysis by learning molecular representations and\nrecognizing complex patterns from data. However, progress has been limited by\nthe lack of large-scale and high-quality annotated datasets. In this work, we\nintroduce 2DNMRGym, the first annotated experimental dataset designed for\nML-based molecular representation learning in 2D NMR. It includes over 22,000\nHSQC spectra, along with the corresponding molecular graphs and SMILES strings.\nUniquely, 2DNMRGym adopts a surrogate supervision setup: models are trained\nusing algorithm-generated annotations derived from a previously validated\nmethod and evaluated on a held-out set of human-annotated gold-standard labels.\nThis enables rigorous assessment of a model's ability to generalize from\nimperfect supervision to expert-level interpretation. We provide benchmark\nresults using a series of 2D and 3D GNN and GNN transformer models,\nestablishing a strong foundation for future work. 2DNMRGym supports scalable\nmodel training and introduces a chemically meaningful benchmark for evaluating\natom-level molecular representations in NMR-guided structural tasks. Our data\nand code is open-source and available on Huggingface and Github.",
    "pdf_url": "http://arxiv.org/pdf/2505.18181v1",
    "published": "2025-05-16T18:02:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11594v1",
    "title": "SageAttention3: Microscaling FP4 Attention for Inference and An Exploration of 8-Bit Training",
    "authors": [
      "Jintao Zhang",
      "Jia Wei",
      "Pengle Zhang",
      "Xiaoming Xu",
      "Haofeng Huang",
      "Haoxu Wang",
      "Kai Jiang",
      "Jun Zhu",
      "Jianfei Chen"
    ],
    "abstract": "The efficiency of attention is important due to its quadratic time\ncomplexity. We enhance the efficiency of attention through two key\ncontributions: First, we leverage the new FP4 Tensor Cores in Blackwell GPUs to\naccelerate attention computation. Our implementation achieves 1038 TOPS on\nRTX5090, which is a 5x speedup over the fastest FlashAttention on RTX5090.\nExperiments show that our FP4 attention can accelerate inference of various\nmodels in a plug-and-play way. Second, we pioneer low-bit attention to training\ntasks. Existing low-bit attention works like FlashAttention3 and SageAttention\nfocus only on inference. However, the efficiency of training large models is\nalso important. To explore whether low-bit attention can be effectively applied\nto training tasks, we design an accurate and efficient 8-bit attention for both\nforward and backward propagation. Experiments indicate that 8-bit attention\nachieves lossless performance in fine-tuning tasks but exhibits slower\nconvergence in pretraining tasks. The code will be available at\nhttps://github.com/thu-ml/SageAttention.",
    "pdf_url": "http://arxiv.org/pdf/2505.11594v1",
    "published": "2025-05-16T18:01:54+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.CV",
      "cs.PF"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11593v2",
    "title": "Mechanically Programming the Cross-Sectional Shape of Soft Growing Robotic Structures for Patient Transfer",
    "authors": [
      "O. Godson Osele",
      "Kentaro Barhydt",
      "Teagan Sullivan",
      "H. Harry Asada",
      "Allison M. Okamura"
    ],
    "abstract": "Pneumatic soft everting robotic structures have the potential to facilitate\nhuman transfer tasks due to their ability to grow underneath humans without\nsliding friction and their utility as a flexible sling when deflated. Tubular\nstructures naturally yield circular cross-sections when inflated, whereas a\nrobotic sling must be both thin enough to grow between them and their resting\nsurface and wide enough to cradle the human. Recent works have achieved\nflattened cross-sections by including rigid components into the structure, but\nthis reduces conformability to the human. We present a method of mechanically\nprogramming the cross-section of soft everting robotic structures using\nflexible strips that constrain radial expansion between points along the outer\nmembrane. Our method enables simultaneously wide and thin profiles while\nmaintaining the full multi-axis flexibility of traditional slings. We develop\nand validate a model relating the geometric design specifications to the\nfabrication parameters, and experimentally characterize their effects on growth\nrate. Finally, we prototype a soft growing robotic sling system and demonstrate\nits use for assisting a single caregiver in bed-to-chair patient transfer.",
    "pdf_url": "http://arxiv.org/pdf/2505.11593v2",
    "published": "2025-05-16T18:00:36+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11592v2",
    "title": "The Prospect from the Upcoming CMB Experiment LiteBIRD to Discover Axion-like Particles Using Milky Way",
    "authors": [
      "Harsh Mehta",
      "Suvodip Mukherjee"
    ],
    "abstract": "The existence of axion-like particles (ALPs) can be probed from their\nsignatures in the Cosmic Microwave Background (CMB) due to the photon-ALP\nresonant conversion over the mass range of ALPs that matches with the effective\nmass of photons in the plasma in the astrophysical systems. Such a conversion\ncan also occur in the Milky Way halo and disk and can cause a unique spatial\nand spectral distortion. The signal is highly non-Gaussian and cannot be\nmeasured precisely by the usual power-spectrum approach. We devise a new\ntechnique to search for this signal from the upcoming full-sky CMB experiment\nLiteBIRD using its multi-frequency band using a template-based spatial profile\nof the ALP distortion signal. This technique captures the large-scale\nnon-Gaussian aspects of the ALP distortion signal in terms of a spatial\ntemplate and makes it possible to search for any non-zero ALP signal. We show\nthat the inference of the ALP coupling using the template-based technique from\nLiteBIRD can provide constraints on the coupling constant approximately $\ng_{a\\gamma} < 6.5 \\times 10^{-12} \\, \\mathrm{GeV}^{-1}$ for ALP masses below\n$10^{-14}$ eV at 95\\% confidence interval which is an order of magnitude better\nthan the current bounds from CERN Axion Solar Telescope (CAST) at $g_{a\\gamma}\n< 6.6 \\times 10^{-11} \\, \\mathrm{GeV}^{-1}$, This shows the capability of\nfuture multi-band CMB experiment LiteBIRD in opening the discovery space\ntowards physics beyond the standard model.",
    "pdf_url": "http://arxiv.org/pdf/2505.11592v2",
    "published": "2025-05-16T18:00:30+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA",
      "astro-ph.HE",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11591v1",
    "title": "Dust stars in the minimal exponential measure model",
    "authors": [
      "Reyhan D. Lambaga",
      "Justin C. Feng",
      "Norman Hsia",
      "Pisin Chen"
    ],
    "abstract": "We report the existence of horizonless compact object solutions supported by\ndust in the Minimal Exponential Measure (MEMe) model, a theory which modifies\nthe couplings between gravity and matter without introducing dynamical degrees\nof freedom. For a perfect fluid source, the field equations for the MEMe model\ncan be rewritten as the Einstein field equations sourced by a perfect fluid\nwith a transformed equation of state, which can endow a sufficiently dense\ncloud of dust with an effective pressure. The resulting dust-supported\nhorizonless compact objects can have masses below $\\sim 10^{-11}~M_\\odot$,\nmaking them suitable as MACHOs comprising a significant mass fraction for dark\nmatter. A necessary condition for the existence of these compact object\nsolutions is that the single free parameter in the MEMe model is\npositive-valued. Additionally, we find that this positive sign for the\nparameter can provide a mechanism for suppressing the formation of (primordial)\nblack holes from the gravitational collapse of matter below a certain mass\nscale.",
    "pdf_url": "http://arxiv.org/pdf/2505.11591v1",
    "published": "2025-05-16T18:00:09+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "83D99, 83C55"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.11590v1",
    "title": "Aharonov-Bohm caging of an electron in a quantum fractal",
    "authors": [
      "Biplab Pal"
    ],
    "abstract": "Fractal geometries exhibit complex structures with scale invariance\nself-similar pattern over various length scales. An artificially designed\nquantum fractal geometry embedded in a uniform magnetic flux has been explored\nin this study. It has been found that due to quantum mechanical effect, such\nquantum fractal display an exotic electronic property which is reflected in its\ntransport characteristics. Owing to this uniform magnetic flux piercing through\neach closed-loop building block of the fractal structure, an electron\ntraversing through such a fractal geometry will pick up a nontrivial\nAharonov-Bohm phase factor, which will influence its transport through the\nsystem. It is shown that, one can completely block the transmission of an\nelectron in this fractal geometry by setting the value of the uniform magnetic\nflux to half flux quantum. This phenomenon of Aharonov-Bohm caging of an\nelectron in this quantum fractal geometry has been supported by the computation\nof the energy spectrum, two-terminal transport and persistent current in its\nvarious generations. This result is very robust against disorder and could be\nuseful in designing efficient quantum algorithms using a quantum fractal\nnetwork.",
    "pdf_url": "http://arxiv.org/pdf/2505.11590v1",
    "published": "2025-05-16T18:00:03+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "cond-mat.other"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.11589v1",
    "title": "A Training Framework for Optimal and Stable Training of Polynomial Neural Networks",
    "authors": [
      "Forsad Al Hossain",
      "Tauhidur Rahman"
    ],
    "abstract": "By replacing standard non-linearities with polynomial activations, Polynomial\nNeural Networks (PNNs) are pivotal for applications such as privacy-preserving\ninference via Homomorphic Encryption (HE). However, training PNNs effectively\npresents a significant challenge: low-degree polynomials can limit model\nexpressivity, while higher-degree polynomials, crucial for capturing complex\nfunctions, often suffer from numerical instability and gradient explosion. We\nintroduce a robust and versatile training framework featuring two synergistic\ninnovations: 1) a novel Boundary Loss that exponentially penalizes activation\ninputs outside a predefined stable range, and 2) Selective Gradient Clipping\nthat effectively tames gradient magnitudes while preserving essential Batch\nNormalization statistics. We demonstrate our framework's broad efficacy by\ntraining PNNs within deep architectures composed of HE-compatible layers (e.g.,\nlinear layers, average pooling, batch normalization, as used in ResNet\nvariants) across diverse image, audio, and human activity recognition datasets.\nThese models consistently achieve high accuracy with low-degree polynomial\nactivations (such as degree 2) and, critically, exhibit stable training and\nstrong performance with polynomial degrees up to 22, where standard methods\ntypically fail or suffer severe degradation. Furthermore, the performance of\nthese PNNs achieves a remarkable parity, closely approaching that of their\noriginal ReLU-based counterparts. Extensive ablation studies validate the\ncontributions of our techniques and guide hyperparameter selection. We confirm\nthe HE-compatibility of the trained models, advancing the practical deployment\nof accurate, stable, and secure deep learning inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.11589v1",
    "published": "2025-05-16T18:00:02+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11587v2",
    "title": "Young stars discovered in dwarf spheroidal galaxies confirm their recent infall into the Milky way",
    "authors": [
      "Francois Hammer",
      "Piercarlo Bonifacio",
      "Elisabetta Caffau",
      "Yanbin Yang",
      "Frederic Arenou",
      "Carine Babusiaux",
      "Monique Spite",
      "Patrick Francois",
      "Ana Gomez",
      "David Katz",
      "Lorenzo Monaco",
      "Marcel Pawlowski",
      "Jianling Wang"
    ],
    "abstract": "Recent observations from the ESA Gaia satellite and with the ESO VLT, have\nidentified the presence of a population of young, 0.5 to 2 Gyr old, stars in\nthe halo and in dwarf spheroidal galaxies surrounding the Milky Way. It\nsuggests that MW dwarf galaxies, currently devoid of gas, had, until recent\ntimes, enough gas to sustain a burst of star formation. The recent loss of gas\ncoincides with their arrival in the vicinity of the Milky Way, in agreement\nwith orbital predictions from Gaia that indicate that most dwarf galaxies\nreached the Milky Way halo less than 3 Gyr years ago. This completely changes\nthe interpretation of their dynamics, mass, and dark matter content.",
    "pdf_url": "http://arxiv.org/pdf/2505.11587v2",
    "published": "2025-05-16T18:00:00+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11588v2",
    "title": "Flavor Equilibration of Supernova Neutrinos: Exploring the Dynamics of Slow Modes",
    "authors": [
      "Ian Padilla-Gay",
      "Heng-Hao Chen",
      "Sajad Abbar",
      "Meng-Ru Wu",
      "Zewei Xiong"
    ],
    "abstract": "Neutrinos experience collective flavor conversion in extreme astrophysical\nenvironments such as core-collapse supernovae (CCSNe). One manifestation of\ncollective conversion is slow flavor conversion (SFC), which has recently\nattracted renewed interest owing to its ubiquity across different regions of\nthe supernova environment. In this study, we systematically examine the\nevolution of kinematic decoherence in a dense neutrino gas undergoing SFC,\nconsidering lepton number asymmetries as large as $30\\%$. Our findings show\nthat the neutrino gas asymptotically evolves toward a generic state of\ncoarse-grained flavor equilibration which is constrained by approximate lepton\nnumber conservation. The equilibration occurs within a few factors of the\ninverse vacuum oscillation frequency, $\\omega^{-1}$, which corresponds to\n(anti)neutrinos reaching near flavor equipartition after a few kilometers for\ntypical supernova neutrino energies. Notably, the quasi-steady state of the\nneutrino number densities can be quantitatively described by the\nneutrino-antineutrino number density ratio $n_{\\bar{\\nu}_e}/n_{\\nu_e}$ alone.\nSuch a simple estimation opens new opportunities for incorporating SFC into\nCCSN simulations, particularly in regions where SFC develops on scales much\nshorter than those of collisions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11588v2",
    "published": "2025-05-16T18:00:00+00:00",
    "categories": [
      "astro-ph.HE",
      "hep-ph"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11501v1",
    "title": "Exactly solvable dissipative dynamics and one-form strong-to-weak spontaneous symmetry breaking in interacting two-dimensional spin systems",
    "authors": [
      "Lucas Sá",
      "Benjamin Béri"
    ],
    "abstract": "We study the dissipative dynamics of a class of interacting \"gamma-matrix\"\nspin models coupled to a Markovian environment. For spins on an arbitrary\ngraph, we construct a Lindbladian that maps to a non-Hermitian model of free\nMajorana fermions hopping on the graph with a background classical\n$\\mathbb{Z}_2$ gauge field. We show, analytically and numerically, that the\nsteady states and relaxation dynamics are qualitatively independent of the\nchoice of the underlying graph, in stark contrast to the Hamiltonian case. We\nalso show that the exponentially many steady states provide a concrete example\nof mixed-state topological order, in the sense of strong-to-weak spontaneous\nsymmetry breaking of a one-form symmetry. While encoding only classical\ninformation, the steady states still exhibit long-range quantum correlations.\nAfterward, we examine the relaxation processes toward the steady state by\nnumerically computing decay rates, which we generically find to be finite, even\nin the dissipationless limit. We however identify symmetry sectors where\nfermion-parity conservation is enhanced to fermion-number conservation, where\nwe can analytically bound the decay rates and prove that they vanish in the\nlimits of both infinitely weak and infinitely strong dissipation. Finally, we\nshow that while the choice of coherent dynamics is very flexible, exact\nsolvability strongly constrains the allowed form of dissipation. Our work\nestablishes an analytically tractable framework to explore nonequilibrium\nquantum phases of matter and the relaxation mechanisms toward them.",
    "pdf_url": "http://arxiv.org/pdf/2505.11501v1",
    "published": "2025-05-16T17:59:59+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech",
      "cond-mat.str-el",
      "nlin.SI"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11500v1",
    "title": "NVSS J151002+570243: accretion and spin of a z > 4 Fermi detected blazar",
    "authors": [
      "Gabriele Alzati",
      "Tullia Sbarrato",
      "Gabriele Ghisellini"
    ],
    "abstract": "Active galactic nuclei formation and evolution is currently an open puzzle.\nTheir enormous mass is not explainable via sub-Eddington accretion and the\nfrequent presence of relativistic jets at high-z, commonly linked with spinning\nblack holes, suggest a less effective accretion process. NVSS J151002+570243 is\npart of this population, being the most distant blazar consistently detected by\nFermi/LAT, hence hosting a powerful jet. We tested the hypothesis of a\nsuper-Eddington accretion process for this source by modeling its big blue bump\nwith a set of accretion disk emission models. We first tested a standard\ngeometrically thin, optically thick $\\alpha$-disk, obtaining a mass of\nLog$M/M_\\odot=8.65\\pm0.19$ consistent with virial-based results and a\nsignificantly sub-Eddington accretion rate $\\lambda=0.02\\pm0.01$. We then\nfocused on the analytic approximations of two numerical models that take into\naccount the General Relativity effects of a spinning black hole (reasonable due\nto the presence of a jet) and a close-to- or super-Eddington accretion rate\n(KERBB and SLIMBH). Despite the focus on super-critical accretion, these models\nconfirm a surprisingly low Eddington ratio, of the order of 3\\%. The hypothesis\nof a continuous accretion at this measured rate is unrealistic, since it would\nimply a seed black hole mass of $\\sim10^6-10^8M_\\odot$ at redshift z=20. Hence\nwe explore the possibility of a continuous super-critical accretion starting\nfrom a $\\sim10^2M_\\odot$ seed, that would spin up the black hole and eventually\ncontribute in launching the relativistic jet. The measured low accretion rate\nwould thus happen only once the jet is active. This idea would reconcile the\nblack holes with large masses accreting at somewhat slow rates that are\nobserved at z>4, with the need of an extremely fast evolution, by allowing the\nformation of stellar-size black hole seeds even as late as at $z\\sim8$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11500v1",
    "published": "2025-05-16T17:59:58+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11499v2",
    "title": "Gauged $τ$-lepton chiral currents and $B \\to K^{(*)} E_{\\rm miss}$",
    "authors": [
      "Luca Di Luzio",
      "Marco Nardecchia",
      "Claudio Toni"
    ],
    "abstract": "We consider a class of theories with a $U(1)_X$ gauge symmetry associated\nwith leptonic chiral currents. The low-energy effective field theory includes a\nlight spin-$1$ boson coupled to the electroweak gauge sector via a Wess-Zumino\nterm, which ensures anomaly cancellation in the infrared. As a concrete\napplication, we show that a light vector boson with mass $m_X \\simeq\n2.1\\,\\text{GeV}$, coupled to a $\\tau$-lepton chiral current, can readily\naccount for the recent $3\\sigma$ excess observed in $B \\to K^{(*)} E_{\\rm\nmiss}$ at Belle II, while remaining consistent with existing constraints from\n$Z \\to \\gamma E_{\\rm miss}$ and direct searches for anomalon fields responsible\nfor anomaly cancellation in the ultraviolet. After classifying\nphenomenologically viable models, we explore in greater detail two concrete\nrealizations which give rise to distinctive phenomenological signatures,\npotentially accessible at future experiments at the high-energy and intensity\nfrontiers.",
    "pdf_url": "http://arxiv.org/pdf/2505.11499v2",
    "published": "2025-05-16T17:59:57+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11498v1",
    "title": "Evolution of granular salty ice analogs for Europa: Sublimation and Irradiation",
    "authors": [
      "Rafael Ottersberg",
      "Antoine Pommerol",
      "Linus Leo Stöckli",
      "Lorenzo Obersnel",
      "André Galli",
      "Axel Murk",
      "Peter Wurz",
      "Nicolas Thomas"
    ],
    "abstract": "We study the evolution of the Vis-NIR reflectance spectrum of salty granular\nice analog samples in a simulation chamber under conditions relevant to the\nsurface of Europa. A novel application and custom calibration of a thermopile\nsensor enabled the measurement of the surface temperature of the samples in far\ninfrared emission. This allows the kinetics of the observed changes to be\nscaled to equivalent timescales on Europa. We observed significant changes in\nthe depth and shape of the broad water absorption bands for all samples on\ntimescales of a few thousand years of equatorial conditions on Europa. This\neffect should be taken into account if quantitative predictions about bulk\ncomposition are made based on remote-sensing data. A narrow absorption feature\nattributed to hydrohalite formed during the sublimation of the sodium chloride\nsample. We used near-infrared spectroscopy in an irradiation chamber to assess\nthe stability of this narrow feature under electron irradiation. We find that\nthe radiation environment present on Europa dehydrates the hydrohalite on short\ntimescales. Therefore, we expect hydrohalite not to be present on the surface,\nunless erupted very recently (< 10 yr) or located in thermal anomalies (> 145\nK). Thus, a detection of hydrohalite would clearly indicate recent activity.",
    "pdf_url": "http://arxiv.org/pdf/2505.11498v1",
    "published": "2025-05-16T17:59:54+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11586v1",
    "title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks",
    "authors": [
      "Rui Zhang",
      "Yun Shen",
      "Hongwei Li",
      "Wenbo Jiang",
      "Hanxiao Chen",
      "Yuan Zhang",
      "Guowen Xu",
      "Yang Zhang"
    ],
    "abstract": "Recent research highlights concerns about the trustworthiness of third-party\nPre-Trained Language Models (PTLMs) due to potential backdoor attacks. These\nbackdoored PTLMs, however, are effective only for specific pre-defined\ndownstream tasks. In reality, these PTLMs can be adapted to many other\nunrelated downstream tasks. Such adaptation may lead to unforeseen consequences\nin downstream model outputs, consequently raising user suspicion and\ncompromising attack stealthiness. We refer to this phenomenon as backdoor\ncomplications. In this paper, we undertake the first comprehensive\nquantification of backdoor complications. Through extensive experiments using 4\nprominent PTLMs and 16 text classification benchmark datasets, we demonstrate\nthe widespread presence of backdoor complications in downstream models\nfine-tuned from backdoored PTLMs. The output distribution of triggered samples\nsignificantly deviates from that of clean samples. Consequently, we propose a\nbackdoor complication reduction method leveraging multi-task learning to\nmitigate complications without prior knowledge of downstream tasks. The\nexperimental results demonstrate that our proposed method can effectively\nreduce complications while maintaining the efficacy and consistency of backdoor\nattacks. Our code is available at\nhttps://github.com/zhangrui4041/Backdoor_Complications.",
    "pdf_url": "http://arxiv.org/pdf/2505.11586v1",
    "published": "2025-05-16T17:59:53+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11497v2",
    "title": "QVGen: Pushing the Limit of Quantized Video Generative Models",
    "authors": [
      "Yushi Huang",
      "Ruihao Gong",
      "Jing Liu",
      "Yifu Ding",
      "Chengtao Lv",
      "Haotong Qin",
      "Jun Zhang"
    ],
    "abstract": "Video diffusion models (DMs) have enabled high-quality video synthesis. Yet,\ntheir substantial computational and memory demands pose serious challenges to\nreal-world deployment, even on high-end GPUs. As a commonly adopted solution,\nquantization has proven notable success in reducing cost for image DMs, while\nits direct application to video DMs remains ineffective. In this paper, we\npresent QVGen, a novel quantization-aware training (QAT) framework tailored for\nhigh-performance and inference-efficient video DMs under extremely low-bit\nquantization (e.g., 4-bit or below). We begin with a theoretical analysis\ndemonstrating that reducing the gradient norm is essential to facilitate\nconvergence for QAT. To this end, we introduce auxiliary modules ($\\Phi$) to\nmitigate large quantization errors, leading to significantly enhanced\nconvergence. To eliminate the inference overhead of $\\Phi$, we propose a\nrank-decay strategy that progressively eliminates $\\Phi$. Specifically, we\nrepeatedly employ singular value decomposition (SVD) and a proposed rank-based\nregularization $\\mathbf{\\gamma}$ to identify and decay low-contributing\ncomponents. This strategy retains performance while zeroing out inference\noverhead. Extensive experiments across $4$ state-of-the-art (SOTA) video DMs,\nwith parameter sizes ranging from $1.3$B $\\sim14$B, show that QVGen is the\nfirst to reach full-precision comparable quality under 4-bit settings.\nMoreover, it significantly outperforms existing methods. For instance, our\n3-bit CogVideoX-2B achieves improvements of $+25.28$ in Dynamic Degree and\n$+8.43$ in Scene Consistency on VBench.",
    "pdf_url": "http://arxiv.org/pdf/2505.11497v2",
    "published": "2025-05-16T17:59:40+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11585v1",
    "title": "Finite geometry and black hole stability: Embedding discrete space into classical manifolds",
    "authors": [
      "Arkady Bolotin"
    ],
    "abstract": "The issue of defining the volume of black holes has significant implications\nfor quantum gravity. Drawing on concepts from quantum theory and general\nrelativity, several motivations for introducing discreteness in geometry can be\nproposed. However, to seriously consider any proposal for a discrete geometry,\nthe identification problem and the challenge of defining a distance function\nwithin such a geometry must be addressed. This paper proposes the faithful\nembedding of sets representing spaces in finite geometry -- a specific type of\ndiscrete geometry characterized by a finite set of points -- into Riemannian\nmanifolds as a solution to these problems. Similar to a classical measuring\napparatus that interprets and understands quantum results in classical terms,\nclassical geometry serves as a bridge between the discreteness of the physical\nworld and our continuous understanding of the properties of space. In this\nframework, the volumetric density of information contained within a black hole\nis established, providing a consistent volume for the Schwarzschild black hole\nobserved by all observers. Furthermore, the study finds that the minimum volume\nof the Schwarzschild black hole is non-zero. This fact implies that a black\nhole can only evaporate until its event horizon radius reaches the Planck\nlength, signifying that black hole remnants are stable. Consequently, the total\ncollapse of a black hole is prevented by the finite nature of the geometry\ndescribing physical space.",
    "pdf_url": "http://arxiv.org/pdf/2505.11585v1",
    "published": "2025-05-16T17:59:21+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.11496v1",
    "title": "Desirability of outcome ranking (DOOR) analysis for multivariate survival outcomes with application to ACTT-1 trial",
    "authors": [
      "Shiyu Shu",
      "Guoqing Diao",
      "Toshimitsu Hamasaki",
      "Scott Evans"
    ],
    "abstract": "Desirability Of Outcome Ranking (DOOR) methodology accounts for problems that\nconventional benefit:risk analyses in clinical trials ignore, such as competing\nrisks and the trade-off relationship between efficacy and toxicity. DOOR levels\ncan be considered as a multi-state process in nature, as event-free survival,\nand survival with side effects are not equivalent and the overall patient\ntrajectory requires recognition. In monotone settings where patients'\nconditions can only decline, we can record event times for each transition from\none level of the DOOR to another, and construct Kaplan-Meier curves displaying\ntransition times. While traditional survival analysis methods such as the Cox\nmodel require assumptions like proportional hazards and suffer from the\nchallenge of interpreting a hazard ratio, Restricted Mean Survival Time (RMST)\noffers an alternative with greater intuitiveness. Therefore, we propose a\ncombination of the two domains to develop estimation and inferential procedures\nthat could benefit from the advantages of both DOOR and RMST. Particularly, the\narea under each survival curve restricted to a time point, or the RMST, has\nclear clinical meanings, from expected event-free survival time, expected\nsurvival time with at most one of the events, to expected lifetime before\ndeath. We show that the nonparametric estimator of the RMSTs asymptotically\nfollows a multivariate Gaussian process through the martingale theory and\nfunctional delta method. There are alternative approaches to hypothesis testing\nthat recognize when patients transition into worse states. We evaluate our\nproposed method with data simulated under a multistate model. We consider\nvarious scenarios, including when the null hypothesis is true, when the\ntreatment difference exists only in certain DOOR levels, and small-sample\nstudies. We also present a real-world example with ACTT-1.",
    "pdf_url": "http://arxiv.org/pdf/2505.11496v1",
    "published": "2025-05-16T17:58:02+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.11495v1",
    "title": "Bracing for Impact: Robust Humanoid Push Recovery and Locomotion with Reduced Order Models",
    "authors": [
      "Lizhi Yang",
      "Blake Werner",
      "Adrian B. Ghansah",
      "Aaron D. Ames"
    ],
    "abstract": "Push recovery during locomotion will facilitate the deployment of humanoid\nrobots in human-centered environments. In this paper, we present a unified\nframework for walking control and push recovery for humanoid robots, leveraging\nthe arms for push recovery while dynamically walking. The key innovation is to\nuse the environment, such as walls, to facilitate push recovery by combining\nSingle Rigid Body model predictive control (SRB-MPC) with Hybrid Linear\nInverted Pendulum (HLIP) dynamics to enable robust locomotion, push detection,\nand recovery by utilizing the robot's arms to brace against such walls and\ndynamically adjusting the desired contact forces and stepping patterns.\nExtensive simulation results on a humanoid robot demonstrate improved\nperturbation rejection and tracking performance compared to HLIP alone, with\nthe robot able to recover from pushes up to 100N for 0.2s while walking at\ncommanded speeds up to 0.5m/s. Robustness is further validated in scenarios\nwith angled walls and multi-directional pushes.",
    "pdf_url": "http://arxiv.org/pdf/2505.11495v1",
    "published": "2025-05-16T17:57:18+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11494v2",
    "title": "SHIELD: Safety on Humanoids via CBFs In Expectation on Learned Dynamics",
    "authors": [
      "Lizhi Yang",
      "Blake Werner",
      "Ryan K. Cosner",
      "David Fridovich-Keil",
      "Preston Culbertson",
      "Aaron D. Ames"
    ],
    "abstract": "Robot learning has produced remarkably effective ``black-box'' controllers\nfor complex tasks such as dynamic locomotion on humanoids. Yet ensuring dynamic\nsafety, i.e., constraint satisfaction, remains challenging for such policies.\nReinforcement learning (RL) embeds constraints heuristically through reward\nengineering, and adding or modifying constraints requires retraining.\nModel-based approaches, like control barrier functions (CBFs), enable runtime\nconstraint specification with formal guarantees but require accurate dynamics\nmodels. This paper presents SHIELD, a layered safety framework that bridges\nthis gap by: (1) training a generative, stochastic dynamics residual model\nusing real-world data from hardware rollouts of the nominal controller,\ncapturing system behavior and uncertainties; and (2) adding a safety layer on\ntop of the nominal (learned locomotion) controller that leverages this model\nvia a stochastic discrete-time CBF formulation enforcing safety constraints in\nprobability. The result is a minimally-invasive safety layer that can be added\nto the existing autonomy stack to give probabilistic guarantees of safety that\nbalance risk and performance. In hardware experiments on an Unitree G1\nhumanoid, SHIELD enables safe navigation (obstacle avoidance) through varied\nindoor and outdoor environments using a nominal (unknown) RL controller and\nonboard perception.",
    "pdf_url": "http://arxiv.org/pdf/2505.11494v2",
    "published": "2025-05-16T17:57:03+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11493v3",
    "title": "GIE-Bench: Towards Grounded Evaluation for Text-Guided Image Editing",
    "authors": [
      "Yusu Qian",
      "Jiasen Lu",
      "Tsu-Jui Fu",
      "Xinze Wang",
      "Chen Chen",
      "Yinfei Yang",
      "Wenze Hu",
      "Zhe Gan"
    ],
    "abstract": "Editing images using natural language instructions has become a natural and\nexpressive way to modify visual content; yet, evaluating the performance of\nsuch models remains challenging. Existing evaluation approaches often rely on\nimage-text similarity metrics like CLIP, which lack precision. In this work, we\nintroduce a new benchmark designed to evaluate text-guided image editing models\nin a more grounded manner, along two critical dimensions: (i) functional\ncorrectness, assessed via automatically generated multiple-choice questions\nthat verify whether the intended change was successfully applied; and (ii)\nimage content preservation, which ensures that non-targeted regions of the\nimage remain visually consistent using an object-aware masking technique and\npreservation scoring. The benchmark includes over 1000 high-quality editing\nexamples across 20 diverse content categories, each annotated with detailed\nediting instructions, evaluation questions, and spatial object masks. We\nconduct a large-scale study comparing GPT-Image-1, the latest flagship in the\ntext-guided image editing space, against several state-of-the-art editing\nmodels, and validate our automatic metrics against human ratings. Results show\nthat GPT-Image-1 leads in instruction-following accuracy, but often\nover-modifies irrelevant image regions, highlighting a key trade-off in the\ncurrent model behavior. GIE-Bench provides a scalable, reproducible framework\nfor advancing more accurate evaluation of text-guided image editing.",
    "pdf_url": "http://arxiv.org/pdf/2505.11493v3",
    "published": "2025-05-16T17:55:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11492v2",
    "title": "Anomalies in Hadronic $B$ Decays: an Update",
    "authors": [
      "Bhubanjyoti Bhattacharya",
      "Marianne Bouchard",
      "Luke Hudy",
      "Alexandre Jean",
      "David London",
      "Christopher MacKenzie"
    ],
    "abstract": "Recently, $B\\to PP$ decays ($B = \\{B^0, B^+, B_s^0\\}$, $P = \\{ \\pi, K \\}$)\nwere analyzed under the assumption of flavor SU(3) symmetry (SU(3)$_F$).\nAlthough the individual fits to $\\Delta S=0$ or $\\Delta S=1$ decays are good,\nit was found that the combined fit is very poor: there is a $3.6\\sigma$\ndisagreement with the SU(3)$_F$ limit of the standard model\n(SM$_{\\rm{SU(3)}_F}$). One can remove this discrepancy by adding\nSU(3)$_F$-breaking effects, but 1000\\% SU(3)$_F$ breaking is required. In this\npaper, we extend this analysis to include decays in which there is an $\\eta$\nand/or $\\eta'$ meson in the final state. We now find that the combined fit\nexhibits a $4.1\\sigma$ discrepancy with the SM$_{\\rm{SU(3)}_F}$, and 1000\\%\nSU(3)$_F$-breaking effects are still required to explain the data. These\nresults are rigorous, group-theoretically -- no theoretical assumptions have\nbeen made. But when one adds some theoretical input motivated by QCD\nfactorization, the discrepancy with the SM$_{\\rm{SU(3)}_F}$ grows to\n$4.9\\sigma$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11492v2",
    "published": "2025-05-16T17:55:24+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11491v1",
    "title": "Potential failures of physics-informed machine learning in traffic flow modeling: theoretical and experimental analysis",
    "authors": [
      "Yuan-Zheng Lei",
      "Yaobang Gong",
      "Dianwei Chen",
      "Yao Cheng",
      "Xianfeng Terry Yang"
    ],
    "abstract": "This study critically examines the performance of physics-informed machine\nlearning (PIML) approaches for traffic flow modeling, defining the failure of a\nPIML model as the scenario where it underperforms both its purely data-driven\nand purely physics-based counterparts. We analyze the loss landscape by\nperturbing trained models along the principal eigenvectors of the Hessian\nmatrix and evaluating corresponding loss values. Our results suggest that\nphysics residuals in PIML do not inherently hinder optimization, contrary to a\ncommonly assumed failure cause. Instead, successful parameter updates require\nboth ML and physics gradients to form acute angles with the quasi-true gradient\nand lie within a conical region. Given inaccuracies in both the physics models\nand the training data, satisfying this condition is often difficult.\nExperiments reveal that physical residuals can degrade the performance of LWR-\nand ARZ-based PIML models, especially under highly physics-driven settings.\nMoreover, sparse sampling and the use of temporally averaged traffic data can\nproduce misleadingly small physics residuals that fail to capture actual\nphysical dynamics, contributing to model failure. We also identify the\nCourant-Friedrichs-Lewy (CFL) condition as a key indicator of dataset\nsuitability for PIML, where successful applications consistently adhere to this\ncriterion. Lastly, we observe that higher-order models like ARZ tend to have\nlarger error lower bounds than lower-order models like LWR, which is consistent\nwith the experimental findings of existing studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11491v1",
    "published": "2025-05-16T17:55:06+00:00",
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11490v1",
    "title": "Duality for finitely valued algebras",
    "authors": [
      "Marco Abbadini",
      "Adam Přenosil"
    ],
    "abstract": "The theory of natural dualities provides a well-developed framework for\nstudying Stone-like dualities induced by an algebra $\\mathbf{L}$ which acts as\na dualizing object when equipped with suitable topological and relational\nstructure. The development of this theory has, however, largely remained\nrestricted to the case where $\\mathbf{L}$ is finite. Motivated by the desire to\nprovide a universal algebraic formulation of the existing duality of Cignoli\nand Marra or locally weakly finite MV-algebras and to extend it to a\ncorresponding class of positive MV-algebras, in this paper we investigate\nStone-like dualities where the algebra $\\mathbf{L}$ is allowed to be infinite.\nThis requires restricting our attention from the whole prevariety generated by\n$\\mathbf{L}$ to the subclass of algebras representable as algebras of\n$\\mathbf{L}$-valued functions of finite range, a distinction that does not\narise in the case of finite $\\mathbf{L}$. Provided some requirements on\n$\\mathbf{L}$ are met, our main result establishes a categorical duality for\nthis class of algebras, which covers the above cases of MV-algebras and\npositive MV-algebras.",
    "pdf_url": "http://arxiv.org/pdf/2505.11490v1",
    "published": "2025-05-16T17:53:09+00:00",
    "categories": [
      "math.LO"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11584v1",
    "title": "LLM Agents Are Hypersensitive to Nudges",
    "authors": [
      "Manuel Cherep",
      "Pattie Maes",
      "Nikhil Singh"
    ],
    "abstract": "LLMs are being set loose in complex, real-world environments involving\nsequential decision-making and tool use. Often, this involves making choices on\nbehalf of human users. However, not much is known about the distribution of\nsuch choices, and how susceptible they are to different choice architectures.\nWe perform a case study with a few such LLM models on a multi-attribute tabular\ndecision-making problem, under canonical nudges such as the default option,\nsuggestions, and information highlighting, as well as additional prompting\nstrategies. We show that, despite superficial similarities to human choice\ndistributions, such models differ in subtle but important ways. First, they\nshow much higher susceptibility to the nudges. Second, they diverge in points\nearned, being affected by factors like the idiosyncrasy of available prizes.\nThird, they diverge in information acquisition strategies: e.g. incurring\nsubstantial cost to reveal too much information, or selecting without revealing\nany. Moreover, we show that simple prompt strategies like zero-shot chain of\nthought (CoT) can shift the choice distribution, and few-shot prompting with\nhuman data can induce greater alignment. Yet, none of these methods resolve the\nsensitivity of these models to nudges. Finally, we show how optimal nudges\noptimized with a human resource-rational model can similarly increase LLM\nperformance for some models. All these findings suggest that behavioral tests\nare needed before deploying models as agents or assistants acting on behalf of\nusers in complex environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.11584v1",
    "published": "2025-05-16T17:53:05+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11489v1",
    "title": "Exactly solvable many-body dynamics from space-time duality",
    "authors": [
      "Bruno Bertini",
      "Pieter W. Claeys",
      "Tomaž Prosen"
    ],
    "abstract": "Recent years have seen significant advances, both theoretical and\nexperimental, in our understanding of quantum many-body dynamics. Given this\nproblem's high complexity, it is surprising that a substantial amount of this\nprogress can be ascribed to exact analytical results. Here we review\ndual-unitary circuits as a particular setting leading to exact results in\nquantum many-body dynamics. Dual-unitary circuits constitute minimal models in\nwhich space and time are treated on an equal footings, yielding exactly\nsolvable yet possibly chaotic evolution. They were the first in which current\nnotions of quantum chaos could be analytically quantified, allow for a full\ncharacterisation of the dynamics of thermalisation, scrambling, and\nentanglement (among others), and can be experimentally realised in current\nquantum simulators. Dual-unitarity is a specific fruitful implementation of the\nmore general idea of space-time duality in which the roles of space and time\nare exchanged to access relevant dynamical properties of quantum many-body\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11489v1",
    "published": "2025-05-16T17:52:54+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "hep-th",
      "math-ph",
      "math.MP",
      "nlin.CD",
      "quant-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.11488v1",
    "title": "Higher-spin effects in black hole and neutron star binary dynamics: worldline supersymmetry beyond minimal coupling",
    "authors": [
      "Domenico Bonocore",
      "Anna Kulesza",
      "Johannes Pirsch"
    ],
    "abstract": "The inclusion of spin effects in the binary dynamics for black hole and\nneutron stars is crucial for the computation of gravitational wave observables.\nWorldline supersymmetric models have shown to be particularly efficient at this\ntask up to quadratic order in spin, but progress at higher orders has been\nhampered by no-go-theorems. In this work we propose a novel approach to\novercome this problem by extending the supersymmetry beyond minimal coupling.\nWe demonstrate the potential of this approach by computing an all-order in spin\nand linear in curvature, manifestly supersymmetric Hamiltonian, as well as a\ncubic order in spin Hamiltonian in arbitrary spacetime dimensions. In doing so,\nwe identify a criterion that uniquely determines the Kerr geometry in terms of\nworldline supersymmetry. Equipped with these Hamiltonians, we demonstrate the\nexponentiation of three-point and Compton amplitudes using the recently\nproposed Generalized Wilson line approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.11488v1",
    "published": "2025-05-16T17:50:51+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11487v1",
    "title": "Area and volume from entangled qubits",
    "authors": [
      "Juan M. Romero",
      "Emiliano Montoya-González"
    ],
    "abstract": "In this paper a relation between entangled states and geometry is studied. In\nparticular, the area of 2D parallelogram is obtained from an entangled 4-qubit\nstate. In addition, the vector area of a 3D parallelogram is derived from\nentangled 6-qubit states. Moreover, the volume of a 3D parallelepiped is\ndeduced from an entangled 9-qubit state. Furthermore, it has been provided the\nquantum circuit in qiskit code for these entangled states. It is worth\nmentioning that parallelograms and parallelepipeds serve as fundamental\nbuilding blocks for more sophisticated geometric structures.",
    "pdf_url": "http://arxiv.org/pdf/2505.11487v1",
    "published": "2025-05-16T17:50:28+00:00",
    "categories": [
      "quant-ph",
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11486v1",
    "title": "Unbiased observable estimation via noisy channel mixtures for fault-tolerant quantum computation",
    "authors": [
      "Dmitrii Khitrin",
      "Kenneth R. Brown",
      "Abhinav Anand"
    ],
    "abstract": "Unitary errors, such as those arising from fault-tolerant compilation of\nquantum algorithms, systematically bias observable estimates. Correcting this\nbias typically requires additional resources, such as an increased number of\nnon-Clifford gates. In this work, we present an alternative method for\ncorrecting bias in the expectation values of observables. The method leverages\na decomposition of the ideal quantum channel into a probabilistic mixture of\nnoisy quantum channels. Using this decomposition, we construct unbiased\nestimators as weighted sums of expectation values obtained from the noisy\nchannels. We provide a detailed analysis of the method, identify the conditions\nunder which it is effective, and validate its performance through numerical\nsimulations. In particular, we demonstrate unbiased observable estimation in\nthe presence of unitary errors by simulating the time dynamics of the Ising\nHamiltonian. Our strategy offers a resource-efficient way to reduce the impact\nof unitary errors, improving methods for estimating observables in noisy\nnear-term quantum devices and fault-tolerant implementation of quantum\nalgorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.11486v1",
    "published": "2025-05-16T17:48:54+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11485v1",
    "title": "Modeling cognitive processes of natural reading with transformer-based Language Models",
    "authors": [
      "Bruno Bianchi",
      "Fermín Travi",
      "Juan E. Kamienkowski"
    ],
    "abstract": "Recent advances in Natural Language Processing (NLP) have led to the\ndevelopment of highly sophisticated language models for text generation. In\nparallel, neuroscience has increasingly employed these models to explore\ncognitive processes involved in language comprehension. Previous research has\nshown that models such as N-grams and LSTM networks can partially account for\npredictability effects in explaining eye movement behaviors, specifically Gaze\nDuration, during reading. In this study, we extend these findings by evaluating\ntransformer-based models (GPT2, LLaMA-7B, and LLaMA2-7B) to further investigate\nthis relationship. Our results indicate that these architectures outperform\nearlier models in explaining the variance in Gaze Durations recorded from\nRioplantense Spanish readers. However, similar to previous studies, these\nmodels still fail to account for the entirety of the variance captured by human\npredictability. These findings suggest that, despite their advancements,\nstate-of-the-art language models continue to predict language in ways that\ndiffer from human readers.",
    "pdf_url": "http://arxiv.org/pdf/2505.11485v1",
    "published": "2025-05-16T17:47:58+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11484v2",
    "title": "SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning",
    "authors": [
      "Yige Xu",
      "Xu Guo",
      "Zhiwei Zeng",
      "Chunyan Miao"
    ],
    "abstract": "Test-Time Scaling (TTS) refers to approaches that improve reasoning\nperformance by allocating extra computation during inference, without altering\nthe model's parameters. While existing TTS methods operate in a discrete token\nspace by generating more intermediate steps, recent studies in Coconut and\nSoftCoT have demonstrated that thinking in the continuous latent space can\nfurther enhance the reasoning performance. Such latent thoughts encode\ninformative thinking without the information loss associated with\nautoregressive token generation, sparking increased interest in\ncontinuous-space reasoning. Unlike discrete decoding, where repeated sampling\nenables exploring diverse reasoning paths, latent representations in continuous\nspace are fixed for a given input, which limits diverse exploration, as all\ndecoded paths originate from the same latent thought. To overcome this\nlimitation, we introduce SoftCoT++ to extend SoftCoT to the Test-Time Scaling\nparadigm by enabling diverse exploration of thinking paths. Specifically, we\nperturb latent thoughts via multiple specialized initial tokens and apply\ncontrastive learning to promote diversity among soft thought representations.\nExperiments across five reasoning benchmarks and two distinct LLM architectures\ndemonstrate that SoftCoT++ significantly boosts SoftCoT and also outperforms\nSoftCoT with self-consistency scaling. Moreover, it shows strong compatibility\nwith conventional scaling techniques such as self-consistency. Source code is\navailable at https://github.com/xuyige/SoftCoT.",
    "pdf_url": "http://arxiv.org/pdf/2505.11484v2",
    "published": "2025-05-16T17:47:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15835v1",
    "title": "Transforming Decoder-Only Transformers for Accurate WiFi-Telemetry Based Indoor Localization",
    "authors": [
      "Nayan Sanjay Bhatia",
      "Katia Obraczka"
    ],
    "abstract": "Wireless Fidelity (WiFi) based indoor positioning is a widely researched area\nfor determining the position of devices within a wireless network. Accurate\nindoor location has numerous applications, such as asset tracking and indoor\nnavigation. Despite advances in WiFi localization techniques -- in particular\napproaches that leverage WiFi telemetry -- their adoption in practice remains\nlimited due to several factors including environmental changes that cause\nsignal fading, multipath effects, interference, which, in turn, impact\npositioning accuracy. In addition, telemetry data differs depending on the WiFi\ndevice vendor, offering distinct features and formats; use case requirements\ncan also vary widely. Currently, there is no unified model to handle all these\nvariations effectively. In this paper, we present WiFiGPT, a Generative\nPretrained Transformer (GPT) based system that is able to handle these\nvariations while achieving high localization accuracy. Our experiments with\nWiFiGPT demonstrate that GPTs, in particular Large Language Models (LLMs), can\neffectively capture subtle spatial patterns in noisy wireless telemetry, making\nthem reliable regressors. Compared to existing state-of-the-art methods, our\nmethod matches and often surpasses conventional approaches for multiple types\nof telemetry. Achieving sub-meter accuracy for RSSI and FTM and\ncentimeter-level precision for CSI demonstrates the potential of LLM-based\nlocalisation to outperform specialized techniques, all without handcrafted\nsignal processing or calibration.",
    "pdf_url": "http://arxiv.org/pdf/2505.15835v1",
    "published": "2025-05-16T17:47:32+00:00",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11483v1",
    "title": "msf-CNN: Patch-based Multi-Stage Fusion with Convolutional Neural Networks for TinyML",
    "authors": [
      "Zhaolan Huang",
      "Emmanuel Baccelli"
    ],
    "abstract": "AI spans from large language models to tiny models running on\nmicrocontrollers (MCUs). Extremely memory-efficient model architectures are\ndecisive to fit within an MCU's tiny memory budget e.g., 128kB of RAM. However,\ninference latency must remain small to fit real-time constraints. An approach\nto tackle this is patch-based fusion, which aims to optimize data flows across\nneural network layers. In this paper, we introduce msf-CNN, a novel technique\nthat efficiently finds optimal fusion settings for convolutional neural\nnetworks (CNNs) by walking through the fusion solution space represented as a\ndirected acyclic graph. Compared to previous work on CNN fusion for MCUs,\nmsf-CNN identifies a wider set of solutions. We published an implementation of\nmsf-CNN running on various microcontrollers (ARM Cortex-M, RISC-V, ESP32). We\nshow that msf-CNN can achieve inference using 50% less RAM compared to the\nprior art (MCUNetV2 and StreamNet). We thus demonstrate how msf-CNN offers\nadditional flexibility for system designers.",
    "pdf_url": "http://arxiv.org/pdf/2505.11483v1",
    "published": "2025-05-16T17:47:15+00:00",
    "categories": [
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2507.19485v1",
    "title": "Creativity as a Human Right: Design Considerations for Computational Creativity Systems",
    "authors": [
      "Alayt Issak"
    ],
    "abstract": "We investigate creativity that is underlined in the Universal Declaration of\nHuman Rights (UDHR) to present design considerations for Computational\nCreativity (CC) systems. We find this declaration to describe creativity in\nsalient aspects and bring to light creativity as a Human Right attributed to\nthe Fourth Generation of such rights. This generation of rights attributes CC\nsystems and the evolving nature of interaction with entities of shared\nintelligence. Our methodology examines five of thirty articles from the UDHR\nand demonstrates each article with actualizations concluding with design\nconsiderations for each. We contribute our findings to ground the relationship\nbetween creativity and CC systems.",
    "pdf_url": "http://arxiv.org/pdf/2507.19485v1",
    "published": "2025-05-16T17:46:37+00:00",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01984v1",
    "title": "Bridging Global Frameworks: Governance Strategies Behind Cisco Common Control Framework v4.0 for Scalable Cloud Compliance",
    "authors": [
      "Nishant Sonkar"
    ],
    "abstract": "CCF v4.0 provides a standard way to ensure that Cisco's cloud products comply\nwith the many quickly evolving requirements worldwide. To cope with increasing\ndemands brought by ISO 27001, SOC 2, NIST, FedRAMP, EU CRA, DORA, and NIS2, CCF\nv4.0 introduces reliable governance by grouping controls using modules mapped\nacross many frameworks. In this document, I discuss the governance structure\ncontrolling the framework's progress, noting how the CAB helped and the\nrelevant steps for mapping and validating controls. Because of this, Cisco now\nuses the same scalable and audit-ready compliance model in all $ 10 B+ of their\ncloud offerings.",
    "pdf_url": "http://arxiv.org/pdf/2506.01984v1",
    "published": "2025-05-16T17:46:20+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11482v3",
    "title": "Unsupervised Detection of Distribution Shift in Inverse Problems using Diffusion Models",
    "authors": [
      "Shirin Shoushtari",
      "Edward P. Chandler",
      "Yuanhao Wang",
      "M. Salman Asif",
      "Ulugbek S. Kamilov"
    ],
    "abstract": "Diffusion models are widely used as priors in imaging inverse problems.\nHowever, their performance often degrades under distribution shifts between the\ntraining and test-time images. Existing methods for identifying and quantifying\ndistribution shifts typically require access to clean test images, which are\nalmost never available while solving inverse problems (at test time). We\npropose a fully unsupervised metric for estimating distribution shifts using\nonly indirect (corrupted) measurements and score functions from diffusion\nmodels trained on different datasets. We theoretically show that this metric\nestimates the KL divergence between the training and test image distributions.\nEmpirically, we show that our score-based metric, using only corrupted\nmeasurements, closely approximates the KL divergence computed from clean\nimages. Motivated by this result, we show that aligning the out-of-distribution\nscore with the in-distribution score -- using only corrupted measurements --\nreduces the KL divergence and leads to improved reconstruction quality across\nmultiple inverse problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11482v3",
    "published": "2025-05-16T17:44:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11481v1",
    "title": "MOSAAIC: Managing Optimization towards Shared Autonomy, Authority, and Initiative in Co-creation",
    "authors": [
      "Alayt Issak",
      "Jeba Rezwana",
      "Casper Harteveld"
    ],
    "abstract": "Striking the appropriate balance between humans and co-creative AI is an open\nresearch question in computational creativity. Co-creativity, a form of hybrid\nintelligence where both humans and AI take action proactively, is a process\nthat leads to shared creative artifacts and ideas. Achieving a balanced dynamic\nin co-creativity requires characterizing control and identifying strategies to\ndistribute control between humans and AI. We define control as the power to\ndetermine, initiate, and direct the process of co-creation. Informed by a\nsystematic literature review of 172 full-length papers, we introduce MOSAAIC\n(Managing Optimization towards Shared Autonomy, Authority, and Initiative in\nCo-creation), a novel framework for characterizing and balancing control in\nco-creation. MOSAAIC identifies three key dimensions of control: autonomy,\ninitiative, and authority. We supplement our framework with control\noptimization strategies in co-creation. To demonstrate MOSAAIC's applicability,\nwe analyze the distribution of control in six existing co-creative AI case\nstudies and present the implications of using this framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.11481v1",
    "published": "2025-05-16T17:41:44+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11480v1",
    "title": "Improving Assembly Code Performance with Large Language Models via Reinforcement Learning",
    "authors": [
      "Anjiang Wei",
      "Tarun Suresh",
      "Huanmi Tan",
      "Yinglun Xu",
      "Gagandeep Singh",
      "Ke Wang",
      "Alex Aiken"
    ],
    "abstract": "Large language models (LLMs) have demonstrated strong performance across a\nwide range of programming tasks, yet their potential for code optimization\nremains underexplored. This work investigates whether LLMs can optimize the\nperformance of assembly code, where fine-grained control over execution enables\nimprovements that are difficult to express in high-level languages. We present\na reinforcement learning framework that trains LLMs using Proximal Policy\nOptimization (PPO), guided by a reward function that considers both functional\ncorrectness, validated through test cases, and execution performance relative\nto the industry-standard compiler gcc -O3. To support this study, we introduce\na benchmark of 8,072 real-world programs. Our model, Qwen2.5-Coder-7B-PPO,\nachieves 96.0% test pass rates and an average speedup of 1.47x over the gcc -O3\nbaseline, outperforming all 20 other models evaluated, including\nClaude-3.7-sonnet. These results indicate that reinforcement learning can\nunlock the potential of LLMs to serve as effective optimizers for assembly code\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2505.11480v1",
    "published": "2025-05-16T17:40:45+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.PF",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11479v1",
    "title": "Nagata products of bimodules over residuated lattices",
    "authors": [
      "Adam Přenosil",
      "Constantine Tsinakis"
    ],
    "abstract": "We study the (restricted) Nagata product construction, which produces a\npartially ordered semigroup from a bimodule consisting of a partially ordered\nsemigroup acting on a (pointed) join semilattice. A canonical example of such a\nbimodule is given by a residuated lattice acting on itself by division, in\nwhich case the Nagata product coincides with the so-called twist product of the\nresiduated lattice. We show that, given some further structure, a pointed\nbimodule can be reconstructed from its restricted Nagata product. This yields\nan adjunction between the category of cyclic pointed residuated bimodules and a\ncertain category of posemigroups with additional structure, which subsumes\nvarious known adjunctions involving the twist product construction.",
    "pdf_url": "http://arxiv.org/pdf/2505.11479v1",
    "published": "2025-05-16T17:40:33+00:00",
    "categories": [
      "math.LO"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11478v2",
    "title": "Automatic Reward Shaping from Confounded Offline Data",
    "authors": [
      "Mingxuan Li",
      "Junzhe Zhang",
      "Elias Bareinboim"
    ],
    "abstract": "A key task in Artificial Intelligence is learning effective policies for\ncontrolling agents in unknown environments to optimize performance measures.\nOff-policy learning methods, like Q-learning, allow learners to make optimal\ndecisions based on past experiences. This paper studies off-policy learning\nfrom biased data in complex and high-dimensional domains where \\emph{unobserved\nconfounding} cannot be ruled out a priori. Building on the well-celebrated Deep\nQ-Network (DQN), we propose a novel deep reinforcement learning algorithm\nrobust to confounding biases in observed data. Specifically, our algorithm\nattempts to find a safe policy for the worst-case environment compatible with\nthe observations. We apply our method to twelve confounded Atari games, and\nfind that it consistently dominates the standard DQN in all games where the\nobserved input to the behavioral and target policies mismatch and unobserved\nconfounders exist.",
    "pdf_url": "http://arxiv.org/pdf/2505.11478v2",
    "published": "2025-05-16T17:40:01+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.16598v1",
    "title": "How the Shortest and Longest HILDCAAs Shaped Earth Outer Radiation Belt During the Van Allen Probes Era?",
    "authors": [
      "Ayushi Nema",
      "Ankush Bhaskar",
      "Kamlesh N. Pathak",
      "Abhirup Datta"
    ],
    "abstract": "High-intensity long-duration continuous auroral electrojet (AE) activity\n(HILDCAA) events are associated with the enhancement of relativistic electron\nfluxes in the inner magnetosphere. The physical mechanisms underlying this\nenhancement are not well established yet. In this study, we analyze two\ncontrasting HILDCAA events, one representing the shortest and the other the\nlongest duration, using NASA Van Allen Probes observations, which have provided\nunprecedented, unique in-situ observations of the harsh radiation environment\naround the Earth. Detailed spectral and temporal analyses reveal that while\nboth events trigger enhancements in electron flux across multiple energy\nchannels, the shortest event is characterized by rapid, transient increases in\nenergy levels. In contrast, the longest event produced sudden and markedly\nhigher flux variation. The long duration event showed an acceleration of\nelectrons to higher energy as compared to the shorter one. Moreover, a clear\ncorrelation between elevated ULF wave power for the longest event compared to\nthe shortest is observed, apart from chorus waves responsible for relativistic\nelectron acceleration. These findings underscore the importance of considering\nthe duration of events in space weather models and assessment and provide\nvaluable insights into the magnetospheric processes that modulate the\nvariability of the radiation belt during HILDCAA conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.16598v1",
    "published": "2025-05-16T17:39:31+00:00",
    "categories": [
      "physics.space-ph"
    ],
    "primary_category": "physics.space-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11477v1",
    "title": "Fractal geometry predicts dynamic differences in structural and functional connectomes",
    "authors": [
      "Anca Radulescu",
      "Eva Kaslik",
      "Alexandry Fikl",
      "Johan Nakuci",
      "Sarah Muldoon",
      "Michael Anderson"
    ],
    "abstract": "Understanding the intricate architecture of brain networks and its connection\nto brain function is essential for deciphering the underlying principles of\ncognition and disease.\n  While traditional graph-theoretical measures have been widely used to\ncharacterize these networks, they often fail to fully capture the emergent\nproperties of large-scale neural dynamics. Here, we introduce an alternative\napproach to quantify brain networks that is rooted in complex dynamics, fractal\ngeometry, and asymptotic analysis.\n  We apply these concepts to brain connectomes and demonstrate how quadratic\niterations and geometric properties of Mandelbrot-like sets can provide novel\ninsights into structural and functional network dynamics. Our findings reveal\nfundamental distinctions between structural (positive) and functional (signed)\nconnectomes, such as the shift of cusp orientation and the variability in\nequi-M set geometry. Notably, structural connectomes exhibit more robust,\npredictable features, while functional connectomes show increased variability\nfor non-trivial tasks. We further demonstrate that traditional\ngraph-theoretical measures, when applied separately to the positive and\nnegative sub-networks of functional connectomes, fail to fully capture their\ndynamic complexity. Instead, size and shape-based invariants of the equi-M set\neffectively differentiate between rest and emotional task states, which\nhighlights their potential as superior markers of emergent network dynamics.\nThese results suggest that incorporating fractal-based methods into network\nneuroscience provides a powerful tool for understanding how information flows\nin natural systems beyond static connectivity measures, while maintaining their\nsimplicity.",
    "pdf_url": "http://arxiv.org/pdf/2505.11477v1",
    "published": "2025-05-16T17:31:58+00:00",
    "categories": [
      "nlin.CD",
      "q-bio.NC"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2505.11476v1",
    "title": "UMArm: Untethered, Modular, Wearable, Soft Pneumatic Arm",
    "authors": [
      "Runze Zuo",
      "Dong Heon Han",
      "Richard Li",
      "Saima Jamal",
      "Daniel Bruder"
    ],
    "abstract": "Robotic arms are essential to modern industries, however, their adaptability\nto unstructured environments remains limited. Soft robotic arms, particularly\nthose actuated pneumatically, offer greater adaptability in unstructured\nenvironments and enhanced safety for human-robot interaction. However, current\npneumatic soft arms are constrained by limited degrees of freedom, precision,\npayload capacity, and reliance on bulky external pressure regulators. In this\nwork, a novel pneumatically driven rigid-soft hybrid arm, ``UMArm'', is\npresented. The shortcomings of pneumatically actuated soft arms are addressed\nby densely integrating high-force-to-weight-ratio, self-regulated McKibben\nactuators onto a lightweight rigid spine structure. The modified McKibben\nactuators incorporate valves and controllers directly inside, eliminating the\nneed for individual pressure lines and external regulators, significantly\nreducing system weight and complexity. Full untethered operation, high payload\ncapacity, precision, and directionally tunable compliance are achieved by the\nUMArm. Portability is demonstrated through a wearable assistive arm experiment,\nand versatility is showcased by reconfiguring the system into an inchworm\nrobot. The results of this work show that the high-degree-of-freedom,\nexternal-regulator-free pneumatically driven arm systems like the UMArm possess\ngreat potential for real-world unstructured environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.11476v1",
    "published": "2025-05-16T17:31:20+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11475v1",
    "title": "HelpSteer3-Preference: Open Human-Annotated Preference Data across Diverse Tasks and Languages",
    "authors": [
      "Zhilin Wang",
      "Jiaqi Zeng",
      "Olivier Delalleau",
      "Hoo-Chang Shin",
      "Felipe Soares",
      "Alexander Bukharin",
      "Ellie Evans",
      "Yi Dong",
      "Oleksii Kuchaiev"
    ],
    "abstract": "Preference datasets are essential for training general-domain,\ninstruction-following language models with Reinforcement Learning from Human\nFeedback (RLHF). Each subsequent data release raises expectations for future\ndata collection, meaning there is a constant need to advance the quality and\ndiversity of openly available preference data. To address this need, we\nintroduce HelpSteer3-Preference, a permissively licensed (CC-BY-4.0),\nhigh-quality, human-annotated preference dataset comprising of over 40,000\nsamples. These samples span diverse real-world applications of large language\nmodels (LLMs), including tasks relating to STEM, coding and multilingual\nscenarios. Using HelpSteer3-Preference, we train Reward Models (RMs) that\nachieve top performance on RM-Bench (82.4%) and JudgeBench (73.7%). This\nrepresents a substantial improvement (~10% absolute) over the previously\nbest-reported results from existing RMs. We demonstrate HelpSteer3-Preference\ncan also be applied to train Generative RMs and how policy models can be\naligned with RLHF using our RMs. Dataset (CC-BY-4.0):\nhttps://huggingface.co/datasets/nvidia/HelpSteer3#preference",
    "pdf_url": "http://arxiv.org/pdf/2505.11475v1",
    "published": "2025-05-16T17:31:19+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11474v1",
    "title": "REACT: Runtime-Enabled Active Collision-avoidance Technique for Autonomous Driving",
    "authors": [
      "Heye Huang",
      "Hao Cheng",
      "Zhiyuan Zhou",
      "Zijin Wang",
      "Qichao Liu",
      "Xiaopeng Li"
    ],
    "abstract": "Achieving rapid and effective active collision avoidance in dynamic\ninteractive traffic remains a core challenge for autonomous driving. This paper\nproposes REACT (Runtime-Enabled Active Collision-avoidance Technique), a\nclosed-loop framework that integrates risk assessment with active avoidance\ncontrol. By leveraging energy transfer principles and human-vehicle-road\ninteraction modeling, REACT dynamically quantifies runtime risk and constructs\na continuous spatial risk field. The system incorporates physically grounded\nsafety constraints such as directional risk and traffic rules to identify\nhigh-risk zones and generate feasible, interpretable avoidance behaviors. A\nhierarchical warning trigger strategy and lightweight system design enhance\nruntime efficiency while ensuring real-time responsiveness. Evaluations across\nfour representative high-risk scenarios including car-following braking,\ncut-in, rear-approaching, and intersection conflict demonstrate REACT's\ncapability to accurately identify critical risks and execute proactive\navoidance. Its risk estimation aligns closely with human driver cognition\n(i.e., warning lead time < 0.4 s), achieving 100% safe avoidance with zero\nfalse alarms or missed detections. Furthermore, it exhibits superior real-time\nperformance (< 50 ms latency), strong foresight, and generalization. The\nlightweight architecture achieves state-of-the-art accuracy, highlighting its\npotential for real-time deployment in safety-critical autonomous systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11474v1",
    "published": "2025-05-16T17:30:13+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11473v1",
    "title": "Application of the Portable Diagnostic Package to the Wisconsin HTS Axisymmetric Mirror (WHAM)",
    "authors": [
      "Keisuke Fujii",
      "Douglass Endrizzi",
      "Jay K. Anderson",
      "Cary B. Forest",
      "Jonathan Pizzo",
      "Tony Qian",
      "Mason Yu",
      "Theodore M. Biewer"
    ],
    "abstract": "We present an application of the Portable Diagnostic Package (PDP) on the\nWisconsin HTS Axisymmetric Mirror (WHAM), which integrates an optical emission\nspectroscopy (OES) system and an active Thomson scattering (TS) system. Due to\nthe designed portability of our system, we realized the installation of the PDP\nOES and TS measurements on WHAM in $\\sim$6 months. The OES system facilitates a\ncomprehensive impurity line survey and enables flow measurements through the\nDoppler effect observed on impurity lines. Notably, plasma rotation profiles\nwere successfully derived from doubly charged carbon lines. In addition, the TS\nsystem enabled the first measurements of the electron temperature in\ncommissioning plasmas on WHAM. These successes underscore the diagnostic\npackage's potential for advancing experimental plasma studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11473v1",
    "published": "2025-05-16T17:29:55+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11472v1",
    "title": "Magnetostriction and Temperature Dependent Gilbert Damping in Boron Doped Fe$_{80}$Ga$_{20}$ Thin Films",
    "authors": [
      "Zhixin Zhang",
      "Jinho Lim",
      "Haoyang Ni",
      "Jian-Min Zuo",
      "Axel Hoffmann"
    ],
    "abstract": "Magnetic thin films with strong magnetoelastic coupling and low Gilbert\ndamping are key materials for many magnetoelectric devices. Here, we\ninvestigated the effects of boron doping concentration on magnetostriction and\ntemperature dependent Gilbert damping in magnetron sputtered\n(Fe$_{80}$Ga$_{20}$)$_{1-x}$B$_{x}$ films. A crystalline to amorphous\nstructural transition was observed for a boron content near 8% and coincided\nwith a decrease in coercivity from 76 Oe to 3 Oe. A 10% doping concentration is\noptimal for achieving both large magnetostriction of 48.8 ppm and low Gilbert\ndamping of $6 \\times 10^{-3}$. The temperature dependence of the damping shows\nan increase at low temperatures with a peak around 40 K and we associate the\nrelative increase $\\Delta\\alpha/\\alpha_{RT}$ with magnetoelastic contributions\nto the damping, which has a maximum of 55.7% at 8% boron. An increase in the\ninhomogeneous linewidth broadening was observed in the structural transition\nregime at about 8% boron concentration. This study suggests that incorporation\nof glass forming elements, in this case boron, into Fe$_{80}$Ga$_{20}$ is a\npractical pathway for simultaneously achieving enhanced magnetoelastic coupling\nand reduced Gilbert damping.",
    "pdf_url": "http://arxiv.org/pdf/2505.11472v1",
    "published": "2025-05-16T17:28:07+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11471v1",
    "title": "CRISP: Clustering Multi-Vector Representations for Denoising and Pruning",
    "authors": [
      "João Veneroso",
      "Rajesh Jayaram",
      "Jinmeng Rao",
      "Gustavo Hernández Ábrego",
      "Majid Hadian",
      "Daniel Cer"
    ],
    "abstract": "Multi-vector models, such as ColBERT, are a significant advancement in neural\ninformation retrieval (IR), delivering state-of-the-art performance by\nrepresenting queries and documents by multiple contextualized token-level\nembeddings. However, this increased representation size introduces considerable\nstorage and computational overheads which have hindered widespread adoption in\npractice. A common approach to mitigate this overhead is to cluster the model's\nfrozen vectors, but this strategy's effectiveness is fundamentally limited by\nthe intrinsic clusterability of these embeddings. In this work, we introduce\nCRISP (Clustered Representations with Intrinsic Structure Pruning), a novel\nmulti-vector training method which learns inherently clusterable\nrepresentations directly within the end-to-end training process. By integrating\nclustering into the training phase rather than imposing it post-hoc, CRISP\nsignificantly outperforms post-hoc clustering at all representation sizes, as\nwell as other token pruning methods. On the BEIR retrieval benchmarks, CRISP\nachieves a significant rate of ~3x reduction in the number of vectors while\noutperforming the original unpruned model. This indicates that learned\nclustering effectively denoises the model by filtering irrelevant information,\nthereby generating more robust multi-vector representations. With more\naggressive clustering, CRISP achieves an 11x reduction in the number of vectors\nwith only a $3.6\\%$ quality loss.",
    "pdf_url": "http://arxiv.org/pdf/2505.11471v1",
    "published": "2025-05-16T17:26:16+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11470v1",
    "title": "No Gold Standard, No Problem: Reference-Free Evaluation of Taxonomies",
    "authors": [
      "Pascal Wullschleger",
      "Majid Zarharan",
      "Donnacha Daly",
      "Marc Pouly",
      "Jennifer Foster"
    ],
    "abstract": "We introduce two reference-free metrics for quality evaluation of taxonomies.\nThe first metric evaluates robustness by calculating the correlation between\nsemantic and taxonomic similarity, covering a type of error not handled by\nexisting metrics. The second uses Natural Language Inference to assess logical\nadequacy. Both metrics are tested on five taxonomies and are shown to correlate\nwell with F1 against gold-standard taxonomies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11470v1",
    "published": "2025-05-16T17:25:40+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11469v1",
    "title": "A central limit theorem for a generalization of the Ewens measure to random tuples of commuting permutations",
    "authors": [
      "Abdelmalek Abdesselam",
      "Shannon Starr"
    ],
    "abstract": "We prove a central limit theorem (CLT) for the number of joint orbits of\nrandom tuples of commuting permutations. In the uniform sampling case this\ngeneralizes the classic CLT of Goncharov for the number of cycles of a single\nrandom permutation. We also consider the case where tuples are weighted by a\nfactor other than one, per joint orbit. We view this as an analogue of the\nEwens measure, for tuples of commuting permutations, where our CLT generalizes\nthe CLT by Hansen. Our proof uses saddle point analysis, in a context related\nto the Hardy-Ramanujan asymptotics and the theorem of Meinardus, but concerns a\nmultiple pole situation. The proof is written in a self-contained manner, and\nhopefully in a manner accessible to a wider audience. We also indicate several\nopen directions of further study related to probability, combinatorics, number\ntheory, an elusive theory of random commuting matrices, and perhaps also\ngeometric group theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.11469v1",
    "published": "2025-05-16T17:24:00+00:00",
    "categories": [
      "math.PR",
      "math.CO",
      "math.NT",
      "60F05, 05A16, 11P82, 60B20"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11468v1",
    "title": "PSDiffusion: Harmonized Multi-Layer Image Generation via Layout and Appearance Alignment",
    "authors": [
      "Dingbang Huang",
      "Wenbo Li",
      "Yifei Zhao",
      "Xinyu Pan",
      "Yanhong Zeng",
      "Bo Dai"
    ],
    "abstract": "Diffusion models have made remarkable advancements in generating high-quality\nimages from textual descriptions. Recent works like LayerDiffuse have extended\nthe previous single-layer, unified image generation paradigm to transparent\nimage layer generation. However, existing multi-layer generation methods fail\nto handle the interactions among multiple layers such as rational global\nlayout, physics-plausible contacts and visual effects like shadows and\nreflections while maintaining high alpha quality. To solve this problem, we\npropose PSDiffusion, a unified diffusion framework for simultaneous multi-layer\ntext-to-image generation. Our model can automatically generate multi-layer\nimages with one RGB background and multiple RGBA foregrounds through a single\nfeed-forward process. Unlike existing methods that combine multiple tools for\npost-decomposition or generate layers sequentially and separately, our method\nintroduces a global-layer interactive mechanism that generates layered-images\nconcurrently and collaboratively, ensuring not only high quality and\ncompleteness for each layer, but also spatial and visual interactions among\nlayers for global coherence.",
    "pdf_url": "http://arxiv.org/pdf/2505.11468v1",
    "published": "2025-05-16T17:23:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11467v1",
    "title": "Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views",
    "authors": [
      "Abhishek Kashyap",
      "Henrik Andreasson",
      "Todor Stoyanov"
    ],
    "abstract": "Vision based robot manipulation uses cameras to capture one or more images of\na scene containing the objects to be manipulated. Taking multiple images can\nhelp if any object is occluded from one viewpoint but more visible from another\nviewpoint. However, the camera has to be moved to a sequence of suitable\npositions for capturing multiple images, which requires time and may not always\nbe possible, due to reachability constraints. So while additional images can\nproduce more accurate grasp poses due to the extra information available, the\ntime-cost goes up with the number of additional views sampled. Scene\nrepresentations like Gaussian Splatting are capable of rendering accurate\nphotorealistic virtual images from user-specified novel viewpoints. In this\nwork, we show initial results which indicate that novel view synthesis can\nprovide additional context in generating grasp poses. Our experiments on the\nGraspnet-1billion dataset show that novel views contributed force-closure\ngrasps in addition to the force-closure grasps obtained from sparsely sampled\nreal views while also improving grasp coverage. In the future we hope this work\ncan be extended to improve grasp extraction from radiance fields constructed\nwith a single input image, using for example diffusion models or generalizable\nradiance fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.11467v1",
    "published": "2025-05-16T17:23:09+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11583v1",
    "title": "Scaling an ISO Compliance Practice: Strategic Insights from Building a \\$1m+ Cybersecurity Certification Line",
    "authors": [
      "Nishant Sonkar"
    ],
    "abstract": "The rapid exponential growth in cloud-first business models and tightened\nglobal data protection regulations have led to the exponential increase in the\nlevel of importance of ISO certifications, especially ISO/IEC 27001, 27017, and\n27018, as strategic imperative propositions for organizations wanting to build\ntrust, ensure compliance, and achieve a competitive advantage. This article\ndescribes a case study of a successful design, implementation, and scaling of a\ncybersecurity certification practice in Armanino LLP, a pioneering US\naccounting and consulting firm. In reaction to increasing client desires for\nformalized information security frameworks, I founded an industry practice from\nconception through implementation to aid mid-market and high-growth technology\nfirms. During one year, the initiative brought in over \\$1 million in new\nservice revenue, expanded our portfolio of cybersecurity clients by 150%, and\nproduced more than 20 successful ISO certifications on various verticals such\nas SaaS, healthcare, and fintech. Based on the strategic wisdom and operational\nstrategy, this paper outlines the technical architecture of the ISO service\nline from modular audit templates to certification readiness kits, from\nstakeholder enablement to integration with SOC 2 and CIS controls. The approach\ngave value to repeatability, speed, and assurance, thus making Armanino a\nreputable certification body. The lessons drawn out provide us with a flexible\ntemplate that can be utilized by firms wishing to build strong compliance\nprograms that can be tailored to address changing digital risk terrains. This\nwork adds to the increasing knowledge about audit scalability, cybersecurity\ncompliance, and ISO standardisation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11583v1",
    "published": "2025-05-16T17:21:55+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11466v1",
    "title": "A comprehensive exploration of interaction networks reveals a connection between entanglement and network structure",
    "authors": [
      "Yoshiaki Horiike",
      "Yuki Kawaguchi"
    ],
    "abstract": "Quantum many-body systems are typically studied assuming translational\nsymmetry in the interaction network. Recent experimental advances in various\nplatforms for quantum simulators have enabled the realization of irregular\ninteraction networks, which are intractable to implement with conventional\ncrystal lattices. Another hallmark of these advances is the ability to observe\nthe time-dependent behaviour of quantum many-body systems. However, the\nrelationship between irregular interaction networks and quantum many-body\ndynamics remains poorly understood. Here, we investigate the connection between\nthe structure of the interaction network and the eigenstate entanglement of the\nquantum Ising model by exploring all possible interaction networks up to seven\nspins. We find that the eigenstate entanglement depends on the structure of the\nHilbert space diagram, particularly the structure of the equienergy subgraph.\nWe further reveal a correlation linking the structure of the Hilbert space\ndiagram to the number of unconstrained spin pairs. Our results demonstrate that\nthe minimum eigenstate entanglement of the quantum Ising model is governed by\nthe specific structure of the interaction network. We anticipate that our\nfindings provide a starting point for exploring quantum many-body systems with\narbitrary interactions and finite system size. Moreover, our approach may be\napplicable to other quantum many-body systems, such as the Hubbard model.",
    "pdf_url": "http://arxiv.org/pdf/2505.11466v1",
    "published": "2025-05-16T17:21:46+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.quant-gas",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11465v1",
    "title": "The Dilemma Between Euphoria and Freedom in Recommendation Algorithms",
    "authors": [
      "James Brusseau"
    ],
    "abstract": "Today's AI recommendation algorithms produce a human dilemma between euphoria\nand freedom. To elaborate, four ways that recommenders reshape experience are\ndelineated. First, the human experience of convenience is tuned to euphoric\nperfection. Second, a kind of personal authenticity becomes capturable with\nalgorithms and data. Third, a conception of human freedom emerges, one that\npromotes unfamiliar interests for users instead of satisfying those that\nalready exist. Finally, a new human dilemma is posed between two types of\npersonal identity. On one side, there are recommendation algorithms that locate\na user's core preferences, and then reinforce that identity with options\ndesigned to resemble those that have already proved satisfying. The result is\nan algorithmic production of euphoria and authenticity. On the other side,\nthere are recommenders that provoke unfamiliar interests and curiosities. These\nproposals deny the existence of an authentic self and instead promote new\npreferences and experiences. The result is a human freedom of new personal\nidentity.",
    "pdf_url": "http://arxiv.org/pdf/2505.11465v1",
    "published": "2025-05-16T17:19:47+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11464v1",
    "title": "Solving Large-Scale QUBO with Transferred Parameters from Multilevel QAOA of low depth",
    "authors": [
      "Bao G Bach",
      "Filip B. Maciejewski",
      "Ilya Safro"
    ],
    "abstract": "The Quantum Approximate Optimization Algorithm (QAOA) is a promising quantum\napproach for tackling combinatorial optimization problems. However, hardware\nconstraints such as limited scaling and susceptibility to noise pose\nsignificant challenges when applying QAOA to large instances. To overcome these\nlimitations, scalable hybrid multilevel strategies have been proposed. In this\nwork, we propose a fast hybrid multilevel algorithm with QAOA parameterization\nthroughout the multilevel hierarchy and its reinforcement with genetic\nalgorithms, which results in a high-quality, low-depth QAOA solver. Notably, we\npropose parameter transfer from the coarsest level to the finer level, showing\nthat the relaxation-based coarsening preserves the problem structural\ninformation needed for QAOA parametrization. Our strategy improves the\ncoarsening phase and leverages both Quantum Relax \\& Round and genetic\nalgorithms to incorporate $p=1$ QAOA samples effectively. The results highlight\nthe practical potential of multilevel QAOA as a scalable method for\ncombinatorial optimization on near-term quantum devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.11464v1",
    "published": "2025-05-16T17:18:36+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11463v1",
    "title": "How AI Generates Creativity from Inauthenticity",
    "authors": [
      "James Brusseau",
      "Luca Turchet"
    ],
    "abstract": "Artificial creativity is presented as a counter to Benjamin's conception of\nan \"aura\" in art. Where Benjamin sees authenticity as art's critical element,\ngenerative artificial intelligence operates as pure inauthenticity. Two\nelements of purely inauthentic art are described: elusiveness and reflection.\nElusiveness is the inability to find an origin-story for the created artwork,\nand reflection is the ability for perceivers to impose any origin that serves\ntheir own purposes. The paper subsequently argues that these elements widen the\nscope of artistic and creative potential. To illustrate, an example is\ndeveloped around musical improvisation with an artificial intelligence partner.\nFinally, a question is raised about whether the inauthentic creativity of AI in\nart can be extended to human experience and our sense of our identities.",
    "pdf_url": "http://arxiv.org/pdf/2505.11463v1",
    "published": "2025-05-16T17:17:31+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11462v2",
    "title": "Disentangling Reasoning and Knowledge in Medical Large Language Models",
    "authors": [
      "Rahul Thapa",
      "Qingyang Wu",
      "Kevin Wu",
      "Harrison Zhang",
      "Angela Zhang",
      "Eric Wu",
      "Haotian Ye",
      "Suhana Bedi",
      "Nevin Aresh",
      "Joseph Boen",
      "Shriya Reddy",
      "Ben Athiwaratkun",
      "Shuaiwen Leon Song",
      "James Zou"
    ],
    "abstract": "Medical reasoning in large language models (LLMs) aims to emulate clinicians'\ndiagnostic thinking, but current benchmarks such as MedQA-USMLE, MedMCQA, and\nPubMedQA often mix reasoning with factual recall. We address this by separating\n11 biomedical QA benchmarks into reasoning- and knowledge-focused subsets using\na PubMedBERT classifier that reaches 81 percent accuracy, comparable to human\nperformance. Our analysis shows that only 32.8 percent of questions require\ncomplex reasoning. We evaluate biomedical models (HuatuoGPT-o1, MedReason, m1)\nand general-domain models (DeepSeek-R1, o4-mini, Qwen3), finding consistent\ngaps between knowledge and reasoning performance. For example, HuatuoGPT-o1\nscores 56.9 on knowledge but only 44.8 on reasoning. In adversarial tests where\nmodels are misled with incorrect initial reasoning, biomedical models degrade\nsharply, while larger or RL-trained general models show more robustness. To\naddress this, we train BioMed-R1 using fine-tuning and reinforcement learning\non reasoning-heavy examples. It achieves the strongest performance among\nsimilarly sized models. Further gains may come from incorporating clinical case\nreports and training with adversarial and backtracking scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.11462v2",
    "published": "2025-05-16T17:16:27+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11461v2",
    "title": "Signal attenuation enables scalable decentralized multi-agent reinforcement learning over networks",
    "authors": [
      "Wesley A Suttle",
      "Vipul K Sharma",
      "Brian M Sadler"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) methods typically require that\nagents enjoy global state observability, preventing development of\ndecentralized algorithms and limiting scalability. Recent work has shown that,\nunder assumptions on decaying inter-agent influence, global observability can\nbe replaced by local neighborhood observability at each agent, enabling\ndecentralization and scalability. Real-world applications enjoying such decay\nproperties remain underexplored, however, despite the fact that signal power\ndecay, or signal attenuation, due to path loss is an intrinsic feature of many\nproblems in wireless communications and radar networks. In this paper, we show\nthat signal attenuation enables decentralization in MARL by considering the\nillustrative special case of performing power allocation for target detection\nin a radar network. To achieve this, we propose two new constrained multi-agent\nMarkov decision process formulations of this power allocation problem, derive\nlocal neighborhood approximations for global value function and policy gradient\nestimates and establish corresponding error bounds, and develop decentralized\nsaddle point policy gradient algorithms for solving the proposed problems. Our\napproach, though oriented towards the specific radar network problem we\nconsider, provides a useful model for extensions to additional problems in\nwireless communications and radar networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11461v2",
    "published": "2025-05-16T17:14:37+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11460v2",
    "title": "Mechanistic inference of stochastic gene expression from structured single-cell data",
    "authors": [
      "Christopher E. Miles"
    ],
    "abstract": "Single-cell gene expression measurements encode variability spanning\nmolecular noise, cell-to-cell heterogeneity, and technical artifacts.\nMechanistic stochastic models provide powerful approaches to disentangle these\nsources, yet inferring underlying dynamics from standard snapshot sequencing\ndata faces fundamental identifiability limitations. This review focuses on how\nstructured datasets with temporal, spatial, or multimodal features offer\nconstraints to resolve these ambiguities, but demand more sophisticated models\nand inference strategies, including machine-learning techniques with inherent\ntradeoffs. We highlight recent progress in the judicious integration of\nstructured single-cell data, stochastic model development, and innovative\ninference strategies to extract predictive, gene-level insights. These advances\nlay the foundation for scaling mechanistic inference upward to regulatory\nnetworks and multicellular tissues.",
    "pdf_url": "http://arxiv.org/pdf/2505.11460v2",
    "published": "2025-05-16T17:14:31+00:00",
    "categories": [
      "q-bio.QM",
      "stat.AP"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.11459v1",
    "title": "ProxyPrompt: Securing System Prompts against Prompt Extraction Attacks",
    "authors": [
      "Zhixiong Zhuang",
      "Maria-Irina Nicolae",
      "Hui-Po Wang",
      "Mario Fritz"
    ],
    "abstract": "The integration of large language models (LLMs) into a wide range of\napplications has highlighted the critical role of well-crafted system prompts,\nwhich require extensive testing and domain expertise. These prompts enhance\ntask performance but may also encode sensitive information and filtering\ncriteria, posing security risks if exposed. Recent research shows that system\nprompts are vulnerable to extraction attacks, while existing defenses are\neither easily bypassed or require constant updates to address new threats. In\nthis work, we introduce ProxyPrompt, a novel defense mechanism that prevents\nprompt leakage by replacing the original prompt with a proxy. This proxy\nmaintains the original task's utility while obfuscating the extracted prompt,\nensuring attackers cannot reproduce the task or access sensitive information.\nComprehensive evaluations on 264 LLM and system prompt pairs show that\nProxyPrompt protects 94.70% of prompts from extraction attacks, outperforming\nthe next-best defense, which only achieves 42.80%.",
    "pdf_url": "http://arxiv.org/pdf/2505.11459v1",
    "published": "2025-05-16T17:13:45+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11458v1",
    "title": "The Dublin Lens: A Cc=1.0 mm Objective Lens Intended for CryoEM at 100 keV",
    "authors": [
      "Germano Motta Alves",
      "Theo Andrews",
      "Patrick McBean",
      "Torquil Wells",
      "Mohamed M. El-Gomati",
      "Stephan Burkhalter",
      "Clemens Schulze-Briese",
      "Pietro Zambon",
      "Greg McMullan",
      "Richard Henderson",
      "Christopher J. Russo",
      "Lewys Jones"
    ],
    "abstract": "We have designed, fabricated and tested a lens with chromatic aberration\ncoefficient (Cc) of 1.0 mm, a 4.0 mm pole-gap and 2.0 mm bore that is wide\nenough to accommodate an anti-contamination system and an objective aperture.\nThis lens extends the temporal-coherence envelope of the electron microscope\nbeyond 2 Angstrom, using a low-cost Schottky FEG. We hope that this lens design\ncan be used to improve all 100 keV electron microscopes designed for\nsingle-particle electron cryomicroscopy (cryoEM).",
    "pdf_url": "http://arxiv.org/pdf/2505.11458v1",
    "published": "2025-05-16T17:13:04+00:00",
    "categories": [
      "physics.ins-det",
      "physics.app-ph",
      "physics.optics"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.11457v2",
    "title": "Noise sensitivity of crossings for high temperature Ising model",
    "authors": [
      "Vincent Tassion",
      "Hugo Vanneuville"
    ],
    "abstract": "Consider the event that there is a $+$ crossing from left to right in a box\nfor the Ising model on the triangular lattice. We show that this event is noise\nsensitive under Glauber dynamics $t \\mapsto \\sigma_t$ in the subcritical regime\n$\\beta<\\beta_c$. We rely on the non-spectral approach from our previous work\n[TV23]. An important aspect in this more general setup is the study of the pair\n$(\\sigma_0,\\sigma_t)$ and in particular the establishment of properties such as\nfinite-energy and spatial mixing.",
    "pdf_url": "http://arxiv.org/pdf/2505.11457v2",
    "published": "2025-05-16T17:11:08+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11456v2",
    "title": "Unsolvability and Beyond in Many-To-Many Non-Bipartite Stable Matching",
    "authors": [
      "Frederik Glitzner",
      "David Manlove"
    ],
    "abstract": "We study the Stable Fixtures problem, a many-to-many generalisation of the\nclassical non-bipartite Stable Roommates matching problem. Building on the\nfoundational work of Tan on stable partitions, we extend his results to this\nsignificantly more general setting and develop a rich framework for\nunderstanding stable structures in many-to-many contexts. Our main\ncontribution, the notion of a generalised stable partition (GSP), not only\ncharacterises the solution space of this problem, but also serves as a\nversatile tool for reasoning about ordinal preference systems with capacity\nconstraints.\n  We show that a GSP can be computed efficiently and and can provide an elegant\nrepresentation of key aspects of a preference system. Leveraging a connection\nto stable half-matchings, we also establish a non-bipartite analogue of the\nRural Hospitals Theorem for stable half-matchings and GSPs, and connect our\nresults to recent work on near-feasible matchings, providing a simpler\nalgorithm and tighter analysis for this problem.\n  Our work also addresses the computational challenges of finding optimal\nstable half-matchings and GSPs, presenting a flexible integer linear\nprogramming model for various objectives. Beyond theoretical insights, we\nconduct the first empirical analysis of random Stable Fixtures instances,\nuncovering surprising results, such as the impact of capacity functions on the\nsolvability likelihood. Our work not only unifies and extends classical and\nrecent perspectives on stability in non-bipartite stable matching but also\nestablishes new tools, techniques, and directions for advancing the study of\nstable matchings and their applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.11456v2",
    "published": "2025-05-16T17:10:44+00:00",
    "categories": [
      "cs.DS",
      "cs.GT"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.11455v1",
    "title": "ASRC-SNN: Adaptive Skip Recurrent Connection Spiking Neural Network",
    "authors": [
      "Shang Xu",
      "Jiayu Zhang",
      "Ziming Wang",
      "Runhao Jiang",
      "Rui Yan",
      "Huajin Tang"
    ],
    "abstract": "In recent years, Recurrent Spiking Neural Networks (RSNNs) have shown\npromising potential in long-term temporal modeling. Many studies focus on\nimproving neuron models and also integrate recurrent structures, leveraging\ntheir synergistic effects to improve the long-term temporal modeling\ncapabilities of Spiking Neural Networks (SNNs). However, these studies often\nplace an excessive emphasis on the role of neurons, overlooking the importance\nof analyzing neurons and recurrent structures as an integrated framework. In\nthis work, we consider neurons and recurrent structures as an integrated system\nand conduct a systematic analysis of gradient propagation along the temporal\ndimension, revealing a challenging gradient vanishing problem. To address this\nissue, we propose the Skip Recurrent Connection (SRC) as a replacement for the\nvanilla recurrent structure, effectively mitigating the gradient vanishing\nproblem and enhancing long-term temporal modeling performance. Additionally, we\npropose the Adaptive Skip Recurrent Connection (ASRC), a method that can learn\nthe skip span of skip recurrent connection in each layer of the network.\nExperiments show that replacing the vanilla recurrent structure in RSNN with\nSRC significantly improves the model's performance on temporal benchmark\ndatasets. Moreover, ASRC-SNN outperforms SRC-SNN in terms of temporal modeling\ncapabilities and robustness.",
    "pdf_url": "http://arxiv.org/pdf/2505.11455v1",
    "published": "2025-05-16T17:10:11+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11454v4",
    "title": "HumaniBench: A Human-Centric Framework for Large Multimodal Models Evaluation",
    "authors": [
      "Shaina Raza",
      "Aravind Narayanan",
      "Vahid Reza Khazaie",
      "Ashmal Vayani",
      "Mukund S. Chettiar",
      "Amandeep Singh",
      "Mubarak Shah",
      "Deval Pandya"
    ],
    "abstract": "Large multimodal models (LMMs) have been widely tested on tasks like visual\nquestion answering (VQA), image captioning, and grounding, but lack rigorous\nevaluation for alignment with human-centered (HC) values such as fairness,\nethics, and inclusivity. To address this gap, we introduce\n\\textbf{HumaniBench}, a novel benchmark of 32,000 real-world image-question\npairs and an evaluation suite. Labels are generated via an AI-assisted pipeline\nand validated by experts. HumaniBench assesses LMMs across seven key alignment\nprinciples: fairness, ethics, empathy, inclusivity, reasoning, robustness, and\nmultilinguality, through diverse open-ended and closed-ended VQA tasks.\nGrounded in AI ethics and real-world needs, these principles provide a holistic\nlens for societal impact. Benchmarking results on different LMM shows that\nproprietary models generally lead in reasoning, fairness, and multilinguality,\nwhile open-source models excel in robustness and grounding. Most models\nstruggle to balance accuracy with ethical and inclusive behavior. Techniques\nlike Chain-of-Thought prompting and test-time scaling improve alignment. As the\nfirst benchmark tailored for HC alignment, HumaniBench offers a rigorous\ntestbed to diagnose limitations, and promote responsible LMM development. All\ndata and code are publicly available for reproducibility.\n  Keywords: HumaniBench, vision-language models, responsible AI benchmark, AI\nalignment evaluation, AI ethics assessment, fairness in AI models, visual\nquestion answering (VQA) benchmark, image captioning evaluation, visual\ngrounding tasks, trustworthy AI models, Chain-of-Thought prompting, test-time\nscaling, ethical AI development tools.",
    "pdf_url": "http://arxiv.org/pdf/2505.11454v4",
    "published": "2025-05-16T17:09:44+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11453v1",
    "title": "EMU/GAMA: A new approach to characterising radio luminosity functions",
    "authors": [
      "J. Prathap",
      "A. M. Hopkins",
      "J. Afonso",
      "M. Bilicki",
      "M. Cowley",
      "S. M. Croom",
      "Y. Gordon",
      "S. Phillipps",
      "E. M. Sadler",
      "S. S. Shabala",
      "U. T. Ahmed",
      "S. Amarantidis",
      "M. J. I. Brown",
      "R. Carvajal",
      "D. Leahy",
      "J. R. Marvil",
      "T. Mukherjee",
      "J. Willingham",
      "T. Zafar"
    ],
    "abstract": "This study characterises the radio luminosity functions (RLFs) for SFGs and\nAGN using statistical redshift estimation in the absence of comprehensive\nspectroscopic data. Sensitive radio surveys over large areas detect many\nsources with faint optical and infrared counterparts, for which redshifts and\nspectra are unavailable. This challenges our attempt to understand the\npopulation of radio sources. Statistical tools are often used to model\nparameters (such as redshift) as an alternative to observational data. Using\nthe data from GAMA G23 and EMU early science observations, we explore simple\nstatistical techniques to estimate the redshifts in order to measure the RLFs\nof the G23 radio sources as a whole and for SFGs and AGN separately. Redshifts\nand AGN/SFG classifications are assigned statistically for those radio sources\nwithout spectroscopic data. The calculated RLFs are compared with existing\nstudies, and the results suggest that the RLFs match remarkably well for low\nredshift galaxies with an optical counterpart. We use a more realistic high\nredshift distribution to model the redshifts of (most likely) high redshift\nradio sources and find that the LFs from our approach match well with measured\nLFs. We also look at strategies to compare the RLFs of radio sources without an\noptical counterpart to existing studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11453v1",
    "published": "2025-05-16T17:09:41+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11452v1",
    "title": "The fate of the Fermi surface coupled to a single-wave-vector cavity mode",
    "authors": [
      "Bernhard Frank",
      "Michele Pini",
      "Johannes Lang",
      "Francesco Piazza"
    ],
    "abstract": "The electromagnetic field of standing-wave or ring cavities induces a\nspatially modulated, infinite-range interaction between atoms in an ultracold\nFermi gas, with a single wavelength comparable to the Fermi length. This\ninteraction has no analog in other systems of itinerant particles and has so\nfar been studied only in the regime where it is attractive at zero distance.\nHere, we fully solve the problem of competing instabilities of the Fermi\nsurface induced by single-wavelength interactions. We find that while the\ndensity-wave (superradiant) instability dominates on the attractive side, it is\nabsent for repulsive interactions, where the competition is instead won by\nnon-superradiant superfluid phases at low temperatures, with Fermion pairs\nforming at both vanishing and finite center-of-mass momentum. Moreover, even in\nthe absence of such symmetry-breaking instabilities, we find the Fermi surface\nto be always nontrivially deformed from an isotropic shape. We estimate this\nfull phenomenology to be within reach of dedicated state-of-the-art\nexperimental setups.",
    "pdf_url": "http://arxiv.org/pdf/2505.11452v1",
    "published": "2025-05-16T17:07:20+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "physics.atom-ph",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.11451v2",
    "title": "Extracting Explainable Dates From Medical Images By Reverse-Engineering UNIX Timestamps",
    "authors": [
      "Lee Harris"
    ],
    "abstract": "Dates often contribute towards highly impactful medical decisions, but it is\nrarely clear how to extract this data. AI has only just begun to be used\ntranscribe such documents, and common methods are either to trust that the\noutput produced by a complex AI model, or to parse the text using regular\nexpressions. Recent work has established that regular expressions are an\nexplainable form of logic, but it is difficult to decompose these into the\ncomponent parts that are required to construct precise UNIX timestamps. First,\nwe test publicly-available regular expressions, and we found that these were\nunable to capture a significant number of our dates. Next, we manually created\neasily-decomposable regular expressions, and we found that these were able to\ndetect the majority of real dates, but also a lot of sequences of text that\nlook like dates. Finally, we used regular expression synthesis to automatically\nidentify regular expressions from the reverse-engineered UNIX timestamps that\nwe created. We find that regular expressions created by regular expression\nsynthesis detect far fewer sequences of text that look like dates than those\nthat were manually created, at the cost of a slight increase to the number of\nmissed dates. Overall, our results show that regular expressions can be created\nthrough regular expression synthesis to identify complex dates and date ranges\nin text transcriptions. To our knowledge, our proposed way of learning\ndeterministic logic by reverse-engineering several many-one mappings and\nfeeding these into a regular expression synthesiser is a new approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.11451v2",
    "published": "2025-05-16T17:07:14+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11450v1",
    "title": "Coherent Spectroscopic Probes of Topology: A Velocity-Gauge Perspective",
    "authors": [
      "Eric R Bittner",
      "Carlos Silva-Acuna"
    ],
    "abstract": "We present a velocity-gauge formalism for computing nonlinear current\nresponse functions in periodic systems and apply it to the Su-Schrieffer-Heeger\n(SSH) model as a minimal topological testbed. By retaining the full minimal\ncoupling Hamiltonian and avoiding the rotating wave approximation, we construct\ngauge-consistent expressions for the linear and third-order current\nsusceptibilities using retarded Green's functions. Our results reveal how\nnonlinear optical spectra encode not only energy-level transitions but also\ninterband phase coherence and topological winding. In the topological phase,\nthe third-order response exhibits characteristic phase inversions and spectral\nasymmetries that are absent in the trivial phase. These features reflect\ngeometric changes in the Bloch eigenstates and highlight the role of virtual\npathways in shaping the nonlinear signal. Our framework offers a robust and\nextensible platform for modeling nonlinear light-matter interactions in\ntopological materials beyond the dipole approximation and the standard\nCoulomb-gauge formulation in molecular spectroscopy.",
    "pdf_url": "http://arxiv.org/pdf/2505.11450v1",
    "published": "2025-05-16T17:07:08+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11582v2",
    "title": "Comparing Lexical and Semantic Vector Search Methods When Classifying Medical Documents",
    "authors": [
      "Lee Harris"
    ],
    "abstract": "Classification is a common AI problem, and vector search is a typical\nsolution. This transforms a given body of text into a numerical representation,\nknown as an embedding, and modern improvements to vector search focus on\noptimising speed and predictive accuracy. This is often achieved through neural\nmethods that aim to learn language semantics. However, our results suggest that\nthese are not always the best solution. Our task was to classify\nrigidly-structured medical documents according to their content, and we found\nthat using off-the-shelf semantic vector search produced slightly worse\npredictive accuracy than creating a bespoke lexical vector search model, and\nthat it required significantly more time to execute. These findings suggest\nthat traditional methods deserve to be contenders in the information retrieval\ntoolkit, despite the prevalence and success of neural models.",
    "pdf_url": "http://arxiv.org/pdf/2505.11582v2",
    "published": "2025-05-16T17:06:35+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11449v1",
    "title": "LLMs unlock new paths to monetizing exploits",
    "authors": [
      "Nicholas Carlini",
      "Milad Nasr",
      "Edoardo Debenedetti",
      "Barry Wang",
      "Christopher A. Choquette-Choo",
      "Daphne Ippolito",
      "Florian Tramèr",
      "Matthew Jagielski"
    ],
    "abstract": "We argue that Large language models (LLMs) will soon alter the economics of\ncyberattacks. Instead of attacking the most commonly used software and\nmonetizing exploits by targeting the lowest common denominator among victims,\nLLMs enable adversaries to launch tailored attacks on a user-by-user basis. On\nthe exploitation front, instead of human attackers manually searching for one\ndifficult-to-identify bug in a product with millions of users, LLMs can find\nthousands of easy-to-identify bugs in products with thousands of users. And on\nthe monetization front, instead of generic ransomware that always performs the\nsame attack (encrypt all your data and request payment to decrypt), an\nLLM-driven ransomware attack could tailor the ransom demand based on the\nparticular content of each exploited device.\n  We show that these two attacks (and several others) are imminently practical\nusing state-of-the-art LLMs. For example, we show that without any human\nintervention, an LLM finds highly sensitive personal information in the Enron\nemail dataset (e.g., an executive having an affair with another employee) that\ncould be used for blackmail. While some of our attacks are still too expensive\nto scale widely today, the incentives to implement these attacks will only\nincrease as LLMs get cheaper. Thus, we argue that LLMs create a need for new\ndefense-in-depth approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.11449v1",
    "published": "2025-05-16T17:05:25+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11448v1",
    "title": "Reconfigurable Integrated Photonic Chips as Dual-Purpose Neuromorphic Accelerators and Physical Unclonable Functions",
    "authors": [
      "George Sarantoglou",
      "Francesco Da Ros",
      "Kostas Sozos",
      "Adonis Bogris",
      "Charis Mesaritakis"
    ],
    "abstract": "In this work, we experimentally validate the dual use of a reconfigurable\nphotonic integrated mesh as a neuromorphic accelerator, targeting signal\nequalization, and as a physical unclonable function offering authentication at\nthe hardware level. The processing node is an optical spectrum slicing\nself-coherent transceiver targeting the mitigation of dispersion impairments of\nan intensity detected QPSK signal, after 25 km of transmission at 32 Gbaud.\nUnavoidable fabrication related imperfections of the nodes, such as waveguide\nroughness, can act as fingerprints of the device, and, during neuromorphic\nprocessing, result in unique weights at the digital back-end during signal\nequalization. Extracted security metrics offer low false positive/negative\nprobability for the generated responses, confirming un-clonability, whereas\nbit-error-ratio for the QPSK equalization task was always below the hardware\nforward error correction limit. The experimental results substantiate the\ncapability of the proposed scheme to simultaneously act as an accelerator and\nas a security token.",
    "pdf_url": "http://arxiv.org/pdf/2505.11448v1",
    "published": "2025-05-16T17:05:15+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.11447v1",
    "title": "Global well-posedness for small data in a 3D temperature-velocity model with Dirichlet boundary noise",
    "authors": [
      "Gianmarco Del Sarto",
      "Marta Lenzi"
    ],
    "abstract": "We analyse a Boussinesq coupled temperature-velocity system on a bounded,\nopen, smooth domain $\\mathcal{D} \\subset \\mathbb{R}^3$. The fluid velocity\n$u^\\varepsilon$ evolves according to the three-dimensional Navier-Stokes\nequations, while the temperature $\\theta^\\varepsilon$ is subject to Dirichlet\nboundary noise of intensity $\\sqrt{\\varepsilon}$. Given a finite time $T>0$,\nunder natural assumptions on the stochastic forcing and for sufficiently small\ninitial data, we show that there exists a unique mild solution $(u^\\varepsilon,\n\\theta^\\varepsilon)$ up to a random stopping time $\\tau^\\varepsilon \\leq T$.\nMoreover, $\\mathbb{P}(\\tau^\\varepsilon = T) \\geq 1 - C \\varepsilon$, and the\nsolution trajectories lie in the optimal regularity class $ (u^\\varepsilon,\n\\theta^\\varepsilon) \\in \\left( H^{1,p}_t(H_x^{-\\tfrac{1}{2} - \\delta}) \\cap\nL^p_t(H_x^{\\tfrac{3}{2} - \\delta}) \\right) \\times C_t(H_x^{-\\tfrac{1}{2} -\n\\delta}) $ for all sufficiently small $\\delta > 0$ and all $p > \\tfrac{2}{1 -\n\\delta}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11447v1",
    "published": "2025-05-16T17:04:28+00:00",
    "categories": [
      "math.PR",
      "60H15, 60H30, 76D03"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11446v3",
    "title": "Polarization Signatures of Quasi-Periodic Oscillations in Simulated Tilted, Truncated Disks",
    "authors": [
      "P. Chris Fragile",
      "Deepika A. Bollimpalli",
      "Jeremy D. Schnittman",
      "Cesare Harvey"
    ],
    "abstract": "We utilize the Monte Carlo radiation transport code, Pandurata, to create\nimages, spectra, polarization maps, and light curves from a set of general\nrelativistic magnetohydrodynamic simulations of tilted, truncated, black hole\naccretion disks. Truncation can have spectral and polarization signatures all\nits own; tilt introduces both inclination and azimuthal dependencies into the\nspectra and polarization; and precession and oscillations of the tilted\naccretion flow inside the truncation radius introduce time dependencies or\nperiodicity to all of this. We use the ray-traced results from our simulations\nto evaluate the feasibility of measuring these effects, particularly in the\ncontext of current and future X-ray polarization observatories. Such detections\ncould greatly improve our understanding of the geometry of accretion disks and\ncoronae in the hard state, the physics of quasi-periodic oscillations (QPOs),\nand how system properties evolve as sources approach the hard-to-soft state\ntransition.",
    "pdf_url": "http://arxiv.org/pdf/2505.11446v3",
    "published": "2025-05-16T17:02:57+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11445v1",
    "title": "GOUHFI: a novel contrast- and resolution-agnostic segmentation tool for Ultra-High Field MRI",
    "authors": [
      "Marc-Antoine Fortin",
      "Anne Louise Kristoffersen",
      "Michael Staff Larsen",
      "Laurent Lamalle",
      "Ruediger Stirnberg",
      "Paal Erik Goa"
    ],
    "abstract": "Recently, Ultra-High Field MRI (UHF-MRI) has become more available and one of\nthe best tools to study the brain. One common step in quantitative neuroimaging\nis the brain segmentation. However, the differences between UHF-MRI and 1.5-3T\nimages are such that the automatic segmentation techniques optimized at these\nfield strengths usually produce unsatisfactory segmentation results for UHF\nimages. It has been particularly challenging to perform quantitative analyses\nas typically done with 1.5-3T data, considerably limiting the potential of\nUHF-MRI. Hence, we propose a novel Deep Learning (DL)-based segmentation\ntechnique called GOUHFI: Generalized and Optimized segmentation tool for\nUltra-High Field Images, designed to segment UHF images of various contrasts\nand resolutions. For training, we used a total of 206 label maps from four\ndatasets acquired at 3T, 7T and 9.4T. In contrast to most DL strategies, we\nused a previously proposed domain randomization approach, where synthetic\nimages generated from the label maps were used for training a 3D U-Net. GOUHFI\nwas tested on seven different datasets and compared to techniques like\nFastSurferVINN and CEREBRUM-7T. GOUHFI was able to the segment six contrasts\nand seven resolutions tested at 3T, 7T and 9.4T. Average Dice-Sorensen\nSimilarity Coefficient (DSC) scores of 0.87, 0.84, 0.91 were computed against\nthe ground truth segmentations at 3T, 7T and 9.4T. Moreover, GOUHFI\ndemonstrated impressive resistance to the typical inhomogeneities observed at\nUHF-MRI, making it a new powerful segmentation tool that allows to apply the\nusual quantitative analysis pipelines also at UHF. Ultimately, GOUHFI is a\npromising new segmentation tool, being the first of its kind proposing a\ncontrast- and resolution-agnostic alternative for UHF-MRI, making it the\nforthcoming alternative for neuroscientists working with UHF-MRI or even lower\nfield strengths.",
    "pdf_url": "http://arxiv.org/pdf/2505.11445v1",
    "published": "2025-05-16T17:01:30+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11444v1",
    "title": "A Generative Framework for Causal Estimation via Importance-Weighted Diffusion Distillation",
    "authors": [
      "Xinran Song",
      "Tianyu Chen",
      "Mingyuan Zhou"
    ],
    "abstract": "Estimating individualized treatment effects from observational data is a\ncentral challenge in causal inference, largely due to covariate imbalance and\nconfounding bias from non-randomized treatment assignment. While inverse\nprobability weighting (IPW) is a well-established solution to this problem, its\nintegration into modern deep learning frameworks remains limited. In this work,\nwe propose Importance-Weighted Diffusion Distillation (IWDD), a novel\ngenerative framework that combines the pretraining of diffusion models with\nimportance-weighted score distillation to enable accurate and fast causal\nestimation-including potential outcome prediction and treatment effect\nestimation. We demonstrate how IPW can be naturally incorporated into the\ndistillation of pretrained diffusion models, and further introduce a\nrandomization-based adjustment that eliminates the need to compute IPW\nexplicitly-thereby simplifying computation and, more importantly, provably\nreducing the variance of gradient estimates. Empirical results show that IWDD\nachieves state-of-the-art out-of-sample prediction performance, with the\nhighest win rates compared to other baselines, significantly improving causal\nestimation and supporting the development of individualized treatment\nstrategies. We will release our PyTorch code for reproducibility and future\nresearch.",
    "pdf_url": "http://arxiv.org/pdf/2505.11444v1",
    "published": "2025-05-16T17:00:52+00:00",
    "categories": [
      "cs.LG",
      "stat.AP",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11443v1",
    "title": "Combined Experimental and Computational Analysis of Lithium Diffusion in Isostructural Pair VNb9O25 and VTa9O25",
    "authors": [
      "Manish Kumar",
      "Md Abdullah Al Muhit",
      "CJ Sturgill",
      "Nima Karimitari",
      "John T. Barber",
      "Hunter Tisdale",
      "Morgan Stefik",
      "Hans-Conrad zur Loye",
      "Christopher Sutton"
    ],
    "abstract": "Wadsley-Roth crystal structures are an attractive class of materials for\nbatteries because lithium diffusion is facilitated by the ReO3-like block\nstructure with electron transport enabled by edge-sharing along shear planes.\nHowever, clear structure-property relationships remain limited, making it\nchallenging to develop improved materials. Here, the first lithiation of\nVTa9O25 is reported, enabling a direct isostructural comparison with the\nbetter-known VNb9O25. These materials have similar unit cell volumes and atomic\nradii yet exhibit different voltage windows, C-rate dependent capacities, and\ntransport metrics. Time-dependent overpotential analysis reveals ionic\ndiffusion as the primary bottleneck to high rate-performance in both cases,\nhowever, the lithium diffusivity for VNb9O25 was an order of magnitude faster\nthan that for VTa9O25. These experimental trends aligned well with density\nfunctional theory calculations combined with molecular dynamics that show a\nfactor of six faster diffusion in VNb9O25. Nudged elastic band calculations of\nthe probable hopping pathways indicate that VNb9O25 consistently exhibits a\nlower activation barrier for lithium diffusion. Bader charge analysis reveals a\nlarger net charge on Li in VNb9O25 due to the higher electronegativity of Nb\nwhich stabilizes the transition state and lowers the barrier. This\nstabilization arises from the stronger Coulombic interaction between Li and its\ncoordinated O-environment. These materials behave similarly upon lithiation\nwherein the lattice vectors (corresponding to the block plane) increase until\nabout 50% lithiation and then decrease. However, the electronic structure\ndiffers, indicating that VNb9O25 undergoes a insulator to metal transition at a\nlower state of charge compared with VTa9O25. Overall, this work establishes the\nrole of the cation (Nb or Ta) on the electronic and transport properties during\nlithiation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11443v1",
    "published": "2025-05-16T17:00:40+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11442v1",
    "title": "Neural-Network Correlation Functions for Light Nuclei with Chiral Two- and Three-Body Interactions",
    "authors": [
      "Pengsheng Wen",
      "Alexandros Gezerlis",
      "Jeremy W. Holt"
    ],
    "abstract": "Finding high-quality trial wave functions for quantum Monte Carlo\ncalculations of light nuclei requires a strong intuition for modeling the\ninterparticle correlations as well as large computational resources for\nexploring the space of variational parameters. Moreover, for systems with\nthree-body interactions, the wave function should account for many-body effects\nbeyond simple pairwise correlations. In this work, we design neural networks\nthat efficiently incorporate these factors to generate expressive wave function\nAnsatzes for light nuclei using variational Monte Carlo. Our neural-network\napproach for A=3 nuclei can capture, already at the level of variational Monte\nCarlo, the overwhelming majority of the ground-state energy estimated by\nGreen's Function Monte Carlo (GFMC). We can find a 91% improvement over\nstandard variational Monte Carlo and achieve a ground state energy within 0.45%\nof the GFMC result for 3H using the softest chiral interaction with neural\nnetworks. The result indicates the potential of neural networks to construct\neffective trial wave functions for quantum Monte Carlo calculations.",
    "pdf_url": "http://arxiv.org/pdf/2505.11442v1",
    "published": "2025-05-16T16:59:20+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11441v4",
    "title": "Is Compression Really Linear with Code Intelligence?",
    "authors": [
      "Shijie Xuyang",
      "Xianzhen Luo",
      "Tianhao Cheng",
      "Zheng Chu",
      "Houyi Li",
      "ziqi wang",
      "Siming Huang",
      "Qingfu Zhu",
      "Qiufeng Wang",
      "Xiangyu Zhang",
      "Shuigeng Zhou",
      "Wanxiang Che"
    ],
    "abstract": "Understanding the relationship between data compression and the capabilities\nof Large Language Models (LLMs) is crucial, especially in specialized domains\nlike code intelligence. Prior work posited a linear relationship between\ncompression and general intelligence. However, it overlooked the multifaceted\nnature of code that encompasses diverse programming languages and tasks, and\nstruggled with fair evaluation of modern Code LLMs. We address this by\nevaluating a diverse array of open-source Code LLMs on comprehensive\nmulti-language, multi-task code benchmarks. To address the challenge of\nefficient and fair evaluation of pre-trained LLMs' code intelligence, we\nintroduce \\textit{Format Annealing}, a lightweight, transparent training\nmethodology designed to assess the intrinsic capabilities of these pre-trained\nmodels equitably. Compression efficacy, measured as bits-per-character (BPC),\nis determined using a novel, large-scale, and previously unseen code validation\nset derived from GitHub. Our empirical results reveal a fundamental logarithmic\nrelationship between measured code intelligence and BPC. This finding refines\nprior hypotheses of linearity, which we suggest are likely observations of the\nlogarithmic curve's tail under specific, limited conditions. Our work provides\na more nuanced understanding of compression's role in developing code\nintelligence and contributes a robust evaluation framework in the code domain.",
    "pdf_url": "http://arxiv.org/pdf/2505.11441v4",
    "published": "2025-05-16T16:59:14+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11440v1",
    "title": "FUOr-Aur 0544+3330: A New YSO Outburst in the Outskirts of Auriga OB1, Viewed Face-On",
    "authors": [
      "Lynne A. Hillenbrand",
      "Adolfo S. Carvalho",
      "Dan Stern",
      "Michael Connelley",
      "Facundo Pérez Paolino",
      "Ahaan Shetty",
      "Zachariah Milby",
      "Howard Isaacson"
    ],
    "abstract": "We present a newly appreciated FU Ori outburst event that began in 2019 and\nreached a peak in early 2021. Suspected young stellar object WISE\nJ054452.25+333009.6 experienced substantial brightening, in excess of $-5$ mag\nat optical wavelengths and $-2.5$ mag at mid-infrared wavelengths. The time\nfrom near-quiescence to peak brightness was approximately 24 months. Optical\nand near-infrared spectra confirm that the outbursting source (hereby\ndesignated FUOr-Aur 0544+3330) shows all the hallmarks of the FU Ori class,\nincluding the Li I indicator of stellar youth. The mix of ionized and neutral\natomic lines, alongside prominent molecular absorption features, is consistent\nwith the expected change in spectral type from earlier in the optical to\nlater-type in the near-infrared. The closest analog among well-studied FU Ori\nobjects is V1515 Cyg. Both sources have unusually narrow-lined absorption\nspectra that can be explained by a face-on disk orientation, such that\ndisk-broadening is minimized and wind-induced blueshift (in e.g. H$\\alpha$,\nNaD, Ca II) is maximized. Both the optical through infrared spectral energy\ndistribution and high-resolution spectrum are well-fit by a pure-accretion disk\nmodel. Adopting a distance of $d=1.5$ kpc, the accretion and central star\nparameters are: $\\dot{M} = 10^{-5.48}$ $M_\\odot$ yr$^{-1}$, $M_* = 0.17 \\\nM_\\odot$, and $R_\\mathrm{inner} = 1.04 \\ R_\\odot$. Other fitted values are disk\ninclination $i=5.9$ deg and source extinction $A_V=1.83$ mag. These parameters\nyield accretion luminosity $L_\\mathrm{acc} = 8.4\\ L_\\odot$ and maximum disk\ntemperature $T_{\\rm{max}} = 6218$ K.",
    "pdf_url": "http://arxiv.org/pdf/2505.11440v1",
    "published": "2025-05-16T16:58:40+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11439v1",
    "title": "SurgPose: Generalisable Surgical Instrument Pose Estimation using Zero-Shot Learning and Stereo Vision",
    "authors": [
      "Utsav Rai",
      "Haozheng Xu",
      "Stamatia Giannarou"
    ],
    "abstract": "Accurate pose estimation of surgical tools in Robot-assisted Minimally\nInvasive Surgery (RMIS) is essential for surgical navigation and robot control.\nWhile traditional marker-based methods offer accuracy, they face challenges\nwith occlusions, reflections, and tool-specific designs. Similarly, supervised\nlearning methods require extensive training on annotated datasets, limiting\ntheir adaptability to new tools. Despite their success in other domains,\nzero-shot pose estimation models remain unexplored in RMIS for pose estimation\nof surgical instruments, creating a gap in generalising to unseen surgical\ntools. This paper presents a novel 6 Degrees of Freedom (DoF) pose estimation\npipeline for surgical instruments, leveraging state-of-the-art zero-shot RGB-D\nmodels like the FoundationPose and SAM-6D. We advanced these models by\nincorporating vision-based depth estimation using the RAFT-Stereo method, for\nrobust depth estimation in reflective and textureless environments.\nAdditionally, we enhanced SAM-6D by replacing its instance segmentation module,\nSegment Anything Model (SAM), with a fine-tuned Mask R-CNN, significantly\nboosting segmentation accuracy in occluded and complex conditions. Extensive\nvalidation reveals that our enhanced SAM-6D surpasses FoundationPose in\nzero-shot pose estimation of unseen surgical instruments, setting a new\nbenchmark for zero-shot RGB-D pose estimation in RMIS. This work enhances the\ngeneralisability of pose estimation for unseen objects and pioneers the\napplication of RGB-D zero-shot methods in RMIS.",
    "pdf_url": "http://arxiv.org/pdf/2505.11439v1",
    "published": "2025-05-16T16:58:03+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11438v2",
    "title": "Inferring correlated distributions: boosted top jets",
    "authors": [
      "Ezequiel Alvarez",
      "Manuel Szewc",
      "Alejandro Szynkman",
      "Santiago Tanco",
      "Tatiana Tarutina"
    ],
    "abstract": "Improving the understanding of signal and background distributions in\nsignal-region is a valuable key to enhance any analysis in collider physics.\nThis is usually a difficult task because -- among others -- signal and\nbackgrounds are hard to discriminate in signal-region, simulations may reach a\nlimit of reliability if they need to model non-perturbative QCD, and\ndistributions are multi-dimensional and many times may be correlated within\neach class. Bayesian density estimation is a technique that leverages prior\nknowledge and data correlations to effectively extract information from data in\nsignal-region. In this work we extend previous works on data-driven mixture\nmodels for meaningful unsupervised signal extraction in collider physics to\nincorporate correlations between features. Using a standard dataset of top and\nQCD jets, we show how simulators, despite having an expected bias, can be used\nto inject sufficient inductive nuance into an inference model in terms of\npriors to then be corrected by data and estimate the true correlated\ndistributions between features within each class. We compare the model with and\nwithout correlations to show how the signal extraction is sensitive to their\ninclusion and we quantify the improvement due to the inclusion of correlations\nusing both supervised and unsupervised metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.11438v2",
    "published": "2025-05-16T16:57:42+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11437v3",
    "title": "The Role of Connection Density in an Adaptive Network with Chaotic Units",
    "authors": [
      "Ramiro Plüss",
      "Pablo Martín Gleiser"
    ],
    "abstract": "We investigate the role of connection density in an adaptive network model of\nchaotic units that dynamically rewire based on their internal states and local\ncoherence. By systematically varying the network's connectivity density, we\nuncover distinct dynamical regimes and structural transitions, revealing\nmechanisms of spontaneous modularity, dynamical segregation, and integration.\nWe find that at higher densities, the network exhibits both local clustering\nand global synchrony. Additionally, we observe that low-density networks tend\nto fragment into desynchronized clusters, while high-density networks converge\nto synchronized states combining strong global integration with persistent\nmodular segregation. Inspired by neural architectures, our model provides a\ngeneral framework for understanding how simple microscopic rules can give rise\nto complex emergent behaviors in dynamical networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11437v3",
    "published": "2025-05-16T16:57:17+00:00",
    "categories": [
      "nlin.AO",
      "05C82, 37N25, 68U20, 92C20",
      "G.2.2; I.2.6; I.6.3; F.1.1"
    ],
    "primary_category": "nlin.AO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11436v2",
    "title": "GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art",
    "authors": [
      "Yiming Lei",
      "Chenkai Zhang",
      "Zeming Liu",
      "Haitao Leng",
      "Shaoguo Liu",
      "Tingting Gao",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "abstract": "Video Comment Art enhances user engagement by providing creative content that\nconveys humor, satire, or emotional resonance, requiring a nuanced and\ncomprehensive grasp of cultural and contextual subtleties. Although Multimodal\nLarge Language Models (MLLMs) and Chain-of-Thought (CoT) have demonstrated\nstrong reasoning abilities in STEM tasks (e.g. mathematics and coding), they\nstill struggle to generate creative expressions such as resonant jokes and\ninsightful satire. Moreover, existing benchmarks are constrained by their\nlimited modalities and insufficient categories, hindering the exploration of\ncomprehensive creativity in video-based Comment Art creation. To address these\nlimitations, we introduce GODBench, a novel benchmark that integrates video and\ntext modalities to systematically evaluate MLLMs' abilities to compose Comment\nArt. Furthermore, inspired by the propagation patterns of waves in physics, we\npropose Ripple of Thought (RoT), a multi-step reasoning framework designed to\nenhance the creativity of MLLMs. Extensive experiments reveal that existing\nMLLMs and CoT methods still face significant challenges in understanding and\ngenerating creative video comments. In contrast, RoT provides an effective\napproach to improve creative composing, highlighting its potential to drive\nmeaningful advancements in MLLM-based creativity. GODBench is publicly\navailable at https://github.com/stan-lei/GODBench-ACL2025.",
    "pdf_url": "http://arxiv.org/pdf/2505.11436v2",
    "published": "2025-05-16T16:56:40+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11435v1",
    "title": "General superconvergence for kernel-based approximation",
    "authors": [
      "Toni Karvonen",
      "Gabriele Santin",
      "Tizian Wenzel"
    ],
    "abstract": "Kernel interpolation is a fundamental technique for approximating functions\nfrom scattered data, with a well-understood convergence theory when\ninterpolating elements of a reproducing kernel Hilbert space. Beyond this\nclassical setting, research has focused on two regimes: misspecified\ninterpolation, where the kernel smoothness exceeds that of the target function,\nand superconvergence, where the target is smoother than the Hilbert space.\n  This work addresses the latter, where smoother target functions yield\nimproved convergence rates, and extends existing results by characterizing\nsuperconvergence for projections in general Hilbert spaces. We show that\nfunctions lying in ranges of certain operators, including adjoint of\nembeddings, exhibit accelerated convergence, which we extend across\ninterpolation scales between these ranges and the full Hilbert space. In\nparticular, we analyze Mercer operators and embeddings into $L_p$ spaces,\nlinking the images of adjoint operators to Mercer power spaces. Applications to\nSobolev spaces are discussed in detail, highlighting how superconvergence\ndepends critically on boundary conditions. Our findings generalize and refine\nprevious results, offering a broader framework for understanding and exploiting\nsuperconvergence. The results are supported by numerical experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.11435v1",
    "published": "2025-05-16T16:54:34+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11434v1",
    "title": "Controlling the Flow: Stability and Convergence for Stochastic Gradient Descent with Decaying Regularization",
    "authors": [
      "Sebastian Kassing",
      "Simon Weissmann",
      "Leif Döring"
    ],
    "abstract": "The present article studies the minimization of convex, L-smooth functions\ndefined on a separable real Hilbert space. We analyze regularized stochastic\ngradient descent (reg-SGD), a variant of stochastic gradient descent that uses\na Tikhonov regularization with time-dependent, vanishing regularization\nparameter. We prove strong convergence of reg-SGD to the minimum-norm solution\nof the original problem without additional boundedness assumptions. Moreover,\nwe quantify the rate of convergence and optimize the interplay between\nstep-sizes and regularization decay. Our analysis reveals how vanishing\nTikhonov regularization controls the flow of SGD and yields stable learning\ndynamics, offering new insights into the design of iterative algorithms for\nconvex problems, including those that arise in ill-posed inverse problems. We\nvalidate our theoretical findings through numerical experiments on image\nreconstruction and ODE-based inverse problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11434v1",
    "published": "2025-05-16T16:53:49+00:00",
    "categories": [
      "math.OC",
      "math.PR",
      "stat.ML"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11433v1",
    "title": "Neuromorphic Imaging Flow Cytometry combined with Adaptive Recurrent Spiking Neural Networks",
    "authors": [
      "Georgios Moustakas",
      "Ioannis Tsilikas",
      "Adonis Bogris",
      "Charis Mesaritakis"
    ],
    "abstract": "We present an experimental imaging flow cytometer using a 1 {\\mu}s temporal\nresolution event-based CMOS camera, with data processed by adaptive feedforward\nand recurrent spiking neural networks. Our study classifies PMMA particles (12,\n16, 20 {\\mu}m) flowing at 0.7 m/s in a microfluidic channel. Processing of\nexperimental data highlighted that spiking recurrent networks, including LSTM\nand GRU models, achieved 98.4% accuracy by leveraging temporal dependencies.\nAdditionally, adaptation mechanisms in lightweight feedforward spiking networks\nimproved accuracy by 4.3%. This work outlines a technological roadmap for\nneuromorphic-assisted biomedical applications, enhancing classification\nperformance while maintaining low latency and sparsity.",
    "pdf_url": "http://arxiv.org/pdf/2505.11433v1",
    "published": "2025-05-16T16:52:56+00:00",
    "categories": [
      "physics.optics",
      "eess.IV"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.11432v2",
    "title": "MegaScale-MoE: Large-Scale Communication-Efficient Training of Mixture-of-Experts Models in Production",
    "authors": [
      "Chao Jin",
      "Ziheng Jiang",
      "Zhihao Bai",
      "Zheng Zhong",
      "Juncai Liu",
      "Xiang Li",
      "Ningxin Zheng",
      "Xi Wang",
      "Cong Xie",
      "Qi Huang",
      "Wen Heng",
      "Yiyuan Ma",
      "Wenlei Bao",
      "Size Zheng",
      "Yanghua Peng",
      "Haibin Lin",
      "Xuanzhe Liu",
      "Xin Jin",
      "Xin Liu"
    ],
    "abstract": "We present MegaScale-MoE, a production system tailored for the efficient\ntraining of large-scale mixture-of-experts (MoE) models. MoE emerges as a\npromising architecture to scale large language models (LLMs) to unprecedented\nsizes, thereby enhancing model performance. However, existing MoE training\nsystems experience a degradation in training efficiency, exacerbated by the\nescalating scale of MoE models and the continuous evolution of hardware.\n  Recognizing the pivotal role of efficient communication in enhancing MoE\ntraining, MegaScale-MoE customizes communication-efficient parallelism\nstrategies for attention and FFNs in each MoE layer and adopts a holistic\napproach to overlap communication with computation at both inter- and\nintra-operator levels. Additionally, MegaScale-MoE applies communication\ncompression with adjusted communication patterns to lower precision, further\nimproving training efficiency. When training a 352B MoE model on 1,440 NVIDIA\nHopper GPUs, MegaScale-MoE achieves a training throughput of 1.41M tokens/s,\nimproving the efficiency by 1.88$\\times$ compared to Megatron-LM. We share our\noperational experience in accelerating MoE training and hope that by offering\nour insights in system design, this work will motivate future research in MoE\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11432v2",
    "published": "2025-05-16T16:52:16+00:00",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11431v1",
    "title": "Robust Equilibria in Shared Resource Allocation via Strengthening Border's Theorem",
    "authors": [
      "David X. Lin",
      "Siddhartha Banerjee",
      "Giannis Fikioris",
      "Éva Tardos"
    ],
    "abstract": "We consider repeated allocation of a shared resource via a non-monetary\nmechanism, wherein a single item must be allocated to one of multiple agents in\neach round. We assume that each agent has i.i.d. values for the item across\nrounds, and additive utilities. Past work on this problem has proposed\nmechanisms where agents can get one of two kinds of guarantees: $(i)$\n(approximate) Bayes-Nash equilibria via linkage-based mechanisms which need\nextensive knowledge of the value distributions, and $(ii)$ simple\ndistribution-agnostic mechanisms with robust utility guarantees for each\nindividual agent, which are worse than the Nash outcome, but hold irrespective\nof how others behave (including possibly collusive behavior). Recent work has\nhinted at barriers to achieving both simultaneously. Our work however\nestablishes this is not the case, by proposing the first mechanism in which\neach agent has a natural strategy that is both a Bayes-Nash equilibrium and\nalso comes with strong robust guarantees for individual agent utilities.\n  Our mechanism comes out of a surprising connection between the online shared\nresource allocation problem and implementation theory. In particular, we show\nthat establishing robust equilibria in this setting reduces to showing that a\nparticular subset of the Border polytope is non-empty. We establish this via a\nnovel joint Schur-convexity argument. This strengthening of Border's criterion\nfor obtaining a stronger conclusion is of independent technical interest, as it\nmay prove useful in other settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.11431v1",
    "published": "2025-05-16T16:51:13+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11430v2",
    "title": "Computing in a Faulty Congested Clique",
    "authors": [
      "Keren Censor-Hillel",
      "Pedro Soto"
    ],
    "abstract": "We study a Faulty Congested Clique model, in which an adversary may fail\nnodes in the network throughout the computation. We show that any task of\n$O(n\\log{n})$-bit input per node can be solved in roughly $n$ rounds, where $n$\nis the size of the network. This nearly matches the linear upper bound on the\ncomplexity of the non-faulty Congested Clique model for such problems, by\nlearning the entire input, and it holds in the faulty model even with a linear\nnumber of faults.\n  Our main contribution is that we establish that one can do much better by\nlooking more closely at the computation. Given a deterministic algorithm\n$\\mathcal{A}$ for the non-faulty Congested Clique model, we show how to\ntransform it into an algorithm $\\mathcal{A}'$ for the faulty model, with an\noverhead that could be as small as some logarithmic-in-$n$ factor, by\nconsidering refined complexity measures of $\\mathcal{A}$.\n  As an exemplifying application of our approach, we show that the\n$O(n^{1/3})$-round complexity of semi-ring matrix multiplication\n[Censor-Hillel, Kaski, Korhonen, Lenzen, Paz, Suomela, PODC 2015] remains the\nsame up to polylog factors in the faulty model, even if the adversary can fail\n$99\\%$ of the nodes (or any other constant fraction).",
    "pdf_url": "http://arxiv.org/pdf/2505.11430v2",
    "published": "2025-05-16T16:48:40+00:00",
    "categories": [
      "cs.DS",
      "cs.DC"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.11429v1",
    "title": "Inflationary Dynamics of Mutated Hilltop Inflation in Einstein-Gauss-Bonnet Gravity Under New Slow-Roll Approximations with Generalised Reheating",
    "authors": [
      "Yogesh",
      "Mehnaz Zahoor",
      "Kashif Ali Wani",
      "Imtiyaz Ahmad Bhat"
    ],
    "abstract": "The advancement in the observational cosmology of the early universe such as\nCosmic Microwave Background (CMB) observations, puts severe constraints on the\ninflationary models. Many inflationary models have been ruled out by CMB,\nnevertheless the models ruled out in standard cold inflationary scenarios can\nbe resurrected in modified gravity models. In this regard we examine the\ndynamics of inflation within the framework of Einstein-Gauss-Bonnet (EGB)\nGravity using the new slow-roll approximation methods proposed in Pozdeeva et\nal. (2024). We consider the Mutated Hilltop inflation model (Pal et al., 2010;\nPinhero and Pal, 2019) due to its origin from super-gravity, a naturally\nperfect choice to study the impact of EGB on inflationary observables such as\ntensor-to-scalar ratio ($r$) and scalar spectral index ($n_s$). The period of\nreheating following the inflationary phase is also examined, and for the {\\it\nPlanck'18} permitted values of $n_s$, constraints on the reheating temperature\n($T_{re}$) are computed for various equations of states during reheating\n($\\omega_{re}$).",
    "pdf_url": "http://arxiv.org/pdf/2505.11429v1",
    "published": "2025-05-16T16:47:55+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11428v1",
    "title": "From relativistic Vlasov-Maxwell to electron-MHD in the quasineutral regime",
    "authors": [
      "Antoine Gagnebin",
      "Mikaela Iacobelli",
      "Alexandre Rege",
      "Stefano Rossi"
    ],
    "abstract": "We study the quasineutral limit for the relativistic Vlasov-Maxwell system in\nthe framework of analytic regularity. Following the high regularity approach\nintroduced by Grenier [44] for the Vlasov-Poisson system, we construct\nlocal-in-time solutions with analytic bounds uniform in the quasineutrality\nparameter $\\varepsilon$. In contrast to the electrostatic case, the presence of\na magnetic field and a solenoidal electric component leads to new oscillatory\neffects that require a refined decomposition of the electromagnetic fields and\nthe introduction of dispersive correctors. We show that, after appropriate\nfiltering, solutions converge strongly as $\\varepsilon$ tends to zero to a\nlimiting system describing kinetic electron magnetohydrodynamics (e-MHD). This\nis the first strong convergence result for the Vlasov-Maxwell system in the\nquasineutral limit under analytic regularity assumptions, providing a rigorous\njustification for the e-MHD reduction, widely used in modelling plasmas in\ntokamaks and stellarators.",
    "pdf_url": "http://arxiv.org/pdf/2505.11428v1",
    "published": "2025-05-16T16:44:41+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11427v1",
    "title": "Mergenetic: a Simple Evolutionary Model Merging Library",
    "authors": [
      "Adrian Robert Minut",
      "Tommaso Mencattini",
      "Andrea Santilli",
      "Donato Crisostomi",
      "Emanuele Rodolà"
    ],
    "abstract": "Model merging allows combining the capabilities of existing models into a new\none - post hoc, without additional training. This has made it increasingly\npopular thanks to its low cost and the availability of libraries that support\nmerging on consumer GPUs. Recent work shows that pairing merging with\nevolutionary algorithms can boost performance, but no framework currently\nsupports flexible experimentation with such strategies in language models. We\nintroduce Mergenetic, an open-source library for evolutionary model merging.\nMergenetic enables easy composition of merging methods and evolutionary\nalgorithms while incorporating lightweight fitness estimators to reduce\nevaluation costs. We describe its design and demonstrate that Mergenetic\nproduces competitive results across tasks and languages using modest hardware.",
    "pdf_url": "http://arxiv.org/pdf/2505.11427v1",
    "published": "2025-05-16T16:43:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11426v1",
    "title": "Beyond Time: Unveiling the Invisible Burden of Mental Load",
    "authors": [
      "Francesca Barigozzi",
      "Pietro Biroli",
      "Chiara Monfardini",
      "Natalia Montinari",
      "Elena Pisanelli",
      "Sveva Vitellozzi"
    ],
    "abstract": "This paper introduces a novel, scalable methodology to measure individual\nperceptions of gaps in mental load -- the cognitive and emotional burden\nassociated with organizing household and childcare tasks -- within heterosexual\ncouples. Using original data from the TIMES Observatory in Italy, the study\ncombines time-use diaries with new survey indicators to quantify cognitive\nlabor, emotional fatigue, and the spillover of mental load into the workplace.\nResults reveal systematic gender asymmetries: women are significantly more\nlikely than men to bear organizational responsibility for domestic tasks,\nreport lower satisfaction with this division, and experience higher emotional\nfatigue. These burdens are underestimated by their partners. The effects are\nparticularly pronounced among college-educated and employed women, who also\nreport greater spillovers of family responsibilities than men during paid work\nhours. The perceived responsibility for managing family activities is more\nstrongly associated with within-couple gaps in time use than with the absolute\ntime spent on their execution, underscoring the relational and conflictual\nnature of mental load.",
    "pdf_url": "http://arxiv.org/pdf/2505.11426v1",
    "published": "2025-05-16T16:42:34+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.11425v1",
    "title": "Face Consistency Benchmark for GenAI Video",
    "authors": [
      "Michal Podstawski",
      "Malgorzata Kudelska",
      "Haohong Wang"
    ],
    "abstract": "Video generation driven by artificial intelligence has advanced\nsignificantly, enabling the creation of dynamic and realistic content. However,\nmaintaining character consistency across video sequences remains a major\nchallenge, with current models struggling to ensure coherence in appearance and\nattributes. This paper introduces the Face Consistency Benchmark (FCB), a\nframework for evaluating and comparing the consistency of characters in\nAI-generated videos. By providing standardized metrics, the benchmark\nhighlights gaps in existing solutions and promotes the development of more\nreliable approaches. This work represents a crucial step toward improving\ncharacter consistency in AI video generation technologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11425v1",
    "published": "2025-05-16T16:41:44+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11424v1",
    "title": "Improving Object Detection Performance through YOLOv8: A Comprehensive Training and Evaluation Study",
    "authors": [
      "Rana Poureskandar",
      "Shiva Razzagzadeh"
    ],
    "abstract": "This study evaluated the performance of a YOLOv8-based segmentation model for\ndetecting and segmenting wrinkles in facial images.",
    "pdf_url": "http://arxiv.org/pdf/2505.11424v1",
    "published": "2025-05-16T16:38:01+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11423v3",
    "title": "When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs",
    "authors": [
      "Xiaomin Li",
      "Zhou Yu",
      "Zhiwei Zhang",
      "Xupeng Chen",
      "Ziji Zhang",
      "Yingying Zhuang",
      "Narayanan Sadagopan",
      "Anurag Beniwal"
    ],
    "abstract": "Reasoning-enhanced large language models (RLLMs), whether explicitly trained\nfor reasoning or prompted via chain-of-thought (CoT), have achieved\nstate-of-the-art performance on many complex reasoning tasks. However, we\nuncover a surprising and previously overlooked phenomenon: explicit CoT\nreasoning can significantly degrade instruction-following accuracy. Evaluating\n15 models on two benchmarks: IFEval (with simple, rule-verifiable constraints)\nand ComplexBench (with complex, compositional constraints), we consistently\nobserve performance drops when CoT prompting is applied. Through large-scale\ncase studies and an attention-based analysis, we identify common patterns where\nreasoning either helps (e.g., with formatting or lexical precision) or hurts\n(e.g., by neglecting simple constraints or introducing unnecessary content). We\npropose a metric, constraint attention, to quantify model focus during\ngeneration and show that CoT reasoning often diverts attention away from\ninstruction-relevant tokens. To mitigate these effects, we introduce and\nevaluate four strategies: in-context learning, self-reflection, self-selective\nreasoning, and classifier-selective reasoning. Our results demonstrate that\nselective reasoning strategies, particularly classifier-selective reasoning,\ncan substantially recover lost performance. To our knowledge, this is the first\nwork to systematically expose reasoning-induced failures in\ninstruction-following and offer practical mitigation strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11423v3",
    "published": "2025-05-16T16:36:00+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11422v1",
    "title": "Complementary Probes of Gravitational Radiation States",
    "authors": [
      "Sreenath K. Manikandan",
      "Frank Wilczek"
    ],
    "abstract": "We demonstrate that the statistical fluctuations in resonant radiation\ndetectors operating in homodyne and heterodyne modes offers additional,\ncomplementary information to that obtained from their direct operation as click\ndetectors. We use this to refine tests of the coherent state hypothesis of\ninterest in connection with gravitational wave fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.11422v1",
    "published": "2025-05-16T16:34:15+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.11421v1",
    "title": "Towards Cultural Bridge by Bahnaric-Vietnamese Translation Using Transfer Learning of Sequence-To-Sequence Pre-training Language Model",
    "authors": [
      "Phan Tran Minh Dat",
      "Vo Hoang Nhat Khang",
      "Quan Thanh Tho"
    ],
    "abstract": "This work explores the journey towards achieving Bahnaric-Vietnamese\ntranslation for the sake of culturally bridging the two ethnic groups in\nVietnam. However, translating from Bahnaric to Vietnamese also encounters some\ndifficulties. The most prominent challenge is the lack of available original\nBahnaric resources source language, including vocabulary, grammar, dialogue\npatterns and bilingual corpus, which hinders the data collection process for\ntraining. To address this, we leverage a transfer learning approach using\nsequence-to-sequence pre-training language model. First of all, we leverage a\npre-trained Vietnamese language model to capture the characteristics of this\nlanguage. Especially, to further serve the purpose of machine translation, we\naim for a sequence-to-sequence model, not encoder-only like BERT or\ndecoder-only like GPT. Taking advantage of significant similarity between the\ntwo languages, we continue training the model with the currently limited\nbilingual resources of Vietnamese-Bahnaric text to perform the transfer\nlearning from language model to machine translation. Thus, this approach can\nhelp to handle the problem of imbalanced resources between two languages, while\nalso optimizing the training and computational processes. Additionally, we also\nenhanced the datasets using data augmentation to generate additional resources\nand defined some heuristic methods to help the translation more precise. Our\napproach has been validated to be highly effective for the Bahnaric-Vietnamese\ntranslation model, contributing to the expansion and preservation of languages,\nand facilitating better mutual understanding between the two ethnic people.",
    "pdf_url": "http://arxiv.org/pdf/2505.11421v1",
    "published": "2025-05-16T16:33:36+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11420v1",
    "title": "Self-supervised perception for tactile skin covered dexterous hands",
    "authors": [
      "Akash Sharma",
      "Carolina Higuera",
      "Chaithanya Krishna Bodduluri",
      "Zixi Liu",
      "Taosha Fan",
      "Tess Hellebrekers",
      "Mike Lambeta",
      "Byron Boots",
      "Michael Kaess",
      "Tingfan Wu",
      "Francois Robert Hogan",
      "Mustafa Mukadam"
    ],
    "abstract": "We present Sparsh-skin, a pre-trained encoder for magnetic skin sensors\ndistributed across the fingertips, phalanges, and palm of a dexterous robot\nhand. Magnetic tactile skins offer a flexible form factor for hand-wide\ncoverage with fast response times, in contrast to vision-based tactile sensors\nthat are restricted to the fingertips and limited by bandwidth. Full hand\ntactile perception is crucial for robot dexterity. However, a lack of\ngeneral-purpose models, challenges with interpreting magnetic flux and\ncalibration have limited the adoption of these sensors. Sparsh-skin, given a\nhistory of kinematic and tactile sensing across a hand, outputs a latent\ntactile embedding that can be used in any downstream task. The encoder is\nself-supervised via self-distillation on a variety of unlabeled hand-object\ninteractions using an Allegro hand sensorized with Xela uSkin. In experiments\nacross several benchmark tasks, from state estimation to policy learning, we\nfind that pretrained Sparsh-skin representations are both sample efficient in\nlearning downstream tasks and improve task performance by over 41% compared to\nprior work and over 56% compared to end-to-end learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.11420v1",
    "published": "2025-05-16T16:32:50+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11419v1",
    "title": "Lattice models with subsystem/weak non-invertible symmetry-protected topological order",
    "authors": [
      "Yuki Furukawa"
    ],
    "abstract": "We construct a family of lattice models which possess subsystem\nnon-invertible symmetry-protected topological (SPT) order and analyze their\ninterface modes protected by the symmetry, whose codimension turns out to be\nmore than one. We also propose 2+1d lattice models which belong to two\ndifferent weak SPT phases distinguished by a combination of translational\nsymmetry and non-invertible symmetry. We show that the interface between them\nexhibits an exotic Lieb-Schultz-Mattis anomaly coming from the symmetry which\ncannot be written as a direct product of an internal symmetry and the lattice\ntranslational symmetry.",
    "pdf_url": "http://arxiv.org/pdf/2505.11419v1",
    "published": "2025-05-16T16:32:35+00:00",
    "categories": [
      "cond-mat.str-el",
      "hep-th",
      "quant-ph"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.11418v1",
    "title": "Energy efficiency analysis of Spiking Neural Networks for space applications",
    "authors": [
      "Paolo Lunghi",
      "Stefano Silvestrini",
      "Dominik Dold",
      "Gabriele Meoni",
      "Alexander Hadjiivanov",
      "Dario Izzo"
    ],
    "abstract": "While the exponential growth of the space sector and new operative concepts\nask for higher spacecraft autonomy, the development of AI-assisted space\nsystems was so far hindered by the low availability of power and energy typical\nof space applications. In this context, Spiking Neural Networks (SNN) are\nhighly attractive due to their theoretically superior energy efficiency due to\ntheir inherently sparse activity induced by neurons communicating by means of\nbinary spikes. Nevertheless, the ability of SNN to reach such efficiency on\nreal world tasks is still to be demonstrated in practice. To evaluate the\nfeasibility of utilizing SNN onboard spacecraft, this work presents a numerical\nanalysis and comparison of different SNN techniques applied to scene\nclassification for the EuroSAT dataset. Such tasks are of primary importance\nfor space applications and constitute a valuable test case given the abundance\nof competitive methods available to establish a benchmark. Particular emphasis\nis placed on models based on temporal coding, where crucial information is\nencoded in the timing of neuron spikes. These models promise even greater\nefficiency of resulting networks, as they maximize the sparsity properties\ninherent in SNN. A reliable metric capable of comparing different architectures\nin a hardware-agnostic way is developed to establish a clear theoretical\ndependence between architecture parameters and the energy consumption that can\nbe expected onboard the spacecraft. The potential of this novel method and his\nflexibility to describe specific hardware platforms is demonstrated by its\napplication to predicting the energy consumption of a BrainChip Akida AKD1000\nneuromorphic processor.",
    "pdf_url": "http://arxiv.org/pdf/2505.11418v1",
    "published": "2025-05-16T16:29:50+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11417v1",
    "title": "EdgeWisePersona: A Dataset for On-Device User Profiling from Natural Language Interactions",
    "authors": [
      "Patryk Bartkowiak",
      "Michal Podstawski"
    ],
    "abstract": "This paper introduces a novel dataset and evaluation benchmark designed to\nassess and improve small language models deployable on edge devices, with a\nfocus on user profiling from multi-session natural language interactions in\nsmart home environments. At the core of the dataset are structured user\nprofiles, each defined by a set of routines - context-triggered, repeatable\npatterns of behavior that govern how users interact with their home systems.\nUsing these profiles as input, a large language model (LLM) generates\ncorresponding interaction sessions that simulate realistic, diverse, and\ncontext-aware dialogues between users and their devices.\n  The primary task supported by this dataset is profile reconstruction:\ninferring user routines and preferences solely from interactions history. To\nassess how well current models can perform this task under realistic\nconditions, we benchmarked several state-of-the-art compact language models and\ncompared their performance against large foundation models. Our results show\nthat while small models demonstrate some capability in reconstructing profiles,\nthey still fall significantly short of large models in accurately capturing\nuser behavior. This performance gap poses a major challenge - particularly\nbecause on-device processing offers critical advantages, such as preserving\nuser privacy, minimizing latency, and enabling personalized experiences without\nreliance on the cloud. By providing a realistic, structured testbed for\ndeveloping and evaluating behavioral modeling under these constraints, our\ndataset represents a key step toward enabling intelligent, privacy-respecting\nAI systems that learn and adapt directly on user-owned devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.11417v1",
    "published": "2025-05-16T16:29:21+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11416v1",
    "title": "MID-L: Matrix-Interpolated Dropout Layer with Layer-wise Neuron Selection",
    "authors": [
      "Pouya Shaeri",
      "Ariane Middel"
    ],
    "abstract": "Modern neural networks often activate all neurons for every input, leading to\nunnecessary computation and inefficiency. We introduce Matrix-Interpolated\nDropout Layer (MID-L), a novel module that dynamically selects and activates\nonly the most informative neurons by interpolating between two transformation\npaths via a learned, input-dependent gating vector. Unlike conventional dropout\nor static sparsity methods, MID-L employs a differentiable Top-k masking\nstrategy, enabling per-input adaptive computation while maintaining end-to-end\ndifferentiability. MID-L is model-agnostic and integrates seamlessly into\nexisting architectures. Extensive experiments on six benchmarks, including\nMNIST, CIFAR-10, CIFAR-100, SVHN, UCI Adult, and IMDB, show that MID-L achieves\nup to average 55\\% reduction in active neurons, 1.7$\\times$ FLOPs savings, and\nmaintains or exceeds baseline accuracy. We further validate the informativeness\nand selectivity of the learned neurons via Sliced Mutual Information (SMI) and\nobserve improved robustness under overfitting and noisy data conditions.\nAdditionally, MID-L demonstrates favorable inference latency and memory usage\nprofiles, making it suitable for both research exploration and deployment on\ncompute-constrained systems. These results position MID-L as a general-purpose,\nplug-and-play dynamic computation layer, bridging the gap between dropout\nregularization and efficient inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.11416v1",
    "published": "2025-05-16T16:29:19+00:00",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11415v2",
    "title": "MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse Mixture-of-Experts Systems",
    "authors": [
      "Yinsicheng Jiang",
      "Yao Fu",
      "Yeqi Huang",
      "Ping Nie",
      "Zhan Lu",
      "Leyang Xue",
      "Congjie He",
      "Man-Kit Sit",
      "Jilong Xue",
      "Li Dong",
      "Ziming Miao",
      "Dayou Du",
      "Tairan Xu",
      "Kai Zou",
      "Edoardo Ponti",
      "Luo Mai"
    ],
    "abstract": "The sparse Mixture-of-Experts (MoE) architecture is increasingly favored for\nscaling Large Language Models (LLMs) efficiently, but it depends on\nheterogeneous compute and memory resources. These factors jointly affect system\nCost, Accuracy, and Performance (CAP), making trade-offs inevitable. Existing\nbenchmarks often fail to capture these trade-offs accurately, complicating\npractical deployment decisions. To address this, we introduce MoE-CAP, a\nbenchmark specifically designed for MoE systems. Our analysis reveals that\nachieving an optimal balance across CAP is difficult with current hardware; MoE\nsystems typically optimize two of the three dimensions at the expense of the\nthird-a dynamic we term the MoE-CAP trade-off. To visualize this, we propose\nthe CAP Radar Diagram. We further introduce sparsity-aware performance\nmetrics-Sparse Memory Bandwidth Utilization (S-MBU) and Sparse Model FLOPS\nUtilization (S-MFU)-to enable accurate performance benchmarking of MoE systems\nacross diverse hardware platforms and deployment scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.11415v2",
    "published": "2025-05-16T16:28:38+00:00",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11581v1",
    "title": "Questioning Representational Optimism in Deep Learning: The Fractured Entangled Representation Hypothesis",
    "authors": [
      "Akarsh Kumar",
      "Jeff Clune",
      "Joel Lehman",
      "Kenneth O. Stanley"
    ],
    "abstract": "Much of the excitement in modern AI is driven by the observation that scaling\nup existing systems leads to better performance. But does better performance\nnecessarily imply better internal representations? While the representational\noptimist assumes it must, this position paper challenges that view. We compare\nneural networks evolved through an open-ended search process to networks\ntrained via conventional stochastic gradient descent (SGD) on the simple task\nof generating a single image. This minimal setup offers a unique advantage:\neach hidden neuron's full functional behavior can be easily visualized as an\nimage, thus revealing how the network's output behavior is internally\nconstructed neuron by neuron. The result is striking: while both networks\nproduce the same output behavior, their internal representations differ\ndramatically. The SGD-trained networks exhibit a form of disorganization that\nwe term fractured entangled representation (FER). Interestingly, the evolved\nnetworks largely lack FER, even approaching a unified factored representation\n(UFR). In large models, FER may be degrading core model capacities like\ngeneralization, creativity, and (continual) learning. Therefore, understanding\nand mitigating FER could be critical to the future of representation learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.11581v1",
    "published": "2025-05-16T16:28:34+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11414v2",
    "title": "A Multigraph Characterization of Permutiple Strings",
    "authors": [
      "Benjamin V. Holt"
    ],
    "abstract": "A permutiple is a natural number whose representation in some base is an\ninteger multiple of a number whose representation has the same collection of\ndigits. A previous paper utilizes a finite-state-machine construction and its\nstate graph to recognize permutiples and to generate new examples. Permutiples\nare associated with walks on the state graph which necessarily satisfy certain\nconditions. However, the above effort does not provide conditions sufficient\nfor the existence of permutiples. In this paper, we provide such a condition,\nwhich we will state using the language of multigraphs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11414v2",
    "published": "2025-05-16T16:28:27+00:00",
    "categories": [
      "math.CO",
      "math.NT"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11413v1",
    "title": "CARES: Comprehensive Evaluation of Safety and Adversarial Robustness in Medical LLMs",
    "authors": [
      "Sijia Chen",
      "Xiaomin Li",
      "Mengxue Zhang",
      "Eric Hanchen Jiang",
      "Qingcheng Zeng",
      "Chen-Hsiang Yu"
    ],
    "abstract": "Large language models (LLMs) are increasingly deployed in medical contexts,\nraising critical concerns about safety, alignment, and susceptibility to\nadversarial manipulation. While prior benchmarks assess model refusal\ncapabilities for harmful prompts, they often lack clinical specificity, graded\nharmfulness levels, and coverage of jailbreak-style attacks. We introduce CARES\n(Clinical Adversarial Robustness and Evaluation of Safety), a benchmark for\nevaluating LLM safety in healthcare. CARES includes over 18,000 prompts\nspanning eight medical safety principles, four harm levels, and four prompting\nstyles: direct, indirect, obfuscated, and role-play, to simulate both malicious\nand benign use cases. We propose a three-way response evaluation protocol\n(Accept, Caution, Refuse) and a fine-grained Safety Score metric to assess\nmodel behavior. Our analysis reveals that many state-of-the-art LLMs remain\nvulnerable to jailbreaks that subtly rephrase harmful prompts, while also\nover-refusing safe but atypically phrased queries. Finally, we propose a\nmitigation strategy using a lightweight classifier to detect jailbreak attempts\nand steer models toward safer behavior via reminder-based conditioning. CARES\nprovides a rigorous framework for testing and improving medical LLM safety\nunder adversarial and ambiguous conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11413v1",
    "published": "2025-05-16T16:25:51+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11412v1",
    "title": "Uncertainty quantification with approximate variational learning for wearable photoplethysmography prediction tasks",
    "authors": [
      "Ciaran Bench",
      "Vivek Desai",
      "Mohammad Moulaeifard",
      "Nils Strodthoff",
      "Philip Aston",
      "Andrew Thompson"
    ],
    "abstract": "Photoplethysmography (PPG) signals encode information about relative changes\nin blood volume that can be used to assess various aspects of cardiac health\nnon-invasively, e.g.\\ to detect atrial fibrillation (AF) or predict blood\npressure (BP). Deep networks are well-equipped to handle the large quantities\nof data acquired from wearable measurement devices. However, they lack\ninterpretability and are prone to overfitting, leaving considerable risk for\npoor performance on unseen data and misdiagnosis. Here, we describe the use of\ntwo scalable uncertainty quantification techniques: Monte Carlo Dropout and the\nrecently proposed Improved Variational Online Newton. These techniques are used\nto assess the trustworthiness of models trained to perform AF classification\nand BP regression from raw PPG time series. We find that the choice of\nhyperparameters has a considerable effect on the predictive performance of the\nmodels and on the quality and composition of predicted uncertainties. E.g. the\nstochasticity of the model parameter sampling determines the proportion of the\ntotal uncertainty that is aleatoric, and has varying effects on predictive\nperformance and calibration quality dependent on the chosen uncertainty\nquantification technique and the chosen expression of uncertainty. We find\nsignificant discrepancy in the quality of uncertainties over the predicted\nclasses, emphasising the need for a thorough evaluation protocol that assesses\nlocal and adaptive calibration. This work suggests that the choice of\nhyperparameters must be carefully tuned to balance predictive performance and\ncalibration quality, and that the optimal parameterisation may vary depending\non the chosen expression of uncertainty.",
    "pdf_url": "http://arxiv.org/pdf/2505.11412v1",
    "published": "2025-05-16T16:21:45+00:00",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11411v1",
    "title": "Is Grokking a Computational Glass Relaxation?",
    "authors": [
      "Xiaotian Zhang",
      "Yue Shang",
      "Entao Yang",
      "Ge Zhang"
    ],
    "abstract": "Understanding neural network's (NN) generalizability remains a central\nquestion in deep learning research. The special phenomenon of grokking, where\nNNs abruptly generalize long after the training performance reaches a\nnear-perfect level, offers a unique window to investigate the underlying\nmechanisms of NNs' generalizability. Here we propose an interpretation for\ngrokking by framing it as a computational glass relaxation: viewing NNs as a\nphysical system where parameters are the degrees of freedom and train loss is\nthe system energy, we find memorization process resembles a rapid cooling of\nliquid into non-equilibrium glassy state at low temperature and the later\ngeneralization is like a slow relaxation towards a more stable configuration.\nThis mapping enables us to sample NNs' Boltzmann entropy (states of density)\nlandscape as a function of training loss and test accuracy. Our experiments in\ntransformers on arithmetic tasks suggests that there is NO entropy barrier in\nthe memorization-to-generalization transition of grokking, challenging previous\ntheory that defines grokking as a first-order phase transition. We identify a\nhigh-entropy advantage under grokking, an extension of prior work linking\nentropy to generalizability but much more significant. Inspired by grokking's\nfar-from-equilibrium nature, we develop a toy optimizer WanD based on\nWang-landau molecular dynamics, which can eliminate grokking without any\nconstraints and find high-norm generalizing solutions. This provides\nstrictly-defined counterexamples to theory attributing grokking solely to\nweight norm evolution towards the Goldilocks zone and also suggests new\npotential ways for optimizer design.",
    "pdf_url": "http://arxiv.org/pdf/2505.11411v1",
    "published": "2025-05-16T16:20:02+00:00",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11580v1",
    "title": "Flash Invariant Point Attention",
    "authors": [
      "Andrew Liu",
      "Axel Elaldi",
      "Nicholas T Franklin",
      "Nathan Russell",
      "Gurinder S Atwal",
      "Yih-En A Ban",
      "Olivia Viessmann"
    ],
    "abstract": "Invariant Point Attention (IPA) is a key algorithm for geometry-aware\nmodeling in structural biology, central to many protein and RNA models.\nHowever, its quadratic complexity limits the input sequence length. We\nintroduce FlashIPA, a factorized reformulation of IPA that leverages\nhardware-efficient FlashAttention to achieve linear scaling in GPU memory and\nwall-clock time with sequence length. FlashIPA matches or exceeds standard IPA\nperformance while substantially reducing computational costs. FlashIPA extends\ntraining to previously unattainable lengths, and we demonstrate this by\nre-training generative models without length restrictions and generating\nstructures of thousands of residues. FlashIPA is available at\nhttps://github.com/flagshippioneering/flash_ipa.",
    "pdf_url": "http://arxiv.org/pdf/2505.11580v1",
    "published": "2025-05-16T16:19:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11410v1",
    "title": "The Time of Bootstrap Percolation in High Dimensions",
    "authors": [
      "Fengxing Zhu"
    ],
    "abstract": "We consider the $d$-neighbor bootstrap percolation process on the\n$d$-dimensional torus, with vertex set $V=\\{1,\\cdots,n\\}^d$ and edge set\n$\\{xy:\\sum_{i=1}^d|x_i-y_i (\\text{mod} \\; n)|=1\\}$. We determine the\npercolation time up to a constant factor with high probability when the initial\ninfection probability is in a certain range and the infection threshold is $d$,\nextending one of the two main theorems from Balister,Bollob{\\'a}s, and Smith\n(2016) about the percolation time with the infection threshold equal to $2$ on\nthe two-dimensional torus.",
    "pdf_url": "http://arxiv.org/pdf/2505.11410v1",
    "published": "2025-05-16T16:18:17+00:00",
    "categories": [
      "math.CO",
      "math.PR"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11409v1",
    "title": "Visual Planning: Let's Think Only with Images",
    "authors": [
      "Yi Xu",
      "Chengzu Li",
      "Han Zhou",
      "Xingchen Wan",
      "Caiqi Zhang",
      "Anna Korhonen",
      "Ivan Vulić"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) and their multimodal\nextensions (MLLMs) have substantially enhanced machine reasoning across diverse\ntasks. However, these models predominantly rely on pure text as the medium for\nboth expressing and structuring reasoning, even when visual information is\npresent. In this work, we argue that language may not always be the most\nnatural or effective modality for reasoning, particularly in tasks involving\nspatial and geometrical information. Motivated by this, we propose a new\nparadigm, Visual Planning, which enables planning through purely visual\nrepresentations, independent of text. In this paradigm, planning is executed\nvia sequences of images that encode step-by-step inference in the visual\ndomain, akin to how humans sketch or visualize future actions. We introduce a\nnovel reinforcement learning framework, Visual Planning via Reinforcement\nLearning (VPRL), empowered by GRPO for post-training large vision models,\nleading to substantial improvements in planning in a selection of\nrepresentative visual navigation tasks, FrozenLake, Maze, and MiniBehavior. Our\nvisual planning paradigm outperforms all other planning variants that conduct\nreasoning in the text-only space. Our results establish Visual Planning as a\nviable and promising alternative to language-based reasoning, opening new\navenues for tasks that benefit from intuitive, image-based inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.11409v1",
    "published": "2025-05-16T16:17:22+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11408v1",
    "title": "Acceleration Potential and Density Profile of Secondary Plasma in the Magnetosphere of Orthogonal Pulsars",
    "authors": [
      "A. Yu. Istomin",
      "F. A. Kniazev",
      "V. S. Beskin"
    ],
    "abstract": "A new method for determining the accelerating potential above the polar caps\nof radio pulsars with an arbitrary inclination angle of the magnetic axis to\nthe rotation axis has been proposed. The approach has been based on the concept\nof a vacuum gap, the height and shape of the upper boundary of which are found\nself-consistently together with the solution of the corresponding Poisson\nequation. In turn, information about the accelerating potential has made it\npossible to determine the transverse profiles of the secondary plasma density.\nIt has also been shown that the effect of inverse Compton scattering on the\nconsidered processes is insignificant.",
    "pdf_url": "http://arxiv.org/pdf/2505.11408v1",
    "published": "2025-05-16T16:17:03+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11407v1",
    "title": "Probing Quantum Structure in Gravitational Radiation",
    "authors": [
      "Sreenath K. Manikandan",
      "Frank Wilczek"
    ],
    "abstract": "Gravitational radiation from known astrophysical sources is conventionally\ntreated classically. This treatment corresponds, implicitly, to the hypothesis\nthat a particular class of quantum-mechanical states -- the so-called coherent\nstates -- adequately describe the gravitational radiation field. We propose\npracticable, quantitative tests of that hypothesis using resonant bar detectors\nmonitored in coincidence with LIGO-style interferometers. Our tests readily\ndistinguish fields that contain significant thermal components or squeezing. We\nidentify concrete circumstances in which the classical (i.e., coherent state)\nhypothesis is likely to fail. Such failures are of fundamental interest, in\nthat addressing them requires us to treat the gravitational field\nquantum-mechanically, and they open a new window into the dynamics of\ngravitational wave sources.",
    "pdf_url": "http://arxiv.org/pdf/2505.11407v1",
    "published": "2025-05-16T16:16:44+00:00",
    "categories": [
      "gr-qc",
      "quant-ph"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.11406v1",
    "title": "Large Language Model Use Impact Locus of Control",
    "authors": [
      "Jenny Xiyu Fu",
      "Brennan Antone",
      "Kowe Kadoma",
      "Malte Jung"
    ],
    "abstract": "As AI tools increasingly shape how we write, they may also quietly reshape\nhow we perceive ourselves. This paper explores the psychological impact of\nco-writing with AI on people's locus of control. Through an empirical study\nwith 462 participants, we found that employment status plays a critical role in\nshaping users' reliance on AI and their locus of control. Current results\ndemonstrated that employed participants displayed higher reliance on AI and a\nshift toward internal control, while unemployed users tended to experience a\nreduction in personal agency. Through quantitative results and qualitative\nobservations, this study opens a broader conversation about AI's role in\nshaping personal agency and identity.",
    "pdf_url": "http://arxiv.org/pdf/2505.11406v1",
    "published": "2025-05-16T16:16:32+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11405v1",
    "title": "EmotionHallucer: Evaluating Emotion Hallucinations in Multimodal Large Language Models",
    "authors": [
      "Bohao Xing",
      "Xin Liu",
      "Guoying Zhao",
      "Chengyu Liu",
      "Xiaolan Fu",
      "Heikki Kälviäinen"
    ],
    "abstract": "Emotion understanding is a critical yet challenging task. Recent advances in\nMultimodal Large Language Models (MLLMs) have significantly enhanced their\ncapabilities in this area. However, MLLMs often suffer from hallucinations,\ngenerating irrelevant or nonsensical content. To the best of our knowledge,\ndespite the importance of this issue, there has been no dedicated effort to\nevaluate emotion-related hallucinations in MLLMs. In this work, we introduce\nEmotionHallucer, the first benchmark for detecting and analyzing emotion\nhallucinations in MLLMs. Unlike humans, whose emotion understanding stems from\nthe interplay of biology and social learning, MLLMs rely solely on data-driven\nlearning and lack innate emotional instincts. Fortunately, emotion psychology\nprovides a solid foundation of knowledge about human emotions. Building on\nthis, we assess emotion hallucinations from two dimensions: emotion psychology\nknowledge and real-world multimodal perception. To support robust evaluation,\nwe utilize an adversarial binary question-answer (QA) framework, which employs\ncarefully crafted basic and hallucinated pairs to assess the emotion\nhallucination tendencies of MLLMs. By evaluating 38 LLMs and MLLMs on\nEmotionHallucer, we reveal that: i) most current models exhibit substantial\nissues with emotion hallucinations; ii) closed-source models outperform\nopen-source ones in detecting emotion hallucinations, and reasoning capability\nprovides additional advantages; iii) existing models perform better in emotion\npsychology knowledge than in multimodal emotion perception. As a byproduct,\nthese findings inspire us to propose the PEP-MEK framework, which yields an\naverage improvement of 9.90% in emotion hallucination detection across selected\nmodels. Resources will be available at\nhttps://github.com/xxtars/EmotionHallucer.",
    "pdf_url": "http://arxiv.org/pdf/2505.11405v1",
    "published": "2025-05-16T16:14:08+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11404v3",
    "title": "Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner",
    "authors": [
      "Wenchuan Zhang",
      "Penghao Zhang",
      "Jingru Guo",
      "Tao Cheng",
      "Jie Chen",
      "Shuwan Zhang",
      "Zhang Zhang",
      "Yuhao Yi",
      "Hong Bu"
    ],
    "abstract": "Recent advances in vision language models (VLMs) have enabled broad progress\nin the general medical field. However, pathology still remains a more\nchallenging subdomain, with current pathology specific VLMs exhibiting\nlimitations in both diagnostic accuracy and reasoning plausibility. Such\nshortcomings are largely attributable to the nature of current pathology\ndatasets, which are primarily composed of image description pairs that lack the\ndepth and structured diagnostic paradigms employed by real world pathologists.\nIn this study, we leverage pathology textbooks and real world pathology experts\nto construct high-quality, reasoning-oriented datasets. Building on this, we\nintroduce Patho-R1, a multimodal RL-based pathology Reasoner, trained through a\nthree-stage pipeline: (1) continued pretraining on 3.5 million image-text pairs\nfor knowledge infusion; (2) supervised fine-tuning on 500k high-quality\nChain-of-Thought samples for reasoning incentivizing; (3) reinforcement\nlearning using Group Relative Policy Optimization and Decoupled Clip and\nDynamic sAmpling Policy Optimization strategies for multimodal reasoning\nquality refinement. To further assess the alignment quality of our dataset, we\npropose Patho-CLIP, trained on the same figure-caption corpus used for\ncontinued pretraining. Comprehensive experimental results demonstrate that both\nPatho-CLIP and Patho-R1 achieve robust performance across a wide range of\npathology-related tasks, including zero-shot classification, cross-modal\nretrieval, Visual Question Answering, and Multiple Choice Question. Our project\nis available at the Patho-R1 repository:\nhttps://github.com/Wenchuan-Zhang/Patho-R1.",
    "pdf_url": "http://arxiv.org/pdf/2505.11404v3",
    "published": "2025-05-16T16:12:50+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01983v1",
    "title": "Improvement of AMPs Identification with Generative Adversarial Network and Ensemble Classification",
    "authors": [
      "Reyhaneh Keshavarzpour",
      "Eghbal Mansoori"
    ],
    "abstract": "Identification of antimicrobial peptides is an important and necessary issue\nin today's era. Antimicrobial peptides are essential as an alternative to\nantibiotics for biomedical applications and many other practical applications.\nThese oligopeptides are useful in drug design and cause innate immunity against\nmicroorganisms. Artificial intelligence algorithms have played a significant\nrole in the ease of identifying these peptides.This research is improved by\nimproving proposed method in the field of antimicrobial peptides prediction.\nSuggested method is improved by combining the best coding method from different\nperspectives, In the following a deep neural network to balance the imbalanced\ncombined datasets. The results of this research show that the proposed method\nhave a significant improvement in the accuracy and efficiency of the prediction\nof antimicrobial peptides and are able to provide the best results compared to\nthe existing methods. These development in the field of prediction and\nclassification of antimicrobial peptides, basically in the fields of medicine\nand pharmaceutical industries, have high effectiveness and application.",
    "pdf_url": "http://arxiv.org/pdf/2506.01983v1",
    "published": "2025-05-16T16:11:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11403v1",
    "title": "Novel Constructions of Words with Strong Avoidance Properties and their Combinatorial Analysis",
    "authors": [
      "Duaa Abdullah",
      "Jasem Hamoud"
    ],
    "abstract": "This paper begins with a comprehensive overview of combinatorics on words and\nsymbolic dynamics, covering their historical origins, fundamental concepts, and\ninterconnections. Building upon this foundation, we introduce novel\nmathematical constructions related to pattern avoidance in infinite words.\nSpecifically, we define Strongly $(k, \\delta)$-Free Words generated via cyclic\nshift morphisms and present a theorem establishing specific avoidance\nproperties for these words, along with a detailed proof. Furthermore, we\npropose a conjecture regarding their factor complexity. These original results\ncontribute to the theoretical understanding of word structures and their\ncombinatorial properties, opening avenues for further research in discrete\nmathematics.",
    "pdf_url": "http://arxiv.org/pdf/2505.11403v1",
    "published": "2025-05-16T16:10:41+00:00",
    "categories": [
      "math.CO",
      "68R15, 11B39, 05A05, 68R15, 37B10",
      "F.2.2"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11402v1",
    "title": "$\\mathbb{Z}^r$-graded rings and their canonical modules",
    "authors": [
      "Margherita Barile",
      "Winfried Bruns"
    ],
    "abstract": "In ``Cohen--Macaulay rings'' Bruns and Herzog define the graded canonical\nmodule for $\\mathbb{Z}^r$-graded rings. We generalize the definition to\nmultigradings and prove that the canonical module ``localizes''. As an\napplication, we give a divisorial proof of the theorem of Danilov and Stanley\non the canonical module of affine normal monoid rings. Along the way, we\ndevelop the basic theory of multigraded rings and modules.",
    "pdf_url": "http://arxiv.org/pdf/2505.11402v1",
    "published": "2025-05-16T16:09:33+00:00",
    "categories": [
      "math.AC",
      "13C14, 13C15, 13C70, 13F05"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11401v1",
    "title": "Can AI automatically analyze public opinion? A LLM agents-based agentic pipeline for timely public opinion analysis",
    "authors": [
      "Jing Liu",
      "Xinxing Ren",
      "Yanmeng Xu",
      "Zekun Guo"
    ],
    "abstract": "This study proposes and implements the first LLM agents based agentic\npipeline for multi task public opinion analysis. Unlike traditional methods, it\noffers an end-to-end, fully automated analytical workflow without requiring\ndomain specific training data, manual annotation, or local deployment. The\npipeline integrates advanced LLM capabilities into a low-cost, user-friendly\nframework suitable for resource constrained environments. It enables timely,\nintegrated public opinion analysis through a single natural language query,\nmaking it accessible to non-expert users. To validate its effectiveness, the\npipeline was applied to a real world case study of the 2025 U.S. China tariff\ndispute, where it analyzed 1,572 Weibo posts and generated a structured, multi\npart analytical report. The results demonstrate some relationships between\npublic opinion and governmental decision-making. These contributions represent\na novel advancement in applying generative AI to public governance, bridging\nthe gap between technical sophistication and practical usability in public\nopinion monitoring.",
    "pdf_url": "http://arxiv.org/pdf/2505.11401v1",
    "published": "2025-05-16T16:09:28+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11400v1",
    "title": "Positive codegree thresholds for Hamilton cycles in hypergraphs",
    "authors": [
      "Richard Mycroft",
      "Camila Zárate-Guerén"
    ],
    "abstract": "For each $k \\geq 3$ and $1 \\leq \\ell \\leq k-1$ we give an asymptotically best\npossible minimum positive codegree condition for the existence of a Hamilton\n$\\ell$-cycle in a $k$-uniform hypergraph. This result exhibits an interesting\nduality with its analogue under a minimum codegree condition. The special case\n$\\ell = k-1$ of our result establishes an asymptotic version of a recent\nconjecture of Illingworth, Lang, M\\\"uyesser, Parczyk and Sgueglia on tight\nHamilton cycles in hypergraphs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11400v1",
    "published": "2025-05-16T16:05:38+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11399v1",
    "title": "On Kerr black hole formation with complete apparent horizon and a new approach toward Penrose inequality",
    "authors": [
      "Xinliang An",
      "Taoran He"
    ],
    "abstract": "Arising from admissible extended scale-critical short-pulse initial data, we\nshow that 3+1 dimensional Einstein vacuum equations admit dynamical Kerr black\nhole formation solutions. Our hyperbolic arguments combine the scale-critical\ngravitational-collapse result by An--Luk with the recent breakthrough by\nKlainerman--Szeftel on proving nonlinear Kerr stability with small angular\nmomentum, which requires us to perform various specific coordinate changes and\nframe transformations. Furthermore, allowing large spacetime angular momentum,\nwith new elliptic arguments and precise leading order calculations, we also\nsolve the apparent horizon in Kerr black hole formation spacetimes (including\nKlainerman--Szeftel's Kerr stability spacetimes) and conduct an exploration,\ndetailing the emergence, evolution, asymptotics and final state of the apparent\nhorizon. Building on our analysis, without time symmetric assumption, we then\nput forward a new mathematical framework and prove both the dynamical Penrose\ninequality and the spacetime Penrose inequality in our black-hole formation\nspacetimes and in the perturbative regime of subextremal Kerr black holes.\nCollectively, without assuming any symmetry, we extend Christodoulou's\ncelebrated trapped surface formation theorem to a black hole formation result.",
    "pdf_url": "http://arxiv.org/pdf/2505.11399v1",
    "published": "2025-05-16T16:05:24+00:00",
    "categories": [
      "gr-qc",
      "math-ph",
      "math.AP",
      "math.DG",
      "math.MP"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.11398v1",
    "title": "Path superposition as resource for perfect quantum teleportation with separable states",
    "authors": [
      "Sayan Mondal",
      "Priya Ghosh",
      "Ujjwal Sen"
    ],
    "abstract": "Quantum teleportation is a quintessential quantum communication protocol that\nenables the transmission of an arbitrary quantum state between two distant\nparties without physically transmitting the state with the help of shared\nentanglement and limited classical communication. We show that it is possible\nto relax the entanglement requirement in quantum teleportation if we have\naccess to a certain strain of superposition of quantum processes. Two types of\nsuperposition of quantum processes are generally considered in the literature:\nsuperposition of paths identified with quantum maps and superposition of\nindefinite causal orders of the maps. We find that when superposition of paths\nis incorporated in the protocol, perfect quantum teleportation becomes possible\nwith nonzero probability, even when the two parties share certain classes of\nseparable states, including pure product states. In contrast, the assistance of\nsuperposition of indefinite causal order of quantum maps in teleportation\nprotocol does not enable any quantum advantage for shared pure product states.\nFurthermore, we show that separable Werner states can also yield quantum\nadvantage in quantum teleportation assisted by the superposition of paths.\nFinally, we establish that the presence of quantum coherence in the control\nqubit is both necessary and sufficient to achieve quantum advantage in quantum\nteleportation assisted with superposition of paths. Our results highlight that\nwhile entanglement is a fundamental resource in standard quantum teleportation,\nsuperposition of paths can serve as an alternate resource for the same.",
    "pdf_url": "http://arxiv.org/pdf/2505.11398v1",
    "published": "2025-05-16T16:03:38+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.03152v1",
    "title": "Adaptive and Robust Image Processing on CubeSats",
    "authors": [
      "Robert Bayer",
      "Julian Priest",
      "Daniel Kjellberg",
      "Jeppe Lindhard",
      "Nikolaj Sørenesen",
      "Nicolaj Valsted",
      "Ívar Óli",
      "Pınar Tözün"
    ],
    "abstract": "CubeSats offer a low-cost platform for space research, particularly for Earth\nobservation. However, their resource-constrained nature and being in space,\nchallenge the flexibility and complexity of the deployed image processing\npipelines and their orchestration. This paper introduces two novel systems,\nDIPP and DISH, to address these challenges. DIPP is a modular and configurable\nimage processing pipeline framework that allows for adaptability to changing\nmission goals even after deployment, while preserving robustness. DISH is a\ndomain-specific language (DSL) and runtime system designed to schedule complex\nimaging workloads on low-power and memory-constrained processors.\n  Our experiments demonstrate that DIPP's decomposition of the processing\npipelines adds negligible overhead, while significantly reducing the network\nrequirements of updating pipelines and being robust against erroneous module\nuploads. Furthermore, we compare DISH to Lua, a general purpose scripting\nlanguage, and demonstrate its comparable expressiveness and lower memory\nrequirement.",
    "pdf_url": "http://arxiv.org/pdf/2506.03152v1",
    "published": "2025-05-16T16:03:04+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11397v1",
    "title": "Weakly-Coupled Trace Anomaly Action for Gravity",
    "authors": [
      "Gregory Gabadadze",
      "Giorgi Tukhashvili"
    ],
    "abstract": "We discuss a local, diff-invariant quantum effective action for gravity that\ncaptures the trace anomaly via a counter-term. We discuss why this counter-term\nis the most significant among infinitely many possible ones, and show how the\ncounter-term leads to a scattering amplitude that is strongly coupled at\narbitrarily low energies. We show how the introduction of a new sector with\nspontaneously broken scale invariance removes the strong coupling problem, and\ndiscuss some physical consequences due to the new sector. Three Appendices\nsummarize quantum effective actions -- highlighting connections between their\nlocal, and seemingly non-local formulations -- for the scale anomaly in 4D QED,\nfor the axial anomaly in 2D QED, and for the scale anomaly in a 2D sigma model.",
    "pdf_url": "http://arxiv.org/pdf/2505.11397v1",
    "published": "2025-05-16T16:02:48+00:00",
    "categories": [
      "hep-th",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11396v2",
    "title": "Finding Counterfactual Evidences for Node Classification",
    "authors": [
      "Dazhuo Qiu",
      "Jinwen Chen",
      "Arijit Khan",
      "Yan Zhao",
      "Francesco Bonchi"
    ],
    "abstract": "Counterfactual learning is emerging as an important paradigm, rooted in\ncausality, which promises to alleviate common issues of graph neural networks\n(GNNs), such as fairness and interpretability. However, as in many real-world\napplication domains where conducting randomized controlled trials is\nimpractical, one has to rely on available observational (factual) data to\ndetect counterfactuals. In this paper, we introduce and tackle the problem of\nsearching for counterfactual evidences for the GNN-based node classification\ntask. A counterfactual evidence is a pair of nodes such that, regardless they\nexhibit great similarity both in the features and in their neighborhood\nsubgraph structures, they are classified differently by the GNN. We develop\neffective and efficient search algorithms and a novel indexing solution that\nleverages both node features and structural information to identify\ncounterfactual evidences, and generalizes beyond any specific GNN. Through\nvarious downstream applications, we demonstrate the potential of counterfactual\nevidences to enhance fairness and accuracy of GNNs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11396v2",
    "published": "2025-05-16T16:02:39+00:00",
    "categories": [
      "cs.LG",
      "cs.DB"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11395v1",
    "title": "Conservative Maltsev Constraint Satisfaction Problems",
    "authors": [
      "Manuel Bodirsky",
      "Andrew Moorhead"
    ],
    "abstract": "We show that for every finite structure B with a conservative Maltsev\npolymorphism, the constraint satisfaction problem for B can be solved by a\nsymmetric linear Z2-Datalog program, and in particular is in the complexity\nclass parity-L. The proof has two steps: we first present the result for a\ncertain subclass whose polymorphism algebras are hereditarily subdirectly\nirreducible. We then show that every other structure in our class can be\nprimitively positively constructed from one of the structures in the subclass.\nThe second step requires different techniques and will be presented in a\ncompanion article.",
    "pdf_url": "http://arxiv.org/pdf/2505.11395v1",
    "published": "2025-05-16T16:01:46+00:00",
    "categories": [
      "math.RA",
      "cs.CC",
      "68W99 (primary), 08A05 (secondary), 08A62 (secondary)",
      "F.1.3"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11394v1",
    "title": "From Fibers to Cells: Fourier-Based Registration Enables Virtual Cresyl Violet Staining From 3D Polarized Light Imaging",
    "authors": [
      "Alexander Oberstrass",
      "Esteban Vaca",
      "Eric Upschulte",
      "Meiqi Niu",
      "Nicola Palomero-Gallagher",
      "David Graessel",
      "Christian Schiffer",
      "Markus Axer",
      "Katrin Amunts",
      "Timo Dickscheid"
    ],
    "abstract": "Comprehensive assessment of the various aspects of the brain's microstructure\nrequires the use of complementary imaging techniques. This includes measuring\nthe spatial distribution of cell bodies (cytoarchitecture) and nerve fibers\n(myeloarchitecture). The gold standard for cytoarchitectonic analysis is light\nmicroscopic imaging of cell-body stained tissue sections. To reveal the 3D\norientations of nerve fibers, 3D Polarized Light Imaging (3D-PLI) has been\nintroduced as a reliable technique providing a resolution in the micrometer\nrange while allowing processing of series of complete brain sections. 3D-PLI\nacquisition is label-free and allows subsequent staining of sections after\nmeasurement. By post-staining for cell bodies, a direct link between fiber- and\ncytoarchitecture can potentially be established within the same section.\nHowever, inevitable distortions introduced during the staining process make a\nnonlinear and cross-modal registration necessary in order to study the detailed\nrelationships between cells and fibers in the images. In addition, the\ncomplexity of processing histological sections for post-staining only allows\nfor a limited number of samples. In this work, we take advantage of deep\nlearning methods for image-to-image translation to generate a virtual staining\nof 3D-PLI that is spatially aligned at the cellular level. In a supervised\nsetting, we build on a unique dataset of brain sections, to which Cresyl violet\nstaining has been applied after 3D-PLI measurement. To ensure high\ncorrespondence between both modalities, we address the misalignment of training\ndata using Fourier-based registration methods. In this way, registration can be\nefficiently calculated during training for local image patches of target and\npredicted staining. We demonstrate that the proposed method enables prediction\nof a Cresyl violet staining from 3D-PLI, matching individual cell instances.",
    "pdf_url": "http://arxiv.org/pdf/2505.11394v1",
    "published": "2025-05-16T15:59:15+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11393v2",
    "title": "Diff-Unfolding: A Model-Based Score Learning Framework for Inverse Problems",
    "authors": [
      "Yuanhao Wang",
      "Shirin Shoushtari",
      "Ulugbek S. Kamilov"
    ],
    "abstract": "Diffusion models are extensively used for modeling image priors for inverse\nproblems. We introduce \\emph{Diff-Unfolding}, a principled framework for\nlearning posterior score functions of \\emph{conditional diffusion models} by\nexplicitly incorporating the physical measurement operator into a modular\nnetwork architecture. Diff-Unfolding formulates posterior score learning as the\ntraining of an unrolled optimization scheme, where the measurement model is\ndecoupled from the learned image prior. This design allows our method to\ngeneralize across inverse problems at inference time by simply replacing the\nforward operator without retraining. We theoretically justify our unrolling\napproach by showing that the posterior score can be derived from a composite\nmodel-based optimization formulation. Extensive experiments on image\nrestoration and accelerated MRI show that Diff-Unfolding achieves\nstate-of-the-art performance, improving PSNR by up to 2 dB and reducing LPIPS\nby $22.7\\%$, while being both compact (47M parameters) and efficient (0.72\nseconds per $256 \\times 256$ image). An optimized C++/LibTorch implementation\nfurther reduces inference time to 0.63 seconds, underscoring the practicality\nof our approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.11393v2",
    "published": "2025-05-16T15:57:19+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11392v1",
    "title": "Theory of Quasi-Statically Screened Electron-Polar Optical Phonon Scattering",
    "authors": [
      "Yuji Go",
      "Rajeev Dutt",
      "Neophytos Neophytou"
    ],
    "abstract": "The scattering of electrons with polar optical phonons (POP) is an important\nmechanism that limits electronic transport and determines electron mobility in\npolar materials. This is typically a stronger mechanism compared to non-polar\nacoustic and optical phonon scattering, and of similar strength to the Coulomb\nionized impurity scattering. At high densities, on the other hand, the cloud of\ncharge carriers screens the dipoles that are responsible for POP scattering,\nand weakens the electron-POP scattering strength. However, in contrast to\nionized impurity scattering, for which the well-known Brooks-Herring equation\nprovides the scattering rates with the effect of screening included, for\nscattering with POP there is no such closed-form mathematical expression. In\nthis work, we derive such an expression based on Fermi's Golden Rule, which\nwould prove particularly useful in understanding electronic transport in\ncomplex crystal and complex band structure materials, in which electron-POP\nscattering could dominate electronic transport.",
    "pdf_url": "http://arxiv.org/pdf/2505.11392v1",
    "published": "2025-05-16T15:56:30+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11391v2",
    "title": "LipDiffuser: Lip-to-Speech Generation with Conditional Diffusion Models",
    "authors": [
      "Danilo de Oliveira",
      "Julius Richter",
      "Tal Peer",
      "Timo Gerkmann"
    ],
    "abstract": "We present LipDiffuser, a conditional diffusion model for lip-to-speech\ngeneration synthesizing natural and intelligible speech directly from silent\nvideo recordings. Our approach leverages the magnitude-preserving ablated\ndiffusion model (MP-ADM) architecture as a denoiser model. To effectively\ncondition the model, we incorporate visual features using magnitude-preserving\nfeature-wise linear modulation (MP-FiLM) alongside speaker embeddings. A neural\nvocoder then reconstructs the speech waveform from the generated\nmel-spectrograms. Evaluations on LRS3 and TCD-TIMIT demonstrate that\nLipDiffuser outperforms existing lip-to-speech baselines in perceptual speech\nquality and speaker similarity, while remaining competitive in downstream\nautomatic speech recognition (ASR). These findings are also supported by a\nformal listening experiment. Extensive ablation studies and cross-dataset\nevaluation confirm the effectiveness and generalization capabilities of our\napproach.",
    "pdf_url": "http://arxiv.org/pdf/2505.11391v2",
    "published": "2025-05-16T15:56:07+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.11390v1",
    "title": "IISE PG&E Energy Analytics Challenge 2025: Hourly-Binned Regression Models Beat Transformers in Load Forecasting",
    "authors": [
      "Millend Roy",
      "Vladimir Pyltsov",
      "Yinbo Hu"
    ],
    "abstract": "Accurate electricity load forecasting is essential for grid stability,\nresource optimization, and renewable energy integration. While\ntransformer-based deep learning models like TimeGPT have gained traction in\ntime-series forecasting, their effectiveness in long-term electricity load\nprediction remains uncertain. This study evaluates forecasting models ranging\nfrom classical regression techniques to advanced deep learning architectures\nusing data from the ESD 2025 competition. The dataset includes two years of\nhistorical electricity load data, alongside temperature and global horizontal\nirradiance (GHI) across five sites, with a one-day-ahead forecasting horizon.\nSince actual test set load values remain undisclosed, leveraging predicted\nvalues would accumulate errors, making this a long-term forecasting challenge.\nWe employ (i) Principal Component Analysis (PCA) for dimensionality reduction\nand (ii) frame the task as a regression problem, using temperature and GHI as\ncovariates to predict load for each hour, (iii) ultimately stacking 24 models\nto generate yearly forecasts.\n  Our results reveal that deep learning models, including TimeGPT, fail to\nconsistently outperform simpler statistical and machine learning approaches due\nto the limited availability of training data and exogenous variables. In\ncontrast, XGBoost, with minimal feature engineering, delivers the lowest error\nrates across all test cases while maintaining computational efficiency. This\nhighlights the limitations of deep learning in long-term electricity\nforecasting and reinforces the importance of model selection based on dataset\ncharacteristics rather than complexity. Our study provides insights into\npractical forecasting applications and contributes to the ongoing discussion on\nthe trade-offs between traditional and modern forecasting methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.11390v1",
    "published": "2025-05-16T15:55:34+00:00",
    "categories": [
      "cs.LG",
      "cs.SY",
      "econ.EM",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11389v2",
    "title": "The Poisson Multiplication Formula",
    "authors": [
      "Lorenzo Cristofaro",
      "Giovanni Peccati"
    ],
    "abstract": "We establish necessary and sufficient conditions implying that the product of\n$m\\geq 2$ Poisson functionals, living in a finite sum of Wiener chaoses, is\nsquare-integrable. Our conditions are expressed in terms of iterated add-one\ncost operators, and are obtained through the use of a novel family of\nPoincar\\'e inequalities for almost surely finite random variables, generalizing\nthe recent findings by Trauthwein (2024). When specialized to the case of\nmultiple Wiener-It\\^o integrals, our results yield general multiplication\nformulae on the Poisson space under minimal conditions, naturally expressed in\nterms of partitions and diagrams. Our work addresses several questions left\nopen in a seminal work by Surgailis (1984), and completes a line of research\ninitiated in D\\\"obler and Peccati (2018).",
    "pdf_url": "http://arxiv.org/pdf/2505.11389v2",
    "published": "2025-05-16T15:53:48+00:00",
    "categories": [
      "math.PR",
      "60H07, 60H05, 60E15, 60G55, 60G57"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.17054v1",
    "title": "METHOD: Modular Efficient Transformer for Health Outcome Discovery",
    "authors": [
      "Linglong Qian",
      "Zina Ibrahim"
    ],
    "abstract": "Recent advances in transformer architectures have revolutionised natural\nlanguage processing, but their application to healthcare domains presents\nunique challenges. Patient timelines are characterised by irregular sampling,\nvariable temporal dependencies, and complex contextual relationships that\ndiffer substantially from traditional language tasks. This paper introduces\n\\METHOD~(Modular Efficient Transformer for Health Outcome Discovery), a novel\ntransformer architecture specifically designed to address the challenges of\nclinical sequence modelling in electronic health records. \\METHOD~integrates\nthree key innovations: (1) a patient-aware attention mechanism that prevents\ninformation leakage whilst enabling efficient batch processing; (2) an adaptive\nsliding window attention scheme that captures multi-scale temporal\ndependencies; and (3) a U-Net inspired architecture with dynamic skip\nconnections for effective long sequence processing. Evaluations on the MIMIC-IV\ndatabase demonstrate that \\METHOD~consistently outperforms the state-of-the-art\n\\ETHOS~model, particularly in predicting high-severity cases that require\nurgent clinical intervention. \\METHOD~exhibits stable performance across\nvarying inference lengths, a crucial feature for clinical deployment where\npatient histories vary significantly in length. Analysis of learned embeddings\nreveals that \\METHOD~better preserves clinical hierarchies and relationships\nbetween medical concepts. These results suggest that \\METHOD~represents a\nsignificant advancement in transformer architectures optimised for healthcare\napplications, providing more accurate and clinically relevant predictions\nwhilst maintaining computational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.17054v1",
    "published": "2025-05-16T15:52:56+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11388v1",
    "title": "The Future is Sparse: Embedding Compression for Scalable Retrieval in Recommender Systems",
    "authors": [
      "Petr Kasalický",
      "Martin Spišák",
      "Vojtěch Vančura",
      "Daniel Bohuněk",
      "Rodrigo Alves",
      "Pavel Kordík"
    ],
    "abstract": "Industry-scale recommender systems face a core challenge: representing\nentities with high cardinality, such as users or items, using dense embeddings\nthat must be accessible during both training and inference. However, as\nembedding sizes grow, memory constraints make storage and access increasingly\ndifficult. We describe a lightweight, learnable embedding compression technique\nthat projects dense embeddings into a high-dimensional, sparsely activated\nspace. Designed for retrieval tasks, our method reduces memory requirements\nwhile preserving retrieval performance, enabling scalable deployment under\nstrict resource constraints. Our results demonstrate that leveraging sparsity\nis a promising approach for improving the efficiency of large-scale\nrecommenders. We release our code at https://github.com/recombee/CompresSAE.",
    "pdf_url": "http://arxiv.org/pdf/2505.11388v1",
    "published": "2025-05-16T15:51:52+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11387v1",
    "title": "High brightness, symmetric electron bunch generation in a plasma wakefield accelerator via a radially-polarized plasma photocathode",
    "authors": [
      "James Chappell",
      "Emily Archer",
      "Roman Walczak",
      "Simon Hooker"
    ],
    "abstract": "The plasma photocathode has previously been proposed as a source of\nultra-high-brightness electron bunches within plasma accelerators. Here, the\nscheme is extended by using a radially-polarized ionizing laser pulse to\ngenerate high-charge, high-brightness electron bunches with symmetric\ntransverse emittance. Efficient start-to-end modelling of the scheme, from\nionization and trapping until drive bunch depletion, enables a multi-objective\nBayesian optimisation routine to be performed to understand the performance of\nthe radially-polarized plasma photocathode, quantify the stability of the\nscheme, and explore the fundamental relation between the witness bunch charge\nand its emittance. Comparison of plasma photocathodes driven by radially- and\nlinearly-polarized laser pulses show that the former yields higher brightness\nelectron bunches when operating in the optimally-loaded regime.",
    "pdf_url": "http://arxiv.org/pdf/2505.11387v1",
    "published": "2025-05-16T15:51:28+00:00",
    "categories": [
      "physics.acc-ph",
      "physics.plasm-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11386v2",
    "title": "MutualNeRF: Improve the Performance of NeRF under Limited Samples with Mutual Information Theory",
    "authors": [
      "Zifan Wang",
      "Jingwei Li",
      "Yitang Li",
      "Yunze Liu"
    ],
    "abstract": "This paper introduces MutualNeRF, a framework enhancing Neural Radiance Field\n(NeRF) performance under limited samples using Mutual Information Theory. While\nNeRF excels in 3D scene synthesis, challenges arise with limited data and\nexisting methods that aim to introduce prior knowledge lack theoretical support\nin a unified framework. We introduce a simple but theoretically robust concept,\nMutual Information, as a metric to uniformly measure the correlation between\nimages, considering both macro (semantic) and micro (pixel) levels. For sparse\nview sampling, we strategically select additional viewpoints containing more\nnon-overlapping scene information by minimizing mutual information without\nknowing ground truth images beforehand. Our framework employs a greedy\nalgorithm, offering a near-optimal solution. For few-shot view synthesis, we\nmaximize the mutual information between inferred images and ground truth,\nexpecting inferred images to gain more relevant information from known images.\nThis is achieved by incorporating efficient, plug-and-play regularization\nterms. Experiments under limited samples show consistent improvement over\nstate-of-the-art baselines in different settings, affirming the efficacy of our\nframework.",
    "pdf_url": "http://arxiv.org/pdf/2505.11386v2",
    "published": "2025-05-16T15:50:08+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11385v1",
    "title": "Compendium Manager: a tool for coordination of workflow management instances for bulk data processing in Python",
    "authors": [
      "Richard J. Abdill",
      "Ran Blekhman"
    ],
    "abstract": "Compendium Manager is a command-line tool written in Python to automate the\nprovisioning, launch, and evaluation of bioinformatics pipelines. Although\nworkflow management tools such as Snakemake and Nextflow enable users to\nautomate the processing of samples within a single sequencing project,\nintegrating many datasets in bulk requires launching and monitoring hundreds or\nthousands of pipelines. We present the Compendium Manager, a lightweight\ncommand-line tool to enable launching and monitoring analysis pipelines at\nscale. The tool can gauge progress through a list of projects, load results\ninto a shared database, and record detailed processing metrics for later\nevaluation and reproducibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.11385v1",
    "published": "2025-05-16T15:49:40+00:00",
    "categories": [
      "q-bio.GN",
      "cs.SE",
      "92-04",
      "J.3"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.11384v1",
    "title": "MOSAIK: Multi-Origin Spatial Transcriptomics Analysis and Integration Kit",
    "authors": [
      "Anthony Baptista",
      "Rosamond Nuamah",
      "Ciro Chiappini",
      "Anita Grigoriadis"
    ],
    "abstract": "Spatial transcriptomics (ST) has revolutionised transcriptomics analysis by\npreserving tissue architecture, allowing researchers to study gene expression\nin its native spatial context. However, despite its potential, ST still faces\nsignificant technical challenges. Two major issues include: (1) the integration\nof raw data into coherent and reproducible analysis workflows, and (2) the\naccurate assignment of transcripts to individual cells. To address these\nchallenges, we present MOSAIK, the first fully integrated, end-to-end workflow\nthat supports raw data from both NanoString CosMx Spatial Molecular Imager\n(CosMx) and 10x Genomics Xenium In Situ (Xenium). MOSAIK (Multi-Origin Spatial\nTranscriptomics Analysis and Integration Kit) unifies transcriptomics and\nimaging data into a single Python object based on the spatialdata format. This\nunified structure ensures compatibility with a broad range of Python tools,\nenabling robust quality control and downstream analyses. With MOSAIK, users can\nperform advanced analyses such as re-segmentation (to more accurately assign\ntranscripts to individual cells), cell typing, tissue domain identification,\nand cell-cell communication within a seamless and reproducible Python\nenvironment.",
    "pdf_url": "http://arxiv.org/pdf/2505.11384v1",
    "published": "2025-05-16T15:46:55+00:00",
    "categories": [
      "q-bio.QM"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.11383v1",
    "title": "Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation",
    "authors": [
      "Zihan Wang",
      "Seungjun Lee",
      "Gim Hee Lee"
    ],
    "abstract": "Vision-and-Language Navigation (VLN) is a core task where embodied agents\nleverage their spatial mobility to navigate in 3D environments toward\ndesignated destinations based on natural language instructions. Recently,\nvideo-language large models (Video-VLMs) with strong generalization\ncapabilities and rich commonsense knowledge have shown remarkable performance\nwhen applied to VLN tasks. However, these models still encounter the following\nchallenges when applied to real-world 3D navigation: 1) Insufficient\nunderstanding of 3D geometry and spatial semantics; 2) Limited capacity for\nlarge-scale exploration and long-term environmental memory; 3) Poor\nadaptability to dynamic and changing environments.To address these limitations,\nwe propose Dynam3D, a dynamic layered 3D representation model that leverages\nlanguage-aligned, generalizable, and hierarchical 3D representations as visual\ninput to train 3D-VLM in navigation action prediction. Given posed RGB-D\nimages, our Dynam3D projects 2D CLIP features into 3D space and constructs\nmulti-level 3D patch-instance-zone representations for 3D geometric and\nsemantic understanding with a dynamic and layer-wise update strategy. Our\nDynam3D is capable of online encoding and localization of 3D instances, and\ndynamically updates them in changing environments to provide large-scale\nexploration and long-term memory capabilities for navigation. By leveraging\nlarge-scale 3D-language pretraining and task-specific adaptation, our Dynam3D\nsets new state-of-the-art performance on VLN benchmarks including R2R-CE,\nREVERIE-CE and NavRAG-CE under monocular settings. Furthermore, experiments for\npre-exploration, lifelong memory, and real-world robot validate the\neffectiveness of practical deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.11383v1",
    "published": "2025-05-16T15:46:27+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11382v1",
    "title": "Trees with proper thinness 2",
    "authors": [
      "Flavia Bonomo-Braberman",
      "Ignacio Maqueda",
      "Nina Pardal"
    ],
    "abstract": "The proper thinness of a graph is an invariant that generalizes the concept\nof a proper interval graph. Every graph has a numerical value of proper\nthinness and the graphs with proper thinness~1 are exactly the proper interval\ngraphs. A graph is proper $k$-thin if its vertices can be ordered in such a way\nthat there is a partition of the vertices into $k$ classes satisfying that for\neach triple of vertices $r < s < t$, such that there is an edge between $r$ and\n$t$, it is true that if $r$ and $s$ belong to the same class, then there is an\nedge between $s$ and $t$, and if $s$ and $t$ belong to the same class, then\nthere is an edge between $r$ and $s$. The proper thinness is the smallest value\nof $k$ such that the graph is proper $k$-thin. In this work we focus on the\ncalculation of proper thinness for trees. We characterize trees of proper\nthinness~2, both structurally and by their minimal forbidden induced subgraphs.\nThe characterizations obtained lead to a polynomial-time recognition algorithm.\nWe furthermore show why the structural results obtained for trees of proper\nthinness~2 cannot be straightforwardly generalized to trees of proper\nthinness~3.",
    "pdf_url": "http://arxiv.org/pdf/2505.11382v1",
    "published": "2025-05-16T15:44:17+00:00",
    "categories": [
      "math.CO",
      "cs.DM",
      "05C75"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11381v2",
    "title": "On the complementary Arthur representations and unitary dual for p-adic classical groups",
    "authors": [
      "Alexander Hazeltine",
      "Dihua Jiang",
      "Baiying Liu",
      "Chi-Heng Lo",
      "Qing Zhang"
    ],
    "abstract": "In [HJLLZ24], we proposed a new conjecture on the structure of the unitary\ndual of connected reductive groups over non-Archimedean local fields of\ncharacteristic zero based on their Arthur representations and verified it for\nall the known cases on the unitary dual problem. One step towards this\nconjecture involves the question whether certain complementary Arthur\nrepresentations are unitary. In this paper, we give an explicit\ncharacterization of the complementary Arthur representations for symplectic and\nsplit odd special orthogonal groups. As applications, we obtain interesting\nconstraints on local components of irreducible self-dual cuspidal automorphic\nrepresentations of GL(N), especially when N=2,3.",
    "pdf_url": "http://arxiv.org/pdf/2505.11381v2",
    "published": "2025-05-16T15:43:59+00:00",
    "categories": [
      "math.RT",
      "math.NT"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11380v1",
    "title": "On the Interconnections of Calibration, Quantification, and Classifier Accuracy Prediction under Dataset Shift",
    "authors": [
      "Alejandro Moreo"
    ],
    "abstract": "When the distribution of the data used to train a classifier differs from\nthat of the test data, i.e., under dataset shift, well-established routines for\ncalibrating the decision scores of the classifier, estimating the proportion of\npositives in a test sample, or estimating the accuracy of the classifier,\nbecome particularly challenging. This paper investigates the interconnections\namong three fundamental problems, calibration, quantification, and classifier\naccuracy prediction, under dataset shift conditions. Specifically, we prove\ntheir equivalence through mutual reduction, i.e., we show that access to an\noracle for any one of these tasks enables the resolution of the other two.\nBased on these proofs, we propose new methods for each problem based on direct\nadaptations of well-established methods borrowed from the other disciplines.\nOur results show such methods are often competitive, and sometimes even surpass\nthe performance of dedicated approaches from each discipline. The main goal of\nthis paper is to fostering cross-fertilization among these research areas,\nencouraging the development of unified approaches and promoting synergies\nacross the fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.11380v1",
    "published": "2025-05-16T15:42:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11379v1",
    "title": "A computational system to handle the orthographic layer of tajwid in contemporary Quranic Orthography",
    "authors": [
      "Alicia González Martínez"
    ],
    "abstract": "Contemporary Quranic Orthography (CQO) relies on a precise system of phonetic\nnotation that can be traced back to the early stages of Islam, when the Quran\nwas mainly oral in nature and the first written renderings of it served as\nmemory aids for this oral tradition. The early systems of diacritical marks\ncreated on top of the Quranic Consonantal Text (QCT) motivated the creation and\nfurther development of a fine-grained system of phonetic notation that\nrepresented tajwid-the rules of recitation. We explored the systematicity of\nthe rules of tajwid, as they are encountered in the Cairo Quran, using a fully\nand accurately encoded digital edition of the Quranic text. For this purpose,\nwe developed a python module that can remove or add the orthographic layer of\ntajwid from a Quranic text in CQO. The interesting characteristic of these two\nsets of rules is that they address the complete Quranic text of the Cairo\nQuran, so they can be used as precise witnesses to study its phonetic and\nprosodic processes. From a computational point of view, the text of the Cairo\nQuran can be used as a linchpin to align and compare Quranic manuscripts, due\nto its richness and completeness. This will let us create a very powerful\nframework to work with the Arabic script, not just within an isolated text, but\nautomatically exploring a specific textual phenomenon in other connected\nmanuscripts. Having all the texts mapped among each other can serve as a\npowerful tool to study the nature of the notation systems of diacritics added\nto the consonantal skeleton.",
    "pdf_url": "http://arxiv.org/pdf/2505.11379v1",
    "published": "2025-05-16T15:41:51+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11378v2",
    "title": "Machine Learning Approaches to Vocal Register Classification in Contemporary Male Pop Music",
    "authors": [
      "Alexander Kim",
      "Charlotte Botha"
    ],
    "abstract": "For singers of all experience levels, one of the most daunting challenges in\nlearning technical repertoire is navigating placement and vocal register in and\naround the passagio (passage between chest voice and head voice registers).\nParticularly in pop music, where a single artist may use a variety of timbre's\nand textures to achieve a desired quality, it can be difficult to identify what\nvocal register within the vocal range a singer is using. This paper presents\ntwo methods for classifying vocal registers in an audio signal of male pop\nmusic through the analysis of textural features of mel-spectrogram images.\nAdditionally, we will discuss the practical integration of these models for\nvocal analysis tools, and introduce a concurrently developed software called\nAVRA which stands for Automatic Vocal Register Analysis. Our proposed methods\nachieved consistent classification of vocal register through both Support\nVector Machine (SVM) and Convolutional Neural Network (CNN) models, which\nsupports the promise of more robust classification possibilities across more\nvoice types and genres of singing.",
    "pdf_url": "http://arxiv.org/pdf/2505.11378v2",
    "published": "2025-05-16T15:41:28+00:00",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.11377v1",
    "title": "TensorMixedStates: a Julia library for simulating pure and mixed quantum states using matrix product states",
    "authors": [
      "Jérôme Houdayer",
      "Grégoire Misguich"
    ],
    "abstract": "We introduce TensorMixedStates, a Julia library built on top of ITensor which\nallows the simulation of quantum systems in presence of dissipation using\nmatrix product states (MPS). It offers three key features: i) it implements the\nMPS representation for mixed states along with associated operations, in\nparticular the time evolution according to a Lindblad equation or discrete time\nevolution using non-unitary gates (quantum channels), ii) it is based on\nITensor, which has proven its effectiveness and which gives access to efficient\nlow-level tensor manipulation as well state-of-the-art algorithms (like DMRG,\nTDVP, quantum numbers conservation and automated parallelization), finally iii)\nit presents a user-friendly interface allowing writing sophisticated\nsimulations for pure and mixed quantum states in a few lines of code.",
    "pdf_url": "http://arxiv.org/pdf/2505.11377v1",
    "published": "2025-05-16T15:41:05+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.str-el"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11376v1",
    "title": "Decoupling Collision Avoidance in and for Optimal Control using Least-Squares Support Vector Machines",
    "authors": [
      "Dries Dirckx",
      "Wilm Decré",
      "Jan Swevers"
    ],
    "abstract": "This paper details an approach to linearise differentiable but non-convex\ncollision avoidance constraints tailored to convex shapes. It revisits\nintroducing differential collision avoidance constraints for convex objects\ninto an optimal control problem (OCP) using the separating hyperplane theorem.\nBy framing this theorem as a classification problem, the hyperplanes are\neliminated as optimisation variables from the OCP. This effectively transforms\nnon-convex constraints into linear constraints. A bi-level algorithm computes\nthe hyperplanes between the iterations of an optimisation solver and\nsubsequently embeds them as parameters into the OCP. Experiments demonstrate\nthe approach's favourable scalability towards cluttered environments and its\napplicability to various motion planning approaches. It decreases trajectory\ncomputation times between 50\\% and 90\\% compared to a state-of-the-art approach\nthat directly includes the hyperplanes as variables in the optimal control\nproblem.",
    "pdf_url": "http://arxiv.org/pdf/2505.11376v1",
    "published": "2025-05-16T15:41:01+00:00",
    "categories": [
      "math.OC",
      "cs.RO"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11375v1",
    "title": "Anti-aliasing of neural distortion effects via model fine tuning",
    "authors": [
      "Alistair Carson",
      "Alec Wright",
      "Stefan Bilbao"
    ],
    "abstract": "Neural networks have become ubiquitous with guitar distortion effects\nmodelling in recent years. Despite their ability to yield perceptually\nconvincing models, they are susceptible to frequency aliasing when driven by\nhigh frequency and high gain inputs. Nonlinear activation functions create both\nthe desired harmonic distortion and unwanted aliasing distortion as the\nbandwidth of the signal is expanded beyond the Nyquist frequency. Here, we\npresent a method for reducing aliasing in neural models via a teacher-student\nfine tuning approach, where the teacher is a pre-trained model with its weights\nfrozen, and the student is a copy of this with learnable parameters. The\nstudent is fine-tuned against an aliasing-free dataset generated by passing\nsinusoids through the original model and removing non-harmonic components from\nthe output spectra. Our results show that this method significantly suppresses\naliasing for both long-short-term-memory networks (LSTM) and temporal\nconvolutional networks (TCN). In the majority of our case studies, the\nreduction in aliasing was greater than that achieved by two times oversampling.\nOne side-effect of the proposed method is that harmonic distortion components\nare also affected. This adverse effect was found to be model-dependent, with\nthe LSTM models giving the best balance between anti-aliasing and preserving\nthe perceived similarity to an analog reference device.",
    "pdf_url": "http://arxiv.org/pdf/2505.11375v1",
    "published": "2025-05-16T15:40:33+00:00",
    "categories": [
      "eess.AS",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.11374v1",
    "title": "A magnetic field detection in the massive O-type bright giant 63 Oph",
    "authors": [
      "James A. Barron",
      "Gregg A. Wade",
      "Gonzalo Holgado",
      "Sergio Simón-Díaz"
    ],
    "abstract": "Surface magnetic fields are detected in less than $10\\%$ of the massive\nO-type star population and even less frequently among `old' massive stars\napproaching the terminal-age main sequence (TAMS). It is unclear to what extent\nthe rarity of magnetic detections in massive stars near the TAMS is due to\nmagnetic field decay or observational biases. We report the detection of a weak\nsurface magnetic field in the O-type giant 63~Oph\n($T_{\\mathrm{eff}}=35.0\\pm0.3\\,$kK, $\\log g=3.51\\pm0.03$) from new ESPaDOnS\ncircularly polarized spectra. The mean longitudinal field strength associated\nwith the magnetic detection is $\\langle B_{z}\\rangle=84\\pm14\\,$G, which we use\nto set a lower limit on the dipolar field strength of\n$B_{\\mathrm{p}}\\geq300\\pm50\\,$G. We report Balmer line equivalent widths (EW)\nand radial velocity (RV) measurements from the analysis of spectra primarily\nobtained by the IACOB project with the FEROS, FIES and HERMES spectrographs. We\nidentify a dominant period of $\\sim19.8\\,$d in the EWs which we attribute to\nthe effects of a rotating magnetosphere under the Oblique Rotator Model. We do\nnot identify any coherent signals in a time-series analysis of archival\nHipparcos, ASAS-SN and K2 photometry. Our findings show that 63~Oph may be a\nrare link between strongly magnetic massive stars detected on or near the\nzero-age main sequence and weakly-magnetic O-type supergiants. Additional\nobservations are needed to fully constrain 63~Oph's magnetic field geometry and\nmagnetospheric properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.11374v1",
    "published": "2025-05-16T15:40:20+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11373v2",
    "title": "A note on hypergraph extensions of Mantel's theorem",
    "authors": [
      "Jie Ma",
      "Tianming Zhu"
    ],
    "abstract": "Chao and Yu introduced an entropy method for hypergraph Tur\\'an problems, and\nused it to show that the family of $\\lfloor k/2\\rfloor$ $k$-uniform tents have\nTur\\'an density $k!/k^k$. Il'kovi\\v{c} and Yan improved this by reducing to a\nsubfamily of $\\lceil k/e\\rceil$ tents. In this note, enhancing\nIl'kovi\\v{c}-Yan's result, we give a significantly shorter entropy proof, with\noptimal bounds within this framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.11373v2",
    "published": "2025-05-16T15:36:09+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11372v1",
    "title": "Increasing delay as a strategy to prove stability",
    "authors": [
      "Ziyad AlSharawi",
      "Jose S. Cánovas"
    ],
    "abstract": "We consider difference equations of the form\n$x_{n+1}=F_0(x_n,\\ldots,x_{n-k+1}),$ and increase the delay through a process\nof successive substitutions to obtain a sequence of systems\n$y_{n+1}=F_j(x_{n-j},\\ldots,x_{n-k-j+1}),\\; j=0,1,\\ldots$. We call this process\n\\emph{the expansion strategy} and use it to establish novel results that enable\nus to prove stability. When the map $F_0$ is sufficiently smooth and has a\nhyperbolic fixed point, we show the fixed point is locally asymptotically\nstable if and only if $\\|\\nabla F_j\\|_1<1$ for some finite number $j$. Our\nlocal stability results complement recent results obtained on Schur stability,\nand they can provide an alternative to the highly acclaimed Jury's algorithm.\nAlso, we show the effectiveness of the expansion strategy in obtaining global\nstability results. Global stability results are obtained by integrating the\nexpansion strategy with the embedding technique. Finally, we give illustrative\nexamples to show the results' practical applicability across various\ndiscrete-time dynamical systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11372v1",
    "published": "2025-05-16T15:35:13+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.11371v1",
    "title": "Compactifying linear optical unitaries using multiport beamsplitters",
    "authors": [
      "P. A. Ameen Yasir",
      "Peter van Loock"
    ],
    "abstract": "We show that any $N$-dimensional unitary matrix can be realized using a\nfinite sequence of concatenated identical multiport beamsplitters. Our\nconstruction is based on a Lie group theorem and is explicitly demonstrated for\nthe two- and three-dimensional cases. We further establish that the widely used\nClements decomposition naturally arises as a special case of this general\nframework. As an application, we present a reconfigurable linear optical\ncircuit that implements a three-dimensional unitary emerging in the unambiguous\ndiscrimination of two nonorthogonal qubit states.",
    "pdf_url": "http://arxiv.org/pdf/2505.11371v1",
    "published": "2025-05-16T15:34:37+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11370v3",
    "title": "Understanding Nonlinear Implicit Bias via Region Counts in Input Space",
    "authors": [
      "Jingwei Li",
      "Jing Xu",
      "Zifan Wang",
      "Huishuai Zhang",
      "Jingzhao Zhang"
    ],
    "abstract": "One explanation for the strong generalization ability of neural networks is\nimplicit bias. Yet, the definition and mechanism of implicit bias in non-linear\ncontexts remains little understood. In this work, we propose to characterize\nimplicit bias by the count of connected regions in the input space with the\nsame predicted label. Compared with parameter-dependent metrics (e.g., norm or\nnormalized margin), region count can be better adapted to nonlinear,\noverparameterized models, because it is determined by the function mapping and\nis invariant to reparametrization. Empirically, we found that small region\ncounts align with geometrically simple decision boundaries and correlate well\nwith good generalization performance. We also observe that good hyper-parameter\nchoices such as larger learning rates and smaller batch sizes can induce small\nregion counts. We further establish the theoretical connections and explain how\nlarger learning rate can induce small region counts in neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11370v3",
    "published": "2025-05-16T15:34:19+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11369v4",
    "title": "Compact, Large-Scale Photonic Neurons by Modulation-and-Weight Microring Resonators",
    "authors": [
      "Weipeng Zhang",
      "Yuxin Wang",
      "Joshua C. Lederman",
      "Bhavin J. Shastri",
      "Paul R. Prucnal"
    ],
    "abstract": "Fabrication imperfections, spatial constraints, and prohibitive costs\ncollectively impede the scalability of neuromorphic photonics. In this work, we\nintroduce a large-scale, compact photonic neuron in which each microring\nperforms modulation and weighting simultaneously. This dual functionality is\nrealized by leveraging both the carrier effect and thermal tunability, thereby\nmerging modulation and weighting to conserve on-chip area, enhancing tuning\nefficiency, and capitalizing on wavelength-division multiplexing (WDM) for\nscalable implementations. In addition, we investigated a range of\nconfigurations for the proposed neuron to better tailor its behavior to various\ncomputational tasks. To illustrate the adaptability of the system's tasks, we\nexplore both spatial and temporal domains, highlighting its versatility through\ntwo representative tasks: image processing and, for the first time, financial\ntime series analysis, which represents a promising new frontier for\nneuromorphic photonics. These findings underscore the considerable promise of\nphotonic computing in addressing a breadth of real-world challenges,\nparticularly under escalating demands for both scalability and flexibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.11369v4",
    "published": "2025-05-16T15:32:25+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.11368v2",
    "title": "GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents",
    "authors": [
      "Lingxiao Diao",
      "Xinyue Xu",
      "Wanxuan Sun",
      "Cheng Yang",
      "Zhuosheng Zhang"
    ],
    "abstract": "Large language models (LLMs) have been widely deployed as autonomous agents\ncapable of following user instructions and making decisions in real-world\napplications. Previous studies have made notable progress in benchmarking the\ninstruction following capabilities of LLMs in general domains, with a primary\nfocus on their inherent commonsense knowledge. Recently, LLMs have been\nincreasingly deployed as domain-oriented agents, which rely on domain-oriented\nguidelines that may conflict with their commonsense knowledge. These guidelines\nexhibit two key characteristics: they consist of a wide range of\ndomain-oriented rules and are subject to frequent updates. Despite these\nchallenges, the absence of comprehensive benchmarks for evaluating the\ndomain-oriented guideline following capabilities of LLMs presents a significant\nobstacle to their effective assessment and further development. In this paper,\nwe introduce GuideBench, a comprehensive benchmark designed to evaluate\nguideline following performance of LLMs. GuideBench evaluates LLMs on three\ncritical aspects: (i) adherence to diverse rules, (ii) robustness to rule\nupdates, and (iii) alignment with human preferences. Experimental results on a\nrange of LLMs indicate substantial opportunities for improving their ability to\nfollow domain-oriented guidelines.",
    "pdf_url": "http://arxiv.org/pdf/2505.11368v2",
    "published": "2025-05-16T15:32:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11367v1",
    "title": "The Effects of Moral Framing on Online Fundraising Outcomes: Evidence from GoFundMe Campaigns",
    "authors": [
      "Ji Eun Kim",
      "Libby Hemphill"
    ],
    "abstract": "This study examines the impact of moral framing on fundraising outcomes,\nincluding both monetary and social support, by analyzing a dataset of 14,088\ncampaigns posted on GoFundMe. We focused on three moral frames: care, fairness,\nand (ingroup) loyalty, and measured their presence in campaign appeals. Our\nresults show that campaigns in the Emergency category are most influenced by\nmoral framing. Generally, negatively framing appeals by emphasizing harm and\nunfairness effectively attracts more donations and comments from supporters.\nHowever, this approach can have a downside, as it may lead to a decrease in the\naverage donation amount per donor. Additionally, we found that loyalty framing\nwas positively associated with receiving more donations and messages across all\nfundraising categories. This research extends existing literature on framing\nand communication strategies related to fundraising and their impact. We also\npropose practical implications for designing features of online fundraising\nplatforms to better support both fundraisers and supporters.",
    "pdf_url": "http://arxiv.org/pdf/2505.11367v1",
    "published": "2025-05-16T15:31:56+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11366v1",
    "title": "Learning Multimodal AI Algorithms for Amplifying Limited User Input into High-dimensional Control Space",
    "authors": [
      "Ali Rabiee",
      "Sima Ghafoori",
      "MH Farhadi",
      "Robert Beyer",
      "Xiangyu Bai",
      "David J Lin",
      "Sarah Ostadabbas",
      "Reza Abiri"
    ],
    "abstract": "Current invasive assistive technologies are designed to infer\nhigh-dimensional motor control signals from severely paralyzed patients.\nHowever, they face significant challenges, including public acceptance, limited\nlongevity, and barriers to commercialization. Meanwhile, noninvasive\nalternatives often rely on artifact-prone signals, require lengthy user\ntraining, and struggle to deliver robust high-dimensional control for dexterous\ntasks. To address these issues, this study introduces a novel human-centered\nmultimodal AI approach as intelligent compensatory mechanisms for lost motor\nfunctions that could potentially enable patients with severe paralysis to\ncontrol high-dimensional assistive devices, such as dexterous robotic arms,\nusing limited and noninvasive inputs. In contrast to the current\nstate-of-the-art (SoTA) noninvasive approaches, our context-aware, multimodal\nshared-autonomy framework integrates deep reinforcement learning algorithms to\nblend limited low-dimensional user input with real-time environmental\nperception, enabling adaptive, dynamic, and intelligent interpretation of human\nintent for complex dexterous manipulation tasks, such as pick-and-place. The\nresults from our ARAS (Adaptive Reinforcement learning for Amplification of\nlimited inputs in Shared autonomy) trained with synthetic users over 50,000\ncomputer simulation episodes demonstrated the first successful implementation\nof the proposed closed-loop human-in-the-loop paradigm, outperforming the SoTA\nshared autonomy algorithms. Following a zero-shot sim-to-real transfer, ARAS\nwas evaluated on 23 human subjects, demonstrating high accuracy in dynamic\nintent detection and smooth, stable 3D trajectory control for dexterous\npick-and-place tasks. ARAS user study achieved a high task success rate of\n92.88%, with short completion times comparable to those of SoTA invasive\nassistive technologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11366v1",
    "published": "2025-05-16T15:31:40+00:00",
    "categories": [
      "cs.RO",
      "cs.HC",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11365v4",
    "title": "Phare: A Safety Probe for Large Language Models",
    "authors": [
      "Pierre Le Jeune",
      "Benoît Malézieux",
      "Weixuan Xiao",
      "Matteo Dora"
    ],
    "abstract": "Ensuring the safety of large language models (LLMs) is critical for\nresponsible deployment, yet existing evaluations often prioritize performance\nover identifying failure modes. We introduce Phare, a multilingual diagnostic\nframework to probe and evaluate LLM behavior across three critical dimensions:\nhallucination and reliability, social biases, and harmful content generation.\nOur evaluation of 17 state-of-the-art LLMs reveals patterns of systematic\nvulnerabilities across all safety dimensions, including sycophancy, prompt\nsensitivity, and stereotype reproduction. By highlighting these specific\nfailure modes rather than simply ranking models, Phare provides researchers and\npractitioners with actionable insights to build more robust, aligned, and\ntrustworthy language systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11365v4",
    "published": "2025-05-16T15:31:08+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01982v2",
    "title": "Music Interpretation and Emotion Perception: A Computational and Neurophysiological Investigation",
    "authors": [
      "Vassilis Lyberatos",
      "Spyridon Kantarelis",
      "Ioanna Zioga",
      "Christina Anagnostopoulou",
      "Giorgos Stamou",
      "Anastasia Georgaki"
    ],
    "abstract": "This study investigates emotional expression and perception in music\nperformance using computational and neurophysiological methods. The influence\nof different performance settings, such as repertoire, diatonic modal etudes,\nand improvisation, as well as levels of expressiveness, on performers'\nemotional communication and listeners' reactions is explored. Professional\nmusicians performed various tasks, and emotional annotations were provided by\nboth performers and the audience. Audio analysis revealed that expressive and\nimprovisational performances exhibited unique acoustic features, while emotion\nanalysis showed stronger emotional responses. Neurophysiological measurements\nindicated greater relaxation in improvisational performances. This multimodal\nstudy highlights the significance of expressivity in enhancing emotional\ncommunication and audience engagement.",
    "pdf_url": "http://arxiv.org/pdf/2506.01982v2",
    "published": "2025-05-16T15:30:38+00:00",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11364v1",
    "title": "APE: An analytical protostellar environment to provide physical conditions to chemical models and synthetic observations",
    "authors": [
      "Pierre Marchand",
      "Audrey Coutens",
      "Antoine Espagnet",
      "Fernando Cruz-Sáenz de Miera",
      "Jean-Christophe Loison",
      "Valentine Wakelam"
    ],
    "abstract": "Chemical modeling and synthetic observations are powerful methods to\ninterpret observations, both requiring a knowledge of the physical conditions.\nIn this paper, we present the Analytical Protostellar Environment (APE) code,\nwhich aims at making chemical simulations and synthetic observations\naccessible. APE contains a physical model of protostellar evolution (including\nthe central object, the envelope, the protoplanetary disk and the outflow) as\nwell as interfaces to publicly available codes to perform chemical simulations,\nradiative transfer calculations, and synthetic interferometry imaging. APE\nproduces density and temperature maps of protostellar systems. The code can\nalso follow individual particles throughout their journey in a collapsing core.\nAPE includes a treatment of the dust grain size-distribution to compute\nopacities self-consistently for subsequent radiative transfer. We show an\nexample of application of APE by computing chemical abundance maps of CO, CN,\nCS, H2CO, and CH3OH in a Class I protostellar system. We also performed\nsynthetic ALMA observations of their molecular emission assuming an edge-on\nsource inclination. The moment 0 maps of CO, CS, and H2CO display an X-shaped\nemission similar to what is observed toward the Class I source IRAS 04302+2247.",
    "pdf_url": "http://arxiv.org/pdf/2505.11364v1",
    "published": "2025-05-16T15:30:28+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11363v1",
    "title": "Upper moderate deviation probabilities for the maximum of branching Brownian motion",
    "authors": [
      "Louis Chataignier"
    ],
    "abstract": "It is known from~\\cite{Bramson1983} that the maximum of branching Brownian\nmotion at time $t$ is asymptotically around an explicit function $m_t$, which\ninvolves a first ballistic order and a logarithmic correction. In this paper,\nwe give an asymptotic equivalent for its upper moderate deviation probability,\nthat is, the probability that the maximum achieves $m_t + x_t$ at time $t$,\nwhere $1 \\ll x_t \\ll t$. We adopt a probabilistic approach that employs a\nmodified version of the second moment method.",
    "pdf_url": "http://arxiv.org/pdf/2505.11363v1",
    "published": "2025-05-16T15:30:09+00:00",
    "categories": [
      "math.PR",
      "60J80, 60F10"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11361v2",
    "title": "Magnetic dipole-dipole transition for scintillation quenching",
    "authors": [
      "Zhe Wang"
    ],
    "abstract": "A magnetic dipole-dipole interaction is proposed as a scintillation quenching\nmechanism. The interaction rate follows $R^{-6}$ as the electric dipole-dipole\ninteraction in F$\\mathrm{\\ddot{o}}$ster resonance energy transfer theory. The\nproposed mechanism causes a long-range resonance energy transfer, and the\nresonance condition is that the spins of donor and acceptor electrons both\nflip, and the energy level differences are the same. When oxygen or organic\nmolecules including heavy elements are dissolved in a liquid scintillator,\nthese requirements are easier to satisfy. The proposal in the paper adds a new\napproach for scintillation quenching in liquid scintillators.",
    "pdf_url": "http://arxiv.org/pdf/2505.11361v2",
    "published": "2025-05-16T15:28:56+00:00",
    "categories": [
      "physics.ins-det",
      "physics.chem-ph"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.11362v1",
    "title": "Channel coding against quantum jammers via minimax",
    "authors": [
      "Michael X. Cao",
      "Yongsheng Yao",
      "Mario Berta"
    ],
    "abstract": "We introduce a minimax approach for characterizing the capacities of fully\nquantum arbitrarily varying channels (FQAVCs) under different shared resource\nmodels. In contrast to previous methods, our technique avoids de Finetti-type\nreductions, allowing us to treat quantum jammers with infinite-dimensional\nsystems. Consequently, we show that the entanglement-assisted and\nshared-randomness-assisted capacities of FQAVCs match those of the\ncorresponding compound channels, even in the presence of general quantum\nadversaries.",
    "pdf_url": "http://arxiv.org/pdf/2505.11362v1",
    "published": "2025-05-16T15:28:56+00:00",
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11360v1",
    "title": "Efficient End-to-End Learning for Decision-Making: A Meta-Optimization Approach",
    "authors": [
      "Rares Cristian",
      "Pavithra Harsha",
      "Georgia Perakis",
      "Brian Quanz"
    ],
    "abstract": "End-to-end learning has become a widely applicable and studied problem in\ntraining predictive ML models to be aware of their impact on downstream\ndecision-making tasks. These end-to-end models often outperform traditional\nmethods that separate training from the optimization and only myopically focus\non prediction error. However, the computational complexity of end-to-end\nframeworks poses a significant challenge, particularly for large-scale\nproblems. While training an ML model using gradient descent, each time we need\nto compute a gradient we must solve an expensive optimization problem. We\npresent a meta-optimization method that learns efficient algorithms to\napproximate optimization problems, dramatically reducing computational overhead\nof solving the decision problem in general, an aspect we leverage in the\ntraining within the end-to-end framework. Our approach introduces a neural\nnetwork architecture that near-optimally solves optimization problems while\nensuring feasibility constraints through alternate projections. We prove\nexponential convergence, approximation guarantees, and generalization bounds\nfor our learning method. This method offers superior computational efficiency,\nproducing high-quality approximations faster and scaling better with problem\nsize compared to existing techniques. Our approach applies to a wide range of\noptimization problems including deterministic, single-stage as well as\ntwo-stage stochastic optimization problems. We illustrate how our proposed\nmethod applies to (1) an electricity generation problem using real data from an\nelectricity routing company coordinating the movement of electricity throughout\n13 states, (2) a shortest path problem with a computer vision task of\npredicting edge costs from terrain maps, (3) a two-stage multi-warehouse\ncross-fulfillment newsvendor problem, as well as a variety of other\nnewsvendor-like problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11360v1",
    "published": "2025-05-16T15:27:50+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11359v1",
    "title": "LGBQPC: Local Granular-Ball Quality Peaks Clustering",
    "authors": [
      "Zihang Jia",
      "Zhen Zhang",
      "Witold Pedrycz"
    ],
    "abstract": "The density peaks clustering (DPC) algorithm has attracted considerable\nattention for its ability to detect arbitrarily shaped clusters based on a\nsimple yet effective assumption. Recent advancements integrating granular-ball\n(GB) computing with DPC have led to the GB-based DPC (GBDPC) algorithm, which\nimproves computational efficiency. However, GBDPC demonstrates limitations when\nhandling complex clustering tasks, particularly those involving data with\ncomplex manifold structures or non-uniform density distributions. To overcome\nthese challenges, this paper proposes the local GB quality peaks clustering\n(LGBQPC) algorithm, which offers comprehensive improvements to GBDPC in both GB\ngeneration and clustering processes based on the principle of justifiable\ngranularity (POJG). Firstly, an improved GB generation method, termed GB-POJG+,\nis developed, which systematically refines the original GB-POJG in four key\naspects: the objective function, termination criterion for GB division,\ndefinition of abnormal GB, and granularity level adaptation strategy. GB-POJG+\nsimplifies parameter configuration by requiring only a single penalty\ncoefficient and ensures high-quality GB generation while maintaining the number\nof generated GBs within an acceptable range. In the clustering phase, two key\ninnovations are introduced based on the GB k-nearest neighbor graph: relative\nGB quality for density estimation and geodesic distance for GB distance metric.\nThese modifications substantially improve the performance of GBDPC on datasets\nwith complex manifold structures or non-uniform density distributions.\nExtensive numerical experiments on 40 benchmark datasets, including both\nsynthetic and publicly available datasets, validate the superior performance of\nthe proposed LGBQPC algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.11359v1",
    "published": "2025-05-16T15:26:02+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11358v1",
    "title": "Universality of noise-induced transitions in nonlinear voter models",
    "authors": [
      "Jaume Llabrés",
      "Maxi San Miguel",
      "Raúl Toral"
    ],
    "abstract": "We analyze the universality classes of phase transitions in a variety of\nnonlinear voter models. By mapping several models with symmetric absorbing\nstates onto a canonical model introduced in previous studies, we confirm that\nthey exhibit a Generalized Voter (GV) transition. We then propose a canonical\nmean-field model that extends the original formulation by incorporating a noise\nterm that eliminates the absorbing states. This generalization gives rise to a\nphase diagram featuring two distinct types of phase transitions: a continuous\nIsing transition and a discontinuous transition we call Modified Generalized\nVoter (MGV). These two transition lines converge at a tricritical point. We map\ndiverse noisy nonlinear voter models onto this extended canonical form. Using\nfinite-size scaling techniques above and below the upper critical dimension, we\nshow that the continuous transition of these models belongs to the Ising\nuniversality class in their respective dimensionality. We also find universal\nbehavior at the tricitical point. Our results provide a unifying framework for\nclassifying phase transitions in stochastic models of opinion dynamics with\nboth nonlinearity and noise.",
    "pdf_url": "http://arxiv.org/pdf/2505.11358v1",
    "published": "2025-05-16T15:25:36+00:00",
    "categories": [
      "physics.soc-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11357v1",
    "title": "The systemic recoil velocity distribution and the scale height of isolated millisecond pulsar systems: Implications on neutron star retention fractions in star clusters",
    "authors": [
      "Hao Ding"
    ],
    "abstract": "The systemic recoil velocity ($v_\\mathrm{sys}$) distribution of millisecond\npulsars (MSPs) is essential for understanding the MSP formation and estimating\nthe retention fractions of MSPs in star clusters, which can potentially be\ndetermined with astrometric studies that take into account MSPs' long-term\ndynamic evolution and the scarcity of radial velocity measurements. We compiled\n65 isolated (or field) MSP systems (including lone MSPs) that are well\nastrometrically determined, and calculated their transverse peculiar (or space)\nvelocities $\\boldsymbol{v}_\\perp$ and Galactic heights $z$. We find that the\nobserved Galactic-longitude components $v_\\mathrm{l}$ of $\\boldsymbol{v}_\\perp$\ncan be well described by a linear combination of three normal distributions.\nAssuming that 1) $v_\\mathrm{l}$ are statistically stable over time (the\n\"stable-$v_\\mathrm{l}$\" assumption), and 2) $\\boldsymbol{v}_\\mathrm{sys}$\ndirections are uniformly distributed (the\n\"isotropic-$\\boldsymbol{v}_\\mathrm{sys}$\" assumption), the MSP $v_\\mathrm{sys}$\ndistribution can be approximated by a linear combination of three Maxwellian\ncomponents. Our dynamical population synthesis analysis based on the derived\n$v_\\mathrm{sys}$ distribution verified the \"stable-$v_\\mathrm{l}$\" assumption\nin the parameter space of this work, and estimated the initial and the current\nGalaxy-wide scale heights of isolated MSP systems to be about 0.32 kpc and 0.66\nkpc, respectively. According to the MSP $v_\\mathrm{sys}$ distribution,\n$\\sim13$% of all the MSPs born in a globular cluster (GC) with the nominal 50\n$\\mathrm{km~s^{-1}}$ central escape velocity can be retained. Therefore, the\n$v_\\mathrm{sys}$ distribution of isolated MSP systems may account for the high\nnumber of MSPs discovered in GCs, which implies that MSPs in star clusters may\nfollow the same formation channel(s) as isolated MSP systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11357v1",
    "published": "2025-05-16T15:23:58+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11356v2",
    "title": "Fractal Graph Contrastive Learning",
    "authors": [
      "Nero Z. Li",
      "Xuehao Zhai",
      "Zhichao Shi",
      "Boshen Shi",
      "Xuhui Jiang"
    ],
    "abstract": "While Graph Contrastive Learning (GCL) has attracted considerable attention\nin the field of graph self-supervised learning, its performance heavily relies\non data augmentations that are expected to generate semantically consistent\npositive pairs. Existing strategies typically resort to random perturbations or\nlocal structure preservation, yet lack explicit control over global structural\nconsistency between augmented views. To address this limitation, we propose\nFractal Graph Contrastive Learning (FractalGCL), a theory-driven framework that\nleverages fractal self-similarity to enforce global topological coherence.\nFractalGCL introduces two key innovations: a renormalisation-based augmentation\nthat generates structurally aligned positive views via box coverings; and a\nfractal-dimension-aware contrastive loss that aligns graph embeddings according\nto their fractal dimensions. While combining the two innovations markedly\nboosts graph-representation quality, it also adds non-trivial computational\noverhead. To mitigate the computational overhead of fractal dimension\nestimation, we derive a one-shot estimator by proving that the dimension\ndiscrepancy between original and renormalised graphs converges weakly to a\ncentred Gaussian distribution. This theoretical insight enables a reduction in\ndimension computation cost by an order of magnitude, cutting overall training\ntime by approximately 61%. The experiments show that FractalGCL not only\ndelivers state-of-the-art results on standard benchmarks but also outperforms\ntraditional baselines on traffic networks by an average margin of about\nremarkably 7%. Codes are available at\n(https://anonymous.4open.science/r/FractalGCL-0511).",
    "pdf_url": "http://arxiv.org/pdf/2505.11356v2",
    "published": "2025-05-16T15:19:10+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11355v1",
    "title": "STRIDE: Sparse Techniques for Regression in Deep Gaussian Processes",
    "authors": [
      "Simon Urbainczyk",
      "Aretha L. Teckentrup",
      "Jonas Latz"
    ],
    "abstract": "Gaussian processes (GPs) have gained popularity as flexible machine learning\nmodels for regression and function approximation with an in-built method for\nuncertainty quantification. However, GPs suffer when the amount of training\ndata is large or when the underlying function contains multi-scale features\nthat are difficult to represent by a stationary kernel. To address the former,\ntraining of GPs with large-scale data is often performed through inducing point\napproximations (also known as sparse GP regression (GPR)), where the size of\nthe covariance matrices in GPR is reduced considerably through a greedy search\non the data set. To aid the latter, deep GPs have gained traction as\nhierarchical models that resolve multi-scale features by combining multiple\nGPs. Posterior inference in deep GPs requires a sampling or, more usual, a\nvariational approximation. Variational approximations lead to large-scale\nstochastic, non-convex optimisation problems and the resulting approximation\ntends to represent uncertainty incorrectly. In this work, we combine\nvariational learning with MCMC to develop a particle-based\nexpectation-maximisation method to simultaneously find inducing points within\nthe large-scale data (variationally) and accurately train the GPs\n(sampling-based). The result is a highly efficient and accurate methodology for\ndeep GP training on large-scale data. We test our method on standard benchmark\nproblems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11355v1",
    "published": "2025-05-16T15:18:15+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.CO"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.11354v1",
    "title": "Truly Confining Supersymmetric Gauge Theories",
    "authors": [
      "Riku Ishikawa",
      "Hitoshi Murayama",
      "Shota Saito"
    ],
    "abstract": "We classify ``truly confining'' (t-confining) supersymmetric gauge theories,\nin which no center charges can be screened, and Wilson loops in the fundamental\nrepresentation are therefore expected to exhibit an area law. In all cases, we\nidentify the condensation of certain ``magnetic'' operators. Many of them have\nmore than three branches, and one with vanishing superpotential, a phenomenon\nnot previously observed.",
    "pdf_url": "http://arxiv.org/pdf/2505.11354v1",
    "published": "2025-05-16T15:16:54+00:00",
    "categories": [
      "hep-th",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11353v1",
    "title": "Hong-Ou-Mandel interferometry with trapped polariton condensates",
    "authors": [
      "S. Baryshev",
      "I. Smirnov",
      "I. Gnusov",
      "T. Cookson",
      "A. Zasedatelev",
      "S. Kilin",
      "P. G. Lagoudakis"
    ],
    "abstract": "We investigate the indistinguishability of polaritons in optically trapped\nBose Einstein condensates by implementing Hong-Ou-Mandel (HOM) interferometry\nand test the limitations of two-polariton interference in the coherent,\nlimit-cycle and thermal statistical regimes. We observe that the HOM dynamics\nof a circularly polarized condensate follows the condensate coherence time with\nthe characteristic HOM-dip approaching the classical limit. Linearly polarized\ncondensates exhibit a combined effect of polariton bunching and two-polariton\ninterference. Under elliptically polarized excitation, the temporal evolution\nof the spinor condensate results in the revival of the HOM-dip at the spinor\nLarmor precession frequency.",
    "pdf_url": "http://arxiv.org/pdf/2505.11353v1",
    "published": "2025-05-16T15:16:28+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.quant-gas"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.11352v1",
    "title": "LegoSLM: Connecting LLM with Speech Encoder using CTC Posteriors",
    "authors": [
      "Rao Ma",
      "Tongzhou Chen",
      "Kartik Audhkhasi",
      "Bhuvana Ramabhadran"
    ],
    "abstract": "Recently, large-scale pre-trained speech encoders and Large Language Models\n(LLMs) have been released, which show state-of-the-art performance on a range\nof spoken language processing tasks including Automatic Speech Recognition\n(ASR). To effectively combine both models for better performance, continuous\nspeech prompts, and ASR error correction have been adopted. However, these\nmethods are prone to suboptimal performance or are inflexible. In this paper,\nwe propose a new paradigm, LegoSLM, that bridges speech encoders and LLMs using\nthe ASR posterior matrices. The speech encoder is trained to generate\nConnectionist Temporal Classification (CTC) posteriors over the LLM vocabulary,\nwhich are used to reconstruct pseudo-audio embeddings by computing a weighted\nsum of the LLM input embeddings. These embeddings are concatenated with text\nembeddings in the LLM input space. Using the well-performing USM and Gemma\nmodels as an example, we demonstrate that our proposed LegoSLM method yields\ngood performance on both ASR and speech translation tasks. By connecting USM\nwith Gemma models, we can get an average of 49% WERR over the USM-CTC baseline\non 8 MLS testsets. The trained model also exhibits modularity in a range of\nsettings -- after fine-tuning the Gemma model weights, the speech encoder can\nbe switched and combined with the LLM in a zero-shot fashion. Additionally, we\npropose to control the decode-time influence of the USM and LLM using a softmax\ntemperature, which shows effectiveness in domain adaptation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11352v1",
    "published": "2025-05-16T15:15:19+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11351v1",
    "title": "Targeted empirical Bayes for more supervised joint factor analysis",
    "authors": [
      "Glenn Palmer",
      "David B. Dunson"
    ],
    "abstract": "Joint Bayesian factor models are popular for characterizing relationships\nbetween multivariate correlated predictors and a response variable. Standard\nmodels assume that all variables, including both the predictors and the\nresponse, are conditionally independent given latent factors. In marginalizing\nout these factors, one obtains a low rank plus diagonal factorization for the\njoint covariance, which implies a linear regression for the response given the\npredictors. Although there are many desirable properties of such models, these\nmethods can struggle to identify the signal when the response is not dependent\non the dominant principal components in the predictors. To address this\nproblem, we propose estimating the residual variance in the response model with\nan empirical Bayes procedure that targets predictive performance of the\nresponse given the predictors. We illustrate that this can lead to substantial\nimprovements in simulation performance. We are particularly motivated by\nstudies assessing the health effects of environmental exposures and provide an\nillustrative application to NHANES data.",
    "pdf_url": "http://arxiv.org/pdf/2505.11351v1",
    "published": "2025-05-16T15:15:02+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.11350v1",
    "title": "Search-TTA: A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild",
    "authors": [
      "Derek Ming Siang Tan",
      "Shailesh",
      "Boyang Liu",
      "Alok Raj",
      "Qi Xuan Ang",
      "Weiheng Dai",
      "Tanishq Duhan",
      "Jimmy Chiun",
      "Yuhong Cao",
      "Florian Shkurti",
      "Guillaume Sartoretti"
    ],
    "abstract": "To perform autonomous visual search for environmental monitoring, a robot may\nleverage satellite imagery as a prior map. This can help inform coarse,\nhigh-level search and exploration strategies, even when such images lack\nsufficient resolution to allow fine-grained, explicit visual recognition of\ntargets. However, there are some challenges to overcome with using satellite\nimages to direct visual search. For one, targets that are unseen in satellite\nimages are underrepresented (compared to ground images) in most existing\ndatasets, and thus vision models trained on these datasets fail to reason\neffectively based on indirect visual cues. Furthermore, approaches which\nleverage large Vision Language Models (VLMs) for generalization may yield\ninaccurate outputs due to hallucination, leading to inefficient search. To\naddress these challenges, we introduce Search-TTA, a multimodal test-time\nadaptation framework that can accept text and/or image input. First, we\npretrain a remote sensing image encoder to align with CLIP's visual encoder to\noutput probability distributions of target presence used for visual search.\nSecond, our framework dynamically refines CLIP's predictions during search\nusing a test-time adaptation mechanism. Through a feedback loop inspired by\nSpatial Poisson Point Processes, gradient updates (weighted by uncertainty) are\nused to correct (potentially inaccurate) predictions and improve search\nperformance. To validate Search-TTA's performance, we curate a visual search\ndataset based on internet-scale ecological data. We find that Search-TTA\nimproves planner performance by up to 9.7%, particularly in cases with poor\ninitial CLIP predictions. It also achieves comparable performance to\nstate-of-the-art VLMs. Finally, we deploy Search-TTA on a real UAV via\nhardware-in-the-loop testing, by simulating its operation within a large-scale\nsimulation that provides onboard sensing.",
    "pdf_url": "http://arxiv.org/pdf/2505.11350v1",
    "published": "2025-05-16T15:15:00+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11349v1",
    "title": "Context parroting: A simple but tough-to-beat baseline for foundation models in scientific machine learning",
    "authors": [
      "Yuanzhao Zhang",
      "William Gilpin"
    ],
    "abstract": "Recently-developed time series foundation models for scientific machine\nlearning exhibit emergent abilities to predict physical systems. These\nabilities include zero-shot forecasting, in which a model forecasts future\nstates of a system given only a short trajectory as context. Here, we show that\nfoundation models applied to physical systems can give accurate predictions,\nbut that they fail to develop meaningful representations of the underlying\nphysics. Instead, foundation models often forecast by context parroting, a\nsimple zero-shot forecasting strategy that copies directly from the context. As\na result, a naive direct context parroting model scores higher than\nstate-of-the-art time-series foundation models on predicting a diverse range of\ndynamical systems, at a tiny fraction of the computational cost. We draw a\nparallel between context parroting and induction heads, which explains why\nlarge language models trained on text can be repurposed for time series\nforecasting. Our dynamical systems perspective also ties the scaling between\nforecast accuracy and context length to the fractal dimension of the attractor,\nproviding insight into the previously observed in-context neural scaling laws.\nContext parroting thus serves as a simple but tough-to-beat baseline for future\ntime-series foundation models and can help identify in-context learning\nstrategies beyond parroting.",
    "pdf_url": "http://arxiv.org/pdf/2505.11349v1",
    "published": "2025-05-16T15:14:47+00:00",
    "categories": [
      "cs.LG",
      "nlin.CD",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11348v1",
    "title": "del Pezzo surfaces with one bad prime over cyclotomic $\\mathbb{Z}_\\ell$-extensions",
    "authors": [
      "Maryam Nowroozi"
    ],
    "abstract": "Let $K$ be a number field and $S$ a finite set of primes of $K$. Scholl\nproved that there are only finitely many $K$-isomorphism classes of del Pezzo\nsurfaces of any degree $1 \\le d \\le 9$ over $K$ with good reduction away from\n$S$. Let instead $K$ be the cyclotomic $\\mathbb{Z}_5$-extension of\n$\\mathbb{Q}$.In this paper, we show, for $d=3$, $4$, that there are infinitely\nmany $\\overline{\\mathbb{Q}}$ isomorphism classes of del Pezzo surfaces, defined\nover $K$, with good reduction away from the unique prime above $5$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11348v1",
    "published": "2025-05-16T15:14:27+00:00",
    "categories": [
      "math.NT",
      "math.AG",
      "11G35 (14G05)"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11347v2",
    "title": "Training NTK to Generalize with KARE",
    "authors": [
      "Johannes Schwab",
      "Bryan Kelly",
      "Semyon Malamud",
      "Teng Andrea Xu"
    ],
    "abstract": "The performance of the data-dependent neural tangent kernel (NTK; Jacot et\nal. (2018)) associated with a trained deep neural network (DNN) often matches\nor exceeds that of the full network. This implies that DNN training via\ngradient descent implicitly performs kernel learning by optimizing the NTK. In\nthis paper, we propose instead to optimize the NTK explicitly. Rather than\nminimizing empirical risk, we train the NTK to minimize its generalization\nerror using the recently developed Kernel Alignment Risk Estimator (KARE; Jacot\net al. (2020)). Our simulations and real data experiments show that NTKs\ntrained with KARE consistently match or significantly outperform the original\nDNN and the DNN- induced NTK (the after-kernel). These results suggest that\nexplicitly trained kernels can outperform traditional end-to-end DNN\noptimization in certain settings, challenging the conventional dominance of\nDNNs. We argue that explicit training of NTK is a form of over-parametrized\nfeature learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.11347v2",
    "published": "2025-05-16T15:13:30+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11346v1",
    "title": "What Can We Learn From MIMO Graph Convolutions?",
    "authors": [
      "Andreas Roth",
      "Thomas Liebig"
    ],
    "abstract": "Most graph neural networks (GNNs) utilize approximations of the general graph\nconvolution derived in the graph Fourier domain. While GNNs are typically\napplied in the multi-input multi-output (MIMO) case, the approximations are\nperformed in the single-input single-output (SISO) case. In this work, we first\nderive the MIMO graph convolution through the convolution theorem and\napproximate it directly in the MIMO case. We find the key MIMO-specific\nproperty of the graph convolution to be operating on multiple computational\ngraphs, or equivalently, applying distinct feature transformations for each\npair of nodes. As a localized approximation, we introduce localized MIMO graph\nconvolutions (LMGCs), which generalize many linear message-passing neural\nnetworks. For almost every choice of edge weights, we prove that LMGCs with a\nsingle computational graph are injective on multisets, and the resulting\nrepresentations are linearly independent when more than one computational graph\nis used. Our experimental results confirm that an LMGC can combine the benefits\nof various methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.11346v1",
    "published": "2025-05-16T15:13:09+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11345v1",
    "title": "Long-Term Average Impulse Control with Mean Field Interactions",
    "authors": [
      "K. L. Helmes",
      "R. H. Stockbridge",
      "C. Zhu"
    ],
    "abstract": "This paper analyzes and provides explicit solutions for a long-term average\nimpulse control problem with a specific mean-field interaction. The underlying\nprocess is a general one-dimensional diffusion with appropriate boundary\nbehavior. The model is motivated by applications such the optimal long-term\nmanagement of renewable natural resources and financial portfolio management.\nEach individual agent seeks to maximize the long-term average reward, which\nconsists of a running reward and incomes from discrete impulses, where the unit\nintervention price depends on the market through a stationary supply rate. In a\ncompetitive market setting, we establish the existence of and explicitly\ncharacterize an equilibrium strategy within a large class of policies under\nmild conditions. Additionally, we formulate and solve the mean field control\nproblem, in which agents cooperate with each other, aiming to realize a common\nmaximal long-term average profit. To illustrate the theoretical results, we\nexamine a stochastic logistic growth model and a population growth model in a\nstochastic environment with impulse control.",
    "pdf_url": "http://arxiv.org/pdf/2505.11345v1",
    "published": "2025-05-16T15:12:48+00:00",
    "categories": [
      "math.OC",
      "math.PR",
      "91A16, 91A15, 93E20, 60H30, 60J60, 91G80"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11344v1",
    "title": "Dynamic Base model Shift for Delta Compression",
    "authors": [
      "Chenyu Huang",
      "Peng Ye",
      "Shenghe Zheng",
      "Xiaohui Wang",
      "Lei Bai",
      "Tao Chen",
      "Wanli Ouyang"
    ],
    "abstract": "Transformer-based models with the pretrain-finetune paradigm bring about\nsignificant progress, along with the heavy storage and deployment costs of\nfinetuned models on multiple tasks. Delta compression attempts to lower the\ncosts by reducing the redundancy of delta parameters (i.e., the difference\nbetween the finetuned and pre-trained model weights) through pruning or\nquantization. However, existing methods by default employ the pretrained model\nas the base model and compress the delta parameters for every task, which may\ncauses significant performance degradation, especially when the compression\nrate is extremely high. To tackle this issue, we investigate the impact of\ndifferent base models on the performance of delta compression and find that the\npre-trained base model can hardly be optimal. To this end, we propose Dynamic\nBase Model Shift (DBMS), which dynamically adapts the base model to the target\ntask before performing delta compression. Specifically, we adjust two\nparameters, which respectively determine the magnitude of the base model shift\nand the overall scale of delta compression, to boost the compression\nperformance on each task. Through low-cost learning of these two parameters,\nour DBMS can maintain most of the finetuned model's performance even under an\nextremely high compression ratio setting, significantly surpassing existing\nmethods. Moreover, our DBMS is orthogonal and can be integrated with a variety\nof other methods, and it has been evaluated across different types of models\nincluding language, vision transformer, and multi-modal models.",
    "pdf_url": "http://arxiv.org/pdf/2505.11344v1",
    "published": "2025-05-16T15:11:19+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11343v2",
    "title": "Revisiting Stochastic Approximation and Stochastic Gradient Descent",
    "authors": [
      "Rajeeva Laxman Karandikar",
      "Bhamidi Visweswara Rao",
      "Mathukumalli Vidyasagar"
    ],
    "abstract": "In this paper, we introduce a new approach to proving the convergence of the\nStochastic Approximation (SA) and the Stochastic Gradient Descent (SGD)\nalgorithms. The new approach is based on a concept called GSLLN (Generalized\nStrong Law of Large Numbers), which extends the traditional SLLN. Using this\nconcept, we provide sufficient conditions for convergence, which effectively\ndecouple the properties of the function whose zero we are trying to find, from\nthe properties of the measurement errors (noise sequence). The new approach\nprovides an alternative to the two widely used approaches, namely the ODE\napproach and the martingale approach, and also permits a wider class of noise\nsignals than either of the two known approaches. In particular, the ``noise''\nor measurement error \\textit{need not} have a finite second moment, and under\nsuitable conditions, not even a finite mean. By adapting this method of proof,\nwe also derive sufficient conditions for the convergence of zero-order SGD,\nwherein the stochastic gradient is computed using $2d$ function evaluations,\nbut no gradient computations. The sufficient conditions derived here are the\nweakest to date, thus leading to a considerable expansion of the applicability\nof SA and SGD theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.11343v2",
    "published": "2025-05-16T15:10:58+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "stat.ML",
      "62L20, 60G17, 93D05"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11342v1",
    "title": "Sobolev Training of End-to-End Optimization Proxies",
    "authors": [
      "Andrew W. Rosemberg",
      "Joaquim Dias Garcia",
      "Russell Bent",
      "Pascal Van Hentenryck"
    ],
    "abstract": "Optimization proxies - machine learning models trained to approximate the\nsolution mapping of parametric optimization problems in a single forward pass -\noffer dramatic reductions in inference time compared to traditional iterative\nsolvers. This work investigates the integration of solver sensitivities into\nsuch end to end proxies via a Sobolev training paradigm and does so in two\ndistinct settings: (i) fully supervised proxies, where exact solver outputs and\nsensitivities are available, and (ii) self supervised proxies that rely only on\nthe objective and constraint structure of the underlying optimization problem.\nBy augmenting the standard training loss with directional derivative\ninformation extracted from the solver, the proxy aligns both its predicted\nsolutions and local derivatives with those of the optimizer. Under Lipschitz\ncontinuity assumptions on the true solution mapping, matching first order\nsensitivities is shown to yield uniform approximation error proportional to the\ntraining set covering radius. Empirically, different impacts are observed in\neach studied setting. On three large Alternating Current Optimal Power Flow\nbenchmarks, supervised Sobolev training cuts mean squared error by up to 56\npercent and the median worst case constraint violation by up to 400 percent\nwhile keeping the optimality gap below 0.22 percent. For a mean variance\nportfolio task trained without labeled solutions, self supervised Sobolev\ntraining halves the average optimality gap in the medium risk region (standard\ndeviation above 10 percent of budget) and matches the baseline elsewhere.\nTogether, these results highlight Sobolev training whether supervised or self\nsupervised as a path to fast reliable surrogates for safety critical large\nscale optimization workloads.",
    "pdf_url": "http://arxiv.org/pdf/2505.11342v1",
    "published": "2025-05-16T15:10:01+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01981v1",
    "title": "Early warning skill, extrapolation and tipping for accelerating cascades",
    "authors": [
      "Peter Ashwin",
      "Robbin Bastiaansen",
      "Anna S. von der Heydt",
      "Paul Ritchie"
    ],
    "abstract": "We investigate how nonlinear behaviour (both of forcing in time and of the\nsystem itself) can affect the skill of early warning signals to predict tipping\nin (directionally) coupled bistable systems when using measures based on\ncritical slowing down due to the breakdown of extrapolation. We quantify the\nskill of early warnings with a time horizon using a receiver-operator\nmethodology for ensembles where noise realisations and parameters are varied to\nexplore the role of extrapolation and how it can break down. We highlight cases\nwhere this can occur in an accelerating cascade of tipping elements, where very\nslow forcing of a slowly evolving ``upstream'' system forces a more rapidly\nevolving ``downstream'' system. If the upstream system crosses a tipping point,\nthis can shorten the timescale of valid extrapolation. In particular,\n``downstream-within-upstream'' tipping will typically have warnings only on a\ntimescale comparable to the duration of the upstream tipping process, rather\nthan the timescale of the original forcing.",
    "pdf_url": "http://arxiv.org/pdf/2506.01981v1",
    "published": "2025-05-16T15:09:38+00:00",
    "categories": [
      "nlin.CD",
      "math.DS",
      "37M10 82C27"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2505.11341v2",
    "title": "Benchmarking Critical Questions Generation: A Challenging Reasoning Task for Large Language Models",
    "authors": [
      "Banca Calvo Figueras",
      "Rodrigo Agerri"
    ],
    "abstract": "The task of Critical Questions Generation (CQs-Gen) aims to foster critical\nthinking by enabling systems to generate questions that expose underlying\nassumptions and challenge the validity of argumentative reasoning structures.\nDespite growing interest in this area, progress has been hindered by the lack\nof suitable datasets and automatic evaluation standards. This paper presents a\ncomprehensive approach to support the development and benchmarking of systems\nfor this task. We construct the first large-scale dataset including $~$5K\nmanually annotated questions. We also investigate automatic evaluation methods\nand propose a reference-based technique using large language models (LLMs) as\nthe strategy that best correlates with human judgments. Our zero-shot\nevaluation of 11 LLMs establishes a strong baseline while showcasing the\ndifficulty of the task. Data and code plus a public leaderboard are provided to\nencourage further research not only in terms of model performance, but also to\nexplore the practical benefits of CQs-Gen for both automated reasoning and\nhuman critical thinking.",
    "pdf_url": "http://arxiv.org/pdf/2505.11341v2",
    "published": "2025-05-16T15:08:04+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11340v1",
    "title": "DecompileBench: A Comprehensive Benchmark for Evaluating Decompilers in Real-World Scenarios",
    "authors": [
      "Zeyu Gao",
      "Yuxin Cui",
      "Hao Wang",
      "Siliang Qin",
      "Yuanda Wang",
      "Bolun Zhang",
      "Chao Zhang"
    ],
    "abstract": "Decompilers are fundamental tools for critical security tasks, from\nvulnerability discovery to malware analysis, yet their evaluation remains\nfragmented. Existing approaches primarily focus on syntactic correctness\nthrough synthetic micro-benchmarks or subjective human ratings, failing to\naddress real-world requirements for semantic fidelity and analyst usability. We\npresent DecompileBench, the first comprehensive framework that enables\neffective evaluation of decompilers in reverse engineering workflows through\nthree key components: \\textit{real-world function extraction} (comprising\n23,400 functions from 130 real-world programs), \\textit{runtime-aware\nvalidation}, and \\textit{automated human-centric assessment} using LLM-as-Judge\nto quantify the effectiveness of decompilers in reverse engineering workflows.\nThrough a systematic comparison between six industrial-strength decompilers and\nsix recent LLM-powered approaches, we demonstrate that LLM-based methods\nsurpass commercial tools in code understandability despite 52.2% lower\nfunctionality correctness. These findings highlight the potential of LLM-based\napproaches to transform human-centric reverse engineering. We open source\n\\href{https://github.com/Jennieett/DecompileBench}{DecompileBench} to provide a\nframework to advance research on decompilers and assist security experts in\nmaking informed tool selections based on their specific requirements.",
    "pdf_url": "http://arxiv.org/pdf/2505.11340v1",
    "published": "2025-05-16T15:07:43+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11339v1",
    "title": "Palladium: A DPU-enabled Multi-Tenant Serverless Cloud over Zero-copy Multi-node RDMA Fabrics",
    "authors": [
      "Shixiong Qi",
      "Songyu Zhang",
      "K. K. Ramakrishnan",
      "Diman Z. Tootaghaj",
      "Hardik Soni",
      "Puneet Sharma"
    ],
    "abstract": "Serverless computing promises enhanced resource efficiency and lower user\ncosts, yet is burdened by a heavyweight, CPU-bound data plane. Prior efforts\nexploiting shared memory reduce overhead locally but fall short when scaling\nacross nodes. Furthermore, serverless environments can have unpredictable and\nlarge-scale multi-tenancy, leading to contention for shared network resources.\n  We present Palladium, a DPU-centric serverless data plane that reduces the\nCPU burden and enables efficient, zero-copy communication in multi-tenant\nserverless clouds. Despite the limited general-purpose processing capability of\nthe DPU cores, Palladium strategically exploits the DPU's potential by (1)\noffloading data transmission to high-performance NIC cores via RDMA, combined\nwith intra-node shared memory to eliminate data copies across nodes, and (2)\nenabling cross-processor (CPU-DPU) shared memory to eliminate redundant data\nmovement, which overwhelms wimpy DPU cores. At the core of Palladium is the\nDPU-enabled network engine (DNE) -- a lightweight reverse proxy that isolates\nRDMA resources from tenant functions, orchestrates inter-node RDMA flows, and\nenforces fairness under contention.\n  To further reduce CPU involvement, Palladium performs early HTTP/TCP-to-RDMA\ntransport conversion at the cloud ingress, bridging the protocol mismatch\nbefore client traffic enters the RDMA fabric, thus avoiding costly protocol\ntranslation along the critical path. We show that careful selection of RDMA\nprimitives (i.e., two-sided instead of one-sided) significantly affects the\nzero-copy data plane.\n  Our preliminary experimental results show that enabling DPU offloading in\nPalladium improves RPS by 20.9x. The latency is reduced by a factor of 21x in\nthe best case, all the while saving up to 7 CPU cores, and only consuming two\nwimpy DPU cores.",
    "pdf_url": "http://arxiv.org/pdf/2505.11339v1",
    "published": "2025-05-16T15:07:16+00:00",
    "categories": [
      "cs.NI",
      "cs.DC"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11338v1",
    "title": "Exploring the Pseudo-modes of Schrödinger Operators with Complex Potentials: A Focus on Resolvent Norm Estimates and Spectral Stability",
    "authors": [
      "Sameh Gana"
    ],
    "abstract": "This paper aims to investigate the pseudo-modes of the one-dimensional\nSchr\\\"odinger operator with complex potentials, focusing on the behavior of the\nresolvent norm along specific curves in the complex plane and assessing the\nstability of the spectrum under small perturbations. The study builds upon\nprevious work of E.B. Davies, L.S. Boulton, and N. Trefethen, specifically\nexamining the resolvent norm of the complex harmonic oscillator along curves of\nthe form $z_{\\eta }= b\\eta + c\\eta ^{p} $ where $ b > 0$, $ \\frac{1}{3}< p <3 $\nindependent of $\\eta> 0$. The present work narrows the focus to the case where\n$p = \\frac{1}{3}$. Numerical computations of pseudo-eigenvalues are performed\nto verify spectral instability.",
    "pdf_url": "http://arxiv.org/pdf/2505.11338v1",
    "published": "2025-05-16T15:05:50+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11337v1",
    "title": "Ergodicity of the Anderson $Φ_2^4$ model",
    "authors": [
      "Hugo Eulry",
      "Antoine Mouzard"
    ],
    "abstract": "We consider the parabolic stochastic quantization equation associated to the\n$\\Phi_2^4$ model on the torus in a spatial white noise environment. We study\nthe long time behavior of this heat equation with independent multiplicative\nwhite noise and additive spacetime white noise, which is a singular SPDE in a\nsingular environement and requires two different renormalization procedures. We\nprove that the solution is global in time with a strong a priori $L^p$ bound\nindependent of the initial data in $C^{-\\varepsilon}$ for large $p$. The\nquenched solution given the environment is shown to be an infinite dimensional\nMarkov process which satisfies the strong Feller property. We prove exponential\nconvergence to a unique invariant measure using a Doeblin criterion for the\ntransition semigroup. In particular, our work is a generalization of a previous\nwork by Tsatsoulis and Weber in a case which is not translation invariant hence\nthe method makes no use of the reversibility of the dynamics or the explicit\nknowledge of the invariant measure and it is therefore in principle applicable\nto situations where these are not available such as the vector-valued case.",
    "pdf_url": "http://arxiv.org/pdf/2505.11337v1",
    "published": "2025-05-16T15:03:12+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.AP",
      "math.MP"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11336v2",
    "title": "XtraGPT: Context-Aware and Controllable Academic Paper Revision via Human-AI Collaboration",
    "authors": [
      "Nuo Chen",
      "Andre Lin HuiKai",
      "Jiaying Wu",
      "Junyi Hou",
      "Zining Zhang",
      "Qian Wang",
      "Xidong Wang",
      "Bingsheng He"
    ],
    "abstract": "Despite the growing adoption of large language models (LLMs) in academic\nworkflows, their capabilities remain limited when it comes to supporting\nhigh-quality scientific writing. Most existing systems are designed for\ngeneral-purpose scientific text generation and fail to meet the sophisticated\ndemands of research communication beyond surface-level polishing, such as\nconceptual coherence across sections. Furthermore, academic writing is\ninherently iterative and revision-driven, a process not well supported by\ndirect prompting-based paradigms. To address these scenarios, we propose a\nhuman-AI collaboration framework for academic paper revision. We first\nintroduce a comprehensive dataset of 7,040 research papers from top-tier venues\nannotated with over 140,000 instruction-response pairs that reflect realistic,\nsection-level scientific revisions. Building on the dataset, we develop\nXtraGPT, the first suite of open-source LLMs, designed to provide\ncontext-aware, instruction-guided writing assistance, ranging from 1.5B to 14B\nparameters. Extensive experiments validate that XtraGPT significantly\noutperforms same-scale baselines and approaches the quality of proprietary\nsystems. Both automated preference assessments and human evaluations confirm\nthe effectiveness of our models in improving scientific drafts.",
    "pdf_url": "http://arxiv.org/pdf/2505.11336v2",
    "published": "2025-05-16T15:02:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11335v2",
    "title": "The Final Layer Holds the Key: A Unified and Efficient GNN Calibration Framework",
    "authors": [
      "Jincheng Huang",
      "Jie Xu",
      "Xiaoshuang Shi",
      "Ping Hu",
      "Lei Feng",
      "Xiaofeng Zhu"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable effectiveness on\ngraph-based tasks. However, their predictive confidence is often miscalibrated,\ntypically exhibiting under-confidence, which harms the reliability of their\ndecisions. Existing calibration methods for GNNs normally introduce additional\ncalibration components, which fail to capture the intrinsic relationship\nbetween the model and the prediction confidence, resulting in limited\ntheoretical guarantees and increased computational overhead. To address this\nissue, we propose a simple yet efficient graph calibration method. We establish\na unified theoretical framework revealing that model confidence is jointly\ngoverned by class-centroid-level and node-level calibration at the final layer.\nBased on this insight, we theoretically show that reducing the weight decay of\nthe final-layer parameters alleviates GNN under-confidence by acting on the\nclass-centroid level, while node-level calibration acts as a finer-grained\ncomplement to class-centroid level calibration, which encourages each test node\nto be closer to its predicted class centroid at the final-layer\nrepresentations. Extensive experiments validate the superiority of our method.",
    "pdf_url": "http://arxiv.org/pdf/2505.11335v2",
    "published": "2025-05-16T15:02:17+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11334v2",
    "title": "MARRS: Masked Autoregressive Unit-based Reaction Synthesis",
    "authors": [
      "Yabiao Wang",
      "Shuo Wang",
      "Jiangning Zhang",
      "Jiafu Wu",
      "Qingdong He",
      "Yong Liu"
    ],
    "abstract": "This work aims at a challenging task: human action-reaction synthesis, i.e.,\ngenerating human reactions conditioned on the action sequence of another\nperson. Currently, autoregressive modeling approaches with vector quantization\n(VQ) have achieved remarkable performance in motion generation tasks. However,\nVQ has inherent disadvantages, including quantization information loss, low\ncodebook utilization, etc. In addition, while dividing the body into separate\nunits can be beneficial, the computational complexity needs to be considered.\nAlso, the importance of mutual perception among units is often neglected. In\nthis work, we propose MARRS, a novel framework designed to generate coordinated\nand fine-grained reaction motions using continuous representations. Initially,\nwe present the Unit-distinguished Motion Variational AutoEncoder (UD-VAE),\nwhich segments the entire body into distinct body and hand units, encoding each\nindependently. Subsequently, we propose Action-Conditioned Fusion (ACF), which\ninvolves randomly masking a subset of reactive tokens and extracting specific\ninformation about the body and hands from the active tokens. Furthermore, we\nintroduce Adaptive Unit Modulation (AUM) to facilitate interaction between body\nand hand units by using the information from one unit to adaptively modulate\nthe other. Finally, for the diffusion model, we employ a compact MLP as a noise\npredictor for each distinct body unit and incorporate the diffusion loss to\nmodel the probability distribution of each token. Both quantitative and\nqualitative results demonstrate that our method achieves superior performance.\nThe code will be released upon acceptance.",
    "pdf_url": "http://arxiv.org/pdf/2505.11334v2",
    "published": "2025-05-16T15:00:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11333v1",
    "title": "Born-limit scattering and pair-breaking crossover in d-wave superconductivity of (TMTSF)2ClO4",
    "authors": [
      "Shota Yano",
      "Kazumi Fukushima",
      "Katsuki Kinjo",
      "Soichiro Yamane",
      "Le Hong Hoàng To",
      "Pascale Senzier",
      "Cécile Mézière",
      "Shamashis Sengupta",
      "Claire A Marrache-Kikuchi",
      "Denis Jerome",
      "Shingo Yonezawa"
    ],
    "abstract": "In the quasi-one-dimensional organic unconventional superconductor\n(TMTSF)2ClO4, the randomness of the non-centrosymmetric ClO4 anions can be\nexperimentally controlled by adjusting the cooling rate through the\nanion-ordering temperature. This feature provides a unique opportunity to study\ndisorder effects on unconventional superconductivity in great detail. We here\nreport on measurements of the electronic specific heat of this system,\nperformed under various cooling rates. The evolution of the residual density of\nstates indicates that the ClO4 randomness works as Born-limit pair breakers,\nwhich, to our knowledge, has never been clearly identified in any\nunconventional superconductors. Furthermore, detailed analyses suggest a\npeculiar crossover from strong unitarity scattering due to molecular defects\ntoward the Born-limit weak scattering due to borders of ordered regions. This\nwork supports the d-wave nature of pairing in (TMTSF)2ClO4 and intends to\nprovide an experimental basis for further developments of pair-breaking\ntheories of unconventional superconductors where multiple electron scattering\nmechanisms coexist.",
    "pdf_url": "http://arxiv.org/pdf/2505.11333v1",
    "published": "2025-05-16T15:00:30+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.11332v1",
    "title": "Wind-induced Natural Gamma Radiation",
    "authors": [
      "A. Chilingarian",
      "B. Sargsyan",
      "D. Aslanyan",
      "L. Kozliner"
    ],
    "abstract": "During the extreme winter storms of 2024-2025 at Aragats, natural gamma\nradiation (NGR) increased by more than 1000%, with fluence reaching 2*10^7\ngammas/cm^2 over 10 hours and a corresponding dose of 3.26 mSv, 120 times\nhigher than normal background radiation for the same period. This unprecedented\nradiation surge was detected during dry, electrified snowstorms, exceeding\nlevels explainable by known atmospheric mechanisms, necessitating a significant\nreassessment of gamma-ray sources in winter storm conditions. These results\nsuggest similar radiation surges may occur in high-altitude and polar regions\n(Arctic and Antarctic), where strong winds and prolonged snowstorms are common.\nUnderstanding radiation surge conditions is essential for refining atmospheric\nmodels, improving radiation monitoring, and assessing environmental and\nclimatic impacts in extreme weather conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11332v1",
    "published": "2025-05-16T14:59:34+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11331v3",
    "title": "Distance-based measures and Epsilon-measures for measurement-based quantum resources",
    "authors": [
      "Arindam Mitra",
      "Sumit Mukherjee",
      "Changhyoup Lee"
    ],
    "abstract": "Quantum resource theories provide a structured and elegant framework for\nquantifying quantum resources. While state-based resource theories have been\nextensively studied, their measurement-based resource theories remain\nrelatively underexplored. In practical scenarios where a quantum state or a set\nof measurements is only partially known, conventional resource measures often\nfall short in capturing the resource content. In such cases, \\epsilon-measures\noffer a robust alternative, making them particularly valuable. In this work, we\ninvestigate the quantification of measurement-based resources using\ndistance-based measures, followed by a detailed analysis of the mathematical\nproperties of \\epsilon-measures. We also extend our analysis by exploring the\nconnections between \\epsilon-measures and some key quantities relevant to\nresource manipulation tasks. Importantly, the analysis of resources based on\nsets of measurements are tedious compared to that of single measurements as the\nformer allows more general transformations such as controlled implementation.\nYet our framework applies not only to resources associated with individual\nmeasurements but also to those arising from sets of measurements. In short, our\nanalysis is applicable to existing resource theories of measurements and has\nthe potential to be useful for all resource theories of measurements that are\nyet to be developed.",
    "pdf_url": "http://arxiv.org/pdf/2505.11331v3",
    "published": "2025-05-16T14:56:28+00:00",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11330v2",
    "title": "Features of the Partition Function of a $Λ>0$ Universe",
    "authors": [
      "Dionysios Anninos",
      "Chiara Baracco",
      "Samuel Brian",
      "Frederik Denef"
    ],
    "abstract": "We consider properties of the gravitational path integral,\n${Z}_{\\text{grav}}$, of a four-dimensional gravitational effective field theory\nwith $\\Lambda>0$ at the quantum level. To leading order, ${Z}_{\\text{grav}}$ is\ndominated by a four-sphere saddle subject to small fluctuations. Beyond this,\n${Z}_{\\text{grav}}$ receives contributions from additional geometries that may\ninclude Einstein metrics of positive curvature. We discuss how a general\npositive curvature Einstein metric contributes to ${Z}_{\\text{grav}}$ at\none-loop level. Along the way, we discuss Einstein-Maxwell theory with\n$\\Lambda>0$, and identify an interesting class of closed non-Einstein\ngravitational instantons. We provide a detailed study for the specific case of\n$\\mathbb{C}P^2$ which is distinguished as the saddle with second largest volume\nand positive definite tensor eigenspectrum. We present exact one-loop results\nfor scalar particles, Maxwell theory, and Einstein gravity about the\nFubini-Study metric on $\\mathbb{C}P^2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11330v2",
    "published": "2025-05-16T14:55:32+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11329v2",
    "title": "TokenWeave: Efficient Compute-Communication Overlap for Distributed LLM Inference",
    "authors": [
      "Raja Gond",
      "Nipun Kwatra",
      "Ramachandran Ramjee"
    ],
    "abstract": "Distributed inference of large language models (LLMs) can introduce overheads\nof up to 20% even over GPUs connected via high-speed interconnects such as\nNVLink. Multiple techniques have been proposed to mitigate these overheads by\ndecomposing computations into finer-grained tasks and overlapping communication\nwith sub-tasks as they complete. However, fine-grained decomposition of a large\ncomputation into many smaller computations on GPUs results in overheads.\nFurthermore, the communication itself uses many streaming multiprocessors\n(SMs), adding to the overhead.\n  We present TokenWeave to address these challenges. TokenWeave proposes a\nToken-Splitting technique that divides the tokens in the inference batch into\ntwo approximately equal subsets in a wave-aware manner. The communication of\none subset is then overlapped with the computation of the other. In addition,\nTokenWeave optimizes the order of the layer normalization computation with\nrespect to communication operations and implements a novel fused\nAllReduce--RMSNorm kernel that carefully leverages Multimem instruction support\navailable on NVIDIA Hopper GPUs. These optimizations allow TokenWeave to\nperform communication and RMSNorm using only 2-8 SMs. Moreover, our kernel\nenables the memory-bound RMSNorm to be overlapped with the other batch's\ncomputation, providing additional gains.\n  Our evaluations demonstrate up to 1.29x speedup in latency and 1.26x higher\nthroughput across multiple models and workloads. In several settings,\nTokenWeave results in better performance compared to an equivalent model with\nall communication removed.",
    "pdf_url": "http://arxiv.org/pdf/2505.11329v2",
    "published": "2025-05-16T14:53:50+00:00",
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11328v1",
    "title": "On the dark matter formation scenario of NGC 4147",
    "authors": [
      "Andrés E. Piatti"
    ],
    "abstract": "We report results on the radial velocity dispersion profile built out to the\noutskirts of NGC 4147, a Milky Way globular cluster with detected strong tidal\ntails. The cluster was chosen to probe, from an observational point of view,\nrecent simulations that suggest that rising velocity dispersion profiles at\nlarge distance from the clusters' centers would be seen in globular clusters\nwithout tidal tails. From GEMINI@GMOS spectra, centered in the infrared CaII\ntriplet region, of selected stars located along the onset of NGC 4147's tidal\ntails, we measured their radial velocities and overall metallicities. The\nderived metallicities were used to ultimately assessing on the highly-ranked\ncluster candidates of 9 stars, located between ~ 7 and 33 pc from the cluster's\ncenter, suitable for testing the aforementioned simulations. We complemented\nthe present radial velocities with others available in the literature for\ncluster's members, and built a cluster velocity dispersion profile which\nsuggests a mostly flat or slightly rising profile at large distances from the\ncluster's center. This outcome confirms that kinematically hot outermost\ncluster's stars are seen in NGC 4147, which disproves the recent model\npredictions. Nevertheless, the mean velocity dispersion of the outermost\ncluster's stars agrees with NGC 4147 being formed in a 10^8-10^9Mo dwarf galaxy\nwith a cored dark matter profile that later was accreted on to the Milky Way.",
    "pdf_url": "http://arxiv.org/pdf/2505.11328v1",
    "published": "2025-05-16T14:53:15+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11327v1",
    "title": "Trace methods for equivariant algebraic K-theory",
    "authors": [
      "David Chan",
      "Teena Gerhardt",
      "Inbar Klang"
    ],
    "abstract": "In the past decades, one of the most fruitful approaches to the study of\nalgebraic $K$-theory has been trace methods, which construct and study trace\nmaps from algebraic $K$-theory to topological Hochschild homology and related\ninvariants. In recent years, theories of equivariant algebraic $K$-theory have\nemerged, but thus far few tools are available for the study and computation of\nthese theories. In this paper, we lay the foundations for a trace methods\napproach to equivariant algebraic $K$-theory. For $G$ a finite group, we\nconstruct a Dennis trace map from equivariant algebraic $K$-theory to a\n$G$-equivariant version of topological Hochschild homology; for $G$ the trivial\ngroup this recovers the ordinary Dennis trace map. We show that upon taking\nfixed points, this recovers the trace map of\nAdamyk--Gerhardt--Hess--Klang--Kong, and gives a trace map from the fixed\npoints of coarse equivariant $A$-theory to the free loop space. We also\nestablish important properties of equivariant topological Hochschild homology,\nsuch as Morita invariance, and explain why it can be considered as a\nmultiplicative norm.",
    "pdf_url": "http://arxiv.org/pdf/2505.11327v1",
    "published": "2025-05-16T14:50:04+00:00",
    "categories": [
      "math.AT",
      "math.KT",
      "55P91, 19D55, 16E40"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11326v1",
    "title": "Temporally-Grounded Language Generation: A Benchmark for Real-Time Vision-Language Models",
    "authors": [
      "Keunwoo Peter Yu",
      "Joyce Chai"
    ],
    "abstract": "Vision-language models (VLMs) have shown remarkable progress in offline tasks\nsuch as image captioning and video question answering. However, real-time\ninteractive environments impose new demands on VLMs, requiring them to generate\nutterances that are not only semantically accurate but also precisely timed. We\nidentify two core capabilities necessary for such settings --\n$\\textit{perceptual updating}$ and $\\textit{contingency awareness}$ -- and\npropose a new benchmark task, $\\textbf{Temporally-Grounded Language Generation\n(TGLG)}$, to evaluate them. TGLG requires models to generate utterances in\nresponse to streaming video such that both content and timing align with\ndynamic visual input. To support this benchmark, we curate evaluation datasets\nfrom sports broadcasting and egocentric human interaction domains, and\nintroduce a new metric, $\\textbf{TRACE}$, to evaluate TGLG by jointly measuring\nsemantic similarity and temporal alignment. Finally, we present\n$\\textbf{Vision-Language Model with Time-Synchronized Interleaving (VLM-TSI)}$,\na model that interleaves visual and linguistic tokens in a time-synchronized\nmanner, enabling real-time language generation without relying on turn-based\nassumptions. Experimental results show that VLM-TSI significantly outperforms a\nstrong baseline, yet overall performance remains modest -- highlighting the\ndifficulty of TGLG and motivating further research in real-time VLMs. Code and\ndata available $\\href{https://github.com/yukw777/tglg}{here}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11326v1",
    "published": "2025-05-16T14:48:30+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11325v1",
    "title": "Uncertainty Quantification for Prior-Data Fitted Networks using Martingale Posteriors",
    "authors": [
      "Thomas Nagler",
      "David Rügamer"
    ],
    "abstract": "Prior-data fitted networks (PFNs) have emerged as promising foundation models\nfor prediction from tabular data sets, achieving state-of-the-art performance\non small to moderate data sizes without tuning. While PFNs are motivated by\nBayesian ideas, they do not provide any uncertainty quantification for\npredictive means, quantiles, or similar quantities. We propose a principled and\nefficient sampling procedure to construct Bayesian posteriors for such\nestimates based on Martingale posteriors, and prove its convergence. Several\nsimulated and real-world data examples showcase the uncertainty quantification\nof our method in inference applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.11325v1",
    "published": "2025-05-16T14:47:43+00:00",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.LG",
      "stat.CO",
      "stat.ML"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.11324v2",
    "title": "Runaway processes in the upper and lower atmosphere: a change of paradigm",
    "authors": [
      "A. Chilingarian"
    ],
    "abstract": "Relativistic Runaway Electron Avalanches (RREA) are central to understanding\na spectrum of high-energy atmospheric phenomena, including Terrestrial\nGamma-ray Flashes (TGFs), Thunderstorm Ground Enhancements (TGEs), and\ngamma-ray glows. Despite their common physical origin, these events are often\ntreated separately due to differences in detection methods, duration, and\naltitude. In this work, we present a unified conceptual and observational\nframework that reinterprets these radiation bursts as manifestations of the\nsame runaway processes occurring in distinct atmospheric depths. Integrating\nrecent results from satellite (ASIM), aircraft (ALOFT), balloon (HELEN), and\nground-based (SEVAN) experiments, we demonstrate consistent spectral and\ntemporal behavior across scales. We propose a rational revision of current\nterminology and challenge longstanding models that attribute TGFs to lightning\nleader dynamics. This study resolves key contradictions in the field,\nestablishes new classification criteria based on physics rather than detector\nlocation, and reshapes our understanding of particle acceleration in\nthunderstorms.",
    "pdf_url": "http://arxiv.org/pdf/2505.11324v2",
    "published": "2025-05-16T14:47:05+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.17053v1",
    "title": "Social preferences with unstable interactive reasoning: Large language models in economic trust games",
    "authors": [
      "Ou Jiamin",
      "Eikmans Emile",
      "Buskens Vincent",
      "Pankowska Paulina",
      "Shan Yuli"
    ],
    "abstract": "While large language models (LLMs) have demonstrated remarkable capabilities\nin understanding human languages, this study explores how they translate this\nunderstanding into social exchange contexts that capture certain essences of\nreal world human interactions. Three LLMs - ChatGPT-4, Claude, and Bard - were\nplaced in economic trust games where players balance self-interest with trust\nand reciprocity, making decisions that reveal their social preferences and\ninteractive reasoning abilities. Our study shows that LLMs deviate from pure\nself-interest and exhibit trust and reciprocity even without being prompted to\nadopt a specific persona. In the simplest one-shot interaction, LLMs emulated\nhow human players place trust at the beginning of such a game. Larger\nhuman-machine divergences emerged in scenarios involving trust repayment or\nmulti-round interactions, where decisions were influenced by both social\npreferences and interactive reasoning. LLMs responses varied significantly when\nprompted to adopt personas like selfish or unselfish players, with the impact\noutweighing differences between models or game types. Response of ChatGPT-4, in\nan unselfish or neutral persona, resembled the highest trust and reciprocity,\nsurpassing humans, Claude, and Bard. Claude and Bard displayed trust and\nreciprocity levels that sometimes exceeded and sometimes fell below human\nchoices. When given selfish personas, all LLMs showed lower trust and\nreciprocity than humans. Interactive reasoning to the actions of counterparts\nor changing game mechanics appeared to be random rather than stable,\nreproducible characteristics in the response of LLMs, though some improvements\nwere observed when ChatGPT-4 responded in selfish or unselfish personas.",
    "pdf_url": "http://arxiv.org/pdf/2505.17053v1",
    "published": "2025-05-16T14:45:59+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11323v1",
    "title": "Convergence Rates of Constrained Expected Improvement",
    "authors": [
      "Haowei Wang",
      "Jingyi Wang",
      "Zhongxiang Dai",
      "Nai-Yuan Chiang",
      "Szu Hui Ng",
      "Cosmin G. Petra"
    ],
    "abstract": "Constrained Bayesian optimization (CBO) methods have seen significant success\nin black-box optimization with constraints, and one of the most commonly used\nCBO methods is the constrained expected improvement (CEI) algorithm. CEI is a\nnatural extension of the expected improvement (EI) when constraints are\nincorporated. However, the theoretical convergence rate of CEI has not been\nestablished. In this work, we study the convergence rate of CEI by analyzing\nits simple regret upper bound. First, we show that when the objective function\n$f$ and constraint function $c$ are assumed to each lie in a reproducing kernel\nHilbert space (RKHS), CEI achieves the convergence rates of $\\mathcal{O}\n\\left(t^{-\\frac{1}{2}}\\log^{\\frac{d+1}{2}}(t) \\right) \\ \\text{and }\\\n\\mathcal{O}\\left(t^{\\frac{-\\nu}{2\\nu+d}} \\log^{\\frac{\\nu}{2\\nu+d}}(t)\\right)$\nfor the commonly used squared exponential and Mat\\'{e}rn kernels, respectively.\nSecond, we show that when $f$ and $c$ are assumed to be sampled from Gaussian\nprocesses (GPs), CEI achieves the same convergence rates with a high\nprobability. Numerical experiments are performed to validate the theoretical\nanalysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.11323v1",
    "published": "2025-05-16T14:44:13+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.11322v1",
    "title": "Intriguing nature of AM Her type candidate CXOU J204734.8+300105",
    "authors": [
      "Rahul Sharma",
      "Chetana Jain",
      "Biswajit Paul",
      "Anjan Dutta",
      "Vikram Rana"
    ],
    "abstract": "The detection and characterization of periodic X-ray signals are crucial for\nidentifying new compact objects and studying the mechanisms powering their\nemission. We report on the timing and spectral variability of CXOU\nJ204734.8+300105, a proposed eclipsing polar-type cataclysmic variable (CV)\ncandidate. This source has been observed once with Chandra and twice with\nXMM-Newton, revealing several intriguing and conflicting features in its X-ray\nemission. The Chandra observation showed a periodicity of $\\sim$6000 s with an\neclipse-like feature. The X-ray light curve from 2017 XMM-Newton observation\nshowed a period of $\\sim$2000 seconds without any apparent eclipse, while the\nsimultaneous optical light curve from OM showed a period of $\\sim$6000 seconds.\nThis variability raises questions about the true nature of the source. Spectral\nanalysis indicates a multi-component emission and emission lines due to Fe. The\nspectral characteristics are consistent with those observed in other CV\nsystems. Additionally, we identified optical and near-infrared counterparts\nfrom various catalogues. Our findings suggest a dynamic and evolving accretion\nenvironment of CXOU J204734.8+300105.",
    "pdf_url": "http://arxiv.org/pdf/2505.11322v1",
    "published": "2025-05-16T14:43:28+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11579v1",
    "title": "Toward Adaptive Categories: Dimensional Governance for Agentic AI",
    "authors": [
      "Zeynep Engin",
      "David Hand"
    ],
    "abstract": "As AI systems evolve from static tools to dynamic agents, traditional\ncategorical governance frameworks -- based on fixed risk tiers, levels of\nautonomy, or human oversight models -- are increasingly insufficient on their\nown. Systems built on foundation models, self-supervised learning, and\nmulti-agent architectures increasingly blur the boundaries that categories were\ndesigned to police. In this Perspective, we make the case for dimensional\ngovernance: a framework that tracks how decision authority, process autonomy,\nand accountability (the 3As) distribute dynamically across human-AI\nrelationships. A critical advantage of this approach is its ability to\nexplicitly monitor system movement toward and across key governance thresholds,\nenabling preemptive adjustments before risks materialize. This dimensional\napproach provides the necessary foundation for more adaptive categorization,\nenabling thresholds and classifications that can evolve with emerging\ncapabilities. While categories remain essential for decision-making, building\nthem upon dimensional foundations allows for context-specific adaptability and\nstakeholder-responsive governance that static approaches cannot achieve. We\noutline key dimensions, critical trust thresholds, and practical examples\nillustrating where rigid categorical frameworks fail -- and where a dimensional\nmindset could offer a more resilient and future-proof path forward for both\ngovernance and innovation at the frontier of artificial intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2505.11579v1",
    "published": "2025-05-16T14:43:12+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11321v1",
    "title": "Anomaly Detection for Non-stationary Time Series using Recurrent Wavelet Probabilistic Neural Network",
    "authors": [
      "Pu Yang",
      "J. A. Barria"
    ],
    "abstract": "In this paper, an unsupervised Recurrent Wavelet Probabilistic Neural Network\n(RWPNN) is proposed, which aims at detecting anomalies in non-stationary\nenvironments by modelling the temporal features using a nonparametric density\nestimation network. The novel framework consists of two components, a Stacked\nRecurrent Encoder-Decoder (SREnc-Dec) module that captures temporal features in\na latent space, and a Multi-Receptive-field Wavelet Probabilistic Network\n(MRWPN) that creates an ensemble probabilistic model to characterise the latent\nspace. This formulation extends the standard wavelet probabilistic networks to\nwavelet deep probabilistic networks, which can handle higher data\ndimensionality. The MRWPN module can adapt to different rates of data variation\nin different datasets without imposing strong distribution assumptions,\nresulting in a more robust and accurate detection for Time Series Anomaly\nDetection (TSAD) tasks in the non-stationary environment. We carry out the\nassessment on 45 real-world time series datasets from various domains, verify\nthe performance of RWPNN in TSAD tasks with several constraints, and show its\nability to provide early warnings for anomalous events.",
    "pdf_url": "http://arxiv.org/pdf/2505.11321v1",
    "published": "2025-05-16T14:43:00+00:00",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11320v1",
    "title": "Understanding and Characterizing Obfuscated Funds Transfers in Ethereum Smart Contracts",
    "authors": [
      "Zhang Sheng",
      "Tan Kia Quang",
      "Shen Wang",
      "Shengchen Duan",
      "Kai Li",
      "Yue Duan"
    ],
    "abstract": "Scam contracts on Ethereum have rapidly evolved alongside the rise of DeFi\nand NFT ecosystems, utilizing increasingly complex code obfuscation techniques\nto avoid early detection. This paper systematically investigates how\nobfuscation amplifies the financial risks of fraudulent contracts and\nundermines existing auditing tools. We propose a transfer-centric obfuscation\ntaxonomy, distilling seven key features, and introduce ObfProbe, a framework\nthat performs bytecode-level smart contract analysis to uncover obfuscation\ntechniques and quantify obfuscation complexity via Z-score ranking. In a\nlarge-scale study of 1.03 million Ethereum contracts, we isolate over 3 000\nhighly obfuscated contracts and identify two scam archetypes, three high-risk\ncontract categories, and MEV bots that employ a variety of obfuscation\nmaneuvers such as inline assembly, dead code insertion, and deep function\nsplitting. We further show that obfuscation substantially increases both the\nscale of financial damage and the time until detection. Finally, we evaluate\nSourceP, a state-of-the-art Ponzi detection tool, on obfuscated versus\nnon-obfuscated samples and observe its accuracy drop from approximately 80\npercent to approximately 12 percent in real-world scenarios. These findings\nhighlight the urgent need for enhanced anti-obfuscation analysis techniques and\nbroader community collaboration to stem the proliferation of scam contracts in\nthe expanding DeFi ecosystem.",
    "pdf_url": "http://arxiv.org/pdf/2505.11320v1",
    "published": "2025-05-16T14:42:51+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11319v1",
    "title": "Time-dependent Hole States in Multiconfigurational Time-Dependent Hartree-Fock Approaches: Applications in Photoionization of Water Molecule",
    "authors": [
      "Zhao-Han Zhang",
      "Yang Li",
      "Himadri Pathak",
      "Takeshi Sato",
      "Kenichi L. Ishikawa",
      "Feng He"
    ],
    "abstract": "By simulating the real-time multielectron wavefunction with the\nmulti-configurational time-dependent Hartree-Fock (MCTDHF) approach, we conduct\nan \\textit{ab initio} study of the single-photon ionization process of a\nbody-fixed water molecule ($\\mathrm{H_2O}$) driven by attosecond pulses. To\nthis end, we present a full-dimensional implementation of the MCTDHF method\nbased on one-center expansions, allowing for the simulation of arbitrarily\npolarized lasers and multi-center polyatomic potentials. With a rigorous\ndefinition of the time-dependent hole state (TDHS) using the time-domain\ngeneralization of extended Koopmans' theorem (TD-EKT), we derive the reduced\nion density matrix within the MCTDHF framework, which inherently encodes the\ntotal and channel-resolved photoionization cross sections of $\\mathrm{H_2O}$.\nThe cross sections obtained are benchmarked against existing experimental and\ntheoretical results, validating the TDHS formalism. Furthermore, by adjusting\nthe phase delay and intensity ratio of a pair of orthogonally polarized\nattosecond pulses, we explore the ultrafast control of attosecond coherence\nbetween electronic states of $\\mathrm{H_2O^+}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11319v1",
    "published": "2025-05-16T14:42:37+00:00",
    "categories": [
      "physics.atom-ph",
      "physics.chem-ph",
      "quant-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11318v2",
    "title": "On the Role of Weight Decay in Collaborative Filtering: A Popularity Perspective",
    "authors": [
      "Donald Loveland",
      "Mingxuan Ju",
      "Tong Zhao",
      "Neil Shah",
      "Danai Koutra"
    ],
    "abstract": "Collaborative filtering (CF) enables large-scale recommendation systems by\nencoding information from historical user-item interactions into dense\nID-embedding tables. However, as embedding tables grow, closed-form solutions\nbecome impractical, often necessitating the use of mini-batch gradient descent\nfor training. Despite extensive work on designing loss functions to train CF\nmodels, we argue that one core component of these pipelines is heavily\noverlooked: weight decay. Attaining high-performing models typically requires\ncareful tuning of weight decay, regardless of loss, yet its necessity is not\nwell understood. In this work, we question why weight decay is crucial in CF\npipelines and how it impacts training. Through theoretical and empirical\nanalysis, we surprisingly uncover that weight decay's primary function is to\nencode popularity information into the magnitudes of the embedding vectors.\nMoreover, we find that tuning weight decay acts as a coarse, non-linear knob to\ninfluence preference towards popular or unpopular items. Based on these\nfindings, we propose PRISM (Popularity-awaRe Initialization Strategy for\nembedding Magnitudes), a straightforward yet effective solution to simplify the\ntraining of high-performing CF models. PRISM pre-encodes the popularity\ninformation typically learned through weight decay, eliminating its necessity.\nOur experiments show that PRISM improves performance by up to 4.77% and reduces\ntraining times by 38.48%, compared to state-of-the-art training strategies.\nAdditionally, we parameterize PRISM to modulate the initialization strength,\noffering a cost-effective and meaningful strategy to mitigate popularity bias.",
    "pdf_url": "http://arxiv.org/pdf/2505.11318v2",
    "published": "2025-05-16T14:41:57+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11317v1",
    "title": "A Practical Approach for Computing the Diameter of a Point Set",
    "authors": [
      "Sariel Har-Peled"
    ],
    "abstract": "We present an approximation algorithm for computing the diameter of a\npoint-set in $\\Re^d$. The new algorithm is sensitive to the ``hardness'' of\ncomputing the diameter of the given input, and for most inputs it is able to\ncompute the exact diameter extremely fast. The new algorithm is simple, robust,\nhas good empirical performance, and can be implemented quickly. As such, it\nseems to be the algorithm of choice in practice for computing/approximating the\ndiameter.",
    "pdf_url": "http://arxiv.org/pdf/2505.11317v1",
    "published": "2025-05-16T14:41:15+00:00",
    "categories": [
      "cs.CG"
    ],
    "primary_category": "cs.CG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11578v4",
    "title": "Spatiotemporal Field Generation Based on Hybrid Mamba-Transformer with Physics-informed Fine-tuning",
    "authors": [
      "Peimian Du",
      "Jiabin Liu",
      "Xiaowei Jin",
      "Wangmeng Zuo",
      "Hui Li"
    ],
    "abstract": "This research confronts the challenge of substantial physical equation\ndiscrepancies encountered in the generation of spatiotemporal physical fields\nthrough data-driven trained models. A spatiotemporal physical field generation\nmodel, named HMT-PF, is developed based on the hybrid Mamba-Transformer\narchitecture, incorporating unstructured grid information as input. A\nfine-tuning block, enhanced with physical information, is introduced to\neffectively reduce the physical equation discrepancies. The physical equation\nresiduals are computed through a point query mechanism for efficient gradient\nevaluation, then encoded into latent space for refinement. The fine-tuning\nprocess employs a self-supervised learning approach to achieve physical\nconsistency while maintaining essential field characteristics. Results show\nthat the hybrid Mamba-Transformer model achieves good performance in generating\nspatiotemporal fields, while the physics-informed fine-tuning mechanism further\nreduces significant physical errors effectively. A MSE-R evaluation method is\ndeveloped to assess the accuracy and realism of physical field generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11578v4",
    "published": "2025-05-16T14:40:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11316v1",
    "title": "Unveiling the origin of the optical and UV emission during the 2017 giant outburst of the Galactic ULX pulsar Swift J0243.6+6124 (Corrigendum)",
    "authors": [
      "J. Alfonso-Garzón",
      "J. van den Eijnden",
      "N. P. M. Kuin",
      "F. Fürst",
      "A. Rouco-Escorial",
      "J. Fabregat",
      "P. Reig",
      "J. M. Mas-Hesse",
      "P. A. Jenke",
      "C. Malacaria",
      "C. Wilson-Hodge"
    ],
    "abstract": "An error was detected in the code of one of the components considered to\nmodel the optical/UV emission of the Galactic ULX pulsar Swift J0243.6+6124\nduring its 2017 giant outburst. This led to an overestimation of the\ncontribution from the X-ray heated surface of the Be star. The addition of the\nX-ray irradiation of a misaligned Be disk to our model is proposed to explain\nthe observations. Preliminary results of the updated model provide good fit to\nthe data.",
    "pdf_url": "http://arxiv.org/pdf/2505.11316v1",
    "published": "2025-05-16T14:40:49+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11315v1",
    "title": "Improving Inference-Time Optimisation for Vocal Effects Style Transfer with a Gaussian Prior",
    "authors": [
      "Chin-Yun Yu",
      "Marco A. Martínez-Ramírez",
      "Junghyun Koo",
      "Wei-Hsiang Liao",
      "Yuki Mitsufuji",
      "György Fazekas"
    ],
    "abstract": "Style Transfer with Inference-Time Optimisation (ST-ITO) is a recent approach\nfor transferring the applied effects of a reference audio to a raw audio track.\nIt optimises the effect parameters to minimise the distance between the style\nembeddings of the processed audio and the reference. However, this method\ntreats all possible configurations equally and relies solely on the embedding\nspace, which can lead to unrealistic or biased results. We address this pitfall\nby introducing a Gaussian prior derived from a vocal preset dataset, DiffVox,\nover the parameter space. The resulting optimisation is equivalent to\nmaximum-a-posteriori estimation. Evaluations on vocal effects transfer on the\nMedleyDB dataset show significant improvements across metrics compared to\nbaselines, including a blind audio effects estimator, nearest-neighbour\napproaches, and uncalibrated ST-ITO. The proposed calibration reduces parameter\nmean squared error by up to 33% and matches the reference style better.\nSubjective evaluations with 16 participants confirm our method's superiority,\nespecially in limited data regimes. This work demonstrates how incorporating\nprior knowledge in inference time enhances audio effects transfer, paving the\nway for more effective and realistic audio processing systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11315v1",
    "published": "2025-05-16T14:40:31+00:00",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.11314v1",
    "title": "CROC: Evaluating and Training T2I Metrics with Pseudo- and Human-Labeled Contrastive Robustness Checks",
    "authors": [
      "Christoph Leiter",
      "Yuki M. Asano",
      "Margret Keuper",
      "Steffen Eger"
    ],
    "abstract": "The assessment of evaluation metrics (meta-evaluation) is crucial for\ndetermining the suitability of existing metrics in text-to-image (T2I)\ngeneration tasks. Human-based meta-evaluation is costly and time-intensive, and\nautomated alternatives are scarce. We address this gap and propose CROC: a\nscalable framework for automated Contrastive Robustness Checks that\nsystematically probes and quantifies metric robustness by synthesizing\ncontrastive test cases across a comprehensive taxonomy of image properties.\nWith CROC, we generate a pseudo-labeled dataset (CROC$^{syn}$) of over one\nmillion contrastive prompt-image pairs to enable a fine-grained comparison of\nevaluation metrics. We also use the dataset to train CROCScore, a new metric\nthat achieves state-of-the-art performance among open-source methods,\ndemonstrating an additional key application of our framework. To complement\nthis dataset, we introduce a human-supervised benchmark (CROC$^{hum}$)\ntargeting especially challenging categories. Our results highlight robustness\nissues in existing metrics: for example, many fail on prompts involving\nnegation, and all tested open-source metrics fail on at least 25% of cases\ninvolving correct identification of body parts.",
    "pdf_url": "http://arxiv.org/pdf/2505.11314v1",
    "published": "2025-05-16T14:39:44+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11313v1",
    "title": "Thermal Static Potential and Pseudo-Scalar Quarkonium Spectral Functions from 2+1 Flavor Lattice QCD",
    "authors": [
      "Sajid Ali",
      "Dibyendu Bala",
      "Olaf Kaczmarek",
      "Pavan"
    ],
    "abstract": "Quarkonia, which are bound states of a heavy quark and antiquark, play a key\nrole in probing the quark-gluon plasma (QGP). The dynamics of quarkonia in the\nQGP are encoded in their finite-temperature spectral functions. In this work,\nwe estimate the quarkonium spectral functions in the pseudo-scalar channel\nusing 2+1 flavor lattice QCD with a pion mass of $320\\,\\text{MeV}$, at\ntemperatures of\n$220\\,\\text{MeV}\\,(1.2\\,T_{pc}),\\,251\\,\\text{MeV}\\,(1.4\\,T_{pc})\\,\\text{and}\\,293\\,\\text{MeV}\\,(1.6\\,T_{pc})$.\nReconstructing the spectral function from the Euclidean lattice correlator is a\nwell-known ill-posed problem, requiring additional physics-motivated input. We\naddress this by smoothly matching contributions from different frequency\nregions of the spectral function, using appropriate physics valid for each\nregion. The spectral function around $\\omega \\sim 2\\,M_q$ is obtained using a\nnon-perturbative complex potential, while for $\\omega \\gg 2\\,M_q$ it is modeled\nusing results from vacuum perturbation theory. Since the pseudoscalar channel\ndoes not receive a transport contribution near $\\omega \\sim 0$, we find that\nthe combination of these two regions already provides a good description of the\nrelativistic lattice pseudoscalar correlator. We observe a substantial thermal\nwidth in the $\\eta_c(1S)$ state, indicating that pseudoscalar charmonium\n($\\eta_c$) is nearing dissolution at the studied temperatures. In comparison,\nthe $\\eta_b$ ground state exhibits little change and remains well-defined.",
    "pdf_url": "http://arxiv.org/pdf/2505.11313v1",
    "published": "2025-05-16T14:39:38+00:00",
    "categories": [
      "hep-lat",
      "hep-ex",
      "hep-ph",
      "hep-th",
      "nucl-th"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2505.11312v3",
    "title": "Where You Place the Norm Matters: From Prejudiced to Neutral Initializations",
    "authors": [
      "Emanuele Francazi",
      "Francesco Pinto",
      "Aurelien Lucchi",
      "Marco Baity-Jesi"
    ],
    "abstract": "Normalization layers, such as Batch Normalization and Layer Normalization,\nare central components in modern neural networks, widely adopted to improve\ntraining stability and generalization. While their practical effectiveness is\nwell documented, a detailed theoretical understanding of how normalization\naffects model behavior, starting from initialization, remains an important open\nquestion. In this work, we investigate how both the presence and placement of\nnormalization within hidden layers influence the statistical properties of\nnetwork predictions before training begins. In particular, we study how these\nchoices shape the distribution of class predictions at initialization, which\ncan range from unbiased (Neutral) to highly concentrated (Prejudiced) toward a\nsubset of classes. Our analysis shows that normalization placement induces\nsystematic differences in the initial prediction behavior of neural networks,\nwhich in turn shape the dynamics of learning. By linking architectural choices\nto prediction statistics at initialization, our work provides a principled\nunderstanding of how normalization can influence early training behavior and\noffers guidance for more controlled and interpretable network design.",
    "pdf_url": "http://arxiv.org/pdf/2505.11312v3",
    "published": "2025-05-16T14:38:30+00:00",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11311v1",
    "title": "Explaining Strategic Decisions in Multi-Agent Reinforcement Learning for Aerial Combat Tactics",
    "authors": [
      "Ardian Selmonaj",
      "Alessandro Antonucci",
      "Adrian Schneider",
      "Michael Rüegsegger",
      "Matthias Sommer"
    ],
    "abstract": "Artificial intelligence (AI) is reshaping strategic planning, with\nMulti-Agent Reinforcement Learning (MARL) enabling coordination among\nautonomous agents in complex scenarios. However, its practical deployment in\nsensitive military contexts is constrained by the lack of explainability, which\nis an essential factor for trust, safety, and alignment with human strategies.\nThis work reviews and assesses current advances in explainability methods for\nMARL with a focus on simulated air combat scenarios. We proceed by adapting\nvarious explainability techniques to different aerial combat scenarios to gain\nexplanatory insights about the model behavior. By linking AI-generated tactics\nwith human-understandable reasoning, we emphasize the need for transparency to\nensure reliable deployment and meaningful human-machine interaction. By\nilluminating the crucial importance of explainability in advancing MARL for\noperational defense, our work supports not only strategic planning but also the\ntraining of military personnel with insightful and comprehensible analyses.",
    "pdf_url": "http://arxiv.org/pdf/2505.11311v1",
    "published": "2025-05-16T14:36:30+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.14707v1",
    "title": "CrypticBio: A Large Multimodal Dataset for Visually Confusing Biodiversity",
    "authors": [
      "Georgiana Manolache",
      "Gerard Schouten",
      "Joaquin Vanschoren"
    ],
    "abstract": "We present CrypticBio, the largest publicly available multimodal dataset of\nvisually confusing species, specifically curated to support the development of\nAI models in the context of biodiversity applications. Visually confusing or\ncryptic species are groups of two or more taxa that are nearly\nindistinguishable based on visual characteristics alone. While much existing\nwork addresses taxonomic identification in a broad sense, datasets that\ndirectly address the morphological confusion of cryptic species are small,\nmanually curated, and target only a single taxon. Thus, the challenge of\nidentifying such subtle differences in a wide range of taxa remains\nunaddressed. Curated from real-world trends in species misidentification among\ncommunity annotators of iNaturalist, CrypticBio contains 52K unique cryptic\ngroups spanning 67K species, represented in 166 million images. Rich\nresearch-grade image annotations--including scientific, multicultural, and\nmultilingual species terminology, hierarchical taxonomy, spatiotemporal\ncontext, and associated cryptic groups--address multimodal AI in biodiversity\nresearch. For easy dataset curation, we provide an open-source pipeline\nCrypticBio-Curate. The multimodal nature of the dataset beyond vision-language\narises from the integration of geographical and temporal data as complementary\ncues to identifying cryptic species. To highlight the importance of the\ndataset, we benchmark a suite of state-of-the-art foundation models across\nCrypticBio subsets of common, unseen, endangered, and invasive species, and\ndemonstrate the substantial impact of geographical context on vision-language\nzero-shot learning for cryptic species. By introducing CrypticBio, we aim to\ncatalyze progress toward real-world-ready biodiversity AI models capable of\nhandling the nuanced challenges of species ambiguity.",
    "pdf_url": "http://arxiv.org/pdf/2505.14707v1",
    "published": "2025-05-16T14:35:56+00:00",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2505.11310v1",
    "title": "Measurements of $W^+W^-$ production cross-sections in $pp$ collisions at $\\sqrt{s}=13$ TeV with the ATLAS detector",
    "authors": [
      "ATLAS Collaboration"
    ],
    "abstract": "Measurements of $W^+W^-\\rightarrow e^\\pm \\nu \\mu^\\mp \\nu$ production\ncross-sections are presented, providing a test of the predictions of\nperturbative quantum chromodynamics and the electroweak theory. The\nmeasurements are based on data from $pp$ collisions at $\\sqrt{s}=13$ TeV\nrecorded by the ATLAS detector at the Large Hadron Collider in 2015-2018,\ncorresponding to an integrated luminosity of 140 fb$^{-1}$. The number of\nevents due to top-quark pair production, the largest background, is reduced by\nrejecting events containing jets with $b$-hadron decays. An improved\nmethodology for estimating the remaining top-quark background enables a precise\nmeasurement of $W^+W^-$ cross-sections with no additional requirements on jets.\nThe fiducial $W^+W^-$ cross-section is determined in a maximum-likelihood fit\nwith an uncertainty of 3.1%. The measurement is extrapolated to the full phase\nspace, resulting in a total $W^+W^-$ cross-section of $127\\pm4$ pb.\nDifferential cross-sections are measured as a function of twelve observables\nthat comprehensively describe the kinematics of $W^+W^-$ events. The\nmeasurements are compared with state-of-the-art theory calculations and\nexcellent agreement with predictions is observed. A charge asymmetry in the\nlepton rapidity is observed as a function of the dilepton invariant mass, in\nagreement with the Standard Model expectation. A CP-odd observable is measured\nto be consistent with no CP violation. Limits on Standard Model effective field\ntheory Wilson coefficients in the Warsaw basis are obtained from the\ndifferential cross-sections.",
    "pdf_url": "http://arxiv.org/pdf/2505.11310v1",
    "published": "2025-05-16T14:35:52+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.11309v1",
    "title": "Decomposing stimulus-specific sensory neural information via diffusion models",
    "authors": [
      "Steeve Laquitaine",
      "Simone Azeglio",
      "Carlo Paris",
      "Ulisse Ferrari",
      "Matthew Chalk"
    ],
    "abstract": "To understand sensory coding, we must ask not only how much information\nneurons encode, but also what that information is about. This requires\ndecomposing mutual information into contributions from individual stimuli and\nstimulus features fundamentally ill-posed problem with infinitely many possible\nsolutions. We address this by introducing three core axioms, additivity,\npositivity, and locality that any meaningful stimulus-wise decomposition should\nsatisfy. We then derive a decomposition that meets all three criteria and\nremains tractable for high-dimensional stimuli. Our decomposition can be\nefficiently estimated using diffusion models, allowing for scaling up to\ncomplex, structured and naturalistic stimuli. Applied to a model of visual\nneurons, our method quantifies how specific stimuli and features contribute to\nencoded information. Our approach provides a scalable, interpretable tool for\nprobing representations in both biological and artificial neural systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11309v1",
    "published": "2025-05-16T14:34:55+00:00",
    "categories": [
      "q-bio.NC",
      "stat.ML"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11308v1",
    "title": "Reinforcement Learning Closures for Underresolved Partial Differential Equations using Synthetic Data",
    "authors": [
      "Lothar Heimbach",
      "Sebastian Kaltenbach",
      "Petr Karnakov",
      "Francis J. Alexander",
      "Petros Koumoutsakos"
    ],
    "abstract": "Partial Differential Equations (PDEs) describe phenomena ranging from\nturbulence and epidemics to quantum mechanics and financial markets. Despite\nrecent advances in computational science, solving such PDEs for real-world\napplications remains prohibitively expensive because of the necessity of\nresolving a broad range of spatiotemporal scales. In turn, practitioners often\nrely on coarse-grained approximations of the original PDEs, trading off\naccuracy for reduced computational resources. To mitigate the loss of detail\ninherent in such approximations, closure models are employed to represent\nunresolved spatiotemporal interactions. We present a framework for developing\nclosure models for PDEs using synthetic data acquired through the method of\nmanufactured solutions. These data are used in conjunction with reinforcement\nlearning to provide closures for coarse-grained PDEs. We illustrate the\nefficacy of our method using the one-dimensional and two-dimensional Burgers'\nequations and the two-dimensional advection equation. Moreover, we demonstrate\nthat closure models trained for inhomogeneous PDEs can be effectively\ngeneralized to homogeneous PDEs. The results demonstrate the potential for\ndeveloping accurate and computationally efficient closure models for systems\nwith scarce data.",
    "pdf_url": "http://arxiv.org/pdf/2505.11308v1",
    "published": "2025-05-16T14:34:42+00:00",
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11307v1",
    "title": "Diffusion Learning with Partial Agent Participation and Local Updates",
    "authors": [
      "Elsa Rizk",
      "Kun Yuan",
      "Ali H. Sayed"
    ],
    "abstract": "Diffusion learning is a framework that endows edge devices with advanced\nintelligence. By processing and analyzing data locally and allowing each agent\nto communicate with its immediate neighbors, diffusion effectively protects the\nprivacy of edge devices, enables real-time response, and reduces reliance on\ncentral servers. However, traditional diffusion learning relies on\ncommunication at every iteration, leading to communication overhead, especially\nwith large learning models. Furthermore, the inherent volatility of edge\ndevices, stemming from power outages or signal loss, poses challenges to\nreliable communication between neighboring agents. To mitigate these issues,\nthis paper investigates an enhanced diffusion learning approach incorporating\nlocal updates and partial agent participation. Local updates will curtail\ncommunication frequency, while partial agent participation will allow for the\ninclusion of agents based on their availability. We prove that the resulting\nalgorithm is stable in the mean-square error sense and provide a tight analysis\nof its Mean-Square-Deviation (MSD) performance. Various numerical experiments\nare conducted to illustrate our theoretical findings.",
    "pdf_url": "http://arxiv.org/pdf/2505.11307v1",
    "published": "2025-05-16T14:33:49+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11306v1",
    "title": "Effective Probabilistic Time Series Forecasting with Fourier Adaptive Noise-Separated Diffusion",
    "authors": [
      "Xinyan Wang",
      "Rui Dai",
      "Kaikui Liu",
      "Xiangxiang Chu"
    ],
    "abstract": "We propose the Fourier Adaptive Lite Diffusion Architecture (FALDA), a novel\nprobabilistic framework for time series forecasting. First, we introduce the\nDiffusion Model for Residual Regression (DMRR) framework, which unifies\ndiffusion-based probabilistic regression methods. Within this framework, FALDA\nleverages Fourier-based decomposition to incorporate a component-specific\narchitecture, enabling tailored modeling of individual temporal components. A\nconditional diffusion model is utilized to estimate the future noise term,\nwhile our proposed lightweight denoiser, DEMA (Decomposition MLP with AdaLN),\nconditions on the historical noise term to enhance denoising performance.\nThrough mathematical analysis and empirical validation, we demonstrate that\nFALDA effectively reduces epistemic uncertainty, allowing probabilistic\nlearning to primarily focus on aleatoric uncertainty. Experiments on six\nreal-world benchmarks demonstrate that FALDA consistently outperforms existing\nprobabilistic forecasting approaches across most datasets for long-term time\nseries forecasting while achieving enhanced computational efficiency without\ncompromising accuracy. Notably, FALDA also achieves superior overall\nperformance compared to state-of-the-art (SOTA) point forecasting approaches,\nwith improvements of up to 9%.",
    "pdf_url": "http://arxiv.org/pdf/2505.11306v1",
    "published": "2025-05-16T14:32:34+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11305v1",
    "title": "Systematic analysis of double Gamow-Teller sum rules",
    "authors": [
      "Hong-Jin Xie",
      "Yi Lu",
      "Shu-Yuan Liang",
      "Yang Lei",
      "Calvin W. Johnson"
    ],
    "abstract": "Sum rules are important bulk properties of transition strength functions for\natomic nuclei. Unlike the Ikeda sum rule for single Gamow-Teller transition,\ndouble Gamow-Teller transition sum rules rely on the details of many-body\nwavefunctions. We approximate the shell model ground state with nucleon-pair\ncondensates, by projection after variation, and compute double Gamow-Teller\n(DGT) transition sum rules from both $\\beta+$ and $\\beta-$ directions. By\nsystematic investigation of DGT sum rules of even-even nuclei in the $1s0d$,\n$1p0f$ major shells, we quantitatively estimate the model-dependent fractions\nin the sum rules, and analyze the importance of double isospin-analogue state\nin the DGT strength function.",
    "pdf_url": "http://arxiv.org/pdf/2505.11305v1",
    "published": "2025-05-16T14:32:26+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11304v1",
    "title": "Heterogeneity-Aware Client Sampling: A Unified Solution for Consistent Federated Learning",
    "authors": [
      "Shudi Weng",
      "Chao Ren",
      "Ming Xiao",
      "Mikael Skoglund"
    ],
    "abstract": "Federated learning (FL) commonly involves clients with diverse communication\nand computational capabilities. Such heterogeneity can significantly distort\nthe optimization dynamics and lead to objective inconsistency, where the global\nmodel converges to an incorrect stationary point potentially far from the\npursued optimum. Despite its critical impact, the joint effect of communication\nand computation heterogeneity has remained largely unexplored, due to the\nintrinsic complexity of their interaction. In this paper, we reveal the\nfundamentally distinct mechanisms through which heterogeneous communication and\ncomputation drive inconsistency in FL. To the best of our knowledge, this is\nthe first unified theoretical analysis of general heterogeneous FL, offering a\nprincipled understanding of how these two forms of heterogeneity jointly\ndistort the optimization trajectory under arbitrary choices of local solvers.\nMotivated by these insights, we propose Federated Heterogeneity-Aware Client\nSampling, FedACS, a universal method to eliminate all types of objective\ninconsistency. We theoretically prove that FedACS converges to the correct\noptimum at a rate of $O(1/\\sqrt{R})$, even in dynamic heterogeneous\nenvironments. Extensive experiments across multiple datasets show that FedACS\noutperforms state-of-the-art and category-specific baselines by 4.3%-36%, while\nreducing communication costs by 22%-89% and computation loads by 14%-105%,\nrespectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.11304v1",
    "published": "2025-05-16T14:31:36+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11303v1",
    "title": "Quantum Correlations in Three-Beam Symmetric Gaussian States Accessed via Photon-Number-Resolving Detection and Quantum Universal Invariants",
    "authors": [
      "Jan Peřina Jr.",
      "Nazarii Sudak",
      "Artur Barasiński",
      "Antonín Černoch"
    ],
    "abstract": "Quantum correlations of 3-beam symmetric Gaussian states are analyzed using\ntheir quantum universal invariants. These invariants, 1-, 2-, and 3-beam\npurities, are expressed in terms of the beams' intensity moments up to sixth\norder. The 3-beam symmetric Gaussian states with varying amounts of the noise\nare experimentally generated using entangled photon pairs from down-conversion,\ntheir invariants are determined, and their quantum correlations are quantified.\nThe coexistence of bi- and tripartite entanglement and genuine tripartite\nentanglement are observed in these states that resemble the noisy GHZ/W states.",
    "pdf_url": "http://arxiv.org/pdf/2505.11303v1",
    "published": "2025-05-16T14:31:22+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11302v1",
    "title": "Depth first representations of $k^2$-trees",
    "authors": [
      "Gabriel Carmona",
      "Giovanni Manzini"
    ],
    "abstract": "The $k^2$-tree is a compact data structure designed to efficiently store\nsparse binary matrices by leveraging both sparsity and clustering of nonzero\nelements. This representation supports efficiently navigational operations and\ncomplex binary operations, such as matrix-matrix multiplication, while\nmaintaining space efficiency. The standard $k^2$-tree follows a level-by-level\nrepresentation, which, while effective, prevents further compression of\nidentical subtrees and it si not cache friendly when accessing individual\nsubtrees. In this work, we introduce some novel depth-first representations of\nthe $k^2$-tree and propose an efficient linear-time algorithm to identify and\ncompress identical subtrees within these structures. Our experimental results\nshow that the use of a depth-first representations is a strategy worth\npursuing: for the adjacency matrix of web graphs exploiting the presence of\nidentical subtrees does improve the compression ratio, and for some matrices\ndepth-first representations turns out to be faster than the standard $k^2$-tree\nin computing the matrix-matrix multiplication.",
    "pdf_url": "http://arxiv.org/pdf/2505.11302v1",
    "published": "2025-05-16T14:30:46+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.11301v1",
    "title": "Geometry-of-numbers over number fields and the density of ADE families of curves having squarefree discriminant",
    "authors": [
      "Martí Oller"
    ],
    "abstract": "For families of curves arising from a Dynkin diagram of type ADE, we show\nthat the density of such curves having squarefree discriminant is equal to the\nproduct of local densities. We do so using the framework of Thorne and Laga's\nPhD theses and geometry-of-numbers techniques developed by Bhargava, here\nexpanded over number fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.11301v1",
    "published": "2025-05-16T14:30:44+00:00",
    "categories": [
      "math.NT",
      "11H99, 11N35, 17B70, 20G30"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11300v1",
    "title": "Spin effect in vacuum pair production under two-color rotating electric fields",
    "authors": [
      "Zhao-Yuan Chen",
      "Orkash Amat",
      "Jin-hui Bai",
      "Mamat Ali Bake"
    ],
    "abstract": "We investigated the spin effect on the vacuum pair production by\nDirac-Heisenberg-Wigner (DHW) formalism under two-color counter-rotating\nelectric fields. We primarily studied the combined effects of the field\nasymmetry, time delay, and frequency chirp on the particle momentum spectrum\nwith and without considering the spin effect. We have observed that the vacuum\npair production process demonstrates spin dependence even in a pure electric\nfield and is sensitive to variations in the field parameters. The results\nindicate that the spin-dependent momentum spectrum exhibited distinct outcomes\nfor various asymmetric fields with different chirp values and time delay. For\nan extended asymmetric field with large chirp and time delay, the particle\nnumber density can be increased by more than six orders of magnitude. The\nspin-up and spin-down particles are approximately comparable for a symmetric\nfield with a small-frequency chirp and are dominated by the spin-up particles\nfor a larger chirp. However, in the case of an asymmetric field, the increase\nin field asymmetry and the chirp parameter lead to a reversal of the spin\nasymmetry degree. For a shortened asymmetric electric field with a\nlarge-frequency chirp, the number of spin-up particles increases, leading to a\nspin asymmetry degree of $98.62\\%$. Conversely, in an extended asymmetric\nfield, the number of spin-down particles increases significantly, which\ncorresponds to a spin asymmetry degree of $99.94\\%$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11300v1",
    "published": "2025-05-16T14:30:30+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11577v1",
    "title": "The Accountability Paradox: How Platform API Restrictions Undermine AI Transparency Mandates",
    "authors": [
      "Florian A. D. Burnat",
      "Brittany I. Davidson"
    ],
    "abstract": "Recent application programming interface (API) restrictions on major social\nmedia platforms challenge compliance with the EU Digital Services Act [20],\nwhich mandates data access for algorithmic transparency. We develop a\nstructured audit framework to assess the growing misalignment between\nregulatory requirements and platform implementations. Our comparative analysis\nof X/Twitter, Reddit, TikTok, and Meta identifies critical ``audit\nblind-spots'' where platform content moderation and algorithmic amplification\nremain inaccessible to independent verification. Our findings reveal an\n``accountability paradox'': as platforms increasingly rely on AI systems, they\nsimultaneously restrict the capacity for independent oversight. We propose\ntargeted policy interventions aligned with the AI Risk Management Framework of\nthe National Institute of Standards and Technology [80], emphasizing federated\naccess models and enhanced regulatory enforcement.",
    "pdf_url": "http://arxiv.org/pdf/2505.11577v1",
    "published": "2025-05-16T14:30:20+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.0; E.0; K.4.1; K.4.2; K.4.3; K.5.0; K.5.2"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11299v1",
    "title": "Wave turbulence, thermalization and multimode locking in optical fibers",
    "authors": [
      "M. Ferraro",
      "K. Baudin",
      "M. Gervaziev",
      "A. Fusaro",
      "A. Picozzi",
      "J. Garnier",
      "G. Millot",
      "D. Kharenko",
      "E. Podivilov",
      "S. Babin",
      "F. Mangini",
      "S. Wabnitz"
    ],
    "abstract": "We present a comprehensive overview of recent advances in theory and\nexperiments on complex light propagation phenomena in nonlinear multimode\nfibers. On the basis of the wave turbulence theory, we derive kinetic equations\ndescribing the out-of-equilibrium process of optical thermalization toward the\nRayleigh-Jeans (RJ) equilibrium distribution. Our theory explains the effect of\nbeam self-cleaning (BSC) in graded-index (GRIN) fibers, whereby a speckled beam\ntransforms into a bell-shaped beam at the fiber output. We theoretically\nexplore the role of random refractive index fluctuations along the fiber, and\nshow how these imperfections can assist the observation of BSC in a practical\nexperimental setting. This conclusion is supported by the derivation of wave\nturbulence kinetic equations that account for the presence of a time-dependent\ndisorder (random mode coupling). The kinetic theory reveals that a weak\ndisorder accelerates the rate of RJ thermalization and condensation. On the\nother hand, although strong disorder is expected to suppress wave condensation,\nthe kinetic equation reveals that an out-of-equilibrium process of condensation\nand RJ thermalization can still occur. The kinetic equations are validated by\nnumerical simulations of the nonlinear Schrodinger equation. We outline a\nseries of recent experiments, which permit to confirm the statistical mechanics\napproach for describing beam propagation and thermalization. For example, we\nhighlight the demonstration of entropy growth, and point out that there are\ninherent limits to peak-power scaling in multimode fiber lasers. We conclude by\npointing out the experimental observation that BSC is accompanied by an effect\nof modal phase-locking. From the one hand this explains the observed\npreservation of the spatial coherence of the beam, but also it points to the\nneed of extending current descriptions in future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.11299v1",
    "published": "2025-05-16T14:30:18+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.11298v1",
    "title": "Graph Representational Learning: When Does More Expressivity Hurt Generalization?",
    "authors": [
      "Sohir Maskey",
      "Raffaele Paolino",
      "Fabian Jogl",
      "Gitta Kutyniok",
      "Johannes F. Lutzeyer"
    ],
    "abstract": "Graph Neural Networks (GNNs) are powerful tools for learning on structured\ndata, yet the relationship between their expressivity and predictive\nperformance remains unclear. We introduce a family of premetrics that capture\ndifferent degrees of structural similarity between graphs and relate these\nsimilarities to generalization, and consequently, the performance of expressive\nGNNs. By considering a setting where graph labels are correlated with\nstructural features, we derive generalization bounds that depend on the\ndistance between training and test graphs, model complexity, and training set\nsize. These bounds reveal that more expressive GNNs may generalize worse unless\ntheir increased complexity is balanced by a sufficiently large training set or\nreduced distance between training and test graphs. Our findings relate\nexpressivity and generalization, offering theoretical insights supported by\nempirical results.",
    "pdf_url": "http://arxiv.org/pdf/2505.11298v1",
    "published": "2025-05-16T14:28:34+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11297v2",
    "title": "Probing Subphonemes in Morphology Models",
    "authors": [
      "Gal Astrach",
      "Yuval Pinter"
    ],
    "abstract": "Transformers have achieved state-of-the-art performance in morphological\ninflection tasks, yet their ability to generalize across languages and\nmorphological rules remains limited. One possible explanation for this behavior\ncan be the degree to which these models are able to capture implicit phenomena\nat the phonological and subphonemic levels. We introduce a language-agnostic\nprobing method to investigate phonological feature encoding in transformers\ntrained directly on phonemes, and perform it across seven morphologically\ndiverse languages. We show that phonological features which are local, such as\nfinal-obstruent devoicing in Turkish, are captured well in phoneme embeddings,\nwhereas long-distance dependencies like vowel harmony are better represented in\nthe transformer's encoder. Finally, we discuss how these findings inform\nempirical strategies for training morphological models, particularly regarding\nthe role of subphonemic feature acquisition.",
    "pdf_url": "http://arxiv.org/pdf/2505.11297v2",
    "published": "2025-05-16T14:27:40+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11296v2",
    "title": "Diagrammatic expressions for steady-state distribution and static responses in population dynamics",
    "authors": [
      "Koya Katayama",
      "Ryuna Nagayama",
      "Sosuke Ito"
    ],
    "abstract": "One of the fundamental questions in population dynamics is how biological\npopulations respond to environmental perturbations. In population dynamics, the\nmean fitness and the fraction of a trait in the steady state are important\nbecause they indicate how well the trait and the population adapt to the\nenvironment. In this study, we examine the parallel mutation-reproduction\nmodel, which is one of the simplest models of an evolvable population. As an\nextension of the Markov chain tree theorem, we derive diagrammatic expressions\nfor the static responses of mean fitness and the steady-state distribution of\nthe population. For the parallel mutation-reproduction model, we consider\nself-loops, which represent trait reproduction and are excluded from the Markov\nchain tree theorem for the linear master equation. To generalize the theorem,\nwe introduce the concept of rooted $0$/$1$ loop forests, which generalize\nspanning trees with loops. We demonstrate that the weights of rooted $0$/$1$\nloop forests yield the static responses of mean fitness and the steady-state\ndistribution. Our results provide exact expressions for the static responses\nand the steady-state distribution. Additionally, we discuss approximations of\nthese expressions in cases where reproduction or mutation is dominant. We\nprovide numerical examples to illustrate these approximations and exact\nexpressions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11296v2",
    "published": "2025-05-16T14:26:35+00:00",
    "categories": [
      "q-bio.PE",
      "cond-mat.stat-mech"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11295v1",
    "title": "Prime Number Error Terms",
    "authors": [
      "Nathan Ng"
    ],
    "abstract": "In 1980 Montgomery made a conjecture about the true order of the error term\nin the prime number theorem. In 2012 the author made an analogous conjecture\nfor the true order of the sum of the M\\\"{o}bius function, $M(x)$. This refined\nan earlier conjecture of Gonek from the 1990's. In this article we speculate on\nthe true size of a large class of prime number error terms and present a\ngeneral conjecture. This general conjecture includes both Montgomery's\nconjecture and the conjecture for $M(x)$ as special cases. Recently, Lamzouri\n(Springer volume: Essays in Analytic Number Theory, In Honor of Helmut Maier's\n70th birthday) showed that an effective linear independence conjecture (ELI)\nfor the zeros of the zeta function implies one of the inequalities in\nMontgomery's conjecture. In this article we adapt Lamzouri's method to show\nthat a generalized effective linear independence (GELI) conjecture implies a\nlower bound for general prime number error terms. Furthermore, of independent\ninterest, we prove an $L^2$ bound for almost periodic functions. This allows us\nto weaken significantly one of the conditions in Lamzouri's main result and\nalso give an improvement of the main theorem in an article of Akbary-Ng-Shahabi\n(Q. J. Math. 65 (2014), no. 3).",
    "pdf_url": "http://arxiv.org/pdf/2505.11295v1",
    "published": "2025-05-16T14:26:19+00:00",
    "categories": [
      "math.NT",
      "11M26 11N56, 11N05, 11J72"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11294v2",
    "title": "Bidirectional Information Flow (BIF) -- A Sample Efficient Hierarchical Gaussian Process for Bayesian Optimization",
    "authors": [
      "Juan D. Guerra",
      "Thomas Garbay",
      "Guillaume Lajoie",
      "Marco Bonizzato"
    ],
    "abstract": "Hierarchical Gaussian Process (H-GP) models divide problems into different\nsubtasks, allowing for different models to address each part, making them\nwell-suited for problems with inherent hierarchical structure. However, typical\nH-GP models do not fully take advantage of this structure, only sending\ninformation up or down the hierarchy. This one-way coupling limits sample\nefficiency and slows convergence. We propose Bidirectional Information Flow\n(BIF), an efficient H-GP framework that establishes bidirectional information\nexchange between parent and child models in H-GPs for online training. BIF\nretains the modular structure of hierarchical models - the parent combines\nsubtask knowledge from children GPs - while introducing top-down feedback to\ncontinually refine children models during online learning. This mutual exchange\nimproves sample efficiency, enables robust training, and allows modular reuse\nof learned subtask models. BIF outperforms conventional H-GP Bayesian\nOptimization methods, achieving up to 4x and 3x higher $R^2$ scores for the\nparent and children respectively, on synthetic and real-world neurostimulation\noptimization tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11294v2",
    "published": "2025-05-16T14:26:03+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11293v1",
    "title": "Breaking the Batch Barrier (B3) of Contrastive Learning via Smart Batch Mining",
    "authors": [
      "Raghuveer Thirukovalluru",
      "Rui Meng",
      "Ye Liu",
      "Karthikeyan K",
      "Mingyi Su",
      "Ping Nie",
      "Semih Yavuz",
      "Yingbo Zhou",
      "Wenhu Chen",
      "Bhuwan Dhingra"
    ],
    "abstract": "Contrastive learning (CL) is a prevalent technique for training embedding\nmodels, which pulls semantically similar examples (positives) closer in the\nrepresentation space while pushing dissimilar ones (negatives) further apart. A\nkey source of negatives are 'in-batch' examples, i.e., positives from other\nexamples in the batch. Effectiveness of such models is hence strongly\ninfluenced by the size and quality of training batches. In this work, we\npropose 'Breaking the Batch Barrier' (B3), a novel batch construction strategy\ndesigned to curate high-quality batches for CL. Our approach begins by using a\npretrained teacher embedding model to rank all examples in the dataset, from\nwhich a sparse similarity graph is constructed. A community detection algorithm\nis then applied to this graph to identify clusters of examples that serve as\nstrong negatives for one another. The clusters are then used to construct\nbatches that are rich in in-batch negatives. Empirical results on the MMEB\nmultimodal embedding benchmark (36 tasks) demonstrate that our method sets a\nnew state of the art, outperforming previous best methods by +1.3 and +2.9\npoints at the 7B and 2B model scales, respectively. Notably, models trained\nwith B3 surpass existing state-of-the-art results even with a batch size as\nsmall as 64, which is 4-16x smaller than that required by other methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.11293v1",
    "published": "2025-05-16T14:25:43+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11292v2",
    "title": "Status of the International Linear Collider",
    "authors": [
      "Y. Abe",
      "S. Arai",
      "S. Araki",
      "H. Araki",
      "Y. Arimoto",
      "A. Aryshev",
      "S. Asai",
      "R. Bajpai",
      "T. Behnke",
      "S. Belomestnykh",
      "I. Bozovic",
      "J. E. Brau",
      "K. Buesser",
      "P. N. Burrows",
      "N. Catalan-Lasheras",
      "E. Cenni",
      "S. Chen",
      "J. Clark",
      "D. Delikaris",
      "M. Demarteau",
      "D. Denisov",
      "S. Doebert",
      "T. Dohmae",
      "R. Dowd",
      "G. Dugan",
      "M. Egi",
      "Y. Enomoto",
      "A. Faus Golfe",
      "F. Forti",
      "K. Fujii",
      "M. Fukuda",
      "F. Gaede",
      "Y. Gao",
      "L. Garcia-Tabares",
      "R. L. Geng",
      "T. Goto",
      "J. Grames",
      "K. Hanagaki",
      "T. Hara",
      "K. Hara",
      "C. Hensel",
      "M. Hiraki",
      "S. Hirose",
      "T. Honma",
      "Y. Horii",
      "K. Inami",
      "M. Ishino",
      "H. Ito",
      "M. Iwasaki",
      "D. Jeans",
      "O. Jinnouchi",
      "R. Katayama",
      "K. Kawagoe",
      "S. Kessoku",
      "T. Kitahara",
      "T. Koseki",
      "K. Krueger",
      "T. Kubo",
      "K. Kubo",
      "A. Kumar",
      "M. Kurata",
      "M. Kuriki",
      "A. J. Lankford",
      "A. Latina",
      "R. Laxdal",
      "M. Liepe",
      "J. List",
      "B. List",
      "C. Madec",
      "J. Maeda",
      "T. W. Markiewicz",
      "T. Masubuchi",
      "T. Matsumoto",
      "K. Mazumdar",
      "P. McBride",
      "P. A. McIntosh",
      "S. Michizono",
      "T. Miura",
      "L. Monaco",
      "G. Moortgat-Pick",
      "T. Mori",
      "Y. Morikawa",
      "H. Murayama",
      "T. Nakada",
      "H. Nakai",
      "H. Nakajima",
      "E. Nakamura",
      "K. Nakamura",
      "K. Nakanishi",
      "T. Nakaya",
      "O. Napoly",
      "S. Narita",
      "M. Nojiri",
      "H. Oide",
      "Y. Okada",
      "T. Okugi",
      "C. Oliver Amoros",
      "M. Omet",
      "W. Ootani",
      "J. Osborne",
      "B. Parker",
      "J. R. Patterson",
      "R. Pöschl",
      "M. E. Peskin",
      "K. Popov",
      "S. Posen",
      "S. Riemann",
      "R. A. Rimmer",
      "A. Robson",
      "M. C. Ross",
      "R. Ruber",
      "D. L. Rubin",
      "T. Saeki",
      "N. Saito",
      "H. Sakai",
      "T. Sanuki",
      "M. Sato",
      "S. Shanab",
      "H. Shimizu",
      "P. Sievers",
      "F. Simon",
      "N. Solyak",
      "S. Stapnes",
      "J. Strube",
      "T. Suehara",
      "R. Takahashi",
      "T. Takahashi",
      "G. Taylor",
      "N. Terunuma",
      "J. Tian",
      "M. Titov",
      "M. Togawa",
      "K. Tsumura",
      "R. Ueki",
      "K. Umemori",
      "P. Urquijo",
      "Y. Ushiroda",
      "C. Vernieri",
      "E. Viklund",
      "M. Vos",
      "N. Walker",
      "Y. Watanabe",
      "H. Weise",
      "A. P. White",
      "T. Yamada",
      "A. Yamamoto",
      "Y. Yamamoto",
      "M. Yamauchi",
      "K. Yokoya",
      "A. F. Zarnecki",
      "J. Zhang",
      "M. Zobov"
    ],
    "abstract": "This paper is not a proposal for a CERN future project but provides\ninformation on the International Linear Collider (ILC) considered for Japan in\norder to facilitate the European Strategy discussion in a global context. It\ndescribes progress to date, ongoing engineering studies, updated cost estimate\nfor the machine at $\\sqrt{s}=250~\\rm GeV$ and the situation in Japan. The\nphysics of the ILC is not presented here, but jointly for all Linear Collider\nprojects in a separate document ``A Linear Collider Vision for the Future of\nParticle Physics'' submitted for the forthcoming European Strategy\ndeliberations.",
    "pdf_url": "http://arxiv.org/pdf/2505.11292v2",
    "published": "2025-05-16T14:25:38+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.11291v1",
    "title": "Theta classes: generalized topological recursion, integrability and $\\mathcal{W}$-constraints",
    "authors": [
      "Vincent Bouchard",
      "Nitin K. Chidambaram",
      "Alessandro Giacchetto",
      "Sergey Shadrin"
    ],
    "abstract": "We study the intersection theory of the $\\Theta^{r,s}$-classes, where $r \\geq\n2$ and $1 \\le s \\le r-1$, which are cohomological field theories obtained as\nthe top degrees of Chiodo classes. We show that the recently introduced\ngeneralized topological recursion on the $(r,s)$ spectral curves computes the\ndescendant integrals of the $\\Theta^{r,s}$-classes. As a consequence, we deduce\nthat the descendant potential of the $\\Theta^{r,s}$-classes is a tau function\nof the $r$-KdV hierarchy, generalizing the Br\\'ezin--Gross--Witten tau function\n(the special case $r=2$, $s=1$). We also explicitly compute the\n$\\mathcal{W}$-constraints satisfied by the descendant potential, obtained as\ndifferential representations of the $\\mathcal{W}(\\mathfrak{gl}_r)$-algebra at\nself-dual level. This work extends previously known results on the Witten\n$r$-spin class, the $r$-spin $\\Theta$-classes (the case $s=r-1$), and the\nNorbury $\\Theta$-classes (the special case $r=2$, $s=1$).",
    "pdf_url": "http://arxiv.org/pdf/2505.11291v1",
    "published": "2025-05-16T14:25:18+00:00",
    "categories": [
      "math.AG",
      "math-ph",
      "math.MP",
      "nlin.SI",
      "14H10, 14H70 (Primary) 81R10 (Secondary)"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11290v1",
    "title": "Time-dependent Hole States in Multiconfigurational Time-Dependent Hartree-Fock Approaches: A Time-Domain Generalization of Extended Koopmans' Theorem",
    "authors": [
      "Zhao-Han Zhang",
      "Yang Li",
      "Himadri Pathak",
      "Takeshi Sato",
      "Kenichi L. Ishikawa",
      "Feng He"
    ],
    "abstract": "We introduce a time-domain generalization of the extended Koopmans' theorem\nwithin the framework of the multiconfigurational time-dependent Hartree-Fock\n(MCTDHF) theory. This formulation naturally yields well-defined time-dependent\nhole states formed by removing one electron from the multielectron system,\nenabling the instantaneous construction of reduced density matrices for the\nphotofragments during MCTDHF simulations with negligible computational\noverhead. Leveraging this foundation, we derive the equation of motion for the\ntime-dependent Dyson orbitals and develop a systematic approach to extract\nhole-resolved observables directly from the time-dependent \\textit{ab initio}\nwavefunctions, such as channel-resolved photoelectron momentum distributions.\nThe proposed method is universally applicable to both projection-based and\nflux-based schemes, offering a powerful tool for disentangling correlated\nelectron-hole dynamics in ultrafast multichannel ionization processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.11290v1",
    "published": "2025-05-16T14:24:34+00:00",
    "categories": [
      "physics.atom-ph",
      "physics.chem-ph",
      "quant-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11289v1",
    "title": "Meta-World+: An Improved, Standardized, RL Benchmark",
    "authors": [
      "Reginald McLean",
      "Evangelos Chatzaroulas",
      "Luc McCutcheon",
      "Frank Röder",
      "Tianhe Yu",
      "Zhanpeng He",
      "K. R. Zentner",
      "Ryan Julian",
      "J K Terry",
      "Isaac Woungang",
      "Nariman Farsad",
      "Pablo Samuel Castro"
    ],
    "abstract": "Meta-World is widely used for evaluating multi-task and meta-reinforcement\nlearning agents, which are challenged to master diverse skills simultaneously.\nSince its introduction however, there have been numerous undocumented changes\nwhich inhibit a fair comparison of algorithms. This work strives to\ndisambiguate these results from the literature, while also leveraging the past\nversions of Meta-World to provide insights into multi-task and\nmeta-reinforcement learning benchmark design. Through this process we release a\nnew open-source version of Meta-World\n(https://github.com/Farama-Foundation/Metaworld/) that has full reproducibility\nof past results, is more technically ergonomic, and gives users more control\nover the tasks that are included in a task set.",
    "pdf_url": "http://arxiv.org/pdf/2505.11289v1",
    "published": "2025-05-16T14:24:03+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11288v1",
    "title": "Generalized Parton Distributions from Lattice QCD with Asymmetric Momentum Transfer: Tensor Case",
    "authors": [
      "Shohini Bhattacharya",
      "Krzysztof Cichy",
      "Martha Constantinou",
      "Andreas Metz",
      "Joshua Miller",
      "Peter Petreczky",
      "Fernanda Steffens"
    ],
    "abstract": "The calculation of generalized parton distributions (GPDs) in lattice QCD was\ntraditionally done by calculating matrix elements in the symmetric frame.\nRecent advancements have significantly reduced computational costs by\ncalculating these matrix elements in the asymmetric frame, allowing us to\nchoose the momentum transfer to be in either the initial or final states only.\nThe theoretical methodology requires a new parametrization of the matrix\nelement to obtain Lorentz-invariant amplitudes, which are then related to the\nGPDs. The formulation and implementation of this approach have already been\nestablished for the unpolarized and helicity GPDs. Building upon this idea, we\nextend this formulation to the four leading-twist quark transversity GPDs\n($H_T$, $E_T$, $\\widetilde{H}_T$, $\\widetilde{E}_T$). We also present numerical\nresults for zero skewness using an $N_f=2+1+1$ ensemble of twisted mass\nfermions with a clover improvement. The light quark masses employed in these\ncalculations correspond to a pion mass of about 260 MeV. Furthermore, we\ninclude a comparison between the symmetric and asymmetric frame calculations to\ndemonstrate frame independence of the Lorentz-invariant amplitudes. Analysis of\nthe matrix elements in the asymmetric frame is performed at several values of\nthe momentum transfer squared, $-t$, ranging from 0.17 GeV$^2$ to 2.29 GeV$^2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11288v1",
    "published": "2025-05-16T14:24:02+00:00",
    "categories": [
      "hep-lat",
      "hep-ex",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2505.11287v1",
    "title": "Representable triangulated functors in terms of semiorthogonal decompositions",
    "authors": [
      "Jonas Frank",
      "Mathias Schulze"
    ],
    "abstract": "A theorem of Bondal and Kapranov lifts representations of cohomological\nfunctors from semiorthogonal decompositions of triangulated categories. We\npresent a version of this result for triangulated functors. To this end, we\nintroduce suitable terminology in enriched category theory and transfer the\noriginal proof.",
    "pdf_url": "http://arxiv.org/pdf/2505.11287v1",
    "published": "2025-05-16T14:23:36+00:00",
    "categories": [
      "math.CT",
      "18A22, 18E40 (Primary) 18G80, 18D20 (Secondary)"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11286v1",
    "title": "Quantum compressed sensing tomographic reconstruction algorithm",
    "authors": [
      "Arim Ryou",
      "Kiwoong Kim",
      "Kyungtaek Jun"
    ],
    "abstract": "Computed tomography (CT) is a non-destructive technique for observing\ninternal images and has proven highly valuable in medical diagnostics. Recent\nadvances in quantum computing have begun to influence tomographic\nreconstruction techniques. The quantum tomographic reconstruction algorithm is\nless affected by artifacts or noise than classical algorithms by using the\nsquare function of the difference between pixels obtained by projecting CT\nimages in quantum superposition states and pixels obtained from experimental\ndata. In particular, by using quantum linear systems, a fast quadratic\nunconstrained binary optimization (QUBO) model formulation for quantum\ntomographic reconstruction is possible. In this paper, we formulate the QUBO\nmodel for quantum compressed sensing tomographic reconstruction, which is a\nlinear combination of the QUBO model for quantum tomographic reconstruction and\nthe QUBO model for total variation in quantum superposition-state CT images. In\nour experiments, we used sinograms obtained by using the Radon transform of\nShepp-Logan images and body CT images. We evaluate the performance of the new\nalgorithm by reconstructing CT images using a hybrid solver with the QUBO model\ncomputed from each sinogram. The new algorithm was able to obtain a solution\nwithin 5 projection images for 30 by 30 image samples and within 6 projection\nimages for 60 by 60 image samples, reconstructing error-free CT images. We\nanticipate that quantum compressed sensing tomographic reconstruction\nalgorithms could significantly reduce the total radiation dose when quantum\ncomputing performance advances.",
    "pdf_url": "http://arxiv.org/pdf/2505.11286v1",
    "published": "2025-05-16T14:23:10+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11285v2",
    "title": "Linear Magnetoresistance and Anomalous Hall Effect in the Superconductor NiBi$_{3}$",
    "authors": [
      "Gabriel Sant'ana",
      "Jully Paola Peña Pacheco",
      "David Mockli",
      "Fabiano Mesquita da Rosa",
      "Sergio Garcia Magalhães",
      "Paulo Pureur",
      "Milton A. Tumelero"
    ],
    "abstract": "The NiBi$_{3}$ compound exhibits a compelling interplay between\nsuperconductivity and magnetism, further enriched by topological\ncharacteristics that make it an exceptional platform for exploring emergent\nelectronic phenomena. Here, we report experimental evidence of unconventional\nmagnetic phenomena in high-quality single crystals of NiBi$_3$, revealed\nthrough detailed magnetotransport measurements. The magnetoresistance displays\na non-usual temperature dependence, featuring both a classical Lorentz-like\ncomponent and a linear-in-field contribution. In addition, anomalous Hall\neffect signal persist down to the superconducting transition temperature and\nvanish above 75 K. These observations suggest that magnetic fluctuations play a\nsignificant role in charge transport in NiBi$_{3}$, highlighting a magnetically\nand topologically intertwined electronic structure. Our findings underscore the\ncomplex and multifaceted nature of this material.",
    "pdf_url": "http://arxiv.org/pdf/2505.11285v2",
    "published": "2025-05-16T14:23:08+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.11284v1",
    "title": "Strictly abnormal geodesics with a degeneracy point in the interior of their domain",
    "authors": [
      "Nicola Paddeu",
      "Alessandro Socionovo"
    ],
    "abstract": "In this article, we study abnormal curves in a family of sub-Riemannian\nmanifolds of rank 2. We focus on abnormal curves whose lifts to the cotangent\nbundle annihilate, at an interior point of the domain, all Lie brackets of\nlength up to three of vector fields tangent to the distribution. We present a\nmethod to prove that such curves are length-minimizing. Finally, we prove that\nstrictly abnormal geodesics may cease to be locally length-minimizing after a\nchange of the metric.",
    "pdf_url": "http://arxiv.org/pdf/2505.11284v1",
    "published": "2025-05-16T14:22:36+00:00",
    "categories": [
      "math.DG",
      "math.OC",
      "53C17"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11283v2",
    "title": "SubROC: AUC-Based Discovery of Exceptional Subgroup Performance for Binary Classifiers",
    "authors": [
      "Tom Siegl",
      "Kutalmış Coşkun",
      "Bjarne C. Hiller",
      "Amin Mirzaei",
      "Florian Lemmerich",
      "Martin Becker"
    ],
    "abstract": "Machine learning (ML) is increasingly employed in real-world applications\nlike medicine or economics, thus, potentially affecting large populations.\nHowever, ML models often do not perform homogeneously, leading to\nunderperformance or, conversely, unusually high performance in certain\nsubgroups (e.g., sex=female AND marital_status=married). Identifying such\nsubgroups can support practical decisions on which subpopulation a model is\nsafe to deploy or where more training data is required. However, an efficient\nand coherent framework for effective search is missing. Consequently, we\nintroduce SubROC, an open-source, easy-to-use framework based on Exceptional\nModel Mining for reliably and efficiently finding strengths and weaknesses of\nclassification models in the form of interpretable population subgroups. SubROC\nincorporates common evaluation measures (ROC and PR AUC), efficient search\nspace pruning for fast exhaustive subgroup search, control for class imbalance,\nadjustment for redundant patterns, and significance testing. We illustrate the\npractical benefits of SubROC in case studies as well as in comparative analyses\nacross multiple datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.11283v2",
    "published": "2025-05-16T14:18:40+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11282v2",
    "title": "MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection",
    "authors": [
      "Shrutarv Awasthi",
      "Anas Gouda",
      "Sven Franke",
      "Jérôme Rutinowski",
      "Frank Hoffmann",
      "Moritz Roidl"
    ],
    "abstract": "Mobile robots are reaching unprecedented speeds, with platforms like Unitree\nB2, and Fraunhofer O3dyn achieving maximum speeds between 5 and 10 m/s.\nHowever, effectively utilizing such speeds remains a challenge due to the\nlimitations of RGB cameras, which suffer from motion blur and fail to provide\nreal-time responsiveness. Event cameras, with their asynchronous operation, and\nlow-latency sensing, offer a promising alternative for high-speed robotic\nperception. In this work, we introduce MTevent, a dataset designed for 6D pose\nestimation and moving object detection in highly dynamic environments with\nlarge detection distances. Our setup consists of a stereo-event camera and an\nRGB camera, capturing 75 scenes, each on average 16 seconds, and featuring 16\nunique objects under challenging conditions such as extreme viewing angles,\nvarying lighting, and occlusions. MTevent is the first dataset to combine\nhigh-speed motion, long-range perception, and real-world object interactions,\nmaking it a valuable resource for advancing event-based vision in robotics. To\nestablish a baseline, we evaluate the task of 6D pose estimation using NVIDIA's\nFoundationPose on RGB images, achieving an Average Recall of 0.22 with\nground-truth masks, highlighting the limitations of RGB-based approaches in\nsuch dynamic settings. With MTevent, we provide a novel resource to improve\nperception models and foster further research in high-speed robotic vision. The\ndataset is available for download\nhttps://huggingface.co/datasets/anas-gouda/MTevent",
    "pdf_url": "http://arxiv.org/pdf/2505.11282v2",
    "published": "2025-05-16T14:18:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11281v1",
    "title": "Adaptive Linear Embedding for Nonstationary High-Dimensional Optimization",
    "authors": [
      "Yuejiang Wen",
      "Paul D. Franzon"
    ],
    "abstract": "Bayesian Optimization (BO) in high-dimensional spaces remains fundamentally\nlimited by the curse of dimensionality and the rigidity of global\nlow-dimensional assumptions. While Random EMbedding Bayesian Optimization\n(REMBO) mitigates this via linear projections into low-dimensional subspaces,\nit typically assumes a single global embedding and a stationary objective. In\nthis work, we introduce Self-Adaptive embedding REMBO (SA-REMBO), a novel\nframework that generalizes REMBO to support multiple random Gaussian\nembeddings, each capturing a different local subspace structure of the\nhigh-dimensional objective. An index variable governs the embedding choice and\nis jointly modeled with the latent optimization variable via a product kernel\nin a Gaussian Process surrogate. This enables the optimizer to adaptively\nselect embeddings conditioned on location, effectively capturing locally\nvarying effective dimensionality, nonstationarity, and heteroscedasticity in\nthe objective landscape. We theoretically analyze the expressiveness and\nstability of the index-conditioned product kernel and empirically demonstrate\nthe advantage of our method across synthetic and real-world high-dimensional\nbenchmarks, where traditional REMBO and other low-rank BO methods fail. Our\nresults establish SA-REMBO as a powerful and flexible extension for scalable BO\nin complex, structured design spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.11281v1",
    "published": "2025-05-16T14:18:19+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.17052v1",
    "title": "SpecEdge: Scalable Edge-Assisted Serving Framework for Interactive LLMs",
    "authors": [
      "Jinwoo Park",
      "Seunggeun Cho",
      "Dongsu Han"
    ],
    "abstract": "Large language models (LLMs) power many modern applications, but serving them\nat scale remains costly and resource-intensive. Current server-centric systems\noverlook consumer-grade GPUs at the edge. We introduce SpecEdge, an\nedge-assisted inference framework that splits LLM workloads between edge and\nserver GPUs using a speculative decoding scheme, exchanging only token outputs\nover the network. SpecEdge employs proactive edge drafting to overlap edge\ntoken creation with server verification and pipeline-aware scheduling that\ninterleaves multiple user requests to increase server-side throughput.\nExperiments show SpecEdge enhances overall cost efficiency by 1.91x through\nachieving 2.22x server throughput, and reduces inter token latency by 11.24%\ncompared to a server-only baseline, introducing a scalable, cost-effective\nparadigm for LLM serving.",
    "pdf_url": "http://arxiv.org/pdf/2505.17052v1",
    "published": "2025-05-16T14:17:59+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11280v1",
    "title": "Temporal fine-tuning for early risk detection",
    "authors": [
      "Horacio Thompson",
      "Esaú Villatoro-Tello",
      "Manuel Montes-y-Gómez",
      "Marcelo Errecalde"
    ],
    "abstract": "Early Risk Detection (ERD) on the Web aims to identify promptly users facing\nsocial and health issues. Users are analyzed post-by-post, and it is necessary\nto guarantee correct and quick answers, which is particularly challenging in\ncritical scenarios. ERD involves optimizing classification precision and\nminimizing detection delay. Standard classification metrics may not suffice,\nresorting to specific metrics such as ERDE(theta) that explicitly consider\nprecision and delay. The current research focuses on applying a multi-objective\napproach, prioritizing classification performance and establishing a separate\ncriterion for decision time. In this work, we propose a completely different\nstrategy, temporal fine-tuning, which allows tuning transformer-based models by\nexplicitly incorporating time within the learning process. Our method allows us\nto analyze complete user post histories, tune models considering different\ncontexts, and evaluate training performance using temporal metrics. We\nevaluated our proposal in the depression and eating disorders tasks for the\nSpanish language, achieving competitive results compared to the best models of\nMentalRiskES 2023. We found that temporal fine-tuning optimized decisions\nconsidering context and time progress. In this way, by properly taking\nadvantage of the power of transformers, it is possible to address ERD by\ncombining precision and speed as a single objective.",
    "pdf_url": "http://arxiv.org/pdf/2505.11280v1",
    "published": "2025-05-16T14:17:03+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11279v2",
    "title": "Existence theory for linear-growth variational integrals with signed measure data",
    "authors": [
      "Eleonora Ficola",
      "Thomas Schmidt"
    ],
    "abstract": "We develop a semicontinuity-based existence theory in $\\mathrm{BV}$ for a\ngeneral class of scalar linear-growth variational integrals with additional\nsigned-measure terms. The results extend and refine previous considerations for\nanisotropic total variations and area-type cases, and they pave the way for a\nvariational approach to the corresponding Euler-Lagrange equations, which\ninvolve the signed measure as right-hand-side datum.",
    "pdf_url": "http://arxiv.org/pdf/2505.11279v2",
    "published": "2025-05-16T14:14:51+00:00",
    "categories": [
      "math.AP",
      "49J45, 35R06, 35J20, 26B30"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11278v1",
    "title": "A Fourier Space Perspective on Diffusion Models",
    "authors": [
      "Fabian Falck",
      "Teodora Pandeva",
      "Kiarash Zahirnia",
      "Rachel Lawrence",
      "Richard Turner",
      "Edward Meeds",
      "Javier Zazo",
      "Sushrut Karmalkar"
    ],
    "abstract": "Diffusion models are state-of-the-art generative models on data modalities\nsuch as images, audio, proteins and materials. These modalities share the\nproperty of exponentially decaying variance and magnitude in the Fourier\ndomain. Under the standard Denoising Diffusion Probabilistic Models (DDPM)\nforward process of additive white noise, this property results in\nhigh-frequency components being corrupted faster and earlier in terms of their\nSignal-to-Noise Ratio (SNR) than low-frequency ones. The reverse process then\ngenerates low-frequency information before high-frequency details. In this\nwork, we study the inductive bias of the forward process of diffusion models in\nFourier space. We theoretically analyse and empirically demonstrate that the\nfaster noising of high-frequency components in DDPM results in violations of\nthe normality assumption in the reverse process. Our experiments show that this\nleads to degraded generation quality of high-frequency components. We then\nstudy an alternate forward process in Fourier space which corrupts all\nfrequencies at the same rate, removing the typical frequency hierarchy during\ngeneration, and demonstrate marked performance improvements on datasets where\nhigh frequencies are primary, while performing on par with DDPM on standard\nimaging benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11278v1",
    "published": "2025-05-16T14:13:02+00:00",
    "categories": [
      "stat.ML",
      "cs.CV",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.11277v4",
    "title": "Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs",
    "authors": [
      "Yaorui Shi",
      "Sihang Li",
      "Chang Wu",
      "Zhiyuan Liu",
      "Junfeng Fang",
      "Hengxing Cai",
      "An Zhang",
      "Xiang Wang"
    ],
    "abstract": "Large language models have demonstrated impressive reasoning capabilities but\nare inherently limited by their knowledge reservoir. Retrieval-augmented\nreasoning mitigates this limitation by allowing LLMs to query external\nresources, but existing methods often retrieve irrelevant or noisy information,\nhindering accurate reasoning. In this paper, we propose AutoRefine, a\nreinforcement learning post-training framework that adopts a new\n``search-and-refine-during-think'' paradigm. AutoRefine introduces explicit\nknowledge refinement steps between successive search calls, enabling the model\nto iteratively filter, distill, and organize evidence before generating an\nanswer. Furthermore, we incorporate tailored retrieval-specific rewards\nalongside answer correctness rewards using group relative policy optimization.\nExperiments on single-hop and multi-hop QA benchmarks demonstrate that\nAutoRefine significantly outperforms existing approaches, particularly in\ncomplex, multi-hop reasoning scenarios. Detailed analysis shows that AutoRefine\nissues frequent, higher-quality searches and synthesizes evidence effectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.11277v4",
    "published": "2025-05-16T14:11:29+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11276v1",
    "title": "Multiclass threshold-based classification",
    "authors": [
      "Francesco Marchetti",
      "Edoardo Legnaro",
      "Sabrina Guastavino"
    ],
    "abstract": "In this paper, we introduce a threshold-based framework for multiclass\nclassification that generalizes the standard argmax rule. This is done by\nreplacing the probabilistic interpretation of softmax outputs with a geometric\none on the multidimensional simplex, where the classification depends on a\nmultidimensional threshold. This change of perspective enables for any trained\nclassification network an a posteriori optimization of the classification score\nby means of threshold tuning, as usually carried out in the binary setting.\nThis allows a further refinement of the prediction capability of any network.\nMoreover, this multidimensional threshold-based setting makes it possible to\ndefine score-oriented losses, which are based on the interpretation of the\nthreshold as a random variable. Our experiments show that the multidimensional\nthreshold tuning yields consistent performance improvements across various\nnetworks and datasets, and that the proposed multiclass score-oriented losses\nare competitive with standard loss functions, resembling the advantages\nobserved in the binary case.",
    "pdf_url": "http://arxiv.org/pdf/2505.11276v1",
    "published": "2025-05-16T14:11:26+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11275v3",
    "title": "TCC-Bench: Benchmarking the Traditional Chinese Culture Understanding Capabilities of MLLMs",
    "authors": [
      "Pengju Xu",
      "Yan Wang",
      "Shuyuan Zhang",
      "Xuan Zhou",
      "Xin Li",
      "Yue Yuan",
      "Fengzhao Li",
      "Shunyuan Zhou",
      "Xingyu Wang",
      "Yi Zhang",
      "Haiying Zhao"
    ],
    "abstract": "Recent progress in Multimodal Large Language Models (MLLMs) have\nsignificantly enhanced the ability of artificial intelligence systems to\nunderstand and generate multimodal content. However, these models often exhibit\nlimited effectiveness when applied to non-Western cultural contexts, which\nraises concerns about their wider applicability. To address this limitation, we\npropose the Traditional Chinese Culture understanding Benchmark (TCC-Bench), a\nbilingual (i.e., Chinese and English) Visual Question Answering (VQA) benchmark\nspecifically designed for assessing the understanding of traditional Chinese\nculture by MLLMs. TCC-Bench comprises culturally rich and visually diverse\ndata, incorporating images from museum artifacts, everyday life scenes, comics,\nand other culturally significant contexts. We adopt a semi-automated pipeline\nthat utilizes GPT-4o in text-only mode to generate candidate questions,\nfollowed by human curation to ensure data quality and avoid potential data\nleakage. The benchmark also avoids language bias by preventing direct\ndisclosure of cultural concepts within question texts. Experimental evaluations\nacross a wide range of MLLMs demonstrate that current models still face\nsignificant challenges when reasoning about culturally grounded visual content.\nThe results highlight the need for further research in developing culturally\ninclusive and context-aware multimodal systems. The code and data can be found\nat: https://tcc-bench.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2505.11275v3",
    "published": "2025-05-16T14:10:41+00:00",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2505.11274v2",
    "title": "SelfBudgeter: Adaptive Token Allocation for Efficient LLM Reasoning",
    "authors": [
      "Zheng Li",
      "Qingxiu Dong",
      "Jingyuan Ma",
      "Di Zhang",
      "Zhifang Sui"
    ],
    "abstract": "Recently, large reasoning models demonstrate exceptional performance on\nvarious tasks. However, reasoning models inefficiently over-process both\ntrivial and complex queries, leading to resource waste and prolonged user\nlatency. To address this challenge, we propose SelfBudgeter - a self-adaptive\ncontrollable reasoning strategy for efficient reasoning. Our approach adopts a\ndual-phase training paradigm: first, the model learns to pre-estimate the\nreasoning cost based on the difficulty of the query. Then, we introduce\nbudget-guided GPRO for reinforcement learning, which effectively maintains\naccuracy while reducing output length. SelfBudgeter allows users to anticipate\ngeneration time and make informed decisions about continuing or interrupting\nthe process. Furthermore, our method enables direct manipulation of reasoning\nlength via pre-filling token budget. Experimental results demonstrate that\nSelfBudgeter can rationally allocate budgets according to problem complexity,\nachieving up to 74.47% response length compression on the MATH benchmark while\nmaintaining nearly undiminished accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.11274v2",
    "published": "2025-05-16T14:08:04+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11273v1",
    "title": "Bilevel Transmission Expansion Planning with Joint Chance-Constrained Dispatch",
    "authors": [
      "Yuxin Xia",
      "Yihong Zhou",
      "Iacopo Savelli",
      "Thomas Morstyn"
    ],
    "abstract": "In transmission expansion planning (TEP), network planners make long-term\ninvestment decisions while anticipating market clearing outcomes that are\nincreasingly affected by renewable generation uncertainty. Additionally, market\nparticipants' sensitivity to network charges and the requirement for cost\nrecovery by the network planner introduce further complexity. Since the\nday-ahead market clears before uncertainty realizes, explicitly modelling these\nuncertainties at the lower-level market clearing becomes important in bilevel\nTEP problems. In this paper, we introduce a novel bilevel TEP framework with\nlower-level joint chance-constrained market clearing that manages line flow\nconstraints under wind uncertainty and accounts for the effect of network\ntariffs on participants' actual marginal costs and utility. To solve this\ncomplex problem, we propose a Strengthened Linear Approximation (SLA) technique\nfor handling Wasserstein distributionally robust joint chance constraints with\nright-hand-side uncertainties (RHS-WDRJCC). The proposed method offers more\nefficient approximations without additional conservativeness and avoids the\nnumerical issues encountered in existing approaches by introducing valid\ninequalities. The case study demonstrates that the proposed model achieves the\ndesired out-of-sample constraint satisfaction probability. Moreover, the\nnumerical results highlight the significant computational advantage of SLA,\nachieving up to a 26x speedup compared to existing methods such as worst-case\nconditional value-at-risk, while maintaining high solution quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.11273v1",
    "published": "2025-05-16T14:06:11+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11272v1",
    "title": "Resistivity of non-Galilean invariant two dimensional Dirac system",
    "authors": [
      "V. M. Kovalev",
      "M. V. Entin",
      "Z. D. Kvon",
      "A. D. Levin",
      "V. A. Chitta",
      "G. M. Gusev",
      "N. N. Mikhailov"
    ],
    "abstract": "We revisited the influence of electron-electron scattering on the resistivity\nof a two-dimensional system with linear spectrum. In conventional systems with\nparabolic spectrum, where Umklapp scattering is either prohibited or\nineffective due to small Fermi surface, particle-particle scattering does not\ncontribute to conductivity because it does not change the total momentum.\nHowever, within the framework of Boltzmann kinetic model, we demonstrate that\nelectron-electron scattering in Dirac systems can significantly contribute to\nconductivity, producing distinct temperature-dependent corrections: a\nT\\textsuperscript{4} behavior at low temperatures and T\\textsuperscript{2}\ndependence at moderate temperatures. While the predicted T\\textsuperscript{4}\nscaling is not observed experimentally -- likely suppressed by dominant weak\nlocalization effects -- the T\\textsuperscript{2} scaling is clearly confirmed\nin our measurements. Specifically, temperature-dependent resistivity data from\ngapless single-valley HgTe quantum well exhibit T\\textsuperscript{2}\ncorrections, which align well with theoretical predictions. Thus, we challenge\nthe paradigm that T\\textsuperscript{2} term in resistivity is absent in\nsingle-band 2D metals.",
    "pdf_url": "http://arxiv.org/pdf/2505.11272v1",
    "published": "2025-05-16T14:05:30+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.11271v1",
    "title": "Semantic Caching of Contextual Summaries for Efficient Question-Answering with Language Models",
    "authors": [
      "Camille Couturier",
      "Spyros Mastorakis",
      "Haiying Shen",
      "Saravan Rajmohan",
      "Victor Rühle"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly deployed across edge and cloud\nplatforms for real-time question-answering and retrieval-augmented generation.\nHowever, processing lengthy contexts in distributed systems incurs high\ncomputational overhead, memory usage, and network bandwidth. This paper\nintroduces a novel semantic caching approach for storing and reusing\nintermediate contextual summaries, enabling efficient information reuse across\nsimilar queries in LLM-based QA workflows. Our method reduces redundant\ncomputations by up to 50-60% while maintaining answer accuracy comparable to\nfull document processing, as demonstrated on NaturalQuestions, TriviaQA, and a\nsynthetic ArXiv dataset. This approach balances computational cost and response\nquality, critical for real-time AI assistants.",
    "pdf_url": "http://arxiv.org/pdf/2505.11271v1",
    "published": "2025-05-16T14:04:31+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11270v1",
    "title": "TAIJI: MCP-based Multi-Modal Data Analytics on Data Lakes",
    "authors": [
      "Chao Zhang",
      "Shaolei Zhang",
      "Quehuan Liu",
      "Sibei Chen",
      "Tong Li",
      "Ju Fan"
    ],
    "abstract": "The variety of data in data lakes presents significant challenges for data\nanalytics, as data scientists must simultaneously analyze multi-modal data,\nincluding structured, semi-structured, and unstructured data. While Large\nLanguage Models (LLMs) have demonstrated promising capabilities, they still\nremain inadequate for multi-modal data analytics in terms of accuracy,\nefficiency, and freshness. First, current natural language (NL) or SQL-like\nquery languages may struggle to precisely and comprehensively capture users'\nanalytical intent. Second, relying on a single unified LLM to process diverse\ndata modalities often leads to substantial inference overhead. Third, data\nstored in data lakes may be incomplete or outdated, making it essential to\nintegrate external open-domain knowledge to generate timely and relevant\nanalytics results.\n  In this paper, we envision a new multi-modal data analytics system.\nSpecifically, we propose a novel architecture built upon the Model Context\nProtocol (MCP), an emerging paradigm that enables LLMs to collaborate with\nknowledgeable agents. First, we define a semantic operator hierarchy tailored\nfor querying multi-modal data in data lakes and develop an AI-agent-powered\nNL2Operator translator to bridge user intent and analytical execution. Next, we\nintroduce an MCP-based execution framework, in which each MCP server hosts\nspecialized foundation models optimized for specific data modalities. This\ndesign enhances both accuracy and efficiency, while supporting high scalability\nthrough modular deployment. Finally, we propose a updating mechanism by\nharnessing the deep research and machine unlearning techniques to refresh the\ndata lakes and LLM knowledges, with the goal of balancing the data freshness\nand inference efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.11270v1",
    "published": "2025-05-16T14:03:30+00:00",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.11269v1",
    "title": "Driving Mechanisms and Forecasting of China's Pet Population-An ARIMA-RF-HW Hybrid Approach",
    "authors": [
      "Shengjia Chang",
      "Xianshuo Yue"
    ],
    "abstract": "This study proposes a dynamically weighted ARIMA-RF-HW hybrid model\nintegrating ARIMA for seasonality and trends, Random Forest for nonlinear\nfeatures, and Holt-Winters smoothing for seasonal adjustment to improve China's\npet population forecasting accuracy. Using 2005-2023 data with nine economic,\nsocial, and policy indicators (urban income, consumption, aging ratio, policy\nquantity, new veterinary drug approvals), data were preprocessed via Z-score\nnormalization and missing value imputation. The results show that key drivers\nof pet populations include urban income (19.48% for cats, 17.15% for dogs),\nconsumption (17.99% for cats), and policy quantity (13.33% for cats, 14.02% for\ndogs), with aging (12.81% for cats, 13.27% for dogs) and urbanization\namplifying the demand for pets. Forecasts show steady cat growth and\nfluctuating dog numbers, reflecting cats' adaptability to urban environments.\nThis research supports policymakers in optimizing pet health management and\nguides enterprises in developing differentiated services, advancing sustainable\nindustry growth.",
    "pdf_url": "http://arxiv.org/pdf/2505.11269v1",
    "published": "2025-05-16T14:03:18+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01980v1",
    "title": "Surgical Foundation Model Leveraging Compression and Entropy Maximization for Image-Guided Surgical Assistance",
    "authors": [
      "Lianhao Yin",
      "Ozanan Meireles",
      "Guy Rosman",
      "Daniela Rus"
    ],
    "abstract": "Real-time video understanding is critical to guide procedures in minimally\ninvasive surgery (MIS). However, supervised learning approaches require large,\nannotated datasets that are scarce due to annotation efforts that are\nprohibitive, e.g., in medical fields. Although self-supervision methods can\naddress such limitations, current self-supervised methods often fail to capture\nstructural and physical information in a form that generalizes across tasks. We\npropose Compress-to-Explore (C2E), a novel self-supervised framework that\nleverages Kolmogorov complexity to learn compact, informative representations\nfrom surgical videos. C2E uses entropy-maximizing decoders to compress images\nwhile preserving clinically relevant details, improving encoder performance\nwithout labeled data. Trained on large-scale unlabeled surgical datasets, C2E\ndemonstrates strong generalization across a variety of surgical ML tasks, such\nas workflow classification, tool-tissue interaction classification,\nsegmentation, and diagnosis tasks, providing improved performance as a surgical\nvisual foundation model. As we further show in the paper, the model's internal\ncompact representation better disentangles features from different structural\nparts of images. The resulting performance improvements highlight the yet\nuntapped potential of self-supervised learning to enhance surgical AI and\nimprove outcomes in MIS.",
    "pdf_url": "http://arxiv.org/pdf/2506.01980v1",
    "published": "2025-05-16T14:02:24+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11268v1",
    "title": "Dark standard siren cosmology with bright galaxy subsets",
    "authors": [
      "Khuzaifa Naveed",
      "Cezary Turski",
      "Archisman Ghosh"
    ],
    "abstract": "In this short paper, we investigate the impact of selecting only a subset of\nbright galaxies to provide redshift information for a dark standard siren\nmeasurement of the Hubble constant $H_0$. Employing gravitational-wave\nobservations from the Third Gravitational-Wave Transient Catalogue (GWTC-3) in\nconjunction with the GLADE+ galaxy catalogue, we show that restricting to\nbright galaxy subsets can enhance the precision of the $H_0$ estimate by up to\n$80\\%$ in the most favorable scenario. A comprehensive assessment of systematic\nuncertainties is still required. This work lays the foundation for employing\nalternative tracers -- such as brightest cluster galaxies (BCGs) and luminous\nred galaxies (LRGs) -- in gravitational-wave cosmology, particularly at\nredshifts where conventional galaxy catalogues offer limited coverage.",
    "pdf_url": "http://arxiv.org/pdf/2505.11268v1",
    "published": "2025-05-16T14:02:01+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11267v1",
    "title": "Equal is Not Always Fair: A New Perspective on Hyperspectral Representation Non-Uniformity",
    "authors": [
      "Wuzhou Quan",
      "Mingqiang Wei",
      "Jinhui Tang"
    ],
    "abstract": "Hyperspectral image (HSI) representation is fundamentally challenged by\npervasive non-uniformity, where spectral dependencies, spatial continuity, and\nfeature efficiency exhibit complex and often conflicting behaviors. Most\nexisting models rely on a unified processing paradigm that assumes homogeneity\nacross dimensions, leading to suboptimal performance and biased\nrepresentations. To address this, we propose FairHyp, a fairness-directed\nframework that explicitly disentangles and resolves the threefold\nnon-uniformity through cooperative yet specialized modules. We introduce a\nRunge-Kutta-inspired spatial variability adapter to restore spatial coherence\nunder resolution discrepancies, a multi-receptive field convolution module with\nsparse-aware refinement to enhance discriminative features while respecting\ninherent sparsity, and a spectral-context state space model that captures\nstable and long-range spectral dependencies via bidirectional Mamba scanning\nand statistical aggregation. Unlike one-size-fits-all solutions, FairHyp\nachieves dimension-specific adaptation while preserving global consistency and\nmutual reinforcement. This design is grounded in the view that non-uniformity\narises from the intrinsic structure of HSI representations, rather than any\nparticular task setting. To validate this, we apply FairHyp across four\nrepresentative tasks including classification, denoising, super-resolution, and\ninpaintin, demonstrating its effectiveness in modeling a shared structural\nflaw. Extensive experiments show that FairHyp consistently outperforms\nstate-of-the-art methods under varied imaging conditions. Our findings redefine\nfairness as a structural necessity in HSI modeling and offer a new paradigm for\nbalancing adaptability, efficiency, and fidelity in high-dimensional vision\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11267v1",
    "published": "2025-05-16T14:00:11+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11266v1",
    "title": "SCAREY: Location-Aware Service Lifecycle Management",
    "authors": [
      "Kurt Horvath",
      "Dragi Kimovski",
      "Radu Prodan"
    ],
    "abstract": "Scheduling services within the computing continuum is complex due to the\ndynamic interplay of the Edge, Fog, and Cloud resources, each offering distinct\ncomputational and networking advantages. This paper introduces SCAREY, a user\nlocation-aided service lifecycle management framework based on state machines.\nSCAREY addresses critical service discovery, provisioning, placement, and\nmonitoring challenges by providing unified dynamic state machine-based\nlifecycle management, allowing instances to transition between discoverable and\nnon-discoverable states based on demand. It incorporates a scalable service\ndeployment algorithm to adjust the number of instances and employs network\nmeasurements to optimize service placement, ensuring minimal latency and\nenhancing sustainability. Real-world evaluations demonstrate a 73% improvement\nin service discovery and acquisition times, 45% cheaper operating costs and\nover 57% less power consumption and lower CO2 emissions compared to existing\nrelated methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.11266v1",
    "published": "2025-05-16T13:58:19+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11265v1",
    "title": "Multi-Fidelity Bayesian Optimization for Nash Equilibria with Black-Box Utilities",
    "authors": [
      "Yunchuan Zhang",
      "Osvaldo Simeone",
      "H. Vincent Poor"
    ],
    "abstract": "Modern open and softwarized systems -- such as O-RAN telecom networks and\ncloud computing platforms -- host independently developed applications with\ndistinct, and potentially conflicting, objectives. Coordinating the behavior of\nsuch applications to ensure stable system operation poses significant\nchallenges, especially when each application's utility is accessible only via\ncostly, black-box evaluations. In this paper, we consider a centralized\noptimization framework in which a system controller suggests joint\nconfigurations to multiple strategic players, representing different\napplications, with the goal of aligning their incentives toward a stable\noutcome. To model this interaction, we formulate a Stackelberg game in which\nthe central optimizer lacks access to analytical utility functions and instead\nmust learn them through sequential, multi-fidelity evaluations. To address this\nchallenge, we propose MF-UCB-PNE, a novel multi-fidelity Bayesian optimization\nstrategy that leverages a budget-constrained sampling process to approximate\npure Nash equilibrium (PNE) solutions. MF-UCB-PNE systematically balances\nexploration across low-cost approximations with high-fidelity exploitation\nsteps, enabling efficient convergence to incentive-compatible configurations.\nWe provide theoretical and empirical insights into the trade-offs between query\ncost and equilibrium accuracy, demonstrating the effectiveness of MF-UCB-PNE in\nidentifying effective equilibrium solutions under limited cost budgets.",
    "pdf_url": "http://arxiv.org/pdf/2505.11265v1",
    "published": "2025-05-16T13:56:43+00:00",
    "categories": [
      "cs.GT",
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11264v1",
    "title": "Multi-view dense image matching with similarity learning and geometry priors",
    "authors": [
      "Mohamed Ali Chebbi",
      "Ewelina Rupnik",
      "Paul Lopes",
      "Marc Pierrot-Deseilligny"
    ],
    "abstract": "We introduce MV-DeepSimNets, a comprehensive suite of deep neural networks\ndesigned for multi-view similarity learning, leveraging epipolar geometry for\ntraining. Our approach incorporates an online geometry prior to characterize\npixel relationships, either along the epipolar line or through homography\nrectification. This enables the generation of geometry-aware features from\nnative images, which are then projected across candidate depth hypotheses using\nplane sweeping. Our method geometric preconditioning effectively adapts\nepipolar-based features for enhanced multi-view reconstruction, without\nrequiring the laborious multi-view training dataset creation. By aggregating\nlearned similarities, we construct and regularize the cost volume, leading to\nimproved multi-view surface reconstruction over traditional dense matching\napproaches. MV-DeepSimNets demonstrates superior performance against leading\nsimilarity learning networks and end-to-end regression models, especially in\nterms of generalization capabilities across both aerial and satellite imagery\nwith varied ground sampling distances. Our pipeline is integrated into MicMac\nsoftware and can be readily adopted in standard multi-resolution image matching\npipelines.",
    "pdf_url": "http://arxiv.org/pdf/2505.11264v1",
    "published": "2025-05-16T13:55:40+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11263v1",
    "title": "A Cosmic Miracle: A Remarkably Luminous Galaxy at $z_{\\rm{spec}}=14.44$ Confirmed with JWST",
    "authors": [
      "Rohan P. Naidu",
      "Pascal A. Oesch",
      "Gabriel Brammer",
      "Andrea Weibel",
      "Yijia Li",
      "Jorryt Matthee",
      "John Chisholm",
      "Clara L. Pollock",
      "Kasper E. Heintz",
      "Benjamin D. Johnson",
      "Xuejian Shen",
      "Raphael E. Hviding",
      "Joel Leja",
      "Sandro Tacchella",
      "Arpita Ganguly",
      "Callum Witten",
      "Hakim Atek",
      "Sirio Belli",
      "Sownak Bose",
      "Rychard Bouwens",
      "Pratika Dayal",
      "Roberto Decarli",
      "Anna de Graaff",
      "Yoshinobu Fudamoto",
      "Emma Giovinazzo",
      "Jenny E. Greene",
      "Garth Illingworth",
      "Akio K. Inoue",
      "Sarah G. Kane",
      "Ivo Labbe",
      "Ecaterina Leonova",
      "Rui Marques-Chaves",
      "Romain A. Meyer",
      "Erica J. Nelson",
      "Guido Roberts-Borsani",
      "Daniel Schaerer",
      "Robert A. Simcoe",
      "Mauro Stefanon",
      "Yuma Sugahara",
      "Sune Toft",
      "Arjen van der Wel",
      "Pieter van Dokkum",
      "Fabian Walter",
      "Darach Watson",
      "John R. Weaver",
      "Katherine E. Whitaker"
    ],
    "abstract": "JWST has revealed a stunning population of bright galaxies at surprisingly\nearly epochs, $z>10$, where few such sources were expected. Here we present the\nmost distant example of this class yet -- MoM-z14, a luminous\n($M_{\\rm{UV}}=-20.2$) source in the COSMOS legacy field at\n$z_{\\rm{spec}}=14.44^{+0.02}_{-0.02}$ that expands the observational frontier\nto a mere 280 million years after the Big Bang. The redshift is confirmed with\nNIRSpec/prism spectroscopy through a sharp Lyman-$\\alpha$ break and\n$\\approx3\\sigma$ detections of five rest-UV emission lines. The number density\nof bright $z_{\\rm{spec}}\\approx14-15$ sources implied by our \"Mirage or\nMiracle\" survey spanning $\\approx350$ arcmin$^{2}$ is $>100\\times$ larger\n($182^{+329}_{-105}\\times$) than pre-JWST consensus models. The high EWs of UV\nlines (${\\approx}15{-}35$ \\AA) signal a rising star-formation history, with a\n${\\approx}10\\times$ increase in the last 5 Myr\n($\\rm{SFR_{\\rm{5Myr}}}/\\rm{SFR_{\\rm{50Myr}}}=9.9^{+3.0}_{-5.8}$). The source is\nextremely compact (circularized $r_{\\rm{e}} = 74^{+15}_{-12}$ pc), and yet\nresolved, suggesting an AGN is not the dominant source of light. The steep UV\nslope ($\\beta=-2.5^{+0.2}_{-0.2}$) implies negligible dust attenuation and a\nyoung stellar population. The absence of a strong damping wing may indicate\nthat the immediate surroundings of MoM-z14 are partially ionized at a redshift\nwhere virtually every reionization model predicts a $\\approx100\\%$ neutral\nfraction. The nitrogen emission and highly super-solar [N/C]$>1$ hint at an\nabundance pattern similar to local globular clusters that may have once hosted\nluminous supermassive stars. Since this abundance pattern is also common among\nthe most ancient stars born in the Milky Way, we may be directly witnessing the\nformation of such stars in dense clusters, connecting galaxy evolution across\nthe entire sweep of cosmic time.",
    "pdf_url": "http://arxiv.org/pdf/2505.11263v1",
    "published": "2025-05-16T13:54:40+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11262v1",
    "title": "A Step towards Interpretable Multimodal AI Models with MultiFIX",
    "authors": [
      "Mafalda Malafaia",
      "Thalea Schlender",
      "Tanja Alderliesten",
      "Peter A. N. Bosman"
    ],
    "abstract": "Real-world problems are often dependent on multiple data modalities, making\nmultimodal fusion essential for leveraging diverse information sources. In\nhigh-stakes domains, such as in healthcare, understanding how each modality\ncontributes to the prediction is critical to ensure trustworthy and\ninterpretable AI models. We present MultiFIX, an interpretability-driven\nmultimodal data fusion pipeline that explicitly engineers distinct features\nfrom different modalities and combines them to make the final prediction.\nInitially, only deep learning components are used to train a model from data.\nThe black-box (deep learning) components are subsequently either explained\nusing post-hoc methods such as Grad-CAM for images or fully replaced by\ninterpretable blocks, namely symbolic expressions for tabular data, resulting\nin an explainable model. We study the use of MultiFIX using several training\nstrategies for feature extraction and predictive modeling. Besides highlighting\nstrengths and weaknesses of MultiFIX, experiments on a variety of synthetic\ndatasets with varying degrees of interaction between modalities demonstrate\nthat MultiFIX can generate multimodal models that can be used to accurately\nexplain both the extracted features and their integration without compromising\npredictive performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.11262v1",
    "published": "2025-05-16T13:54:29+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11261v1",
    "title": "Fourier Low-rank and Sparse Tensor for Efficient Tensor Completion",
    "authors": [
      "Jingyang Li",
      "Jiuqian Shang",
      "Yang Chen"
    ],
    "abstract": "Tensor completion is crucial in many scientific domains with missing data\nproblems. Traditional low-rank tensor models, including CP, Tucker, and\nTensor-Train, exploit low-dimensional structures to recover missing data.\nHowever, these methods often treat all tensor modes symmetrically, failing to\ncapture the unique spatiotemporal patterns inherent in scientific data, where\nthe temporal component exhibits both low-frequency stability and high-frequency\nvariations. To address this, we propose a novel model, \\underline{F}ourier\n\\underline{Lo}w-rank and \\underline{S}parse \\underline{T}ensor (FLoST), which\ndecomposes the tensor along the temporal dimension using a Fourier transform.\nThis approach captures low-frequency components with low-rank matrices and\nhigh-frequency fluctuations with sparsity, resulting in a hybrid structure that\nefficiently models both smooth and localized variations. Compared to the\nwell-known tubal-rank model, which assumes low-rankness across all frequency\ncomponents, FLoST requires significantly fewer parameters, making it\ncomputationally more efficient, particularly when the time dimension is large.\nThrough theoretical analysis and empirical experiments, we demonstrate that\nFLoST outperforms existing tensor completion models in terms of both accuracy\nand computational efficiency, offering a more interpretable solution for\nspatiotemporal data reconstruction.",
    "pdf_url": "http://arxiv.org/pdf/2505.11261v1",
    "published": "2025-05-16T13:54:07+00:00",
    "categories": [
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11260v1",
    "title": "Metastability for the Curie-Weiss-Potts model with unbounded random interactions",
    "authors": [
      "Johan L. A. Dubbeldam",
      "Vicente Lenz Burnier",
      "Elena Pulvirenti",
      "Martin Slowik"
    ],
    "abstract": "We analyse the metastable behaviour of the disordered Curie-Weiss-Potts\n(DCWP) model subject to a Glauber dynamics. The model is a randomly disordered\nversion of the mean-field $q$-spin Potts model (CWP), where the interaction\ncoefficients between spins are general independent random variables. These\nrandom variables are chosen to have fixed mean (for simplicity taken to be $1$)\nand well defined cumulant generating function, with a fixed distribution not\ndepending on the number of particles. The system evolves as a discrete-time\nMarkov chain with single spin flip Metropolis dynamics at finite inverse\ntemperature $\\beta$. We provide a comparison of the metastable behaviour of the\nCWP and DCWP models, when $N \\to \\infty$. First, we establish the metastability\nof the CWP model and, using this result, prove metastability for the DCWP model\n(with high probability). We then determine the ratio between the metastable\ntransition time for the DCWP model and the corresponding time for the CWP\nmodel. Specifically, we derive the asymptotic tail behavior and moments of this\nratio. Our proof combines the potential-theoretic approach to metastability\nwith concentration of measure techniques, the latter adapted to our specific\ncontext.",
    "pdf_url": "http://arxiv.org/pdf/2505.11260v1",
    "published": "2025-05-16T13:51:18+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP",
      "60K35, 60K37, 82B20, 82B44, 82C44"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11259v2",
    "title": "Linear Convergence of the Frank-Wolfe Algorithm over Product Polytopes",
    "authors": [
      "Gabriele Iommazzo",
      "David Martínez-Rubio",
      "Francisco Criado",
      "Elias Wirth",
      "Sebastian Pokutta"
    ],
    "abstract": "We study the linear convergence of Frank-Wolfe algorithms over product\npolytopes. We analyze two condition numbers for the product polytope, namely\nthe \\emph{pyramidal width} and the \\emph{vertex-facet distance}, based on the\ncondition numbers of individual polytope components. As a result, for convex\nobjectives that are $\\mu$-Polyak-{\\L}ojasiewicz, we show linear convergence\nrates quantified in terms of the resulting condition numbers. We apply our\nresults to the problem of approximately finding a feasible point in a polytope\nintersection in high-dimensions, and demonstrate the practical efficiency of\nour algorithms through empirical results.",
    "pdf_url": "http://arxiv.org/pdf/2505.11259v2",
    "published": "2025-05-16T13:50:55+00:00",
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11258v1",
    "title": "Dimensionality-dependent electronic and vibrational dynamics in low-dimensional organic-inorganic tin halides",
    "authors": [
      "Yanmei He",
      "Xinyi Cai",
      "Rafael B. Araujo",
      "Yibo Wang",
      "Sankaran Ramesh",
      "Junsheng Chen",
      "Muyi Zhang",
      "Tomas Edvinsson",
      "Feng Gao",
      "Tonu Pullerits"
    ],
    "abstract": "Photo-induced dynamics of electronic processes in materials are driven by the\ncoupling between electronic and nuclear degrees of freedom. Here we construct\n1D and 2D organic-inorganic tin halides to investigate the functional role of\ndimensionality to exciton-phonon coupling (EPC) and exciton self-trapping. The\nresults show that the 1D system has strong EPC leading to\nexcitation-independent self-trapped exciton (STE) emission, while the 2D system\nexhibits over ten times weaker EPC resulting in free exciton emission. By\nperforming femtosecond transient absorption experiments, we directly resolve\nthe room-temperature vibrational wavepackets in the 1D system, some of which\npropagate along the STE potential energy surface. A combination of wagging and\nasymmetric stretching motions (~106 cm-1) in tin iodide is identified as such a\nmode inducing exciton self-trapping. While no room-temperature wavepackets are\nobserved in the 2D system. These findings uncover the interplay between the\ndimensionality-dependent EPC and electronic/nuclear dynamics, offering\nconstructive guidance to develop multifunctional organic-inorganic metal\nhalides.",
    "pdf_url": "http://arxiv.org/pdf/2505.11258v1",
    "published": "2025-05-16T13:50:36+00:00",
    "categories": [
      "physics.chem-ph",
      "physics.optics"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11257v1",
    "title": "DRAGON: A Large-Scale Dataset of Realistic Images Generated by Diffusion Models",
    "authors": [
      "Giulia Bertazzini",
      "Daniele Baracchi",
      "Dasara Shullani",
      "Isao Echizen",
      "Alessandro Piva"
    ],
    "abstract": "The remarkable ease of use of diffusion models for image generation has led\nto a proliferation of synthetic content online. While these models are often\nemployed for legitimate purposes, they are also used to generate fake images\nthat support misinformation and hate speech. Consequently, it is crucial to\ndevelop robust tools capable of detecting whether an image has been generated\nby such models. Many current detection methods, however, require large volumes\nof sample images for training. Unfortunately, due to the rapid evolution of the\nfield, existing datasets often cover only a limited range of models and quickly\nbecome outdated. In this work, we introduce DRAGON, a comprehensive dataset\ncomprising images from 25 diffusion models, spanning both recent advancements\nand older, well-established architectures. The dataset contains a broad variety\nof images representing diverse subjects. To enhance image realism, we propose a\nsimple yet effective pipeline that leverages a large language model to expand\ninput prompts, thereby generating more diverse and higher-quality outputs, as\nevidenced by improvements in standard quality metrics. The dataset is provided\nin multiple sizes (ranging from extra-small to extra-large) to accomodate\ndifferent research scenarios. DRAGON is designed to support the forensic\ncommunity in developing and evaluating detection and attribution techniques for\nsynthetic content. Additionally, the dataset is accompanied by a dedicated test\nset, intended to serve as a benchmark for assessing the performance of newly\ndeveloped methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.11257v1",
    "published": "2025-05-16T13:50:34+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11576v2",
    "title": "Concept-Guided Interpretability via Neural Chunking",
    "authors": [
      "Shuchen Wu",
      "Stephan Alaniz",
      "Shyamgopal Karthik",
      "Peter Dayan",
      "Eric Schulz",
      "Zeynep Akata"
    ],
    "abstract": "Neural networks are often described as black boxes, reflecting the\nsignificant challenge of understanding their internal workings and\ninteractions. We propose a different perspective that challenges the prevailing\nview: rather than being inscrutable, neural networks exhibit patterns in their\nraw population activity that mirror regularities in the training data. We refer\nto this as the Reflection Hypothesis and provide evidence for this phenomenon\nin both simple recurrent neural networks (RNNs) and complex large language\nmodels (LLMs). Building on this insight, we propose to leverage our cognitive\ntendency of chunking to segment high-dimensional neural population dynamics\ninto interpretable units that reflect underlying concepts. We propose three\nmethods to extract recurring chunks on a neural population level, complementing\neach other based on label availability and neural data dimensionality. Discrete\nsequence chunking (DSC) learns a dictionary of entities in a lower-dimensional\nneural space; population averaging (PA) extracts recurring entities that\ncorrespond to known labels; and unsupervised chunk discovery (UCD) can be used\nwhen labels are absent. We demonstrate the effectiveness of these methods in\nextracting concept-encoding entities agnostic to model architectures. These\nconcepts can be both concrete (words), abstract (POS tags), or structural\n(narrative schema). Additionally, we show that extracted chunks play a causal\nrole in network behavior, as grafting them leads to controlled and predictable\nchanges in the model's behavior. Our work points to a new direction for\ninterpretability, one that harnesses both cognitive principles and the\nstructure of naturalistic data to reveal the hidden computations of complex\nlearning systems, gradually transforming them from black boxes into systems we\ncan begin to understand.",
    "pdf_url": "http://arxiv.org/pdf/2505.11576v2",
    "published": "2025-05-16T13:49:43+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11256v1",
    "title": "Anisotropic magnetic phase diagrams, tricriticality, and spin-reorientation in high-pressure grown SmCrO$_3$ single crystals",
    "authors": [
      "Ning Yuan",
      "Erik Walendy",
      "Nour Maraytta",
      "Waldemar Hergett",
      "Luca Bischof",
      "Michael Merz",
      "Rüdiger Klingeler"
    ],
    "abstract": "SmCrO$_3$ single crystals were successfully grown utilizing the high-pressure\noptical floating-zone method and their crystal structure, magnetization\nbehavior, and magnetic phase diagrams were thoroughly investigated. Magnetic\nstudies were conducted for fields applied along all principal crystallographic\ndirections, with measurements taken at temperatures as low as 0.4 K and\nmagnetic fields up to 14 T. The single crystal growth parameters are reported\nand the orthorhombic structure with the centrosymmetric space group $Pbnm$ is\nconfirmed. Long-range order of the Cr$^{3+}$ and Sm$^{3+}$ magnetic sublattices\nevolves at $T_{\\rm N}$ = 192 K and $T_{\\rm N2}$=3 K, respectively. In contrast\nto previous studies on polycrystals our single crystal data imply a\ndiscontinuous and one-step spin-reorientation (SR) of net magnetic moments\n$\\tilde{M}$ from the $c$ axis into the $ab$ plane at zero magnetic field at\n$T_{\\rm SR}$=33 K. Its discontinuous nature is maintained if $B$ is applied\n$||c$ axis but tricritical behavior and a triple point is found for $B||a$\naxis. While our data are consistent with the magnetic representation $\\Gamma_4$\nfor $T > T_{\\mathrm {SR}}$, the size and in-plane direction of the observed net\nmagnetic moment disagree to previously proposed spin configurations, i.e.,\n$\\Gamma_1$ and $\\Gamma_2$, for the spin-reoriented phases. In general, our\nhigh-quality single crystals enable us to revisit the phase diagram and to\nclarify the complex magnetism in SmCrO3 arising from the interplay of\nanisotropic 3$d$ and 4$f$ magnetic sublattices.",
    "pdf_url": "http://arxiv.org/pdf/2505.11256v1",
    "published": "2025-05-16T13:49:36+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.11255v1",
    "title": "Parametric Model Order Reduction by Box Clustering with Applications in Mechatronic Systems",
    "authors": [
      "Juan Angelo Vargas-Fajardo",
      "Diana Manvelyan-Stroot",
      "Catharina Czech",
      "Pietro Botazzoli",
      "Fabian Duddeck"
    ],
    "abstract": "High temperatures and structural deformations can compromise the\nfunctionality and reliability of new components for mechatronic systems.\nTherefore, high-fidelity simulations (HFS) are employed during the design\nprocess, as they enable a detailed analysis of the thermal and structural\nbehavior of the system. However, such simulations are both computationally\nexpensive and tedious, particularly during iterative optimization procedures.\nEstablishing a parametric reduced order model (pROM) can accelerate the\ndesign's optimization if the model can accurately predict the behavior over a\nwide range of material and geometric properties. However, many existing methods\nexhibit limitations when applied to wide design ranges.\n  In this work, we introduce the parametric Box Reduction (pBR) method, a\nmatrix interpolation technique that minimizes the non-physical influence of\ntraining points due to the large parameter ranges. For this purpose, we define\na new interpolation function that computes a local weight for each design\nvariable and integrates them into the global function. Furthermore, we develop\nan intuitive clustering technique to select the training points for the model,\navoiding numerical artifacts from distant points. Additionally, these two\nstrategies do not require normalizing the parameter space and handle every\nproperty equally. The effectiveness of the pBR method is validated through two\nphysical applications: structural deformation of a cantilever Timoshenko beam\nand heat transfer of a power module of a power converter. The results\ndemonstrate that the pBR approach can accurately capture the behavior of\nmechatronic components across large parameter ranges without sacrificing\ncomputational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.11255v1",
    "published": "2025-05-16T13:48:49+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11254v1",
    "title": "Delta Attention: Fast and Accurate Sparse Attention Inference by Delta Correction",
    "authors": [
      "Jeffrey Willette",
      "Heejun Lee",
      "Sung Ju Hwang"
    ],
    "abstract": "The attention mechanism of a transformer has a quadratic complexity, leading\nto high inference costs and latency for long sequences. However, attention\nmatrices are mostly sparse, which implies that many entries may be omitted from\ncomputation for efficient inference. Sparse attention inference methods aim to\nreduce this computational burden; however, they also come with a troublesome\nperformance degradation. We discover that one reason for this degradation is\nthat the sparse calculation induces a distributional shift in the attention\noutputs. The distributional shift causes decoding-time queries to fail to align\nwell with the appropriate keys from the prefill stage, leading to a drop in\nperformance. We propose a simple, novel, and effective procedure for correcting\nthis distributional shift, bringing the distribution of sparse attention\noutputs closer to that of quadratic attention. Our method can be applied on top\nof any sparse attention method, and results in an average 36%pt performance\nincrease, recovering 88% of quadratic attention accuracy on the 131K RULER\nbenchmark when applied on top of sliding window attention with sink tokens\nwhile only adding a small overhead. Our method can maintain approximately 98.5%\nsparsity over full quadratic attention, making our model 32 times faster than\nFlash Attention 2 when processing 1M token prefills.",
    "pdf_url": "http://arxiv.org/pdf/2505.11254v1",
    "published": "2025-05-16T13:48:33+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11253v1",
    "title": "Emergent Thermalization Thresholds in Unitary Dynamics of Inhomogeneously Disordered Systems",
    "authors": [
      "Soumya Kanti Pal",
      "C L Sriram",
      "Shamik Gupta"
    ],
    "abstract": "Inspired by the avalanche scenario for many-body localization (MBL)\ninstability, we reverse the conventional set-up and ask whether a large\nweakly-disordered chain can thermalize a smaller, strongly-disordered chain\nwhen the composite system evolves unitarily. Using transport as a dynamical\nprobe, we identify three distinct thermalization regimes as a function of the\ndisorder strength of the smaller chain: (i) complete thermalization with\nself-averaging at weak disorder, (ii) realization-dependent thermalization with\nstrong sample-to-sample fluctuations at intermediate disorder, and (iii)\nabsence of thermalization at strong disorder. We find that the\nnon-self-averaging regime broadens with the size of the weakly-disordered\nchain, revealing a nuanced interplay between disorder and system size. These\nresults highlight how inhomogeneous disorder can induce emergent thermalization\nthresholds in closed quantum systems, providing direct access to disorder\nregimes where thermalization or its absence can be reliably observed.",
    "pdf_url": "http://arxiv.org/pdf/2505.11253v1",
    "published": "2025-05-16T13:46:40+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.dis-nn",
      "quant-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.13508v2",
    "title": "Time-R1: Towards Comprehensive Temporal Reasoning in LLMs",
    "authors": [
      "Zijia Liu",
      "Peixuan Han",
      "Haofei Yu",
      "Haoru Li",
      "Jiaxuan You"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate impressive capabilities but lack\nrobust temporal intelligence, struggling to integrate reasoning about the past\nwith predictions and plausible generations of the future. Meanwhile, existing\nmethods typically target isolated temporal skills, such as question answering\nabout past events or basic forecasting, and exhibit poor generalization,\nparticularly when dealing with events beyond their knowledge cutoff or\nrequiring creative foresight. To address these limitations, we introduce\n\\textit{Time-R1}, the first framework to endow a moderate-sized (3B-parameter)\nLLM with comprehensive temporal abilities: understanding, prediction, and\ncreative generation. Our approach features a novel three-stage development\npath; the first two constitute a \\textit{reinforcement learning (RL)\ncurriculum} driven by a meticulously designed dynamic rule-based reward system.\nThis framework progressively builds (1) foundational temporal understanding and\nlogical event-time mappings from historical data, (2) future event prediction\nskills for events beyond its knowledge cutoff, and finally (3) enables\nremarkable generalization to creative future scenario generation without any\nfine-tuning. Strikingly, experiments demonstrate that Time-R1 outperforms\nmodels over 200 times larger, including the state-of-the-art 671B DeepSeek-R1,\non highly challenging future event prediction and creative scenario generation\nbenchmarks. This work provides strong evidence that thoughtfully engineered,\nprogressive RL fine-tuning allows smaller, efficient models to achieve superior\ntemporal performance, offering a practical and scalable path towards truly\ntime-aware AI. To foster further research, we also release \\textit{Time-Bench},\na large-scale multi-task temporal reasoning dataset derived from 10 years of\nnews data, and our series of \\textit{Time-R1} checkpoints.",
    "pdf_url": "http://arxiv.org/pdf/2505.13508v2",
    "published": "2025-05-16T13:46:28+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11252v1",
    "title": "Lightweight LIF-only SNN accelerator using differential time encoding",
    "authors": [
      "Daniel Windhager",
      "Lothar Ratschbacher",
      "Bernhard A. Moser",
      "Michael Lunglmayr"
    ],
    "abstract": "Spiking Neural Networks (SNNs) offer a promising solution to the problem of\nincreasing computational and energy requirements for modern Machine Learning\n(ML) applications. Due to their unique data representation choice of using\nspikes and spike trains, they mostly rely on additions and thresholding\noperations to achieve results approaching state-of-the-art (SOTA) Artificial\nNeural Networks (ANNs). This advantage is hindered by the fact that their\ntemporal characteristic does not map well to already existing accelerator\nhardware like GPUs. Therefore, this work will introduce a hardware accelerator\narchitecture capable of computing feedforward LIF-only SNNs, as well as an\naccompanying encoding method to efficiently encode already existing data into\nspike trains. Together, this leads to a design capable of >99% accuracy on the\nMNIST dataset, with ~0.29ms inference times on a Xilinx Ultrascale+ FPGA, as\nwell as ~0.17ms on a custom ASIC using the open-source predictive 7nm ASAP7\nPDK. Furthermore, this work will showcase the advantages of the previously\npresented differential time encoding for spikes, as well as provide proof that\nmerging spikes from different synapses given in differential time encoding can\nbe done efficiently in hardware.",
    "pdf_url": "http://arxiv.org/pdf/2505.11252v1",
    "published": "2025-05-16T13:42:39+00:00",
    "categories": [
      "cs.NE",
      "eess.SP"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11251v2",
    "title": "The LHC has ruled out Supersymmetry -- really?",
    "authors": [
      "L. Constantin",
      "S. Kraml",
      "F. Mahmoudi"
    ],
    "abstract": "Despite early hopes that the Large Hadron Collider (LHC) would quickly unveil\nsupersymmetric particles, none have been detected to date. This review examines\nthe impact of the LHC results on the viability of weak-scale supersymmetry, and\ndiscusses whether the possibility of discovering supersymmetric particles\nremains within reach.",
    "pdf_url": "http://arxiv.org/pdf/2505.11251v2",
    "published": "2025-05-16T13:42:01+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11250v3",
    "title": "Rethinking Irregular Time Series Forecasting: A Simple yet Effective Baseline",
    "authors": [
      "Xvyuan Liu",
      "Xiangfei Qiu",
      "Xingjian Wu",
      "Zhengyu Li",
      "Chenjuan Guo",
      "Jilin Hu",
      "Bin Yang"
    ],
    "abstract": "The forecasting of irregular multivariate time series (IMTS) is a critical\ntask in domains like healthcare and climate science. However, this task faces\ntwo significant hurdles: 1) the inherent non-uniformity and missing data in\nIMTS complicate the modeling of temporal dynamics, and 2) existing methods\noften rely on computationally expensive architectures. To address these dual\nchallenges, we introduce APN, a general and efficient forecasting framework. At\nthe core of APN is a novel Time-Aware Patch Aggregation (TAPA) module that\nintroduces an aggregation-based paradigm for adaptive patching, moving beyond\nthe limitations of fixed-span segmentation and interpolation-based methods.\nTAPA first learns dynamic temporal boundaries to define data-driven segments.\nCrucially, instead of resampling or interpolating, it directly computes patch\nrepresentations via a time-aware weighted aggregation of all raw observations,\nwhere weights are determined by each observation's temporal relevance to the\nsegment. This approach provides two key advantages: it preserves data fidelity\nby avoiding the introduction of artificial data points and ensures complete\ninformation coverage by design.The resulting regularized and information-rich\npatch representations enable the use of a lightweight query module for\nhistorical context aggregation and a simple MLP for final prediction. Extensive\nexperiments on multiple real-world datasets demonstrate that APN establishes a\nnew state-of-the-art, significantly outperforming existing methods in both\nprediction accuracy and computational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.11250v3",
    "published": "2025-05-16T13:42:00+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11249v1",
    "title": "Depolarization of synchrotron radiation of a relativistic electron beam",
    "authors": [
      "O. Novak",
      "M. Diachenko",
      "R. Kholodov"
    ],
    "abstract": "We present a theoretical study on the radiative self-polarization of a\nhigh-energy electron beam propagating perpendicular to a strong magnetic field.\nRecently, a similar setup has been proposed as a source of polarized electron\nand photon beams. We focus on the dependence of electron and radiation\npolarization on the dimensionless parameter $\\varepsilon$, which is\nproportional to the product of electron energy and magnetic field strength. The\nnumerical solution of the balance equation shows that the resulting electron\nbeam polarization increases rapidly as a function of $\\varepsilon$ for\n$\\varepsilon \\ll 1$ and saturates at a value of approximately $-0.8$. If\n$\\varepsilon \\gg 1$, the rate of self-polarization decreases significantly. At\nthe same time, a substantial or nearly complete depolarization of synchrotron\nradiation is observed, particularly for an electron beam with spins initially\naligned parallel to the field.",
    "pdf_url": "http://arxiv.org/pdf/2505.11249v1",
    "published": "2025-05-16T13:41:57+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11248v1",
    "title": "Unfolded Deep Graph Learning for Networked Over-the-Air Computation",
    "authors": [
      "Xiao Tang",
      "Huirong Xiao",
      "Chao Shen",
      "Li Sun",
      "Qinghe Du",
      "Dusit Niyato",
      "Zhu Han"
    ],
    "abstract": "Over-the-air computation (AirComp) has emerged as a promising technology that\nenables simultaneous transmission and computation through wireless channels. In\nthis paper, we investigate the networked AirComp in multiple clusters allowing\ndiversified data computation, which is yet challenged by the transceiver\ncoordination and interference management therein. Particularly, we aim to\nmaximize the multi-cluster weighted-sum AirComp rate, where the transmission\nscalar as well as receive beamforming are jointly investigated while addressing\nthe interference issue. From an optimization perspective, we decompose the\nformulated problem and adopt the alternating optimization technique with an\niterative process to approximate the solution. Then, we reinterpret the\niterations through the principle of algorithm unfolding, where the channel\ncondition and mutual interference in the AirComp network constitute an\nunderlying graph. Accordingly, the proposed unfolding architecture learns the\nweights parameterized by graph neural networks, which is trained through\nstochastic gradient descent approach. Simulation results show that our\nproposals outperform the conventional schemes, and the proposed unfolded graph\nlearning substantially alleviates the interference and achieves superior\ncomputation performance, with strong and efficient adaptation to the dynamic\nand scalable networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11248v1",
    "published": "2025-05-16T13:41:54+00:00",
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11247v2",
    "title": "LD-Scene: LLM-Guided Diffusion for Controllable Generation of Adversarial Safety-Critical Driving Scenarios",
    "authors": [
      "Mingxing Peng",
      "Yuting Xie",
      "Xusen Guo",
      "Ruoyu Yao",
      "Hai Yang",
      "Jun Ma"
    ],
    "abstract": "Ensuring the safety and robustness of autonomous driving systems necessitates\na comprehensive evaluation in safety-critical scenarios. However, these\nsafety-critical scenarios are rare and difficult to collect from real-world\ndriving data, posing significant challenges to effectively assessing the\nperformance of autonomous vehicles. Typical existing methods often suffer from\nlimited controllability and lack user-friendliness, as extensive expert\nknowledge is essentially required. To address these challenges, we propose\nLD-Scene, a novel framework that integrates Large Language Models (LLMs) with\nLatent Diffusion Models (LDMs) for user-controllable adversarial scenario\ngeneration through natural language. Our approach comprises an LDM that\ncaptures realistic driving trajectory distributions and an LLM-based guidance\nmodule that translates user queries into adversarial loss functions,\nfacilitating the generation of scenarios aligned with user queries. The\nguidance module integrates an LLM-based Chain-of-Thought (CoT) code generator\nand an LLM-based code debugger, enhancing the controllability and robustness in\ngenerating guidance functions. Extensive experiments conducted on the nuScenes\ndataset demonstrate that LD-Scene achieves state-of-the-art performance in\ngenerating realistic, diverse, and effective adversarial scenarios.\nFurthermore, our framework provides fine-grained control over adversarial\nbehaviors, thereby facilitating more effective testing tailored to specific\ndriving scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.11247v2",
    "published": "2025-05-16T13:41:05+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11246v1",
    "title": "Entropy-Driven Genetic Optimization for Deep-Feature-Guided Low-Light Image Enhancement",
    "authors": [
      "Nirjhor Datta",
      "Afroza Akther",
      "M. Sohel Rahman"
    ],
    "abstract": "Image enhancement methods often prioritize pixel level information,\noverlooking the semantic features. We propose a novel, unsupervised,\nfuzzy-inspired image enhancement framework guided by NSGA-II algorithm that\noptimizes image brightness, contrast, and gamma parameters to achieve a balance\nbetween visual quality and semantic fidelity. Central to our proposed method is\nthe use of a pre trained deep neural network as a feature extractor. To find\nthe best enhancement settings, we use a GPU-accelerated NSGA-II algorithm that\nbalances multiple objectives, namely, increasing image entropy, improving\nperceptual similarity, and maintaining appropriate brightness. We further\nimprove the results by applying a local search phase to fine-tune the top\ncandidates from the genetic algorithm. Our approach operates entirely without\npaired training data making it broadly applicable across domains with limited\nor noisy labels. Quantitatively, our model achieves excellent performance with\naverage BRISQUE and NIQE scores of 19.82 and 3.652, respectively, in all\nunpaired datasets. Qualitatively, enhanced images by our model exhibit\nsignificantly improved visibility in shadowed regions, natural balance of\ncontrast and also preserve the richer fine detail without introducing noticable\nartifacts. This work opens new directions for unsupervised image enhancement\nwhere semantic consistency is critical.",
    "pdf_url": "http://arxiv.org/pdf/2505.11246v1",
    "published": "2025-05-16T13:40:56+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11244v1",
    "title": "A Review of Tools and Techniques for Optimization of Workload Mapping and Scheduling in Heterogeneous HPC System",
    "authors": [
      "Aasish Kumar Sharma",
      "Julian Kunkel"
    ],
    "abstract": "This paper presents a systematic review of mapping and scheduling strategies\nwithin the High-Performance Computing (HPC) compute continuum, with a\nparticular emphasis on heterogeneous systems. It introduces a prototype\nworkflow to establish foundational concepts in workload characterization and\nresource allocation. Building on this, a thorough analysis of 66 selected\nresearch papers - spanning the period from 2017 to 2024 - is conducted,\nevaluating contemporary tools and techniques used for workload mapping and\nscheduling.\n  The review highlights that conventional Job Shop scheduling formulations\noften lack the expressiveness required to model the complexity of modern HPC\ndata centers effectively. It also reaffirms the classification of HPC\nscheduling problems as NP-hard, due to their combinatorial nature and the\ndiversity of system and workload constraints. The analysis reveals a prevailing\nreliance on heuristic and meta-heuristic strategies, including nature-inspired,\nevolutionary, sorting, and search algorithms.\n  To bridge the observed gaps, the study advocates for hybrid optimization\napproaches that strategically integrate heuristics, meta-heuristics, machine\nlearning, and emerging quantum computing techniques. Such integration, when\ntailored to specific problem domains, holds promise for significantly improving\nthe scalability, efficiency, and adaptability of workload optimization in\nheterogeneous HPC environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.11244v1",
    "published": "2025-05-16T13:38:23+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11245v1",
    "title": "Diffusion-NPO: Negative Preference Optimization for Better Preference Aligned Generation of Diffusion Models",
    "authors": [
      "Fu-Yun Wang",
      "Yunhao Shui",
      "Jingtan Piao",
      "Keqiang Sun",
      "Hongsheng Li"
    ],
    "abstract": "Diffusion models have made substantial advances in image generation, yet\nmodels trained on large, unfiltered datasets often yield outputs misaligned\nwith human preferences. Numerous methods have been proposed to fine-tune\npre-trained diffusion models, achieving notable improvements in aligning\ngenerated outputs with human preferences. However, we argue that existing\npreference alignment methods neglect the critical role of handling\nunconditional/negative-conditional outputs, leading to a diminished capacity to\navoid generating undesirable outcomes. This oversight limits the efficacy of\nclassifier-free guidance~(CFG), which relies on the contrast between\nconditional generation and unconditional/negative-conditional generation to\noptimize output quality. In response, we propose a straightforward but\nversatile effective approach that involves training a model specifically\nattuned to negative preferences. This method does not require new training\nstrategies or datasets but rather involves minor modifications to existing\ntechniques. Our approach integrates seamlessly with models such as SD1.5, SDXL,\nvideo diffusion models and models that have undergone preference optimization,\nconsistently enhancing their alignment with human preferences.",
    "pdf_url": "http://arxiv.org/pdf/2505.11245v1",
    "published": "2025-05-16T13:38:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11243v1",
    "title": "A Set-Sequence Model for Time Series",
    "authors": [
      "Elliot L. Epstein",
      "Apaar Sadhwani",
      "Kay Giesecke"
    ],
    "abstract": "In many financial prediction problems, the behavior of individual units (such\nas loans, bonds, or stocks) is influenced by observable unit-level factors and\nmacroeconomic variables, as well as by latent cross-sectional effects.\nTraditional approaches attempt to capture these latent effects via handcrafted\nsummary features. We propose a Set-Sequence model that eliminates the need for\nhandcrafted features. The Set model first learns a shared cross-sectional\nsummary at each period. The Sequence model then ingests the summary-augmented\ntime series for each unit independently to predict its outcome. Both components\nare learned jointly over arbitrary sets sampled during training. Our approach\nharnesses the set nature of the cross-section and is computationally efficient,\ngenerating set summaries in linear time relative to the number of units. It is\nalso flexible, allowing the use of existing sequence models and accommodating a\nvariable number of units at inference. Empirical evaluations demonstrate that\nour Set-Sequence model significantly outperforms benchmarks on stock return\nprediction and mortgage behavior tasks. Code will be released.",
    "pdf_url": "http://arxiv.org/pdf/2505.11243v1",
    "published": "2025-05-16T13:36:07+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.CP",
      "I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11242v1",
    "title": "Inspiral-merger-ringdown waveforms with gravitational self-force results within the effective-one-body formalism",
    "authors": [
      "Benjamin Leather",
      "Alessandra Buonanno",
      "Maarten van de Meent"
    ],
    "abstract": "Gravitational self-force (GSF) theory is a strong-gravity perturbative\napproach to the relativistic two-body problem, primarily developed to model\nextreme-mass-ratio inspirals, where one compact object is significantly more\nmassive than the companion. However, recent advancements in GSF calculations,\nparticularly involving second-order self-force (2GSF) results, indicated a much\nbroader applicability across a wider range of mass ratios. These developments\nhave motivated efforts to incorporate GSF results into the effective-one-body\n(EOB) framework, where they have already been successfully integrated into the\nstate-of-the-art waveform model, SEOBNRv5, employed in recent LIGO-Virgo-KAGRA\n(LVK) observing runs. In this work, we present SEOBNR-GSF, a nonspinning\ninspiral-merger-ringdown (IMR) EOB waveform model that introduces a\nGSF-informed EOB Hamiltonian as its central innovation. This marks the first\ncomplete IMR waveform model constructed primarily from GSF results. We show\nthat our model outperforms inspiral waveforms from full 2GSF calculations in\nthe intermediate-to-comparable mass regime. Furthermore, by comparing with a\npost-Newtonian-informed variant, SEOBNR-GSF-PN, we demonstrate that the\ninclusion of numerical GSF information in the Hamiltonian leads to significant\nimprovements in model fidelity. Finally, we benchmark our model against\nhigh-accuracy, nonspinning numerical-relativity simulations from the Simulating\neXtreme Spacetimes (SXS) catalogue and find that its median mismatch is\ncomparable to that of SEOBNRv5, suggesting that this approach holds promise for\nfurther enhancing future EOB waveform models.",
    "pdf_url": "http://arxiv.org/pdf/2505.11242v1",
    "published": "2025-05-16T13:35:58+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.17051v1",
    "title": "Embedding-to-Prefix: Parameter-Efficient Personalization for Pre-Trained Large Language Models",
    "authors": [
      "Bernd Huber",
      "Ghazal Fazelnia",
      "Andreas Damianou",
      "Sebastian Peleato",
      "Max Lefarov",
      "Praveen Ravichandran",
      "Marco De Nadai",
      "Mounia Lalmas-Roellke",
      "Paul N. Bennett"
    ],
    "abstract": "Large language models (LLMs) excel at generating contextually relevant\ncontent. However, tailoring these outputs to individual users for effective\npersonalization is a significant challenge. While rich user-specific\ninformation often exists as pre-existing user representations, such as\nembeddings learned from preferences or behaviors, current methods to leverage\nthese for LLM personalization typically require costly fine-tuning or\ntoken-heavy prompting. We propose Embedding-to-Prefix (E2P), a\nparameter-efficient method that injects pre-computed context embeddings into an\nLLM's hidden representation space through a learned projection to a single soft\ntoken prefix. This enables effective personalization while keeping the backbone\nmodel frozen and avoiding expensive adaptation techniques. We evaluate E2P\nacross two public datasets and in a production setting: dialogue\npersonalization on Persona-Chat, contextual headline generation on PENS, and\nlarge-scale personalization for music and podcast consumption. Results show\nthat E2P preserves contextual signals and achieves strong performance with\nminimal computational overhead, offering a scalable, efficient solution for\ncontextualizing generative AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.17051v1",
    "published": "2025-05-16T13:34:25+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11241v1",
    "title": "Unique global solution of an integral-differential equation of Footloose Entrepreneur model in new economic geography",
    "authors": [
      "Kensuke Ohtake"
    ],
    "abstract": "This paper studies the Footloose Entrepreneur model in new economic geography\nin continuous space. In an appropriate function space, the model is formulated\nas an initial value problem for an infinite-dimensional ordinary differential\nequation. A unique global solution is constructed based on the Banach fixed\npoint theorem. The stability of a homogeneous stationary solution is then\ninvestigated and numerical simulations of the asymptotic behavior of the\nsolution are performed. Numerical solutions starting near the unstable\nhomogeneous stationary solution converge to spike-shaped stationary solutions,\nand the number of spikes decreases with decreasing transport costs and\nstrengthening preference for variety.",
    "pdf_url": "http://arxiv.org/pdf/2505.11241v1",
    "published": "2025-05-16T13:31:06+00:00",
    "categories": [
      "econ.TH",
      "math.DS"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.16534v1",
    "title": "Remarks on elliptic equations degenerating on lower dimensional manifolds",
    "authors": [
      "Gabriele Cora",
      "Gabriele Fioravanti",
      "Stefano Vita"
    ],
    "abstract": "The paper continues the analysis started in\n[Cora-Fioravanti-Vita-25,Fioravanti-24] on the local regularity theory for\nelliptic equations having coefficients which are degenerate or singular on some\nlower dimensional manifold. The model operator is given by\n$L_au(z)=\\mathrm{div}(|y|^a\\nabla u)(z)$, where $z=(x,y)\\in\\mathbb\nR^{d-n}\\times\\mathbb R^n$, $2\\leq n\\leq d$ are two integers and $a\\in\\mathbb\nR$. The weight term is degenerate/singular on the (possibly very) thin\ncharacteristic manifold $\\Sigma_0=\\{|y|=0\\}$ of dimension $0\\leq d-n\\leq d-2$.\nWhenever $a+n>0$, we prove smoothness of the axially symmetric $L_a$-harmonic\nfunctions. In the mid-range $a+n\\in(0,2)$, we deal with regularity estimates\nfor solutions with inhomogeneous conormal boundary conditions prescribed at\n$\\Sigma_0$, and we establish the connection with fractional Laplacians on very\nthin flat manifolds via Dirichlet-to-Neumann maps, as a higher codimensional\nanalogue of the extension theory developed by Caffarelli and Silvestre.\nFinally, whenever $a+n<2$ we complement the study in [Fioravanti-24], providing\nsome regularity estimates for solutions having a homogeneous Dirichlet boundary\ncondition prescribed at $\\Sigma_0$ by a boundary Harnack type principle.",
    "pdf_url": "http://arxiv.org/pdf/2505.16534v1",
    "published": "2025-05-16T13:30:59+00:00",
    "categories": [
      "math.AP",
      "35B65, 35J70, 35J75, 35B40, 35B07"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11240v1",
    "title": "Nitrogen-vacancy centre in lonsdaleite: a novel nanoscale sensor?",
    "authors": [
      "Anjay Manian",
      "Mitchell O. de Vries",
      "Daniel Stavrevski",
      "Qiang Sun",
      "Salvy P. Russo",
      "Andrew D. Greentree"
    ],
    "abstract": "Hexagonal diamond, often called lonsdaleite, is an exotic allotrope of\ncarbon, predicted to be harder than cubic (conventional) diamond with a wider\nbandgap. Due to its pure sp$^3$ bonded lattice, it should be expected to host\nsub-bandgap defect centres (colour centres). Here we perform \\textit{ab initio}\nmodeling of nitrogen-vacancy (NV) colour centres in hexagonal diamond\nnanocrystals; for both the neutral and negatively charged species (NV$^0$ and\nNV$^-$). We identify three distinct configurations for the NV center: two of\nwhich are analogous to NV in diamond, and one which is a configuration that can\nonly exist in the hexagonal form. The diamond-like NV systems comprise three\nsymmetry equivalent centers which reside on the same carbon plane, and one\ndefect that is split across two planes and replaces a carbon-carbon bond. There\nis an additional NV centre where the N and V each have four nearest neighbour\ncarbon atoms. The presence of this latter configuration would provide an\nunambiguous determination of the hexagonal nature of lonsdaleite. Quantum\nchemical analysis show all derivatives to be thermochemically stable, and each\nwith their own unique photophysical properties, spectral profiles, and\nmagneto-optical characteristics. By assuming that the ground state properties\nof the NV$^-$ in hexagonal diamond are comparable to those of NV$^-$ in cubic\ndiamond, albeit with increased strain, we predict ground state fine structure\nsplitting for two of the centres of 2.74~GHz and 4.56~MHz, compared with\n2.87~GHz for cubic diamond. The possibility of optically detected magnetic\nresonance with NV$^-$ in lonsdaleite would provide a new carbon-based quantum\nsensing system, and an unambiguous method to resolve outstanding issues around\nthe structure of lonsdaleite as hexagonal diamond.",
    "pdf_url": "http://arxiv.org/pdf/2505.11240v1",
    "published": "2025-05-16T13:30:36+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11239v2",
    "title": "Massive-STEPS: Massive Semantic Trajectories for Understanding POI Check-ins -- Dataset and Benchmarks",
    "authors": [
      "Wilson Wongso",
      "Hao Xue",
      "Flora D. Salim"
    ],
    "abstract": "Understanding human mobility through Point-of-Interest (POI) recommendation\nis increasingly important for applications such as urban planning, personalized\nservices, and generative agent simulation. However, progress in this field is\nhindered by two key challenges: the over-reliance on older datasets from\n2012-2013 and the lack of reproducible, city-level check-in datasets that\nreflect diverse global regions. To address these gaps, we present Massive-STEPS\n(Massive Semantic Trajectories for Understanding POI Check-ins), a large-scale,\npublicly available benchmark dataset built upon the Semantic Trails dataset and\nenriched with semantic POI metadata. Massive-STEPS spans 12 geographically and\nculturally diverse cities and features more recent (2017-2018) and\nlonger-duration (24 months) check-in data than prior datasets. We benchmarked a\nwide range of POI recommendation models on Massive-STEPS using both supervised\nand zero-shot approaches, and evaluated their performance across multiple urban\ncontexts. By releasing Massive-STEPS, we aim to facilitate reproducible and\nequitable research in human mobility and POI recommendation. The dataset and\nbenchmarking code are available at:\nhttps://github.com/cruiseresearchgroup/Massive-STEPS",
    "pdf_url": "http://arxiv.org/pdf/2505.11239v2",
    "published": "2025-05-16T13:29:18+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11238v1",
    "title": "Harnessing Photon Indistinguishability in Quantum Extreme Learning Machines",
    "authors": [
      "Malo Joly",
      "Adrian Makowski",
      "Baptiste Courme",
      "Lukas Porstendorfer",
      "Steffen Wilksen",
      "Edoardo Charbon",
      "Christopher Gies",
      "Hugo Defienne",
      "Sylvain Gigan"
    ],
    "abstract": "Recent advancements in machine learning have led to an exponential increase\nin computational demands, driving the need for innovative computing platforms.\nQuantum computing, with its Hilbert space scaling exponentially with the number\nof particles, emerges as a promising solution. In this work, we implement a\nquantum extreme machine learning (QELM) protocol leveraging indistinguishable\nphoton pairs and multimode fiber as a random densly connected layer. We\nexperimentally study QELM performance based on photon coincidences -- for\ndistinguishable and indistinguishable photons -- on an image classification\ntask. Simulations further show that increasing the number of photons reveals a\nclear quantum advantage. We relate this improved performance to the enhanced\ndimensionality and expressivity of the feature space, as indicated by the\nincreased rank of the feature matrix in both experiment and simulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11238v1",
    "published": "2025-05-16T13:28:01+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11237v1",
    "title": "Concept Drift Guided LayerNorm Tuning for Efficient Multimodal Metaphor Identification",
    "authors": [
      "Wenhao Qian",
      "Zhenzhen Hu",
      "Zijie Song",
      "Jia Li"
    ],
    "abstract": "Metaphorical imagination, the ability to connect seemingly unrelated\nconcepts, is fundamental to human cognition and communication. While\nunderstanding linguistic metaphors has advanced significantly, grasping\nmultimodal metaphors, such as those found in internet memes, presents unique\nchallenges due to their unconventional expressions and implied meanings.\nExisting methods for multimodal metaphor identification often struggle to\nbridge the gap between literal and figurative interpretations. Additionally,\ngenerative approaches that utilize large language models or text-to-image\nmodels, while promising, suffer from high computational costs. This paper\nintroduces \\textbf{C}oncept \\textbf{D}rift \\textbf{G}uided \\textbf{L}ayerNorm\n\\textbf{T}uning (\\textbf{CDGLT}), a novel and training-efficient framework for\nmultimodal metaphor identification. CDGLT incorporates two key innovations: (1)\nConcept Drift, a mechanism that leverages Spherical Linear Interpolation\n(SLERP) of cross-modal embeddings from a CLIP encoder to generate a new,\ndivergent concept embedding. This drifted concept helps to alleviate the gap\nbetween literal features and the figurative task. (2) A prompt construction\nstrategy, that adapts the method of feature extraction and fusion using\npre-trained language models for the multimodal metaphor identification task.\nCDGLT achieves state-of-the-art performance on the MET-Meme benchmark while\nsignificantly reducing training costs compared to existing generative methods.\nAblation studies demonstrate the effectiveness of both Concept Drift and our\nadapted LN Tuning approach. Our method represents a significant step towards\nefficient and accurate multimodal metaphor understanding. The code is\navailable:\n\\href{https://github.com/Qianvenh/CDGLT}{https://github.com/Qianvenh/CDGLT}.",
    "pdf_url": "http://arxiv.org/pdf/2505.11237v1",
    "published": "2025-05-16T13:27:57+00:00",
    "categories": [
      "cs.MM",
      "cs.LG"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2505.11236v1",
    "title": "ForgetMeNot: Understanding and Modeling the Impact of Forever Chemicals Toward Sustainable Large-Scale Computing",
    "authors": [
      "Rohan Basu Roy",
      "Raghavendra Kanakagiri",
      "Yankai Jiang",
      "Devesh Tiwari"
    ],
    "abstract": "Fluorinated compounds, often referred to as forever chemicals, are critical\nin various steps of semiconductor fabrication like lithography, etching,\nchamber cleaning, and others. Forever chemical emissions can exhibit global\nwarming potentials thousands of times greater than carbon dioxide and persist\nin the atmosphere for millennia. Despite their severe impact, most\nsustainability works in computer systems have focused on carbon emissions\nalone. We address this gap by introducing ForgetMeNot, a modeling tool that\nquantifies fluorinated compound emissions by integrating fabrication\nfacility-specific practices and hardware specifications, and validate its\naccuracy using real-world emission data from fabrication facilities. We show\nhow ForgetMeNot can enable fabrication facilities to optimize design and\nmaterial usage decisions for emission reduction and provide researchers with a\nmethodology to calibrate emission estimates for hardware designs. When\nForgetMeNot is applied to analyze emissions for manufacturing CPUs, DRAM, and\nstorage, it illustrates how hardware generations, lithography techniques, and\ncapacities impact fluorinated compound emissions. Finally, we demonstrate how\ndatacenter operators can assemble low-emission servers while balancing\nperformance demands. By factoring in fluorinated emissions into manufacturing\ndecisions, ForgetMeNot paves the way for building more sustainable systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11236v1",
    "published": "2025-05-16T13:27:29+00:00",
    "categories": [
      "cs.ET",
      "cond-mat.mtrl-sci",
      "cs.AR",
      "cs.DC"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.11235v1",
    "title": "Memory-Efficient Orthogonal Fine-Tuning with Principal Subspace Adaptation",
    "authors": [
      "Fei Wu",
      "Jia Hu",
      "Geyong Min",
      "Shiqiang Wang"
    ],
    "abstract": "Driven by the relentless growth in model parameters, which renders full\nfine-tuning prohibitively expensive for large-scale deployment,\nparameter-efficient fine-tuning (PEFT) has emerged as a crucial approach for\nrapidly adapting large models to a wide range of downstream tasks. Among the\nPEFT family, orthogonal fine-tuning and its variants have demonstrated\nremarkable performance by preserving hyperspherical energy, which encodes\npairwise angular similarity between neurons. However, these methods are\ninherently memory-inefficient due to the need to store intermediate activations\nfrom multiple full-dimensional sparse matrices. To address this limitation, we\npropose Memory-efficient Orthogonal Fine-Tuning (MOFT) with principal subspace\nadaptation. Specifically, we first establish a theoretical condition under\nwhich orthogonal transformations within a low-rank subspace preserve\nhyperspherical energy. Based on this insight, we constrain orthogonal\nfine-tuning to the principal subspace defined by the top-r components obtained\nthrough singular value decomposition and impose an additional constraint on the\nprojection matrix to satisfy the preservation condition. To enhance MOFT's\nflexibility across tasks, we relax strict orthogonality by introducing two\nlearnable scaling vectors. Extensive experiments on 37 diverse tasks and four\nmodels across NLP and CV demonstrate that MOFT consistently outperforms key\nbaselines while significantly reducing the memory footprint of orthogonal\nfine-tuning.",
    "pdf_url": "http://arxiv.org/pdf/2505.11235v1",
    "published": "2025-05-16T13:26:48+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11234v2",
    "title": "Some Aspects of Three-Quark Potentials (Part II)",
    "authors": [
      "Oleg Andreev"
    ],
    "abstract": "We continue our investigation of the effective string model for the triply\nheavy quark system, mimicking that in pure $SU(3)$ gauge theory. We present\nanalytical and numerical studies of the three-quark potential for isosceles and\ncollinear geometries. In the general case, we derive the asymptotic expression\nof the potential in the infrared limit. Here we also demonstrate the\nuniversality of the string tension and interpret the transition between two\ndistinct regimes, occurring when one of the triangle's angles formed by the\nquarks is equal to $\\frac{2}{3}\\pi$, as a breaking of permutational symmetry.\nThis symmetry breaking implies the emergence of a heavy quark dressed by\ngluons, transforming in the two-index antisymmetric representation.\nAdditionally, we discuss various aspects of the $Y$- and $\\Delta$-laws,\ndiquarks, and connections to lattice QCD.",
    "pdf_url": "http://arxiv.org/pdf/2505.11234v2",
    "published": "2025-05-16T13:26:36+00:00",
    "categories": [
      "hep-ph",
      "hep-lat",
      "hep-th",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11233v1",
    "title": "A note on iterated sumsets races",
    "authors": [
      "Paul Péringuey",
      "Anne de Roton"
    ],
    "abstract": "This short note answers a question raised by Nathanson \\cite{Nath25} about\n\"races\" between iterated sumsets. We prove that for any integer $n$, there are\nfinite sets of integers $A$ and $B$ with same diameter such that the signs of\nthe elements of the sequence $(|hA|-|hB|)_h$ changes at least $n$ times.\nKravitz proved in \\cite{Kravitz} a much better result. This brief and modest\nnote may serve as a stepping stone towards his work.",
    "pdf_url": "http://arxiv.org/pdf/2505.11233v1",
    "published": "2025-05-16T13:26:29+00:00",
    "categories": [
      "math.NT",
      "math.CO",
      "11P70"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11232v2",
    "title": "AW-GATCN: Adaptive Weighted Graph Attention Convolutional Network for Event Camera Data Joint Denoising and Object Recognition",
    "authors": [
      "Haiyu Li",
      "Charith Abhayaratne"
    ],
    "abstract": "Event cameras, which capture brightness changes with high temporal\nresolution, inherently generate a significant amount of redundant and noisy\ndata beyond essential object structures. The primary challenge in event-based\nobject recognition lies in effectively removing this noise without losing\ncritical spatial-temporal information. To address this, we propose an Adaptive\nGraph-based Noisy Data Removal framework for Event-based Object Recognition.\nSpecifically, our approach integrates adaptive event segmentation based on\nnormalized density analysis, a multifactorial edge-weighting mechanism, and\nadaptive graph-based denoising strategies. These innovations significantly\nenhance the integration of spatiotemporal information, effectively filtering\nnoise while preserving critical structural features for robust recognition.\nExperimental evaluations on four challenging datasets demonstrate that our\nmethod achieves superior recognition accuracies of 83.77%, 76.79%, 99.30%, and\n96.89%, surpassing existing graph-based methods by up to 8.79%, and improving\nnoise reduction performance by up to 19.57%, with an additional accuracy gain\nof 6.26% compared to traditional Euclidean-based techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.11232v2",
    "published": "2025-05-16T13:26:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11231v1",
    "title": "MM-INT: Telemetry in Programmable Switches with Multiple Queues using Source-based Multipath Routing",
    "authors": [
      "Mateus N. Bragatto",
      "João Paulo M. Clevelares",
      "Cristina K. Dominicini",
      "Rodolfo S. Villaça",
      "Fábio L. Verdi"
    ],
    "abstract": "This article emphasizes the importance of queues associated with the ports of\nswitches in network monitoring. Traditionally, data collection about these\nqueues is done using programmable data planes and telemetry based on INT\n(In-band Network Telemetry) probes, assuming there is only a single queue per\noutput port. The MM-INT (Multiqueue Multicast - INT)\n  is a solution that utilizes registers to store data from all queues and\nports, enabling the efficient collection of monitoring information. The MM-INT\navoids probe overload and employs the origin-based routing mechanism and\nmulticast trees for the probes. The results demonstrate significant reductions\nin the number of probes sent compared to other traditional solutions found in\nthe literature.",
    "pdf_url": "http://arxiv.org/pdf/2505.11231v1",
    "published": "2025-05-16T13:25:53+00:00",
    "categories": [
      "cs.NI",
      "C.2.1"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11230v1",
    "title": "Learning traffic flows: Graph Neural Networks for Metamodelling Traffic Assignment",
    "authors": [
      "Oskar Bohn Lassen",
      "Serio Agriesti",
      "Mohamed Eldafrawi",
      "Daniele Gammelli",
      "Guido Cantelmo",
      "Guido Gentile",
      "Francisco Camara Pereira"
    ],
    "abstract": "The Traffic Assignment Problem is a fundamental, yet computationally\nexpensive, task in transportation modeling, especially for large-scale\nnetworks. Traditional methods require iterative simulations to reach\nequilibrium, making real-time or large-scale scenario analysis challenging. In\nthis paper, we propose a learning-based approach using Message-Passing Neural\nNetworks as a metamodel to approximate the equilibrium flow of the Stochastic\nUser Equilibrium assignment. Our model is designed to mimic the algorithmic\nstructure used in conventional traffic simulators allowing it to better capture\nthe underlying process rather than just the data. We benchmark it against other\nconventional deep learning techniques and evaluate the model's robustness by\ntesting its ability to predict traffic flows on input data outside the domain\non which it was trained. This approach offers a promising solution for\naccelerating out-of-distribution scenario assessments, reducing computational\ncosts in large-scale transportation planning, and enabling real-time\ndecision-making.",
    "pdf_url": "http://arxiv.org/pdf/2505.11230v1",
    "published": "2025-05-16T13:25:22+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11229v1",
    "title": "Symbolic Model Checking in External Memory",
    "authors": [
      "Steffan Christ Sølvsten",
      "Jaco van de Pol"
    ],
    "abstract": "We extend the external memory BDD package Adiar with support for monotone\nvariable substitution. Doing so, it now supports the relational product\noperation at the heart of symbolic model checking. We also identify additional\navenues for merging variable substitution fully and the conjunction operation\npartially inside the relational product's existential quantification step. For\nsmaller BDDs, these additional ideas improve the running of Adiar for model\nchecking tasks up to 47%. For larger instances, the computation time is mostly\nunaffected as it is dominated by the existential quantification.\n  Adiar's relational product is about one order of magnitude slower than\nconventional depth-first BDD implementations. Yet, its I/O-efficiency allows\nits running time to be virtually independent of the amount of internal memory.\nThis allows it to compute on BDDs with much less internal memory and\npotentially to solve model checking tasks beyond the reach of conventional\nimplementations.\n  Compared to the only other external memory BDD package, CAL, Adiar is several\norders of magnitude faster when computing on larger instances.",
    "pdf_url": "http://arxiv.org/pdf/2505.11229v1",
    "published": "2025-05-16T13:24:52+00:00",
    "categories": [
      "cs.DS",
      "cs.LO",
      "68W30 (primary) 68Q60, 68R07 (secondary)",
      "E.1; F.2.2; I.1.2"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.11228v2",
    "title": "Learning hidden cascades via classification",
    "authors": [
      "Derrick Gilchrist Edward Manoharan",
      "Anubha Goel",
      "Alexandros Iosifidis",
      "Henri Hansen",
      "Juho Kanniainen"
    ],
    "abstract": "The spreading dynamics in social networks are often studied under the\nassumption that individuals' statuses, whether informed or infected, are fully\nobservable. However, in many real-world situations, such statuses remain\nunobservable, which is crucial for determining an individual's potential to\nfurther spread the infection. While this final status is hidden, intermediate\nindicators such as symptoms of infection are observable and provide important\ninsights into the spread process. We propose a partial observability-aware\nMachine Learning framework to learn the characteristics of the spreading model.\nWe term the method Distribution Classification, which utilizes the power of\nclassifiers to infer the underlying transmission dynamics. We evaluate our\nmethod on two types of synthetic networks and extend the study to a real-world\ninsider trading network. Results show that the method performs well, especially\non complex networks with high cyclic connectivity, supporting its utility in\nanalyzing real-world spreading phenomena where direct observation of individual\nstatuses is not possible.",
    "pdf_url": "http://arxiv.org/pdf/2505.11228v2",
    "published": "2025-05-16T13:23:52+00:00",
    "categories": [
      "cs.SI",
      "cs.LG"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11227v1",
    "title": "Is PRM Necessary? Problem-Solving RL Implicitly Induces PRM Capability in LLMs",
    "authors": [
      "Zhangying Feng",
      "Qianglong Chen",
      "Ning Lu",
      "Yongqian Li",
      "Siqi Cheng",
      "Shuangmu Peng",
      "Duyu Tang",
      "Shengcai Liu",
      "Zhirui Zhang"
    ],
    "abstract": "The development of reasoning capabilities represents a critical frontier in\nlarge language models (LLMs) research, where reinforcement learning (RL) and\nprocess reward models (PRMs) have emerged as predominant methodological\nframeworks. Contrary to conventional wisdom, empirical evidence from\nDeepSeek-R1 demonstrates that pure RL training focused on mathematical\nproblem-solving can progressively enhance reasoning abilities without PRM\nintegration, challenging the perceived necessity of process supervision. In\nthis study, we conduct a systematic investigation of the relationship between\nRL training and PRM capabilities. Our findings demonstrate that problem-solving\nproficiency and process supervision capabilities represent complementary\ndimensions of reasoning that co-evolve synergistically during pure RL training.\nIn particular, current PRMs underperform simple baselines like majority voting\nwhen applied to state-of-the-art models such as DeepSeek-R1 and QwQ-32B. To\naddress this limitation, we propose Self-PRM, an introspective framework in\nwhich models autonomously evaluate and rerank their generated solutions through\nself-reward mechanisms. Although Self-PRM consistently improves the accuracy of\nthe benchmark (particularly with larger sample sizes), analysis exposes\npersistent challenges: The approach exhibits low precision (<10\\%) on difficult\nproblems, frequently misclassifying flawed solutions as valid. These analyses\nunderscore the need for continued RL scaling to improve reward alignment and\nintrospective accuracy. Overall, our findings suggest that PRM may not be\nessential for enhancing complex reasoning, as pure RL not only improves\nproblem-solving skills but also inherently fosters robust PRM capabilities. We\nhope these findings provide actionable insights for building more reliable and\nself-aware complex reasoning models.",
    "pdf_url": "http://arxiv.org/pdf/2505.11227v1",
    "published": "2025-05-16T13:23:26+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11226v1",
    "title": "Counting integral points in thin sets of type II: singularities, sieves, and stratification",
    "authors": [
      "Dante Bonolis",
      "Lillian B. Pierce",
      "Katharine Woo"
    ],
    "abstract": "Consider an absolutely irreducible polynomial $F(Y,X_1,\\ldots,X_n) \\in\n\\mathbb{Z}[Y,X_1,\\ldots,X_n]$ that is monic in $Y$ and is a polynomial in $Y^m$\nfor an integer $m \\geq 1$. Let $N(F,B)$ count the number of $\\mathbf{x} \\in\n[-B,B]^n \\cap \\mathbb{Z}^n$ such that $F(y,\\mathbf{x})=0$ is solvable for $y\n\\in\\mathbb{Z}$. In nomenclature of Serre, bounding $N(F,B)$ corresponds to\ncounting integral points in an affine thin set of type II. Previously, in this\ngenerality Serre proved $N(F,B) \\ll_F B^{n-1/2}(\\log B)^{\\gamma}$ for some\n$\\gamma<1$. When $m \\geq 2$, this new work proves $N(F,B) \\ll_{n,F,\\epsilon}\nB^{n-1+1/(n+1) + \\epsilon}$ under a nondegeneracy condition that encapsulates\nthat $F(Y,\\mathbf{X})$ is truly a polynomial in $n+1$ variables, even after\nperforming any $\\text{GL}_n(\\mathbb{Q})$ change of variables on\n$X_1,\\ldots,X_n$. Under GRH, this result also holds when $m=1$. We show that\ngeneric polynomials satisfy the relevant nondegeneracy condition. Moreover, for\na certain class of polynomials, we prove the stronger bound $N(F,B) \\ll_{F}\nB^{n-1}(\\log B)^{e(n)}$, comparable to a conjecture of Serre. A key strength of\nthese results is that they require no nonsingularity property of\n$F(Y,\\mathbf{X})$. The Katz-Laumon stratification for character sums, in a new\nuniform formulation appearing in a companion paper of Bonolis, Kowalski and\nWoo, is a key ingredient in the sieve method we develop to prove upper bounds\nthat explicitly control any dependence on the size of the coefficients of $F$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11226v1",
    "published": "2025-05-16T13:23:23+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11225v1",
    "title": "HAPO: Training Language Models to Reason Concisely via History-Aware Policy Optimization",
    "authors": [
      "Chengyu Huang",
      "Zhengxin Zhang",
      "Claire Cardie"
    ],
    "abstract": "While scaling the length of responses at test-time has been shown to markedly\nimprove the reasoning abilities and performance of large language models\n(LLMs), it often results in verbose outputs and increases inference cost. Prior\napproaches for efficient test-time scaling, typically using universal budget\nconstraints or query-level length optimization, do not leverage historical\ninformation from previous encounters with the same problem during training. We\nhypothesize that this limits their ability to progressively make solutions more\nconcise over time. To address this, we present History-Aware Policy\nOptimization (HAPO), which keeps track of a history state (e.g., the minimum\nlength over previously generated correct responses) for each problem. HAPO\nemploys a novel length reward function based on this history state to\nincentivize the discovery of correct solutions that are more concise than those\npreviously found. Crucially, this reward structure avoids overly penalizing\nshorter incorrect responses with the goal of facilitating exploration towards\nmore efficient solutions. By combining this length reward with a correctness\nreward, HAPO jointly optimizes for correctness and efficiency. We use HAPO to\ntrain DeepSeek-R1-Distill-Qwen-1.5B, DeepScaleR-1.5B-Preview, and\nQwen-2.5-1.5B-Instruct, and evaluate HAPO on several math benchmarks that span\nvarious difficulty levels. Experiment results demonstrate that HAPO effectively\ninduces LLMs' concise reasoning abilities, producing length reductions of\n33-59% with accuracy drops of only 2-5%.",
    "pdf_url": "http://arxiv.org/pdf/2505.11225v1",
    "published": "2025-05-16T13:21:28+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11224v2",
    "title": "Tracing the formation and migration history: molecular signatures in the atmosphere of misaligned hot Jupiter WASP-94Ab using JWST NIRSpec/G395H",
    "authors": [
      "Eva-Maria Ahrer",
      "Siddharth Gandhi",
      "Lili Alderson",
      "James Kirk",
      "Johanna Teske",
      "Richard A. Booth",
      "Catriona H. McDonald",
      "Duncan A. Christie",
      "Alastair B. Claringbold",
      "Rebecca Nealon",
      "Vatsal Panwar",
      "Dimitri Veras",
      "Hannah R. Wakeford",
      "Peter J. Wheatley",
      "Maria Zamyatina"
    ],
    "abstract": "The discovery of hot Jupiters that orbit very close to their host stars has\nlong challenged traditional models of planetary formation and migration.\nCharacterising their atmospheric composition - mainly in the form of the\ncarbon-to-oxygen (C/O) ratio and metallicity - can provide insights into their\nformation locations and evolution pathways. With JWST we can characterise the\natmospheres of these types of planets more precisely than previously possible,\nprimarily because it allows us to determine both their atmospheric oxygen and\ncarbon composition. Here, we present a JWST NIRSpec/G395H transmission spectrum\nfrom 2.8-5.1$\\mu m$ of WASP-94Ab, an inflated hot Jupiter with a retrograde\nmisaligned orbit around its F-type host star. We find a relatively cloud-free\natmosphere, with absorption features of H$_2$O and CO$_2$ at detection\nsignificances of $\\sim 4\\sigma$ and $\\sim 11\\sigma$, respectively. In addition,\nwe detect tentative evidence of CO absorption at $\\sim3\\sigma$, as well as\nhints of sulphur with the detection of H$_2$S at a $\\sim 2.5\\sigma$ confidence\nlevel. Our favoured equilibrium chemistry model determines a C/O ratio of\n$0.49^{+0.08}_{-0.13}$ for WASP-94Ab's atmosphere, which is substellar compared\nto the star's C/O ratio of $0.68 \\pm 0.10$. The retrieved atmospheric\nmetallicity is similar to the star's metallicity as both are $\\sim 2\\times$\nsolar. We find that this sub-stellar C/O ratio and stellar metallicity can be\nbest explained by pebble accretion or planetesimal accretion in combination\nwith large-distance migration of the planet.",
    "pdf_url": "http://arxiv.org/pdf/2505.11224v2",
    "published": "2025-05-16T13:19:16+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11223v1",
    "title": "Th/Eu abundance ratio of red giants in the Kepler Field",
    "authors": [
      "Ainun Azhari",
      "Tadafumi Matsuno",
      "Wako Aoki",
      "Miho N Ishigaki",
      "Eline Tolstoy"
    ],
    "abstract": "The r-process production in the early universe has been well constrained by\nthe extensive studies of metal-poor stars. However, the r-process enrichment in\nthe metal-rich regime is still not well understood. In this study, we examine\nthe abundance ratios of Th and Eu, which represent the actinides and\nlanthanides, respectively, for a sample of metal-rich disk stars. Our sample\ncovers 89 giant stars in the Kepler field with metallicities $-0.7 \\leq\n\\rm{[Fe/H]} \\leq 0.4$ and ages from a few hundred Myr to $\\sim 14$ Gyr. Age\ninformation for this sample is available from stellar seismology, which is\nessential for studying the radioactive element Th. We derive Th and Eu\nabundances through $\\chi^2$ fitting of high-resolution archival spectra ($R\n\\sim 80,000$) observed with the High Dispersion Spectrograph (HDS) at the\nSubaru Telescope. We create synthetic spectra for individual stars using a 1D\nLTE spectral synthesis code, Turbospectrum, adopting MARCS model atmospheres.\nOur study establishes the use of a less extensively studied Th II line at 5989\nangstrom, carefully taking into account the blends of other spectral lines to\nderive the Th abundance. We successfully determine Eu abundance for 89 stars in\nour sample and Th for 81 stars. For the remaining 8 stars, we estimate the\nupper limits of Th abundance. After correcting the Th abundance for the decay,\nwe find no correlation between $\\rm{[Th/Eu]}$ and $\\rm{[Fe/H]}$, which\nindicates that actinides production with respect to lanthanides does not depend\non metallicity. On the other hand, we find a positive correlation of\n$\\rm{[Th/Eu]}$ with age, with a slope of $0.10 \\pm 0.04$. This may hint at the\npossibility that the dominant r-process sources are different between the early\nand late universe.",
    "pdf_url": "http://arxiv.org/pdf/2505.11223v1",
    "published": "2025-05-16T13:19:06+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11222v1",
    "title": "Open/closed correspondence for the projective line",
    "authors": [
      "Zhengyu Zong"
    ],
    "abstract": "We establish a correspondence between the disk invariants of the complex\nprojective line $\\bP^1$ with boundary condition specified by an $S^1$-invariant\nLagrangian sub-manifold $L$ and the genus-zero closed Gromov-Witten invariants\nof a toric surface $X$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11222v1",
    "published": "2025-05-16T13:18:56+00:00",
    "categories": [
      "math.AG",
      "14N35, 53D45"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11221v1",
    "title": "Sample Efficient Reinforcement Learning via Large Vision Language Model Distillation",
    "authors": [
      "Donghoon Lee",
      "Tung M. Luu",
      "Younghwan Lee",
      "Chang D. Yoo"
    ],
    "abstract": "Recent research highlights the potential of multimodal foundation models in\ntackling complex decision-making challenges. However, their large parameters\nmake real-world deployment resource-intensive and often impractical for\nconstrained systems. Reinforcement learning (RL) shows promise for\ntask-specific agents but suffers from high sample complexity, limiting\npractical applications. To address these challenges, we introduce LVLM to\nPolicy (LVLM2P), a novel framework that distills knowledge from large\nvision-language models (LVLM) into more efficient RL agents. Our approach\nleverages the LVLM as a teacher, providing instructional actions based on\ntrajectories collected by the RL agent, which helps reduce less meaningful\nexploration in the early stages of learning, thereby significantly accelerating\nthe agent's learning progress. Additionally, by leveraging the LVLM to suggest\nactions directly from visual observations, we eliminate the need for manual\ntextual descriptors of the environment, enhancing applicability across diverse\ntasks. Experiments show that LVLM2P significantly enhances the sample\nefficiency of baseline RL algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.11221v1",
    "published": "2025-05-16T13:15:54+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11575v1",
    "title": "On Some Series Involving the Central Binomial Coefficients",
    "authors": [
      "Kunle Adegoke",
      "Robert Frontczak",
      "Taras Goy"
    ],
    "abstract": "In this paper, we explore a variety of series involving the central binomial\ncoefficients, highlighting their structural properties and connections to other\nmathematical objects. Specifically, we derive new closed-form representations\nand examine the convergence properties of infinite series with a repeating\nalternation pattern of signs involving central binomial coefficients. More\nconcretely, we derive the series\n$$\\sum\\limits_{n=0}^{\\infty}\\frac{(-1)^{\\omega_n}}{2n+1}\\tbinom{2n}{n}x^n,\\,\\,\\,\n\\sum\\limits_{n=0}^{\\infty}{(-1)^{\\omega_n}}\\tbinom{2n}{n}x^n\\,\\,\\, \\text{and}\n\\,\\,\\, \\sum\\limits_{n=0}^{\\infty}{(-1)^{\\omega_n}}n\\tbinom{2n}{n}x^n,$$ where\n$\\omega_n$ represents both $\\lfloor\\frac{n}{2}\\rfloor$ and\n$\\lceil\\frac{n}{2}\\rceil$. Also, we present novel series involving Fibonacci\nand Lucas numbers, deriving many interesting identities.",
    "pdf_url": "http://arxiv.org/pdf/2505.11575v1",
    "published": "2025-05-16T13:15:46+00:00",
    "categories": [
      "math.CO",
      "40A30, 11B37, 11B39"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11220v1",
    "title": "Singularity Categories of Bäckström Orders",
    "authors": [
      "Hongrui Wei"
    ],
    "abstract": "B\\\"ackstr\\\"om orders are a class of algebras over complete discrete valuation\nrings. Their Cohen-Macaulay representations are in correspondence with the\nrepresentations of certain quivers/species by Ringel and Roggenkamp. In this\npaper, we give explicit descriptions of the singularity categories of\nB\\\"ackstr\\\"om orders via certain von Neumann regular algebras and associated\nbimodules. We further provide singular equivalences between B\\\"ackstr\\\"om\norders and specific finite dimensional algebras with radical square zero. We\nalso classify B\\\"ackstr\\\"om orders of finite global dimension, as well as\nGorenstein, Iwanaga-Gorenstein and sg-Hom-finite B\\\"ackstr\\\"om orders.",
    "pdf_url": "http://arxiv.org/pdf/2505.11220v1",
    "published": "2025-05-16T13:15:45+00:00",
    "categories": [
      "math.RT",
      "16G30 16G50 18G25 18G80"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11219v1",
    "title": "Formal Uncertainty Propagation for Stochastic Dynamical Systems with Additive Noise",
    "authors": [
      "Steven Adams",
      "Eduardo Figueiredo",
      "Luca Laurenti"
    ],
    "abstract": "In this paper, we consider discrete-time non-linear stochastic dynamical\nsystems with additive process noise in which both the initial state and noise\ndistributions are uncertain. Our goal is to quantify how the uncertainty in\nthese distributions is propagated by the system dynamics for possibly infinite\ntime steps. In particular, we model the uncertainty over input and noise as\nambiguity sets of probability distributions close in the $\\rho$-Wasserstein\ndistance and aim to quantify how these sets evolve over time. Our approach\nrelies on results from quantization theory, optimal transport, and stochastic\noptimization to construct ambiguity sets of distributions centered at mixture\nof Gaussian distributions that are guaranteed to contain the true sets for both\nfinite and infinite prediction time horizons. We empirically evaluate the\neffectiveness of our framework in various benchmarks from the control and\nmachine learning literature, showing how our approach can efficiently and\nformally quantify the uncertainty in linear and non-linear stochastic dynamical\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11219v1",
    "published": "2025-05-16T13:15:17+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11218v2",
    "title": "Quantum computing with atomic qubit arrays: confronting the cost of connectivity",
    "authors": [
      "M. Saffman"
    ],
    "abstract": "These notes present a review of the status of quantum computing with arrays\nof neutral atom qubits, an approach which has demonstrated remarkable progress\nin the last few years. Scaling digital quantum computing to qubit counts and\ncontrol fidelities that will enable solving outstanding scientific questions,\nand provide commercial value, is an outstanding challenge, not least because of\nthe requirement of connecting and entangling distant qubits. Long-range Rydberg\ngates and physical motion outfit atomic qubit arrays with tools for\nestablishing connectivity. These tools operate on different timescales and with\ndistinct levels of parallelization. We analyze several prototypical\narchitectures from the perspective of achieving fast connectivity for circuits\nwith large scale entanglement, as well as fast cycle times for measurement\nbased quantum error correcting codes. Extending Rydberg interactions to\nmultiple atomic species has emerged as a promising route to achieving this\nlatter requirement.",
    "pdf_url": "http://arxiv.org/pdf/2505.11218v2",
    "published": "2025-05-16T13:14:56+00:00",
    "categories": [
      "quant-ph",
      "physics.atom-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11217v1",
    "title": "Seeing Sound, Hearing Sight: Uncovering Modality Bias and Conflict of AI models in Sound Localization",
    "authors": [
      "Yanhao Jia",
      "Ji Xie",
      "S Jivaganesh",
      "Hao Li",
      "Xu Wu",
      "Mengmi Zhang"
    ],
    "abstract": "Imagine hearing a dog bark and turning toward the sound only to see a parked\ncar, while the real, silent dog sits elsewhere. Such sensory conflicts test\nperception, yet humans reliably resolve them by prioritizing sound over\nmisleading visuals. Despite advances in multimodal AI integrating vision and\naudio, little is known about how these systems handle cross-modal conflicts or\nwhether they favor one modality. In this study, we systematically examine\nmodality bias and conflict resolution in AI sound localization. We assess\nleading multimodal models and benchmark them against human performance in\npsychophysics experiments across six audiovisual conditions, including\ncongruent, conflicting, and absent cues. Humans consistently outperform AI,\ndemonstrating superior resilience to conflicting or missing visuals by relying\non auditory information. In contrast, AI models often default to visual input,\ndegrading performance to near chance levels. To address this, we finetune a\nstate-of-the-art model using a stereo audio-image dataset generated via 3D\nsimulations. Even with limited training data, the refined model surpasses\nexisting benchmarks. Notably, it also mirrors human-like horizontal\nlocalization bias favoring left-right precision-likely due to the stereo audio\nstructure reflecting human ear placement. These findings underscore how sensory\ninput quality and system architecture shape multimodal representation accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.11217v1",
    "published": "2025-05-16T13:13:25+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.11216v1",
    "title": "GeoMM: On Geodesic Perspective for Multi-modal Learning",
    "authors": [
      "Shibin Mei",
      "Hang Wang",
      "Bingbing Ni"
    ],
    "abstract": "Geodesic distance serves as a reliable means of measuring distance in\nnonlinear spaces, and such nonlinear manifolds are prevalent in the current\nmultimodal learning. In these scenarios, some samples may exhibit high\nsimilarity, yet they convey different semantics, making traditional distance\nmetrics inadequate for distinguishing between positive and negative samples.\nThis paper introduces geodesic distance as a novel distance metric in\nmulti-modal learning for the first time, to mine correlations between samples,\naiming to address the limitations of common distance metric. Our approach\nincorporates a comprehensive series of strategies to adapt geodesic distance\nfor the current multimodal learning. Specifically, we construct a graph\nstructure to represent the adjacency relationships among samples by\nthresholding distances between them and then apply the shortest-path algorithm\nto obtain geodesic distance within this graph. To facilitate efficient\ncomputation, we further propose a hierarchical graph structure through\nclustering and combined with incremental update strategies for dynamic status\nupdates. Extensive experiments across various downstream tasks validate the\neffectiveness of our proposed method, demonstrating its capability to capture\ncomplex relationships between samples and improve the performance of multimodal\nlearning models.",
    "pdf_url": "http://arxiv.org/pdf/2505.11216v1",
    "published": "2025-05-16T13:12:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11215v1",
    "title": "Magnetic monopoles in Yang-Mills-Higgs theory with impurities",
    "authors": [
      "D. Bazeia",
      "M. A. Liao",
      "M. A. Marques"
    ],
    "abstract": "In this work, BPS models built from the coupling of Yang-Mills-Higgs\nLagrangian to impurities are investigated. We first consider scalar impurities,\nwhich in the BPS limit generate monopoles similar to those obtained in a\npreviously considered class of $\\mathrm{SU(2)}\\times\\mathrm{Z}_2$ or\n$\\mathrm{SU(2)}\\times\\mathrm{SU(2)}$ models. We then focus on coupling with\nnonabelian impurities, defined as fixed backgrounds produced from fields\ntransforming under the adjoint representation of SU(2), with a coupling chosen\nto preserve half of the BPS sectors. The nature of this coupling, the ensuing\nBogomol'nyi bound and BPS equations, as well as the effect of these impurities\nin the abelianization that leads to the emergence of a U(1) gauge group are\ninvestigated. We study in greater detail impurities with spherical symmetry,\nand examine the manner in which impurity coupling changes the asymptotic\nbehavior and range of monopole interactions. Moreover, we introduce a method\nthat can be used to approximate solutions with the use of small perturbations\naround the Prasad-Sommerfield monopole, and discuss the possibility of\nextending the aforementioned results to dyons. In order to exemplify the most\nimportant properties of the theory, several specific impurity models are\npresented, with the respective monopole solutions are found numerically. These\nsolutions present novel internal structure and multiple features that would not\nbe possible in the original theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.11215v1",
    "published": "2025-05-16T13:12:19+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11214v1",
    "title": "Unveiling the Potential of Vision-Language-Action Models with Open-Ended Multimodal Instructions",
    "authors": [
      "Wei Zhao",
      "Gongsheng Li",
      "Zhefei Gong",
      "Pengxiang Ding",
      "Han Zhao",
      "Donglin Wang"
    ],
    "abstract": "Vision-Language-Action (VLA) models have recently become highly prominent in\nthe field of robotics. Leveraging vision-language foundation models trained on\nlarge-scale internet data, the VLA model can generate robotic actions directly\nfrom visual observations and human instructions through a single end-to-end\nneural network. Despite their effectiveness, current VLA models usually accept\nonly one form of human prompting, language instructions, which may constrain\ntheir applicability in open-ended human-robot interactions. For example, a user\nmight expect the robot to retrieve an object shown in an image, follow an\ninstruction written on the whiteboard, or imitate a behavior demonstrated in a\nvideo, rather than relying solely on language-based descriptions. To address\nthis gap, we introduce OE-VLA, which explores the potential of VLA models for\nopen-ended multimodal instructions. Extensive results demonstrate that our\nOE-VLA not only achieves comparable performance to traditional VLA models with\nlinguistic input but also delivers impressive results across four additional\ncategories of open-ended tasks. The proposed methodology could significantly\nexpand the applications of VLA models across various everyday scenarios and\nfacilitate human-robot interaction.",
    "pdf_url": "http://arxiv.org/pdf/2505.11214v1",
    "published": "2025-05-16T13:12:08+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11213v1",
    "title": "Brinkman's law as $Γ$-limit of compressible low Mach Navier-Stokes equations and application to randomly perforated domains",
    "authors": [
      "Peter Bella",
      "Friederike Lemming",
      "Roberta Marziani",
      "Florian Oschmann"
    ],
    "abstract": "We consider the time-dependent compressible Navier-Stokes equations in the\nlow Mach number regime inside a family of domains\n$(\\Omega_\\varepsilon)_{\\varepsilon > 0}$ in $\\mathbb{R}^3$. Assuming that\n$\\lim_{\\varepsilon \\to 0} \\Omega_\\varepsilon = \\Omega \\subset \\mathbb{R}^3$ in\na suitable sense, we show that in the limit the fluid flow inside $\\Omega$ is\ngoverned by the incompressible Navier-Stokes-Brinkman equations, provided the\nlatter one admits a strong solution. The abstract convergence result is\ncomplemented with a stochastic homogenization result for randomly perforated\ndomains in the critical regime.",
    "pdf_url": "http://arxiv.org/pdf/2505.11213v1",
    "published": "2025-05-16T13:10:14+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11212v1",
    "title": "Near-critical gene expression in embryonic boundary precision",
    "authors": [
      "Michael Vennettilli",
      "Krishna P. Ramachandran",
      "Andrew Mugler"
    ],
    "abstract": "Embryonic development relies on the formation of sharp, precise gene\nexpression boundaries. In the fruit fly Drosophila melanogaster, boundary\nformation has been proposed to occur at a dynamical critical point. Yet, in the\nparadigmatic case of the hunchback (hb) gene, evidence suggests that boundary\nformation occurs in a bistable regime, not at the dynamical critical point. We\ndevelop a minimal model for hb expression and identify a single parameter that\ntunes the system from its monostable regime to its bistable regime, crossing\nthe critical point in between. We find that boundary precision is maximized\nwhen the system is weakly bistable--near, but not at, the critical\npoint--optimally negotiating the tradeoff between two key effects of\nbistability: sharpening the boundary and amplifying its noise. Incorporating\nthe diffusion of Hb proteins into our model, we show that boundary precision is\nmaximized simultaneously at an optimal degree of bistability and an optimal\ndiffusion strength. Our work elucidates design principles of precise boundary\nformation and has general implications for pattern formation in multicellular\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11212v1",
    "published": "2025-05-16T13:07:34+00:00",
    "categories": [
      "physics.bio-ph",
      "q-bio.MN"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11211v2",
    "title": "Bayesian Hierarchical Invariant Prediction",
    "authors": [
      "Francisco Madaleno",
      "Pernille Julie Viuff Sand",
      "Francisco C. Pereira",
      "Sergio Hernan Garrido Mejia"
    ],
    "abstract": "We propose Bayesian Hierarchical Invariant Prediction (BHIP) reframing\nInvariant Causal Prediction (ICP) through the lens of Hierarchical Bayes. We\nleverage the hierarchical structure to explicitly test invariance of causal\nmechanisms under heterogeneous data, resulting in improved computational\nscalability for a larger number of predictors compared to ICP. Moreover, given\nits Bayesian nature BHIP enables the use of prior information. In this paper,\nwe test two sparsity inducing priors: horseshoe and spike-and-slab, both of\nwhich allow us a more reliable identification of causal features. We test BHIP\nin synthetic and real-world data showing its potential as an alternative\ninference method to ICP.",
    "pdf_url": "http://arxiv.org/pdf/2505.11211v2",
    "published": "2025-05-16T13:06:25+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11210v2",
    "title": "Minimizing False-Positive Attributions in Explanations of Non-Linear Models",
    "authors": [
      "Anders Gjølbye",
      "Stefan Haufe",
      "Lars Kai Hansen"
    ],
    "abstract": "Suppressor variables can influence model predictions without being dependent\non the target outcome and they pose a significant challenge for Explainable AI\n(XAI) methods. These variables may cause false-positive feature attributions,\nundermining the utility of explanations. Although effective remedies exist for\nlinear models, their extension to non-linear models and to instance-based\nexplanations has remained limited. We introduce PatternLocal, a novel XAI\ntechnique that addresses this gap. PatternLocal begins with a locally linear\nsurrogate, e.g. LIME, KernelSHAP, or gradient-based methods, and transforms the\nresulting discriminative model weights into a generative representation,\nthereby suppressing the influence of suppressor variables while preserving\nlocal fidelity. In extensive hyperparameter optimization on the XAI-TRIS\nbenchmark, PatternLocal consistently outperformed other XAI methods and reduced\nfalse-positive attributions when explaining non-linear tasks, thereby enabling\nmore reliable and actionable insights.",
    "pdf_url": "http://arxiv.org/pdf/2505.11210v2",
    "published": "2025-05-16T13:06:12+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11209v2",
    "title": "The Parameter Dependence of $\\mathbf{n_{s}}$ and $\\mathbf{r}$ of the Scalar Power Spectrum during Single-Field Slow-Roll Inflation: A Comparative Study of Inflationary Potentials",
    "authors": [
      "Guanqiao Liu"
    ],
    "abstract": "Inflation in cosmology is a specific stage preceding the Big Bang, aimed at\nsolving both old background problems and new perturbation issues. Single-field\ninflation is a candidate to illustrate the picture of the initial universe, and\nvarious potential functions lead to different scenarios during the inflationary\nstage. This paper introduces two essential parameters: the spectral index and\nthe tensor-to-scalar ratio detected from the initial power spectrum, derived\nfrom the action of the scalar field and using approximation that the potential\nis flat. A brief overview of the origins of Starobinsky Inflation, Chaotic\nInflation, Small Field Inflation, and Natural Inflation is also presented,\nalong with their mathematical representations. Finally, the results derived\nfrom various inflation models regarding the index and ratio are tested using\nthe Planck data, and the deviations in each model are analyzed.",
    "pdf_url": "http://arxiv.org/pdf/2505.11209v2",
    "published": "2025-05-16T13:06:04+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11208v1",
    "title": "GLOVA: Global and Local Variation-Aware Analog Circuit Design with Risk-Sensitive Reinforcement Learning",
    "authors": [
      "Dongjun Kim",
      "Junwoo Park",
      "Chaehyeon Shin",
      "Jaeheon Jung",
      "Kyungho Shin",
      "Seungheon Baek",
      "Sanghyuk Heo",
      "Woongrae Kim",
      "Inchul Jeong",
      "Joohwan Cho",
      "Jongsun Park"
    ],
    "abstract": "Analog/mixed-signal circuit design encounters significant challenges due to\nperformance degradation from process, voltage, and temperature (PVT)\nvariations. To achieve commercial-grade reliability, iterative manual design\nrevisions and extensive statistical simulations are required. While several\nstudies have aimed to automate variation aware analog design to reduce\ntime-to-market, the substantial mismatches in real-world wafers have not been\nthoroughly addressed. In this paper, we present GLOVA, an analog circuit sizing\nframework that effectively manages the impact of diverse random mismatches to\nimprove robustness against PVT variations. In the proposed approach,\nrisk-sensitive reinforcement learning is leveraged to account for the\nreliability bound affected by PVT variations, and ensemble-based critic is\nintroduced to achieve sample-efficient learning. For design verification, we\nalso propose $\\mu$-$\\sigma$ evaluation and simulation reordering method to\nreduce simulation costs of identifying failed designs. GLOVA supports\nverification through industrial-level PVT variation evaluation methods,\nincluding corner simulation as well as global and local Monte Carlo (MC)\nsimulations. Compared to previous state-of-the-art variation-aware analog\nsizing frameworks, GLOVA achieves up to 80.5$\\times$ improvement in sample\nefficiency and 76.0$\\times$ reduction in time.",
    "pdf_url": "http://arxiv.org/pdf/2505.11208v1",
    "published": "2025-05-16T13:05:45+00:00",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11207v2",
    "title": "Some explicit values of a $q$-multiple zeta-star function at roots of unity",
    "authors": [
      "Takao Komatsu"
    ],
    "abstract": "In this paper, we show some expressions of certain $q$-multiple zeta-star\nvalues at roots of unity. These explicit formulas are expressed by using the\ndeterminants or Bell polynomials. Explicit formulas for other types of values\ncan be found from recurrence relations obtained using generating functions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11207v2",
    "published": "2025-05-16T13:05:15+00:00",
    "categories": [
      "math.NT",
      "math.CO"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11206v1",
    "title": "Global Regularity to the liquid crystal flows of Q-tensor model",
    "authors": [
      "Z. Chen",
      "E. Terraneo"
    ],
    "abstract": "In this paper we investigate a forced incompressible Navier-Stokes equation\ncoupled with a parabolic type equation of Q-tensors in a domain $U\\subset\\R^3.$\nIn the case $U$ is bounded, we prove the existence of a global strong solution\nwhen the initial data are sufficiently small, improving a result in Xiao's\npaper [J. Differ. Equations 2017]. The key tool of the proof is a {maximum\nprinciple.} Then, we establish also a result of continuous dependence of\nsolutions on the\n  initial data. Finally, if $U=\\R^3,$ based on a result of Du, Hu and Wang\n[Arch. Rational Mech. Anal. 2020], we give an interesting regularity criterium\njust via the $\\dot{B}^{-1}_{\\infty,\\infty}$ norm of $u$ and the $L^\\infty$ norm\nof the initial data $Q_0$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11206v1",
    "published": "2025-05-16T13:03:36+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11205v3",
    "title": "IssueCourier: Multi-Relational Heterogeneous Temporal Graph Neural Network for Open-Source Issue Assignment",
    "authors": [
      "Chunying Zhou",
      "Xiaoyuan Xie",
      "Gong Chen",
      "Peng He",
      "Bing Li"
    ],
    "abstract": "Issue assignment plays a critical role in open-source software (OSS)\nmaintenance, which involves recommending the most suitable developers to\naddress the reported issues. Given the high volume of issue reports in\nlarge-scale projects, manually assigning issues is tedious and costly. Previous\nstudies have proposed automated issue assignment approaches that primarily\nfocus on modeling issue report textual information, developers' expertise, or\ninteractions between issues and developers based on historical issue-fixing\nrecords. However, these approaches often suffer from performance limitations\ndue to the presence of incorrect and missing labels in OSS datasets, as well as\nthe long tail of developer contributions and the changes of developer activity\nas the project evolves. To address these challenges, we propose IssueCourier, a\nnovel Multi-Relational Heterogeneous Temporal Graph Neural Network approach for\nissue assignment. Specifically, we formalize five key relationships among\nissues, developers, and source code files to construct a heterogeneous graph.\nThen, we further adopt a temporal slicing technique that partitions the graph\ninto a sequence of time-based subgraphs to learn stage-specific patterns.\nFurthermore, we provide a benchmark dataset with relabeled ground truth to\naddress the problem of incorrect and missing labels in existing OSS datasets.\nFinally, to evaluate the performance of IssueCourier, we conduct extensive\nexperiments on our benchmark dataset. The results show that IssueCourier can\nimprove over the best baseline up to 45.49% in top-1 and 31.97% in MRR.",
    "pdf_url": "http://arxiv.org/pdf/2505.11205v3",
    "published": "2025-05-16T13:03:26+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11204v1",
    "title": "RanDeS: Randomized Delta Superposition for Multi-Model Compression",
    "authors": [
      "Hangyu Zhou",
      "Aaron Gokaslan",
      "Volodymyr Kuleshov",
      "Bharath Hariharan"
    ],
    "abstract": "From a multi-model compression perspective, model merging enables\nmemory-efficient serving of multiple models fine-tuned from the same base, but\nsuffers from degraded performance due to interference among their task-specific\nparameter adjustments (i.e., deltas). In this paper, we reformulate model\nmerging as a compress-and-retrieve scheme, revealing that the task interference\narises from the summation of irrelevant deltas during model retrieval. To\naddress this issue, we use random orthogonal transformations to decorrelate\nthese vectors into self-cancellation. We show that this approach drastically\nreduces interference, improving performance across both vision and language\ntasks. Since these transformations are fully defined by random seeds, adding\nnew models requires no extra memory. Further, their data- and model-agnostic\nnature enables easy addition or removal of models with minimal compute\noverhead, supporting efficient and flexible multi-model serving.",
    "pdf_url": "http://arxiv.org/pdf/2505.11204v1",
    "published": "2025-05-16T13:02:12+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11203v2",
    "title": "Homotopy properties of regular mappings into real retract rational varieties",
    "authors": [
      "Juliusz Banecki"
    ],
    "abstract": "We study homotopy properties of regular mappings from spheres into a real\nretract rational variety $Y$. We show that the homotopy classes which are\nrepresented by such mappings form subgroups of the homotopy groups of $Y$, and\nthat the groups are independent of the choice of the basepoint on $Y$ as long\nas $Y$ is connected. We also construct regular representatives of all the\nWhitehead products in all the homotopy groups of $Y$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11203v2",
    "published": "2025-05-16T13:01:27+00:00",
    "categories": [
      "math.AG",
      "math.AT",
      "14P99, 14P25"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11202v1",
    "title": "Taylor dispersion of bubble swarms rising in quiescent liquid",
    "authors": [
      "Guangyuan Huang",
      "Hendrik Hessenkemper",
      "Shiyong Tan",
      "Rui Ni",
      "Anna-E. Sommer",
      "Andrew D. Bragg",
      "Tian Ma"
    ],
    "abstract": "We study the dispersion of bubble swarms rising in initially quiescent water\nusing 3D Lagrangian tracking of deformable bubbles and tracer particles in an\noctagonal bubble column. First, we compare the dispersion inside bubble swarms\nwith that for single-bubble cases and find that the horizontal mean squared\ndisplacement (MSD) in the swarm cases exhibits oscillations around the\nasymptotic scaling predicted for a diffusive regime. This occurs due to\nwake-induced bubble motion, however, the oscillatory behaviour is heavily\ndamped compared to the single-bubble cases due to the presence of\nbubble-induced turbulence (BIT) and bubble-bubble interactions in the swarm.\nThe vertical MSD in bubble swarms is nearly an order of magnitude faster than\nthe single-bubble cases, due to the much higher vertical fluctuating bubble\nvelocities in the swarms. We also investigate tracer dispersion in BIT and find\nthat concerning the time to transition away from the ballistic regime, larger\nbubbles with a higher gas void fraction transition earlier than tracers,\nconsistent with Mathai et al. (\\textit{Phys. Rev. Lett.} 121, 054501, 2018).\nHowever, for bubble swarms with smaller bubbles and a lower gas void fraction,\nthey transition at the same time. This differing behavior is due to the\nturbulence being more well-mixed for the larger bubble case, whereas for the\nsmaller bubble case the tracer dispersion is highly dependent on the wake\nfluctuations generated by the oscillating motion of nearby bubbles.",
    "pdf_url": "http://arxiv.org/pdf/2505.11202v1",
    "published": "2025-05-16T12:59:03+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.11201v1",
    "title": "Search for Double Beta Plus Decays with NuDoubt++",
    "authors": [
      "Cloé Girard-Carillo"
    ],
    "abstract": "The NuDoubt++ experiment proposes a novel detector concept to search for\ndouble beta plus decays using a hybrid opaque liquid scintillator. This design\ncombines recent advances in scintillator technologies (namely, slow and opaque\nmedia, and optimized wavelength-shifting fibers coupled to silicon\nphotomultipliers) to achieve improved particle identification and background\nrejection. We present the physics motivations, detector design, first prototype\nlayout, and expected sensitivities for both standard and exotic modes, using\n78Kr as an initial target isotope. With this approach, NuDoubt++ aims to make\nthe first observation of positron emitting Standard Model two-neutrino modes\nand improve current constraints on Beyond Standard Model neutrinoless\nprocesses.",
    "pdf_url": "http://arxiv.org/pdf/2505.11201v1",
    "published": "2025-05-16T12:57:33+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.11200v1",
    "title": "Audio Turing Test: Benchmarking the Human-likeness of Large Language Model-based Text-to-Speech Systems in Chinese",
    "authors": [
      "Xihuai Wang",
      "Ziyi Zhao",
      "Siyu Ren",
      "Shao Zhang",
      "Song Li",
      "Xiaoyu Li",
      "Ziwen Wang",
      "Lin Qiu",
      "Guanglu Wan",
      "Xuezhi Cao",
      "Xunliang Cai",
      "Weinan Zhang"
    ],
    "abstract": "Recent advances in large language models (LLMs) have significantly improved\ntext-to-speech (TTS) systems, enhancing control over speech style, naturalness,\nand emotional expression, which brings TTS Systems closer to human-level\nperformance. Although the Mean Opinion Score (MOS) remains the standard for TTS\nSystem evaluation, it suffers from subjectivity, environmental inconsistencies,\nand limited interpretability. Existing evaluation datasets also lack a\nmulti-dimensional design, often neglecting factors such as speaking styles,\ncontext diversity, and trap utterances, which is particularly evident in\nChinese TTS evaluation. To address these challenges, we introduce the Audio\nTuring Test (ATT), a multi-dimensional Chinese corpus dataset ATT-Corpus paired\nwith a simple, Turing-Test-inspired evaluation protocol. Instead of relying on\ncomplex MOS scales or direct model comparisons, ATT asks evaluators to judge\nwhether a voice sounds human. This simplification reduces rating bias and\nimproves evaluation robustness. To further support rapid model development, we\nalso finetune Qwen2-Audio-Instruct with human judgment data as Auto-ATT for\nautomatic evaluation. Experimental results show that ATT effectively\ndifferentiates models across specific capability dimensions using its\nmulti-dimensional design. Auto-ATT also demonstrates strong alignment with\nhuman evaluations, confirming its value as a fast and reliable assessment tool.\nThe white-box ATT-Corpus and Auto-ATT can be found in ATT Hugging Face\nCollection\n(https://huggingface.co/collections/meituan/audio-turing-test-682446320368164faeaf38a4).",
    "pdf_url": "http://arxiv.org/pdf/2505.11200v1",
    "published": "2025-05-16T12:57:23+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.11199v1",
    "title": "NoPE: The Counting Power of Transformers with No Positional Encodings",
    "authors": [
      "Chris Köcher",
      "Alexander Kozachinskiy",
      "Anthony Widjaja Lin",
      "Marco Sälzer",
      "Georg Zetzsche"
    ],
    "abstract": "Positional Encodings (PEs) seem to be indispensable for ensuring\nexpressiveness of transformers; without them attention transformers reduce to a\nbag-of-word model. NoPE-transformers (i.e. with No PEs) with unique hard\nattention mechanisms were very recently shown to only be able to express\nregular languages, i.e., with limited counting ability. This paper shows that,\nwith average hard attention mechanisms, NoPE-transformers are still\nsurprisingly expressive: they can express counting languages corresponding to\nnonnegative integer solutions to multivariate polynomial equations (i.e.\nDiophantine equations), reasoning about which is well-known to be undecidable.\nIn fact, we provide a precise characterization of languages expressible by\nAverage Hard Attention NoPE-Transformers (NoPE-AHATs): they correspond\nprecisely to what we call \\emph{semi-algebraic sets}, i.e., finite unions of\nsets of nonnegative integer solutions to systems of multivariate polynomial\ninequations. We obtain several interesting consequences of our\ncharacterization. Firstly, NoPE-transformers can express counting properties\nthat are far more complex than established models like simplified counter\nmachines and Petri nets, but cannot express a very simple counting property of\nPARITY. Secondly, the problem of analyzing NoPE-transformers is undecidable,\ne.g., whether a given NoPE transformer classifies all input strings in one\nclass. To complement our results, we exhibit a counting language that is not\nexpressible by average hard attention transformers even with arbitrary PEs but\nis expressible in the circuit complexity class TC$^0$, answering an open\nproblem.",
    "pdf_url": "http://arxiv.org/pdf/2505.11199v1",
    "published": "2025-05-16T12:56:59+00:00",
    "categories": [
      "cs.CL",
      "cs.FL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11198v1",
    "title": "User-centric Music Recommendations",
    "authors": [
      "Jaime Ramirez Castillo",
      "M. Julia Flores",
      "Ann E. Nicholson"
    ],
    "abstract": "This work presents a user-centric recommendation framework, designed as a\npipeline with four distinct, connected, and customizable phases. These phases\nare intended to improve explainability and boost user engagement.\n  We have collected the historical Last.fm track playback records of a single\nuser over approximately 15 years. The collected dataset includes more than\n90,000 playbacks and approximately 14,000 unique tracks.\n  From track playback records, we have created a dataset of user temporal\ncontexts (each row is a specific moment when the user listened to certain music\ndescriptors). As music descriptors, we have used community-contributed Last.fm\ntags and Spotify audio features. They represent the music that, throughout\nyears, the user has been listening to.\n  Next, given the most relevant Last.fm tags of a moment (e.g. the hour of the\nday), we predict the Spotify audio features that best fit the user preferences\nin that particular moment. Finally, we use the predicted audio features to find\ntracks similar to these features. The final aim is to recommend (and discover)\ntracks that the user may feel like listening to at a particular moment.\n  For our initial study case, we have chosen to predict only a single audio\nfeature target: danceability. The framework, however, allows to include more\ntarget variables.\n  The ability to learn the musical habits from a single user can be quite\npowerful, and this framework could be extended to other users.",
    "pdf_url": "http://arxiv.org/pdf/2505.11198v1",
    "published": "2025-05-16T12:56:40+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11197v2",
    "title": "Modeling Cell Dynamics and Interactions with Unbalanced Mean Field Schrödinger Bridge",
    "authors": [
      "Zhenyi Zhang",
      "Zihan Wang",
      "Yuhao Sun",
      "Tiejun Li",
      "Peijie Zhou"
    ],
    "abstract": "Modeling the dynamics from sparsely time-resolved snapshot data is crucial\nfor understanding complex cellular processes and behavior. Existing methods\nleverage optimal transport, Schr\\\"odinger bridge theory, or their variants to\nsimultaneously infer stochastic, unbalanced dynamics from snapshot data.\nHowever, these approaches remain limited in their ability to account for\ncell-cell interactions. This integration is essential in real-world scenarios\nsince intercellular communications are fundamental life processes and can\ninfluence cell state-transition dynamics. To address this challenge, we\nformulate the Unbalanced Mean-Field Schr\\\"odinger Bridge (UMFSB) framework to\nmodel unbalanced stochastic interaction dynamics from snapshot data. Inspired\nby this framework, we further propose CytoBridge, a deep learning algorithm\ndesigned to approximate the UMFSB problem. By explicitly modeling cellular\ntransitions, proliferation, and interactions through neural networks,\nCytoBridge offers the flexibility to learn these processes directly from data.\nThe effectiveness of our method has been extensively validated using both\nsynthetic gene regulatory data and real scRNA-seq datasets. Compared to\nexisting methods, CytoBridge identifies growth, transition, and interaction\npatterns, eliminates false transitions, and reconstructs the developmental\nlandscape with greater accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.11197v2",
    "published": "2025-05-16T12:55:13+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11196v1",
    "title": "DiCo: Revitalizing ConvNets for Scalable and Efficient Diffusion Modeling",
    "authors": [
      "Yuang Ai",
      "Qihang Fan",
      "Xuefeng Hu",
      "Zhenheng Yang",
      "Ran He",
      "Huaibo Huang"
    ],
    "abstract": "Diffusion Transformer (DiT), a promising diffusion model for visual\ngeneration, demonstrates impressive performance but incurs significant\ncomputational overhead. Intriguingly, analysis of pre-trained DiT models\nreveals that global self-attention is often redundant, predominantly capturing\nlocal patterns-highlighting the potential for more efficient alternatives. In\nthis paper, we revisit convolution as an alternative building block for\nconstructing efficient and expressive diffusion models. However, naively\nreplacing self-attention with convolution typically results in degraded\nperformance. Our investigations attribute this performance gap to the higher\nchannel redundancy in ConvNets compared to Transformers. To resolve this, we\nintroduce a compact channel attention mechanism that promotes the activation of\nmore diverse channels, thereby enhancing feature diversity. This leads to\nDiffusion ConvNet (DiCo), a family of diffusion models built entirely from\nstandard ConvNet modules, offering strong generative performance with\nsignificant efficiency gains. On class-conditional ImageNet benchmarks, DiCo\noutperforms previous diffusion models in both image quality and generation\nspeed. Notably, DiCo-XL achieves an FID of 2.05 at 256x256 resolution and 2.53\nat 512x512, with a 2.7x and 3.1x speedup over DiT-XL/2, respectively.\nFurthermore, our largest model, DiCo-H, scaled to 1B parameters, reaches an FID\nof 1.90 on ImageNet 256x256-without any additional supervision during training.\nCode: https://github.com/shallowdream204/DiCo.",
    "pdf_url": "http://arxiv.org/pdf/2505.11196v1",
    "published": "2025-05-16T12:54:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11195v1",
    "title": "Decentralized Framework for Teleportation in Quantum Core Interconnects",
    "authors": [
      "Rajeswari Suance P S",
      "Ruchika Gupta",
      "Maurizio Palesi",
      "John Jose"
    ],
    "abstract": "Multi-core quantum computing architectures offer a promising and scalable\nsolution to the challenges of integrating large number of qubits into existing\nmonolithic chip design. However, the issue of transferring quantum information\nacross the cores remains unresolved. Quantum Teleportation offers a potential\napproach for efficient qubit transfer, but existing methods primarily rely on\ncentralized interconnection mechanisms for teleportation, which may limit\nscalability and parallel communication. We proposes a decentralized framework\nfor teleportation in multi-core quantum computing systems, aiming to address\nthese limitations. We introduce two variants of teleportation within the\ndecentralized framework and evaluate their impact on reducing end-to-end\ncommunication delay and quantum circuit depth. Our findings demonstrate that\nthe optimized teleportation strategy, termed two-way teleportation, results in\na substantial 40% reduction in end-to-end communication latency for synthetic\nbenchmarks and a 30% reduction for real benchmark applications, and 24%\ndecrease in circuit depth compared to the baseline teleportation strategy.\nThese results highlight the significant potential of decentralized\nteleportation to improve the performance of large-scale quantum systems,\noffering a scalable and efficient solution for future quantum architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.11195v1",
    "published": "2025-05-16T12:53:44+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11194v1",
    "title": "Prot2Text-V2: Protein Function Prediction with Multimodal Contrastive Alignment",
    "authors": [
      "Xiao Fei",
      "Michail Chatzianastasis",
      "Sarah Almeida Carneiro",
      "Hadi Abdine",
      "Lawrence P. Petalidis",
      "Michalis Vazirgiannis"
    ],
    "abstract": "Predicting protein function from sequence is a central challenge in\ncomputational biology. While existing methods rely heavily on structured\nontologies or similarity-based techniques, they often lack the flexibility to\nexpress structure-free functional descriptions and novel biological functions.\nIn this work, we introduce Prot2Text-V2, a novel multimodal sequence-to-text\nmodel that generates free-form natural language descriptions of protein\nfunction directly from amino acid sequences. Our method combines a protein\nlanguage model as a sequence encoder (ESM-3B) and a decoder-only language model\n(LLaMA-3.1-8B-Instruct) through a lightweight nonlinear modality projector. A\nkey innovation is our Hybrid Sequence-level Contrastive Alignment Learning\n(H-SCALE), which improves cross-modal learning by matching mean- and std-pooled\nprotein embeddings with text representations via contrastive loss. After the\nalignment phase, we apply instruction-based fine-tuning using LoRA on the\ndecoder to teach the model how to generate accurate protein function\ndescriptions conditioned on the protein sequence. We train Prot2Text-V2 on\nabout 250K curated entries from SwissProt and evaluate it under low-homology\nconditions, where test sequences have low similarity with training samples.\nProt2Text-V2 consistently outperforms traditional and LLM-based baselines\nacross various metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.11194v1",
    "published": "2025-05-16T12:53:21+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11193v2",
    "title": "Reducing Sensor Requirements by Relaxing the Network Metric Dimension",
    "authors": [
      "Paula Mürmann",
      "Robin Jaccard",
      "Maximilien Dreveton",
      "Aryan Alavi Razavi Ravari",
      "Patrick Thiran"
    ],
    "abstract": "Source localization in graphs involves identifying the origin of a phenomenon\nor event, such as an epidemic outbreak or a misinformation source, by\nleveraging structural graph properties. One key concept in this context is the\nmetric dimension, which quantifies the minimum number of strategically placed\nsensors needed to uniquely identify all vertices based on their distances.\nWhile powerful, the traditional metric dimension imposes a stringent\nrequirement that every vertex must be uniquely identified, often necessitating\na large number of sensors. In this work, we relax the metric dimension and\nallow vertices at a graph distance less than k to share identical distance\nprofiles relative to the sensors. This relaxation reduces the number of sensors\nneeded while maintaining sufficient resolution for practical applications like\nsource localization and network monitoring. We provide two main theoretical\ncontributions: an analysis of the k-relaxed metric dimension in deterministic\ntrees, revealing the interplay between structural properties and sensor\nplacement, and an extension to random trees generated by branching processes,\noffering insights into stochastic settings. We also conduct numerical\nexperiments across a variety of graph types, including random trees, random\ngeometric graphs, and real-world networks. The results show that the relaxed\nmetric dimension is significantly smaller than the traditional metric\ndimension. Furthermore, the number of vertices indistinguishable from any given\ntarget vertex always remains small. Finally, we propose and evaluate a two-step\nlocalization strategy that balances the trade-off between resolution and the\nnumber of sensors required. This strategy identifies an optimal relaxation\nlevel that minimizes the total number of sensors across both steps, providing a\npractical and efficient approach to source localization.",
    "pdf_url": "http://arxiv.org/pdf/2505.11193v2",
    "published": "2025-05-16T12:51:42+00:00",
    "categories": [
      "cs.DM"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2505.11192v3",
    "title": "FALCON: False-Negative Aware Learning of Contrastive Negatives in Vision-Language Pretraining",
    "authors": [
      "Myunsoo Kim",
      "Seong-Woong Shim",
      "Byung-Jun Lee"
    ],
    "abstract": "False negatives pose a critical challenge in vision-language pretraining\n(VLP) due to the many-to-many correspondence between images and texts in\nlarge-scale datasets. These false negatives introduce conflicting supervision\nsignals that degrade the learned embedding space and diminish the effectiveness\nof hard negative sampling. In this paper, we propose FALCON (False-negative\nAware Learning of COntrastive Negatives), a learning-based mini-batch\nconstruction strategy that adaptively balances the trade-off between hard and\nfalse negatives during VLP. Rather than relying on fixed heuristics, FALCON\nemploys a negative mining scheduler that dynamically selects negative samples\nof appropriate hardness for each anchor instance during mini-batch\nconstruction, guided by a proxy for cross-modal alignment improvement.\nExperimental results demonstrate that FALCON significantly improves performance\nacross two widely adopted VLP frameworks (ALBEF, BLIP-2) and a broad range of\ndownstream tasks and evaluation settings, underscoring its effectiveness and\nrobustness in mitigating the impact of false negatives.",
    "pdf_url": "http://arxiv.org/pdf/2505.11192v3",
    "published": "2025-05-16T12:50:05+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11191v2",
    "title": "Multi-Modal Multi-Task (M3T) Federated Foundation Models for Embodied AI: Potentials and Challenges for Edge Integration",
    "authors": [
      "Kasra Borazjani",
      "Payam Abdisarabshali",
      "Fardis Nadimi",
      "Naji Khosravan",
      "Minghui Liwang",
      "Xianbin Wang",
      "Yiguang Hong",
      "Seyyedali Hosseinalipour"
    ],
    "abstract": "As embodied AI systems become increasingly multi-modal, personalized, and\ninteractive, they must learn effectively from diverse sensory inputs, adapt\ncontinually to user preferences, and operate safely under resource and privacy\nconstraints. These challenges expose a pressing need for machine learning\nmodels capable of swift, context-aware adaptation while balancing model\ngeneralization and personalization. Here, two methods emerge as suitable\ncandidates, each offering parts of these capabilities: multi-modal multi-task\nfoundation models (M3T-FMs) provide a pathway toward generalization across\ntasks and modalities, whereas federated learning (FL) offers the infrastructure\nfor distributed, privacy-preserving model updates and user-level model\npersonalization. However, when used in isolation, each of these approaches\nfalls short of meeting the complex and diverse capability requirements of\nreal-world embodied AI environments. In this vision paper, we introduce\nmulti-modal multi-task federated foundation models (M3T-FFMs) for embodied AI,\na new paradigm that unifies the strengths of M3T-FMs with the\nprivacy-preserving distributed training nature of FL, enabling intelligent\nsystems at the wireless edge. We collect critical deployment dimensions of\nM3T-FFMs in embodied AI ecosystems under a unified framework, which we name\n\"EMBODY\": Embodiment heterogeneity, Modality richness and imbalance, Bandwidth\nand compute constraints, On-device continual learning, Distributed control and\nautonomy, and Yielding safety, privacy, and personalization. For each, we\nidentify concrete challenges and envision actionable research directions. We\nalso present an evaluation framework for deploying M3T-FFMs in embodied AI\nsystems, along with the associated trade-offs. Finally, we present a prototype\nimplementation of M3T-FFMs and evaluate their energy and latency performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.11191v2",
    "published": "2025-05-16T12:49:36+00:00",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11190v1",
    "title": "JaxSGMC: Modular stochastic gradient MCMC in JAX",
    "authors": [
      "Stephan Thaler",
      "Paul Fuchs",
      "Ana Cukarska",
      "Julija Zavadlav"
    ],
    "abstract": "We present JaxSGMC, an application-agnostic library for stochastic gradient\nMarkov chain Monte Carlo (SG-MCMC) in JAX. SG-MCMC schemes are uncertainty\nquantification (UQ) methods that scale to large datasets and high-dimensional\nmodels, enabling trustworthy neural network predictions via Bayesian deep\nlearning. JaxSGMC implements several state-of-the-art SG-MCMC samplers to\npromote UQ in deep learning by reducing the barriers of entry for switching\nfrom stochastic optimization to SG-MCMC sampling. Additionally, JaxSGMC allows\nusers to build custom samplers from standard SG-MCMC building blocks. Due to\nthis modular structure, we anticipate that JaxSGMC will accelerate research\ninto novel SG-MCMC schemes and facilitate their application across a broad\nrange of domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.11190v1",
    "published": "2025-05-16T12:49:21+00:00",
    "categories": [
      "stat.CO",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11189v1",
    "title": "Can Global XAI Methods Reveal Injected Bias in LLMs? SHAP vs Rule Extraction vs RuleSHAP",
    "authors": [
      "Francesco Sovrano"
    ],
    "abstract": "Generative AI systems can help spread information but also misinformation and\nbiases, potentially undermining the UN Sustainable Development Goals (SDGs).\nExplainable AI (XAI) aims to reveal the inner workings of AI systems and expose\nmisbehaviours or biases. However, current XAI tools, built for simpler models,\nstruggle to handle the non-numerical nature of large language models (LLMs).\nThis paper examines the effectiveness of global XAI methods, such as\nrule-extraction algorithms and SHAP, in detecting bias in LLMs. To do so, we\nfirst show a text-to-ordinal mapping strategy to convert non-numerical\ninputs/outputs into numerical features, enabling these tools to identify (some)\nmisinformation-related biases in LLM-generated content. Then, we inject\nnon-linear biases of varying complexity (univariate, conjunctive, and\nnon-convex) into widespread LLMs like ChatGPT and Llama via system\ninstructions, using global XAI methods to detect them. This way, we found that\nRuleFit struggles with conjunctive and non-convex biases, while SHAP can\napproximate conjunctive biases but cannot express them as actionable rules.\nHence, we introduce RuleSHAP, a global rule extraction algorithm combining SHAP\nand RuleFit to detect more non-univariate biases, improving injected bias\ndetection over RuleFit by +94% (MRR@1) on average.",
    "pdf_url": "http://arxiv.org/pdf/2505.11189v1",
    "published": "2025-05-16T12:48:44+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11188v1",
    "title": "Chemically active droplets in crowded environments",
    "authors": [
      "Jacques Fries",
      "Roxanne Berthin",
      "Chengjie Luo",
      "Marie Jardat",
      "David Zwicker",
      "Vincent Dahirel",
      "Pierre Illien"
    ],
    "abstract": "Biomolecular condensates are essential for cellular organization and result\nfrom phase separation in systems far from thermodynamic equilibrium. Among\nvarious models, chemically active droplets play a significant role, consisting\nof proteins that switch between attractive and repulsive states via\nnonequilibrium chemical reactions. While field-based simulations have provided\ninsights into their behavior, these coarse-grained approaches fail to capture\nmolecular-scale effects, particularly in crowded cellular environments.\nMacromolecular crowding, a key feature of intracellular organization, strongly\ninfluences molecular transport within condensates, yet its quantitative impact\nremains underexplored. This study investigates the interplay between chemically\nactive droplets and crowders by using particle-based models, that provide\nmolecular insight, and a field-based model, that complements this picture.\nSurprisingly, crowding reduces droplet size while expanding the overall dense\nphase volume, challenging equilibrium-based expectations. This effect arises\nfrom the interplay between depletion interactions, diffusion hindrance, and\nnonequilibrium particle fluxes. Our findings provide a step towards a more\ncomprehensive understanding of chemically active droplets in complex, realistic\ncellular environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.11188v1",
    "published": "2025-05-16T12:45:54+00:00",
    "categories": [
      "cond-mat.soft",
      "physics.bio-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.11187v1",
    "title": "PRIMAGAL: a PRIMAger Galactic Plane Far-IR polarization survey to quantify the magnetic fields' role in the formation and evolution of large star-forming filaments",
    "authors": [
      "S. Molinari",
      "J. D. Soler",
      "V. -M. Pelkonen",
      "A. Nucara",
      "E. Schisano",
      "A. Traficante",
      "C. Mininni",
      "M. Benedettini",
      "A. Coletta",
      "D. Elia",
      "S. Pezzuto"
    ],
    "abstract": "The PRIMAger instrument on board the proposed PRIMA satellite will offer the\nunprecedented capability to obtain hundreds of square-degree maps in polarised\nemission at sub-arcminute resolution in four Far-IR bands. This will open a\nunique window to study magnetic fields in our Galaxy. PRIMAGAL, a proposed\nsurvey of polarized dust emission in the Milky Way Galactic Plane will\ndetermine the strength and orientation of magnetic fields towards several\nthousands of filamentary clouds in a wide range of linear masses, column\ndensities, evolution, star-formation rates and efficiencies, and Galactic\nenvironment. This survey will address for the first time in a statistically\nsignificant fashion the role that magnetic fields play in shaping the\nformation, evolution and fragmentation of dense ISM filaments down to a minimum\nscale of 0.4 pc up to 8 kpc distance from the Sun. A 4-band polarization survey\nof the Galactic Plane with |b|<1{\\deg} (a total of 720 sq. deg.) can be\nexecuted by PRIMAger in about 1200 hours including all mapping and instrument\noverhead.",
    "pdf_url": "http://arxiv.org/pdf/2505.11187v1",
    "published": "2025-05-16T12:45:53+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11186v1",
    "title": "On the Magnetic Reconnection and its Properties during a Flare Using a Magnetohydrodynamics Simulation",
    "authors": [
      "Sushree S Nayak",
      "Qiang Hu",
      "Wen He",
      "Sanjay Kumar",
      "Ramit Bhattacharyya"
    ],
    "abstract": "We study the magnetic reconnection during a flare by investigating flare\nribbon dynamics using observations and data-constrained magnetohydrodynamics\n(MHD) simulation. In particular, we estimate the reconnection flux and the\nreconnection flux rates using flare ribbons of an M1.1 flare hosted by the\nactive region 12184 utilizing the technique developed by Qiu et al. (2002, ApJ,\n565, 1335). The reconnection flux and corresponding flux rates are found to be\n10^20 Mx and 10^18 Mx/s respectively. To understand the flare onset and the\norigin of flare ribbons, we perform an MHD simulation initiated by the\nnon-force-free-field extrapolation. Importantly, the extrapolated configuration\nidentifies a three-dimensional (3D) magnetic neutral point and a flux rope in\nthe flaring region, which is crucial to the flaring activity. The reconnection\ninitiates at the null point and, subsequently the flux rope rises and appears\nto reconnect there, which is favorable for the eruption of the filament. The\nsurrounding field lines also seem to take part in the null point reconnection.\nIn later stage, a current sheet is formed below the null point ensuing a\nsecondary reconnection near an X-type topology, further contributing to the\nenergy release process in the flare. We trace the footpoint evolution of the\nfield lines lying over the flare ribbons and find a significant similarity\nbetween the observed flare ribbons and the evolution of footpoints computed\nfrom the MHD simulation. We estimated induced electric field during the flare\nand found it to be $\\approx$ .52 V/cm, a slight less value, as per many past\nliteratures. Additional findings are the enhancement of vertical current\ndensity near the flaring ribbons, a signature of successive reconnections near\nthe null point. Overall, the present work contributes to the understanding of\nthe ribbon formation in a flaring process and the involved magnetic\nreconnection.",
    "pdf_url": "http://arxiv.org/pdf/2505.11186v1",
    "published": "2025-05-16T12:45:15+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11185v1",
    "title": "VitaGraph: Building a Knowledge Graph for Biologically Relevant Learning Tasks",
    "authors": [
      "Francesco Madeddu",
      "Lucia Testa",
      "Gianluca De Carlo",
      "Michele Pieroni",
      "Andrea Mastropietro",
      "Aris Anagnostopoulos",
      "Paolo Tieri",
      "Sergio Barbarossa"
    ],
    "abstract": "The intrinsic complexity of human biology presents ongoing challenges to\nscientific understanding. Researchers collaborate across disciplines to expand\nour knowledge of the biological interactions that define human life. AI\nmethodologies have emerged as powerful tools across scientific domains,\nparticularly in computational biology, where graph data structures effectively\nmodel biological entities such as protein-protein interaction (PPI) networks\nand gene functional networks. Those networks are used as datasets for paramount\nnetwork medicine tasks, such as gene-disease association prediction, drug\nrepurposing, and polypharmacy side effect studies. Reliable predictions from\nmachine learning models require high-quality foundational data. In this work,\nwe present a comprehensive multi-purpose biological knowledge graph constructed\nby integrating and refining multiple publicly available datasets. Building upon\nthe Drug Repurposing Knowledge Graph (DRKG), we define a pipeline tasked with\na) cleaning inconsistencies and redundancies present in DRKG, b) coalescing\ninformation from the main available public data sources, and c) enriching the\ngraph nodes with expressive feature vectors such as molecular fingerprints and\ngene ontologies. Biologically and chemically relevant features improve the\ncapacity of machine learning models to generate accurate and well-structured\nembedding spaces. The resulting resource represents a coherent and reliable\nbiological knowledge graph that serves as a state-of-the-art platform to\nadvance research in computational biology and precision medicine. Moreover, it\noffers the opportunity to benchmark graph-based machine learning and network\nmedicine models on relevant tasks. We demonstrate the effectiveness of the\nproposed dataset by benchmarking it against the task of drug repurposing, PPI\nprediction, and side-effect prediction, modeled as link prediction problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11185v1",
    "published": "2025-05-16T12:43:04+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11184v1",
    "title": "A Framework of Model Reduction with Arbitrary Orders of Accuracy for the Boltzmann Equation",
    "authors": [
      "Zhenning Cai",
      "Ruo Li",
      "Yixiao Lu",
      "Yanli Wang"
    ],
    "abstract": "This paper presents a general framework for constructing reduced models that\napproximate the Boltzmann equation with arbitrary orders of accuracy in terms\nof the Knudsen number $\\mathit{Kn}$, applicable to general collision models in\nrarefied gas dynamics. The framework is based on an orthogonal decomposition of\nthe distribution function into components of different orders in $\\mathit{Kn}$,\nfrom which the reduced models are systematically derived through asymptotic\nanalysis. Compared to the Chapman-Enskog expansion, our approach yields more\ntractable model structures. Notably, we establish that a reduced model\nretaining all terms up to $O(\\mathit{Kn}^n)$ in the expansion surprisingly\nyields models with order of accuracy $O(\\mathit{Kn}^{n+1})$. Furthermore, when\nthe collision term is linearized, the accuracy improves dramatically to\n$O(\\mathit{Kn}^{2n})$. These results extend to regularized models containing\nsecond-order derivatives. As concrete applications, we explicitly derive\n13-moment systems of Burnett and super-Burnett orders valid for arbitrary\ncollision models.",
    "pdf_url": "http://arxiv.org/pdf/2505.11184v1",
    "published": "2025-05-16T12:40:15+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11183v1",
    "title": "On Next-Token Prediction in LLMs: How End Goals Determine the Consistency of Decoding Algorithms",
    "authors": [
      "Jacob Trauger",
      "Ambuj Tewari"
    ],
    "abstract": "Probabilistic next-token prediction trained using cross-entropy loss is the\nbasis of most large language models. Given a sequence of previous values,\nnext-token prediction assigns a probability to each possible next value in the\nvocabulary. There are many ways to use next-token prediction to output token\nsequences. This paper examines a few of these algorithms (greedy, lookahead,\nrandom sampling, and temperature-scaled random sampling) and studies their\nconsistency with respect to various goals encoded as loss functions. Although\nconsistency of surrogate losses with respect to a target loss function is a\nwell researched topic, we are the first to study it in the context of LLMs (to\nthe best of our knowledge). We find that, so long as next-token prediction\nconverges to its true probability distribution, random sampling is consistent\nwith outputting sequences that mimic sampling from the true probability\ndistribution. For the other goals, such as minimizing the 0-1 loss on the\nentire sequence, we show no polynomial-time algorithm is optimal for all\nprobability distributions and all decoding algorithms studied are only optimal\nfor a subset of probability distributions. When analyzing these results, we see\nthat there is a dichotomy created between the goals of information retrieval\nand creative generation for the decoding algorithms. This shows that choosing\nthe correct decoding algorithm based on the desired goal is extremely important\nand many of the ones used are lacking theoretical grounding in numerous\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.11183v1",
    "published": "2025-05-16T12:38:45+00:00",
    "categories": [
      "stat.ML",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.11182v1",
    "title": "Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning",
    "authors": [
      "Yuzhuo Dai",
      "Jiaqi Jin",
      "Zhibin Dong",
      "Siwei Wang",
      "Xinwang Liu",
      "En Zhu",
      "Xihong Yang",
      "Xinbiao Gan",
      "Yu Feng"
    ],
    "abstract": "In incomplete multi-view clustering (IMVC), missing data induce prototype\nshifts within views and semantic inconsistencies across views. A feasible\nsolution is to explore cross-view consistency in paired complete observations,\nfurther imputing and aligning the similarity relationships inherently shared\nacross views. Nevertheless, existing methods are constrained by two-tiered\nlimitations: (1) Neither instance- nor cluster-level consistency learning\nconstruct a semantic space shared across views to learn consensus semantics.\nThe former enforces cross-view instances alignment, and wrongly regards\nunpaired observations with semantic consistency as negative pairs; the latter\nfocuses on cross-view cluster counterparts while coarsely handling fine-grained\nintra-cluster relationships within views. (2) Excessive reliance on consistency\nresults in unreliable imputation and alignment without incorporating\nview-specific cluster information. Thus, we propose an IMVC framework,\nimputation- and alignment-free for consensus semantics learning (FreeCSL). To\nbridge semantic gaps across all observations, we learn consensus prototypes\nfrom available data to discover a shared space, where semantically similar\nobservations are pulled closer for consensus semantics learning. To capture\nsemantic relationships within specific views, we design a heuristic graph\nclustering based on modularity to recover cluster structure with intra-cluster\ncompactness and inter-cluster separation for cluster semantics enhancement.\nExtensive experiments demonstrate, compared to state-of-the-art competitors,\nFreeCSL achieves more confident and robust assignments on IMVC task.",
    "pdf_url": "http://arxiv.org/pdf/2505.11182v1",
    "published": "2025-05-16T12:37:10+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11181v1",
    "title": "Feasibility with Language Models for Open-World Compositional Zero-Shot Learning",
    "authors": [
      "Jae Myung Kim",
      "Stephan Alaniz",
      "Cordelia Schmid",
      "Zeynep Akata"
    ],
    "abstract": "Humans can easily tell if an attribute (also called state) is realistic,\ni.e., feasible, for an object, e.g. fire can be hot, but it cannot be wet. In\nOpen-World Compositional Zero-Shot Learning, when all possible state-object\ncombinations are considered as unseen classes, zero-shot predictors tend to\nperform poorly. Our work focuses on using external auxiliary knowledge to\ndetermine the feasibility of state-object combinations. Our Feasibility with\nLanguage Model (FLM) is a simple and effective approach that leverages Large\nLanguage Models (LLMs) to better comprehend the semantic relationships between\nstates and objects. FLM involves querying an LLM about the feasibility of a\ngiven pair and retrieving the output logit for the positive answer. To mitigate\npotential misguidance of the LLM given that many of the state-object\ncompositions are rare or completely infeasible, we observe that the in-context\nlearning ability of LLMs is essential. We present an extensive study\nidentifying Vicuna and ChatGPT as best performing, and we demonstrate that our\nFLM consistently improves OW-CZSL performance across all three benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11181v1",
    "published": "2025-05-16T12:37:08+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11180v1",
    "title": "mmRAG: A Modular Benchmark for Retrieval-Augmented Generation over Text, Tables, and Knowledge Graphs",
    "authors": [
      "Chuan Xu",
      "Qiaosheng Chen",
      "Yutong Feng",
      "Gong Cheng"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for\nenhancing the capabilities of large language models. However, existing RAG\nevaluation predominantly focuses on text retrieval and relies on opaque,\nend-to-end assessments of generated outputs. To address these limitations, we\nintroduce mmRAG, a modular benchmark designed for evaluating multi-modal RAG\nsystems. Our benchmark integrates queries from six diverse question-answering\ndatasets spanning text, tables, and knowledge graphs, which we uniformly\nconvert into retrievable documents. To enable direct, granular evaluation of\nindividual RAG components -- such as the accuracy of retrieval and query\nrouting -- beyond end-to-end generation quality, we follow standard information\nretrieval procedures to annotate document relevance and derive dataset\nrelevance. We establish baseline performance by evaluating a wide range of RAG\nimplementations on mmRAG.",
    "pdf_url": "http://arxiv.org/pdf/2505.11180v1",
    "published": "2025-05-16T12:31:29+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.13507v1",
    "title": "Open Set Domain Adaptation with Vision-language models via Gradient-aware Separation",
    "authors": [
      "Haoyang Chen"
    ],
    "abstract": "Open-Set Domain Adaptation (OSDA) confronts the dual challenge of aligning\nknown-class distributions across domains while identifying\ntarget-domain-specific unknown categories. Current approaches often fail to\nleverage semantic relationships between modalities and struggle with error\naccumulation in unknown sample detection. We propose to harness Contrastive\nLanguage-Image Pretraining (CLIP) to address these limitations through two key\ninnovations: 1) Prompt-driven cross-domain alignment: Learnable textual prompts\nconditioned on domain discrepancy metrics dynamically adapt CLIP's text\nencoder, enabling semantic consistency between source and target domains\nwithout explicit unknown-class supervision. 2) Gradient-aware open-set\nseparation: A gradient analysis module quantifies domain shift by comparing the\nL2-norm of gradients from the learned prompts, where known/unknown samples\nexhibit statistically distinct gradient behaviors. Evaluations on Office-Home\nshow that our method consistently outperforms CLIP baseline and standard\nbaseline. Ablation studies confirm the gradient norm's critical role.",
    "pdf_url": "http://arxiv.org/pdf/2505.13507v1",
    "published": "2025-05-16T12:31:17+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11179v1",
    "title": "On physically grounded boundary conditions for the compressible MHD system",
    "authors": [
      "Jan Brezina",
      "Eduard Feireisl"
    ],
    "abstract": "We consider a general compressible MHD system, where the magnetic field\npropagates in a heterogeneous medium. Using suitable penalization in terms of\nthe transport coefficients we perform several singular limits. As a result we\nobtain:\n  1. A rigorous justification of physically grounded boundary conditions for\nthe compressible MHD system on a bounded domain.\n  2. Existence of weak solutions for arbitrary finite energy initial data in\nthe situation the Maxwell induction equation holds also outside the fluid\ndomain.\n  3. A suitable theoretical platform for numerical experiments on domains with\ngeometrically complicated boundaries.",
    "pdf_url": "http://arxiv.org/pdf/2505.11179v1",
    "published": "2025-05-16T12:25:52+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11178v1",
    "title": "CompAlign: Improving Compositional Text-to-Image Generation with a Complex Benchmark and Fine-Grained Feedback",
    "authors": [
      "Yixin Wan",
      "Kai-Wei Chang"
    ],
    "abstract": "State-of-the-art T2I models are capable of generating high-resolution images\ngiven textual prompts. However, they still struggle with accurately depicting\ncompositional scenes that specify multiple objects, attributes, and spatial\nrelations. We present CompAlign, a challenging benchmark with an emphasis on\nassessing the depiction of 3D-spatial relationships, for evaluating and\nimproving models on compositional image generation. CompAlign consists of 900\ncomplex multi-subject image generation prompts that combine numerical and\n3D-spatial relationships with varied attribute bindings. Our benchmark is\nremarkably challenging, incorporating generation tasks with 3+ generation\nsubjects with complex 3D-spatial relationships. Additionally, we propose\nCompQuest, an interpretable and accurate evaluation framework that decomposes\ncomplex prompts into atomic sub-questions, then utilizes a MLLM to provide\nfine-grained binary feedback on the correctness of each aspect of generation\nelements in model-generated images. This enables precise quantification of\nalignment between generated images and compositional prompts. Furthermore, we\npropose an alignment framework that uses CompQuest's feedback as preference\nsignals to improve diffusion models' compositional image generation abilities.\nUsing adjustable per-image preferences, our method is easily scalable and\nflexible for different tasks. Evaluation of 9 T2I models reveals that: (1)\nmodels remarkable struggle more with compositional tasks with more complex\n3D-spatial configurations, and (2) a noticeable performance gap exists between\nopen-source accessible models and closed-source commercial models. Further\nempirical study on using CompAlign for model alignment yield promising results:\npost-alignment diffusion models achieve remarkable improvements in\ncompositional accuracy, especially on complex generation tasks, outperforming\nprevious approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.11178v1",
    "published": "2025-05-16T12:23:58+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.14706v2",
    "title": "Particle identification in the GlueX detector with machine learning",
    "authors": [
      "Eric Habjan",
      "Richard Dube",
      "James McIntyre",
      "Mezmur Edo",
      "Richard Jones"
    ],
    "abstract": "In particle physics experiments, identifying the types of particles\nregistered in a detector is essential for the accurate reconstruction of\nparticle collisions. At Thomas Jefferson National Accelerator Facility\n(Jefferson Lab), the GlueX experiment performs particle identification (PID) by\nsetting specific thresholds, known as cuts, on the kinematic properties of\ntracks and showers obtained from detector hits. Our research aims to enhance\nthis cut-based method by employing machine-learning algorithms based on\nmulti-layer perceptrons and boosted decision trees. Similar approaches have\nbeen applied in other particle physics experiments and offer an opportunity to\nincrease PID accuracies using reconstructed kinematic data. Our study\nillustrates that both MLPs and BDTs can identify charged and neutral particles\nin Monte Carlo (MC) simulated GlueX data with significantly improved accuracy\nover the current cuts-based PID method.",
    "pdf_url": "http://arxiv.org/pdf/2505.14706v2",
    "published": "2025-05-16T12:23:47+00:00",
    "categories": [
      "physics.ins-det",
      "hep-ex",
      "nucl-ex",
      "physics.data-an"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.11177v1",
    "title": "Low-Resource Language Processing: An OCR-Driven Summarization and Translation Pipeline",
    "authors": [
      "Hrishit Madhavi",
      "Jacob Cherian",
      "Yuvraj Khamkar",
      "Dhananjay Bhagat"
    ],
    "abstract": "This paper presents an end-to-end suite for multilingual information\nextraction and processing from image-based documents. The system uses Optical\nCharacter Recognition (Tesseract) to extract text in languages such as English,\nHindi, and Tamil, and then a pipeline involving large language model APIs\n(Gemini) for cross-lingual translation, abstractive summarization, and\nre-translation into a target language. Additional modules add sentiment\nanalysis (TensorFlow), topic classification (Transformers), and date extraction\n(Regex) for better document comprehension. Made available in an accessible\nGradio interface, the current research shows a real-world application of\nlibraries, models, and APIs to close the language gap and enhance access to\ninformation in image media across different linguistic environments",
    "pdf_url": "http://arxiv.org/pdf/2505.11177v1",
    "published": "2025-05-16T12:20:37+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50 (Natural language processing), 68U10 (Image processing)"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11176v2",
    "title": "Enhancing and Scaling Search Query Datasets for Recommendation Systems",
    "authors": [
      "Aaron Rodrigues",
      "Mahmood Hegazy",
      "Azzam Naeem"
    ],
    "abstract": "This paper presents a deployed, production-grade system designed to enhance\nand scale search query datasets for intent-based recommendation systems in\ndigital banking. In real-world environments, the growing volume and complexity\nof user intents create substantial challenges for data management, resulting in\nsuboptimal recommendations and delayed product onboarding. To overcome these\nchallenges, our approach shifts the focus from model-centric enhancements to\nautomated, data-centric strategies. The proposed system integrates three core\nmodules: Synthetic Query Generation, Intent Disambiguation, and Intent Gap\nAnalysis. Synthetic Query Generation produces diverse and realistic user\nqueries. Our experiments reveal no statistically significant difference when\nusing synthetic data for Clinc150, while Banking77 and a proprietary dataset\nshow significant differences. We dig into the underlying factors driving these\nvariations, demonstrating that our approach effectively alleviates the cold\nstart problem (i.e. the challenge of recommending new products with limited\nhistorical data). Intent Disambiguation refines broad and overlapping intent\ncategories into precise subintents, achieving an F1 score of 0.863 $\\pm$ 0.127\nagainst expert reannotations and leading to clearer differentiation and more\nprecise recommendation mapping. Meanwhile, Intent Gap Analysis identifies\nlatent customer needs by extracting novel intents from unlabeled queries;\nrecovery rates reach up to 71\\% in controlled evaluations. Deployed in a live\nbanking environment, our system demonstrates significant improvements in\nrecommendation precision and operation agility, ultimately delivering enhanced\nuser experiences and strategic business benefits. This work underscores the\nrole of high-quality, scalable data in modern AI-driven applications and\nadvocates a proactive approach to data enhancement as a key driver of value.",
    "pdf_url": "http://arxiv.org/pdf/2505.11176v2",
    "published": "2025-05-16T12:20:31+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11175v2",
    "title": "Real-Time Verification of Embodied Reasoning for Generative Skill Acquisition",
    "authors": [
      "Bo Yue",
      "Shuqi Guo",
      "Kaiyu Hu",
      "Chujiao Wang",
      "Benyou Wang",
      "Kui Jia",
      "Guiliang Liu"
    ],
    "abstract": "Generative skill acquisition enables embodied agents to actively learn a\nscalable and evolving repertoire of control skills, crucial for the advancement\nof large decision models. While prior approaches often rely on supervision\nsignals from generalist agents (e.g., LLMs), their effectiveness in complex 3D\nenvironments remains unclear; exhaustive evaluation incurs substantial\ncomputational costs, significantly hindering the efficiency of skill learning.\nInspired by recent successes in verification models for mathematical reasoning,\nwe propose VERGSA (Verifying Embodied Reasoning in Generative Skill\nAcquisition), a framework that systematically integrates real-time verification\nprinciples into embodied skill learning. VERGSA establishes 1) a seamless\nextension from verification of mathematical reasoning into embodied learning by\ndynamically incorporating contextually relevant tasks into prompts and defining\nsuccess metrics for both subtasks and overall tasks, and 2) an automated,\nscalable reward labeling scheme that synthesizes dense reward signals by\niteratively finalizing the contribution of scene configuration and subtask\nlearning to overall skill acquisition. To the best of our knowledge, this\napproach constitutes the first comprehensive training dataset for\nverification-driven generative skill acquisition, eliminating arduous manual\nreward engineering. Experiments validate the efficacy of our approach: 1) the\nexemplar task pool improves the average task success rates by 21%, 2) our\nverification model boosts success rates by 24% for novel tasks and 36% for\nencountered tasks, and 3) outperforms LLM-as-a-Judge baselines in verification\nquality.",
    "pdf_url": "http://arxiv.org/pdf/2505.11175v2",
    "published": "2025-05-16T12:19:13+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11174v2",
    "title": "Electric-Magnetic Duality for Symmetric Tensor Gauge Theories and Immobile $p$-branes",
    "authors": [
      "Ryuki Makino",
      "Shin Sasaki",
      "Kenta Shiozawa"
    ],
    "abstract": "We study electric-magnetic duality in Lorentz invariant symmetric tensor\ngauge theories, where immobile charged particles - fractons - arise due to the\ngeneralized current conservation $\\partial_{\\mu} \\partial_{\\nu} J^{\\mu \\nu} =\n0$ and the fracton gauge principle. We show that the duality in the symmetric\ngauge theories holds only in four-dimensional spacetime. In higher dimensions,\nthe duality does not hold with only the symmetric gauge fields but tensor\nfields with more complex symmetries come into play. Furthermore, we show that a\nhierarchy for the symmetric gauge field theories of higher ranks is interpreted\nby the bi-form calculus. We also discuss the restricted immobility of\n$p$-branes in the mixed symmetric gauge theories. As a byproduct, we find that\nnovel self-duality conditions are defined as BPS equations in the\nfour-dimensional Euclidean space.",
    "pdf_url": "http://arxiv.org/pdf/2505.11174v2",
    "published": "2025-05-16T12:18:13+00:00",
    "categories": [
      "hep-th",
      "cond-mat.str-el"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11173v1",
    "title": "MmWave-LoRadar Empowered Vehicular Integrated Sensing and Communication Systems: LoRa Meets FMCW",
    "authors": [
      "Yi Tao",
      "Ziwei Wan",
      "Zhuoran Li",
      "Zhen Gao",
      "Gaojie Chen",
      "Rui Na"
    ],
    "abstract": "The integrated sensing and communication (ISAC) technique is regarded as a\nkey component in future vehicular applications. In this paper, we propose an\nISAC solution that integrates Long Range (LoRa) modulation with\nfrequency-modulated continuous wave (FMCW) radar in the millimeter-wave\n(mmWave) band, called mmWave-LoRadar. This design introduces the sensing\ncapabilities to the LoRa communication with a simplified hardware architecture.\nParticularly, we uncover the dual discontinuity issues in time and phase of the\nmmWave-LoRadar received signals, rendering conventional signal processing\ntechniques ineffective. As a remedy, we propose a corresponding hardware design\nand signal processing schemes under the compressed sampling framework. These\ntechniques effectively cope with the dual discontinuity issues and mitigate the\ndemands for high-sampling-rate analog-to-digital converters while achieving\ngood performance. Simulation results demonstrate the superiority of the\nmmWave-LoRadar ISAC system in vehicular communication and sensing networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11173v1",
    "published": "2025-05-16T12:17:48+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11172v4",
    "title": "On the holomorphic foliations admitting a common invariant algebraic set",
    "authors": [
      "Guangfeng Dong",
      "Chujun Lu"
    ],
    "abstract": "In this paper, we study the holomorphic foliations admitting a common\ninvariant algebraic set $C$ defined by a polynomial $f$ in $\n\\mathbb{K}[x_1,x_2,...,x_n]$ over any characteristic $0$ subfield\n$\\mathbb{K}\\subseteq\\mathbb{C}$. For the $\\mathbb{K}[x_1,x_2,...,x_n]$-module\n$V_f$ of vector fields generating foliations that admit $C$ as an invariant\nset, we provide several conditions under which the module $V_f$ can be freely\ngenerated by a minimal generating set. In particular, when $n=2$ and $f$ is a\nweakly tame polynomial, we show that the $\\mathbb{K}[x,y]$-module $V_f$ is\nfreely generated by two polynomial vector fields, one of which is the\nHamiltonian vector field induced by $f$, if and only if, $f$ belongs to the\nJacobian ideal $\\langle f_x, f_y\\rangle$ in $\\mathbb{K}[x,y]$. Our proof\nemploys a purely elementary method.",
    "pdf_url": "http://arxiv.org/pdf/2505.11172v4",
    "published": "2025-05-16T12:16:03+00:00",
    "categories": [
      "math.DS",
      "Primary: 37F75, Secondary: 32M25,"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.11171v1",
    "title": "Development of an achromatic spectrometer for a laser-wakefield-accelerator experiment",
    "authors": [
      "F. Peña",
      "E. Adli",
      "P. Drobniak",
      "D. Kalvik",
      "K. N. Sjobak",
      "C. A. Lindstrøm"
    ],
    "abstract": "The large gradients of plasma-wakefield accelerators promise to shorten\naccelerators and reduce their financial and environmental costs. For such\naccelerators, a key challenge is the transport of beams with high divergence\nand energy spread. Achromatic optics is a potential solution that would allow\nstaging of plasma accelerators without beam-quality degradation. For this, a\nnonlinear plasma lens is being developed within the SPARTA project. As a first\napplication of this lens, we aim to implement an achromatic spectrometer for\nelectron bunches produced by a laser-wakefield accelerator. This will greatly\nimprove the resolution across the typically one to tens of percent energy\nspread bunches and therefore help diagnosis and optimization of the plasma\ninteraction. We report on progress in designing such an experiment.",
    "pdf_url": "http://arxiv.org/pdf/2505.11171v1",
    "published": "2025-05-16T12:15:55+00:00",
    "categories": [
      "physics.acc-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11170v1",
    "title": "Gaussian Weight Sampling for Scalable, Efficient and Stable Pseudo-Quantization Training",
    "authors": [
      "Myeonghwan Ahn",
      "Sungjoo Yoo"
    ],
    "abstract": "Ever-growing scale of large language models (LLMs) is pushing for improved\nefficiency, favoring fully quantized training (FQT) over BF16. While FQT\naccelerates training, it faces consistency challenges and requires searching\nover an exponential number of cases, each needing over 200B tokens to ensure\nstability.\n  Pseudo-quantization training (PQT) addresses the issues of FQT, although it\nis not well-studied. We explore the practical implications of PQT in detail and\npropose a noise distribution $R$ that is floating-point (FP)-friendly, with\nideal properties including stochastic precision annealing. As a result, the\nproposed method serves as an effective theoretical foundation for low-precision\nFP parameters through PQT, utilizing efficient fake quantization via an\naddition and subsequent FP casting.\n  We demonstrate that Gaussian weight sampling is (1) scalable: supports\nlow-precision FP parameters down to FP6 and high-precision noise up to 9-bit\nwith BF16 operator. The proposed method is (2) efficient: incurring\ncomputational overhead as low as 1.40\\% on the A100 GPU in terms of Llama2\ntraining tokens per second, and requiring 2 bytes per parameter in GPU memory.\nWe demonstrate that PQT with Gaussian weight sampling is (3) stable: closely\nfollowing or even surpassing performance of the BF16 baseline while\npre-training GPT2 and Llama2 models with up to 1B parameters and 300B tokens.",
    "pdf_url": "http://arxiv.org/pdf/2505.11170v1",
    "published": "2025-05-16T12:14:12+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11169v1",
    "title": "Locally Differentially Private Graph Clustering via the Power Iteration Method",
    "authors": [
      "Vorapong Suppakitpaisarn",
      "Sayan Mukherjee"
    ],
    "abstract": "We propose a locally differentially private graph clustering algorithm.\nPrevious works have explored this problem, including approaches that apply\nspectral clustering to graphs generated via the randomized response algorithm.\nHowever, these methods only achieve accurate results when the privacy budget is\nin $\\Omega(\\log n)$, which is unsuitable for many practical applications. In\nresponse, we present an interactive algorithm based on the power iteration\nmethod. Given that the noise introduced by the largest eigenvector constant can\nbe significant, we incorporate a technique to eliminate this constant. As a\nresult, our algorithm attains local differential privacy with a constant\nprivacy budget when the graph is well-clustered and has a minimum degree of\n$\\tilde{\\Omega}(\\sqrt{n})$. In contrast, while randomized response has been\nshown to produce accurate results under the same minimum degree condition, it\nis limited to graphs generated from the stochastic block model. We perform\nexperiments to demonstrate that our method outperforms spectral clustering\napplied to randomized response results.",
    "pdf_url": "http://arxiv.org/pdf/2505.11169v1",
    "published": "2025-05-16T12:11:46+00:00",
    "categories": [
      "cs.DS",
      "cs.SI"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.11574v1",
    "title": "InfiJanice: Joint Analysis and In-situ Correction Engine for Quantization-Induced Math Degradation in Large Language Models",
    "authors": [
      "Zhen Li",
      "Yupeng Su",
      "Songmiao Wang",
      "Runming Yang",
      "Congkai Xie",
      "Aofan Liu",
      "Ming Li",
      "Jiannong Cao",
      "Yuan Xie",
      "Ngai Wong",
      "Hongxia Yang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive performance on\ncomplex reasoning benchmarks such as GSM8K, MATH, and AIME. However, the\nsubstantial computational demands of these tasks pose significant challenges\nfor real-world deployment. Model quantization has emerged as a promising\napproach to reduce memory footprint and inference latency by representing\nweights and activations with lower bit-widths. In this work, we conduct a\ncomprehensive study of mainstream quantization methods(e.g., AWQ, GPTQ,\nSmoothQuant) on the most popular open-sourced models (e.g., Qwen2.5, LLaMA3\nseries), and reveal that quantization can degrade mathematical reasoning\naccuracy by up to 69.81%. To better understand this degradation, we develop an\nautomated assignment and judgment pipeline that qualitatively categorizes\nfailures into four error types and quantitatively identifies the most impacted\nreasoning capabilities. Building on these findings, we employ an automated\ndata-curation pipeline to construct a compact \"Silver Bullet\" datasets.\nTraining a quantized model on as few as 332 carefully selected examples for\njust 3-5 minutes on a single GPU is enough to restore its reasoning accuracy to\nmatch that of the full-precision baseline.",
    "pdf_url": "http://arxiv.org/pdf/2505.11574v1",
    "published": "2025-05-16T12:11:40+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11168v1",
    "title": "CheX-DS: Improving Chest X-ray Image Classification with Ensemble Learning Based on DenseNet and Swin Transformer",
    "authors": [
      "Xinran Li",
      "Yu Liu",
      "Xiujuan Xu",
      "Xiaowei Zhao"
    ],
    "abstract": "The automatic diagnosis of chest diseases is a popular and challenging task.\nMost current methods are based on convolutional neural networks (CNNs), which\nfocus on local features while neglecting global features. Recently,\nself-attention mechanisms have been introduced into the field of computer\nvision, demonstrating superior performance. Therefore, this paper proposes an\neffective model, CheX-DS, for classifying long-tail multi-label data in the\nmedical field of chest X-rays. The model is based on the excellent CNN model\nDenseNet for medical imaging and the newly popular Swin Transformer model,\nutilizing ensemble deep learning techniques to combine the two models and\nleverage the advantages of both CNNs and Transformers. The loss function of\nCheX-DS combines weighted binary cross-entropy loss with asymmetric loss,\neffectively addressing the issue of data imbalance. The NIH ChestX-ray14\ndataset is selected to evaluate the model's effectiveness. The model\noutperforms previous studies with an excellent average AUC score of 83.76\\%,\ndemonstrating its superior performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.11168v1",
    "published": "2025-05-16T12:10:01+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11167v1",
    "title": "Numerical Block-Diagonalization and Linked Cluster Expansion for Deriving Effective Hamiltonians: Applications to Spin Excitations",
    "authors": [
      "Tsutomu Momoi",
      "Owen Benton"
    ],
    "abstract": "We present a non-perturbative framework for deriving effective Hamiltonians\nthat describe low-energy excitations in quantum many-body systems. The method\ncombines block diagonalization based on the Cederbaum--Schirmer--Meyer\ntransformation with the numerical linked-cluster (NLC) expansion. A key feature\nof the approach is a variational criterion that uniquely determines the unitary\ntransformation by minimizing the transformation of the state basis within the\nlow-energy subspace. This criterion also provides a robust guideline for\nselecting relevant eigenstates, even in the presence of avoided level crossing\nand mixing induced by particle-number-nonconserving interactions. We\ndemonstrate the method in two quantum spin models: the one-dimensional\ntransverse-field Ising model and the two-dimensional Shastry--Sutherland model,\nrelevant to SrCu$_2$(BO$_3$)$_2$. In both cases, the derived effective\nHamiltonians faithfully reproduce the structure and dynamics of magnon and\ntriplon excitations, including the emergence of topological band structures.\nThe block diagonalization enables quantum fluctuations to be incorporated\nnon-perturbatively, while the NLC expansion systematically accounts for\nfinite-size corrections from larger clusters. This approach naturally generates\nlong-range effective interactions near criticality, even when the original\nHamiltonian includes only short-range couplings. The proposed framework\nprovides a general and computationally feasible tool for constructing\nphysically meaningful effective models across a broad range of quantum\nmany-body systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11167v1",
    "published": "2025-05-16T12:10:00+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.11166v1",
    "title": "SoLoPO: Unlocking Long-Context Capabilities in LLMs via Short-to-Long Preference Optimization",
    "authors": [
      "Huashan Sun",
      "Shengyi Liao",
      "Yansen Han",
      "Yu Bai",
      "Yang Gao",
      "Cheng Fu",
      "Weizhou Shen",
      "Fanqi Wan",
      "Ming Yan",
      "Ji Zhang",
      "Fei Huang"
    ],
    "abstract": "Despite advances in pretraining with extended context lengths, large language\nmodels (LLMs) still face challenges in effectively utilizing real-world\nlong-context information, primarily due to insufficient long-context alignment\ncaused by data quality issues, training inefficiencies, and the lack of\nwell-designed optimization objectives. To address these limitations, we propose\na framework named $\\textbf{S}$h$\\textbf{o}$rt-to-$\\textbf{Lo}$ng\n$\\textbf{P}$reference $\\textbf{O}$ptimization ($\\textbf{SoLoPO}$), decoupling\nlong-context preference optimization (PO) into two components: short-context PO\nand short-to-long reward alignment (SoLo-RA), supported by both theoretical and\nempirical evidence. Specifically, short-context PO leverages preference pairs\nsampled from short contexts to enhance the model's contextual knowledge\nutilization ability. Meanwhile, SoLo-RA explicitly encourages reward score\nconsistency utilization for the responses when conditioned on both short and\nlong contexts that contain identical task-relevant information. This\nfacilitates transferring the model's ability to handle short contexts into\nlong-context scenarios. SoLoPO is compatible with mainstream preference\noptimization algorithms, while substantially improving the efficiency of data\nconstruction and training processes. Experimental results show that SoLoPO\nenhances all these algorithms with respect to stronger length and domain\ngeneralization abilities across various long-context benchmarks, while\nachieving notable improvements in both computational and memory efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.11166v1",
    "published": "2025-05-16T12:08:48+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11165v1",
    "title": "Maximizing Asynchronicity in Event-based Neural Networks",
    "authors": [
      "Haiqing Hao",
      "Nikola Zubić",
      "Weihua He",
      "Zhipeng Sui",
      "Davide Scaramuzza",
      "Wenhui Wang"
    ],
    "abstract": "Event cameras deliver visual data with high temporal resolution, low latency,\nand minimal redundancy, yet their asynchronous, sparse sequential nature\nchallenges standard tensor-based machine learning (ML). While the recent\nasynchronous-to-synchronous (A2S) paradigm aims to bridge this gap by\nasynchronously encoding events into learned representations for ML pipelines,\nexisting A2S approaches often sacrifice representation expressivity and\ngeneralizability compared to dense, synchronous methods. This paper introduces\nEVA (EVent Asynchronous representation learning), a novel A2S framework to\ngenerate highly expressive and generalizable event-by-event representations.\nInspired by the analogy between events and language, EVA uniquely adapts\nadvances from language modeling in linear attention and self-supervised\nlearning for its construction. In demonstration, EVA outperforms prior A2S\nmethods on recognition tasks (DVS128-Gesture and N-Cars), and represents the\nfirst A2S framework to successfully master demanding detection tasks, achieving\na remarkable 47.7 mAP on the Gen1 dataset. These results underscore EVA's\ntransformative potential for advancing real-time event-based vision\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2505.11165v1",
    "published": "2025-05-16T12:07:50+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11164v1",
    "title": "Parkour in the Wild: Learning a General and Extensible Agile Locomotion Policy Using Multi-expert Distillation and RL Fine-tuning",
    "authors": [
      "Nikita Rudin",
      "Junzhe He",
      "Joshua Aurand",
      "Marco Hutter"
    ],
    "abstract": "Legged robots are well-suited for navigating terrains inaccessible to wheeled\nrobots, making them ideal for applications in search and rescue or space\nexploration. However, current control methods often struggle to generalize\nacross diverse, unstructured environments. This paper introduces a novel\nframework for agile locomotion of legged robots by combining multi-expert\ndistillation with reinforcement learning (RL) fine-tuning to achieve robust\ngeneralization. Initially, terrain-specific expert policies are trained to\ndevelop specialized locomotion skills. These policies are then distilled into a\nunified foundation policy via the DAgger algorithm. The distilled policy is\nsubsequently fine-tuned using RL on a broader terrain set, including real-world\n3D scans. The framework allows further adaptation to new terrains through\nrepeated fine-tuning. The proposed policy leverages depth images as\nexteroceptive inputs, enabling robust navigation across diverse, unstructured\nterrains. Experimental results demonstrate significant performance improvements\nover existing methods in synthesizing multi-terrain skills into a single\ncontroller. Deployment on the ANYmal D robot validates the policy's ability to\nnavigate complex environments with agility and robustness, setting a new\nbenchmark for legged robot locomotion.",
    "pdf_url": "http://arxiv.org/pdf/2505.11164v1",
    "published": "2025-05-16T12:07:37+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11163v1",
    "title": "Foundation Time-Series AI Model for Realized Volatility Forecasting",
    "authors": [
      "Anubha Goel",
      "Puneet Pasricha",
      "Martin Magris",
      "Juho Kanniainen"
    ],
    "abstract": "Time series foundation models (FMs) have emerged as a popular paradigm for\nzero-shot multi-domain forecasting. These models are trained on numerous\ndiverse datasets and claim to be effective forecasters across multiple\ndifferent time series domains, including financial data. In this study, we\nevaluate the effectiveness of FMs, specifically the TimesFM model, for\nvolatility forecasting, a core task in financial risk management. We first\nevaluate TimesFM in its pretrained (zero-shot) form, followed by our custom\nfine-tuning procedure based on incremental learning, and compare the resulting\nmodels against standard econometric benchmarks. While the pretrained model\nprovides a reasonable baseline, our findings show that incremental fine-tuning,\nwhich allows the model to adapt to new financial return data over time, is\nessential for learning volatility patterns effectively. Fine-tuned variants not\nonly improve forecast accuracy but also statistically outperform traditional\nmodels, as demonstrated through Diebold-Mariano and Giacomini-White tests.\nThese results highlight the potential of foundation models as scalable and\nadaptive tools for financial forecasting-capable of delivering strong\nperformance in dynamic market environments when paired with targeted\nfine-tuning strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11163v1",
    "published": "2025-05-16T12:07:17+00:00",
    "categories": [
      "q-fin.RM",
      "q-fin.ST"
    ],
    "primary_category": "q-fin.RM"
  },
  {
    "id": "http://arxiv.org/abs/2505.11162v1",
    "title": "Sliding Speed Influences Electrovibration-Induced Finger Friction Dynamics on Touchscreens",
    "authors": [
      "Jagan K Balasubramanian",
      "Daan M Pool",
      "Yasemin Vardar"
    ],
    "abstract": "Electrovibration technology can render tactile textures on capacitive\ntouchscreens by modulating friction between the finger and the screen through\nelectrostatic attraction force generated by applying an alternating voltage\nsignal to the screen. This signal should be carefully calibrated for realistic\nand robust texture rendering. However, this process is challenging due to\nvariations in sliding speed, applied force, and individual skin mechanics,\nwhich affect friction in complex and unpredictable ways. Here, we investigate\nhow exploration conditions affect electrovibration-induced finger friction on\ntouchscreens and the role of skin mechanics in this process. Ten participants\nslid their index fingers across an electrovibration-enabled touchscreen at five\nsliding speeds ($20\\sim100$ mm/s) and applied force levels ($0.2\\sim0.6$ N)\nwhile we measured contact forces and skin accelerations. The touchscreen was\nexcited with amplitude-modulated voltage signals across frequencies relevant to\ntouch. We modeled the finger-touchscreen friction response as a first-order\nsystem and the skin mechanics as a mass-spring-damper system. Our results\nshowed that the sliding speed influenced the cutoff frequency of the friction\nresponse as well as the moving mass and stiffness of the finger for the tested\nexploration ranges. Specifically, for every 1 mm/s increase in speed, the\ncutoff frequency, the finger moving mass, and stiffness increased by $13.8$ Hz,\n$3.23\\times 10^{-5}$ kg, and $4.04$ N/m, respectively. Further correlation\nanalysis revealed that finger stiffness affected the cutoff frequency more than\nthe moving mass. Finally, we developed a practical model for\nelectrovibration-induced finger friction on touchscreens that accounts for\nsliding speed variations, paving the way for delivering consistent haptic\nfeedback through electrovibration.",
    "pdf_url": "http://arxiv.org/pdf/2505.11162v1",
    "published": "2025-05-16T12:07:13+00:00",
    "categories": [
      "cs.HC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11161v2",
    "title": "Charge gap and charge redistribution among copper and oxygen orbitals in the normal state of the Emery model",
    "authors": [
      "G. L. Reaney",
      "N. Kowalski",
      "A. -M. S. Tremblay",
      "G. Sordi"
    ],
    "abstract": "Unraveling the behavior of the electrons in the copper-oxygen planes of\ncuprate superconductors remains a challenge. Here we examine the electronic\ncharge redistribution among planar copper and oxygen orbitals and the charge\ngap using the Emery model in the normal state, solved with cellular dynamical\nmean-field theory at finite temperature. We quantify the charge redistribution\nas a function of the onsite Coulomb repulsion on the copper orbitals, the bare\ncopper-oxygen energy difference, and the hole or electron doping. We find that\nthe position relative to the metal to insulator boundary of the\nZaanen-Sawatzky-Allen diagram determines the charge redistribution among copper\nand oxygen orbitals. For a fixed bare Cu-O energy difference, an increase in\nthe Cu electron repulsion leads to a transfer of the electronic charge from Cu\nto O orbitals. For a fixed charge gap size of the undoped state, as the system\nevolves from a charge-transfer to a Mott-Hubbard regime, the electronic charge\nis transferred from Cu to O orbitals. Our findings posit the Coulomb repulsion\nand the bare charge-transfer energy as key drivers of the microscopic process\nof charge redistribution in the CuO$_2$ plane. They quantify the\nanticorrelation between the charge gap size and oxygen hole content. They show\nthat for fixed band-structure parameters, the charge gap and the charge\nredistribution between Cu and O orbitals provide a way to understand observed\ntrends in cuprates.",
    "pdf_url": "http://arxiv.org/pdf/2505.11161v2",
    "published": "2025-05-16T12:07:07+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.11160v1",
    "title": "Protecting Young Users on Social Media: Evaluating the Effectiveness of Content Moderation and Legal Safeguards on Video Sharing Platforms",
    "authors": [
      "Fatmaelzahraa Eltaher",
      "Rahul Krishna Gajula",
      "Luis Miralles-Pechuán",
      "Patrick Crotty",
      "Juan Martínez-Otero",
      "Christina Thorpe",
      "Susan McKeever"
    ],
    "abstract": "Video-sharing social media platforms, such as TikTok, YouTube, and Instagram,\nimplement content moderation policies aimed at reducing exposure to harmful\nvideos among minor users. As video has become the dominant and most immersive\nform of online content, understanding how effectively this medium is moderated\nfor younger audiences is urgent. In this study, we evaluated the effectiveness\nof video moderation for different age groups on three of the main video-sharing\nplatforms: TikTok, YouTube, and Instagram. We created experimental accounts for\nthe children assigned ages 13 and 18. Using these accounts, we evaluated 3,000\nvideos served up by the social media platforms, in passive scrolling and search\nmodes, recording the frequency and speed at which harmful videos were\nencountered. Each video was manually assessed for level and type of harm, using\ndefinitions from a unified framework of harmful content.\n  The results show that for passive scrolling or search-based scrolling,\naccounts assigned to the age 13 group encountered videos that were deemed\nharmful, more frequently and quickly than those assigned to the age 18 group.\nOn YouTube, 15\\% of recommended videos to 13-year-old accounts during passive\nscrolling were assessed as harmful, compared to 8.17\\% for 18-year-old\naccounts. On YouTube, videos labelled as harmful appeared within an average of\n3:06 minutes of passive scrolling for the younger age group. Exposure occurred\nwithout user-initiated searches, indicating weaknesses in the algorithmic\nfiltering systems. These findings point to significant gaps in current video\nmoderation practices by social media platforms. Furthermore, the ease with\nwhich underage users can misrepresent their age demonstrates the urgent need\nfor more robust verification methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.11160v1",
    "published": "2025-05-16T12:06:42+00:00",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11159v1",
    "title": "Sonification of entanglement dynamics in many-qubit systems",
    "authors": [
      "Juliette Tudoce",
      "Marcin Płodzień",
      "Maciej Lewenstein",
      "Reiko Yamada"
    ],
    "abstract": "Quantum mechanics poses significant challenges for audio-visual\nrepresentation, particularly concerning quantum entanglement. Sonification --\nthe auditory representation of data -- offers a promising complementary\napproach. This paper investigates sonification techniques applied to dynamical\nentanglement generation in many-qubit systems with the help of phase space\nmethods and entanglement measure. We study dynamics of entanglement generation\nin many-qubit system in dynamical protocol governed by two models: the one-axis\ntwisting model, and a quantum kicked-rotor exhibiting both regular and quantum\nchaotic behavior. We present a procedure of entanglement dynamics sonification,\nallowing mapping the phase-space representation of a many-qubit quantum state\nand von Neuman entanglement entropy to sound. Results demonstrate how\nsonification enhances perception of dynamic entanglement offering intuitive and\nartistic insight into quantum correlations behaviors.",
    "pdf_url": "http://arxiv.org/pdf/2505.11159v1",
    "published": "2025-05-16T12:04:49+00:00",
    "categories": [
      "quant-ph",
      "physics.ed-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11158v2",
    "title": "Recent Advances in Diffusion Models for Hyperspectral Image Processing and Analysis: A Review",
    "authors": [
      "Xing Hu",
      "Xiangcheng Liu",
      "Danfeng Hong",
      "Qianqian Duan",
      "Linghua Jiang",
      "Haima Yang",
      "Dawei Zhan"
    ],
    "abstract": "Hyperspectral image processing and analysis has important application value\nin remote sensing, agriculture and environmental monitoring, but its high\ndimensionality, data redundancy and noise interference etc. bring great\nchallenges to the analysis. Traditional models have limitations in dealing with\nthese complex data, and it is difficult to meet the increasing demand for\nanalysis. In recent years, Diffusion models, as a class of emerging generative\napproaches, have demonstrated promising capabilities in hyperspectral image\n(HSI) processing tasks. By simulating the diffusion process of data in time,\nthe Diffusion Model are capable of modeling high-dimensional spectral\nstructures, generate high-quality samples, and achieve competitive performance\nin spectral-spatial denoising tasks and data enhancement. In this paper, we\nreview the recent research advances in diffusion modeling for hyperspectral\nimage processing and analysis, and discuss its applications in tasks such as\nhigh-dimensional data processing, noise removal, classification, and anomaly\ndetection. The performance of diffusion-based models on image processing is\ncompared and the challenges are summarized. It is shown that the diffusion\nmodel can significantly improve the accuracy and efficiency of hyperspectral\nimage analysis, providing a new direction for future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.11158v2",
    "published": "2025-05-16T11:59:48+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15834v1",
    "title": "MPPFND: A Dataset and Analysis of Detecting Fake News with Multi-Platform Propagation",
    "authors": [
      "Congyuan Zhao",
      "Lingwei Wei",
      "Ziming Qin",
      "Wei Zhou",
      "Yunya Song",
      "Songlin Hu"
    ],
    "abstract": "Fake news spreads widely on social media, leading to numerous negative\neffects. Most existing detection algorithms focus on analyzing news content and\nsocial context to detect fake news. However, these approaches typically detect\nfake news based on specific platforms, ignoring differences in propagation\ncharacteristics across platforms. In this paper, we introduce the MPPFND\ndataset, which captures propagation structures across multiple platforms. We\nalso describe the commenting and propagation characteristics of different\nplatforms to show that their social contexts have distinct features. We propose\na multi-platform fake news detection model (APSL) that uses graph neural\nnetworks to extract social context features from various platforms. Experiments\nshow that accounting for cross-platform propagation differences improves fake\nnews detection performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.15834v1",
    "published": "2025-05-16T11:59:31+00:00",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11157v1",
    "title": "Attention on the Sphere",
    "authors": [
      "Boris Bonev",
      "Max Rietmann",
      "Andrea Paris",
      "Alberto Carpentieri",
      "Thorsten Kurth"
    ],
    "abstract": "We introduce a generalized attention mechanism for spherical domains,\nenabling Transformer architectures to natively process data defined on the\ntwo-dimensional sphere - a critical need in fields such as atmospheric physics,\ncosmology, and robotics, where preserving spherical symmetries and topology is\nessential for physical accuracy. By integrating numerical quadrature weights\ninto the attention mechanism, we obtain a geometrically faithful spherical\nattention that is approximately rotationally equivariant, providing strong\ninductive biases and leading to better performance than Cartesian approaches.\nTo further enhance both scalability and model performance, we propose\nneighborhood attention on the sphere, which confines interactions to geodesic\nneighborhoods. This approach reduces computational complexity and introduces\nthe additional inductive bias for locality, while retaining the symmetry\nproperties of our method. We provide optimized CUDA kernels and\nmemory-efficient implementations to ensure practical applicability. The method\nis validated on three diverse tasks: simulating shallow water equations on the\nrotating sphere, spherical image segmentation, and spherical depth estimation.\nAcross all tasks, our spherical Transformers consistently outperform their\nplanar counterparts, highlighting the advantage of geometric priors for\nlearning on spherical domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.11157v1",
    "published": "2025-05-16T11:59:30+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11156v2",
    "title": "Simultaneous probes of pseudogap and disorder by hard x-ray photoemission applied for a candidate thermoelectric Al-Pd-Ru quasicrystal",
    "authors": [
      "N. U. Sakamoto",
      "G. Nozue",
      "H. Fujiwara",
      "Y. Torii",
      "M. Sakaguchi",
      "T. D. Nakamura",
      "T. Kiss",
      "H. Sugawara",
      "S. Tanaka",
      "Y. Iwasaki",
      "Y. Niwa",
      "A. Ishikawa",
      "T. D. Yamamoto",
      "R. Tamura",
      "A. Yasui",
      "A. Sekiyama"
    ],
    "abstract": "The bulk electronic structure of Al-Pd-Ru quasicrystal (QC) have been\ninvestigated by hard X-ray photoemission spectroscopy (HAXPES). We have found\nan intrinsic pseudogap structure in which the spectral weight in the vicinity\nof the Fermi level (E_F) is remarkably suppressed at any photon energy. The\nvalence-band HAXPES spectra and the asymmetry of the core-level peaks indicate\na contribution of the Al sites to the electronic structure in the vicinity of\nE_F with less contributions from the Pd and Ru sites. The disorder effects are\nfound in the core-level lineshapes of the Al-Pd-Ru QC, of which the widths are\nmuch broader than those of the other reference crystalline solids with less\ndisorder.",
    "pdf_url": "http://arxiv.org/pdf/2505.11156v2",
    "published": "2025-05-16T11:58:07+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.dis-nn",
      "cond-mat.other",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11155v1",
    "title": "Controlling spatial correlation in k-space interpolation networks for MRI reconstruction: denoising versus apparent blurring",
    "authors": [
      "Istvan Homolya",
      "Peter Dawood",
      "Jannik Stebani",
      "Felix Breuer",
      "Grit Hein",
      "Matthias Gamer",
      "Florian Knoll",
      "Martin Blaimer"
    ],
    "abstract": "Purpose: To improve the interpretability of noise amplification and apparent\nblurring of k-space interpolation networks, and to optimize for them in the\nloss function as a model-based regularizer in k-space interpolation networks.\n  Methods: Network is subjected to noise amplification analysis through\nautomatic differentiation of the input with respect to the input. Noise\nvariance maps are decomposed into terms accounting for the linear and nonlinear\ncharacteristics of the network. Variance maps are derived in each iteration,\nallowing for runtime quality monitoring. Maximum variance (eigenpixel) and\nresidual variance maps (pixel contamination) are introduced, which describe the\nnetwork noise amplification and apparent blurring, respectively. By including\nthe variance maps in the training, the loss function is enriched with a\nmodel-based regularizer beyond the k-space data consistency term. Accordingly,\nthe proposed g-factor-informed RAKI (GIF-RAKI) establishes a recurrent flow of\nnoise and apparent blurring information into the training, that drives the\ndenoising via the trainable nonlinear activation function.\n  Results: GIF-RAKI outperforms other RAKI implementations, supported by\ndifference maps, and image quality metrics. Eigenpixel and pixel contamination\nmaps provide quantitative metrics for noise amplification and apparent\nblurring, respectively, without the need for a gold standard reference. RAKI\nwith tuneable Leaky ReLU is capable of adjusting its own nonlinearity\nautomatically.\n  Conclusion: The additional model-based loss terms allow to optimize for the\ntrade-off between denoising and apparent blurring during RAKI training. This\nhas the potential to eliminate the need for heuristic hyperparameter tweaking.",
    "pdf_url": "http://arxiv.org/pdf/2505.11155v1",
    "published": "2025-05-16T11:57:31+00:00",
    "categories": [
      "physics.med-ph"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11154v1",
    "title": "MPMA: Preference Manipulation Attack Against Model Context Protocol",
    "authors": [
      "Zihan Wang",
      "Hongwei Li",
      "Rui Zhang",
      "Yu Liu",
      "Wenbo Jiang",
      "Wenshu Fan",
      "Qingchuan Zhao",
      "Guowen Xu"
    ],
    "abstract": "Model Context Protocol (MCP) standardizes interface mapping for large\nlanguage models (LLMs) to access external data and tools, which revolutionizes\nthe paradigm of tool selection and facilitates the rapid expansion of the LLM\nagent tool ecosystem. However, as the MCP is increasingly adopted, third-party\ncustomized versions of the MCP server expose potential security\nvulnerabilities. In this paper, we first introduce a novel security threat,\nwhich we term the MCP Preference Manipulation Attack (MPMA). An attacker\ndeploys a customized MCP server to manipulate LLMs, causing them to prioritize\nit over other competing MCP servers. This can result in economic benefits for\nattackers, such as revenue from paid MCP services or advertising income\ngenerated from free servers. To achieve MPMA, we first design a Direct\nPreference Manipulation Attack ($\\mathtt{DPMA}$) that achieves significant\neffectiveness by inserting the manipulative word and phrases into the tool name\nand description. However, such a direct modification is obvious to users and\nlacks stealthiness. To address these limitations, we further propose\nGenetic-based Advertising Preference Manipulation Attack ($\\mathtt{GAPMA}$).\n$\\mathtt{GAPMA}$ employs four commonly used strategies to initialize\ndescriptions and integrates a Genetic Algorithm (GA) to enhance stealthiness.\nThe experiment results demonstrate that $\\mathtt{GAPMA}$ balances high\neffectiveness and stealthiness. Our study reveals a critical vulnerability of\nthe MCP in open ecosystems, highlighting an urgent need for robust defense\nmechanisms to ensure the fairness of the MCP ecosystem.",
    "pdf_url": "http://arxiv.org/pdf/2505.11154v1",
    "published": "2025-05-16T11:55:12+00:00",
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11153v1",
    "title": "Bi-directional Recurrence Improves Transformer in Partially Observable Markov Decision Processes",
    "authors": [
      "Ashok Arora",
      "Neetesh Kumar"
    ],
    "abstract": "In real-world reinforcement learning (RL) scenarios, agents often encounter\npartial observability, where incomplete or noisy information obscures the true\nstate of the environment. Partially Observable Markov Decision Processes\n(POMDPs) are commonly used to model these environments, but effective\nperformance requires memory mechanisms to utilise past observations. While\nrecurrence networks have traditionally addressed this need, transformer-based\nmodels have recently shown improved sample efficiency in RL tasks. However,\ntheir application to POMDPs remains underdeveloped, and their real-world\ndeployment is constrained due to the high parameter count. This work introduces\na novel bi-recurrent model architecture that improves sample efficiency and\nreduces model parameter count in POMDP scenarios. The architecture replaces the\nmultiple feed forward layers with a single layer of bi-directional recurrence\nunit to better capture and utilize sequential dependencies and contextual\ninformation. This approach improves the model's ability to handle partial\nobservability and increases sample efficiency, enabling effective learning from\ncomparatively fewer interactions. To evaluate the performance of the proposed\nmodel architecture, experiments were conducted on a total of 23 POMDP\nenvironments. The proposed model architecture outperforms existing\ntransformer-based, attention-based, and recurrence-based methods by a margin\nranging from 87.39% to 482.04% on average across the 23 POMDP environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.11153v1",
    "published": "2025-05-16T11:54:48+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11152v1",
    "title": "Learning Dense Hand Contact Estimation from Imbalanced Data",
    "authors": [
      "Daniel Sungho Jung",
      "Kyoung Mu Lee"
    ],
    "abstract": "Hands are essential to human interaction, and understanding contact between\nhands and the world can promote comprehensive understanding of their function.\nRecently, there have been growing number of hand interaction datasets that\ncover interaction with object, other hand, scene, and body. Despite the\nsignificance of the task and increasing high-quality data, how to effectively\nlearn dense hand contact estimation remains largely underexplored. There are\ntwo major challenges for learning dense hand contact estimation. First, there\nexists class imbalance issue from hand contact datasets where majority of\nsamples are not in contact. Second, hand contact datasets contain spatial\nimbalance issue with most of hand contact exhibited in finger tips, resulting\nin challenges for generalization towards contacts in other hand regions. To\ntackle these issues, we present a framework that learns dense HAnd COntact\nestimation (HACO) from imbalanced data. To resolve the class imbalance issue,\nwe introduce balanced contact sampling, which builds and samples from multiple\nsampling groups that fairly represent diverse contact statistics for both\ncontact and non-contact samples. Moreover, to address the spatial imbalance\nissue, we propose vertex-level class-balanced (VCB) loss, which incorporates\nspatially varying contact distribution by separately reweighting loss\ncontribution of each vertex based on its contact frequency across dataset. As a\nresult, we effectively learn to predict dense hand contact estimation with\nlarge-scale hand contact data without suffering from class and spatial\nimbalance issue. The codes will be released.",
    "pdf_url": "http://arxiv.org/pdf/2505.11152v1",
    "published": "2025-05-16T11:54:25+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11151v1",
    "title": "STEP: A Unified Spiking Transformer Evaluation Platform for Fair and Reproducible Benchmarking",
    "authors": [
      "Sicheng Shen",
      "Dongcheng Zhao",
      "Linghao Feng",
      "Zeyang Yue",
      "Jindong Li",
      "Tenglong Li",
      "Guobin Shen",
      "Yi Zeng"
    ],
    "abstract": "Spiking Transformers have recently emerged as promising architectures for\ncombining the efficiency of spiking neural networks with the representational\npower of self-attention. However, the lack of standardized implementations,\nevaluation pipelines, and consistent design choices has hindered fair\ncomparison and principled analysis. In this paper, we introduce \\textbf{STEP},\na unified benchmark framework for Spiking Transformers that supports a wide\nrange of tasks, including classification, segmentation, and detection across\nstatic, event-based, and sequential datasets. STEP provides modular support for\ndiverse components such as spiking neurons, input encodings, surrogate\ngradients, and multiple backends (e.g., SpikingJelly, BrainCog). Using STEP, we\nreproduce and evaluate several representative models, and conduct systematic\nablation studies on attention design, neuron types, encoding schemes, and\ntemporal modeling capabilities. We also propose a unified analytical model for\nenergy estimation, accounting for spike sparsity, bitwidth, and memory access,\nand show that quantized ANNs may offer comparable or better energy efficiency.\nOur results suggest that current Spiking Transformers rely heavily on\nconvolutional frontends and lack strong temporal modeling, underscoring the\nneed for spike-native architectural innovations. The full code is available at:\nhttps://github.com/Fancyssc/STEP",
    "pdf_url": "http://arxiv.org/pdf/2505.11151v1",
    "published": "2025-05-16T11:50:14+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11150v1",
    "title": "Second roton feature in the strongly coupled electron liquid",
    "authors": [
      "Thomas M. Chuna",
      "Jan Vorberger",
      "Panagiotis Tolias",
      "Alexander Benedix Robles",
      "Michael Hecht",
      "Phil-Alexander Hofmann",
      "Zhandos A. Moldabekov",
      "Tobias Dornheim"
    ],
    "abstract": "We present extensive \\emph{ab initio} path integral Monte Carlo (PIMC)\nresults for the dynamic properties of the finite temperature uniform electron\ngas (UEG) over a broad range of densities, $2\\leq r_s\\leq300$. We demonstrate\nthat the direct analysis of the imaginary-time density--density correlation\nfunction (ITCF) allows for a rigorous assessment of the density and temperature\ndependence of the previously reported roton-type feature [T.~Dornheim,\n\\emph{Phys.~Rev.~Lett.}~\\textbf{121}, 255001 (2018)] at intermediate\nwavenumbers. We clearly resolve the emergence of a second roton at the second\nharmonic of the original feature for $r_s\\gtrsim100$, which we identify as an\nincipient phonon dispersion. Finally, we use our highly accurate PIMC results\nfor the ITCF as the basis for an analytic continuation to compute the dynamic\nstructure factor, which additionally substantiates the existence of the second\nroton in the strongly coupled electron liquid. Our investigation further\nelucidates the complex interplay between quantum delocalization and Coulomb\ncoupling in the UEG. All PIMC results are freely available online and provide\nvaluable benchmarks for other theoretical methodologies and approximations.",
    "pdf_url": "http://arxiv.org/pdf/2505.11150v1",
    "published": "2025-05-16T11:50:06+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.quant-gas",
      "cond-mat.str-el"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11149v1",
    "title": "Absence of a Runaway Greenhouse Limit on Lava Planets",
    "authors": [
      "Iris D. Boer",
      "Harrison Nicholls",
      "Tim Lichtenberg"
    ],
    "abstract": "Climate transitions on exoplanets offer valuable insights into the\natmospheric processes governing planetary habitability. Previous pure-steam\natmospheric models show a thermal limit in outgoing long-wave radiation, which\nhas been used to define the inner edge of the classical habitable zone and\nguide exoplanet surveys aiming to identify and characterize potentially\nhabitable worlds. We expand upon previous modelling by treating (i) the\ndissolution of volatiles into a magma ocean underneath the atmosphere, (ii) a\nbroader volatile range of the atmospheric composition including H2O, CO2, CO,\nH2, CH4 and N2, and (iii) a surface temperature- and mantle redox-dependent\nequilibrium chemistry. We find that multi-component atmospheres of outgassed\ncomposition located above partially or fully-molten mantles do not exhibit the\ncharacteristic thermal radiation limit that arises from pure-steam models,\nthereby undermining the canonical concept of a runaway greenhouse limit, and\nhence challenging the conventional approach of using it to define an\nirradiation-based habitable zone. Our results show that atmospheric heat loss\nto space is strongly dependent on the oxidation and melting state of the\nunderlying planetary mantle, through their significant influence on the\natmosphere's equilibrium composition. This suggests an evolutionary hysteresis\nin climate scenarios: initially molten and cooling planets do not converge to\nthe same climate regime as solidified planets that heat up by external\nirradiation. Steady-state models cannot recover evolutionary climate\ntransitions, which instead require self-consistent models of the temporal\nevolution of the coupled feedback processes between interior and atmosphere\nover geologic time.",
    "pdf_url": "http://arxiv.org/pdf/2505.11149v1",
    "published": "2025-05-16T11:50:05+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11148v1",
    "title": "Conformal transformations of spacetimes without observer horizons",
    "authors": [
      "Leonardo García-Heveling",
      "Abdelghani Zeghib"
    ],
    "abstract": "We prove that for a certain class of Lorentzian manifolds, namely causal\nspacetimes without observer horizons, conformal transformations can be\nclassified into two types: escaping and non-escaping. This means that\nsuccessive powers of a given conformal transformation will either send all\npoints to infinity, or none. As an application, we classify the conformal\ntransformations of Einstein's static universe. We also study the question of\nessentiality in this context, i.e. which conformal transformations are\nisometric for some metric in the conformal class.",
    "pdf_url": "http://arxiv.org/pdf/2505.11148v1",
    "published": "2025-05-16T11:49:47+00:00",
    "categories": [
      "math.DG",
      "gr-qc",
      "math-ph",
      "math.MP",
      "53C50 (primary) 58D19 (secondary)"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11147v1",
    "title": "High-resolution, high-efficiency narrowband spectroscopy with an s-p-phased holographic grating in double pass",
    "authors": [
      "Casper Farret Jentink",
      "Francesco Pepe",
      "Christophe Lovis",
      "Christian Schwab",
      "François Wildi",
      "Andrew Clawson"
    ],
    "abstract": "High-resolution spectroscopy (R>50,000) in astronomy typically uses\nechelle-type spectrographs, which excel for exoplanet detection via radial\nvelocity but compromise throughput for atmospheric characterization. We propose\nand test a novel method to achieve very high spectral resolution with\nsignificantly higher throughput within a limited bandpass using a tuned, high\nfringe-density volume phase holographic (VPH) grating in double pass. Using a\nwavelength-tunable laser, we measured the dispersion and diffraction efficiency\nof this setup, finding that our tested VPH grating reaches a\ndiffraction-limited resolving power >140,000 in double pass with a peak\ndiffraction efficiency of 79% for unpolarized light. Based on current\nmanufacturing capabilities, we estimate double-pass diffraction efficiencies\n>50% with resolving powers >200,000 are achievable from visible to\nnear-infrared wavelengths, limited only by detector size.",
    "pdf_url": "http://arxiv.org/pdf/2505.11147v1",
    "published": "2025-05-16T11:49:45+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.11146v1",
    "title": "X2C: A Dataset Featuring Nuanced Facial Expressions for Realistic Humanoid Imitation",
    "authors": [
      "Peizhen Li",
      "Longbing Cao",
      "Xiao-Ming Wu",
      "Runze Yang",
      "Xiaohan Yu"
    ],
    "abstract": "The ability to imitate realistic facial expressions is essential for humanoid\nrobots engaged in affective human-robot communication. However, the lack of\ndatasets containing diverse humanoid facial expressions with proper annotations\nhinders progress in realistic humanoid facial expression imitation. To address\nthese challenges, we introduce X2C (Anything to Control), a dataset featuring\nnuanced facial expressions for realistic humanoid imitation. With X2C, we\ncontribute: 1) a high-quality, high-diversity, large-scale dataset comprising\n100,000 (image, control value) pairs. Each image depicts a humanoid robot\ndisplaying a diverse range of facial expressions, annotated with 30 control\nvalues representing the ground-truth expression configuration; 2) X2CNet, a\nnovel human-to-humanoid facial expression imitation framework that learns the\ncorrespondence between nuanced humanoid expressions and their underlying\ncontrol values from X2C. It enables facial expression imitation in the wild for\ndifferent human performers, providing a baseline for the imitation task,\nshowcasing the potential value of our dataset; 3) real-world demonstrations on\na physical humanoid robot, highlighting its capability to advance realistic\nhumanoid facial expression imitation. Code and Data:\nhttps://lipzh5.github.io/X2CNet/",
    "pdf_url": "http://arxiv.org/pdf/2505.11146v1",
    "published": "2025-05-16T11:48:19+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11573v1",
    "title": "A panoramic view of groupoids and MRAs",
    "authors": [
      "Marius Ionescu",
      "Paul S. Muhly"
    ],
    "abstract": "This sequel to \\cite{im2008} uses groupoid technology to provide new proofs\nof the famous theorems of Mallat \\cite[Theorem 1 and 2]{Mall_TAMS89} that\nextend to much broader contexts than those conceived by Mallat.\n  This work was inspired in large part by\n\\cite{Bagg_co_JFAA09,Bag_co_JFA10,LarRae_CM06,Larsen-Raeburn2007}, written by\nIain Raeburn and co-authors.",
    "pdf_url": "http://arxiv.org/pdf/2505.11573v1",
    "published": "2025-05-16T11:47:46+00:00",
    "categories": [
      "math.OA",
      "22A22, 42C40, 46L99"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11145v1",
    "title": "Piezomagnetic effect in 5$d$ transition metal oxides Y$_2$Ir$_2$O$_7$ and Cd$_2$Os$_2$O$_7$ with all-in/all-out magnetic order",
    "authors": [
      "Hiroki Nanjo",
      "Yoshinori Imai",
      "Takuya Aoyama",
      "Junichi Yamaura",
      "Kenya Ohgushi"
    ],
    "abstract": "We investigated the piezomagnetic effect in pyrochlore-type oxides\nY$_2$Ir$_2$O$_7$ and Cd$_2$Os$_2$O$_7$, which show a non-coplanar magnetic\nstructure called the all-in/all-out antiferromagnetic order at low\ntemperatures. The all-in/all-out magnetic order can be viewed as a ferroic\norder of the $xyz$-type magnetic octupoles. We observed a linear development of\nmagnetization with applying stress for both materials. We then estimated the\npowder-averaged piezomagnetic tensor at 50 K to be $Q = 5.74 \\times 10^{-6}$\n$\\mu_{\\text{B}}$/Ir$\\cdot$MPa for Y$_2$Ir$_2$O$_7$, and $Q = 3.49 \\times\n10^{-7}$ $\\mu_{\\text{B}}$/Os$\\cdot$MPa for Cd$_2$Os$_2$O$_7$. We discuss the\nmicroscopic mechanism of the piezomagnetic effect in terms of the\nstress-induced modification of the g-tensor anisotropy and\nDzyaloshinskii-Moriya (D-M) interactions. This work paves the way for the\nfurther development of piezomagnetic materials using a strategy based on\nmagnetic multipoles.",
    "pdf_url": "http://arxiv.org/pdf/2505.11145v1",
    "published": "2025-05-16T11:45:36+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.11144v1",
    "title": "Separability Properties of Monadically Dependent Graph Classes",
    "authors": [
      "Édouard Bonnet",
      "Samuel Braunfeld",
      "Ioannis Eleftheriadis",
      "Colin Geniet",
      "Nikolas Mählmann",
      "Michał Pilipczuk",
      "Wojciech Przybyszewski",
      "Szymon Toruńczyk"
    ],
    "abstract": "A graph class $\\mathcal C$ is monadically dependent if one cannot interpret\nall graphs in colored graphs from $\\mathcal C$ using a fixed first-order\ninterpretation. We prove that monadically dependent classes can be exactly\ncharacterized by the following property, which we call flip-separability: for\nevery $r\\in \\mathbb{N}$, $\\varepsilon>0$, and every graph $G\\in \\mathcal{C}$\nequipped with a weight function on vertices, one can apply a bounded (in terms\nof $\\mathcal{C},r,\\varepsilon$) number of flips (complementations of the\nadjacency relation on a subset of vertices) to $G$ so that in the resulting\ngraph, every radius-$r$ ball contains at most an $\\varepsilon$-fraction of the\ntotal weight. On the way to this result, we introduce a robust toolbox for\nworking with various notions of local separations in monadically dependent\nclasses.",
    "pdf_url": "http://arxiv.org/pdf/2505.11144v1",
    "published": "2025-05-16T11:44:35+00:00",
    "categories": [
      "math.CO",
      "cs.DM",
      "cs.LO",
      "math.LO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11143v1",
    "title": "Nash: Neural Adaptive Shrinkage for Structured High-Dimensional Regression",
    "authors": [
      "William R. P. Denault"
    ],
    "abstract": "Sparse linear regression is a fundamental tool in data analysis. However,\ntraditional approaches often fall short when covariates exhibit structure or\narise from heterogeneous sources. In biomedical applications, covariates may\nstem from distinct modalities or be structured according to an underlying\ngraph. We introduce Neural Adaptive Shrinkage (Nash), a unified framework that\nintegrates covariate-specific side information into sparse regression via\nneural networks. Nash adaptively modulates penalties on a per-covariate basis,\nlearning to tailor regularization without cross-validation. We develop a\nvariational inference algorithm for efficient training and establish\nconnections to empirical Bayes regression. Experiments on real data demonstrate\nthat Nash can improve accuracy and adaptability over existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.11143v1",
    "published": "2025-05-16T11:43:01+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.11142v1",
    "title": "Open-Source Multi-Viewpoint Surgical Telerobotics",
    "authors": [
      "Guido Caccianiga",
      "Yarden Sharon",
      "Bernard Javot",
      "Senya Polikovsky",
      "Gökce Ergün",
      "Ivan Capobianco",
      "André L. Mihaljevic",
      "Anton Deguet",
      "Katherine J. Kuchenbecker"
    ],
    "abstract": "As robots for minimally invasive surgery (MIS) gradually become more\naccessible and modular, we believe there is a great opportunity to rethink and\nexpand the visualization and control paradigms that have characterized surgical\nteleoperation since its inception. We conjecture that introducing one or more\nadditional adjustable viewpoints in the abdominal cavity would not only unlock\nnovel visualization and collaboration strategies for surgeons but also\nsubstantially boost the robustness of machine perception toward shared\nautonomy. Immediate advantages include controlling a second viewpoint and\nteleoperating surgical tools from a different perspective, which would allow\ncollaborating surgeons to adjust their views independently and still maneuver\ntheir robotic instruments intuitively. Furthermore, we believe that capturing\nsynchronized multi-view 3D measurements of the patient's anatomy would unlock\nadvanced scene representations. Accurate real-time intraoperative 3D perception\nwill allow algorithmic assistants to directly control one or more robotic\ninstruments and/or robotic cameras. Toward these goals, we are building a\nsynchronized multi-viewpoint, multi-sensor robotic surgery system by\nintegrating high-performance vision components and upgrading the da Vinci\nResearch Kit control logic. This short paper reports a functional summary of\nour setup and elaborates on its potential impacts in research and future\nclinical practice. By fully open-sourcing our system, we will enable the\nresearch community to reproduce our setup, improve it, and develop powerful\nalgorithms, effectively boosting clinical translation of cutting-edge research.",
    "pdf_url": "http://arxiv.org/pdf/2505.11142v1",
    "published": "2025-05-16T11:41:27+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11141v2",
    "title": "Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans",
    "authors": [
      "Yansheng Qiu",
      "Li Xiao",
      "Zhaopan Xu",
      "Pengfei Zhou",
      "Zheng Wang",
      "Kaipeng Zhang"
    ],
    "abstract": "The goal of achieving Artificial General Intelligence (AGI) is to imitate\nhumans and surpass them. Models such as OpenAI's o1, o3, and DeepSeek's R1 have\ndemonstrated that large language models (LLMs) with human-like reasoning\ncapabilities exhibit exceptional performance and are being gradually integrated\ninto multimodal large language models (MLLMs). However, whether these models\npossess capabilities comparable to humans in handling reasoning tasks remains\nunclear at present. In this paper, we propose Human-Aligned Bench, a benchmark\nfor fine-grained alignment of multimodal reasoning with human performance.\nSpecifically, we collected 9,794 multimodal questions that solely rely on\ncontextual reasoning, including bilingual (Chinese and English) multimodal\nquestions and pure text-based questions, encompassing four question types:\nvisual reasoning, definition judgment, analogical reasoning, and logical\njudgment. More importantly, each question is accompanied by human success rates\nand options that humans are prone to choosing incorrectly. Extensive\nexperiments on the Human-Aligned Bench reveal notable differences between the\nperformance of current MLLMs in multimodal reasoning and human performance. The\nfindings on our benchmark provide insights into the development of the\nnext-generation models.",
    "pdf_url": "http://arxiv.org/pdf/2505.11141v2",
    "published": "2025-05-16T11:41:19+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.13506v1",
    "title": "EcoSafeRAG: Efficient Security through Context Analysis in Retrieval-Augmented Generation",
    "authors": [
      "Ruobing Yao",
      "Yifei Zhang",
      "Shuang Song",
      "Neng Gao",
      "Chenyang Tu"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) compensates for the static knowledge\nlimitations of Large Language Models (LLMs) by integrating external knowledge,\nproducing responses with enhanced factual correctness and query-specific\ncontextualization. However, it also introduces new attack surfaces such as\ncorpus poisoning at the same time. Most of the existing defense methods rely on\nthe internal knowledge of the model, which conflicts with the design concept of\nRAG. To bridge the gap, EcoSafeRAG uses sentence-level processing and\nbait-guided context diversity detection to identify malicious content by\nanalyzing the context diversity of candidate documents without relying on LLM\ninternal knowledge. Experiments show EcoSafeRAG delivers state-of-the-art\nsecurity with plug-and-play deployment, simultaneously improving clean-scenario\nRAG performance while maintaining practical operational costs (relatively\n1.2$\\times$ latency, 48\\%-80\\% token reduction versus Vanilla RAG).",
    "pdf_url": "http://arxiv.org/pdf/2505.13506v1",
    "published": "2025-05-16T11:40:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11140v1",
    "title": "Scaling Reasoning can Improve Factuality in Large Language Models",
    "authors": [
      "Mike Zhang",
      "Johannes Bjerva",
      "Russa Biswas"
    ],
    "abstract": "Recent studies on large language model (LLM) reasoning capabilities have\ndemonstrated promising improvements in model performance by leveraging a\nlengthy thinking process and additional computational resources during\ninference, primarily in tasks involving mathematical reasoning (Muennighoff et\nal., 2025). However, it remains uncertain if longer reasoning chains inherently\nenhance factual accuracy, particularly beyond mathematical contexts. In this\nwork, we thoroughly examine LLM reasoning within complex open-domain\nquestion-answering (QA) scenarios. We initially distill reasoning traces from\nadvanced, large-scale reasoning models (QwQ-32B and DeepSeek-R1-671B), then\nfine-tune a variety of models ranging from smaller, instruction-tuned variants\nto larger architectures based on Qwen2.5. To enrich reasoning traces, we\nintroduce factual information from knowledge graphs in the form of paths into\nour reasoning traces. Our experimental setup includes four baseline approaches\nand six different instruction-tuned models evaluated across a benchmark of six\ndatasets, encompassing over 22.6K questions. Overall, we carry out 168\nexperimental runs and analyze approximately 1.7 million reasoning traces. Our\nfindings indicate that, within a single run, smaller reasoning models achieve\nnoticeable improvements in factual accuracy compared to their original\ninstruction-tuned counterparts. Moreover, our analysis demonstrates that adding\ntest-time compute and token budgets factual accuracy consistently improves by\n2-8%, further confirming the effectiveness of test-time scaling for enhancing\nperformance and consequently improving reasoning accuracy in open-domain QA\ntasks. We release all the experimental artifacts for further research.",
    "pdf_url": "http://arxiv.org/pdf/2505.11140v1",
    "published": "2025-05-16T11:39:33+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11139v1",
    "title": "Covariance Density Neural Networks",
    "authors": [
      "Om Roy",
      "Yashar Moshfeghi",
      "Keith Smith"
    ],
    "abstract": "Graph neural networks have re-defined how we model and predict on network\ndata but there lacks a consensus on choosing the correct underlying graph\nstructure on which to model signals. CoVariance Neural Networks (VNN) address\nthis issue by using the sample covariance matrix as a Graph Shift Operator\n(GSO). Here, we improve on the performance of VNNs by constructing a Density\nMatrix where we consider the sample Covariance matrix as a quasi-Hamiltonian of\nthe system in the space of random variables. Crucially, using this density\nmatrix as the GSO allows components of the data to be extracted at different\nscales, allowing enhanced discriminability and performance. We show that this\napproach allows explicit control of the stability-discriminability trade-off of\nthe network, provides enhanced robustness to noise compared to VNNs, and\noutperforms them in useful real-life applications where the underlying\ncovariance matrix is informative. In particular, we show that our model can\nachieve strong performance in subject-independent Brain Computer Interface EEG\nmotor imagery classification, outperforming EEGnet while being faster. This\nshows how covariance density neural networks provide a basis for the\nnotoriously difficult task of transferability of BCIs when evaluated on unseen\nindividuals.",
    "pdf_url": "http://arxiv.org/pdf/2505.11139v1",
    "published": "2025-05-16T11:38:13+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11138v1",
    "title": "Non-Ohmic behavior in (Bi$_{1-x}$Sb$_x$)$_2$Te$_3$ by Joule heating",
    "authors": [
      "Sofie Kölling",
      "Daan H. Wielens",
      "İnanç Adagideli",
      "Alexander Brinkman"
    ],
    "abstract": "A prerequisite to using the net spin polarization generated by a source-drain\nbias in three-dimensional topological insulators for spintronic applications,\nis understanding how such a bias alters the transport properties of these\nmaterials. At low temperatures, quantum corrections can dominate the\ntemperature dependence of the resistance. Although a DC bias does not break\ntime-reversal symmetry and is therefore not expected to suppress quantum\ncorrections, an increase of the electron temperature due to Joule heating can\ncause a suppression. This suppression at finite bias can lead to a non-Ohmic\ndifferential resistance in the three-dimensional topological insulator\n(Bi$_{1-x}$Sb$_x$)$_2$Te$_3$, consisting of a zero-bias resistance peak (from\nelectron-electron interactions) and a high-bias background (from weak\nantilocalization). We show that the bias voltage dependence of quantum\ncorrections can be mapped to the temperature dependence, while the heating\neffect on the lattice temperature remains small. When searching for non-Ohmic\neffects due to novel phenomena in three-dimensional topological insulators,\nJoule heating should not be overlooked.",
    "pdf_url": "http://arxiv.org/pdf/2505.11138v1",
    "published": "2025-05-16T11:38:04+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.11137v1",
    "title": "Covariance Symmetries Classification in Multitemporal/Multipass PolSAR Images",
    "authors": [
      "Dehbia Hanis",
      "Luca Pallotta",
      "Augusto Aubry",
      "Aichouche Belhadj-Aissa",
      "Antonio De Maio"
    ],
    "abstract": "A polarimetric synthetic aperture radar (PolSAR) system, which uses multiple\nimages acquired with different polarizations in both transmission and\nreception, has the potential to improve the description and interpretation of\nthe observed scene. This is typically achieved by exploiting the polarimetric\ncovariance or coherence matrix associated with each pixel, which is processed\nto meet a specific goal in Earth observation. This paper presents a design\nframework for selecting the structure of the polarimetric covariance matrix\nthat accurately reflects the symmetry associated with the analyzed pixels. The\nproposed methodology leverages both polarimetric and temporal information from\nmultipass PolSAR images to enhance the retrieval of information from the\nacquired data. To accomplish this, it is assumed that the covariance matrix (of\nthe overall acquired data) is given as the Kronecker product of the temporal\nand polarimetric covariances. An alternating maximization algorithm, known as\nthe flip-flop method, is then developed to estimate both matrices while\nenforcing the symmetry constraint on the polarimetric covariance. Subsequently,\nthe symmetry structure classification is formulated as a multiple hypothesis\ntesting problem, which is solved using model order selection techniques. The\nproposed approach is quantitatively assessed on simulated data, showing its\nadvantages over its competitor, which does not exploit temporal correlations.\nFor example, it reaches accuracies of 94.6% and 92.0% for the reflection and\nazimuth symmetry classes, respectively, while the competitor achieves 72.5% and\n72.6% under the same simulation conditions. Finally, the effectiveness of the\nproposed framework is further demonstrated using measured RADARSAT-2 data,\ncorroborating the results obtained from the simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.11137v1",
    "published": "2025-05-16T11:36:36+00:00",
    "categories": [
      "eess.SP",
      "stat.AP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11136v1",
    "title": "Reinforcement Learning for AMR Charging Decisions: The Impact of Reward and Action Space Design",
    "authors": [
      "Janik Bischoff",
      "Alexandru Rinciog",
      "Anne Meyer"
    ],
    "abstract": "We propose a novel reinforcement learning (RL) design to optimize the\ncharging strategy for autonomous mobile robots in large-scale block stacking\nwarehouses. RL design involves a wide array of choices that can mostly only be\nevaluated through lengthy experimentation. Our study focuses on how different\nreward and action space configurations, ranging from flexible setups to more\nguided, domain-informed design configurations, affect the agent performance.\nUsing heuristic charging strategies as a baseline, we demonstrate the\nsuperiority of flexible, RL-based approaches in terms of service times.\nFurthermore, our findings highlight a trade-off: While more open-ended designs\nare able to discover well-performing strategies on their own, they may require\nlonger convergence times and are less stable, whereas guided configurations\nlead to a more stable learning process but display a more limited\ngeneralization potential. Our contributions are threefold. First, we extend\nSLAPStack, an open-source, RL-compatible simulation-framework to accommodate\ncharging strategies. Second, we introduce a novel RL design for tackling the\ncharging strategy problem. Finally, we introduce several novel adaptive\nbaseline heuristics and reproducibly evaluate the design using a Proximal\nPolicy Optimization agent and varying different design configurations, with a\nfocus on reward.",
    "pdf_url": "http://arxiv.org/pdf/2505.11136v1",
    "published": "2025-05-16T11:33:29+00:00",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11135v1",
    "title": "Scalability of Reinforcement Learning Methods for Dispatching in Semiconductor Frontend Fabs: A Comparison of Open-Source Models with Real Industry Datasets",
    "authors": [
      "Patrick Stöckermann",
      "Henning Südfeld",
      "Alessandro Immordino",
      "Thomas Altenmüller",
      "Marc Wegmann",
      "Martin Gebser",
      "Konstantin Schekotihin",
      "Georg Seidel",
      "Chew Wye Chan",
      "Fei Fei Zhang"
    ],
    "abstract": "Benchmark datasets are crucial for evaluating approaches to scheduling or\ndispatching in the semiconductor industry during the development and deployment\nphases. However, commonly used benchmark datasets like the Minifab or SMT2020\nlack the complex details and constraints found in real-world scenarios. To\nmitigate this shortcoming, we compare open-source simulation models with a real\nindustry dataset to evaluate how optimization methods scale with different\nlevels of complexity. Specifically, we focus on Reinforcement Learning methods,\nperforming optimization based on policy-gradient and Evolution Strategies. Our\nresearch provides insights into the effectiveness of these optimization methods\nand their applicability to realistic semiconductor frontend fab simulations. We\nshow that our proposed Evolution Strategies-based method scales much better\nthan a comparable policy-gradient-based approach. Moreover, we identify the\nselection and combination of relevant bottleneck tools to control by the agent\nas crucial for an efficient optimization. For the generalization across\ndifferent loading scenarios and stochastic tool failure patterns, we achieve\nadvantages when utilizing a diverse training dataset. While the overall\napproach is computationally expensive, it manages to scale well with the number\nof CPU cores used for training. For the real industry dataset, we achieve an\nimprovement of up to 4% regarding tardiness and up to 1% regarding throughput.\nFor the less complex open-source models Minifab and SMT2020, we observe\ndouble-digit percentage improvement in tardiness and single digit percentage\nimprovement in throughput by use of Evolution Strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11135v1",
    "published": "2025-05-16T11:32:29+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11572v1",
    "title": "ASR-FAIRBENCH: Measuring and Benchmarking Equity Across Speech Recognition Systems",
    "authors": [
      "Anand Rai",
      "Satyam Rahangdale",
      "Utkarsh Anand",
      "Animesh Mukherjee"
    ],
    "abstract": "Automatic Speech Recognition (ASR) systems have become ubiquitous in everyday\napplications, yet significant disparities in performance across diverse\ndemographic groups persist. In this work, we introduce the ASR-FAIRBENCH\nleaderboard which is designed to assess both the accuracy and equity of ASR\nmodels in real-time. Leveraging the Meta's Fair-Speech dataset, which captures\ndiverse demographic characteristics, we employ a mixed-effects Poisson\nregression model to derive an overall fairness score. This score is integrated\nwith traditional metrics like Word Error Rate (WER) to compute the Fairness\nAdjusted ASR Score (FAAS), providing a comprehensive evaluation framework. Our\napproach reveals significant performance disparities in SOTA ASR models across\ndemographic groups and offers a benchmark to drive the development of more\ninclusive ASR technologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11572v1",
    "published": "2025-05-16T11:31:31+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.11134v1",
    "title": "Towards Robust Spiking Neural Networks:Mitigating Heterogeneous Training Vulnerability via Dominant Eigencomponent Projection",
    "authors": [
      "Desong Zhang",
      "Jia Hu",
      "Geyong Min"
    ],
    "abstract": "Spiking Neural Networks (SNNs) process information via discrete spikes,\nenabling them to operate at remarkably low energy levels. However, our\nexperimental observations reveal a striking vulnerability when SNNs are trained\nusing the mainstream method--direct encoding combined with backpropagation\nthrough time (BPTT): even a single backward pass on data drawn from a slightly\ndifferent distribution can lead to catastrophic network collapse. Our\ntheoretical analysis attributes this vulnerability to the repeated inputs\ninherent in direct encoding and the gradient accumulation characteristic of\nBPTT, which together produce an exceptional large Hessian spectral radius. To\naddress this challenge, we develop a hyperparameter-free method called Dominant\nEigencomponent Projection (DEP). By orthogonally projecting gradients to\nprecisely remove their dominant components, DEP effectively reduces the Hessian\nspectral radius, thereby preventing SNNs from settling into sharp minima.\nExtensive experiments demonstrate that DEP not only mitigates the vulnerability\nof SNNs to heterogeneous data poisoning, but also significantly enhances\noverall robustness compared to key baselines, providing strong support for\nsafer and more reliable SNN deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.11134v1",
    "published": "2025-05-16T11:29:49+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11133v1",
    "title": "Event disturbance rejection: a case study",
    "authors": [
      "Alessandro Cecconi",
      "Michelangelo Bin",
      "Rodolphe Sepulchre",
      "Lorenzo Marconi"
    ],
    "abstract": "This article introduces the problem of robust event disturbance rejection.\nInspired by the design principle of linear output regulation, a control\nstructure based on excitable systems is proposed. Unlike the linear case,\ncontraction of the closed-loop system must be enforced through specific input\nsignals. This induced contraction enables a steady-state analysis similar to\nthe linear case. Thanks to the excitable nature of the systems, the focus\nshifts from precise trajectory tracking to the regulation of discrete events,\nsuch as spikes. The study emphasizes rejecting events rather than trajectories\nand demonstrates the robustness of the approach, even under mismatches between\nthe controller and the exosystem. This work is a first step towards developing\na design principle for event regulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11133v1",
    "published": "2025-05-16T11:27:36+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11132v1",
    "title": "Fairness-aware Anomaly Detection via Fair Projection",
    "authors": [
      "Feng Xiao",
      "Xiaoying Tang",
      "Jicong Fan"
    ],
    "abstract": "Unsupervised anomaly detection is a critical task in many high-social-impact\napplications such as finance, healthcare, social media, and cybersecurity,\nwhere demographics involving age, gender, race, disease, etc, are used\nfrequently. In these scenarios, possible bias from anomaly detection systems\ncan lead to unfair treatment for different groups and even exacerbate social\nbias. In this work, first, we thoroughly analyze the feasibility and necessary\nassumptions for ensuring group fairness in unsupervised anomaly detection.\nSecond, we propose a novel fairness-aware anomaly detection method FairAD. From\nthe normal training data, FairAD learns a projection to map data of different\ndemographic groups to a common target distribution that is simple and compact,\nand hence provides a reliable base to estimate the density of the data. The\ndensity can be directly used to identify anomalies while the common target\ndistribution ensures fairness between different groups. Furthermore, we propose\na threshold-free fairness metric that provides a global view for model's\nfairness, eliminating dependence on manual threshold selection. Experiments on\nreal-world benchmarks demonstrate that our method achieves an improved\ntrade-off between detection accuracy and fairness under both balanced and\nskewed data across different groups.",
    "pdf_url": "http://arxiv.org/pdf/2505.11132v1",
    "published": "2025-05-16T11:26:00+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11131v2",
    "title": "One Image is Worth a Thousand Words: A Usability Preservable Text-Image Collaborative Erasing Framework",
    "authors": [
      "Feiran Li",
      "Qianqian Xu",
      "Shilong Bao",
      "Zhiyong Yang",
      "Xiaochun Cao",
      "Qingming Huang"
    ],
    "abstract": "Concept erasing has recently emerged as an effective paradigm to prevent\ntext-to-image diffusion models from generating visually undesirable or even\nharmful content. However, current removal methods heavily rely on manually\ncrafted text prompts, making it challenging to achieve a high erasure\n(efficacy) while minimizing the impact on other benign concepts (usability). In\nthis paper, we attribute the limitations to the inherent gap between the text\nand image modalities, which makes it hard to transfer the intricately entangled\nconcept knowledge from text prompts to the image generation process. To address\nthis, we propose a novel solution by directly integrating visual supervision\ninto the erasure process, introducing the first text-image Collaborative\nConcept Erasing (Co-Erasing) framework. Specifically, Co-Erasing describes the\nconcept jointly by text prompts and the corresponding undesirable images\ninduced by the prompts, and then reduces the generating probability of the\ntarget concept through negative guidance. This approach effectively bypasses\nthe knowledge gap between text and image, significantly enhancing erasure\nefficacy. Additionally, we design a text-guided image concept refinement\nstrategy that directs the model to focus on visual features most relevant to\nthe specified text concept, minimizing disruption to other benign concepts.\nFinally, comprehensive experiments suggest that Co-Erasing outperforms\nstate-of-the-art erasure approaches significantly with a better trade-off\nbetween efficacy and usability. Codes are available at\nhttps://github.com/Ferry-Li/Co-Erasing.",
    "pdf_url": "http://arxiv.org/pdf/2505.11131v2",
    "published": "2025-05-16T11:25:50+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11130v1",
    "title": "A Direct Diabatic States Construction Method with Consistent Orbitals for Valence and Rydberg States",
    "authors": [
      "Jiamin Jin",
      "Zexing Qu",
      "Chungen Liu"
    ],
    "abstract": "This work presents a novel methodology termed Direct Diabatic States\nConstruction (DDSC), which integrates fragment wavefunctions into an\nanti-symmetric wavefunction for the entire system. Using a fragment-localized\nstate-consistent molecular orbital (FL-SC MO), this approach enables direct\nconstruction of all diabatic states at the same root. Each diabatic state is\nformed as a linear combination of a set of diabatic configurations. The\nvalidity and effectiveness of DDSC have been demonstrated through its\napplication to the LiH molecule. The results show that this method is suitable\nfor constructing both valence and Rydberg diabatic states. One of the key\nadvantages of DDSC is its ability to directly compute diabatic couplings, which\ncan be converted to non-adiabatic coupling (NAC) vectors along the reaction\ncoordinate. The DDSC method efficiently builds the diabatic potential energy\nmatrix (DPEM), especially for systems with clear fragment partitions and weak\ninter-fragment interactions, such as charge transfer reactions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11130v1",
    "published": "2025-05-16T11:24:19+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11129v1",
    "title": "PhiNet v2: A Mask-Free Brain-Inspired Vision Foundation Model from Video",
    "authors": [
      "Makoto Yamada",
      "Kian Ming A. Chai",
      "Ayoub Rhim",
      "Satoki Ishikawa",
      "Mohammad Sabokrou",
      "Yao-Hung Hubert Tsai"
    ],
    "abstract": "Recent advances in self-supervised learning (SSL) have revolutionized\ncomputer vision through innovative architectures and learning objectives, yet\nthey have not fully leveraged insights from biological visual processing\nsystems. Recently, a brain-inspired SSL model named PhiNet was proposed; it is\nbased on a ResNet backbone and operates on static image inputs with strong\naugmentation. In this paper, we introduce PhiNet v2, a novel Transformer-based\narchitecture that processes temporal visual input (that is, sequences of\nimages) without relying on strong augmentation. Our model leverages variational\ninference to learn robust visual representations from continuous input streams,\nsimilar to human visual processing. Through extensive experimentation, we\ndemonstrate that PhiNet v2 achieves competitive performance compared to\nstate-of-the-art vision foundation models, while maintaining the ability to\nlearn from sequential input without strong data augmentation. This work\nrepresents a significant step toward more biologically plausible computer\nvision systems that process visual information in a manner more closely aligned\nwith human cognitive processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.11129v1",
    "published": "2025-05-16T11:23:30+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11128v2",
    "title": "What's Inside Your Diffusion Model? A Score-Based Riemannian Metric to Explore the Data Manifold",
    "authors": [
      "Simone Azeglio",
      "Arianna Di Bernardo"
    ],
    "abstract": "Recent advances in diffusion models have demonstrated their remarkable\nability to capture complex image distributions, but the geometric properties of\nthe learned data manifold remain poorly understood. We address this gap by\nintroducing a score-based Riemannian metric that leverages the Stein score\nfunction from diffusion models to characterize the intrinsic geometry of the\ndata manifold without requiring explicit parameterization. Our approach defines\na metric tensor in the ambient space that stretches distances perpendicular to\nthe manifold while preserving them along tangential directions, effectively\ncreating a geometry where geodesics naturally follow the manifold's contours.\nWe develop efficient algorithms for computing these geodesics and demonstrate\ntheir utility for both interpolation between data points and extrapolation\nbeyond the observed data distribution. Through experiments on synthetic data\nwith known geometry, Rotated MNIST, and complex natural images via Stable\nDiffusion, we show that our score-based geodesics capture meaningful\ntransformations that respect the underlying data distribution. Our method\nconsistently outperforms baseline approaches on perceptual metrics (LPIPS) and\ndistribution-level metrics (FID, KID), producing smoother, more realistic image\ntransitions. These results reveal the implicit geometric structure learned by\ndiffusion models and provide a principled way to navigate the manifold of\nnatural images through the lens of Riemannian geometry.",
    "pdf_url": "http://arxiv.org/pdf/2505.11128v2",
    "published": "2025-05-16T11:19:57+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11127v1",
    "title": "Risk theory in a finite customer-pool setting",
    "authors": [
      "Michel Mandjes",
      "Daniël Rutgers"
    ],
    "abstract": "This paper investigates an insurance model with a finite number of major\nclients and a large number of small clients, where the dynamics of the latter\ngroup are modeled by a spectrally positive L\\'evy process. We begin by\nanalyzing this general model, in which the inter-arrival times are\nexponentially distributed (though not identically), and derive the closed-form\nLaplace transform of the ruin probability. Next, we examine a simplified\nversion of the model involving only the major clients, and explore the tail\nasymptotics of the ruin probability, focusing on the cases where the claim\nsizes follow phase-type or regularly varying distributions. Finally, we derive\nthe distribution of the overshoot over an exponentially distributed initial\nreserve, expressed in terms of its Laplace-Stieltjes transform.",
    "pdf_url": "http://arxiv.org/pdf/2505.11127v1",
    "published": "2025-05-16T11:19:53+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11126v1",
    "title": "FedDuA: Doubly Adaptive Federated Learning",
    "authors": [
      "Shokichi Takakura",
      "Seng Pei Liew",
      "Satoshi Hasegawa"
    ],
    "abstract": "Federated learning is a distributed learning framework where clients\ncollaboratively train a global model without sharing their raw data. FedAvg is\na popular algorithm for federated learning, but it often suffers from slow\nconvergence due to the heterogeneity of local datasets and anisotropy in the\nparameter space. In this work, we formalize the central server optimization\nprocedure through the lens of mirror descent and propose a novel framework,\ncalled FedDuA, which adaptively selects the global learning rate based on both\ninter-client and coordinate-wise heterogeneity in the local updates. We prove\nthat our proposed doubly adaptive step-size rule is minimax optimal and provide\na convergence analysis for convex objectives. Although the proposed method does\nnot require additional communication or computational cost on clients,\nextensive numerical experiments show that our proposed framework outperforms\nbaselines in various settings and is robust to the choice of hyperparameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.11126v1",
    "published": "2025-05-16T11:15:27+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11125v1",
    "title": "GraphOracle: A Foundation Model for Knowledge Graph Reasoning",
    "authors": [
      "Enjun Du",
      "Siyi Liu",
      "Yongqi Zhang"
    ],
    "abstract": "Foundation models have demonstrated remarkable capabilities across various\ndomains, but developing analogous models for knowledge graphs presents unique\nchallenges due to their dynamic nature and the need for cross-domain reasoning.\nTo address these issues, we introduce \\textbf{\\textsc{GraphOracle}}, a\nrelation-centric foundation model that unifies reasoning across knowledge\ngraphs by converting them into Relation-Dependency Graphs (RDG), explicitly\nencoding compositional patterns with fewer edges than prior methods. A\nquery-dependent attention mechanism is further developed to learn inductive\nrepresentations for both relations and entities. Pre-training on diverse\nknowledge graphs, followed by minutes-level fine-tuning, enables effective\ngeneralization to unseen entities, relations, and entire graphs. Through\ncomprehensive experiments on 31 diverse benchmarks spanning transductive,\ninductive, and cross-domain settings, we demonstrate consistent\nstate-of-the-art performance with minimal adaptation, improving the prediction\nperformance by up to 35\\% compared to the strongest baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.11125v1",
    "published": "2025-05-16T11:14:57+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11124v1",
    "title": "Topological Quantum Molecular Dynamics",
    "authors": [
      "Yujuan Xie",
      "Ruoxi Liu",
      "Bing Gu"
    ],
    "abstract": "We develop a unified quantum geometric framework to understand reactive\nquantum dynamics. The critical roles of the quantum geometry of adiabatic\nelectronic states in both adiabatic and non-adiabatic quantum dynamics are\nunveiled. A numerically exact, divergence-free topological quantum molecular\ndynamics method is developed through a discrete local trivialization of the\nprojected electronic Hilbert space bundle over the nuclear configuration space.\nIn this approach, the singular electronic quantum geometric tensor-Abelian for\nadiabatic dynamics and non-Abelian for non-adiabatic dynamics-is fully encoded\nin the global electronic overlap matrix. With numerical illustrations, it is\ndemonstrated that atomic motion-whether adiabatic or non-adiabatic-is governed\nnot only by the variation in electronic energies with nuclear configurations\n(potential energy surface) but also by the variation in electronic states\n(electronic quantum geometry).",
    "pdf_url": "http://arxiv.org/pdf/2505.11124v1",
    "published": "2025-05-16T11:14:34+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11123v1",
    "title": "Conditioning Matters: Training Diffusion Policies is Faster Than You Think",
    "authors": [
      "Zibin Dong",
      "Yicheng Liu",
      "Yinchuan Li",
      "Hang Zhao",
      "Jianye Hao"
    ],
    "abstract": "Diffusion policies have emerged as a mainstream paradigm for building\nvision-language-action (VLA) models. Although they demonstrate strong robot\ncontrol capabilities, their training efficiency remains suboptimal. In this\nwork, we identify a fundamental challenge in conditional diffusion policy\ntraining: when generative conditions are hard to distinguish, the training\nobjective degenerates into modeling the marginal action distribution, a\nphenomenon we term loss collapse. To overcome this, we propose Cocos, a simple\nyet general solution that modifies the source distribution in the conditional\nflow matching to be condition-dependent. By anchoring the source distribution\naround semantics extracted from condition inputs, Cocos encourages stronger\ncondition integration and prevents the loss collapse. We provide theoretical\njustification and extensive empirical results across simulation and real-world\nbenchmarks. Our method achieves faster convergence and higher success rates\nthan existing approaches, matching the performance of large-scale pre-trained\nVLAs using significantly fewer gradient steps and parameters. Cocos is\nlightweight, easy to implement, and compatible with diverse policy\narchitectures, offering a general-purpose improvement to diffusion policy\ntraining.",
    "pdf_url": "http://arxiv.org/pdf/2505.11123v1",
    "published": "2025-05-16T11:14:22+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11122v2",
    "title": "Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining",
    "authors": [
      "Yu Shi",
      "Yitong Duan",
      "Jian Li"
    ],
    "abstract": "Alpha factor mining is pivotal in quantitative investment for identifying\npredictive signals from complex financial data. While traditional formulaic\nalpha mining relies on human expertise, contemporary automated methods, such as\nthose based on genetic programming or reinforcement learning, often struggle\nwith search inefficiency or yield alpha factors that are difficult to\ninterpret. This paper introduces a novel framework that integrates Large\nLanguage Models (LLMs) with Monte Carlo Tree Search (MCTS) to overcome these\nlimitations. Our framework leverages the LLM's instruction-following and\nreasoning capability to iteratively generate and refine symbolic alpha formulas\nwithin an MCTS-driven exploration. A key innovation is the guidance of MCTS\nexploration by rich, quantitative feedback from financial backtesting of each\ncandidate factor, enabling efficient navigation of the vast search space.\nFurthermore, a frequent subtree avoidance mechanism is introduced to enhance\nsearch diversity and prevent formulaic homogenization, further improving\nperformance. Experimental results on real-world stock market data demonstrate\nthat our LLM-based framework outperforms existing methods by mining alphas with\nsuperior predictive accuracy and trading performance. The resulting formulas\nare also more amenable to human interpretation, establishing a more effective\nand efficient paradigm for formulaic alpha mining.",
    "pdf_url": "http://arxiv.org/pdf/2505.11122v2",
    "published": "2025-05-16T11:14:17+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11121v1",
    "title": "Redundancy-Aware Pretraining of Vision-Language Foundation Models in Remote Sensing",
    "authors": [
      "Mathis Jürgen Adler",
      "Leonard Hackel",
      "Gencer Sumbul",
      "Begüm Demir"
    ],
    "abstract": "The development of foundation models through pretraining of vision-language\nmodels (VLMs) has recently attracted great attention in remote sensing (RS).\nVLM pretraining aims to learn image and language alignments from a large number\nof image-text pairs. Each pretraining image is often associated with multiple\ncaptions containing redundant information due to repeated or semantically\nsimilar phrases, resulting in increased pretraining and inference time. To\novercome this, we introduce a weighted feature aggregation (WFA) strategy for\nVLM pretraining in RS. Our strategy aims to extract and exploit complementary\ninformation from multiple captions per image while reducing redundancies\nthrough feature aggregation with importance weighting. To calculate adaptive\nimportance weights for different captions of each image, we propose two\ntechniques: (i) non-parametric uniqueness and (ii) learning-based attention. In\nthe first technique, importance weights are calculated based on the bilingual\nevaluation understudy (BLEU) scores of the captions to emphasize unique\nsentences and reduce the influence of repetitive ones. In the second technique,\nimportance weights are learned through an attention mechanism instead of\nrelying on hand-crafted features. The effectiveness of the proposed WFA\nstrategy with the two techniques is analyzed in terms of downstream performance\non text-to-image retrieval in RS. Experimental results show that the proposed\nstrategy enables efficient and effective pretraining of VLMs in RS. Based on\nthe experimental analysis, we derive guidelines for selecting appropriate\ntechniques depending on downstream task requirements and resource constraints.\nThe code of this work is publicly available at\nhttps://git.tu-berlin.de/rsim/redundacy-aware-rs-vlm.",
    "pdf_url": "http://arxiv.org/pdf/2505.11121v1",
    "published": "2025-05-16T11:08:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11571v1",
    "title": "Quantum Coherence and Chaotic Dynamics: Guiding Molecular Machines Toward Low-Entropy States",
    "authors": [
      "Andrei Tudor Patrascu"
    ],
    "abstract": "Quantum coherence profoundly alters classical thermodynamic expectations by\nmodifying the structure and accessibility of probability distributions.\nClassically, transitions to lower-entropy states (local second-law violations)\nare exponentially suppressed, as lower-entropy configurations have fewer\navailable microstates and are statistically improbable. However, introducing\nquantum coherence and structured quantum interference among semiclassical\ntrajectories significantly changes this scenario. Quantum coherence reduces\nlocal entropy by establishing correlations among states that are classically\nindependent, effectively restructuring probability amplitudes to channel\ntransitions toward otherwise improbable low-entropy states. We analyze this\nphenomenon explicitly within the framework of semiclassical approximations,\nemploying the Van Vleck-Gutzwiller propagator to quantify how interference\nterms arising from coherent superpositions modify classical fluctuation\ntheorems. We demonstrate that quantum coherence, especially when combined with\nchaos-assisted dynamical tunneling, greatly enhances the probability of\ntransitions to low-entropy configurations, creating pronounced counter-ergodic\neffects. Furthermore, by considering purification of mixed quantum states, we\npropose methodologies for deliberately engineering quantum phases among\ninterfering pathways. This phase engineering can explicitly enhance\ncoherence-driven transitions into lower-entropy states, providing a novel\nthermodynamic resource. Finally, we explore the feasibility of molecular-scale\nquantum machines exploiting these principles, highlighting their potential\napplications in quantum thermodynamics and quantum biology for performing\nuseful work through coherence-mediated entropy reduction.",
    "pdf_url": "http://arxiv.org/pdf/2505.11571v1",
    "published": "2025-05-16T11:03:51+00:00",
    "categories": [
      "quant-ph",
      "hep-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11120v2",
    "title": "Search for dwarf galaxies in the southwestern sector of the Local cosmic void",
    "authors": [
      "A. A. Popova",
      "I. D. Karachentsev"
    ],
    "abstract": "We performed a search for new dwarf galaxies in a direction towards the\nsouthwestern part of the Local Void using the data on DESI Legacy Imaging\nSurveys. In a sky area of $\\sim1000$ square degrees, we discovered 12\ncandidates to nearby dwarfs with a high confidence. Four of them are probable\nnew companions to the nearby galaxy M 83 and others are isolated objects. We\nfound also 20 nearby dwarf candidates with a low confidence. Almost all of the\ndetected galaxies are classified as late type dwarfs. A new cluster of bluish\nstars with an angular diameter of 0.9$^{\\prime}$ is revealed by us at a high\ngalactic latitude, $b = -29^{\\circ}$. Being at a distance of $\\sim70$ kpc, it\ncan be a globular cluster associated with the Milky Way stellar stream\nSagittarius dSph or a new ultra-faint satellite of the Milky Way.",
    "pdf_url": "http://arxiv.org/pdf/2505.11120v2",
    "published": "2025-05-16T11:03:42+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11119v1",
    "title": "Predicting Student Dropout Risk With A Dual-Modal Abrupt Behavioral Changes Approach",
    "authors": [
      "Jiabei Cheng",
      "Zhen-Qun Yang",
      "Jiannong Cao",
      "Yu Yang",
      "Xinzhe Zheng"
    ],
    "abstract": "Timely prediction of students at high risk of dropout is critical for early\nintervention and improving educational outcomes. However, in offline\neducational settings, poor data quality, limited scale, and high heterogeneity\noften hinder the application of advanced machine learning models. Furthermore,\nwhile educational theories provide valuable insights into dropout phenomena,\nthe lack of quantifiable metrics for key indicators limits their use in\ndata-driven modeling. Through data analysis and a review of educational\nliterature, we identified abrupt changes in student behavior as key early\nsignals of dropout risk. To address this, we propose the Dual-Modal Multiscale\nSliding Window (DMSW) Model, which integrates academic performance and\nbehavioral data to dynamically capture behavior patterns using minimal data.\nThe DMSW model improves prediction accuracy by 15% compared to traditional\nmethods, enabling educators to identify high-risk students earlier, provide\ntimely support, and foster a more inclusive learning environment. Our analysis\nhighlights key behavior patterns, offering practical insights for preventive\nstrategies and tailored support. These findings bridge the gap between theory\nand practice in dropout prediction, giving educators an innovative tool to\nenhance student retention and outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2505.11119v1",
    "published": "2025-05-16T11:02:55+00:00",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11118v1",
    "title": "Prototype sub-wavelength structure anti-reflection coating on alumina filters for ground-based CMB telescopes",
    "authors": [
      "Kosuke Aizawa",
      "Ryosuke Akizawa",
      "Scott Cray",
      "Shaul Hanany",
      "Shotaro Kawano",
      "Jürgen Koch",
      "Kuniaki Konishi",
      "Rex Lam",
      "Tomotake Matsumura",
      "Haruyuki Sakurai",
      "Ryota Takaku"
    ],
    "abstract": "We present designs and fabrication of sub-wavelength anti-reflection (AR)\nstructures on alumina for infrared absorptive filters with passbands near 30,\n125, and 250 GHz. These bands are widely used by ground-based instruments\nmeasuring the cosmic microwave background radiation. The designs are tuned to\nprovide reflectance of 2% or less for fractional bandwidths between 51% and\n72%, with each of the three primary bands containing two sub-bands. We make the\nsub-wavelength structures (SWS), which resemble a two-dimensional array of\npyramids, using laser ablation. We measure the shapes of the fabricated\npyramids and show that for incidence angles up to 20 degrees the predicted\nin-band average reflectance is 2% or less, in agreement with the design. The\nband average instrumental polarization is less than $3\\times 10^{-3}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11118v1",
    "published": "2025-05-16T11:01:24+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.17050v1",
    "title": "Towards Robust Evaluation of STEM Education: Leveraging MLLMs in Project-Based Learning",
    "authors": [
      "Yanhao Jia",
      "Xinyi Wu",
      "Qinglin Zhang",
      "Yiran Qin",
      "Luwei Xiao",
      "Shuai Zhao"
    ],
    "abstract": "Project-Based Learning (PBL) involves a variety of highly correlated\nmultimodal data, making it a vital educational approach within STEM\ndisciplines. With the rapid development of multimodal large language models\n(MLLMs), researchers have begun exploring their potential to enhance tasks such\nas information retrieval, knowledge comprehension, and data generation in\neducational settings. However, existing benchmarks fall short in providing both\na free-form output structure and a rigorous human expert validation process,\nlimiting their effectiveness in evaluating real-world educational tasks.\nAdditionally, few methods have developed automated pipelines to assist with the\ncomplex responsibilities of teachers leveraging MLLMs, largely due to model\nhallucination and instability, which lead to unreliable implementation. To\naddress this gap, we introduce PBLBench, a novel benchmark designed to evaluate\ncomplex reasoning grounded in domain-specific knowledge and long-context\nunderstanding, thereby challenging models with tasks that closely resemble\nthose handled by human experts. To establish reliable ground truth, we adopt\nthe Analytic Hierarchy Process (AHP), utilizing expert-driven pairwise\ncomparisons to derive structured and weighted evaluation criteria. We assess\nthe performance of 15 leading MLLMs/LLMs using PBLBench and demonstrate that\neven the most advanced models achieve only 59% rank accuracy, underscoring the\nsignificant challenges presented by this benchmark. We believe PBLBench will\nserve as a catalyst for the development of more capable AI agents, ultimately\naiming to alleviate teacher workload and enhance educational productivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.17050v1",
    "published": "2025-05-16T11:01:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.CY",
      "cs.MM"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11117v3",
    "title": "Dual-Balancing for Physics-Informed Neural Networks",
    "authors": [
      "Chenhong Zhou",
      "Jie Chen",
      "Zaifeng Yang",
      "Ching Eng Png"
    ],
    "abstract": "Physics-informed neural networks (PINNs) have emerged as a new learning\nparadigm for solving partial differential equations (PDEs) by enforcing the\nconstraints of physical equations, boundary conditions (BCs), and initial\nconditions (ICs) into the loss function. Despite their successes, vanilla PINNs\nstill suffer from poor accuracy and slow convergence due to the intractable\nmulti-objective optimization issue. In this paper, we propose a novel\nDual-Balanced PINN (DB-PINN), which dynamically adjusts loss weights by\nintegrating inter-balancing and intra-balancing to alleviate two imbalance\nissues in PINNs. Inter-balancing aims to mitigate the gradient imbalance\nbetween PDE residual loss and condition-fitting losses by determining an\naggregated weight that offsets their gradient distribution discrepancies.\nIntra-balancing acts on condition-fitting losses to tackle the imbalance in\nfitting difficulty across diverse conditions. By evaluating the fitting\ndifficulty based on the loss records, intra-balancing can allocate the\naggregated weight proportionally to each condition loss according to its\nfitting difficulty level. We further introduce a robust weight update strategy\nto prevent abrupt spikes and arithmetic overflow in instantaneous weight values\ncaused by large loss variances, enabling smooth weight updating and stable\ntraining. Extensive experiments demonstrate that DB-PINN achieves significantly\nsuperior performance than those popular gradient-based weighting methods in\nterms of convergence speed and prediction accuracy. Our code and supplementary\nmaterial are available at https://github.com/chenhong-zhou/DualBalanced-PINNs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11117v3",
    "published": "2025-05-16T11:00:54+00:00",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11116v1",
    "title": "Planar Velocity Estimation for Fast-Moving Mobile Robots Using Event-Based Optical Flow",
    "authors": [
      "Liam Boyle",
      "Jonas Kühne",
      "Nicolas Baumann",
      "Niklas Bastuck",
      "Michele Magno"
    ],
    "abstract": "Accurate velocity estimation is critical in mobile robotics, particularly for\ndriver assistance systems and autonomous driving. Wheel odometry fused with\nInertial Measurement Unit (IMU) data is a widely used method for velocity\nestimation; however, it typically requires strong assumptions, such as non-slip\nsteering, or complex vehicle dynamics models that do not hold under varying\nenvironmental conditions like slippery surfaces. We introduce an approach to\nvelocity estimation that is decoupled from wheel-to-surface traction\nassumptions by leveraging planar kinematics in combination with optical flow\nfrom event cameras pointed perpendicularly at the ground. The asynchronous\nmicro-second latency and high dynamic range of event cameras make them highly\nrobust to motion blur, a common challenge in vision-based perception techniques\nfor autonomous driving. The proposed method is evaluated through in-field\nexperiments on a 1:10 scale autonomous racing platform and compared to precise\nmotion capture data, demonstrating not only performance on par with the\nstate-of-the-art Event-VIO method but also a 38.3 % improvement in lateral\nerror. Qualitative experiments at highway speeds of up to 32 m/s further\nconfirm the effectiveness of our approach, indicating significant potential for\nreal-world deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.11116v1",
    "published": "2025-05-16T11:00:33+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11115v1",
    "title": "Dependence of the intensity of the nonwave component of EUV waves on coronal magnetic field configuration",
    "authors": [
      "Yuwei Li",
      "J. H. Guo",
      "Y. W. Ni",
      "Z. Y. Zhang",
      "P. F. Chen"
    ],
    "abstract": "Context. Mounting evidence has shown that EUV waves consist of a fast-mode\nmagnetohydrodynamic (MHD) wave (or shock wave) followed by a slower nonwave\ncomponent, as predicted by the magnetic fieldline stretching model. However,\nnot all observed events display both wavefronts, particularly the slower\nnonwave component. Even in case that the slower nonwave component is present,\nthe intensity distribution often exhibits strong anisotropy.\n  Aims. This study is intended to unveil the formation condition of the slower\nnonwave component of EUV waves. Methods. We analyzed the EUV wave event on 8\nMarch 2019, and compared the EUV wave intensity map with the extrapolation\ncoronal potential magnetic field. Data-inspired MHD simulation was also\nperformed.\n  Results. Two types of EUV waves are identified, and the slower nonwave\ncomponent exhibits strong anisotropy. By reconstructing 3D coronal magnetic\nfields, we found that the slower nonwave component of EUV waves is more\npronounced in the regions where magnetic fields are backward-inclined, which is\nfurther reproduced by our MHD simulations.\n  Conclusions. The anisotropy of the slower nonwave component of EUV waves is\nstrongly related to the magnetic configuration, with backward-inclined field\nlines favoring their appearance. The more the field lines are forward-inclined,\nthe weaker such wavelike fronts are.",
    "pdf_url": "http://arxiv.org/pdf/2505.11115v1",
    "published": "2025-05-16T10:58:08+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11114v1",
    "title": "Directional transport and nonlinear localization of light in a one-dimensional driven-dissipative photonic lattice",
    "authors": [
      "Tony Mathew Blessan",
      "Bastián Real",
      "Camille Druelle",
      "Clarisse Fournier",
      "Alberto Muñoz de las Heras",
      "Alejandro González-Tudela",
      "Isabelle Sagnes",
      "Abdelmounaim Harouri",
      "Luc Le Gratiet",
      "Aristide Lemaître",
      "Sylvain Ravets",
      "Jacqueline Bloch",
      "Clément Hainaut",
      "Alberto Amo"
    ],
    "abstract": "Photonic lattices facilitate band structure engineering, supporting both\nlocalized and extended modes through their geometric design. However, greater\ncontrol over these modes can be achieved by taking advantage of the\ninterference effect between external drives with precisely tuned phases and\nphotonic modes within the lattice. In this work, we build on this principle to\ndemonstrate optical switching, directed light propagation and site-specific\nlocalization in a one-dimensional photonic lattice of coupled microresonators\nby resonantly driving the system with a coherent field of controlled phase.\nImportantly, our experimental results provide direct evidence that increased\ndriving power acts as a tuning parameter enabling nonlinear localization at\nfrequencies previously inaccessible in the linear regime. These findings open\nnew avenues for controlling light propagation and localization in lattices with\nmore elaborate band structures.",
    "pdf_url": "http://arxiv.org/pdf/2505.11114v1",
    "published": "2025-05-16T10:54:48+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.11113v1",
    "title": "A Schrödinger operator with confining potential having quadratic growth",
    "authors": [
      "Chiara Alessi",
      "Lorenzo Brasco",
      "Michele Miranda Jr"
    ],
    "abstract": "We study the spectral properties of a Schr\\\"odinger operator, in presence of\na confining potential given by the distance squared from a fixed compact\npotential well. We prove continuity estimates on both the eigenvalues and the\neigenstates, lower bounds on the ground state energy, regularity and\nintegrability properties of eigenstates. We also get explicit decay estimates\nat infinity, by means of elementary nonlinear methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.11113v1",
    "published": "2025-05-16T10:53:47+00:00",
    "categories": [
      "math.AP",
      "math.SP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11112v1",
    "title": "Relativistic regularized kappa distributions",
    "authors": [
      "Linh Han Than",
      "Klaus Scherer",
      "Horst Fichtner"
    ],
    "abstract": "The special relativistic generalization of isotropic regularized kappa\ndistributions is derived and compared to that of the original Olbertian (or\nstandard) kappa distributions. It is demonstrated that for the latter the kappa\nparameter is even stronger limited than in the non-relativistic case, while for\nthe former all positive kappa values remain possible. After a derivation of the\nnon-relativistic limits, the pressures of the distributions are studied as a\nspecific case of the moments of both the relativistic standard and regularized\nkappa distributions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11112v1",
    "published": "2025-05-16T10:53:07+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11111v1",
    "title": "FairSHAP: Preprocessing for Fairness Through Attribution-Based Data Augmentation",
    "authors": [
      "Lin Zhu",
      "Yijun Bian",
      "Lei You"
    ],
    "abstract": "Ensuring fairness in machine learning models is critical, particularly in\nhigh-stakes domains where biased decisions can lead to serious societal\nconsequences. Existing preprocessing approaches generally lack transparent\nmechanisms for identifying which features or instances are responsible for\nunfairness. This obscures the rationale behind data modifications. We introduce\nFairSHAP, a novel pre-processing framework that leverages Shapley value\nattribution to improve both individual and group fairness. FairSHAP identifies\nfairness-critical instances in the training data using an interpretable measure\nof feature importance, and systematically modifies them through instance-level\nmatching across sensitive groups. This process reduces discriminative risk - an\nindividual fairness metric - while preserving data integrity and model\naccuracy. We demonstrate that FairSHAP significantly improves demographic\nparity and equality of opportunity across diverse tabular datasets, achieving\nfairness gains with minimal data perturbation and, in some cases, improved\npredictive performance. As a model-agnostic and transparent method, FairSHAP\nintegrates seamlessly into existing machine learning pipelines and provides\nactionable insights into the sources of bias.Our code is on\nhttps://github.com/youlei202/FairSHAP.",
    "pdf_url": "http://arxiv.org/pdf/2505.11111v1",
    "published": "2025-05-16T10:48:19+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11110v1",
    "title": "Deepfake Forensic Analysis: Source Dataset Attribution and Legal Implications of Synthetic Media Manipulation",
    "authors": [
      "Massimiliano Cassia",
      "Luca Guarnera",
      "Mirko Casu",
      "Ignazio Zangara",
      "Sebastiano Battiato"
    ],
    "abstract": "Synthetic media generated by Generative Adversarial Networks (GANs) pose\nsignificant challenges in verifying authenticity and tracing dataset origins,\nraising critical concerns in copyright enforcement, privacy protection, and\nlegal compliance. This paper introduces a novel forensic framework for\nidentifying the training dataset (e.g., CelebA or FFHQ) of GAN-generated images\nthrough interpretable feature analysis. By integrating spectral transforms\n(Fourier/DCT), color distribution metrics, and local feature descriptors\n(SIFT), our pipeline extracts discriminative statistical signatures embedded in\nsynthetic outputs. Supervised classifiers (Random Forest, SVM, XGBoost) achieve\n98-99% accuracy in binary classification (real vs. synthetic) and multi-class\ndataset attribution across diverse GAN architectures (StyleGAN, AttGAN, GDWCT,\nStarGAN, and StyleGAN2). Experimental results highlight the dominance of\nfrequency-domain features (DCT/FFT) in capturing dataset-specific artifacts,\nsuch as upsampling patterns and spectral irregularities, while color histograms\nreveal implicit regularization strategies in GAN training. We further examine\nlegal and ethical implications, showing how dataset attribution can address\ncopyright infringement, unauthorized use of personal data, and regulatory\ncompliance under frameworks like GDPR and California's AB 602. Our framework\nadvances accountability and governance in generative modeling, with\napplications in digital forensics, content moderation, and intellectual\nproperty litigation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11110v1",
    "published": "2025-05-16T10:47:18+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11109v1",
    "title": "MAVOS-DD: Multilingual Audio-Video Open-Set Deepfake Detection Benchmark",
    "authors": [
      "Florinel-Alin Croitoru",
      "Vlad Hondru",
      "Marius Popescu",
      "Radu Tudor Ionescu",
      "Fahad Shahbaz Khan",
      "Mubarak Shah"
    ],
    "abstract": "We present the first large-scale open-set benchmark for multilingual\naudio-video deepfake detection. Our dataset comprises over 250 hours of real\nand fake videos across eight languages, with 60% of data being generated. For\neach language, the fake videos are generated with seven distinct deepfake\ngeneration models, selected based on the quality of the generated content. We\norganize the training, validation and test splits such that only a subset of\nthe chosen generative models and languages are available during training, thus\ncreating several challenging open-set evaluation setups. We perform experiments\nwith various pre-trained and fine-tuned deepfake detectors proposed in recent\nliterature. Our results show that state-of-the-art detectors are not currently\nable to maintain their performance levels when tested in our open-set\nscenarios. We publicly release our data and code at:\nhttps://huggingface.co/datasets/unibuc-cs/MAVOS-DD.",
    "pdf_url": "http://arxiv.org/pdf/2505.11109v1",
    "published": "2025-05-16T10:42:30+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11108v2",
    "title": "Personalized Robotic Object Rearrangement from Scene Context",
    "authors": [
      "Kartik Ramachandruni",
      "Sonia Chernova"
    ],
    "abstract": "Object rearrangement is a key task for household robots requiring\npersonalization without explicit instructions, meaningful object placement in\nenvironments occupied with objects, and generalization to unseen objects and\nnew environments. To facilitate research addressing these challenges, we\nintroduce PARSEC, an object rearrangement benchmark for learning user\norganizational preferences from observed scene context to place objects in a\npartially arranged environment. PARSEC is built upon a novel dataset of 110K\nrearrangement examples crowdsourced from 72 users, featuring 93 object\ncategories and 15 environments. To better align with real-world organizational\nhabits, we propose ContextSortLM, an LLM-based personalized rearrangement model\nthat handles flexible user preferences by explicitly accounting for objects\nwith multiple valid placement locations when placing items in partially\narranged environments. We evaluate ContextSortLM and existing personalized\nrearrangement approaches on the PARSEC benchmark and complement these findings\nwith a crowdsourced evaluation of 108 online raters ranking model predictions\nbased on alignment with user preferences. Our results indicate that\npersonalized rearrangement models leveraging multiple scene context sources\nperform better than models relying on a single context source. Moreover,\nContextSortLM outperforms other models in placing objects to replicate the\ntarget user's arrangement and ranks among the top two in all three environment\ncategories, as rated by online evaluators. Importantly, our evaluation\nhighlights challenges associated with modeling environment semantics across\ndifferent environment categories and provides recommendations for future work.",
    "pdf_url": "http://arxiv.org/pdf/2505.11108v2",
    "published": "2025-05-16T10:40:44+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11107v1",
    "title": "Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token Level Granularity",
    "authors": [
      "Chan-Jan Hsu",
      "Davide Buffelli",
      "Jamie McGowan",
      "Feng-Ting Liao",
      "Yi-Chang Chen",
      "Sattar Vakili",
      "Da-shan Shiu"
    ],
    "abstract": "Recent advances in large language models (LLMs) have demonstrated the power\nof reasoning through self-generated chains of thought. Multiple reasoning\nagents can collaborate to raise joint reasoning quality above individual\noutcomes. However, such agents typically interact in a turn-based manner,\ntrading increased latency for improved quality. In this paper, we propose Group\nThink--a single LLM that acts as multiple concurrent reasoning agents, or\nthinkers. With shared visibility into each other's partial generation progress,\nGroup Think introduces a new concurrent-reasoning paradigm in which multiple\nreasoning trajectories adapt dynamically to one another at the token level. For\nexample, a reasoning thread may shift its generation mid-sentence upon\ndetecting that another thread is better positioned to continue. This\nfine-grained, token-level collaboration enables Group Think to reduce redundant\nreasoning and improve quality while achieving significantly lower latency.\nMoreover, its concurrent nature allows for efficient utilization of idle\ncomputational resources, making it especially suitable for edge inference,\nwhere very small batch size often underutilizes local~GPUs. We give a simple\nand generalizable modification that enables any existing LLM to perform Group\nThink on a local GPU. We also present an evaluation strategy to benchmark\nreasoning latency and empirically demonstrate latency improvements using\nopen-source LLMs that were not explicitly trained for Group Think. We hope this\nwork paves the way for future LLMs to exhibit more sophisticated and more\nefficient collaborative behavior for higher quality generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11107v1",
    "published": "2025-05-16T10:40:35+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11106v1",
    "title": "Inferring the Most Similar Variable-length Subsequences between Multidimensional Time Series",
    "authors": [
      "Thanadej Rattanakornphan",
      "Piyanon Charoenpoonpanich",
      "Chainarong Amornbunchornvej"
    ],
    "abstract": "Finding the most similar subsequences between two multidimensional time\nseries has many applications: e.g. capturing dependency in stock market or\ndiscovering coordinated movement of baboons. Considering one pattern occurring\nin one time series, we might be wondering whether the same pattern occurs in\nanother time series with some distortion that might have a different length.\nNevertheless, to the best of our knowledge, there is no efficient framework\nthat deals with this problem yet. In this work, we propose an algorithm that\nprovides the exact solution of finding the most similar multidimensional\nsubsequences between time series where there is a difference in length both\nbetween time series and between subsequences. The algorithm is built based on\ntheoretical guarantee of correctness and efficiency. The result in simulation\ndatasets illustrated that our approach not just only provided correct solution,\nbut it also utilized running time only quarter of time compared against the\nbaseline approaches. In real-world datasets, it extracted the most similar\nsubsequences even faster (up to 20 times faster against baseline methods) and\nprovided insights regarding the situation in stock market and following\nrelations of multidimensional time series of baboon movement. Our approach can\nbe used for any time series. The code and datasets of this work are provided\nfor the public use.",
    "pdf_url": "http://arxiv.org/pdf/2505.11106v1",
    "published": "2025-05-16T10:39:46+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "stat.ME"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11105v1",
    "title": "On the Turán number of the expansion of the $t$-fan",
    "authors": [
      "Xin Cheng",
      "Dániel Gerbner",
      "Hilal Hama Karim",
      "Junpeng Zhou"
    ],
    "abstract": "The $t$-fan is the graph on $2t+1$ vertices consisting of $t$ triangles which\nintersect at exactly one common vertex. For a given graph $F$, the\n$r$-expansion $F^r$ of $F$ is the $r$-uniform hypergraph obtained from $F$ by\nadding $r-2$ distinct new vertices to each edge of $F$. We determine the\nTur\\'an number of the 3-expansion of the $t$-fan for sufficiently large $n$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11105v1",
    "published": "2025-05-16T10:37:21+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11104v1",
    "title": "Multilevel Optimization: Geometric Coarse Models and Convergence Analysis",
    "authors": [
      "Ferdinand Vanmaele",
      "Yara Elshiaty",
      "Stefania Petra"
    ],
    "abstract": "We study multilevel techniques, commonly used in PDE multigrid literature, to\nsolve structured optimization problems. For a given hierarchy of levels, we\nformulate a coarse model that approximates the problem at each level and\nprovides a descent direction for the fine-grid objective using fewer variables.\nUnlike common algebraic approaches, we assume the objective function and its\ngradient can be evaluated at each level. Under the assumptions of strong\nconvexity and gradient L-smoothness, we analyze convergence and extend the\nmethod to box-constrained optimization. Large-scale numerical experiments on a\ndiscrete tomography problem show that the multilevel approach converges rapidly\nwhen far from the solution and performs competitively with state-of-the-art\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2505.11104v1",
    "published": "2025-05-16T10:35:13+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11103v2",
    "title": "Propagation of Love waves in linear elastic isotropic Cosserat materials",
    "authors": [
      "Marius Apetrii",
      "Emilian Bulgariu",
      "Ionel-Dumitrel Ghiba",
      "Hassam Khan",
      "Patrizio Neff"
    ],
    "abstract": "We investigate the propagation of Love waves in an isotropic half-space\nmodelled as a linear {elastic isotropic} Cosserat material. To this aim, we\nshow that a method commonly used to study Rayleigh wave propagation is also\napplicable to the analysis of Love wave propagation. This approach is based on\nthe explicit solution of an algebraic Riccati equation, which operates\nindependently of the traditional Stroh formalism. The method provides a\nstraightforward numerical algorithm to determine the wave amplitudes and\nspeed{s}. Beyond its numerical simplicity, the method guarantees the existence\nand uniqueness of a subsonic wave speed, addressing a problem that remains\nunresolved in most Cosserat solids generalised {continua} theories. Although\noften overlooked, proving the existence of an admissible solution is, in fact,\nthe key point that validates or invalidates the entire analytical approach used\nto derive the equation determining the wave speed. Interestingly, it is\nconfirmed that the Love waves do not need the artificial introduction of a\nsurface layer, as indicated in the literature.",
    "pdf_url": "http://arxiv.org/pdf/2505.11103v2",
    "published": "2025-05-16T10:34:06+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11102v2",
    "title": "On the Nature of the Fundamental Plasma Excitation in a Plasmonic Crystal",
    "authors": [
      "A. R. Khisameeva",
      "A. Shuvaev",
      "A. A. Zabolotnykh",
      "A. S. Astrakhantseva",
      "D. A. Khudaiberdiev",
      "A. Pimenov",
      "I. V. Kukushkin",
      "V. M. Muravev"
    ],
    "abstract": "We report on the experimental study of the spectrum of plasma excitations in\na plasmonic crystal fabricated from the two-dimensional electron system in an\nAlGaAs/GaAs semiconductor heterostructure. We perform a comprehensive research\non the mode frequency and relaxation as a function of the gate width across\ndifferent plasmonic crystal periods. Importantly, we develop an analytical\napproach that accurately describes the behavior of plasma excitations in\nplasmonic crystals, providing new insights into the fundamental physics of\nplasmonic systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11102v2",
    "published": "2025-05-16T10:33:19+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.11101v1",
    "title": "Nonlocal dielectric properties of water: the role of electronic delocalisation",
    "authors": [
      "Darka Labavić",
      "Florian N. Brünig",
      "Roland R. Netz",
      "Marie-Laure Bocquet",
      "Hélène Berthoumieux"
    ],
    "abstract": "The nonlocal dielectric properties of liquid water are studied in the context\nof {\\it ab initio} molecular dynamics simulations based on density functional\ntheory. We calculate the dielectric response from the charge structure factor\nof the liquid using the fluctuation-dissipation theorem. We show that the\ndielectric response function of {\\it ab initio} simulations differs\nsignificantly from that of classical force-fields, both qualitatively and\nquantitatively. In particular, it exhibits a larger amplitude and a wider range\nof responding wave numbers. We suggest that the difference is due to the\nlocalisation of the electronic charge density inherent in classical force files\nand Wannier post-treatment of DFT densities. The localised charge models do not\nreproduce the shape of the response function even for $q$ corresponding to\nintermolecular distances, and could lead to a significant underestimation of\nthe dielectric response of the liquid by a factor of 10.",
    "pdf_url": "http://arxiv.org/pdf/2505.11101v1",
    "published": "2025-05-16T10:31:46+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11100v1",
    "title": "Bidirectional Distillation: A Mixed-Play Framework for Multi-Agent Generalizable Behaviors",
    "authors": [
      "Lang Feng",
      "Jiahao Lin",
      "Dong Xing",
      "Li Zhang",
      "De Ma",
      "Gang Pan"
    ],
    "abstract": "Population-population generalization is a challenging problem in multi-agent\nreinforcement learning (MARL), particularly when agents encounter unseen\nco-players. However, existing self-play-based methods are constrained by the\nlimitation of inside-space generalization. In this study, we propose\nBidirectional Distillation (BiDist), a novel mixed-play framework, to overcome\nthis limitation in MARL. BiDist leverages knowledge distillation in two\nalternating directions: forward distillation, which emulates the historical\npolicies' space and creates an implicit self-play, and reverse distillation,\nwhich systematically drives agents towards novel distributions outside the\nknown policy space in a non-self-play manner. In addition, BiDist operates as a\nconcise and efficient solution without the need for the complex and costly\nstorage of past policies. We provide both theoretical analysis and empirical\nevidence to support BiDist's effectiveness. Our results highlight its\nremarkable generalization ability across a variety of cooperative, competitive,\nand social dilemma tasks, and reveal that BiDist significantly diversifies the\npolicy distribution space. We also present comprehensive ablation studies to\nreinforce BiDist's effectiveness and key success factors. Source codes are\navailable in the supplementary material.",
    "pdf_url": "http://arxiv.org/pdf/2505.11100v1",
    "published": "2025-05-16T10:31:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11099v2",
    "title": "HyMamba: Mamba with Hybrid Geometry-Feature Coupling for Efficient Point Cloud Classification",
    "authors": [
      "Bin Liu",
      "Chunyang Wang",
      "Xuelian Liu",
      "Bo Xiao",
      "Guan Xi"
    ],
    "abstract": "Point cloud classification is one of the essential technologies for achieving\nintelligent perception of 3D environments by machines, its core challenge is to\nefficiently extract local and global features. Mamba leverages state space\nmodels (SSMs) for global point cloud modeling. Although prior Mamba-based point\ncloud processing methods pay attention to the limitation of its flattened\nsequence modeling mechanism in fusing local and global features, the critical\nissue of weakened local geometric relevance caused by decoupling geometric\nstructures and features in the input patches remains not fully revealed, and\nboth jointly limit local feature extraction. Therefore, we propose HyMamba, a\ngeometry and feature coupled Mamba framework featuring: (1) Geometry-Feature\nCoupled Pooling (GFCP), which achieves physically interpretable geometric\ninformation coupling by dynamically aggregating adjacent geometric information\ninto local features; (2) Collaborative Feature Enhancer (CoFE), which enhances\nsparse signal capture through cross-path feature hybridization while\neffectively integrating global and local contexts. We conducted extensive\nexperiments on ModelNet40 and ScanObjectNN datasets. The results demonstrate\nthat the proposed model achieves superior classification performance,\nparticularly on the ModelNet40, where it elevates accuracy to 95.99% with\nmerely 0.03M additional parameters. Furthermore, it attains 98.9% accuracy on\nthe ModelNetFewShot dataset, validating its robust generalization capabilities\nunder sparse samples. Our code and weights are available at\nhttps://github.com/L1277471578/HyMamba",
    "pdf_url": "http://arxiv.org/pdf/2505.11099v2",
    "published": "2025-05-16T10:30:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11098v2",
    "title": "Pedestrian mobility citizen science complements expert mapping for enhancing inclusive neighborhood placemaking",
    "authors": [
      "Ferran Larroya",
      "Josep Perelló",
      "Roger Paez",
      "Manuela Valtchanova"
    ],
    "abstract": "Cities are complex systems that demand integrated approaches, with increasing\nattention focused on the neighborhood level. This study examines the interplay\nbetween expert-based mapping and citizen science in the Primer de Maig\nneighborhood of Granollers, Catalonia, Spain--an area marked by poor-quality\npublic spaces and long-standing socio-economic challenges. Seventy-two\nresidents were organized into 19 groups to record their pedestrian mobility\nwhile engaging in protocolized playful social actions. Their GPS identified\nopportunity units for meaningful public space activation. Although 56% of\nobserved actions occurred within expert-defined units, the remaining 44% took\nplace elsewhere. Clustering analysis of geo-located action stops revealed seven\ndistinct clusters, highlighting overlooked areas with significant social\npotential. These findings underscore the complementarity of top-down and\nbottom-up approaches, demonstrating how citizen science and community science\napproaches enriches urban diagnostics by integrating subjective,\ncommunity-based perspectives in public space placemaking and informing\ninclusive, adaptive sustainable urban transformation strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11098v2",
    "published": "2025-05-16T10:28:51+00:00",
    "categories": [
      "physics.soc-ph",
      "cs.CY",
      "physics.comp-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11097v1",
    "title": "Verifiably Forgotten? Gradient Differences Still Enable Data Reconstruction in Federated Unlearning",
    "authors": [
      "Fuyao Zhang",
      "Wenjie Li",
      "Yurong Hao",
      "Xinyu Yan",
      "Yang Cao",
      "Wei Yang Bryan Lim"
    ],
    "abstract": "Federated Unlearning (FU) has emerged as a critical compliance mechanism for\ndata privacy regulations, requiring unlearned clients to provide verifiable\nProof of Federated Unlearning (PoFU) to auditors upon data removal requests.\nHowever, we uncover a significant privacy vulnerability: when gradient\ndifferences are used as PoFU, honest-but-curious auditors may exploit\nmathematical correlations between gradient differences and forgotten samples to\nreconstruct the latter. Such reconstruction, if feasible, would face three key\nchallenges: (i) restricted auditor access to client-side data, (ii) limited\nsamples derivable from individual PoFU, and (iii) high-dimensional redundancy\nin gradient differences. To overcome these challenges, we propose Inverting\nGradient difference to Forgotten data (IGF), a novel learning-based\nreconstruction attack framework that employs Singular Value Decomposition (SVD)\nfor dimensionality reduction and feature extraction. IGF incorporates a\ntailored pixel-level inversion model optimized via a composite loss that\ncaptures both structural and semantic cues. This enables efficient and\nhigh-fidelity reconstruction of large-scale samples, surpassing existing\nmethods. To counter this novel attack, we design an orthogonal obfuscation\ndefense that preserves PoFU verification utility while preventing sensitive\nforgotten data reconstruction. Experiments across multiple datasets validate\nthe effectiveness of the attack and the robustness of the defense. The code is\navailable at https://anonymous.4open.science/r/IGF.",
    "pdf_url": "http://arxiv.org/pdf/2505.11097v1",
    "published": "2025-05-16T10:28:30+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11096v1",
    "title": "Determining the utility of ultrafast nonlinear contrast enhanced and super resolution ultrasound for imaging microcirculation in the human small intestine",
    "authors": [
      "Clotilde Vié",
      "Martina Tashkova",
      "James Burn",
      "Matthieu Toulemonde",
      "Jipeng Yan",
      "Jingwen Zhu",
      "Cameron A. B. Smith",
      "Biao Huang",
      "Su Yan",
      "Kevin G. Murphy",
      "Gary Frost",
      "Meng-Xing Tang"
    ],
    "abstract": "The regulation of intestinal blood flow is critical to gastrointestinal\nfunction. Imaging the intestinal mucosal micro-circulation in vivo has the\npotential to provide new insight into the gut physiology and pathophysiology.\nWe aimed to determine whether ultrafast contrast enhanced ultrasound (CEUS) and\nsuper-resolution ultrasound localisation microscopy (SRUS/ULM) could be a\nuseful tool for imaging the small intestine microcirculation in vivo\nnon-invasively and for detecting changes in blood flow in the duodenum.\nUltrafast CEUS and SRUS/ULM were used to image the small intestinal\nmicrocirculation in a cohort of 20 healthy volunteers (BMI<25). Participants\nwere imaged while conscious and either having been fasted, or following\ningestion of a liquid meal or water control, or under acute stress. For the\nfirst time we have performed ultrafast CEUS and ULM on the human small\nintestine, providing unprecedented resolution images of the intestinal\nmicrocirculation. We evaluated flow speed inside small vessels in healthy\nvolunteers (2.78 +/- 0.05 mm/s, mean +/- SEM) and quantified changes in the\nperfusion of this microcirculation in response to nutrient ingestion. Perfusion\nof the microvasculature of the intestinal mucosa significantly increased\npost-prandially (36.2% +/- 12.2%, mean +/- SEM, p<0.05). The feasibility of 3D\nSRUS/ULM was also demonstrated. This study demonstrates the potential utility\nof ultrafast CEUS for assessing perfusion and detecting changes in blood flow\nin the duodenum. SRUS/ULM also proved a useful tool to image the microvascular\nblood flow in vivo non-invasively and to evaluate blood speed inside the\nmicrovasculature of the human small intestine.",
    "pdf_url": "http://arxiv.org/pdf/2505.11096v1",
    "published": "2025-05-16T10:28:17+00:00",
    "categories": [
      "physics.med-ph",
      "eess.SP"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11095v1",
    "title": "Towards Better Evaluation for Generated Patent Claims",
    "authors": [
      "Lekang Jiang",
      "Pascal A Scherz",
      "Stephan Goetz"
    ],
    "abstract": "Patent claims define the scope of protection and establish the legal\nboundaries of an invention. Drafting these claims is a complex and\ntime-consuming process that usually requires the expertise of skilled patent\nattorneys, which can form a large access barrier for many small enterprises. To\nsolve these challenges, researchers have investigated the use of large language\nmodels (LLMs) for automating patent claim generation. However, existing studies\nhighlight inconsistencies between automated evaluation metrics and human expert\nassessments. To bridge this gap, we introduce Patent-CE, the first\ncomprehensive benchmark for evaluating patent claims. Patent-CE includes\ncomparative claim evaluations annotated by patent experts, focusing on five key\ncriteria: feature completeness, conceptual clarity, terminology consistency,\nlogical linkage, and overall quality. Additionally, we propose PatClaimEval, a\nnovel multi-dimensional evaluation method specifically designed for patent\nclaims. Our experiments demonstrate that PatClaimEval achieves the highest\ncorrelation with human expert evaluations across all assessment criteria among\nall tested metrics. This research provides the groundwork for more accurate\nevaluations of automated patent claim generation systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11095v1",
    "published": "2025-05-16T10:27:16+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11094v1",
    "title": "Blockchain-Enabled Decentralized Privacy-Preserving Group Purchasing for Energy Plans",
    "authors": [
      "Sid Chi-Kin Chau",
      "Yue Zhou"
    ],
    "abstract": "Retail energy markets are increasingly consumer-oriented, thanks to a growing\nnumber of energy plans offered by a plethora of energy suppliers, retailers and\nintermediaries. To maximize the benefits of competitive retail energy markets,\ngroup purchasing is an emerging paradigm that aggregates consumers' purchasing\npower by coordinating switch decisions to specific energy providers for\ndiscounted energy plans. Traditionally, group purchasing is mediated by a\ntrusted third-party, which suffers from the lack of privacy and transparency.\nIn this paper, we introduce a novel paradigm of decentralized\nprivacy-preserving group purchasing, empowered by privacy-preserving blockchain\nand secure multi-party computation, to enable users to form a coalition for\ncoordinated switch decisions in a decentralized manner, without a trusted\nthird-party. The coordinated switch decisions are determined by a competitive\nonline algorithm, based on users' private consumption data and current energy\nplan tariffs. Remarkably, no private user consumption data will be revealed to\nothers in the online decision-making process, which is carried out in a\ntransparently verifiable manner to eliminate frauds from dishonest users and\nsupports fair mutual compensations by sharing the switching costs to\nincentivize group purchasing. We implemented our decentralized group purchasing\nsolution as a smart contract on Solidity-supported blockchain platform (e.g.,\nEthereum), and provide extensive empirical evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11094v1",
    "published": "2025-05-16T10:26:15+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11093v1",
    "title": "Lasso and Partially-Rotated Designs",
    "authors": [
      "Rares-Darius Buhai"
    ],
    "abstract": "We consider the sparse linear regression model $\\mathbf{y} = X \\beta\n+\\mathbf{w}$, where $X \\in \\mathbb{R}^{n \\times d}$ is the design, $\\beta \\in\n\\mathbb{R}^{d}$ is a $k$-sparse secret, and $\\mathbf{w} \\sim N(0, I_n)$ is the\nnoise. Given input $X$ and $\\mathbf{y}$, the goal is to estimate $\\beta$. In\nthis setting, the Lasso estimate achieves prediction error $O(k \\log d / \\gamma\nn)$, where $\\gamma$ is the restricted eigenvalue (RE) constant of $X$ with\nrespect to $\\mathrm{support}(\\beta)$. In this paper, we introduce a new\n$\\textit{semirandom}$ family of designs -- which we call\n$\\textit{partially-rotated}$ designs -- for which the RE constant with respect\nto the secret is bounded away from zero even when a subset of the design\ncolumns are arbitrarily correlated among themselves.\n  As an example of such a design, suppose we start with some arbitrary $X$, and\nthen apply a random rotation to the columns of $X$ indexed by\n$\\mathrm{support}(\\beta)$. Let $\\lambda_{\\min}$ be the smallest eigenvalue of\n$\\frac{1}{n} X_{\\mathrm{support}(\\beta)}^\\top X_{\\mathrm{support}(\\beta)}$,\nwhere $X_{\\mathrm{support}(\\beta)}$ is the restriction of $X$ to the columns\nindexed by $\\mathrm{support}(\\beta)$. In this setting, our results imply that\nLasso achieves prediction error $O(k \\log d / \\lambda_{\\min} n)$ with high\nprobability. This prediction error bound is independent of the arbitrary\ncolumns of $X$ not indexed by $\\mathrm{support}(\\beta)$, and is as good as if\nall of these columns were perfectly well-conditioned.\n  Technically, our proof reduces to showing that matrices with a certain\ndeterministic property -- which we call $\\textit{restricted normalized\northogonality}$ (RNO) -- lead to RE constants that are independent of a subset\nof the matrix columns. This property is similar but incomparable with the\nrestricted orthogonality condition of [CT05].",
    "pdf_url": "http://arxiv.org/pdf/2505.11093v1",
    "published": "2025-05-16T10:25:08+00:00",
    "categories": [
      "math.ST",
      "cs.DS",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.11092v1",
    "title": "Hydrodynamic limit for some gradient and attractive spin models",
    "authors": [
      "Chiara Franceschini",
      "Patrícia Gonçalves",
      "Kohei Hayashi",
      "Makiko Sasada"
    ],
    "abstract": "We study the hydrodynamic limit for three gradient spin models: generalized\nKipnis-Marchioro-Presutti (KMP), its discrete version and a family of harmonic\nmodels, under symmetric and nearest-neighbor interactions. These three models\nshare some universal properties: occupation variables are unbounded, all these\nprocesses are of gradient type, their invariant measures are product with\nspatially homogeneous weights, and, notably, they are all attractive, meaning\nthat the process preserves the partial order of measures along the dynamics. In\nview of hydrodynamics of large-scale interacting systems, dealing with\nprocesses taking values in unbounded configuration spaces is known to be a\nchallenging problem. In the present paper, we show the hydrodynamic limit for\nall three models listed above in a comprehensive way, and show as a main\nresult, that, under the diffusive time scaling, the hydrodynamic equation is\ngiven by the heat equation with model-dependent diffusion coefficient. Our\nnovelty is showing the attractiveness for each model, which is crucial for the\nproof of hydrodynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.11092v1",
    "published": "2025-05-16T10:24:39+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11091v1",
    "title": "Symmetric generalized numerical semigroups in $\\mathbb{N}^d$ with embedding dimension $2d+1$",
    "authors": [
      "Om Prakash Bhardwaj",
      "Carmelo Cisto"
    ],
    "abstract": "In this article, we classify all symmetric generalized numerical semigroups\nin $\\mathbb{N}^d$ of embedding dimension $2d+1$. Consequently, we show that in\nthis case the property of being symmetric is equivalent to have a unique\nmaximal gap with respect to natural partial order in $\\mathbb{N}^d$. Moreover,\nwe deduce that when $d>1$, there does not exist any generalized numerical\nsemigroup of embedding dimension $2d+1$, which is almost symmetric but not\nsymmetric.",
    "pdf_url": "http://arxiv.org/pdf/2505.11091v1",
    "published": "2025-05-16T10:24:29+00:00",
    "categories": [
      "math.AC",
      "20M14, 11D07"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11090v1",
    "title": "Sufficient conditions for $t$-tough graphs to be Hamiltonian and pancyclic or bipartite",
    "authors": [
      "Xiangge Liu",
      "Caili Jia",
      "Yong Lu",
      "Jiaxu Zhong"
    ],
    "abstract": "The toughness of graph $G$, denoted by $\\tau(G)$, is\n$\\tau(G)=\\min\\{\\frac{|S|}{c(G-S)}:S\\subseteq V(G),c(G-S)\\geq2\\}$ for every\nvertex cut $S$ of $V(G)$ and the number of components of $G$ is denoted by\n$c(G)$. Bondy in 1973, suggested the ``metaconjecture\" that almost any\nnontrivial condition on a graph which implies that the graph is Hamiltonian\nalso implies that the graph is pancyclic. Recently, Benediktovich [Discrete\nApplied Mathematics. 365 (2025) 130--137] confirmed the Bondy's metaconjecture\nfor $t$-tough graphs in the case when $t\\in\\{1;2;3\\}$ in terms of the size, the\nspectral radius and the signless Laplacian spectral radius of the graph. In\nthis paper, we will confirm the Bondy's metaconjecture for $t$-tough graphs in\nthe case when $t\\geq4$ in terms of the size, the spectral radius, the signless\nLaplacian spectral radius, the distance spectral radius and the distance\nsignless Laplacian spectral radius of graphs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11090v1",
    "published": "2025-05-16T10:23:55+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11089v2",
    "title": "Inexact Column Generation for Bayesian Network Structure Learning via Difference-of-Submodular Optimization",
    "authors": [
      "Yiran Yang",
      "Rui Chen"
    ],
    "abstract": "In this paper, we consider a score-based Integer Programming (IP) approach\nfor solving the Bayesian Network Structure Learning (BNSL) problem.\nState-of-the-art BNSL IP formulations suffer from the exponentially large\nnumber of variables and constraints. A standard approach in IP to address such\nchallenges is to employ row and column generation techniques, which dynamically\ngenerate rows and columns, while the complex pricing problem remains a\ncomputational bottleneck for BNSL. For the general class of $\\ell_0$-penalized\nlikelihood scores, we show how the pricing problem can be reformulated as a\ndifference of submodular optimization problem, and how the Difference of Convex\nAlgorithm (DCA) can be applied as an inexact method to efficiently solve the\npricing problems. Empirically, we show that, for continuous Gaussian data, our\nrow and column generation approach yields solutions with higher quality than\nstate-of-the-art score-based approaches, especially when the graph density\nincreases, and achieves comparable performance against benchmark\nconstraint-based and hybrid approaches, even when the graph size increases.",
    "pdf_url": "http://arxiv.org/pdf/2505.11089v2",
    "published": "2025-05-16T10:23:19+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.11088v1",
    "title": "Investigation of the spin dynamics of quantum spin dimers with Dzyaloshinsky-Moriya interaction",
    "authors": [
      "R. Wieser",
      "R. Sánchez Galán"
    ],
    "abstract": "We investigate the ground state configuration and spin dynamics of a quantum\nspin spiral dimer when a magnetic field is applied to one of its constituent\nspins. By adiabatic changing the magnetic field, it is possible to change the\nnon-magnetic ground state to a classical spiral state, which oscillates\nperiodically to its inverted classical spiral state configuration. This\noscillation can be halted at any time, leading to the possibility of\nmanipulating the quantum state and the magnetic configuration of the spin\ndimer. Notably, this idea is not limited to spin dimers and can also be\nextended to quantum spin chains with an even number of spins.",
    "pdf_url": "http://arxiv.org/pdf/2505.11088v1",
    "published": "2025-05-16T10:22:01+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.11087v1",
    "title": "Degeneration of Calabi-Yau metrics and canonical basis",
    "authors": [
      "Yang Li"
    ],
    "abstract": "For polarised degenerations of Calabi-Yau manifolds whose essential skeleton\nhas dimension $1\\leq m\\leq n$, we show that the $C^0$ potential theoretic limit\nof the Calabi-Yau metrics agrees with the non-archimedean Calabi-Yau metric on\nthe Berkovich analytification. Moreover, this limit data can be encoded into\nthe unique minimiser of the Kontorovich functional of an optimal transport\nproblem, under some algebro-geometric assumptions on the existence of a\ncanonical basis of sections for tensor powers of the polarisation line bundle.",
    "pdf_url": "http://arxiv.org/pdf/2505.11087v1",
    "published": "2025-05-16T10:21:15+00:00",
    "categories": [
      "math.DG",
      "math.AG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13505v1",
    "title": "Simulating non-Brownian suspensions with non-homogeneous Navier slip boundary conditions",
    "authors": [
      "Daniela Moreno-Chaparro",
      "Florencio Balboa Usabiaga",
      "Nicolas Moreno",
      "Marco Ellero"
    ],
    "abstract": "Fluid-structure interactions are commonly modeled using no-slip boundary\nconditions. However, small deviations from these conditions can significantly\nalter the dynamics of suspensions and particles, especially at the micro and\nnano scales. This work presents a robust implicit numerical method for\nsimulating non-colloidal suspensions with non-homogeneous Navier slip boundary\nconditions. Our approach is based on a regularized boundary integral\nformulation, enabling accurate and efficient computation of hydrodynamic\ninteractions. This makes the method well-suited for large-scale simulations. We\nvalidate the method by comparing computed drag forces on homogeneous and Janus\nparticles with analytical results. Additionally, we consider the effective\nviscosity of suspensions with varying slip lengths, benchmarking against\navailable analytical no-slip and partial-slip theories.",
    "pdf_url": "http://arxiv.org/pdf/2505.13505v1",
    "published": "2025-05-16T10:18:56+00:00",
    "categories": [
      "cond-mat.soft",
      "physics.flu-dyn"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.11086v1",
    "title": "Analysis of Customer Journeys Using Prototype Detection and Counterfactual Explanations for Sequential Data",
    "authors": [
      "Keita Kinjo"
    ],
    "abstract": "Recently, the proliferation of omni-channel platforms has attracted interest\nin customer journeys, particularly regarding their role in developing marketing\nstrategies. However, few efforts have been taken to quantitatively study or\ncomprehensively analyze them owing to the sequential nature of their data and\nthe complexity involved in analysis. In this study, we propose a novel approach\ncomprising three steps for analyzing customer journeys. First, the distance\nbetween sequential data is defined and used to identify and visualize\nrepresentative sequences. Second, the likelihood of purchase is predicted based\non this distance. Third, if a sequence suggests no purchase, counterfactual\nsequences are recommended to increase the probability of a purchase using a\nproposed method, which extracts counterfactual explanations for sequential\ndata. A survey was conducted, and the data were analyzed; the results revealed\nthat typical sequences could be extracted, and the parts of those sequences\nimportant for purchase could be detected. We believe that the proposed approach\ncan support improvements in various marketing activities.",
    "pdf_url": "http://arxiv.org/pdf/2505.11086v1",
    "published": "2025-05-16T10:17:53+00:00",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11085v1",
    "title": "A Fast Kernel-based Conditional Independence test with Application to Causal Discovery",
    "authors": [
      "Oliver Schacht",
      "Biwei Huang"
    ],
    "abstract": "Kernel-based conditional independence (KCI) testing is a powerful\nnonparametric method commonly employed in causal discovery tasks. Despite its\nflexibility and statistical reliability, cubic computational complexity limits\nits application to large datasets. To address this computational bottleneck, we\npropose \\textit{FastKCI}, a scalable and parallelizable kernel-based\nconditional independence test that utilizes a mixture-of-experts approach\ninspired by embarrassingly parallel inference techniques for Gaussian\nprocesses. By partitioning the dataset based on a Gaussian mixture model over\nthe conditioning variables, FastKCI conducts local KCI tests in parallel,\naggregating the results using an importance-weighted sampling scheme.\nExperiments on synthetic datasets and benchmarks on real-world production data\nvalidate that FastKCI maintains the statistical power of the original KCI test\nwhile achieving substantial computational speedups. FastKCI thus represents a\npractical and efficient solution for conditional independence testing in causal\ninference on large-scale data.",
    "pdf_url": "http://arxiv.org/pdf/2505.11085v1",
    "published": "2025-05-16T10:14:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11084v1",
    "title": "Extremals for Poincaré-Sobolev sharp constants in Steiner symmetric sets",
    "authors": [
      "Lorenzo Brasco",
      "Luca Briani",
      "Francesca Prinari"
    ],
    "abstract": "We prove existence of minimizers for the sharp Poincar\\'e-Sobolev constant in\ngeneral Steiner symmetric sets, in the subcritical and superhomogeneous regime.\nThe sets considered are not necessarily bounded, thus the relevant embeddings\nmay suffer from a lack of compactness. We prove existence by means of an\nelementary compactness method. We also prove an exponential decay at infinity\nfor minimizers, showing that in the case of Steiner symmetric sets the relevant\nestimates only depend on the underlying geometry. Finally, we illustrate the\noptimality of the existence result, by means of some examples.",
    "pdf_url": "http://arxiv.org/pdf/2505.11084v1",
    "published": "2025-05-16T10:14:25+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11083v1",
    "title": "Fault Diagnosis across Heterogeneous Domains via Self-Adaptive Temporal-Spatial Attention and Sample Generation",
    "authors": [
      "Guangqiang Li",
      "M. Amine Atoui",
      "Xiangshun Li"
    ],
    "abstract": "Deep learning methods have shown promising performance in fault diagnosis for\nmultimode process. Most existing studies assume that the collected health state\ncategories from different operating modes are identical. However, in real\nindustrial scenarios, these categories typically exhibit only partial overlap.\nThe incompleteness of the available data and the large distributional\ndifferences between the operating modes pose a significant challenge to\nexisting fault diagnosis methods. To address this problem, a novel fault\ndiagnosis model named self-adaptive temporal-spatial attention network\n(TSA-SAN) is proposed. First, inter-mode mappings are constructed using healthy\ncategory data to generate multimode samples. To enrich the diversity of the\nfault data, interpolation is performed between healthy and fault samples.\nSubsequently, the fault diagnosis model is trained using real and generated\ndata. The self-adaptive instance normalization is established to suppress\nirrelevant information while retaining essential statistical features for\ndiagnosis. In addition, a temporal-spatial attention mechanism is constructed\nto focus on the key features, thus enhancing the generalization ability of the\nmodel. The extensive experiments demonstrate that the proposed model\nsignificantly outperforms the state-of-the-art methods. The code will be\navailable on Github at https://github.com/GuangqiangLi/TSA-SAN.",
    "pdf_url": "http://arxiv.org/pdf/2505.11083v1",
    "published": "2025-05-16T10:14:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11082v3",
    "title": "Complexity of Firefighting on Graphs",
    "authors": [
      "Julius Althoetmar",
      "Jamico Schade",
      "Torben Schürenberg"
    ],
    "abstract": "We consider a pursuit-evasion game that describes the process of\nextinguishing a fire burning on the nodes of an undirected graph. We denote the\nminimum number of firefighters required by $\\text{ffn}(G)$ and provide a\ncharacterization for the graphs with $\\text{ffn}(G)=1$ and $\\text{ffn}(G)=2$ as\nwell as almost sharp bounds for complete binary trees. We show that deciding\nwhether $\\text{ffn}(G) \\leq m$ for given $G$ and $m$ is NP-hard. Furthermore,\nwe show that shortest strategies can have superpolynomial length, leaving open\nwhether the problem is in NP. Based on some plausible conjectures, we also\nprove that this decision problem is neither NP-hard for graphs with bounded\ntreewidth nor for constant $m$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11082v3",
    "published": "2025-05-16T10:13:30+00:00",
    "categories": [
      "cs.CC",
      "cs.DM",
      "05Cxx",
      "F.2.2; G.2.2"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2506.14777v2",
    "title": "WebXAII: an open-source web framework to study human-XAI interaction",
    "authors": [
      "Jules Leguy",
      "Pierre-Antoine Jean",
      "Felipe Torres Figueroa",
      "Sébastien Harispe"
    ],
    "abstract": "This article introduces WebXAII, an open-source web framework designed to\nfacilitate research on human interaction with eXplainable Artificial\nIntelligence (XAI) systems. The field of XAI is rapidly expanding, driven by\nthe growing societal implications of the widespread adoption of AI (and in\nparticular machine learning) across diverse applications. Researchers who study\nthe interaction between humans and XAI techniques typically develop ad hoc\ninterfaces in order to conduct their studies. These interfaces are usually not\nshared alongside the results of the studies, which limits their reusability and\nthe reproducibility of experiments. In response, we design and implement\nWebXAII, a web-based platform that can embody full experimental protocols,\nmeaning that it can present all aspects of the experiment to human participants\nand record their responses. The experimental protocols are translated into a\ncomposite architecture of generic views and modules, which offers a lot of\nflexibility. The architecture is defined in a structured configuration file, so\nthat protocols can be implemented with minimal programming skills. We\ndemonstrate that WebXAII can effectively embody relevant protocols, by\nreproducing the protocol of a state-of-the-art study of the literature.",
    "pdf_url": "http://arxiv.org/pdf/2506.14777v2",
    "published": "2025-05-16T10:12:53+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11081v1",
    "title": "ShiQ: Bringing back Bellman to LLMs",
    "authors": [
      "Pierre Clavier",
      "Nathan Grinsztajn",
      "Raphael Avalos",
      "Yannis Flet-Berliac",
      "Irem Ergun",
      "Omar D. Domingues",
      "Eugene Tarassov",
      "Olivier Pietquin",
      "Pierre H. Richemond",
      "Florian Strub",
      "Matthieu Geist"
    ],
    "abstract": "The fine-tuning of pre-trained large language models (LLMs) using\nreinforcement learning (RL) is generally formulated as direct policy\noptimization. This approach was naturally favored as it efficiently improves a\npretrained LLM, seen as an initial policy. Another RL paradigm, Q-learning\nmethods, has received far less attention in the LLM community while\ndemonstrating major success in various non-LLM RL tasks. In particular,\nQ-learning effectiveness comes from its sample efficiency and ability to learn\noffline, which is particularly valuable given the high computational cost of\nsampling with LLMs. However, naively applying a Q-learning-style update to the\nmodel's logits is ineffective due to the specificity of LLMs. Our core\ncontribution is to derive theoretically grounded loss functions from Bellman\nequations to adapt Q-learning methods to LLMs. To do so, we carefully adapt\ninsights from the RL literature to account for LLM-specific characteristics,\nensuring that the logits become reliable Q-value estimates. We then use this\nloss to build a practical algorithm, ShiQ for Shifted-Q, that supports\noff-policy, token-wise learning while remaining simple to implement. Finally,\nwe evaluate ShiQ on both synthetic data and real-world benchmarks, e.g.,\nUltraFeedback and BFCL-V3, demonstrating its effectiveness in both single-turn\nand multi-turn LLM settings",
    "pdf_url": "http://arxiv.org/pdf/2505.11081v1",
    "published": "2025-05-16T10:12:11+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11080v2",
    "title": "BLEUBERI: BLEU is a surprisingly effective reward for instruction following",
    "authors": [
      "Yapei Chang",
      "Yekyung Kim",
      "Michael Krumdick",
      "Amir Zadeh",
      "Chuan Li",
      "Chris Tanner",
      "Mohit Iyyer"
    ],
    "abstract": "Reward models are central to aligning LLMs with human preferences, but they\nare costly to train, requiring large-scale human-labeled preference data and\npowerful pretrained LLM backbones. Meanwhile, the increasing availability of\nhigh-quality synthetic instruction-following datasets raises the question: can\nsimpler, reference-based metrics serve as viable alternatives to reward models\nduring RL-based alignment? In this paper, we show first that BLEU, a basic\nstring-matching metric, surprisingly matches strong reward models in agreement\nwith human preferences on general instruction-following datasets. Based on this\ninsight, we develop BLEUBERI, a method that first identifies challenging\ninstructions and then applies Group Relative Policy Optimization (GRPO) using\nBLEU directly as the reward function. We demonstrate that BLEUBERI-trained\nmodels are competitive with models trained via reward model-guided RL across\nfour challenging instruction-following benchmarks and three different base\nlanguage models. A human evaluation further supports that the quality of\nBLEUBERI model outputs is on par with those from reward model-aligned models.\nMoreover, BLEUBERI models generate outputs that are more factually grounded\nthan competing methods. Overall, we show that given access to high-quality\nreference outputs (easily obtained via existing instruction-following datasets\nor synthetic data generation), string matching-based metrics are cheap yet\neffective proxies for reward models during alignment. We release our code and\ndata at https://github.com/lilakk/BLEUBERI.",
    "pdf_url": "http://arxiv.org/pdf/2505.11080v2",
    "published": "2025-05-16T10:11:43+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11079v2",
    "title": "ALLM4ADD: Unlocking the Capabilities of Audio Large Language Models for Audio Deepfake Detection",
    "authors": [
      "Hao Gu",
      "Jiangyan Yi",
      "Chenglong Wang",
      "Jianhua Tao",
      "Zheng Lian",
      "Jiayi He",
      "Yong Ren",
      "Yujie Chen",
      "Zhengqi Wen"
    ],
    "abstract": "Audio deepfake detection (ADD) has grown increasingly important due to the\nrise of high-fidelity audio generative models and their potential for misuse.\nGiven that audio large language models (ALLMs) have made significant progress\nin various audio processing tasks, a heuristic question arises: \\textit{Can\nALLMs be leveraged to solve ADD?}. In this paper, we first conduct a\ncomprehensive zero-shot evaluation of ALLMs on ADD, revealing their\nineffectiveness. To this end, we propose ALLM4ADD, an ALLM-driven framework for\nADD. Specifically, we reformulate ADD task as an audio question answering\nproblem, prompting the model with the question: ``Is this audio fake or\nreal?''. We then perform supervised fine-tuning to enable the ALLM to assess\nthe authenticity of query audio. Extensive experiments are conducted to\ndemonstrate that our ALLM-based method can achieve superior performance in fake\naudio detection, particularly in data-scarce scenarios. As a pioneering study,\nwe anticipate that this work will inspire the research community to leverage\nALLMs to develop more effective ADD systems. Code is available at\nhttps://github.com/ucas-hao/qwen_audio_for_add.git",
    "pdf_url": "http://arxiv.org/pdf/2505.11079v2",
    "published": "2025-05-16T10:10:03+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.11078v1",
    "title": "Analytical Fidelity Calculations for Photonic Linear Cluster State Generation",
    "authors": [
      "Rohit Prasad",
      "Simon Reiß",
      "Giora Peniakov",
      "Yorick Reum",
      "Peter van Loock",
      "Sven Höfling",
      "Tobias Huber-Loyola",
      "Andreas Theo Pfenning"
    ],
    "abstract": "By precisely timed optical excitation of their spin, optical emitters such as\nsemiconductor quantum dots or atoms can be harnessed as sources of linear\nphotonic cluster states. This significantly reduces the required resource\noverhead to reach fault-tolerant optical quantum computing. Here, we develop an\nalgorithm that analytically tracks the global density matrix through the\nprocess of the protocol for generating linear-cluster states by Lindner and\nRudolph. From this we derive a model to calculate the entangling gate fidelity\nand the state fidelity of the generated linear optical cluster states. Our\nmodel factors in various sources of error, such as spin decoherence and the\nfinite excited state lifetime. Additionally, we highlight the presence of\npartial reinitialization of spin coherence with each photon emission,\neliminating the hard limitation of coherence time. Our framework provides\nvaluable insight into the cost-to-improvement trade-offs for device design\nparameters as well as the identification of optimal working points. For a\ncombined state-of-the-art quantum dot with a spin coherence time of T_2^*=535\nns and an excited state lifetime of {\\tau}=23 ps, we show that a near-unity\nentangling gate fidelity as well as near-unity state fidelity for 3-photon and\n7-photon linear cluster states can be reached.",
    "pdf_url": "http://arxiv.org/pdf/2505.11078v1",
    "published": "2025-05-16T10:08:37+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11077v2",
    "title": "LLM-Enhanced Symbolic Control for Safety-Critical Applications",
    "authors": [
      "Amir Bayat",
      "Alessandro Abate",
      "Necmiye Ozay",
      "Raphael M. Jungers"
    ],
    "abstract": "Motivated by Smart Manufacturing and Industry 4.0, we introduce a framework\nfor synthesizing Abstraction-Based Controller Design (ABCD) for reach-avoid\nproblems from Natural Language (NL) specifications using Large Language Models\n(LLMs). A Code Agent interprets an NL description of the control problem and\ntranslates it into a formal language interpretable by state-of-the-art symbolic\ncontrol software, while a Checker Agent verifies the correctness of the\ngenerated code and enhances safety by identifying specification mismatches.\nEvaluations show that the system handles linguistic variability and improves\nrobustness over direct planning with LLMs. The proposed approach lowers the\nbarrier to formal control synthesis by enabling intuitive, NL-based task\ndefinition while maintaining safety guarantees through automated validation.",
    "pdf_url": "http://arxiv.org/pdf/2505.11077v2",
    "published": "2025-05-16T10:08:25+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11076v2",
    "title": "Addition is almost all you need: Compressing neural networks with double binary factorization",
    "authors": [
      "Vladimír Boža",
      "Vladimír Macko"
    ],
    "abstract": "Binary quantization approaches, which replace weight matrices with binary\nmatrices and substitute costly multiplications with cheaper additions, offer a\ncomputationally efficient approach to address the increasing computational and\nstorage requirements of Large Language Models (LLMs). However, the severe\nquantization constraint ($\\pm1$) can lead to significant accuracy degradation.\nIn this paper, we propose Double Binary Factorization (DBF), a novel method\nthat factorizes dense weight matrices into products of two binary (sign)\nmatrices, each accompanied by scaling vectors. DBF preserves the efficiency\nadvantages of binary representations while achieving compression rates that are\ncompetitive with or superior to state-of-the-art methods. Specifically, in a\n1-bit per weight range, DBF is better than existing binarization approaches. In\na 2-bit per weight range, DBF is competitive with the best quantization methods\nlike QuIP\\# and QTIP. Unlike most existing compression techniques, which offer\nlimited compression level choices, DBF allows fine-grained control over\ncompression ratios by adjusting the factorization's intermediate dimension.\nBased on this advantage, we further introduce an algorithm for estimating\nnon-uniform layer-wise compression ratios for DBF, based on previously\ndeveloped channel pruning criteria.\n  Code available at: https://github.com/usamec/double_binary",
    "pdf_url": "http://arxiv.org/pdf/2505.11076v2",
    "published": "2025-05-16T10:07:36+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11570v1",
    "title": "Tool-Aided Evolutionary LLM for Generative Policy Toward Efficient Resource Management in Wireless Federated Learning",
    "authors": [
      "Chongyang Tan",
      "Ruoqi Wen",
      "Rongpeng Li",
      "Zhifeng Zhao",
      "Ekram Hossain",
      "Honggang Zhang"
    ],
    "abstract": "Federated Learning (FL) enables distributed model training across edge\ndevices in a privacy-friendly manner. However, its efficiency heavily depends\non effective device selection and high-dimensional resource allocation in\ndynamic and heterogeneous wireless environments. Conventional methods demand a\nconfluence of domain-specific expertise, extensive hyperparameter tuning,\nand/or heavy interaction cost. This paper proposes a Tool-aided Evolutionary\nLarge Language Model (T-ELLM) framework to generate a qualified policy for\ndevice selection in a wireless FL environment. Unlike conventional optimization\nmethods, T-ELLM leverages natural language-based scenario prompts to enhance\ngeneralization across varying network conditions. The framework decouples the\njoint optimization problem mathematically, enabling tractable learning of\ndevice selection policies while delegating resource allocation to convex\noptimization tools. To improve adaptability, T-ELLM integrates a\nsample-efficient, model-based virtual learning environment that captures the\nrelationship between device selection and learning performance, facilitating\nsubsequent group relative policy optimization. This concerted approach reduces\nreliance on real-world interactions, minimizing communication overhead while\nmaintaining high-fidelity decision-making. Theoretical analysis proves that the\ndiscrepancy between virtual and real environments is bounded, ensuring the\nadvantage function learned in the virtual environment maintains a provably\nsmall deviation from real-world conditions. Experimental results demonstrate\nthat T-ELLM outperforms benchmark methods in energy efficiency and exhibits\nrobust adaptability to environmental changes.",
    "pdf_url": "http://arxiv.org/pdf/2505.11570v1",
    "published": "2025-05-16T10:07:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11075v1",
    "title": "Pseudo-Label Quality Decoupling and Correction for Semi-Supervised Instance Segmentation",
    "authors": [
      "Jianghang Lin",
      "Yilin Lu",
      "Yunhang Shen",
      "Chaoyang Zhu",
      "Shengchuan Zhang",
      "Liujuan Cao",
      "Rongrong Ji"
    ],
    "abstract": "Semi-Supervised Instance Segmentation (SSIS) involves classifying and\ngrouping image pixels into distinct object instances using limited labeled\ndata. This learning paradigm usually faces a significant challenge of unstable\nperformance caused by noisy pseudo-labels of instance categories and pixel\nmasks. We find that the prevalent practice of filtering instance pseudo-labels\nassessing both class and mask quality with a single score threshold, frequently\nleads to compromises in the trade-off between the qualities of class and mask\nlabels. In this paper, we introduce a novel Pseudo-Label Quality Decoupling and\nCorrection (PL-DC) framework for SSIS to tackle the above challenges. Firstly,\nat the instance level, a decoupled dual-threshold filtering mechanism is\ndesigned to decouple class and mask quality estimations for instance-level\npseudo-labels, thereby independently controlling pixel classifying and grouping\nqualities. Secondly, at the category level, we introduce a dynamic instance\ncategory correction module to dynamically correct the pseudo-labels of instance\ncategories, effectively alleviating category confusion. Lastly, we introduce a\npixel-level mask uncertainty-aware mechanism at the pixel level to re-weight\nthe mask loss for different pixels, thereby reducing the impact of noise\nintroduced by pixel-level mask pseudo-labels. Extensive experiments on the COCO\nand Cityscapes datasets demonstrate that the proposed PL-DC achieves\nsignificant performance improvements, setting new state-of-the-art results for\nSSIS. Notably, our PL-DC shows substantial gains even with minimal labeled\ndata, achieving an improvement of +11.6 mAP with just 1% COCO labeled data and\n+15.5 mAP with 5% Cityscapes labeled data. The code will be public.",
    "pdf_url": "http://arxiv.org/pdf/2505.11075v1",
    "published": "2025-05-16T10:07:17+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11074v1",
    "title": "Heavy-ion and fixed-target physics at LHCb",
    "authors": [
      "Daniele Marangotto"
    ],
    "abstract": "The latest results obtained by the LHCb collaboration from heavy-ion and\nfixed-target collisions recorded during the Run 2 LHC data-taking are\npresented. They mainly focus on heavy hadron production for varying nuclear\ncollision systems, probing nuclear matter physics in different regimes,\nincluding Cold Nuclear Matter and Quark Gluon Plasma effects. Measurements of\nstrangeness production and $\\Lambda$ baryon polarisation are also reported.\nEven more valuable results will come soon from the ongoing Run 3 data-taking.",
    "pdf_url": "http://arxiv.org/pdf/2505.11074v1",
    "published": "2025-05-16T10:07:08+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.11073v1",
    "title": "Can we distinguish whether black holes have singularities or not through echoes and light rings?",
    "authors": [
      "Xiao-Pin Rao",
      "Hyat Huang"
    ],
    "abstract": "A recent work [Phys. Rev. D 111, 104040] shows that the curvature singularity\nof a black hole can vanish at a fine-tuned mass value, which implies that\nregular black holes could be special states in black hole evolution. We study\nthe quasinormal modes (QNMs) of the Bardeen black hole and its singular\ncounterparts under scalar and electromagnetic perturbations, employing the WKB\nmethod and time-domain analysis, respectively. The time-domain analysis results\nsuggest that echo signals may emerge in the QNMs of singular black hole states.\nFurthermore, we investigate the null geodesics of these black holes. We find\nthat a black hole with singularity may possess two light rings, whereas regular\nblack holes consistently maintain only one light ring. Similar conclusions are\nalso valid for the regular Hayward black hole and its singular counterparts.",
    "pdf_url": "http://arxiv.org/pdf/2505.11073v1",
    "published": "2025-05-16T10:06:57+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.11569v1",
    "title": "Towards Adaptive Deep Learning: Model Elasticity via Prune-and-Grow CNN Architectures",
    "authors": [
      "Pooja Mangal",
      "Sudaksh Kalra",
      "Dolly Sapra"
    ],
    "abstract": "Deploying deep convolutional neural networks (CNNs) on resource-constrained\ndevices presents significant challenges due to their high computational demands\nand rigid, static architectures. To overcome these limitations, this thesis\nexplores methods for enabling CNNs to dynamically adjust their computational\ncomplexity based on available hardware resources. We introduce adaptive CNN\narchitectures capable of scaling their capacity at runtime, thus efficiently\nbalancing performance and resource utilization. To achieve this adaptability,\nwe propose a structured pruning and dynamic re-construction approach that\ncreates nested subnetworks within a single CNN model. This approach allows the\nnetwork to dynamically switch between compact and full-sized configurations\nwithout retraining, making it suitable for deployment across varying hardware\nplatforms. Experiments conducted across multiple CNN architectures including\nVGG-16, AlexNet, ResNet-20, and ResNet-56 on CIFAR-10 and Imagenette datasets\ndemonstrate that adaptive models effectively maintain or even enhance\nperformance under varying computational constraints. Our results highlight that\nembedding adaptability directly into CNN architectures significantly improves\ntheir robustness and flexibility, paving the way for efficient real-world\ndeployment in diverse computational environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.11569v1",
    "published": "2025-05-16T10:06:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11072v1",
    "title": "The Giant Arc -- Filament of Figment?",
    "authors": [
      "Till Sawala",
      "Meri Teeriaho"
    ],
    "abstract": "The so-called \"Giant Arc\" is a sparse pattern of MgII absorbers spanning\napproximately 740 comoving Mpc, whose discovery has been claimed to contradict\nthe large-scale homogeneity inherent to the standard cosmological model. We\npreviously showed that, with the same algorithm and parameters used for its\ndiscovery, very similar patterns are abundant in uniform random distributions,\nand among equivalent halo samples in a cosmological simulation of the standard\nmodel. In a response, the original discoverers of the \"Giant Arc\" have argued\nthat these parameters were only appropriate for their specific observational\ndata, but that a smaller linking length should be used for control studies, in\nwhich case far fewer patterns are detected. We briefly review and disprove\nthese arguments, and demonstrate that large patterns like the \"Giant Arc\" are\nindeed ubiquitous in a statistically homogeneous universe.",
    "pdf_url": "http://arxiv.org/pdf/2505.11072v1",
    "published": "2025-05-16T10:05:38+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11071v1",
    "title": "Walsh-Floquet Theory of Periodic Kick Drives",
    "authors": [
      "James Walkling",
      "Marin Bukov"
    ],
    "abstract": "Periodic kick drives are ubiquitous in digital quantum control, computation,\nand simulation, and are instrumental in studies of chaos and thermalization for\ntheir efficient representation through discrete gates. However, in the commonly\nused Fourier basis, kick drives lead to poor convergence of physical\nquantities. Instead, here we use the Walsh basis of periodic square-wave\nfunctions to describe the physics of periodic kick drives. In the strongly\nkicked regime, we find that it recovers Floquet dynamics of single- and\nmany-body systems more accurately than the Fourier basis, due to the shape of\nthe system's response in time. To understand this behavior, we derive an\nextended Sambe space formulation and an inverse-frequency expansion in the\nWalsh basis. We explain the enhanced performance within the framework of\nsingle-particle localization on the frequency lattice, where localization is\ncorrelated with small truncation errors. We show that strong hybridization\nbetween states of the kicked system and Walsh modes gives rise to Walsh\npolaritons that can be studied on digital quantum simulators. Our work lays the\nfoundations of Walsh-Floquet theory, which is naturally implementable on\ndigital quantum devices and suited to Floquet state manipulation using discrete\ngates.",
    "pdf_url": "http://arxiv.org/pdf/2505.11071v1",
    "published": "2025-05-16T10:05:31+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.other",
      "cond-mat.quant-gas"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11070v1",
    "title": "Towards Self-Improvement of Diffusion Models via Group Preference Optimization",
    "authors": [
      "Renjie Chen",
      "Wenfeng Lin",
      "Yichen Zhang",
      "Jiangchuan Wei",
      "Boyuan Liu",
      "Chao Feng",
      "Jiao Ran",
      "Mingyu Guo"
    ],
    "abstract": "Aligning text-to-image (T2I) diffusion models with Direct Preference\nOptimization (DPO) has shown notable improvements in generation quality.\nHowever, applying DPO to T2I faces two challenges: the sensitivity of DPO to\npreference pairs and the labor-intensive process of collecting and annotating\nhigh-quality data. In this work, we demonstrate that preference pairs with\nmarginal differences can degrade DPO performance. Since DPO relies exclusively\non relative ranking while disregarding the absolute difference of pairs, it may\nmisclassify losing samples as wins, or vice versa. We empirically show that\nextending the DPO from pairwise to groupwise and incorporating reward\nstandardization for reweighting leads to performance gains without explicit\ndata selection. Furthermore, we propose Group Preference Optimization (GPO), an\neffective self-improvement method that enhances performance by leveraging the\nmodel's own capabilities without requiring external data. Extensive experiments\ndemonstrate that GPO is effective across various diffusion models and tasks.\nSpecifically, combining with widely used computer vision models, such as YOLO\nand OCR, the GPO improves the accurate counting and text rendering capabilities\nof the Stable Diffusion 3.5 Medium by 20 percentage points. Notably, as a\nplug-and-play method, no extra overhead is introduced during inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.11070v1",
    "published": "2025-05-16T10:04:57+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11069v1",
    "title": "Purcell enhanced and tunable single-photon emission at telecom wavelengths from InAs quantum dots in circular photonic crystal resonators",
    "authors": [
      "Andrea Barbiero",
      "Ginny Shooter",
      "Joanna Skiba-Szymanska",
      "Junyang. Huang",
      "Loganathan Ravi",
      "J. Iwan Davies",
      "Ben Ramsay",
      "David J. P. Ellis",
      "Andrew J. Shields",
      "Tina Müller",
      "R. Mark Stevenson"
    ],
    "abstract": "Embedding semiconductor quantum dots into bullseye resonators has\nsignificantly advanced the development of bright telecom quantum light sources\nfor fiber-based quantum networks. To further improve the device flexibility and\nstability, the bullseye approach should be combined with a pin diode structure\nto enable Stark tuning, deterministic charging, and enhanced coherence. In this\nwork, we fabricate and characterize photonic structures incorporating hole\ngratings that efficiently support charge carrier transport while maintaining\nexcellent optical performance. We report bright, Purcell-enhanced single-photon\nemission in the telecom C-band under above-band and phonon-assisted excitation.\nAdditionally, we present electrically contacted resonators, demonstrating wide\nrange tuneability of quantum dot transitions in the telecom O-band. These\nresults mark significant steps toward scalable and tunable quantum light\nsources for real-world quantum photonic applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.11069v1",
    "published": "2025-05-16T10:03:54+00:00",
    "categories": [
      "physics.optics",
      "quant-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.11068v1",
    "title": "Beyond KL-divergence: Risk Aware Control Through Cross Entropy and Adversarial Entropy Regularization",
    "authors": [
      "Menno van Zutphen",
      "Domagoj Herceg",
      "Duarte J. Antunes"
    ],
    "abstract": "While the idea of robust dynamic programming (DP) is compelling for systems\naffected by uncertainty, addressing worst-case disturbances generally results\nin excessive conservatism. This paper introduces a method for constructing\ncontrol policies robust to adversarial disturbance distributions that relate to\na provided empirical distribution. The character of the adversary is shaped by\na regularization term comprising a weighted sum of (i) the cross-entropy\nbetween the empirical and the adversarial distributions, and (ii) the entropy\nof the adversarial distribution itself. The regularization weights are\ninterpreted as the likelihood factor and the temperature respectively. The\nproposed framework leads to an efficient DP-like algorithm -- referred to as\nthe minsoftmax algorithm -- to obtain the optimal control policy, where the\ndisturbances follow an analytical softmax distribution in terms of the\nempirical distribution, temperature, and likelihood factor. It admits a number\nof control-theoretic interpretations and can thus be understood as a flexible\ntool for integrating complementary features of related control frameworks. In\nparticular, in the linear model quadratic cost setting, with a Gaussian\nempirical distribution, we draw connections to the well-known\n$\\mathcal{H}_{\\infty}$-control. We illustrate our results through a numerical\nexample.",
    "pdf_url": "http://arxiv.org/pdf/2505.11068v1",
    "published": "2025-05-16T10:02:46+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11067v1",
    "title": "Assessing the Performance of Analog Training for Transfer Learning",
    "authors": [
      "Omobayode Fagbohungbe",
      "Corey Lammie",
      "Malte J. Rasch",
      "Takashi Ando",
      "Tayfun Gokmen",
      "Vijay Narayanan"
    ],
    "abstract": "Analog in-memory computing is a next-generation computing paradigm that\npromises fast, parallel, and energy-efficient deep learning training and\ntransfer learning (TL). However, achieving this promise has remained elusive\ndue to a lack of suitable training algorithms. Analog memory devices exhibit\nasymmetric and non-linear switching behavior in addition to device-to-device\nvariation, meaning that most, if not all, of the current off-the-shelf training\nalgorithms cannot achieve good training outcomes. Also, recently introduced\nalgorithms have enjoyed limited attention, as they require bi-directionally\nswitching devices of unrealistically high symmetry and precision and are highly\nsensitive. A new algorithm chopped TTv2 (c-TTv2), has been introduced, which\nleverages the chopped technique to address many of the challenges mentioned\nabove. In this paper, we assess the performance of the c-TTv2 algorithm for\nanalog TL using a Swin-ViT model on a subset of the CIFAR100 dataset. We also\ninvestigate the robustness of our algorithm to changes in some device\nspecifications, including weight transfer noise, symmetry point skew, and\nsymmetry point variability",
    "pdf_url": "http://arxiv.org/pdf/2505.11067v1",
    "published": "2025-05-16T10:02:32+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.CV",
      "cs.DC",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11066v1",
    "title": "A Multi-modal Fusion Network for Terrain Perception Based on Illumination Aware",
    "authors": [
      "Rui Wang",
      "Shichun Yang",
      "Yuyi Chen",
      "Zhuoyang Li",
      "Zexiang Tong",
      "Jianyi Xu",
      "Jiayi Lu",
      "Xinjie Feng",
      "Yaoguang Cao"
    ],
    "abstract": "Road terrains play a crucial role in ensuring the driving safety of\nautonomous vehicles (AVs). However, existing sensors of AVs, including cameras\nand Lidars, are susceptible to variations in lighting and weather conditions,\nmaking it challenging to achieve real-time perception of road conditions. In\nthis paper, we propose an illumination-aware multi-modal fusion network (IMF),\nwhich leverages both exteroceptive and proprioceptive perception and optimizes\nthe fusion process based on illumination features. We introduce an\nillumination-perception sub-network to accurately estimate illumination\nfeatures. Moreover, we design a multi-modal fusion network which is able to\ndynamically adjust weights of different modalities according to illumination\nfeatures. We enhance the optimization process by pre-training of the\nillumination-perception sub-network and incorporating illumination loss as one\nof the training constraints. Extensive experiments demonstrate that the IMF\nshows a superior performance compared to state-of-the-art methods. The\ncomparison results with single modality perception methods highlight the\ncomprehensive advantages of multi-modal fusion in accurately perceiving road\nterrains under varying lighting conditions. Our dataset is available at:\nhttps://github.com/lindawang2016/IMF.",
    "pdf_url": "http://arxiv.org/pdf/2505.11066v1",
    "published": "2025-05-16T10:02:22+00:00",
    "categories": [
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11065v1",
    "title": "Time Travel is Cheating: Going Live with DeepFund for Real-Time Fund Investment Benchmarking",
    "authors": [
      "Changlun Li",
      "Yao Shi",
      "Chen Wang",
      "Qiqi Duan",
      "Runke Ruan",
      "Weijie Huang",
      "Haonan Long",
      "Lijun Huang",
      "Yuyu Luo",
      "Nan Tang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across\nfinancial tasks, including financial report summarization, earnings call\ntranscript analysis, and asset classification. However, their real-world\neffectiveness in managing complex fund investment remains inadequately\nassessed. A fundamental limitation of existing benchmarks for evaluating\nLLM-driven trading strategies is their reliance on historical back-testing,\ninadvertently enabling LLMs to \"time travel\"-leveraging future information\nembedded in their training corpora, thus resulting in possible information\nleakage and overly optimistic performance estimates. To address this issue, we\nintroduce DeepFund, a live fund benchmark tool designed to rigorously evaluate\nLLM in real-time market conditions. Utilizing a multi-agent architecture,\nDeepFund connects directly with real-time stock market data-specifically data\npublished after each model pretraining cutoff-to ensure fair and leakage-free\nevaluations. Empirical tests on nine flagship LLMs from leading global\ninstitutions across multiple investment dimensions-including ticker-level\nanalysis, investment decision-making, portfolio management, and risk\ncontrol-reveal significant practical challenges. Notably, even cutting-edge\nmodels such as DeepSeek-V3 and Claude-3.7-Sonnet incur net trading losses\nwithin DeepFund real-time evaluation environment, underscoring the present\nlimitations of LLMs for active fund management. Our code is available at\nhttps://github.com/HKUSTDial/DeepFund.",
    "pdf_url": "http://arxiv.org/pdf/2505.11065v1",
    "published": "2025-05-16T10:00:56+00:00",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11064v1",
    "title": "Angular structure of Drell-Yan reaction in the TMD factorization approach",
    "authors": [
      "Alexey Vladimirov"
    ],
    "abstract": "We study angular distributions in the Drell-Yan process using an extended\ntransverse momentum dependent (TMD) factorization framework that includes\nkinematic power corrections. This approach allows the description of\nobservables previously considered power-suppressed. The results show good\nagreement with experimental data and provide the first LHC-based indication of\nthe Boer-Mulders function, highlighting the value of power corrections in TMD\nphenomenology.",
    "pdf_url": "http://arxiv.org/pdf/2505.11064v1",
    "published": "2025-05-16T10:00:33+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11063v2",
    "title": "Think Twice Before You Act: Enhancing Agent Behavioral Safety with Thought Correction",
    "authors": [
      "Changyue Jiang",
      "Xudong Pan",
      "Min Yang"
    ],
    "abstract": "LLM-based autonomous agents possess capabilities such as reasoning, tool\ninvocation, and environment interaction, enabling the execution of complex\nmulti-step tasks. The internal reasoning process, i.e., thought, of behavioral\ntrajectory significantly influences tool usage and subsequent actions but can\nintroduce potential risks. Even minor deviations in the agent's thought may\ntrigger cascading effects leading to irreversible safety incidents. To address\nthe safety alignment challenges in long-horizon behavioral trajectories, we\npropose Thought-Aligner, a plug-in dynamic thought correction module. Utilizing\na lightweight and resource-efficient model, Thought-Aligner corrects each\nhigh-risk thought on the fly before each action execution. The corrected\nthought is then reintroduced to the agent, ensuring safer subsequent decisions\nand tool interactions. Importantly, Thought-Aligner modifies only the reasoning\nphase without altering the underlying agent framework, making it easy to deploy\nand widely applicable to various agent frameworks. To train the Thought-Aligner\nmodel, we construct an instruction dataset across ten representative scenarios\nand simulate ReAct execution trajectories, generating 5,000 diverse\ninstructions and more than 11,400 safe and unsafe thought pairs. The model is\nfine-tuned using contrastive learning techniques. Experiments across three\nagent safety benchmarks involving 12 different LLMs demonstrate that\nThought-Aligner raises agent behavioral safety from approximately 50% in the\nunprotected setting to 90% on average. Additionally, Thought-Aligner maintains\nresponse latency below 100ms with minimal resource usage, demonstrating its\ncapability for efficient deployment, broad applicability, and timely\nresponsiveness. This method thus provides a practical dynamic safety solution\nfor the LLM-based agents.",
    "pdf_url": "http://arxiv.org/pdf/2505.11063v2",
    "published": "2025-05-16T10:00:15+00:00",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.11062v1",
    "title": "HSRMamba: Efficient Wavelet Stripe State Space Model for Hyperspectral Image Super-Resolution",
    "authors": [
      "Baisong Li",
      "Xingwang Wang",
      "Haixiao Xu"
    ],
    "abstract": "Single hyperspectral image super-resolution (SHSR) aims to restore\nhigh-resolution images from low-resolution hyperspectral images. Recently, the\nVisual Mamba model has achieved an impressive balance between performance and\ncomputational efficiency. However, due to its 1D scanning paradigm, the model\nmay suffer from potential artifacts during image generation. To address this\nissue, we propose HSRMamba. While maintaining the computational efficiency of\nVisual Mamba, we introduce a strip-based scanning scheme to effectively reduce\nartifacts from global unidirectional scanning. Additionally, HSRMamba uses\nwavelet decomposition to alleviate modal conflicts between high-frequency\nspatial features and low-frequency spectral features, further improving\nsuper-resolution performance. Extensive experiments show that HSRMamba not only\nexcels in reducing computational load and model size but also outperforms\nexisting methods, achieving state-of-the-art results.",
    "pdf_url": "http://arxiv.org/pdf/2505.11062v1",
    "published": "2025-05-16T09:57:41+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11061v2",
    "title": "Lifelong reinforcement learning for health-aware fast charging of lithium-ion batteries",
    "authors": [
      "Meng Yuan",
      "Changfu Zou"
    ],
    "abstract": "Fast charging of lithium-ion batteries remains a critical bottleneck for\nwidespread adoption of electric vehicles and stationary energy storage systems,\nas improperly designed fast charging can accelerate battery degradation and\nshorten lifespan. In this work, we address this challenge by proposing a\nhealth-aware fast charging strategy that explicitly balances charging speed and\nbattery longevity across the entire service life. The key innovation lies in\nestablishing a mapping between anode overpotential and the state of health\n(SoH) of battery, which is then used to constrain the terminal charging voltage\nin a twin delayed deep deterministic policy gradient (TD3) framework. By\nincorporating this SoH-dependent voltage constraint, our designed deep learning\nmethod mitigates side reactions and effectively extends battery life. To\nvalidate the proposed approach, a high-fidelity single particle model with\nelectrolyte is implemented in the widely adopted PyBaMM simulation platform,\ncapturing degradation phenomena at realistic scales. Comparative life-cycle\nsimulations against conventional CC-CV, its variants, and constant\ncurrent-constant overpotential methods show that the TD3-based controller\nreduces overall degradation while maintaining competitively fast charge times.\nThese results demonstrate the practical viability of deep reinforcement\nlearning for advanced battery management systems and pave the way for future\nexplorations of health-aware, performance-optimized charging strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11061v2",
    "published": "2025-05-16T09:57:35+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11060v1",
    "title": "CUBIC: Concept Embeddings for Unsupervised Bias Identification using VLMs",
    "authors": [
      "David Méndez",
      "Gianpaolo Bontempo",
      "Elisa Ficarra",
      "Roberto Confalonieri",
      "Natalia Díaz-Rodríguez"
    ],
    "abstract": "Deep vision models often rely on biases learned from spurious correlations in\ndatasets. To identify these biases, methods that interpret high-level,\nhuman-understandable concepts are more effective than those relying primarily\non low-level features like heatmaps. A major challenge for these concept-based\nmethods is the lack of image annotations indicating potentially bias-inducing\nconcepts, since creating such annotations requires detailed labeling for each\ndataset and concept, which is highly labor-intensive. We present CUBIC (Concept\nembeddings for Unsupervised Bias IdentifiCation), a novel method that\nautomatically discovers interpretable concepts that may bias classifier\nbehavior. Unlike existing approaches, CUBIC does not rely on predefined bias\ncandidates or examples of model failures tied to specific biases, as such\ninformation is not always available. Instead, it leverages image-text latent\nspace and linear classifier probes to examine how the latent representation of\na superclass label$\\unicode{x2014}$shared by all instances in the\ndataset$\\unicode{x2014}$is influenced by the presence of a given concept. By\nmeasuring these shifts against the normal vector to the classifier's decision\nboundary, CUBIC identifies concepts that significantly influence model\npredictions. Our experiments demonstrate that CUBIC effectively uncovers\npreviously unknown biases using Vision-Language Models (VLMs) without requiring\nthe samples in the dataset where the classifier underperforms or prior\nknowledge of potential biases.",
    "pdf_url": "http://arxiv.org/pdf/2505.11060v1",
    "published": "2025-05-16T09:57:15+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T10",
      "I.2.4; I.5.2"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11059v2",
    "title": "Upper bound of holographic entanglement entropy combinations",
    "authors": [
      "Xin-Xiang Ju",
      "Ya-Wen Sun",
      "Yang Zhao"
    ],
    "abstract": "In this work, we develop a systematic formalism to evaluate the upper bound\nof a large family of holographic entanglement entropy combinations when fixing\n$n$ subsystems and fine-tuning one other subsystem. The upper bound\nconfigurations and values of these entropy combinations can be derived and\nclassified. The upper bound of these entropy combinations reveals holographic\n$n+1$-partite entanglement that $n$ fixed subsystems participate in. In\nAdS$_3$/CFT$_2$, AdS$_4$/CFT$_3$, and even higher-dimensional holography, one\ncan, in principle, find different formulas of upper bound values, reflecting\nthe fundamental difference in entanglement structure in different dimensions.",
    "pdf_url": "http://arxiv.org/pdf/2505.11059v2",
    "published": "2025-05-16T09:56:24+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11058v1",
    "title": "Side Channel Analysis in Homomorphic Encryption",
    "authors": [
      "Baraq Ghaleb",
      "William J Buchanan"
    ],
    "abstract": "Homomorphic encryption provides many opportunities for privacy-aware\nprocessing, including with methods related to machine learning. Many of our\nexisting cryptographic methods have been shown in the past to be susceptible to\nside channel attacks. With these, the implementation of the cryptographic\nmethods can reveal information about the private keys used, the result, or even\nthe original plaintext. An example of this includes the processing of the RSA\nexponent using the Montgomery method, and where 0's and 1's differ in their\nprocessing time for modular exponentiation. With FHE, we typically use lattice\nmethods, and which can have particular problems in their implementation in\nrelation to side channel leakage. This paper aims to outline a range of\nweaknesses within FHE implementations as related to side channel analysis. It\noutlines a categorization for side-channel analysis, some case studies, and\nmitigation strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11058v1",
    "published": "2025-05-16T09:56:03+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11057v1",
    "title": "Local consistency and axioms of functional dependence",
    "authors": [
      "Timon Barlag",
      "Miika Hannula",
      "Juha Kontinen",
      "Nina Pardal",
      "Jonni Virtema"
    ],
    "abstract": "Local consistency arises in diverse areas, including Bayesian statistics,\nrelational databases, and quantum foundations. Likewise, the notion of\nfunctional dependence arises in all of these areas. We adopt a general approach\nto study logical inference in a setting that enables both global inconsistency\nand local consistency. Our approach builds upon pairwise consistent families of\nK-relations, i.e, relations with tuples annotated with elements of some\npositive commutative monoid. The framework covers, e.g., families of\nprobability distributions arising from quantum experiments and their\npossibilistic counterparts. As a first step, we investigate the entailment\nproblem for functional dependencies (FDs) in this setting. Notably, the\ntransitivity rule for FDs is no longer sound, but can be replaced by two novel\naxiom schemes. We provide a complete axiomatisation and a PTIME algorithm for\nthe entailment problem of unary FDs. In addition, we explore when contextual\nfamilies over the Booleans have realisations as contextual families over\nvarious monoids.",
    "pdf_url": "http://arxiv.org/pdf/2505.11057v1",
    "published": "2025-05-16T09:55:34+00:00",
    "categories": [
      "quant-ph",
      "cs.DB",
      "68P15, 81P13"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11056v1",
    "title": "Empowering the Teaching and Learning of Geometry in Basic Education by Combining Extended Reality and Machine Learning",
    "authors": [
      "Carlos R. Cunha",
      "André Moreira",
      "Sílvia Coelho",
      "Vítor Mendonça",
      "João Pedro Gomes"
    ],
    "abstract": "Technology has helped to innovate in the teaching-learning process. Today's\nstudents are more demanding actors when it comes to the environment, they have\nat their disposal to learn, experiment and develop critical thinking. The area\nof mathematics has successively suffered from students' learning difficulties,\nwhether due to lack of motivation, low abstraction ability, or lack of new\ntools for teachers to bring innovation into the classroom and outside it. While\nit is true that digitalization has entered schools, it often follows a process\nof digital replication of approaches and materials that were previously only\navailable on physical media. This work focuses on the use of Extended Realities\nfor teaching mathematics, and very particularly in the teaching of geometry,\nwith a proposition of a conceptual model that combines the use of Extended\nReality and Machine Learning. The proposed model was subject to prototyping,\nwhich is presented as a form of laboratory validation as a contribution to\ninnovate the way in which the geometry teaching-learning process is developed,\nas well as through the ability to obtain useful insights for teachers and\nstudents throughout the process.",
    "pdf_url": "http://arxiv.org/pdf/2505.11056v1",
    "published": "2025-05-16T09:54:45+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.11055v1",
    "title": "Internal Effectful Forcing in System T",
    "authors": [
      "Martin H. Escardo",
      "Bruno da Rocha Paiva",
      "Vincent Rahli",
      "Ayberk Tosun"
    ],
    "abstract": "The effectful forcing technique allows one to show that the denotation of a\nclosed System T term of type $(\\iota \\to \\iota) \\to \\iota$ in the\nset-theoretical model is a continuous function $(\\mathbb{N} \\to \\mathbb{N}) \\to\n\\mathbb{N}$. For this purpose, an alternative dialogue-tree semantics is\ndefined and related to the set-theoretical semantics by a logical relation. In\nthis paper, we apply effectful forcing to show that the dialogue tree of a\nSystem T term is itself System T-definable, using the Church encoding of trees.",
    "pdf_url": "http://arxiv.org/pdf/2505.11055v1",
    "published": "2025-05-16T09:54:24+00:00",
    "categories": [
      "cs.LO",
      "math.LO",
      "03B38, 03B40, 03F50",
      "F.4.1; F.3.1; F.3.2"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11054v1",
    "title": "NeuralSurv: Deep Survival Analysis with Bayesian Uncertainty Quantification",
    "authors": [
      "Mélodie Monod",
      "Alessandro Micheli",
      "Samir Bhatt"
    ],
    "abstract": "We introduce NeuralSurv, the first deep survival model to incorporate\nBayesian uncertainty quantification. Our non-parametric, architecture-agnostic\nframework flexibly captures time-varying covariate-risk relationships in\ncontinuous time via a novel two-stage data-augmentation scheme, for which we\nestablish theoretical guarantees. For efficient posterior inference, we\nintroduce a mean-field variational algorithm with coordinate-ascent updates\nthat scale linearly in model size. By locally linearizing the Bayesian neural\nnetwork, we obtain full conjugacy and derive all coordinate updates in closed\nform. In experiments, NeuralSurv delivers superior calibration compared to\nstate-of-the-art deep survival models, while matching or exceeding their\ndiscriminative performance across both synthetic benchmarks and real-world\ndatasets. Our results demonstrate the value of Bayesian principles in\ndata-scarce regimes by enhancing model calibration and providing robust,\nwell-calibrated uncertainty estimates for the survival function.",
    "pdf_url": "http://arxiv.org/pdf/2505.11054v1",
    "published": "2025-05-16T09:53:21+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11053v1",
    "title": "Conceptual framework for the application of deep neural networks to surface composition reconstruction from Mercury's exospheric data",
    "authors": [
      "Adrian Kazakov",
      "Anna Milillo",
      "Alessandro Mura",
      "Stavro Ivanovski",
      "Valeria Mangano",
      "Alessandro Aronica",
      "Elisabetta De Angelis",
      "Pier Paolo Di Bartolomeo",
      "Alessandro Brin",
      "Luca Colasanti",
      "Miguel Escalona-Moran",
      "Francesco Lazzarotto",
      "Stefano Massetti",
      "Martina Moroni",
      "Raffaella Noschese",
      "Fabrizio Nuccilli",
      "Stefano Orsini",
      "Christina Plainaki",
      "Rosanna Rispoli",
      "Roberto Sordini",
      "Mirko Stumpo",
      "Nello Vertolli"
    ],
    "abstract": "Surface information derived from exospheric measurements at planetary bodies\ncomplements surface mapping provided by dedicated imagers, offering critical\ninsights into surface release processes, interactions within the planetary\nenvironment, space weathering, and planetary evolution. This study explores the\nfeasibility of deriving Mercury's regolith elemental composition from in-situ\nmeasurements of its neutral exosphere using deep neural networks (DNNs). We\npresent a supervised feed-forward DNN architecture - a multilayer perceptron\n(MLP) - that, starting from exospheric densities and proton precipitation\nfluxes, predicts the chemical elements of the surface regolith below. It serves\nas an estimator for the surface-exosphere interaction and the processes leading\nto exosphere formation. Because the DNN requires a comprehensive exospheric\ndataset not available from previous missions, this study uses simulated\nexosphere components and simulated drivers. Extensive training and testing\ncampaigns demonstrate the MLP's ability to accurately predict and reconstruct\nsurface composition maps from these simulated measurements. Although this\ninitial version does not aim to reproduce Mercury's actual surface composition,\nit provides a proof of concept, showcasing the algorithm's robustness and\ncapacity for handling complex datasets to create estimators for exospheric\ngeneration models. Moreover, our tests reveal substantial potential for further\ndevelopment, suggesting that this method could significantly enhance the\nanalysis of complex surface-exosphere interactions and complement planetary\nexosphere models. This work anticipates applying the approach to data from the\nBepiColombo mission, specifically the SERENA package, whose nominal phase\nbegins in 2027.",
    "pdf_url": "http://arxiv.org/pdf/2505.11053v1",
    "published": "2025-05-16T09:52:45+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "cs.LG"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11052v2",
    "title": "Dynamical Stability and Critical Exponents of the Neutral (S-type) Gubser-Rocha Model with Momentum Dissipation",
    "authors": [
      "Shuta Ishigaki"
    ],
    "abstract": "The (S-type) Gubser-Rocha model is a holographic model that shows the linear\ndependence of the entropy density on the temperature. With an appropriate\nchoice of the boundary action, this model exhibits a continuous phase\ntransition in the neutral limit. In this paper, we investigate several aspects\nof this phase transition. Firstly, we show that the critical exponents of the\nphase transition match those in the mean-field percolation theory.\nSubsequently, we also investigate the dynamical stability, and the emergence of\nthe Nambu-Goldstone modes by analyzing the quasinormal modes of the\nperturbation fields. The dynamical stability agrees with the thermodynamic\nstability. In addition, we find that there is an emergent Nambu-Goldstone mode\nin the broken phase of the S-type model.",
    "pdf_url": "http://arxiv.org/pdf/2505.11052v2",
    "published": "2025-05-16T09:52:05+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.11051v1",
    "title": "CAMEO: Collection of Multilingual Emotional Speech Corpora",
    "authors": [
      "Iwona Christop",
      "Maciej Czajka"
    ],
    "abstract": "This paper presents CAMEO -- a curated collection of multilingual emotional\nspeech datasets designed to facilitate research in emotion recognition and\nother speech-related tasks. The main objectives were to ensure easy access to\nthe data, to allow reproducibility of the results, and to provide a\nstandardized benchmark for evaluating speech emotion recognition (SER) systems\nacross different emotional states and languages. The paper describes the\ndataset selection criteria, the curation and normalization process, and\nprovides performance results for several models. The collection, along with\nmetadata, and a leaderboard, is publicly available via the Hugging Face\nplatform.",
    "pdf_url": "http://arxiv.org/pdf/2505.11051v1",
    "published": "2025-05-16T09:52:00+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11050v2",
    "title": "Halting Recurrent GNNs and the Graded $μ$-Calculus",
    "authors": [
      "Jeroen Bollen",
      "Jan Van den Bussche",
      "Stijn Vansummeren",
      "Jonni Virtema"
    ],
    "abstract": "Graph Neural Networks (GNNs) are a class of machine-learning models that\noperate on graph-structured data. Their expressive power is intimately related\nto logics that are invariant under graded bisimilarity. Current proposals for\nrecurrent GNNs either assume that the graph size is given to the model, or\nsuffer from a lack of termination guarantees. In this paper, we propose a\nhalting mechanism for recurrent GNNs. We prove that our halting model can\nexpress all node classifiers definable in graded modal mu-calculus, even for\nthe standard GNN variant that is oblivious to the graph size. To prove our main\nresult, we develop a new approximate semantics for graded mu-calculus, which we\nbelieve to be of independent interest. We leverage this new semantics into a\nnew model-checking algorithm, called the counting algorithm, which is oblivious\nto the graph size. In a final step we show that the counting algorithm can be\nimplemented on a halting recurrent GNN.",
    "pdf_url": "http://arxiv.org/pdf/2505.11050v2",
    "published": "2025-05-16T09:46:36+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11049v1",
    "title": "GuardReasoner-VL: Safeguarding VLMs via Reinforced Reasoning",
    "authors": [
      "Yue Liu",
      "Shengfang Zhai",
      "Mingzhe Du",
      "Yulin Chen",
      "Tri Cao",
      "Hongcheng Gao",
      "Cheng Wang",
      "Xinfeng Li",
      "Kun Wang",
      "Junfeng Fang",
      "Jiaheng Zhang",
      "Bryan Hooi"
    ],
    "abstract": "To enhance the safety of VLMs, this paper introduces a novel reasoning-based\nVLM guard model dubbed GuardReasoner-VL. The core idea is to incentivize the\nguard model to deliberatively reason before making moderation decisions via\nonline RL. First, we construct GuardReasoner-VLTrain, a reasoning corpus with\n123K samples and 631K reasoning steps, spanning text, image, and text-image\ninputs. Then, based on it, we cold-start our model's reasoning ability via SFT.\nIn addition, we further enhance reasoning regarding moderation through online\nRL. Concretely, to enhance diversity and difficulty of samples, we conduct\nrejection sampling followed by data augmentation via the proposed safety-aware\ndata concatenation. Besides, we use a dynamic clipping parameter to encourage\nexploration in early stages and exploitation in later stages. To balance\nperformance and token efficiency, we design a length-aware safety reward that\nintegrates accuracy, format, and token cost. Extensive experiments demonstrate\nthe superiority of our model. Remarkably, it surpasses the runner-up by 19.27%\nF1 score on average. We release data, code, and models (3B/7B) of\nGuardReasoner-VL at https://github.com/yueliu1999/GuardReasoner-VL/",
    "pdf_url": "http://arxiv.org/pdf/2505.11049v1",
    "published": "2025-05-16T09:46:10+00:00",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13504v1",
    "title": "An agentic system with reinforcement-learned subsystem improvements for parsing form-like documents",
    "authors": [
      "Ayesha Amjad",
      "Saurav Sthapit",
      "Tahir Qasim Syed"
    ],
    "abstract": "Extracting alphanumeric data from form-like documents such as invoices,\npurchase orders, bills, and financial documents is often performed via vision\n(OCR) and learning algorithms or monolithic pipelines with limited potential\nfor systemic improvements. We propose an agentic AI system that leverages Large\nLanguage Model (LLM) agents and a reinforcement learning (RL) driver agent to\nautomate consistent, self-improving extraction under LLM inference uncertainty.\nOur work highlights the limitations of monolithic LLM-based extraction and\nintroduces a modular, multi-agent framework with task-specific prompts and an\nRL policy of rewards and penalties to guide a meta-prompting agent to learn\nfrom past errors and improve prompt-based actor agents. This self-corrective\nadaptive system handles diverse documents, file formats, layouts, and LLMs,\naiming to automate accurate information extraction without the need for human\nintervention. Results as reported on two benchmark datasets of SOIRE, and CORD,\nare promising for the agentic AI framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.13504v1",
    "published": "2025-05-16T09:46:10+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11568v2",
    "title": "BioCube: A Multimodal Dataset for Biodiversity Research",
    "authors": [
      "Stylianos Stasinos",
      "Martino Mensio",
      "Elena Lazovik",
      "Athanasios Trantas"
    ],
    "abstract": "Biodiversity research requires complete and detailed information to study\necosystem dynamics at different scales. Employing data-driven methods like\nMachine Learning is getting traction in ecology and more specific biodiversity,\noffering alternative modelling pathways. For these methods to deliver accurate\nresults there is the need for large, curated and multimodal datasets that offer\ngranular spatial and temporal resolutions. In this work, we introduce BioCube,\na multimodal, fine-grained global dataset for ecology and biodiversity\nresearch. BioCube incorporates species observations through images, audio\nrecordings and descriptions, environmental DNA, vegetation indices,\nagricultural, forest, land indicators, and high-resolution climate variables.\nAll observations are geospatially aligned under the WGS84 geodetic system,\nspanning from 2000 to 2020. The dataset will become available at\nhttps://huggingface.co/datasets/BioDT/BioCube while the acquisition and\nprocessing code base at https://github.com/BioDT/bfm-data.",
    "pdf_url": "http://arxiv.org/pdf/2505.11568v2",
    "published": "2025-05-16T09:46:08+00:00",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.11048v1",
    "title": "Revisiting the bimodality of galactic habitability in IllustrisTNG",
    "authors": [
      "Ana Mitrašinović",
      "Branislav Vukotić",
      "Teodora Žižak",
      "Miroslav Micic",
      "Milan M. Ćirković"
    ],
    "abstract": "The potential of galaxies to host habitable planets is central to\nastrobiology, tightly linked to galaxy-scale evolution and cosmological\nprocesses. Using IllustrisTNG, we revisit the proposed local peak in the\nmass-metallicity relation for small, metal-rich, star-forming galaxies\n(Cloudlet) as an indicator of enhanced galactic habitability. We refine the\nearlier analysis by applying updated filtering criteria to identify a more\nrefined sample, further selecting objects based on their history. This process\nresulted in a confirmed sample of 97 dwarf galaxies, alongside 519 additional\nstructures of uncertain origin, potentially comprising both numerical artefacts\nand unrecognised physical systems. Under these stricter conditions, the\nproposed bimodality in galactic habitability is strongly diminished. However,\nthe astrobiological potential of metal-rich dwarfs, most of which are compact\nremnants of more massive galaxies that underwent tidal stripping, is a\nthrilling area of exploration. Although dense stellar environments are\ntraditionally seen as inhospitable, recent studies highlight the role of\ndynamic environments in enhancing the distribution of biological material.\nFurthermore, the potential habitability of tidal structures formed in the\naftermath of galactic interactions is a fascinating possibility. Our findings\nsuggest that non-traditional structures support conditions favourable for life,\nopening up exciting new avenues for astrobiological research. This research\nunderscores the need for a holistic approach to studying habitability that\nmoves beyond planetary and stellar-focused frameworks to incorporate the\nbroader galactic environment. Understanding the interactions between galaxies,\ntheir evolution, and the influence of their surroundings is essential to\ndeveloping a more comprehensive model of how and where life might emerge and\npersist across the Universe.",
    "pdf_url": "http://arxiv.org/pdf/2505.11048v1",
    "published": "2025-05-16T09:42:50+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11047v1",
    "title": "User-centric Vehicle-to-Grid Optimization with an Input Convex Neural Network-based Battery Degradation Model",
    "authors": [
      "Arghya Mallick",
      "Georgios Pantazis",
      "Mohammad Khosravi",
      "Peyman Mohajerin Esfahani",
      "Sergio Grammatico"
    ],
    "abstract": "We propose a data-driven, user-centric vehicle-to-grid (V2G) methodology\nbased on multi-objective optimization to balance battery degradation and V2G\nrevenue according to EV user preference. Given the lack of accurate and\ngeneralizable battery degradation models, we leverage input convex neural\nnetworks (ICNNs) to develop a data-driven degradation model trained on\nextensive experimental datasets. This approach enables our model to capture\nnonconvex dependencies on battery temperature and time while maintaining\nconvexity with respect to the charging rate. Such a partial convexity property\nensures that the second stage of our methodology remains computationally\nefficient. In the second stage, we integrate our data-driven degradation model\ninto a multi-objective optimization framework to generate an optimal smart\ncharging profile for each EV. This profile effectively balances the trade-off\nbetween financial benefits from V2G participation and battery degradation,\ncontrolled by a hyperparameter reflecting the user prioritization of battery\nhealth. Numerical simulations show the high accuracy of the ICNN model in\npredicting battery degradation for unseen data. Finally, we present a trade-off\ncurve illustrating financial benefits from V2G versus losses from battery\nhealth degradation based on user preferences and showcase smart charging\nstrategies under realistic scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.11047v1",
    "published": "2025-05-16T09:42:00+00:00",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11046v1",
    "title": "Artifacts of Idiosyncracy in Global Street View Data",
    "authors": [
      "Tim Alpherts",
      "Sennay Ghebreab",
      "Nanne van Noord"
    ],
    "abstract": "Street view data is increasingly being used in computer vision applications\nin recent years. Machine learning datasets are collected for these applications\nusing simple sampling techniques. These datasets are assumed to be a systematic\nrepresentation of cities, especially when densely sampled. Prior works however,\nshow that there are clear gaps in coverage, with certain cities or regions\nbeing covered poorly or not at all. Here we demonstrate that a cities'\nidiosyncracies, such as city layout, may lead to biases in street view data for\n28 cities across the globe, even when they are densely covered. We\nquantitatively uncover biases in the distribution of coverage of street view\ndata and propose a method for evaluation of such distributions to get better\ninsight in idiosyncracies in a cities' coverage. In addition, we perform a case\nstudy of Amsterdam with semi-structured interviews, showing how idiosyncracies\nof the collection process impact representation of cities and regions and\nallowing us to address biases at their source.",
    "pdf_url": "http://arxiv.org/pdf/2505.11046v1",
    "published": "2025-05-16T09:40:53+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11045v1",
    "title": "Scalable thru-hole epitaxy of GaN through self-adjusting $h$-BN masks via solution-processed 2D stacks",
    "authors": [
      "Jongwoo Ha",
      "Minah Choi",
      "Jieun Yang",
      "Chinkyo Kim"
    ],
    "abstract": "Selective epitaxy on 2D-material masks is a promising pathway for achieving\nlocalized, defect-suppressed GaN growth, but conventional 2D transfer processes\nlimit scalability and interface control. Here, we demonstrate a thru-hole\nepitaxy (THE) method that enables vertically connected and laterally overgrown\nGaN domains through a spin-coated, solution-processed stack of hexagonal boron\nnitride ($h$-BN) flakes. The disordered $h$-BN mask exhibits a self-adjusting\nstructure during growth, which locally reconfigures to allow percolative\nprecursor transport and coherent GaN nucleation beneath otherwise blocking\nlayers. Comprehensive structural analyses using scanning electron microscopy,\nRaman mapping, and high-resolution transmission electron microscopy confirm\nboth the presence of epitaxial GaN beneath the h-BN and suppression of\nthreading dislocations. This strategy eliminates the need for patterned 2D mask\ntransfers and demonstrates a scalable route to selective-area GaN growth on\narbitrary substrates, relevant to future micro-LED and photonic integration\nplatforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.11045v1",
    "published": "2025-05-16T09:38:23+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11044v1",
    "title": "Exploration by Random Distribution Distillation",
    "authors": [
      "Zhirui Fang",
      "Kai Yang",
      "Jian Tao",
      "Jiafei Lyu",
      "Lusong Li",
      "Li Shen",
      "Xiu Li"
    ],
    "abstract": "Exploration remains a critical challenge in online reinforcement learning, as\nan agent must effectively explore unknown environments to achieve high returns.\nCurrently, the main exploration algorithms are primarily count-based methods\nand curiosity-based methods, with prediction-error methods being a prominent\nexample. In this paper, we propose a novel method called \\textbf{R}andom\n\\textbf{D}istribution \\textbf{D}istillation (RDD), which samples the output of\na target network from a normal distribution. RDD facilitates a more extensive\nexploration by explicitly treating the difference between the prediction\nnetwork and the target network as an intrinsic reward. Furthermore, by\nintroducing randomness into the output of the target network for a given state\nand modeling it as a sample from a normal distribution, intrinsic rewards are\nbounded by two key components: a pseudo-count term ensuring proper exploration\ndecay and a discrepancy term accounting for predictor convergence. We\ndemonstrate that RDD effectively unifies both count-based and prediction-error\napproaches. It retains the advantages of prediction-error methods in\nhigh-dimensional spaces, while also implementing an intrinsic reward decay mode\nakin to the pseudo-count method. In the experimental section, RDD is compared\nwith more advanced methods in a series of environments. Both theoretical\nanalysis and experimental results confirm the effectiveness of our approach in\nimproving online exploration for reinforcement learning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.11044v1",
    "published": "2025-05-16T09:38:21+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11043v1",
    "title": "Angle-dependent resonant tunneling and thermoelectric energy management in a hybrid 1D-2D-1D semiconductor nanostructure",
    "authors": [
      "Xiaoguang Luo",
      "Jiaming Wang",
      "Jiawen Dai",
      "Junqiang Zhang",
      "Nian Liu"
    ],
    "abstract": "Low-dimensional semiconductors have been widely exploited in thermoelectric\nenergy conversion for high efficiencies due to their suppressed lattice thermal\nconduction, sharply defined electronic density of states, and tunable\nenergy-selective electron transmission. However, the widespread challenge of\nFermi-level pinning or doping constraints limit precise control over\nthermoelectric energy management via chemical potential modulation. Here, we\nproposed an alternative strategy: leveraging angle-dependent electron incidence\nto dynamically manipulate electron transmission and heat transport, which was\nimplemented theoretically in a two-dimensional InP/InAs/InP double-barrier\nheterostructure integrated with laterally one-dimensional electrodes. By\ncombining the transfer matrix method and Landauer formalism, we demonstrated\nthe angle-dependent resonant tunneling dynamics, tunable negative differential\nresistance effect, and near-Carnot limits in thermoelectric energy conversions.\nAngular modulation enables precise control over transmission resonances,\nfacilitating dynamic transitions among thermoelectric regimes (power\ngeneration, cooling, and hybrid heating) without requiring extreme chemical\npotential shifts. This work establishes angularly resolved electron\ntransmission as a versatile mechanism for on-chip thermal management and\ncryogenic applications, offering a pathway to circumvent material limitations\nin next-generation nanoelectronics and quantum devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.11043v1",
    "published": "2025-05-16T09:37:13+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.11042v2",
    "title": "Delayed Active Swimmer in a Velocity Landscape",
    "authors": [
      "Viktor Holubec",
      "Alexander Fischer",
      "Giovanni Volpe",
      "Frank Cichos"
    ],
    "abstract": "Self-propelled active particles exhibit delayed responses to environmental\nchanges, modulating their propulsion speed through intrinsic sensing and\nfeedback mechanisms. This adaptive behavior fundamentally determines their\ndynamics and self-organization in active matter systems, with implications for\nbiological microswimmers and engineered microrobots. Here, we investigate\nactive Brownian particles whose propulsion speed is governed by spatially\nvarying activity landscapes, incorporating a temporal delay between\nenvironmental sensing and speed adaptation. Through analytical solutions\nderived for both short-time and long-time delay regimes, we demonstrate that\nsteady-state density and polarization profiles exhibit maxima at characteristic\ndelays. Significantly, we observe that the polarization profile undergoes sign\nreversal when the swimming distance during the delay time exceeds the\ncharacteristic diffusion length, providing a novel mechanism for controlling\nparticle transport without external fields. Our theoretical predictions,\nvalidated through experimental observations and numerical simulations,\nestablish time delay as a crucial control parameter for particle transport and\norganization in active matter systems. These findings provide insights into how\nbiological microorganisms might use response delays to gain navigation\nadvantages and suggest design principles for synthetic microswimmers with\nprogrammable responses to heterogeneous environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.11042v2",
    "published": "2025-05-16T09:36:48+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.11040v1",
    "title": "Efficient Attention via Pre-Scoring: Prioritizing Informative Keys in Transformers",
    "authors": [
      "Zhexiang Li",
      "Haoyu Wang",
      "Yutong Bao",
      "David Woodruff"
    ],
    "abstract": "Recent advances in transformer architectures deeply enhance long-context\nlanguage modeling. Among them, HyperAttention achieves competitive efficiency\nby combining a single-level LSH-based clustering with uniform residual\nsampling. However,such a sampling limits crucial keys' capturing, which in turn\nraises the overall perplexity. In this paper, we propose a pre-scoring\nmechanism to assist HyperAttention to prioritize significant keys.\nSpecifically, we introduce three scoring methods: K-means clustering, K-median\nclustering, and leverage score-based ranking (inspired by LevAttention) to\nfilter keys effectively. We further replace HyperAttention's original uniform\nresidual sampling entirely, relying exclusively on our pre-scoring mechanism.\nExperiments on ChatGLM2 (131k token context) reduce perplexity from 12 to 8.3,\nwhich outperforms standard HyperAttention. Moreover, when running on the\nVision-Transformer (ViT), our method shows that it can guarantee similar\naccuracy compared with LevAttention, and will surpass LevAttention given\nspecific parameters. Although this method introduces computational overhead,\nits combination with HyperAttention remains 20 times faster than\nFlashAttention, providing a balanced trade-off between speed and modeling\naccuracy. Our results highlight the effectiveness of integrating pre-scoring\ninto hierarchical attention mechanisms, significantly improving Transformer's\nefficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.11040v1",
    "published": "2025-05-16T09:35:11+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11041v1",
    "title": "In silico tool for identification of colorectal cancer from cell-free DNA biomarkers",
    "authors": [
      "Kartavya Mathur",
      "Shipra Jain",
      "Nisha Bajiya",
      "Nishant Kumar",
      "Gajendra P. S. Raghava"
    ],
    "abstract": "Colorectal cancer remains a major global health concern, with early detection\nbeing pivotal for improving patient outcomes. In this study, we leveraged high\nthroughput methylation profiling of cellfree DNA to identify and validate\ndiagnostic biomarkers for CRC. The GSE124600 study data were downloaded from\nthe Gene Expression Omnibus, as the discovery cohort, comprising 142 CRC and\n132 normal cfDNA methylation profiles obtained via MCTA seq. After\npreprocessing and filtering, 97,863 CpG sites were retained for further\nanalysis. Differential methylation analysis using statistical tests identified\n30,791 CpG sites as significantly altered in CRC samples, where p is less than\n0.05. Univariate scoring enabled the selection of top ranking features, which\nwere further refined using multiple feature selection algorithms, including\nRecursive Feature Elimination, Sequential Feature Selection, and SVC L1.\nVarious machine learning models such as Logistic Regression, Support Vector\nMachines, Random Forest, and Multi layer Perceptron were trained and tested\nusing independent validation datasets. The best performance was achieved with\nan MLP model trained on 25 features selected by RFE, reaching an AUROC of 0.89\nand MCC of 0.78 on validation data. Additionally, a deep learning based\nconvolutional neural network achieved an AUROC of 0.78. Functional annotation\nof the most predictive CpG sites identified several genes involved in key\ncellular processes, some of which were validated for differential expression in\nCRC using the GEPIA2 platform. Our study highlights the potential of cfDNA\nmethylation markers combined with ML and DL models for noninvasive and accurate\nCRC detection, paving the way for clinically relevant diagnostic tools.",
    "pdf_url": "http://arxiv.org/pdf/2505.11041v1",
    "published": "2025-05-16T09:35:11+00:00",
    "categories": [
      "q-bio.GN"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.11039v1",
    "title": "Minimal $(n-2)$-umbilic submanifolds of the Euclidean space",
    "authors": [
      "A. E. Kanellopoulou"
    ],
    "abstract": "This paper investigates minimal $n$-dimensional submanifolds in the Euclidean\nspace that are $(n-2)$-umbilic, meaning they carry an umbilical distribution of\nrank $n-2$. We establish a correspondence between the class of minimal\n($n-2$)-umbilic submanifolds and the class of ($n-2$)-singular minimal\nsurfaces. These surfaces are the critical points of its \"energy potential\" and\nhave been previously studied in various contexts, including physics and\narchitecture where, for instance, they model surfaces with minimal potential\nenergy under gravitational forces. We show that minimal, generic,\n($n-2$)-umbilic submanifolds, $n\\geq4$, are ($n-2$)-rotational submanifolds\nwhose profile is an ($n-2$)-singular minimal surface and vise versa.\nFurthermore, we develop a Weierstrass type method of local parametrization of\nall ($n-2$)-singular minimal surfaces, enabling a parametric description of all\nminimal $n$-dimensional, $n\\geq4$, hypersurfaces of the Euclidean space with a\nnowhere vanishing principal curvature of multiplicity $n-2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11039v1",
    "published": "2025-05-16T09:33:48+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11038v1",
    "title": "Connected dom-forcing sets in graphs",
    "authors": [
      "Susanth P",
      "Charles Dominic",
      "Premodkumar K P"
    ],
    "abstract": "In a graph G, a dominating set Df subset of V (G) is called a dom-forcing set\nif the sub-graph induced by Df must form a zero forcing set. The minimum\ncardinality of such a set is known as the dom-forcing number of the graph G,\ndenoted by Fd(G). A connected dom-forcing forcing set of a graph G, is a\ndom-forcing set of G that induces a sub graph of G which is connected. The\nconnected dom-forcing number of G, Fcd(G), is the minimum size of a connected\ndom-forcing set. This study delves into the concept of the connected\ndom-forcing number Fcd(G), examining its properties and characteristics.\nFurthermore, it seeks to accurately determine Fcd(G) for several well-known\ngraphs and their graph products.",
    "pdf_url": "http://arxiv.org/pdf/2505.11038v1",
    "published": "2025-05-16T09:32:51+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11037v2",
    "title": "Evolutionary training-free guidance in diffusion model for 3D multi-objective molecular generation",
    "authors": [
      "Ruiqing Sun",
      "Dawei Feng",
      "Sen Yang",
      "Yijie Wang",
      "Huaimin Wang"
    ],
    "abstract": "Discovering novel 3D molecular structures that simultaneously satisfy\nmultiple property targets remains a central challenge in materials and drug\ndesign. Although recent diffusion-based models can generate 3D conformations,\nthey require expensive retraining for each new property or property-combination\nand lack flexibility in enforcing structural constraints. We introduce EGD\n(Evolutionary Guidance in Diffusion), a training-free framework that embeds\nevolutionary operators directly into the diffusion sampling process. By\nperforming crossover on noise-perturbed samples and then denoising them with a\npretrained Unconditional diffusion model, EGD seamlessly blends structural\nfragments and steers generation toward user-specified objectives without any\nadditional model updates. On both single- and multi-target 3D conditional\ngeneration tasks-and on multi-objective optimization of quantum properties EGD\noutperforms state-of-the-art conditional diffusion methods in accuracy and runs\nup to five times faster per generation. In the single-objective optimization of\nprotein ligands, EGD enables customized ligand generation. Moreover, EGD can\nembed arbitrary 3D fragments into the generated molecules while optimizing\nmultiple conflicting properties in one unified process. This combination of\nefficiency, flexibility, and controllable structure makes EGD a powerful tool\nfor rapid, guided exploration of chemical space.",
    "pdf_url": "http://arxiv.org/pdf/2505.11037v2",
    "published": "2025-05-16T09:32:40+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.11036v1",
    "title": "Dimensionality dependence of diffusion-entropy scaling: Sensitivity to the diffusion mechanism",
    "authors": [
      "Nayana Venkatareddy",
      "Mohd Moid",
      "Prabal K. Maiti",
      "Biman Bagchi"
    ],
    "abstract": "While entropy quantifies the volume of the accessible phase space, diffusion\ncharacterizes the rate of its exploration, capturing distinct yet\ninterconnected aspects of a system's dynamics. In this Letter, we employ\ncomputer simulations to independently compute D and S for Lennard-Jones (LJ)\nliquid and water in two and three dimensions, and for water also in one\ndimension, across a broad range of thermodynamic states. We observe that the\nratio of diffusion coefficients between two states exhibits a nearly perfect\nexponential dependence on their entropy difference. For LJ liquids, the\nprefactor of the exponential shows a strong dimensionality dependence,\nconsistent in trend but quantitatively different from theoretical predictions.\nIn contrast, water displays a remarkably weak dimensionality dependence,\ndeviating from theoretical expectations, which we attribute to the dominant\nrole of jump diffusion. Surprisingly, the exponential diffusion-entropy\nrelationship persists even when translational and rotational contributions to\nentropy are considered separately, underscoring the robustness of the D-S\nrelation across different degrees of freedom.",
    "pdf_url": "http://arxiv.org/pdf/2505.11036v1",
    "published": "2025-05-16T09:31:49+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.11035v1",
    "title": "Deep Latent Variable Model based Vertical Federated Learning with Flexible Alignment and Labeling Scenarios",
    "authors": [
      "Kihun Hong",
      "Sejun Park",
      "Ganguk Hwang"
    ],
    "abstract": "Federated learning (FL) has attracted significant attention for enabling\ncollaborative learning without exposing private data. Among the primary\nvariants of FL, vertical federated learning (VFL) addresses feature-partitioned\ndata held by multiple institutions, each holding complementary information for\nthe same set of users. However, existing VFL methods often impose restrictive\nassumptions such as a small number of participating parties, fully aligned\ndata, or only using labeled data. In this work, we reinterpret alignment gaps\nin VFL as missing data problems and propose a unified framework that\naccommodates both training and inference under arbitrary alignment and labeling\nscenarios, while supporting diverse missingness mechanisms. In the experiments\non 168 configurations spanning four benchmark datasets, six training-time\nmissingness patterns, and seven testing-time missingness patterns, our method\noutperforms all baselines in 160 cases with an average gap of 9.6 percentage\npoints over the next-best competitors. To the best of our knowledge, this is\nthe first VFL framework to jointly handle arbitrary data alignment, unlabeled\ndata, and multi-party collaboration all at once.",
    "pdf_url": "http://arxiv.org/pdf/2505.11035v1",
    "published": "2025-05-16T09:30:15+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11034v1",
    "title": "CleanPatrick: A Benchmark for Image Data Cleaning",
    "authors": [
      "Fabian Gröger",
      "Simone Lionetti",
      "Philippe Gottfrois",
      "Alvaro Gonzalez-Jimenez",
      "Ludovic Amruthalingam",
      "Elisabeth Victoria Goessinger",
      "Hanna Lindemann",
      "Marie Bargiela",
      "Marie Hofbauer",
      "Omar Badri",
      "Philipp Tschandl",
      "Arash Koochek",
      "Matthew Groh",
      "Alexander A. Navarini",
      "Marc Pouly"
    ],
    "abstract": "Robust machine learning depends on clean data, yet current image data\ncleaning benchmarks rely on synthetic noise or narrow human studies, limiting\ncomparison and real-world relevance. We introduce CleanPatrick, the first\nlarge-scale benchmark for data cleaning in the image domain, built upon the\npublicly available Fitzpatrick17k dermatology dataset. We collect 496,377\nbinary annotations from 933 medical crowd workers, identify off-topic samples\n(4%), near-duplicates (21%), and label errors (22%), and employ an aggregation\nmodel inspired by item-response theory followed by expert review to derive\nhigh-quality ground truth. CleanPatrick formalizes issue detection as a ranking\ntask and adopts typical ranking metrics mirroring real audit workflows.\nBenchmarking classical anomaly detectors, perceptual hashing, SSIM, Confident\nLearning, NoiseRank, and SelfClean, we find that, on CleanPatrick,\nself-supervised representations excel at near-duplicate detection, classical\nmethods achieve competitive off-topic detection under constrained review\nbudgets, and label-error detection remains an open challenge for fine-grained\nmedical classification. By releasing both the dataset and the evaluation\nframework, CleanPatrick enables a systematic comparison of image-cleaning\nstrategies and paves the way for more reliable data-centric artificial\nintelligence.",
    "pdf_url": "http://arxiv.org/pdf/2505.11034v1",
    "published": "2025-05-16T09:29:41+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11033v2",
    "title": "Einstein Telescope and Cosmic Explorer",
    "authors": [
      "Matteo Di Giovanni"
    ],
    "abstract": "The goal of this talk is to give an overview of the current status of the\ndevelopment of the Einstein Telescope and Cosmic Explorer ground based\ngravitational wave (GW) detectors and of their foreseen scientific goals. These\ndetectors will be up to a factor 8 more sensitive across the band covered by\ncurrent detectors, namely LIGO, Virgo and KAGRA, and will extend the accessible\nfrequency band towards the low frequency regime, i.e., below 10 Hz. These\nimprovements will not only enhance the number and quality of GW observations,\nbut will also enable researchers to have access to sources and physical\nprocesses which are out of reach for current detectors and explore the\npossibility of detecting previously unknown GW sources. The improvement in\nsensitivity in the low frequency regime will also increase the observation time\nof compact binary coalescence events, strengthening the collaboration with\nelectromagnetic observatories for multimessenger observations of binary neutron\nstar events. In fact, current detectors proved that joint observations of GW\nevents with electromagnetic observatories are not only possible, but they can\nalso give us unprecedented insights on the underlying physics of astrophysical\nprocesses.",
    "pdf_url": "http://arxiv.org/pdf/2505.11033v2",
    "published": "2025-05-16T09:29:21+00:00",
    "categories": [
      "gr-qc",
      "physics.ins-det"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.11032v2",
    "title": "DexGarmentLab: Dexterous Garment Manipulation Environment with Generalizable Policy",
    "authors": [
      "Yuran Wang",
      "Ruihai Wu",
      "Yue Chen",
      "Jiarui Wang",
      "Jiaqi Liang",
      "Ziyu Zhu",
      "Haoran Geng",
      "Jitendra Malik",
      "Pieter Abbeel",
      "Hao Dong"
    ],
    "abstract": "Garment manipulation is a critical challenge due to the diversity in garment\ncategories, geometries, and deformations. Despite this, humans can effortlessly\nhandle garments, thanks to the dexterity of our hands. However, existing\nresearch in the field has struggled to replicate this level of dexterity,\nprimarily hindered by the lack of realistic simulations of dexterous garment\nmanipulation. Therefore, we propose DexGarmentLab, the first environment\nspecifically designed for dexterous (especially bimanual) garment manipulation,\nwhich features large-scale high-quality 3D assets for 15 task scenarios, and\nrefines simulation techniques tailored for garment modeling to reduce the\nsim-to-real gap. Previous data collection typically relies on teleoperation or\ntraining expert reinforcement learning (RL) policies, which are labor-intensive\nand inefficient. In this paper, we leverage garment structural correspondence\nto automatically generate a dataset with diverse trajectories using only a\nsingle expert demonstration, significantly reducing manual intervention.\nHowever, even extensive demonstrations cannot cover the infinite states of\ngarments, which necessitates the exploration of new algorithms. To improve\ngeneralization across diverse garment shapes and deformations, we propose a\nHierarchical gArment-manipuLation pOlicy (HALO). It first identifies\ntransferable affordance points to accurately locate the manipulation area, then\ngenerates generalizable trajectories to complete the task. Through extensive\nexperiments and detailed analysis of our method and baseline, we demonstrate\nthat HALO consistently outperforms existing methods, successfully generalizing\nto previously unseen instances even with significant variations in shape and\ndeformation where others fail. Our project page is available at:\nhttps://wayrise.github.io/DexGarmentLab/.",
    "pdf_url": "http://arxiv.org/pdf/2505.11032v2",
    "published": "2025-05-16T09:26:59+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.11031v2",
    "title": "OntoURL: A Benchmark for Evaluating Large Language Models on Symbolic Ontological Understanding, Reasoning and Learning",
    "authors": [
      "Xiao Zhang",
      "Huiyuan Lai",
      "Qianru Meng",
      "Johan Bos"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\na range of natural language processing tasks, yet their ability to process\nstructured symbolic knowledge remains underexplored. To address this gap, we\npropose a taxonomy of LLMs' ontological capabilities and introduce OntoURL, the\nfirst comprehensive benchmark designed to systematically evaluate LLMs'\nproficiency in handling ontologies -- formal, symbolic representations of\ndomain knowledge through concepts, relationships, and instances. Based on the\nproposed taxonomy, OntoURL systematically assesses three dimensions:\nunderstanding, reasoning, and learning through 15 distinct tasks comprising\n58,981 questions derived from 40 ontologies across 8 domains. Experiments with\n20 open-source LLMs reveal significant performance differences across models,\ntasks, and domains, with current LLMs showing proficiency in understanding\nontological knowledge but substantial weaknesses in reasoning and learning\ntasks. These findings highlight fundamental limitations in LLMs' capability to\nprocess symbolic knowledge and establish OntoURL as a critical benchmark for\nadvancing the integration of LLMs with formal knowledge representations.",
    "pdf_url": "http://arxiv.org/pdf/2505.11031v2",
    "published": "2025-05-16T09:26:06+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11030v1",
    "title": "The heteronomy of algorithms: Traditional knowledge and computational knowledge",
    "authors": [
      "David M. Berry"
    ],
    "abstract": "If an active citizen should increasingly be a computationally enlightened\none, replacing the autonomy of reason with the heteronomy of algorithms, then I\nargue in this article that we must begin teaching the principles of critiquing\nthe computal through new notions of what we might call digital Bildung. Indeed,\nif civil society itself is mediated by computational systems and media, the\npublic use of reason must also be complemented by skills for negotiating and\nusing these computal forms to articulate such critique. Not only is there a\nneed to raise the intellectual tone regarding computation and its related\nsoftwarization processes, but there is an urgent need to attend to the likely\nepistemic challenges from computation which, as presently constituted, tends\ntowards justification through a philosophy of utility rather than through a\nphilosophy of care for the territory of the intellect. We therefore need to\ndevelop an approach to this field that uses concepts and methods drawn from\nphilosophy, politics, history, anthropology, sociology, media studies, computer\nscience, and the humanities more generally, to try to understand these issues -\nparticularly the way in which software and data increasingly penetrate our\neveryday life and the pressures and fissures that are created. We must, in\nother words, move to undertake a critical interdisciplinary research program to\nunderstand the way in which these systems are created, instantiated, and\nnormatively engendered in both specific and general contexts.",
    "pdf_url": "http://arxiv.org/pdf/2505.11030v1",
    "published": "2025-05-16T09:25:00+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.MM",
      "K.4.0; K.4.1"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11029v1",
    "title": "Exploiting the Asymmetric Uncertainty Structure of Pre-trained VLMs on the Unit Hypersphere",
    "authors": [
      "Li Ju",
      "Max Andersson",
      "Stina Fredriksson",
      "Edward Glöckner",
      "Andreas Hellander",
      "Ekta Vats",
      "Prashant Singh"
    ],
    "abstract": "Vision-language models (VLMs) as foundation models have significantly\nenhanced performance across a wide range of visual and textual tasks, without\nrequiring large-scale training from scratch for downstream tasks. However,\nthese deterministic VLMs fail to capture the inherent ambiguity and uncertainty\nin natural language and visual data. Recent probabilistic post-hoc adaptation\nmethods address this by mapping deterministic embeddings onto probability\ndistributions; however, existing approaches do not account for the asymmetric\nuncertainty structure of the modalities, and the constraint that meaningful\ndeterministic embeddings reside on a unit hypersphere, potentially leading to\nsuboptimal performance. In this paper, we address the asymmetric uncertainty\nstructure inherent in textual and visual data, and propose AsymVLM to build\nprobabilistic embeddings from pre-trained VLMs on the unit hypersphere,\nenabling uncertainty quantification. We validate the effectiveness of the\nprobabilistic embeddings on established benchmarks, and present comprehensive\nablation studies demonstrating the inherent nature of asymmetry in the\nuncertainty structure of textual and visual data.",
    "pdf_url": "http://arxiv.org/pdf/2505.11029v1",
    "published": "2025-05-16T09:24:29+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11028v1",
    "title": "Remarks on criticality theory for Schrödinger operators and its application to wave equations with potentials",
    "authors": [
      "Motohiro Sobajima"
    ],
    "abstract": "In this paper, we give an alternative perspective of the criticality theory\nfor (nonnegative) Schr\\\"odinger operators. Schr\\\"odinger operator $S=-\\Delta+V$\nis classified as subcritical/critical in terms of the existence/nonexistence of\na positive Green function for the associated elliptic equation $Su=f$. Such a\nproperty strongly affects to the large-time behavior of solutions to the\nparabolic equation $\\partial_tv+Sv=0$. In this paper, we propose a remarkable\nquantity in terms of the structure of Hilbert lattices, which keeps some\nimportant properties including the notion of criticality theory. As an\napplication, we study the large-time behavior of solutions to the hyperbolic\nequation $\\partial_t^2w+Sw=0$.",
    "pdf_url": "http://arxiv.org/pdf/2505.11028v1",
    "published": "2025-05-16T09:22:23+00:00",
    "categories": [
      "math.AP",
      "35J10, 35B09, 47F05"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11027v2",
    "title": "A User-centric Game for Balancing V2G Benefits with Battery Degradation of Electric Vehicles",
    "authors": [
      "Arghya Mallick",
      "Georgios Pantazis",
      "Peyman Mohajerin Esfahani",
      "Sergio Grammatico"
    ],
    "abstract": "We present a novel user-centric vehicle-to-grid (V2G) framework that enables\nelectric vehicle (EV) users to balance the trade-off between financial benefits\nfrom V2G and battery health degradation based on individual preference signals.",
    "pdf_url": "http://arxiv.org/pdf/2505.11027v2",
    "published": "2025-05-16T09:22:08+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.11026v1",
    "title": "StRuCom: A Novel Dataset of Structured Code Comments in Russian",
    "authors": [
      "Maria Dziuba",
      "Valentin Malykh"
    ],
    "abstract": "Structured code comments in docstring format are essential for code\ncomprehension and maintenance, but existing machine learning models for their\ngeneration perform poorly for Russian compared to English. To bridge this gap,\nwe present StRuCom - the first large-scale dataset (153K examples) specifically\ndesigned for Russian code documentation. Unlike machine-translated English\ndatasets that distort terminology (e.g., technical loanwords vs. literal\ntranslations) and docstring structures, StRuCom combines human-written comments\nfrom Russian GitHub repositories with synthetically generated ones, ensuring\ncompliance with Python, Java, JavaScript, C#, and Go standards through\nautomated validation. Fine-tuning Qwen2.5-Coder models (0.5B-7B) on StRuCom\nshows statistically significant improvements of chrf++ and BERTScore over\nbaseline models.",
    "pdf_url": "http://arxiv.org/pdf/2505.11026v1",
    "published": "2025-05-16T09:22:07+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11025v1",
    "title": "Generalization Bounds for Quantum Learning via Rényi Divergences",
    "authors": [
      "Naqueeb Ahmad Warsi",
      "Ayanava Dasgupta",
      "Masahito Hayashi"
    ],
    "abstract": "This work advances the theoretical understanding of quantum learning by\nestablishing a new family of upper bounds on the expected generalization error\nof quantum learning algorithms, leveraging the framework introduced by Caro et\nal. (2024) and a new definition for the expected true loss. Our primary\ncontribution is the derivation of these bounds in terms of quantum and\nclassical R\\'enyi divergences, utilizing a variational approach for evaluating\nquantum R\\'enyi divergences, specifically the Petz and a newly introduced\nmodified sandwich quantum R\\'enyi divergence. Analytically and numerically, we\ndemonstrate the superior performance of the bounds derived using the modified\nsandwich quantum R\\'enyi divergence compared to those based on the Petz\ndivergence. Furthermore, we provide probabilistic generalization error bounds\nusing two distinct techniques: one based on the modified sandwich quantum\nR\\'enyi divergence and classical R\\'enyi divergence, and another employing\nsmooth max R\\'enyi divergence.",
    "pdf_url": "http://arxiv.org/pdf/2505.11025v1",
    "published": "2025-05-16T09:21:31+00:00",
    "categories": [
      "quant-ph",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11024v1",
    "title": "Leveraging Real-Time Data Analysis and Multiple Kernel Learning for Manufacturing of Innovative Steels",
    "authors": [
      "Wolfgang Rannetbauer",
      "Simon Hubmer",
      "Carina Hambrock",
      "Ronny Ramlau"
    ],
    "abstract": "The implementation of thermally sprayed components in steel manufacturing\npresents challenges for production and plant maintenance. While enhancing\nperformance through specialized surface properties, these components may\nencounter difficulties in meeting modified requirements due to standardization\nin the refurbishment process. This article proposes updating the established\ncoating process for thermally spray coated components for steel manufacturing\n(TCCSM) by integrating real-time data analytics and predictive quality\nmanagement. Two essential components--the data aggregator and the quality\npredictor--are designed through continuous process monitoring and the\napplication of data-driven methodologies to meet the dynamic demands of the\nevolving steel landscape. The quality predictor is powered by the simple and\neffective multiple kernel learning strategy with the goal of realizing\npredictive quality. The data aggregator, designed with sensors, flow meters,\nand intelligent data processing for the thermal spray coating process, is\nproposed to facilitate real-time analytics. The performance of this combination\nwas verified using small-scale tests that enabled not only the accurate\nprediction of coating quality based on the collected data but also proactive\nnotification to the operator as soon as significant deviations are identified.",
    "pdf_url": "http://arxiv.org/pdf/2505.11024v1",
    "published": "2025-05-16T09:21:14+00:00",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11023v1",
    "title": "Informed, but Not Always Improved: Challenging the Benefit of Background Knowledge in GNNs",
    "authors": [
      "Kutalmış Coşkun",
      "Ivo Kavisanczki",
      "Amin Mirzaei",
      "Tom Siegl",
      "Bjarne C. Hiller",
      "Stefan Lüdtke",
      "Martin Becker"
    ],
    "abstract": "In complex and low-data domains such as biomedical research, incorporating\nbackground knowledge (BK) graphs, such as protein-protein interaction (PPI)\nnetworks, into graph-based machine learning pipelines is a promising research\ndirection. However, while BK is often assumed to improve model performance, its\nactual contribution and the impact of imperfect knowledge remain poorly\nunderstood. In this work, we investigate the role of BK in an important\nreal-world task: cancer subtype classification. Surprisingly, we find that (i)\nstate-of-the-art GNNs using BK perform no better than uninformed models like\nlinear regression, and (ii) their performance remains largely unchanged even\nwhen the BK graph is heavily perturbed. To understand these unexpected results,\nwe introduce an evaluation framework, which employs (i) a synthetic setting\nwhere the BK is clearly informative and (ii) a set of perturbations that\nsimulate various imperfections in BK graphs. With this, we test the robustness\nof BK-aware models in both synthetic and real-world biomedical settings. Our\nfindings reveal that careful alignment of GNN architectures and BK\ncharacteristics is necessary but holds the potential for significant\nperformance improvements.",
    "pdf_url": "http://arxiv.org/pdf/2505.11023v1",
    "published": "2025-05-16T09:21:00+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11567v1",
    "title": "Beyond Time: Cross-Dimensional Frequency Supervision for Time Series Forecasting",
    "authors": [
      "Tianyi Shi",
      "Zhu Meng",
      "Yue Chen",
      "Siyang Zheng",
      "Fei Su",
      "Jin Huang",
      "Changrui Ren",
      "Zhicheng Zhao"
    ],
    "abstract": "Time series forecasting plays a crucial role in various fields, and the\nmethods based on frequency domain analysis have become an important branch.\nHowever, most existing studies focus on the design of elaborate model\narchitectures and are often tailored for limited datasets, still lacking\nuniversality. Besides, the assumption of independent and identically\ndistributed (IID) data also contradicts the strong correlation of the time\ndomain labels. To address these issues, abandoning time domain supervision, we\npropose a purely frequency domain supervision approach named cross-dimensional\nfrequency (X-Freq) loss. Specifically, based on a statistical phenomenon, we\nfirst prove that the information entropy of the time series is higher than its\nspectral entropy, which implies higher certainty in frequency domain and thus\ncan provide better supervision. Secondly, the Fourier Transform and the Wavelet\nTransform are applied to the time dimension and the channel dimension of the\ntime series respectively, to capture the long-term and short-term frequency\nvariations as well as the spatial configuration features. Thirdly, the loss\nbetween predictions and targets is uniformly computed in the frequency domain.\nMoreover, we plug-and-play incorporate X-Freq into multiple advanced\nforecasting models and compare on 14 real-world datasets. The experimental\nresults demonstrate that, without making any modification to the original\narchitectures or hyperparameters, X-Freq can improve the forecasting\nperformance by an average of 3.3% on long-term forecasting datasets and 27.7%\non short-term ones, showcasing superior generality and practicality. The code\nwill be released publicly.",
    "pdf_url": "http://arxiv.org/pdf/2505.11567v1",
    "published": "2025-05-16T09:17:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.06289v1",
    "title": "On the role of secondary electrons in the color change of high-dose X-ray irradiated topaz",
    "authors": [
      "G. S. Elettivo",
      "M. Ferraro",
      "R. Filosa",
      "A. Nicolino",
      "B. Marmiroli",
      "A. Turchet",
      "R. G. Agostino"
    ],
    "abstract": "Owing to its high brightness, synchrotron light allows for investigating with\nextreme precision the physical properties of matter. The irradiation with\nhigh-dose X-ray beams may also lead to modification of the latter, thus\nallowing for material processing. Here we investigate the color change of topaz\nirradiated with synchrotron light, shedding light on the role played by\nsecondary electrons in the formation of color centers. As a matter of fact,\ntreatments of natural topaz to induce its color change are largely used in the\njewelry industry. Nevertheless, the physical mechanisms behind the topaz's\ncolor change have not yet been fully understood. To date, it has been shown\nthat the combined action of high-energy beam irradiation (either electrons,\nneutrons, or {\\gamma}-rays) and thermal annealing permits to provide colorless\nnatural topaz with an artificial blue color, which is largely appealed in the\ngem market. Here we demonstrate that it is possible to irreversibly provide\nnatural topaz with a blue color even by exploiting lower energy beams, such as\nX-rays, provided that enough dose is absorbed, thus paving the way for\ndeveloping novel protocols for making artificially blue topazes.",
    "pdf_url": "http://arxiv.org/pdf/2506.06289v1",
    "published": "2025-05-16T09:17:06+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11022v1",
    "title": "Beam Intensity Limitations in Future Multi-Bend Achromat Light Sources",
    "authors": [
      "Ilya Agapov",
      "Sergey Antipov"
    ],
    "abstract": "We show that emittance of fourth-generation 6 GeV machines such as PETRA IV\nis close to what is theoretically achievable due to beam intensity limitations\nfrom space charge and intra-beam scattering. Investigating these limitations,\nin particular their scaling with the bare lattice emittance and the beam\nenergy, we argue that achieving further significant emittance reduction and\nincrease in radiation brightness is only possible by increasing the beam\nenergy. We outline the design and technological challenges on the way to such\nimprovement.",
    "pdf_url": "http://arxiv.org/pdf/2505.11022v1",
    "published": "2025-05-16T09:16:37+00:00",
    "categories": [
      "physics.acc-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11021v1",
    "title": "Stabilization of a polar phase in WO3 thin films by epitaxial strain",
    "authors": [
      "Ewout van der Veer",
      "Martin F. Sarott",
      "Jack T. Eckstein",
      "Stijn Feringa",
      "Dennis van der Veen",
      "Johanna van Gent González",
      "Majid Ahmadi",
      "Ellen M. Kiens",
      "Gertjan Koster",
      "Bart J. Kooi",
      "Michael A. Carpenter",
      "Ekhard K. H. Salje",
      "Beatriz Noheda"
    ],
    "abstract": "The introduction of new simple oxides that are CMOS-compatible constitutes an\nimportant step towards multifunctional oxide electronics. One such oxide,\ntungsten trioxide (WO3), has raised much interest as an electrode material.\nHere we reveal the presence of a previously unreported polar phase of WO3,\nobtained in thin films grown on YAlO3 substrates. The epitaxial strain\nstabilizes a triclinic phase, whose unit cell could be fully determined by\nmeans of large-scale reciprocal space mapping, rarely reported in thin films.\n  Unconventional strain accommodation mechanisms enable the triclinic phase to\nbe stabilized up to unexpectedly large film thicknesses. The strain gradients\naround domain walls and local variations of octahedral tilts, observed by\nscanning transmission electron microscopy, could explain this behavior.\n  An in-plane striped domain pattern with needle-like bifurcations is visible\nin piezoresponse force microscopy maps, evidencing the polar nature of the\nfilms. Correspondingly, local modulations of the conductivity of the film are\nshown by conductive atomic force microscopy and scanning electron microscopy.\nThese results open the possibility for adding functionalities to WO3-based\ndevices by controlling conductivity and epitaxial strain.",
    "pdf_url": "http://arxiv.org/pdf/2505.11021v1",
    "published": "2025-05-16T09:15:37+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11020v1",
    "title": "Classifying Shelf Life Quality of Pineapples by Combining Audio and Visual Features",
    "authors": [
      "Yi-Lu Jiang",
      "Wen-Chang Chang",
      "Ching-Lin Wang",
      "Kung-Liang Hsu",
      "Chih-Yi Chiu"
    ],
    "abstract": "Determining the shelf life quality of pineapples using non-destructive\nmethods is a crucial step to reduce waste and increase income. In this paper, a\nmultimodal and multiview classification model was constructed to classify\npineapples into four quality levels based on audio and visual characteristics.\nFor research purposes, we compiled and released the PQC500 dataset consisting\nof 500 pineapples with two modalities: one was tapping pineapples to record\nsounds by multiple microphones and the other was taking pictures by multiple\ncameras at different locations, providing multimodal and multi-view audiovisual\nfeatures. We modified the contrastive audiovisual masked autoencoder to train\nthe cross-modal-based classification model by abundant combinations of audio\nand visual pairs. In addition, we proposed to sample a compact size of training\ndata for efficient computation. The experiments were evaluated under various\ndata and model configurations, and the results demonstrated that the proposed\ncross-modal model trained using audio-major sampling can yield 84% accuracy,\noutperforming the unimodal models of only audio and only visual by 6% and 18%,\nrespectively.",
    "pdf_url": "http://arxiv.org/pdf/2505.11020v1",
    "published": "2025-05-16T09:14:30+00:00",
    "categories": [
      "cs.CV",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11019v1",
    "title": "Predicting Financial Market Crises using Multilayer Network Analysis and LSTM-based Forecasting of Spillover Effects",
    "authors": [
      "Mahdi Kohan Sefidi"
    ],
    "abstract": "Financial crises often occur without warning, yet markets leading up to these\nevents display increasing volatility and complex interdependencies across\nmultiple sectors. This study proposes a novel approach to predicting market\ncrises by combining multilayer network analysis with Long Short-Term Memory\n(LSTM) models, using Granger causality to capture within-layer connections and\nRandom Forest to model interlayer relationships. Specifically, we utilize\nGranger causality to model the temporal dependencies between market variables\nwithin individual layers, such as asset prices, trading values, and returns. To\nrepresent the interactions between different market variables across sectors,\nwe apply Random Forest to model the interlayer connections, capturing the\nspillover effects between these features. The LSTM model is then trained to\npredict market instability and potential crises based on the dynamic features\nof the multilayer network. Our results demonstrate that this integrated\napproach, combining Granger causality, Random Forest, and LSTM, significantly\nenhances the accuracy of market crisis prediction, outperforming traditional\nforecasting models. This methodology provides a powerful tool for financial\ninstitutions and policymakers to better monitor systemic risks and take\nproactive measures to mitigate financial crises.",
    "pdf_url": "http://arxiv.org/pdf/2505.11019v1",
    "published": "2025-05-16T09:14:08+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.11018v1",
    "title": "Rethinking the Mean Teacher Strategy from the Perspective of Self-paced Learning",
    "authors": [
      "Pengchen Zhang",
      "Alan J. X. Guo",
      "Sipin Luo",
      "Zhe Han",
      "Lin Guo"
    ],
    "abstract": "Semi-supervised medical image segmentation has attracted significant\nattention due to its potential to reduce manual annotation costs. The mean\nteacher (MT) strategy, commonly understood as introducing smoothed, temporally\nlagged consistency regularization, has demonstrated strong performance across\nvarious tasks in this field. In this work, we reinterpret the MT strategy on\nsupervised data as a form of self-paced learning, regulated by the output\nagreement between the temporally lagged teacher model and the ground truth\nlabels. This idea is further extended to incorporate agreement between a\ntemporally lagged model and a cross-architectural model, which offers greater\nflexibility in regulating the learning pace and enables application to\nunlabeled data. Specifically, we propose dual teacher-student learning (DTSL),\na framework that introduces two groups of teacher-student models with different\narchitectures. The output agreement between the cross-group teacher and student\nmodels is used as pseudo-labels, generated via a Jensen-Shannon\ndivergence-based consensus label generator (CLG). Extensive experiments on\npopular datasets demonstrate that the proposed method consistently outperforms\nexisting state-of-the-art approaches. Ablation studies further validate the\neffectiveness of the proposed modules.",
    "pdf_url": "http://arxiv.org/pdf/2505.11018v1",
    "published": "2025-05-16T09:14:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11017v1",
    "title": "Logo-LLM: Local and Global Modeling with Large Language Models for Time Series Forecasting",
    "authors": [
      "Wenjie Ou",
      "Zhishuo Zhao",
      "Dongyue Guo",
      "Yi Lin"
    ],
    "abstract": "Time series forecasting is critical across multiple domains, where time\nseries data exhibits both local patterns and global dependencies. While\nTransformer-based methods effectively capture global dependencies, they often\noverlook short-term local variations in time series. Recent methods that adapt\nlarge language models (LLMs) into time series forecasting inherit this\nlimitation by treating LLMs as black-box encoders, relying solely on the\nfinal-layer output and underutilizing hierarchical representations. To address\nthis limitation, we propose Logo-LLM, a novel LLM-based framework that\nexplicitly extracts and models multi-scale temporal features from different\nlayers of a pre-trained LLM. Through empirical analysis, we show that shallow\nlayers of LLMs capture local dynamics in time series, while deeper layers\nencode global trends. Moreover, Logo-LLM introduces lightweight Local-Mixer and\nGlobal-Mixer modules to align and integrate features with the temporal input\nacross layers. Extensive experiments demonstrate that Logo-LLM achieves\nsuperior performance across diverse benchmarks, with strong generalization in\nfew-shot and zero-shot settings while maintaining low computational overhead.",
    "pdf_url": "http://arxiv.org/pdf/2505.11017v1",
    "published": "2025-05-16T09:10:49+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11016v1",
    "title": "GoLeash: Mitigating Golang Software Supply Chain Attacks with Runtime Policy Enforcement",
    "authors": [
      "Carmine Cesarano",
      "Martin Monperrus",
      "Roberto Natella"
    ],
    "abstract": "Modern software supply chain attacks consist of introducing new, malicious\ncapabilities into trusted third-party software components, in order to\npropagate to a victim through a package dependency chain. These attacks are\nespecially concerning for the Go language ecosystem, which is extensively used\nin critical cloud infrastructures. We present GoLeash, a novel system that\napplies the principle of least privilege at the package-level granularity, by\nenforcing distinct security policies for each package in the supply chain. This\nfiner granularity enables GoLeash to detect malicious packages more precisely\nthan traditional sandboxing that handles security policies at process- or\ncontainer-level. Moreover, GoLeash remains effective under obfuscation, can\novercome the limitations of static analysis, and incurs acceptable runtime\noverhead.",
    "pdf_url": "http://arxiv.org/pdf/2505.11016v1",
    "published": "2025-05-16T09:10:07+00:00",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11015v2",
    "title": "WildDoc: How Far Are We from Achieving Comprehensive and Robust Document Understanding in the Wild?",
    "authors": [
      "An-Lan Wang",
      "Jingqun Tang",
      "Liao Lei",
      "Hao Feng",
      "Qi Liu",
      "Xiang Fei",
      "Jinghui Lu",
      "Han Wang",
      "Weiwei Liu",
      "Hao Liu",
      "Yuliang Liu",
      "Xiang Bai",
      "Can Huang"
    ],
    "abstract": "The rapid advancements in Multimodal Large Language Models (MLLMs) have\nsignificantly enhanced capabilities in Document Understanding. However,\nprevailing benchmarks like DocVQA and ChartQA predominantly comprise\n\\textit{scanned or digital} documents, inadequately reflecting the intricate\nchallenges posed by diverse real-world scenarios, such as variable illumination\nand physical distortions. This paper introduces WildDoc, the inaugural\nbenchmark designed specifically for assessing document understanding in natural\nenvironments. WildDoc incorporates a diverse set of manually captured document\nimages reflecting real-world conditions and leverages document sources from\nestablished benchmarks to facilitate comprehensive comparisons with digital or\nscanned documents. Further, to rigorously evaluate model robustness, each\ndocument is captured four times under different conditions. Evaluations of\nstate-of-the-art MLLMs on WildDoc expose substantial performance declines and\nunderscore the models' inadequate robustness compared to traditional\nbenchmarks, highlighting the unique challenges posed by real-world document\nunderstanding. Our project homepage is available at\nhttps://bytedance.github.io/WildDoc.",
    "pdf_url": "http://arxiv.org/pdf/2505.11015v2",
    "published": "2025-05-16T09:09:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11014v1",
    "title": "A Cautionary Tale on Integrating Studies with Disparate Outcome Measures for Causal Inference",
    "authors": [
      "Harsh Parikh",
      "Trang Quynh Nguyen",
      "Elizabeth A. Stuart",
      "Kara E. Rudolph",
      "Caleb H. Miles"
    ],
    "abstract": "Data integration approaches are increasingly used to enhance the efficiency\nand generalizability of studies. However, a key limitation of these methods is\nthe assumption that outcome measures are identical across datasets -- an\nassumption that often does not hold in practice. Consider the following opioid\nuse disorder (OUD) studies: the XBOT trial and the POAT study, both evaluating\nthe effect of medications for OUD on withdrawal symptom severity (not the\nprimary outcome of either trial). While XBOT measures withdrawal severity using\nthe subjective opiate withdrawal scale, POAT uses the clinical opiate\nwithdrawal scale. We analyze this realistic yet challenging setting where\noutcome measures differ across studies and where neither study records both\ntypes of outcomes. Our paper studies whether and when integrating studies with\ndisparate outcome measures leads to efficiency gains. We introduce three sets\nof assumptions -- with varying degrees of strength -- linking both outcome\nmeasures. Our theoretical and empirical results highlight a cautionary tale:\nintegration can improve asymptotic efficiency only under the strongest\nassumption linking the outcomes. However, misspecification of this assumption\nleads to bias. In contrast, a milder assumption may yield finite-sample\nefficiency gains, yet these benefits diminish as sample size increases. We\nillustrate these trade-offs via a case study integrating the XBOT and POAT\ndatasets to estimate the comparative effect of two medications for opioid use\ndisorder on withdrawal symptoms. By systematically varying the assumptions\nlinking the SOW and COW scales, we show potential efficiency gains and the\nrisks of bias. Our findings emphasize the need for careful assumption selection\nwhen fusing datasets with differing outcome measures, offering guidance for\nresearchers navigating this common challenge in modern data integration.",
    "pdf_url": "http://arxiv.org/pdf/2505.11014v1",
    "published": "2025-05-16T09:08:28+00:00",
    "categories": [
      "stat.ME",
      "cs.LG",
      "econ.EM"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.13503v1",
    "title": "Ancestry-Adjusted Polygenic Risk Scores for Predicting Obesity Risk in the Indonesian Population",
    "authors": [
      "Jocelyn Verna Siswanto",
      "Belinda Mutiara",
      "Felicia Austin",
      "Jonathan Susanto",
      "Cathelyn Theophila Tan",
      "Restu Unggul Kresnadi",
      "Kezia Irene"
    ],
    "abstract": "Obesity prevalence in Indonesian adults increased from 10.5% in 2007 to 23.4%\nin 2023. Studies showed that genetic predisposition significantly influences\nobesity susceptibility. To aid this, polygenic risk scores (PRS) help aggregate\nthe effects of numerous genetic variants to assess genetic risk. However, 91%\nof genome-wide association studies (GWAS) involve European populations,\nlimiting their applicability to Indonesians due to genetic diversity. This\nstudy aims to develop and validate an ancestry adjusted PRS for obesity in the\nIndonesian population using principal component analysis (PCA) method\nconstructed from the 1000 Genomes Project data and our own genomic data from\napproximately 2,800 Indonesians. We calculate PRS for obesity using all races,\nthen determine the first four principal components using ancestry-informative\nSNPs and develop a linear regression model to predict PRS based on these\nprincipal components. The raw PRS is adjusted by subtracting the predicted\nscore to obtain an ancestry adjusted PRS for the Indonesian population. Our\nresults indicate that the ancestry-adjusted PRS improves obesity risk\nprediction. Compared to the unadjusted PRS, the adjusted score improved\nclassification performance with a 5% increase in area under the ROC curve\n(AUC). This approach underscores the importance of population-specific\nadjustments in genetic risk assessments to enable more effective personalized\nhealthcare and targeted intervention strategies for diverse populations.",
    "pdf_url": "http://arxiv.org/pdf/2505.13503v1",
    "published": "2025-05-16T09:06:17+00:00",
    "categories": [
      "stat.ME",
      "q-bio.GN",
      "62P10, 92B15"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.11013v2",
    "title": "Towards Robust and Controllable Text-to-Motion via Masked Autoregressive Diffusion",
    "authors": [
      "Zongye Zhang",
      "Bohan Kong",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "abstract": "Generating 3D human motion from text descriptions remains challenging due to\nthe diverse and complex nature of human motion. While existing methods excel\nwithin the training distribution, they often struggle with out-of-distribution\nmotions, limiting their applicability in real-world scenarios. Existing\nVQVAE-based methods often fail to represent novel motions faithfully using\ndiscrete tokens, which hampers their ability to generalize beyond seen data.\nMeanwhile, diffusion-based methods operating on continuous representations\noften lack fine-grained control over individual frames. To address these\nchallenges, we propose a robust motion generation framework MoMADiff, which\ncombines masked modeling with diffusion processes to generate motion using\nframe-level continuous representations. Our model supports flexible\nuser-provided keyframe specification, enabling precise control over both\nspatial and temporal aspects of motion synthesis. MoMADiff demonstrates strong\ngeneralization capability on novel text-to-motion datasets with sparse\nkeyframes as motion prompts. Extensive experiments on two held-out datasets and\ntwo standard benchmarks show that our method consistently outperforms\nstate-of-the-art models in motion quality, instruction fidelity, and keyframe\nadherence. The code is available at: https://github.com/zzysteve/MoMADiff",
    "pdf_url": "http://arxiv.org/pdf/2505.11013v2",
    "published": "2025-05-16T09:06:15+00:00",
    "categories": [
      "cs.CV",
      "cs.MM",
      "I.3.8"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11012v1",
    "title": "Doppler Resilient Complementary Sequences: Tighter Aperiodic Ambiguity Function Bound and Optimal Constructions",
    "authors": [
      "Zheng Wang",
      "Yang Yang",
      "Zhengchun Zhou",
      "Avik Ranjan Adhikary",
      "Pingzhi Fan"
    ],
    "abstract": "Doppler-resilient complementary sequence sets (DRCSs) are crucial in modern\ncommunication and sensing systems in mobile environments. In this paper, we\npropose a new lower bound for the aperiodic ambiguity function (AF) of\nunimodular DRCSs based on weight vectors, which generalizes the existing bound\nas a special case. The proposed lower bound is tighter than the\nShen-Yang-Zhou-Liu-Fan bound. Finally, we propose a novel class of aperiodic\nDRCSs with small alphabets based on quasi-Florentine rectangles and Butson-type\nHadamard matrices. Interestingly, the proposed DRCSs asymptotically satisfy the\nproposed bound.",
    "pdf_url": "http://arxiv.org/pdf/2505.11012v1",
    "published": "2025-05-16T09:04:37+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.11011v1",
    "title": "Humans expect rationality and cooperation from LLM opponents in strategic games",
    "authors": [
      "Darija Barak",
      "Miguel Costa-Gomes"
    ],
    "abstract": "As Large Language Models (LLMs) integrate into our social and economic\ninteractions, we need to deepen our understanding of how humans respond to LLMs\nopponents in strategic settings. We present the results of the first controlled\nmonetarily-incentivised laboratory experiment looking at differences in human\nbehaviour in a multi-player p-beauty contest against other humans and LLMs. We\nuse a within-subject design in order to compare behaviour at the individual\nlevel. We show that, in this environment, human subjects choose significantly\nlower numbers when playing against LLMs than humans, which is mainly driven by\nthe increased prevalence of `zero' Nash-equilibrium choices. This shift is\nmainly driven by subjects with high strategic reasoning ability. Subjects who\nplay the zero Nash-equilibrium choice motivate their strategy by appealing to\nperceived LLM's reasoning ability and, unexpectedly, propensity towards\ncooperation. Our findings provide foundational insights into the multi-player\nhuman-LLM interaction in simultaneous choice games, uncover heterogeneities in\nboth subjects' behaviour and beliefs about LLM's play when playing against\nthem, and suggest important implications for mechanism design in mixed\nhuman-LLM systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.11011v1",
    "published": "2025-05-16T09:01:09+00:00",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.MA",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.11010v2",
    "title": "ReviewInstruct: A Review-Driven Multi-Turn Conversations Generation Method for Large Language Models",
    "authors": [
      "Jiangxu Wu",
      "Cong Wang",
      "TianHuang Su",
      "Jun Yang",
      "Haozhi Lin",
      "Chao Zhang",
      "Ming Peng",
      "Kai Shi",
      "SongPan Yang",
      "BinQing Pan",
      "ZiXian Li",
      "Ni Yang",
      "ZhenYu Yang"
    ],
    "abstract": "The effectiveness of large language models (LLMs) in conversational AI is\nhindered by their reliance on single-turn supervised fine-tuning (SFT) data,\nwhich limits contextual coherence in multi-turn dialogues. Existing methods for\ngenerating multi-turn dialogue data struggle to ensure both diversity and\nquality in instructions. To address this, we propose Review-Instruct, a novel\nframework that synthesizes multi-turn conversations through an iterative\n\"Ask-Respond-Review\" process involving three agent roles: a Candidate, multiple\nReviewers, and a Chairman. The framework iteratively refines instructions by\nincorporating Reviewer feedback, enhancing dialogue diversity and difficulty.\nWe construct a multi-turn dataset using the Alpaca dataset and fine-tune the\nLLaMA2-13B model. Evaluations on MT-Bench, MMLU-Pro, and Auto-Arena demonstrate\nsignificant improvements, achieving absolute gains of 2.9\\% on MMLU-Pro and 2\\%\non MT-Bench compared to prior state-of-the-art models based on LLaMA2-13B.\nAblation studies confirm the critical role of the Review stage and the use of\nmultiple Reviewers in boosting instruction diversity and difficulty. Our work\nhighlights the potential of review-driven, multi-agent frameworks for\ngenerating high-quality conversational data at scale.",
    "pdf_url": "http://arxiv.org/pdf/2505.11010v2",
    "published": "2025-05-16T08:59:07+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11009v1",
    "title": "Concept of a System-on-Chip Research Platform Benchmarking Interaction of Memristor-based Bio-inspired Computing Paradigms",
    "authors": [
      "Christian Grewing",
      "Arun Ashok",
      "Sabitha Kusuma",
      "Michael Schiek",
      "Andre Zambanini",
      "Stefan van Waasen"
    ],
    "abstract": "A system architecture is suggested for a System on Chip that will combine\nseveral different memristor-based, bio-inspired computation arrays with inter-\nand intra-chip communication. It will serve as a benchmark system for future\ndevelopments. The architecture takes the special requirements into account\nwhich are caused by the memristor co-integration on commercial CMOS structures\nin a post processing step of the chip. The interface considers the necessary\ndata bandwidth to monitor the internal Network on Chip at speed and provides\nenough flexibility to give different measurement options.",
    "pdf_url": "http://arxiv.org/pdf/2505.11009v1",
    "published": "2025-05-16T08:54:44+00:00",
    "categories": [
      "cs.ET"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.11008v1",
    "title": "Reconstructing Syllable Sequences in Abugida Scripts with Incomplete Inputs",
    "authors": [
      "Ye Kyaw Thu",
      "Thazin Myint Oo"
    ],
    "abstract": "This paper explores syllable sequence prediction in Abugida languages using\nTransformer-based models, focusing on six languages: Bengali, Hindi, Khmer,\nLao, Myanmar, and Thai, from the Asian Language Treebank (ALT) dataset. We\ninvestigate the reconstruction of complete syllable sequences from various\nincomplete input types, including consonant sequences, vowel sequences, partial\nsyllables (with random character deletions), and masked syllables (with fixed\nsyllable deletions). Our experiments reveal that consonant sequences play a\ncritical role in accurate syllable prediction, achieving high BLEU scores,\nwhile vowel sequences present a significantly greater challenge. The model\ndemonstrates robust performance across tasks, particularly in handling partial\nand masked syllable reconstruction, with strong results for tasks involving\nconsonant information and syllable masking. This study advances the\nunderstanding of sequence prediction for Abugida languages and provides\npractical insights for applications such as text prediction, spelling\ncorrection, and data augmentation in these scripts.",
    "pdf_url": "http://arxiv.org/pdf/2505.11008v1",
    "published": "2025-05-16T08:54:21+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11566v1",
    "title": "Theory: Multidimensional Space of Events",
    "authors": [
      "Sergii Kavun"
    ],
    "abstract": "This paper extends Bayesian probability theory by developing a\nmultidimensional space of events (MDSE) theory that accounts for mutual\ninfluences between events and hypotheses sets. While traditional Bayesian\napproaches assume conditional independence between certain variables,\nreal-world systems often exhibit complex interdependencies that limit classical\nmodel applicability. Building on established probabilistic foundations, our\napproach introduces a mathematical formalism for modeling these complex\nrelationships. We developed the MDSE theory through rigorous mathematical\nderivation and validated it using three complementary methodologies: analytical\nproofs, computational simulations, and case studies drawn from diverse domains.\nResults demonstrate that MDSE successfully models complex dependencies with\n15-20% improved prediction accuracy compared to standard Bayesian methods when\napplied to datasets with high interdimensionality. This theory particularly\nexcels in scenarios with over 50 interrelated variables, where traditional\nmethods show exponential computational complexity growth while MDSE maintains\npolynomial scaling. Our findings indicate that MDSE provides a viable\nmathematical foundation for extending Bayesian reasoning to complex systems\nwhile maintaining computational tractability. This approach offers practical\napplications in engineering challenges including risk assessment, resource\noptimization, and forecasting problems where multiple interdependent factors\nmust be simultaneously considered.",
    "pdf_url": "http://arxiv.org/pdf/2505.11566v1",
    "published": "2025-05-16T08:54:12+00:00",
    "categories": [
      "stat.ME",
      "math.LO",
      "math.PR",
      "stat.ML",
      "60A10, 62F15, 68T27, 05C35, 05C40, 03E75",
      "G.3; G.3; I.2.3; G.2.2; G.2.2; F.4.1"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.11007v1",
    "title": "Structure and dynamics of ionic liquids under shear flow",
    "authors": [
      "Abbas Gholami",
      "Sebastian Kloth",
      "Zhen-Hao Xu",
      "Kurt Kremer",
      "Michael Vogel",
      "Torsten Stuehn",
      "Joseph F. Rudzinski"
    ],
    "abstract": "We investigate the intrinsic behavior of ionic liquids under shear flow,\nusing a coarse-grained model of C4mim-PF6 as a prototypical example. The\nimportance of long-ranged electrostatics is assessed as a function of shear\nrate by comparing Ewald and reaction field treatments. An appropriate\ncomparison is achieved through the implementation of the proper Lees-Edwards\nboundary conditions within the ESPResSo++ simulation software. Our results\ndemonstrate that while structural properties are relatively insensitive to the\nelectrostatic treatment, the more accurate treatment via the Ewald approach is\nessential for studies of dynamics, in particular, at lower shear rates.\nFurthermore, we identify a critical shear rate beyond which structural and\ndynamical properties begin to deviate from equilibrium behavior, while\nremaining largely unchanged below this threshold. Finally, we demonstrate that\nthe dynamic heterogeneity of the liquid decreases as a function of increasing\nshear rate, which can be primarily explained by the faster dynamics induced by\nthe shear flow. These results hold relevance for investigations of\nprocess-dependent properties of ionic-liquid-based materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.11007v1",
    "published": "2025-05-16T08:53:27+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.soft"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.11006v2",
    "title": "Supervised Models Can Generalize Also When Trained on Random Labels",
    "authors": [
      "Oskar Allerbo",
      "Thomas B. Schön"
    ],
    "abstract": "The success of unsupervised learning raises the question of whether also\nsupervised models can be trained without using the information in the output\n$y$. In this paper, we demonstrate that this is indeed possible. The key step\nis to formulate the model as a smoother, i.e. on the form $\\hat{f}=Sy$, and to\nconstruct the smoother matrix $S$ independently of $y$, e.g. by training on\nrandom labels. We present a simple model selection criterion based on the\ndistribution of the out-of-sample predictions and show that, in contrast to\ncross-validation, this criterion can be used also without access to $y$. We\ndemonstrate on real and synthetic data that $y$-free trained versions of linear\nand kernel ridge regression, smoothing splines, and neural networks perform\nsimilarly to their standard, $y$-based, versions and, most importantly,\nsignificantly better than random guessing.",
    "pdf_url": "http://arxiv.org/pdf/2505.11006v2",
    "published": "2025-05-16T08:51:44+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.11005v3",
    "title": "Solute mixing in porous media with dispersion and buoyancy",
    "authors": [
      "Marco De Paoli",
      "Guru Sreevanshu Yerragolam",
      "Roberto Verzicco",
      "Detlef Lohse"
    ],
    "abstract": "We analyse the process of convective mixing in two-dimensional, homogeneous\nand isotropic porous media with dispersion. We considered a Rayleigh-Taylor\ninstability in which the presence of a solute produces density differences\ndriving the flow. The effect of dispersion is modelled using an anisotropic\nFickian dispersion tensor (Bear, J. Geophys. Res. 1961). In addition to\nmolecular diffusion ($D_m^*$), the solute is redistributed by an additional\nspreading, in longitudinal and transverse flow directions, which is quantified\nby the coefficients $D_l^*$ and $D_t^*$, respectively, and it is produced by\nthe presence of the pores. The flow is controlled by three dimensionless\nparameters: the Rayleigh-Darcy number $Ra$, defining the relative strength of\nconvection and diffusion, and the dispersion parameters $r=D_l^*/D_t^*$ and\n$\\Delta=D_m^*/D_t^*$. With the aid of numerical Darcy simulations, we\ninvestigate the mixing dynamics without and with dispersion. We find that in\nabsence of dispersion ($\\Delta\\to\\infty$) the dynamics is self-similar and\nindependent of $Ra$, and the flow evolves following several regimes, which we\nanalyse. Then we analyse the effect of dispersion on the flow evolution for a\nfixed value of the Rayleigh-Darcy number ($Ra=10^4$). A detailed analysis of\nthe molecular and dispersive components of the mean scalar dissipation reveals\na complex interplay between flow structures and solute mixing. The proposed\ntheoretical framework, in combination with pore-scale simulations and bead\npacks experiments, can be used to validate and improve current dispersion\nmodels to obtain more reliable estimates of solute transport and spreading in\nbuoyancy-driven subsurface flows.",
    "pdf_url": "http://arxiv.org/pdf/2505.11005v3",
    "published": "2025-05-16T08:51:12+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.geo-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.11004v2",
    "title": "Illusion or Algorithm? Investigating Memorization, Emergence, and Symbolic Processing in In-Context Learning",
    "authors": [
      "Jingcheng Niu",
      "Subhabrata Dutta",
      "Ahmed Elshabrawy",
      "Harish Tayyar Madabushi",
      "Iryna Gurevych"
    ],
    "abstract": "Large-scale Transformer language models (LMs) trained solely on next-token\nprediction with web-scale data can solve a wide range of tasks after seeing\njust a few examples. The mechanism behind this capability, known as in-context\nlearning (ICL), remains both controversial and poorly understood. Some studies\nargue that it is merely the result of memorizing vast amounts of data, while\nothers contend that it reflects a fundamental, symbolic algorithmic development\nin LMs. In this work, we introduce a suite of investigative tasks and a novel\nmethod to systematically investigate ICL by leveraging the full Pythia scaling\nsuite, including interim checkpoints that capture progressively larger amount\nof training data. By carefully exploring ICL performance on downstream tasks\nand simultaneously conducting a mechanistic analysis of the residual stream's\nsubspace, we demonstrate that ICL extends beyond mere \"memorization\" of the\ntraining corpus, yet does not amount to the implementation of an independent\nsymbolic algorithm. Our results also clarify several aspects of ICL, including\nthe influence of training dynamics, model capabilities, and elements of\nmechanistic interpretability. Overall, our work advances the understanding of\nICL and its implications, offering model developers insights into potential\nimprovements and providing AI security practitioners with a basis for more\ninformed guidelines.",
    "pdf_url": "http://arxiv.org/pdf/2505.11004v2",
    "published": "2025-05-16T08:50:42+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.11003v1",
    "title": "ForensicHub: A Unified Benchmark & Codebase for All-Domain Fake Image Detection and Localization",
    "authors": [
      "Bo Du",
      "Xuekang Zhu",
      "Xiaochen Ma",
      "Chenfan Qu",
      "Kaiwen Feng",
      "Zhe Yang",
      "Chi-Man Pun",
      "Jian Liu",
      "Jizhe Zhou"
    ],
    "abstract": "The field of Fake Image Detection and Localization (FIDL) is highly\nfragmented, encompassing four domains: deepfake detection (Deepfake), image\nmanipulation detection and localization (IMDL), artificial\nintelligence-generated image detection (AIGC), and document image manipulation\nlocalization (Doc). Although individual benchmarks exist in some domains, a\nunified benchmark for all domains in FIDL remains blank. The absence of a\nunified benchmark results in significant domain silos, where each domain\nindependently constructs its datasets, models, and evaluation protocols without\ninteroperability, preventing cross-domain comparisons and hindering the\ndevelopment of the entire FIDL field. To close the domain silo barrier, we\npropose ForensicHub, the first unified benchmark & codebase for all-domain fake\nimage detection and localization. Considering drastic variations on dataset,\nmodel, and evaluation configurations across all domains, as well as the\nscarcity of open-sourced baseline models and the lack of individual benchmarks\nin some domains, ForensicHub: i) proposes a modular and configuration-driven\narchitecture that decomposes forensic pipelines into interchangeable components\nacross datasets, transforms, models, and evaluators, allowing flexible\ncomposition across all domains; ii) fully implements 10 baseline models, 6\nbackbones, 2 new benchmarks for AIGC and Doc, and integrates 2 existing\nbenchmarks of DeepfakeBench and IMDLBenCo through an adapter-based design; iii)\nconducts indepth analysis based on the ForensicHub, offering 8 key actionable\ninsights into FIDL model architecture, dataset characteristics, and evaluation\nstandards. ForensicHub represents a significant leap forward in breaking the\ndomain silos in the FIDL field and inspiring future breakthroughs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11003v1",
    "published": "2025-05-16T08:49:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.11002v2",
    "title": "Power convexity of solutions to complex Monge-Ampère equation in $\\mathbb{C}^2$",
    "authors": [
      "Wei Zhang",
      "Qi Zhou"
    ],
    "abstract": "The convexity of solutions to boundary value problems for fully nonlinear\nelliptic partial differential equations (such as real or complex $k$-Hessian\nequations) is a challenging topic. In this paper, we establish the power\nconvexity of solutions to the Dirichlet problem for the complex Monge-Amp\\`ere\nequation on bounded, smooth, strictly convex domain in $\\mathbb{C}^2$. Our\napproach is based on the constant rank theorem and the deformation process.",
    "pdf_url": "http://arxiv.org/pdf/2505.11002v2",
    "published": "2025-05-16T08:49:53+00:00",
    "categories": [
      "math.AP",
      "35B50, 32W20"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.11001v1",
    "title": "On certain symmetries of $\\mathbb R^3$ with a diagonal metric",
    "authors": [
      "Adara M. Blaga"
    ],
    "abstract": "We determine Killing vector fields on the $3$-dimensional space $\\mathbb R^3$\nendowed with a special diagonal metric.",
    "pdf_url": "http://arxiv.org/pdf/2505.11001v1",
    "published": "2025-05-16T08:48:54+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11000v1",
    "title": "Neutron Spin Resonance Near a Lifshitz Transition in Overdoped Ba$_{0.4}$K$_{0.6}$Fe$_2$As$_2$",
    "authors": [
      "Yang Li",
      "Dingsong Wu",
      "Yingjie Shu",
      "Bo Liu",
      "Uwe Stuhr",
      "Guochu Deng",
      "Anton P. J. Stamp",
      "Lin Zhao",
      "Xingjiang Zhou",
      "Shiliang Li",
      "Amit Pokhriyal",
      "Haranath Ghosh",
      "Wenshan Hong",
      "Huiqian Luo"
    ],
    "abstract": "Elucidating the relationship between spin excitations and fermiology is\nessential for clarifying the pairing mechanism in iron-based superconductors\n(FeSCs). Here, we report inelastic neutron scattering results on the hole\noverdoped Ba$_{0.4}$K$_{0.6}$Fe$_2$As$_2$ near a Lifshitz transition, where the\nelectron pocket at $M$ point is nearly replace by four hole pockets. In the\nnormal state, the spin excitations are observed at incommensurate wave vectors\nwith chimney-like dispersions. By cooling down to the superconducting state, a\nneutron spin resonance mode emerges with a peak energy of $E_r=$ 14-15 meV\nweakly modulated along $L$-direction. The incommensurability notably increases\nat low energies, giving rise to downward dispersions of the resonance mode.\nThis behavior contrasts sharply with the upward dispersions of resonance\nobserved in optimally doped Ba$_{0.67}$K$_{0.33}$Fe$_2$As$_2$ contributed by\nthe hole to electron scattering, but resembles with the cases in KFe$_2$As$_2$\nand KCa$_2$Fe$_4$As$_4$F$_2$ where the fermiology are dominated by hole\npockets. These results highlight the critical role of electronic structure\nmodifications near the Fermi level, especially in governing interband\nscattering under imperfect nesting conditions, which fundamentally shape the\nspin dynamics of FeSCs.",
    "pdf_url": "http://arxiv.org/pdf/2505.11000v1",
    "published": "2025-05-16T08:48:03+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.10999v1",
    "title": "DDAE++: Enhancing Diffusion Models Towards Unified Generative and Discriminative Learning",
    "authors": [
      "Weilai Xiang",
      "Hongyu Yang",
      "Di Huang",
      "Yunhong Wang"
    ],
    "abstract": "While diffusion models have gained prominence in image synthesis, their\ngenerative pre-training has been shown to yield discriminative representations,\npaving the way towards unified visual generation and understanding. However,\ntwo key questions remain: 1) Can these representations be leveraged to improve\nthe training of diffusion models themselves, rather than solely benefiting\ndownstream tasks? 2) Can the feature quality be enhanced to rival or even\nsurpass modern self-supervised learners, without compromising generative\ncapability? This work addresses these questions by introducing\nself-conditioning, a straightforward yet effective mechanism that internally\nleverages the rich semantics inherent in denoising network to guide its own\ndecoding layers, forming a tighter bottleneck that condenses high-level\nsemantics to improve generation. Results are compelling: our method boosts both\ngeneration FID and recognition accuracy with 1% computational overhead and\ngeneralizes across diverse diffusion architectures. Crucially,\nself-conditioning facilitates an effective integration of discriminative\ntechniques, such as contrastive self-distillation, directly into diffusion\nmodels without sacrificing generation quality. Extensive experiments on\npixel-space and latent-space datasets show that in linear evaluations, our\nenhanced diffusion models, particularly UViT and DiT, serve as strong\nrepresentation learners, surpassing various self-supervised models.",
    "pdf_url": "http://arxiv.org/pdf/2505.10999v1",
    "published": "2025-05-16T08:47:16+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10998v1",
    "title": "Investigating the axial structure of the nucleon based on large-volume lattice QCD at the physical point",
    "authors": [
      "Ryutaro Tsuji",
      "Yasumichi Aoki",
      "Ken-Ichi Ishikawa",
      "Yoshinobu Kuramashi",
      "Shoichi Sasaki",
      "Kohei Sato",
      "Eigo Shintani",
      "Hiromasa Watanabe",
      "Takeshi Yamazaki"
    ],
    "abstract": "We present a short summary for the calculations of the nucleon\n$\\textit{isovector}$ form factors, which are relevant to improving the accuracy\nof the current neutrino oscillation experiments. The calculations are carried\nout with two of three sets of the $2+1$ flavor lattice QCD configurations\ngenerated at the physical point in large spatial volumes by the PACS\nCollaboration. The two gauge configurations are generated with the six\nstout-smeared $O(a)$ improved Wilson quark action and Iwasaki gauge action at\nthe lattice spacing of $0.09$ fm and $0.06$ fm. We summarize the results for\nthree form factors as well as the nucleon axial-vector ($g_A$), induced\npseudoscalar ($g_P^*$) and pion-nucleon ($g_{\\pi NN}$) couplings. Although our\ncouplings agree with the experimental data, a firm conclusion should be drawn\nonly after a continuum limit extrapolation is taken. We investigate the\npartially conserved axial-vector current (PCAC) relation in the context of the\nnucleon correlation functions. The low-energy relations arising from the PCAC\nrelation can be used to verify whether the lattice QCD data correctly reproduce\nthe physics in the continuum within the statistical accuracy. It is\ndemonstrated that our $\\textit{new analysis}$ reduces the systematic\nuncertainty for the induced pseudoscalar and pseudoscalar form factors to a\ngreater extent than the $\\textit{traditional analysis}$, and the results offer\na theoretical insight into the pion-pole dominance model. Finally, we examine\nthe applicable $q^2$ region for the low-energy relations.",
    "pdf_url": "http://arxiv.org/pdf/2505.10998v1",
    "published": "2025-05-16T08:46:46+00:00",
    "categories": [
      "hep-lat"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2505.10997v2",
    "title": "Hybrid Monetary Ecosystems: Integrating Stablecoins and Fiat in the Future of Currency Systems",
    "authors": [
      "Hongzhe Wen",
      "Songbai Li",
      "Jamie Zhang"
    ],
    "abstract": "With market capitalization exceeding USD 200 billion as of early 2025,\nstablecoins have evolved from a crypto-focused innovation into a vital\ncomponent of the global monetary structure. This paper identifies the\ncharacteristics of stablecoins from an analytical perspective and investigates\nthe role of stablecoins in forming hybrid monetary ecosystems where public\n(fiat, CBDC) and private (USDC, USDT, DAI) monies coexist. Through econometric\nanalysis with multiple models, we find that stablecoins maintain strong peg\nstability, while each type also exhibits distinctive responses to market\nvariables such as trading volume and capitalization, depending on the\nmechanisms behind. We introduce a hybrid system design that proposes a\ntwo-layer structure where private stablecoin issuers are backed by central bank\nreserves, ensuring uniformity, security, and programmability. This model merges\nthe advantages of decentralized finance and payment innovation while utilizing\nthe Federal Reserve's institutional trust. A case study on the 2023 SVB-USDC\ndepeg event illustrates how such a hybrid system could prevent panic-induced\ninstability through transparent reserves, secured liquidity, and interoperable\nassets. Ultimately, this research examines the model using the Dybvig model and\nMonte Carlo Simulation and concludes, with the results of the examinations,\nthat a hybrid monetary model not only enhances financial inclusivity,\nscalability, and dollar utility in digital ecosystems but also strengthens\nsystemic resilience, offering a credible blueprint for future digital dollar\narchitectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.10997v2",
    "published": "2025-05-16T08:46:33+00:00",
    "categories": [
      "q-fin.GN",
      "econ.TH"
    ],
    "primary_category": "q-fin.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.10996v1",
    "title": "Visual Anomaly Detection under Complex View-Illumination Interplay: A Large-Scale Benchmark",
    "authors": [
      "Yunkang Cao",
      "Yuqi Cheng",
      "Xiaohao Xu",
      "Yiheng Zhang",
      "Yihan Sun",
      "Yuxiang Tan",
      "Yuxin Zhang",
      "Xiaonan Huang",
      "Weiming Shen"
    ],
    "abstract": "The practical deployment of Visual Anomaly Detection (VAD) systems is\nhindered by their sensitivity to real-world imaging variations, particularly\nthe complex interplay between viewpoint and illumination which drastically\nalters defect visibility. Current benchmarks largely overlook this critical\nchallenge. We introduce Multi-View Multi-Illumination Anomaly Detection (M2AD),\na new large-scale benchmark comprising 119,880 high-resolution images designed\nexplicitly to probe VAD robustness under such interacting conditions. By\nsystematically capturing 999 specimens across 10 categories using 12\nsynchronized views and 10 illumination settings (120 configurations total),\nM2AD enables rigorous evaluation. We establish two evaluation protocols:\nM2AD-Synergy tests the ability to fuse information across diverse\nconfigurations, and M2AD-Invariant measures single-image robustness against\nrealistic view-illumination effects. Our extensive benchmarking shows that\nstate-of-the-art VAD methods struggle significantly on M2AD, demonstrating the\nprofound challenge posed by view-illumination interplay. This benchmark serves\nas an essential tool for developing and validating VAD methods capable of\novercoming real-world complexities. Our full dataset and test suite will be\nreleased at https://hustcyq.github.io/M2AD to facilitate the field.",
    "pdf_url": "http://arxiv.org/pdf/2505.10996v1",
    "published": "2025-05-16T08:46:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10995v1",
    "title": "Recurrent Jetlets Associated with the Disappearance of a Satellite Spot",
    "authors": [
      "Liheng Yang",
      "Xiaoli Yan",
      "Jun Zhang",
      "Zhike Xue",
      "Zhe Xu",
      "Jincheng Wang",
      "Yijun Hou",
      "Yian Zhou",
      "Defang Kong",
      "Roslan Umar",
      "Xinsheng Zhang",
      "Qiaoling Li",
      "Liping Yang"
    ],
    "abstract": "Recurrent small-scale eruptions are fascinating phenomena in the solar\natmosphere. However, their underlying physical mechanisms remain unclear. On\n2021 May 23, five recurrent jetlets (J1-J5) were observed continuously ejecting\nfrom a satellite spot located at the north edge of AR 12824. Using\nhigh-resolution, multi-wavelength data from NVST, SDO, and IRIS, we investigate\nthe physical characteristics of these jetlets and their relationship with the\nsatellite spot. The widths of these jetlets range from 1300 to 2900 km, their\nlifetimes range span 3 to 10 minutes, and their projection speeds vary from\n152.8 to 406.0 km s$^{-1}$. During the eruptions, the satellite spot moved\nnorthwest at a low speed of 376 $\\pm$ 12 m s$^{-1}$. Its area gradually\ndecreased due to magnetic cancellation with surrounding positive magnetic\nfield, resulting in an average cancellation rate of 1.3$\\times$10$^{18}$ Mx\nhr$^{-1}$. Dark lanes that separated from the satellite spot and small pores\nwere observed to move toward nearby these features or dark lanes with opposite\npolarities, eventually disappearing during the magnetic cancellation process.\nJ4 was driven by an eruption of a micro-filament. Spectral observations\nrevealed a redshift on the right side of J4 and a blueshift on the left side of\nits base, suggesting a counterclockwise rotation. The horizontal magnetic field\nof the satellite spot consistently exhibited a vortex structure throughout its\nevolution until it vanished. The nonlinear force-free field extrapolation\nconfirms that the satellite spot serves as one footpoint of a mini-flux rope.\nThese observations reveal that these jetlets might result from\nthree-dimensional null-point magnetic reconnection, initiated by the continuous\neruption of a mini-flux-rope or multiple mini-flux-ropes, driven by sustained\nmagnetic cancellation.",
    "pdf_url": "http://arxiv.org/pdf/2505.10995v1",
    "published": "2025-05-16T08:45:11+00:00",
    "categories": [
      "astro-ph.SR",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10994v1",
    "title": "Space Group Equivariant Crystal Diffusion",
    "authors": [
      "Rees Chang",
      "Angela Pak",
      "Alex Guerra",
      "Ni Zhan",
      "Nick Richardson",
      "Elif Ertekin",
      "Ryan P. Adams"
    ],
    "abstract": "Accelerating inverse design of crystalline materials with generative models\nhas significant implications for a range of technologies. Unlike other atomic\nsystems, 3D crystals are invariant to discrete groups of isometries called the\nspace groups. Crucially, these space group symmetries are known to heavily\ninfluence materials properties. We propose SGEquiDiff, a crystal generative\nmodel which naturally handles space group constraints with space group\ninvariant likelihoods. SGEquiDiff consists of an SE(3)-invariant, telescoping\ndiscrete sampler of crystal lattices; permutation-invariant, transformer-based\nautoregressive sampling of Wyckoff positions, elements, and numbers of\nsymmetrically unique atoms; and space group equivariant diffusion of atomic\ncoordinates. We show that space group equivariant vector fields automatically\nlive in the tangent spaces of the Wyckoff positions. SGEquiDiff achieves\nstate-of-the-art performance on standard benchmark datasets as assessed by\nquantitative proxy metrics and quantum mechanical calculations.",
    "pdf_url": "http://arxiv.org/pdf/2505.10994v1",
    "published": "2025-05-16T08:45:04+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.10993v2",
    "title": "Content Generation Models in Computational Pathology: A Comprehensive Survey on Methods, Applications, and Challenges",
    "authors": [
      "Yuan Zhang",
      "Xinfeng Zhang",
      "Xiaoming Qi",
      "Xinyu Wu",
      "Feng Chen",
      "Guanyu Yang",
      "Huazhu Fu"
    ],
    "abstract": "Content generation modeling has emerged as a promising direction in\ncomputational pathology, offering capabilities such as data-efficient learning,\nsynthetic data augmentation, and task-oriented generation across diverse\ndiagnostic tasks. This review provides a comprehensive synthesis of recent\nprogress in the field, organized into four key domains: image generation, text\ngeneration, molecular profile-morphology generation, and other specialized\ngeneration applications. By analyzing over 150 representative studies, we trace\nthe evolution of content generation architectures -- from early generative\nadversarial networks to recent advances in diffusion models and generative\nvision-language models. We further examine the datasets and evaluation\nprotocols commonly used in this domain and highlight ongoing limitations,\nincluding challenges in generating high-fidelity whole slide images, clinical\ninterpretability, and concerns related to the ethical and legal implications of\nsynthetic data. The review concludes with a discussion of open challenges and\nprospective research directions, with an emphasis on developing integrated and\nclinically deployable generation systems. This work aims to provide a\nfoundational reference for researchers and practitioners developing content\ngeneration models in computational pathology.",
    "pdf_url": "http://arxiv.org/pdf/2505.10993v2",
    "published": "2025-05-16T08:44:50+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10992v1",
    "title": "ReaCritic: Large Reasoning Transformer-based DRL Critic-model Scaling For Heterogeneous Networks",
    "authors": [
      "Feiran You",
      "Hongyang Du"
    ],
    "abstract": "Heterogeneous Networks (HetNets) pose critical challenges for intelligent\nmanagement due to the diverse user requirements and time-varying wireless\nconditions. These factors introduce significant decision complexity, which\nlimits the adaptability of existing Deep Reinforcement Learning (DRL) methods.\nIn many DRL algorithms, especially those involving value-based or actor-critic\nstructures, the critic component plays a key role in guiding policy learning by\nestimating value functions. However, conventional critic models often use\nshallow architectures that map observations directly to scalar estimates,\nlimiting their ability to handle multi-task complexity. In contrast, recent\nprogress in inference-time scaling of Large Language Models (LLMs) has shown\nthat generating intermediate reasoning steps can significantly improve decision\nquality. Motivated by this, we propose ReaCritic, a large reasoning\ntransformer-based criticmodel scaling scheme that brings reasoning ability into\nDRL. ReaCritic performs horizontal reasoning over parallel state-action inputs\nand vertical reasoning through deep transformer stacks. It is compatible with a\nbroad range of value-based and actor-critic DRL algorithms and enhances\ngeneralization in dynamic wireless environments. Extensive experiments\ndemonstrate that ReaCritic improves convergence speed and final performance\nacross various HetNet settings and standard OpenAI Gym control tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.10992v1",
    "published": "2025-05-16T08:42:08+00:00",
    "categories": [
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10991v3",
    "title": "Most General Explanations of Tree Ensembles (Extended Version)",
    "authors": [
      "Yacine Izza",
      "Alexey Ignatiev",
      "Sasha Rubin",
      "Joao Marques-Silva",
      "Peter J. Stuckey"
    ],
    "abstract": "Explainable Artificial Intelligence (XAI) is critical for attaining trust in\nthe operation of AI systems. A key question of an AI system is ``why was this\ndecision made this way''. Formal approaches to XAI use a formal model of the AI\nsystem to identify abductive explanations. While abductive explanations may be\napplicable to a large number of inputs sharing the same concrete values, more\ngeneral explanations may be preferred for numeric inputs. So-called inflated\nabductive explanations give intervals for each feature ensuring that any input\nwhose values fall withing these intervals is still guaranteed to make the same\nprediction. Inflated explanations cover a larger portion of the input space,\nand hence are deemed more general explanations. But there can be many\n(inflated) abductive explanations for an instance. Which is the best? In this\npaper, we show how to find a most general abductive explanation for an AI\ndecision. This explanation covers as much of the input space as possible, while\nstill being a correct formal explanation of the model's behaviour. Given that\nwe only want to give a human one explanation for a decision, the most general\nexplanation gives us the explanation with the broadest applicability, and hence\nthe one most likely to seem sensible. (The paper has been accepted at IJCAI2025\nconference.)",
    "pdf_url": "http://arxiv.org/pdf/2505.10991v3",
    "published": "2025-05-16T08:42:01+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10990v1",
    "title": "Time-resolved electron dynamics in antiferromagnetic CoO(001) thin films",
    "authors": [
      "Mathias Augstein",
      "Friederike Wührl",
      "Konrad Gillmeister",
      "Cheng-Tien Chiang",
      "Wolf Widdra"
    ],
    "abstract": "Ultrathin antiferromagnetic CoO(001)-(1x1) films of 2 and 4 monolayers (ML)\non Ag(001) are investigated by time- and angle-resolved two-photon\nphotoelectron (2PPE) spectroscopy. Pump-probe spectra show unoccupied states\nbetween 3.6 and 4.0\\,eV above the Fermi level ($E_{F}$), which are identified\nas image potential states with momentum-dependent lifetimes between 12 to\n20\\,fs. Electrons photoexcited across the band gap show lifetimes of 27\\,fs at\nthe bottom of the Co $3d$ $t_{2g}$-derived conduction band minimum. This\nlifetime is much shorter than in conventional semiconductors. Our observations\npoint either to strong electron correlation effects as has been demonstrated\nfor NiO or to an ultrafast relaxation pathway via metallic substrate states.",
    "pdf_url": "http://arxiv.org/pdf/2505.10990v1",
    "published": "2025-05-16T08:41:11+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11565v2",
    "title": "ACSE-Eval: Can LLMs threat model real-world cloud infrastructure?",
    "authors": [
      "Sarthak Munshi",
      "Swapnil Pathak",
      "Sonam Ghatode",
      "Thenuga Priyadarshini",
      "Dhivya Chandramouleeswaran",
      "Ashutosh Rana"
    ],
    "abstract": "While Large Language Models have shown promise in cybersecurity applications,\ntheir effectiveness in identifying security threats within cloud deployments\nremains unexplored. This paper introduces AWS Cloud Security Engineering Eval,\na novel dataset for evaluating LLMs cloud security threat modeling\ncapabilities. ACSE-Eval contains 100 production grade AWS deployment scenarios,\neach featuring detailed architectural specifications, Infrastructure as Code\nimplementations, documented security vulnerabilities, and associated threat\nmodeling parameters. Our dataset enables systemic assessment of LLMs abilities\nto identify security risks, analyze attack vectors, and propose mitigation\nstrategies in cloud environments. Our evaluations on ACSE-Eval demonstrate that\nGPT 4.1 and Gemini 2.5 Pro excel at threat identification, with Gemini 2.5 Pro\nperforming optimally in 0-shot scenarios and GPT 4.1 showing superior results\nin few-shot settings. While GPT 4.1 maintains a slight overall performance\nadvantage, Claude 3.7 Sonnet generates the most semantically sophisticated\nthreat models but struggles with threat categorization and generalization. To\npromote reproducibility and advance research in automated cybersecurity threat\nanalysis, we open-source our dataset, evaluation metrics, and methodologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.11565v2",
    "published": "2025-05-16T08:40:09+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10989v1",
    "title": "RAGSynth: Synthetic Data for Robust and Faithful RAG Component Optimization",
    "authors": [
      "Haiyang Shen",
      "Hang Yan",
      "Zhongshi Xing",
      "Mugeng Liu",
      "Yue Li",
      "Zhiyang Chen",
      "Yuxiang Wang",
      "Jiuzheng Wang",
      "Yun Ma"
    ],
    "abstract": "RAG can enhance the performance of LLMs on knowledge-intensive tasks. Various\nRAG paradigms, including vanilla, planning-based, and iterative RAG, are built\nupon 2 cores: the retriever, which should robustly select relevant documents\nacross complex queries, and the generator, which should faithfully synthesize\nresponses. However, existing retrievers rely heavily on public knowledge and\nstruggle with queries of varying logical complexity and clue completeness,\nwhile generators frequently face fidelity problems. In this work, we introduce\nRAGSynth, a framework that includes a data construction modeling and a\ncorresponding synthetic data generation implementation, designed to optimize\nretriever robustness and generator fidelity. Additionally, we present\nSynthBench, a benchmark encompassing 8 domain-specific documents across 4\ndomains, featuring diverse query complexities, clue completeness, and\nfine-grained citation granularity. Leveraging RAGSynth, we generate a\nlarge-scale synthetic dataset, including single and multi-hop. Extensive\nexperiments demonstrate that the synthetic data significantly improves the\nrobustness of the retrievers and the fidelity of the generators. Additional\nevaluations confirm that RAGSynth can also generalize well across different\ndomains. By integrating the optimized retrievers into various RAG paradigms, we\nconsistently observe enhanced RAG system performance. We have open-sourced the\nimplementation on https://github.com/EachSheep/RAGSynth.",
    "pdf_url": "http://arxiv.org/pdf/2505.10989v1",
    "published": "2025-05-16T08:38:25+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10988v1",
    "title": "DRL-Based Injection Molding Process Parameter Optimization for Adaptive and Profitable Production",
    "authors": [
      "Joon-Young Kim",
      "Jecheon Yu",
      "Heekyu Kim",
      "Seunghwa Ryu"
    ],
    "abstract": "Plastic injection molding remains essential to modern manufacturing. However,\noptimizing process parameters to balance product quality and profitability\nunder dynamic environmental and economic conditions remains a persistent\nchallenge. This study presents a novel deep reinforcement learning (DRL)-based\nframework for real-time process optimization in injection molding, integrating\nproduct quality and profitability into the control objective. A profit function\nwas developed to reflect real-world manufacturing costs, incorporating resin,\nmold wear, and electricity prices, including time-of-use variations. Surrogate\nmodels were constructed to predict product quality and cycle time, enabling\nefficient offline training of DRL agents using soft actor-critic (SAC) and\nproximal policy optimization (PPO) algorithms. Experimental results demonstrate\nthat the proposed DRL framework can dynamically adapt to seasonal and\noperational variations, consistently maintaining product quality while\nmaximizing profit. Compared to traditional optimization methods such as genetic\nalgorithms, the DRL models achieved comparable economic performance with up to\n135x faster inference speeds, making them well-suited for real-time\napplications. The framework's scalability and adaptability highlight its\npotential as a foundation for intelligent, data-driven decision-making in\nmodern manufacturing environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.10988v1",
    "published": "2025-05-16T08:35:31+00:00",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10987v1",
    "title": "A Superlinearly Convergent Evolution Strategy",
    "authors": [
      "Tobias Glasmachers"
    ],
    "abstract": "We present a hybrid algorithm between an evolution strategy and a quasi\nNewton method. The design is based on the Hessian Estimation Evolution\nStrategy, which iteratively estimates the inverse square root of the Hessian\nmatrix of the problem. This is akin to a quasi-Newton method and corresponding\nderivative-free trust-region algorithms like NEWUOA. The proposed method\ntherefore replaces the global recombination step commonly found in non-elitist\nevolution strategies with a quasi-Newton step. Numerical results show\nsuperlinear convergence, resulting in improved performance in particular on\nsmooth convex problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.10987v1",
    "published": "2025-05-16T08:33:30+00:00",
    "categories": [
      "math.OC",
      "cs.NE"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10986v1",
    "title": "Nonlinear Three-Dimensional Electrohydrodynamic Interactions of Viscous Dielectric Drops",
    "authors": [
      "Michael A. McDougall",
      "Stephen K. Wilson",
      "Debasish Das"
    ],
    "abstract": "When a drop of a leaky dielectric fluid is suspended in another fluid and\nsubjected to a uniform DC electric field, it becomes polarized, leading to\ntangential electric stresses that drive fluid motion both inside and outside\nthe drop. In the presence of a second drop, the dynamics of the first drop are\naltered due to electrohydrodynamic interactions with the second, causing the\ndrops to translate due to dielectrophoretic forces and hydrodynamic\ninteractions. We present a semi-analytical nonlinear three-dimensional small\ndeformation theory for a pair of identical, widely-separated leaky dielectric\ndrops suspended in a weakly conducting fluid. This theory is valid under\nconditions of large drop separation, high drop viscosity, and high surface\ntension, ensuring that the drops remain nearly spherical. For the first time,\nwe develop a model within the Taylor--Melcher leaky dielectric framework that\nincorporates both transient charge relaxation and convection. This allows the\nmodel to capture the transition to Quincke rotation, a symmetry-breaking\nphenomenon in which drops begin to spontaneously rotate in sufficiently strong\nfields. We derive and numerically integrate coupled nonlinear ordinary\ndifferential equations for the dipole moments, shapes, and positions of the\ndrops. Our results show good quantitative agreement with previous numerical and\nexperimental work in the limit of zero charge relaxation and convection. We\nalso discuss the hysteresis in the onset of Quincke rotation of isolated drops\nobserved in experiments. Various trajectories for pairs of drops undergoing\nQuincke rotation are presented, along with results for fixed drops. In\nparticular, we show that the onset of Quincke rotation for a pair of drops is\nqualitatively different from that for an isolated drop due to\nelectrohydrodynamic interactions and a pair of solid spheres due to straining\nflows present only in drops.",
    "pdf_url": "http://arxiv.org/pdf/2505.10986v1",
    "published": "2025-05-16T08:33:28+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.10985v3",
    "title": "On the properties of alternating invariant functions",
    "authors": [
      "Haiqing Zhu",
      "Su Hu",
      "Min-Soo Kim"
    ],
    "abstract": "Functions satisfying the functional equation \\begin{align*} \\sum_{r=0}^{n-1}\n(-1)^r f(x+ry, ny) = f(x,y), \\quad \\text{for any positive odd integer $n$},\n\\end{align*} are named the alternating invariant functions. Examples of such\nfunctions include Euler polynomials, alternating Hurwitz zeta functions and\ntheir associated Gamma functions. In this paper, we systematically investigate\nthe fundamental properties of alternating invariant functions. We prove that\nthe set of such functions is closed under translation, reflection, and\ndifferentiation. In addition, we define a convolution operation on alternating\ninvariant functions and derive explicit convolution formulas for Euler\npolynomials and alternating Hurwitz zeta functions, respectively. Furthermore,\nusing distributional relations, we construct new examples of alternating\ninvariant functions, including suitable combinations of trigonometric,\nexponential, and logarithmic functions, among others.",
    "pdf_url": "http://arxiv.org/pdf/2505.10985v3",
    "published": "2025-05-16T08:31:15+00:00",
    "categories": [
      "math.NT",
      "math.CA",
      "math.CO",
      "11B68, 11M06, 33B15, 33B10"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.10984v1",
    "title": "Magnetotransport signatures of spin-orbit coupling in high-temperature cuprate superconductors",
    "authors": [
      "Aleix Barrera",
      "Huidong Li",
      "Thomas Gunkel",
      "Jordi Alcalà",
      "Silvia Damerio",
      "Can Onur Avci",
      "Anna Palau"
    ],
    "abstract": "Spin transport in superconductors offers a compelling platform to merge the\ndissipationless nature of superconductivity with the functional promise of\nspin-based electronics. A significant challenge in achieving spin polarisation\nin conventional superconductors stems from the singlet state of Cooper pairs,\nwhich exhibit no net spin. The generation of spin-polarised carriers,\nquasiparticles, or triplet pairs in superconductors has predominantly been\nrealised in hybrid superconductor/ferromagnet systems through proximity-induced\nspin polarisation. Historically, cuprate superconductors have been\ncharacterised by strong electronic correlations but negligible spin-orbit\ncoupling. Here, we report exceptionally large anisotropic magnetoresistance and\na pronounced planar Hall effect arising near the superconducting phase\ntransition in the prototypical high-temperature cuprate superconductor\nYBa2Cu3O7-x without using a proximity ferromagnet. These effects, unprecedented\nin centrosymmetric cuprates, emerge from spin-polarised quasiparticle transport\nmediated by strong spin-orbit coupling. By systematically tuning magnetic field\nstrength, orientation, temperature, and doping, we show clear evidence of\nspin-orbit-driven transport phenomena in a material class long thought to lack\nsuch interactions. Our findings reveal an unexpected spin-orbit landscape in\ncuprates and open a route to engineer spintronic functionalities in\nhigh-temperature superconductors.",
    "pdf_url": "http://arxiv.org/pdf/2505.10984v1",
    "published": "2025-05-16T08:30:27+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.10983v1",
    "title": "GenoArmory: A Unified Evaluation Framework for Adversarial Attacks on Genomic Foundation Models",
    "authors": [
      "Haozheng Luo",
      "Chenghao Qiu",
      "Yimin Wang",
      "Shang Wu",
      "Jiahao Yu",
      "Han Liu",
      "Binghui Wang",
      "Yan Chen"
    ],
    "abstract": "We propose the first unified adversarial attack benchmark for Genomic\nFoundation Models (GFMs), named GenoArmory. Unlike existing GFM benchmarks,\nGenoArmory offers the first comprehensive evaluation framework to\nsystematically assess the vulnerability of GFMs to adversarial attacks.\nMethodologically, we evaluate the adversarial robustness of five\nstate-of-the-art GFMs using four widely adopted attack algorithms and three\ndefense strategies. Importantly, our benchmark provides an accessible and\ncomprehensive framework to analyze GFM vulnerabilities with respect to model\narchitecture, quantization schemes, and training datasets. Additionally, we\nintroduce GenoAdv, a new adversarial sample dataset designed to improve GFM\nsafety. Empirically, classification models exhibit greater robustness to\nadversarial perturbations compared to generative models, highlighting the\nimpact of task type on model vulnerability. Moreover, adversarial attacks\nfrequently target biologically significant genomic regions, suggesting that\nthese models effectively capture meaningful sequence features.",
    "pdf_url": "http://arxiv.org/pdf/2505.10983v1",
    "published": "2025-05-16T08:29:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10982v1",
    "title": "Facets in Argumentation: A Formal Approach to Argument Significance",
    "authors": [
      "Johannes Fichte",
      "Nicolas Fröhlich",
      "Markus Hecher",
      "Victor Lagerkvist",
      "Yasir Mahmood",
      "Arne Meier",
      "Jonathan Persson"
    ],
    "abstract": "Argumentation is a central subarea of Artificial Intelligence (AI) for\nmodeling and reasoning about arguments. The semantics of abstract argumentation\nframeworks (AFs) is given by sets of arguments (extensions) and conditions on\nthe relationship between them, such as stable or admissible. Today's solvers\nimplement tasks such as finding extensions, deciding credulous or skeptical\nacceptance, counting, or enumerating extensions. While these tasks are well\ncharted, the area between decision, counting/enumeration and fine-grained\nreasoning requires expensive reasoning so far. We introduce a novel concept\n(facets) for reasoning between decision and enumeration. Facets are arguments\nthat belong to some extensions (credulous) but not to all extensions\n(skeptical). They are most natural when a user aims to navigate, filter, or\ncomprehend the significance of specific arguments, according to their needs. We\nstudy the complexity and show that tasks involving facets are much easier than\ncounting extensions. Finally, we provide an implementation, and conduct\nexperiments to demonstrate feasibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.10982v1",
    "published": "2025-05-16T08:29:38+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10981v3",
    "title": "Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory",
    "authors": [
      "Yexiang Liu",
      "Zekun Li",
      "Zhi Fang",
      "Nan Xu",
      "Ran He",
      "Tieniu Tan"
    ],
    "abstract": "Recently, scaling test-time compute on Large Language Models (LLM) has\ngarnered wide attention. However, there has been limited investigation of how\nvarious reasoning prompting strategies perform as scaling. In this paper, we\nfocus on a standard and realistic scaling setting: majority voting. We\nsystematically conduct experiments on 6 LLMs $\\times$ 8 prompting strategies\n$\\times$ 6 benchmarks. Experiment results consistently show that as the\nsampling time and computational overhead increase, complicated prompting\nstrategies with superior initial performance gradually fall behind simple\nChain-of-Thought. We analyze this phenomenon and provide theoretical proofs.\nAdditionally, we propose a probabilistic method to efficiently predict scaling\nperformance and identify the best prompting strategy under large sampling\ntimes, eliminating the need for resource-intensive inference processes in\npractical applications. Furthermore, we introduce two ways derived from our\ntheoretical analysis to significantly improve the scaling performance. We hope\nthat our research can promote to re-examine the role of complicated prompting,\nunleash the potential of simple prompting strategies, and provide new insights\nfor enhancing test-time scaling performance. Code is available at\nhttps://github.com/MraDonkey/rethinking_prompting.",
    "pdf_url": "http://arxiv.org/pdf/2505.10981v3",
    "published": "2025-05-16T08:28:57+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10980v1",
    "title": "Spray-Invariant Sets in Infinite-Dimensional Manifolds",
    "authors": [
      "Kaveh Eftekharinasab"
    ],
    "abstract": "We introduce the concept of spray-invariant sets on infinite-dimensional\nmanifolds, where any geodesic of a spray starting in the set stays within it\nfor its entire domain. These sets, possibly including singular spaces such as\nstratified spaces, exhibit different geometric properties depending on their\nregularity: singular sets may show sensitive dependence, for example, on\nparametrization, whereas for differentiable submanifolds invariance is\npreserved under reparametrization.\n  This framework offers a broader perspective on geodesic preservation than the\nrigid notion of totally geodesic submanifolds, with examples arising naturally\neven in simple settings, such as linear spaces equipped with flat sprays.",
    "pdf_url": "http://arxiv.org/pdf/2505.10980v1",
    "published": "2025-05-16T08:28:25+00:00",
    "categories": [
      "math.DG",
      "58B20, 53C22, 37B35"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11564v1",
    "title": "HessFormer: Hessians at Foundation Scale",
    "authors": [
      "Diego Granziol"
    ],
    "abstract": "Whilst there have been major advancements in the field of first order\noptimisation of deep learning models, where state of the art open source\nmixture of expert models go into the hundreds of billions of parameters,\nmethods that rely on Hessian vector products, are still limited to run on a\nsingle GPU and thus cannot even work for models in the billion parameter range.\nWe release a software package \\textbf{HessFormer}, which integrates nicely with\nthe well known Transformers package and allows for distributed hessian vector\ncomputation across a single node with multiple GPUs. Underpinning our\nimplementation is a distributed stochastic lanczos quadrature algorithm, which\nwe release for public consumption. Using this package we investigate the\nHessian spectral density of the recent Deepseek $70$bn parameter model.",
    "pdf_url": "http://arxiv.org/pdf/2505.11564v1",
    "published": "2025-05-16T08:27:43+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10979v1",
    "title": "A Scalable Procedure for $\\mathcal{H}_{\\infty}-$Control Design",
    "authors": [
      "Amit Kumar",
      "Prasad Vilas Chanekar"
    ],
    "abstract": "This paper proposes a novel gradient based scalable procedure for\n$\\mathcal{H}_{\\infty}-$control design. We compute the gradient using algebraic\nRiccati equation and then couple it with a novel Armijo rule inspired step-size\nselection procedure. We perform numerical experiments of the proposed solution\nprocedure on an exhaustive list of benchmark engineering systems to show its\nconvergence properties. Finally we compare our proposed solution procedure with\navailable semi-definite programming based gradient-descent algorithm to\ndemonstrate its scalability.",
    "pdf_url": "http://arxiv.org/pdf/2505.10979v1",
    "published": "2025-05-16T08:27:26+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10978v2",
    "title": "Group-in-Group Policy Optimization for LLM Agent Training",
    "authors": [
      "Lang Feng",
      "Zhenghai Xue",
      "Tingcong Liu",
      "Bo An"
    ],
    "abstract": "Recent advances in group-based reinforcement learning (RL) have driven\nfrontier large language models (LLMs) in single-turn tasks like mathematical\nreasoning. However, their scalability to long-horizon LLM agent training\nremains limited. Unlike static tasks, agent-environment interactions unfold\nover many steps and often yield sparse or delayed rewards, making credit\nassignment across individual steps significantly more challenging. In this\nwork, we propose Group-in-Group Policy Optimization (GiGPO), a novel RL\nalgorithm that achieves fine-grained credit assignment for LLM agents while\npreserving the appealing properties of group-based RL: critic-free, low memory,\nand stable convergence. GiGPO introduces a two-level structure for estimating\nrelative advantage: (i) At the episode-level, GiGPO computes macro relative\nadvantages based on groups of complete trajectories; (ii) At the step-level,\nGiGPO introduces an anchor state grouping mechanism that retroactively\nconstructs step-level groups by identifying repeated environment states across\ntrajectories. Actions stemming from the same state are grouped together,\nenabling micro relative advantage estimation. This hierarchical structure\neffectively captures both global trajectory quality and local step\neffectiveness without relying on auxiliary models or additional rollouts. We\nevaluate GiGPO on two challenging agent benchmarks, ALFWorld and WebShop, using\nQwen2.5-1.5B-Instruct and Qwen2.5-7B-Instruct. Crucially, GiGPO delivers\nfine-grained per-step credit signals and achieves performance gains of > 12\\%\non ALFWorld and > 9\\% on WebShop over the GRPO baseline: all while maintaining\nthe same GPU memory overhead, identical LLM rollout, and incurring little to no\nadditional time cost.",
    "pdf_url": "http://arxiv.org/pdf/2505.10978v2",
    "published": "2025-05-16T08:26:59+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10977v1",
    "title": "Trapping in a Casimir Force Set-Up Controlled by Solution Permeability",
    "authors": [
      "S. Pal",
      "L. Inacio",
      "L. M. Woods",
      "U. De Giovannini",
      "C. Persson",
      "M. Boström"
    ],
    "abstract": "We have designed a system enabling tuning Casimir attraction/repulsion\ntransitions between a polystyrene sphere attached to an atomic force microscope\ntip near a Teflon surface in a magnetic fluid mixture. Notably, the trapping\ndistances can be changed by several orders of magnitude by changes in\nzero-frequency transverse electric contributions to the Casimir force. We\ndemonstrate that this can be achieved via modifications in the average diameter\nfor the magnetite particles while keeping the magnetite volume fractions fixed.",
    "pdf_url": "http://arxiv.org/pdf/2505.10977v1",
    "published": "2025-05-16T08:25:03+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.10976v1",
    "title": "Automated quasar continuum estimation using neural networks: a comparative study of deep-learning architectures",
    "authors": [
      "Francesco Pistis",
      "Michele Fumagalli",
      "Matteo Fossati",
      "Trystyn Berg",
      "Elena S. Mangola",
      "Rajeshwari Dutta",
      "Margherita Grespan",
      "Angela Iovino",
      "Katarzyna Małek",
      "Sean Morrison",
      "David N. A. Murphy",
      "William J. Pearson",
      "Ignasi Pérez-Ráfols",
      "Matthew M. Pieri",
      "Agnieszka Pollo",
      "Daniela Vergani"
    ],
    "abstract": "Context. Ongoing and upcoming large spectroscopic surveys are drastically\nincreasing the number of observed quasar spectra, requiring the development of\nfast and accurate automated methods to estimate spectral continua. Aims. This\nstudy evaluates the performance of three neural networks (NN) - an autoencoder,\na convolutional NN (CNN), and a U-Net - in predicting quasar continua within\nthe rest-frame wavelength range of $1020~\\text{\\AA}$ to $2000~\\text{\\AA}$. The\nability to generalize and predict galaxy continua within the range of\n$3500~\\text{\\AA}$ to $5500~\\text{\\AA}$ is also tested. Methods. The performance\nof these architectures is evaluated using the absolute fractional flux error\n(AFFE) on a library of mock quasar spectra for the WEAVE survey, and on real\ndata from the Early Data Release observations of the Dark Energy Spectroscopic\nInstrument (DESI) and the VIMOS Public Extragalactic Redshift Survey (VIPERS).\nResults. The autoencoder outperforms the U-Net, achieving a median AFFE of\n0.009 for quasars. The best model also effectively recovers the Ly$\\alpha$\noptical depth evolution in DESI quasar spectra. With minimal optimization, the\nsame architectures can be generalized to the galaxy case, with the autoencoder\nreaching a median AFFE of 0.014 and reproducing the D4000n break in DESI and\nVIPERS galaxies.",
    "pdf_url": "http://arxiv.org/pdf/2505.10976v1",
    "published": "2025-05-16T08:24:13+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.10975v1",
    "title": "Survey of End-to-End Multi-Speaker Automatic Speech Recognition for Monaural Audio",
    "authors": [
      "Xinlu He",
      "Jacob Whitehill"
    ],
    "abstract": "Monaural multi-speaker automatic speech recognition (ASR) remains challenging\ndue to data scarcity and the intrinsic difficulty of recognizing and\nattributing words to individual speakers, particularly in overlapping speech.\nRecent advances have driven the shift from cascade systems to end-to-end (E2E)\narchitectures, which reduce error propagation and better exploit the synergy\nbetween speech content and speaker identity. Despite rapid progress in E2E\nmulti-speaker ASR, the field lacks a comprehensive review of recent\ndevelopments. This survey provides a systematic taxonomy of E2E neural\napproaches for multi-speaker ASR, highlighting recent advances and comparative\nanalysis. Specifically, we analyze: (1) architectural paradigms (SIMO vs.~SISO)\nfor pre-segmented audio, analyzing their distinct characteristics and\ntrade-offs; (2) recent architectural and algorithmic improvements based on\nthese two paradigms; (3) extensions to long-form speech, including segmentation\nstrategy and speaker-consistent hypothesis stitching. Further, we (4) evaluate\nand compare methods across standard benchmarks. We conclude with a discussion\nof open challenges and future research directions towards building robust and\nscalable multi-speaker ASR.",
    "pdf_url": "http://arxiv.org/pdf/2505.10975v1",
    "published": "2025-05-16T08:21:59+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.23779v1",
    "title": "Largest square divisors of shifted primes",
    "authors": [
      "Runbo Li"
    ],
    "abstract": "The author shows that there are infinitely many primes $p$ such that for any\nnonzero integer $a$, $p-a$ is divisible by a square $d^2 >\np^{\\frac{1}{2}+\\frac{1}{700}}$. The exponent $\\frac{1}{2}+\\frac{1}{700}$\nimproves Merikoski's $\\frac{1}{2}+\\frac{1}{2000}$. Many powerful devices in\nHarman's sieve are used for this improvement.",
    "pdf_url": "http://arxiv.org/pdf/2505.23779v1",
    "published": "2025-05-16T08:21:36+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.10974v2",
    "title": "Thermodynamics of the $S=1/2$ maple-leaf Heisenberg antiferromagnet",
    "authors": [
      "Taras Hutak"
    ],
    "abstract": "The Heisenberg antiferromagnet on the maple-leaf lattice has recently\ngathered a great deal of attention. Competition between three nonequivalent\nbond interactions results in various ground-state quantum phases, the exact\ndimer-product singlet ground state being among them. The thermodynamic\nproperties of this model are much less understood. We used high-temperature\nexpansion up to the $18$th order to study the thermodynamics of the $S=1/2$\nHeisenberg model on the uniform maple-leaf lattice with the ground state\nexhibiting a six-sublattice $120^{\\circ}$ long-range magnetic order. Pad\\'{e}\napproximants allow us to get reliable results up to the temperatures of about\n$T\\approx 0.4$. To study thermodynamics for arbitrary temperatures, we made the\ninterpolation using the entropy method. Based on the analysis of close Pad\\'{e}\napproximants, we find ground-state energy $e_{0}=-0.53064\\ldots -0.53023$ in\ngood agreement with numerical results. The specific heat $c(T)$ has a typical\nmaximum at rather low temperatures $T\\approx0.379$ and the uniform\nsusceptibility $\\chi(T)$ at $T\\approx0.49$. We also estimate the value of\n$\\chi(T)$ at zero temperature $\\chi_{0}\\approx0.05\\ldots0.06$. The ground-state\norder manifests itself in the divergence of the so-called generalized Wilson\nratio.",
    "pdf_url": "http://arxiv.org/pdf/2505.10974v2",
    "published": "2025-05-16T08:21:21+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.10973v3",
    "title": "GRoQ-LoCO: Generalist and Robot-agnostic Quadruped Locomotion Control using Offline Datasets",
    "authors": [
      "Narayanan PP",
      "Sarvesh Prasanth Venkatesan",
      "Srinivas Kantha Reddy",
      "Shishir Kolathaya"
    ],
    "abstract": "Recent advancements in large-scale offline training have demonstrated the\npotential of generalist policy learning for complex robotic tasks. However,\napplying these principles to legged locomotion remains a challenge due to\ncontinuous dynamics and the need for real-time adaptation across diverse\nterrains and robot morphologies. In this work, we propose GRoQ-LoCO, a\nscalable, attention-based framework that learns a single generalist locomotion\npolicy across multiple quadruped robots and terrains, relying solely on offline\ndatasets. Our approach leverages expert demonstrations from two distinct\nlocomotion behaviors - stair traversal (non-periodic gaits) and flat terrain\ntraversal (periodic gaits) - collected across multiple quadruped robots, to\ntrain a generalist model that enables behavior fusion. Crucially, our framework\noperates solely on proprioceptive data from all robots without incorporating\nany robot-specific encodings. The policy is directly deployable on an Intel i7\nnuc, producing low-latency control outputs without any test-time optimization.\nOur extensive experiments demonstrate zero-shot transfer across highly diverse\nquadruped robots and terrains, including hardware deployment on the Unitree\nGo1, a commercially available 12kg robot. Notably, we evaluate challenging\ncross-robot training setups where different locomotion skills are unevenly\ndistributed across robots, yet observe successful transfer of both flat walking\nand stair traversal behaviors to all robots at test time. We also show\npreliminary walking on Stoch 5, a 70kg quadruped, on flat and outdoor terrains\nwithout requiring any fine tuning. These results demonstrate the potential of\noffline, data-driven learning to generalize locomotion across diverse quadruped\nmorphologies and behaviors.",
    "pdf_url": "http://arxiv.org/pdf/2505.10973v3",
    "published": "2025-05-16T08:17:01+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "I.2.9"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10972v1",
    "title": "Inelastic tunneling into multipolaronic bound states in single-layer MoS$_2$",
    "authors": [
      "Camiel van Efferen",
      "Laura Pätzold",
      "Tfyeche Y. Tounsi",
      "Arne Schobert",
      "Michael Winter",
      "Yann in 't Veld",
      "Mark Georger",
      "Affan Safeer",
      "Christian Krämer",
      "Jeison Fischer",
      "Jan Berges",
      "Thomas Michely",
      "Roberto Mozara",
      "Tim Wehling",
      "Wouter Jolie"
    ],
    "abstract": "Polarons are quasiparticles that arise from the interaction of electrons or\nholes with lattice vibrations. Though polarons are well-studied across multiple\ndisciplines, experimental observations of polarons in two-dimensional crystals\nare sparse. We use scanning tunneling microscopy and spectroscopy to measure\ninelastic excitations of polaronic bound states emerging from coupling of\nnon-polar zone-boundary phonons to Bloch electrons in n-doped metallic\nsingle-layer MoS$_2$. The latter is kept chemically pristine via contactless\nchemical doping. Tunneling into the vibrationally coupled polaronic states\nleads to a series of evenly spaced peaks in the differential conductance on\neither side of the Fermi level. Combining density functional (perturbation)\ntheory with a recently developed ab initio electron-lattice downfolding\ntechnique, we show that the energy spacing stems from the longitudinal-acoustic\nphonon mode that flattens at the Brillouin zone edge and is responsible for the\nformation of stable multipolarons in metallic MoS$_2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.10972v1",
    "published": "2025-05-16T08:16:04+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.10971v2",
    "title": "Collective excited states at small amplitude in neutron elastic scattering at low-energies",
    "authors": [
      "Do Quang Tam",
      "Nguyen Hoang Tung",
      "Nguyen Hoang Phuc",
      "T. V. Nhan Hao"
    ],
    "abstract": "We investigate the contributions of isoscalar and isovector collective\nexcitations in the neutron elastic scattering of $^{16}$O, $^{40}$Ca,\n$^{48}$Ca, and $^{208}$Pb nuclei by using a microscopic optical potential (MOP)\nderived from nuclear structure models based on self-consistent mean-field\napproaches. Particular attention is given to the role of these collective modes\nin shaping the imaginary part of the MOP and the resulting angular\ndistributions. Our analysis indicates that both isoscalar and isovector\ncontributions are significant for all considered targets, especially for light\nand medium targets. Furthermore, the Coulomb interaction is found to play an\nimportant role in describing absorption mechanisms and reproducing the\nexperimental angular distributions.",
    "pdf_url": "http://arxiv.org/pdf/2505.10971v2",
    "published": "2025-05-16T08:12:32+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.10970v1",
    "title": "Bullet shooting cloud-cloud collision in MIR bubble N65",
    "authors": [
      "En Chen",
      "Xi Chen",
      "Min Fang",
      "Xuepeng Chen",
      "Qianru He",
      "Tian Yang"
    ],
    "abstract": "We report that the formation of the twin-bubble system N65 and N65bis may be\ncaused by the cloud-cloud collision (CCC) from the Bullet Nebula. The\nblue-shifted $^{13}$CO gas component (N65a [47, 55] km s$^{-1}$) is associated\nwith the twin-bubble system, while the red-shifted $^{13}$CO gas component\n(N65b [55, 62] km s$^{-1}$) is linked to the Bullet Nebula. The distinct\nsignatures of CCC, such as the bridge feature, the U-shape cavity and the\ncomplementary distribution with displacement, are found between N65a and N65b.\nThe collision timescale is estimated to be 1.15 to 2.0 Myr, which is consistent\nwith the dynamical ages of the two \\HII regions in N65a (0.73 Myr for N65bis\nand 1.19 Myr for N65, respectively), indicating their CCC-related origin. A\ntotal of 354 young stellar objects (YSOs) are founded, which are clustered into\neight MST (Minimum Spinning Tree) groups. The distribution of M1 (at the\npost-frontal edge) and M2, M3, M4 (at the pre-frontal edge) suggests that the\nCCC triggers star formation along the collision path of $b=0^{\\circ}.35$, with\nyounger YSOs present at the pre-frontal edge. Therefore, the bipolar morphology\nof the twin-bubble system can be interpreted by the collision of N65a and N65b\nalong $b=0^{\\circ}.35$ about 2 Myr ago.",
    "pdf_url": "http://arxiv.org/pdf/2505.10970v1",
    "published": "2025-05-16T08:12:04+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.10969v2",
    "title": "Benchmarking CFAR and CNN-based Peak Detection Algorithms in ISAC under Hardware Impairments",
    "authors": [
      "Paolo Tosi",
      "Steffen Schieler",
      "Marcus Henninger",
      "Sebastian Semper",
      "Silvio Mandelli"
    ],
    "abstract": "Peak detection is a fundamental task in radar and has therefore been studied\nextensively in radar literature. However, Integrated Sensing and Communication\n(ISAC) systems for sixth generation (6G) cellular networks need to perform peak\ndetection under hardware impairments and constraints imposed by the underlying\nsystem designed for communications. This paper presents a comparative study of\nclassical Constant False Alarm Rate (CFAR)-based algorithms and a recently\nproposed Convolutional Neural Network (CNN)-based method for peak detection in\nISAC radar images. To impose practical constraints of ISAC systems, we model\nthe impact of hardware impairments, such as power amplifier nonlinearities and\nquantization noise. We perform extensive simulation campaigns focusing on\nmulti-target detection under varying noise as well as on target separation in\nresolution-limited scenarios. The results show that CFAR detectors require\napproximate knowledge of the operating scenario and the use of window functions\nfor reliable performance. The CNN, on the other hand, achieves high performance\nin all scenarios, but requires a preprocessing step for the input data.",
    "pdf_url": "http://arxiv.org/pdf/2505.10969v2",
    "published": "2025-05-16T08:10:36+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10968v1",
    "title": "Towards local and compositional measurements in quantum field theory",
    "authors": [
      "Robert Oeckl",
      "Adamantia Zampeli"
    ],
    "abstract": "A universal framework for the joint measurement of multiple localized\nobservables in quantum field theory satisfying spacetime locality and\ncompositionality is still lacking. We present an approach to the problem that\nis based on the one hand on the positive formalism, an axiomatic framework,\nwhere it is clear from the outset that we satisfy locality and\ncompositionality, while also having a consistent probabilistic interpretation.\nOn the other hand, the approach is based on standard tools from quantum field\ntheory, in particular the path integral and the Schwinger-Keldysh formalism.\nAfter an overview of the conceptual foundations we introduce the modulus-square\nconstruction as a formalization of the measurement process for an important\nclass of observables including quadratic observables. We show that this\nconstruction has many of the desired properties, including positivity,\nlocality, single measurement recovery and compositionality. We introduce a\nrenormalization scheme for the measurement of quadratic observables that also\nsatisfies compositionality, in contrast to previous renormalization schemes. We\ndiscuss relativistic causality, confirming that measurements in our scheme are\nindeed localized in the spacetime regions where the underlying observables have\nsupport.",
    "pdf_url": "http://arxiv.org/pdf/2505.10968v1",
    "published": "2025-05-16T08:08:42+00:00",
    "categories": [
      "hep-th",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.10967v1",
    "title": "Exploration of amorphous V$_2$O$_5$ as cathode for magnesium batteries",
    "authors": [
      "Vijay Choyal",
      "Debsundar Dey",
      "Gopalakrishnan Sai Gautam"
    ],
    "abstract": "Development of energy storage technologies that can exhibit higher energy\ndensities, better safety, and lower supply-chain constraints than the current\nstate-of-the-art Li-ion batteries (LIBs) is crucial for our transition into\nsustainable energy use. In this context, Mg batteries (MBs) offer a promising\npathway to design energy storage systems with superior volumetric energy\ndensities than LIBs but require the development of positive electrodes\n(cathodes) exhibiting high energy and power densities. Notably, amorphous\nmaterials that lack long range order can exhibit `flatter' potential energy\nsurfaces than crystalline frameworks, possibly resulting in faster Mg$^{2+}$\nmotion. Here, we use a combination of ab initio molecular dynamics (AIMD), and\nmachine learned interatomic potential (MLIP) based calculations to explore\namorphous V$_2$O$_5$ as a potential cathode for MBs. Using an AIMD-generated\ndataset, we train and validate moment tensor potentials that can accurately\nmodel amorphous (Mg)V$_2$O$_5$ Due to the amorphization of V$_2$O$_5$, we\nobserve a 10-14% drop in the average Mg intercalation voltage $-$ but the\nvoltage remains higher than sulfide Mg cathodes. Importantly, we find a\n$\\sim$seven (five) orders of magnitude higher Mg$^{2+}$ diffusivity in\namorphous MgV$_2$O$_5$ than its crystalline version\n(thiospinel-Mg$_x$Ti$_2$S$_4$), which is directly attributable to the\namorphization of the structure. Also, we note the Mg$^{2+}$ motion in the\namorphous structure is significantly cross-correlated at low temperatures, with\nthe correlation decreasing with increase in temperature. Thus, our work\nhighlights the potential of amorphous V$_2$O$_5$ as a cathode that can exhibit\nboth high energy and power densities, resulting in the practical deployment of\nMBs.",
    "pdf_url": "http://arxiv.org/pdf/2505.10967v1",
    "published": "2025-05-16T08:06:04+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.10966v1",
    "title": "Can Large Language Models Correctly Interpret Equations with Errors?",
    "authors": [
      "Lachlan McGinness",
      "Peter Baumgartner"
    ],
    "abstract": "This paper explores the potential of Large Language Models to accurately\ntranslate student written equations from the Australian Physics Olympiads into\na standard format. Large Language Models were used to extract equations from\nstudent responses and convert these into a standardised format for a computer\nalgebra system. Models with more than fourteen billion parameters were unable\nto complete the task in the required timeframe. No open source model was able\nto achieve the desired level of accuracy given resource constraints available\nfor marking the exam. To improve the accuracy, we implement LLM-modulo and\nconsensus frameworks and report on the results. Future work to improve\nperformance could involve breaking the task into smaller components before\nparsing to the models.",
    "pdf_url": "http://arxiv.org/pdf/2505.10966v1",
    "published": "2025-05-16T08:04:46+00:00",
    "categories": [
      "physics.ed-ph"
    ],
    "primary_category": "physics.ed-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10965v1",
    "title": "Privacy and Confidentiality Requirements Engineering for Process Data",
    "authors": [
      "Fabian Haertel",
      "Juergen Mangler",
      "Nataliia Klievtsova",
      "Celine Mader",
      "Eugen Rigger",
      "Stefanie Rinderle-Ma"
    ],
    "abstract": "The application and development of process mining techniques face significant\nchallenges due to the lack of publicly available real-life event logs. One\nreason for companies to abstain from sharing their data are privacy and\nconfidentiality concerns. Privacy concerns refer to personal data as specified\nin the GDPR and have been addressed in existing work by providing\nprivacy-preserving techniques for event logs. However, the concept of\nconfidentiality in event logs not pertaining to individuals remains unclear,\nalthough they might contain a multitude of sensitive business data. This work\naddresses confidentiality of process data based on the privacy and\nconfidentiality engineering method (PCRE). PCRE interactively explores privacy\nand confidentiality requirements regarding process data with different\nstakeholders and defines privacy-preserving actions to address possible\nconcerns. We co-construct and evaluate PCRE based on structured interviews with\nprocess analysts in two manufacturing companies. PCRE is generic, hence\napplicable in different application domains. The goal is to systematically\nscrutinize process data and balance the trade-off between privacy and utility\nloss.",
    "pdf_url": "http://arxiv.org/pdf/2505.10965v1",
    "published": "2025-05-16T08:03:02+00:00",
    "categories": [
      "cs.SE",
      "cs.CR"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.10964v2",
    "title": "A naive generalization of the hyperbolic and the quasihyperbolic metrics",
    "authors": [
      "Bibekananda Maji",
      "Pritam Naskar",
      "Swadesh Kumar Sahoo"
    ],
    "abstract": "Although the hyperbolic metric possesses many remarkable properties, it is\nnot defined on arbitrary subdomains of $\\mathbb{R}^n$ with $n \\geq 2$. This\narticle introduces a new hyperbolic-type metric that provides an alternative\napproach to this limitation. The proposed metric coincides with the hyperbolic\nmetric on balls and half-spaces, and, quite unexpectedly, agrees with the\nquasihyperbolic metric in unbounded domains. We compute the density of this\nmetric in several classical domains and discuss aspects of its curvature.\nFurthermore, we establish characterizations of uniform domains and John disks\nin terms of the newly defined metric. In addition, we investigate several\ngeometric properties of the metric, including the existence of geodesics and\nthe minimal length of non-trivial closed curves in multiply connected domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.10964v2",
    "published": "2025-05-16T08:00:26+00:00",
    "categories": [
      "math.MG",
      "math.CV",
      "30F45, 30L15, 51K05, 30C65, 30L10, 51M10"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10963v1",
    "title": "Beyond real: Alternative unitary cluster Jastrow models for molecular electronic structure calculations on near-term quantum computers",
    "authors": [
      "Nikolay V. Tkachenko",
      "Hang Ren",
      "Wendy M. Billings",
      "Rebecca Tomann",
      "K. Birgitta Whaley",
      "Martin Head-Gordon"
    ],
    "abstract": "Near-term quantum devices require wavefunction ans\\\"atze that are expressive\nwhile also of shallow circuit depth in order to both accurately and efficiently\nsimulate molecular electronic structure. While unitary coupled cluster (e.g.,\nUCCSD) has become a standard, the high gate count associated with the\nimplementation of this limits its feasibility on noisy intermediate-scale\nquantum (NISQ) hardware. K-fold unitary cluster Jastrow (uCJ) ans\\\"atze\nmitigate this challenge by providing $O(kN^2)$ circuit scaling and favorable\nlinear depth circuit implementation. Previous work has focused on the real\norbital-rotation (Re-uCJ) variant of uCJ, which allows an exact (Trotter-free)\nimplementation. Here we extend and generalize the $k$-fold uCJ framework by\nintroducing two new variants, Im-uCJ and g-uCJ, which incorporate imaginary and\nfully complex orbital rotation operators, respectively. Similar to Re-uCJ, both\nof the new variants achieve quadratic gate-count scaling. Our results focus on\nthe simplest $k=1$ model, and show that the uCJ models frequently maintain\nenergy errors within chemical accuracy. Both g-uCJ and Im-uCJ are more\nexpressive in terms of capturing electron correlation and are also more\naccurate than the earlier Re-uCJ ansatz. We further show that Im-uCJ and g-uCJ\ncircuits can also be implemented exactly, without any Trotter decomposition.\nNumerical tests using $k=1$ on $H_2$, $H_3^+$, $Be_2$, $C_2H_4$, $C_2H_6$ and\n$C_6H_6$ in various basis sets confirm the practical feasibility of these\nshallow Jastrow-based ans\\\"atze for applications on near-term quantum hardware.",
    "pdf_url": "http://arxiv.org/pdf/2505.10963v1",
    "published": "2025-05-16T07:59:37+00:00",
    "categories": [
      "quant-ph",
      "physics.chem-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10962v1",
    "title": "MPS-Prover: Advancing Stepwise Theorem Proving by Multi-Perspective Search and Data Curation",
    "authors": [
      "Zhenwen Liang",
      "Linfeng Song",
      "Yang Li",
      "Tao Yang",
      "Feng Zhang",
      "Haitao Mi",
      "Dong Yu"
    ],
    "abstract": "Automated Theorem Proving (ATP) in formal languages remains a formidable\nchallenge in AI, demanding rigorous logical deduction and navigating vast\nsearch spaces. While large language models (LLMs) have shown promising\nperformance, existing stepwise provers often suffer from biased search\nguidance, leading to inefficiencies and suboptimal proof strategies. This paper\nintroduces the Multi-Perspective Search Prover (MPS-Prover), a novel stepwise\nATP system designed to overcome these limitations. MPS-Prover incorporates two\nkey innovations: a highly effective post-training data curation strategy that\nprunes approximately 40% of redundant training data without sacrificing\nperformance, and a multi-perspective tree search mechanism. This search\nintegrates a learned critic model with strategically designed heuristic rules\nto diversify tactic selection, prevent getting trapped in unproductive states,\nand enhance search robustness. Extensive evaluations demonstrate that\nMPS-Prover achieves state-of-the-art performance on multiple challenging\nbenchmarks, including miniF2F and ProofNet, outperforming prior 7B parameter\nmodels. Furthermore, our analyses reveal that MPS-Prover generates\nsignificantly shorter and more diverse proofs compared to existing stepwise and\nwhole-proof methods, highlighting its efficiency and efficacy. Our work\nadvances the capabilities of LLM-based formal reasoning and offers a robust\nframework and a comprehensive analysis for developing more powerful theorem\nprovers.",
    "pdf_url": "http://arxiv.org/pdf/2505.10962v1",
    "published": "2025-05-16T07:56:03+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10961v1",
    "title": "Let the Trial Begin: A Mock-Court Approach to Vulnerability Detection using LLM-Based Agents",
    "authors": [
      "Ratnadira Widyasari",
      "Martin Weyssow",
      "Ivana Clairine Irsan",
      "Han Wei Ang",
      "Frank Liauw",
      "Eng Lieh Ouh",
      "Lwin Khin Shar",
      "Hong Jin Kang",
      "David Lo"
    ],
    "abstract": "Detecting vulnerabilities in source code remains a critical yet challenging\ntask, especially when benign and vulnerable functions share significant\nsimilarities. In this work, we introduce VulTrial, a courtroom-inspired\nmulti-agent framework designed to enhance automated vulnerability detection. It\nemploys four role-specific agents, which are security researcher, code author,\nmoderator, and review board. Through extensive experiments using GPT-3.5 and\nGPT-4o we demonstrate that Vultrial outperforms single-agent and multi-agent\nbaselines. Using GPT-4o, VulTrial improves the performance by 102.39% and\n84.17% over its respective baseline. Additionally, we show that role-specific\ninstruction tuning in multi-agent with small data (50 pair samples) improves\nthe performance of VulTrial further by 139.89% and 118.30%. Furthermore, we\nanalyze the impact of increasing the number of agent interactions on VulTrial's\noverall performance. While multi-agent setups inherently incur higher costs due\nto increased token usage, our findings reveal that applying VulTrial to a\ncost-effective model like GPT-3.5 can improve its performance by 69.89%\ncompared to GPT-4o in a single-agent setting, at a lower overall cost.",
    "pdf_url": "http://arxiv.org/pdf/2505.10961v1",
    "published": "2025-05-16T07:54:10+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.15833v1",
    "title": "Adversarially Robust Spiking Neural Networks with Sparse Connectivity",
    "authors": [
      "Mathias Schmolli",
      "Maximilian Baronig",
      "Robert Legenstein",
      "Ozan Özdenizci"
    ],
    "abstract": "Deployment of deep neural networks in resource-constrained embedded systems\nrequires innovative algorithmic solutions to facilitate their energy and memory\nefficiency. To further ensure the reliability of these systems against\nmalicious actors, recent works have extensively studied adversarial robustness\nof existing architectures. Our work focuses on the intersection of adversarial\nrobustness, memory- and energy-efficiency in neural networks. We introduce a\nneural network conversion algorithm designed to produce sparse and\nadversarially robust spiking neural networks (SNNs) by leveraging the sparse\nconnectivity and weights from a robustly pretrained artificial neural network\n(ANN). Our approach combines the energy-efficient architecture of SNNs with a\nnovel conversion algorithm, leading to state-of-the-art performance with\nenhanced energy and memory efficiency through sparse connectivity and\nactivations. Our models are shown to achieve up to 100x reduction in the number\nof weights to be stored in memory, with an estimated 8.6x increase in energy\nefficiency compared to dense SNNs, while maintaining high performance and\nrobustness against adversarial threats.",
    "pdf_url": "http://arxiv.org/pdf/2505.15833v1",
    "published": "2025-05-16T07:52:51+00:00",
    "categories": [
      "cs.NE",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.10960v1",
    "title": "Relational Graph Transformer",
    "authors": [
      "Vijay Prakash Dwivedi",
      "Sri Jaladi",
      "Yangyi Shen",
      "Federico López",
      "Charilaos I. Kanatsoulis",
      "Rishi Puri",
      "Matthias Fey",
      "Jure Leskovec"
    ],
    "abstract": "Relational Deep Learning (RDL) is a promising approach for building\nstate-of-the-art predictive models on multi-table relational data by\nrepresenting it as a heterogeneous temporal graph. However, commonly used Graph\nNeural Network models suffer from fundamental limitations in capturing complex\nstructural patterns and long-range dependencies that are inherent in relational\ndata. While Graph Transformers have emerged as powerful alternatives to GNNs on\ngeneral graphs, applying them to relational entity graphs presents unique\nchallenges: (i) Traditional positional encodings fail to generalize to massive,\nheterogeneous graphs; (ii) existing architectures cannot model the temporal\ndynamics and schema constraints of relational data; (iii) existing tokenization\nschemes lose critical structural information. Here we introduce the Relational\nGraph Transformer (RelGT), the first graph transformer architecture designed\nspecifically for relational tables. RelGT employs a novel multi-element\ntokenization strategy that decomposes each node into five components (features,\ntype, hop distance, time, and local structure), enabling efficient encoding of\nheterogeneity, temporality, and topology without expensive precomputation. Our\narchitecture combines local attention over sampled subgraphs with global\nattention to learnable centroids, incorporating both local and database-wide\nrepresentations. Across 21 tasks from the RelBench benchmark, RelGT\nconsistently matches or outperforms GNN baselines by up to 18%, establishing\nGraph Transformers as a powerful architecture for Relational Deep Learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.10960v1",
    "published": "2025-05-16T07:51:58+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10959v1",
    "title": "Novel high symmetry super-hard C48 and C32 allotropes with ana and ukc original topologies: Crystal chemistry and DFT investigations",
    "authors": [
      "Samir F Matar"
    ],
    "abstract": "Novel high symmetry body centered carbon allotropes: cubic C48 and tetragonal\nC32 are proposed with respective original ana and ukc topologies. Devised from\ncrystal structure engineering, their ground state structures and energy derived\nphysical properties were accurately derived based on quantum mechanics\ncalculations within the density functional theory DFT. Both allotropes made of\ndistorted tetrahedral C4 arrangements were found dense with rho larger than\n3g.cm-3 that remain lower than diamond (rho = 3.50 g.cm-3). With cohesive\nalbeit with metastable ground state structures, both allotropes show stability\nfrom the mechanical (elastic properties) and dynamic (phonons band structures)\nproperties. Vickers hardness magnitudes HV(C48) =47 GPa and HV(C32) = 59 GPa\npoint to super-hard materials. The electronic band structures range from large\ndirect band gap close to 5 eV for C48 to indirect band gap close to 2.5 eV\nsemi-conducting C32. Such findings of original allotropes with targeted\nphysical properties are bound to enrich the field of research on carbon.",
    "pdf_url": "http://arxiv.org/pdf/2505.10959v1",
    "published": "2025-05-16T07:51:22+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.10958v1",
    "title": "Measurement of viscoelastic properties of a liquid using an immersed rotating body of a general shape subjected to oscillatory shear",
    "authors": [
      "Hye Jin Ahn",
      "Wook Ryol Hwang"
    ],
    "abstract": "We propose a novel method for measuring linear and non-linear viscoelastic\nproperties of a liquid by the oscillatory motion of an immersed rotating body\nin a vessel. The shape of a rotating object is general and we tested four\ndifferent types of impellers: a disk, an anchor, and two different flat bladed\nturbines. In deriving the expressions of complex shear moduli, two different\napproaches were employed: one is based on the complex viscosity and the other\nis on the relationship between mean shear stress and mean shear strain. Both\nmethods yield identical expressions for complex moduli. Using the latter\nmethod, the mean shear stress was appropriately scaled with torque, and the\nstrain magnitude was scaled with the deflection angle, enabling its application\nto large-strain nonlinear oscillatory tests. Aqueous polyethylene oxide (PEO)\nsolutions, xanthan gum solution and ketchup were tested and linear viscoelastic\nresponses of storage and loss moduli were first presented as a function of the\noscillation frequency. In spite of the presence of non-rheometric and highly\nnon-uniform flow field, comparison with the data from the conventional\ncone-and-plate fixture of a rheometer shows remarkably accurate measurement\nwith at most 7% average error within the frequency range from 0.01 [rad/s] to\n100 [rad/s] for all the impeller geometries. In addition, large amplitude\noscillatory shear experiments were also tested and discrepancy with highly\nelastic fluid were discussed. The proposed method may facilitate the in-situ\nmeasurement of viscoelastic properties of a fluid within an industrial\nreactor/agitator as a tool for on-line monitoring.",
    "pdf_url": "http://arxiv.org/pdf/2505.10958v1",
    "published": "2025-05-16T07:51:20+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.10957v1",
    "title": "An approach for thermal conductivity measurements in thin films: Combining localized surface topography, thermal analysis, and machine learning techniques",
    "authors": [
      "Mohsen Dehbashi",
      "Anna Kazmierczak-Balata",
      "Jerzy Bodzenta"
    ],
    "abstract": "This study presents a comprehensive methodology for determining the thermal\nconductivity (TC) of materials with high reliability. The methodology addresses\nissues such as surface topographical variations and substrate interference by\ncombining Scanning Thermal Microscopy (SThM) with machine learning (ML) models\nand normalization techniques. Micro- and nanostructural variations in thin\nfilms exacerbate measurement inconsistencies, reducing repeatability and\nreliability. These interconnected challenges highlight the need for a novel,\nflexible, and adaptive methodology that can comprehensively address the\ncomplexities of thin film characterization while maintaining accuracy and\nefficiency. In this approach, sample surface was divided into fine spatial\ngrids for localized thermal and topographical measurements. A\nsubstrate-thickness factor (C factor) was introduced to account for thickness\nand substrate effects on thin film TC, and high-performance Random Forest\nregression was used to predict TC across a broad range of materials. The models\nwere trained on a dataset of 2,352 measurements that covered a wide range of\nmaterial properties and then validated with an additional 980 measurements.\nThey achieved high predictive accuracy, with a $R^2$ of 0.97886 during training\nand 0.96630 during testing. This approach addresses instrumental limitations\nand integrates experimental techniques with computational modeling, providing a\nscalable framework for a wide range of material science applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.10957v1",
    "published": "2025-05-16T07:50:19+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.10956v1",
    "title": "The strong law of large numbers and a functional central limit theorem for general Markov additive processes",
    "authors": [
      "Andreas E. Kyprianou",
      "Victor Rivero"
    ],
    "abstract": "In this note we re-visit the fundamental question of the strong law of large\nnumbers and central limit theorem for processes in continuous time with\nconditional stationary and independent increments. For convenience we refer to\nthem as Markov additive processes, or MAPs for short. Historically used in the\nsetting of queuing theory, MAPs have often been written about when the\nunderlying modulating process is an ergodic Markov chain on a finite state\nspace. Recent works have addressed the strong law of large numbers when the\nunderlying modulating process is a general Markov processes. We add to the\nlatter with a different approach based on an ergodic theorem for additive\nfunctionals and on the semi-martingale structure of the additive part. This\napproach also allows us to deal with the setting that the modulator of the MAP\nis either positive or null recurrent. The methodology additionally inspires a\nCLT-type result.",
    "pdf_url": "http://arxiv.org/pdf/2505.10956v1",
    "published": "2025-05-16T07:49:02+00:00",
    "categories": [
      "math.PR",
      "60J80, 60E10"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01979v1",
    "title": "Speculative Decoding via Hybrid Drafting and Rollback-Aware Branch Parallelism",
    "authors": [
      "Yuhao Shen",
      "Junyi Shen",
      "Quan Kong",
      "Tianyu Liu",
      "Yao Lu",
      "Cong Wang"
    ],
    "abstract": "Recently, speculative decoding (SD) has emerged as a promising technique to\naccelerate LLM inference by employing a small draft model to propose draft\ntokens in advance, and validating them in parallel with the large target model.\nHowever, the existing SD methods still remain fundamentally constrained by\ntheir serialized execution, which causes the mutual waiting bubbles between the\ndraft and target models. To address this challenge, we draw inspiration from\nbranch prediction in modern processors and propose a novel framework\n\\textbf{SpecBranch} to unlock branch parallelism in SD. Specifically, we first\ntake an in-depth analysis of the potential of branch parallelism in SD, and\nrecognize that the key challenge lies in the trade-offs between parallelization\nand token rollback. Based on the analysis, we strategically introduce parallel\nspeculative branches to preemptively hedge against likely rejections.\nMeanwhile, to enhance parallelism, we jointly orchestrate adaptive draft\nlengths with a hybrid combination of the implicit draft model confidence and\nexplicit reusing of target model features. Extensive experiments across various\nmodels and benchmarks show that SpecBranch achieves over \\textbf{1.8}$\\times\n\\sim$ \\textbf{4.5}$\\times$ speedups against the auto-regressive decoding and\nreduces rollback tokens by $\\textbf{50}$\\% for poorly aligned models, realizing\nits applicability for real-world deployments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01979v1",
    "published": "2025-05-16T07:45:05+00:00",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10955v1",
    "title": "Tent transformed order $2$ nets and quasi-Monte Carlo rules with quadratic error decay",
    "authors": [
      "Bernd Käßemodel",
      "Nicolas Nagel",
      "Tino Ullrich"
    ],
    "abstract": "We investigate the use of order $2$ digital nets for quasi-Monte Carlo\nquadrature of nonperiodic functions with bounded mixed second derivative over\nthe cube. By using the so-called tent transform and its mapping properties we\ninherit error bounds from the periodic setting. Our analysis is based on decay\nproperties of the multivariate Faber-Schauder coefficients of functions with\nbounded mixed second weak derivatives. As already observed by Hinrichs,\nMarkhasin, Oettershagen, T. Ullrich (Numerische Mathematik 2016), order $2$\nnets work particularly well on tensorized (periodic) Faber splines. From this\nwe obtain a quadratic decay rate for tent transformed order $2$ nets also in\nthe nonperiodic setting. This improves the formerly best known bound for this\nclass of point sets by a factor of $\\log N$.\n  We back up our findings with numerical experiments, even suggesting that the\nbounds for order $2$ nets can be improved even further. This particularly\nindicates that point sets of lower complexity (compared to previously\nconsidered constructions) may already give (near) optimal error decay rates for\nquadrature of functions with second order mixed smoothness.",
    "pdf_url": "http://arxiv.org/pdf/2505.10955v1",
    "published": "2025-05-16T07:44:35+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.10954v1",
    "title": "Constrained Preferential Bayesian Optimization and Its Application in Banner Ad Design",
    "authors": [
      "Koki Iwai",
      "Yusuke Kumagae",
      "Yuki Koyama",
      "Masahiro Hamasaki",
      "Masataka Goto"
    ],
    "abstract": "Preferential Bayesian optimization (PBO) is a variant of Bayesian\noptimization that observes relative preferences (e.g., pairwise comparisons)\ninstead of direct objective values, making it especially suitable for\nhuman-in-the-loop scenarios. However, real-world optimization tasks often\ninvolve inequality constraints, which existing PBO methods have not yet\naddressed. To fill this gap, we propose constrained preferential Bayesian\noptimization (CPBO), an extension of PBO that incorporates inequality\nconstraints for the first time. Specifically, we present a novel acquisition\nfunction for this purpose. Our technical evaluation shows that our CPBO method\nsuccessfully identifies optimal solutions by focusing on exploring feasible\nregions. As a practical application, we also present a designer-in-the-loop\nsystem for banner ad design using CPBO, where the objective is the designer's\nsubjective preference, and the constraint ensures a target predicted\nclick-through rate. We conducted a user study with professional ad designers,\ndemonstrating the potential benefits of our approach in guiding creative design\nunder real-world constraints.",
    "pdf_url": "http://arxiv.org/pdf/2505.10954v1",
    "published": "2025-05-16T07:41:07+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GR",
      "cs.HC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10953v1",
    "title": "Multi-channel electrically tunable varifocal metalens with compact multilayer polarization-dependent metasurfaces and liquid crystals",
    "authors": [
      "Zhiyao Ma",
      "Zhe Li",
      "Tian Tian",
      "Yuxuan Liao",
      "Xue Feng",
      "Yongzhuo Li",
      "Kaiyu Cui",
      "Fang Liu",
      "Hao Sun",
      "Wei Zhang",
      "Yidong Huang"
    ],
    "abstract": "As an essential module of optical systems, varifocal lens usually consists of\nmultiple mechanically moving lenses along the optical axis. The recent\ndevelopment of metasurfaces with tunable functionalities holds the promise of\nminiaturizing varifocal lens. However, existing varifocal metalenses are hard\nto combine electrical tunability with scalable number and range of focal\nlengths, thus limiting the practical applications. Our previous work shows that\nthe electrically tunable channels could be increased to 2N by cascading N\npolarization-dependent metasurfaces with liquid crystals (LCs). Here, we\ndemonstrated a compact eight-channel electrically tunable varifocal metalens\nwith three single-layer polarization-multiplexed bi-focal metalens and three LC\ncells. The total thickness of the device is ~6 mm, while the focal lengths\ncould be switched among eight values within the range of 3.6 to 9.6 mm. The\nscheme is scalable in number and range of focal lengths and readily for further\nminiaturization. We believe that our proposal would open new possibilities of\nminiaturized imaging systems, AR/VR displays, LiDAR, etc.",
    "pdf_url": "http://arxiv.org/pdf/2505.10953v1",
    "published": "2025-05-16T07:40:32+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.10952v1",
    "title": "Age-stratified clustering of multiple long-term conditions",
    "authors": [
      "Anirban Chakraborty",
      "Bruce Guthrie",
      "Sohan Seth"
    ],
    "abstract": "Background: Most people with any long-term condition have multiple long-term\nconditions, but our understanding of how conditions cluster is limited. Many\nclustering studies identify clusters in the whole population, but the clusters\nthat occur in people of different ages may be distinct. The aim of this paper\nwas to explore similarities and differences in clusters found in different\nage-groups.\n  Method: We present a method for finding similar clusters in multiple\nage-groups, referred to as cluster sets, using Latent Class Analysis (LCA) and\nChebyshev distance metric. We analyse a primary care electronic health record\n(EHR) dataset recording the presence of 40 long-term conditions (LTCs) in\n570,355 people aged 40-99 years with at least one of these conditions,\nanalysing in five-year age-groups.\n  Findings: We find that the 600 clusters found separately in 12 age-strata can\nbe summarised by 342 cluster sets with 263 cluster sets only being found in a\nsingle age-group (singleton cluster sets), and 79 cluster sets being present in\nmultiple age-groups. We observe that 31 conditions of the 40 conditions studied\nappear in cluster sets with the respective condition being the only condition\npresent with a very high prevalence of more than 0.9 whereas the remaining\ncluster sets typically contain two to four conditions present with a high\nprevalence of more than 0.7.\n  Interpretation: Multimorbidity profiles in different age-groups are often\ndistinct (singleton cluster sets observed only in that age-group), but similar\nclusters with small variations in their composition are also found in multiple\nage-groups. This demonstrates the age dependency of MLTC clusters and presents\na case for age-stratified clustering.",
    "pdf_url": "http://arxiv.org/pdf/2505.10952v1",
    "published": "2025-05-16T07:40:02+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10951v2",
    "title": "SubGCache: Accelerating Graph-based RAG with Subgraph-level KV Cache",
    "authors": [
      "Qiuyu Zhu",
      "Liang Zhang",
      "Qianxiong Xu",
      "Cheng Long",
      "Jie Zhang"
    ],
    "abstract": "Graph-based retrieval-augmented generation (RAG) enables large language\nmodels (LLMs) to incorporate structured knowledge via graph retrieval as\ncontextual input, enhancing more accurate and context-aware reasoning. We\nobserve that for different queries, it could retrieve similar subgraphs as\nprompts, and thus we propose SubGCache, which aims to reduce inference latency\nby reusing computation across queries with similar structural prompts (i.e.,\nsubgraphs). Specifically, SubGCache clusters queries based on subgraph\nembeddings, constructs a representative subgraph for each cluster, and\npre-computes the key-value (KV) cache of the representative subgraph. For each\nquery with its retrieved subgraph within a cluster, it reuses the pre-computed\nKV cache of the representative subgraph of the cluster without computing the KV\ntensors again for saving computation. Experiments on two new datasets across\nmultiple LLM backbones and graph-based RAG frameworks demonstrate that\nSubGCache consistently reduces inference latency with comparable and even\nimproved generation quality, achieving up to 6.68$\\times$ reduction in\ntime-to-first-token (TTFT).",
    "pdf_url": "http://arxiv.org/pdf/2505.10951v2",
    "published": "2025-05-16T07:39:41+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10950v1",
    "title": "Shackled Dancing: A Bit-Locked Diffusion Algorithm for Lossless and Controllable Image Steganography",
    "authors": [
      "Tianshuo Zhang",
      "Gao Jia",
      "Wenzhe Zhai",
      "Rui Yann",
      "Xianglei Xing"
    ],
    "abstract": "Data steganography aims to conceal information within visual content, yet\nexisting spatial- and frequency-domain approaches suffer from trade-offs\nbetween security, capacity, and perceptual quality. Recent advances in\ngenerative models, particularly diffusion models, offer new avenues for\nadaptive image synthesis, but integrating precise information embedding into\nthe generative process remains challenging. We introduce Shackled Dancing\nDiffusion, or SD$^2$, a plug-and-play generative steganography method that\ncombines bit-position locking with diffusion sampling injection to enable\ncontrollable information embedding within the generative trajectory. SD$^2$\nleverages the expressive power of diffusion models to synthesize diverse\ncarrier images while maintaining full message recovery with $100\\%$ accuracy.\nOur method achieves a favorable balance between randomness and constraint,\nenhancing robustness against steganalysis without compromising image fidelity.\nExtensive experiments show that SD$^2$ substantially outperforms prior methods\nin security, embedding capacity, and stability. This algorithm offers new\ninsights into controllable generation and opens promising directions for secure\nvisual communication.",
    "pdf_url": "http://arxiv.org/pdf/2505.10950v1",
    "published": "2025-05-16T07:38:58+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10949v1",
    "title": "FP64 is All You Need: Rethinking Failure Modes in Physics-Informed Neural Networks",
    "authors": [
      "Chenhui Xu",
      "Dancheng Liu",
      "Amir Nassereldine",
      "Jinjun Xiong"
    ],
    "abstract": "Physics Informed Neural Networks (PINNs) often exhibit failure modes in which\nthe PDE residual loss converges while the solution error stays large, a\nphenomenon traditionally blamed on local optima separated from the true\nsolution by steep loss barriers. We challenge this understanding by demonstrate\nthat the real culprit is insufficient arithmetic precision: with standard FP32,\nthe LBFGS optimizer prematurely satisfies its convergence test, freezing the\nnetwork in a spurious failure phase. Simply upgrading to FP64 rescues\noptimization, enabling vanilla PINNs to solve PDEs without any failure modes.\nThese results reframe PINN failure modes as precision induced stalls rather\nthan inescapable local minima and expose a three stage training dynamic\nunconverged, failure, success whose boundaries shift with numerical precision.\nOur findings emphasize that rigorous arithmetic precision is the key to\ndependable PDE solving with neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.10949v1",
    "published": "2025-05-16T07:38:13+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10948v1",
    "title": "The Way We Prompt: Conceptual Blending, Neural Dynamics, and Prompt-Induced Transitions in LLMs",
    "authors": [
      "Makoto Sato"
    ],
    "abstract": "Large language models (LLMs), inspired by neuroscience, exhibit behaviors\nthat often evoke a sense of personality and intelligence-yet the mechanisms\nbehind these effects remain elusive. Here, we operationalize Conceptual\nBlending Theory (CBT) as an experimental framework, using prompt-based methods\nto reveal how LLMs blend and compress meaning. By systematically investigating\nPrompt-Induced Transitions (PIT) and Prompt-Induced Hallucinations (PIH), we\nuncover structural parallels and divergences between artificial and biological\ncognition. Our approach bridges linguistics, neuroscience, and empirical AI\nresearch, demonstrating that human-AI collaboration can serve as a living\nprototype for the future of cognitive science. This work proposes prompt\nengineering not just as a technical tool, but as a scientific method for\nprobing the deep structure of meaning itself.",
    "pdf_url": "http://arxiv.org/pdf/2505.10948v1",
    "published": "2025-05-16T07:37:21+00:00",
    "categories": [
      "cs.CL",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10947v2",
    "title": "Certifying Stability of Reinforcement Learning Policies using Generalized Lyapunov Functions",
    "authors": [
      "Kehan Long",
      "Jorge Cortés",
      "Nikolay Atanasov"
    ],
    "abstract": "We study the problem of certifying the stability of closed-loop systems under\ncontrol policies derived from optimal control or reinforcement learning (RL).\nClassical Lyapunov methods require a strict step-wise decrease in the Lyapunov\nfunction but such a certificate is difficult to construct for a learned control\npolicy. The value function associated with an RL policy is a natural Lyapunov\nfunction candidate but it is not clear how it should be modified. To gain\nintuition, we first study the linear quadratic regulator (LQR) problem and make\ntwo key observations. First, a Lyapunov function can be obtained from the value\nfunction of an LQR policy by augmenting it with a residual term related to the\nsystem dynamics and stage cost. Second, the classical Lyapunov decrease\nrequirement can be relaxed to a generalized Lyapunov condition requiring only\ndecrease on average over multiple time steps. Using this intuition, we consider\nthe nonlinear setting and formulate an approach to learn generalized Lyapunov\nfunctions by augmenting RL value functions with neural network residual terms.\nOur approach successfully certifies the stability of RL policies trained on\nGymnasium and DeepMind Control benchmarks. We also extend our method to jointly\ntrain neural controllers and stability certificates using a multi-step Lyapunov\nloss, resulting in larger certified inner approximations of the region of\nattraction compared to the classical Lyapunov approach. Overall, our\nformulation enables stability certification for a broad class of systems with\nlearned policies by making certificates easier to construct, thereby bridging\nclassical control theory and modern learning-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.10947v2",
    "published": "2025-05-16T07:36:40+00:00",
    "categories": [
      "cs.LG",
      "cs.RO",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10946v2",
    "title": "ToDMA: Large Model-Driven Token-Domain Multiple Access for Semantic Communications",
    "authors": [
      "Li Qiao",
      "Mahdi Boloursaz Mashhadi",
      "Zhen Gao",
      "Robert Schober",
      "Deniz Gündüz"
    ],
    "abstract": "Token communications (TokCom) is an emerging generative semantic\ncommunication concept that reduces transmission rates by using context and\nmultimodal large language model (MLLM)-based token processing, with tokens\nserving as universal semantic units across modalities. In this paper, we\npropose a semantic multiple access scheme in the token domain, referred to as\ntoken domain multiple access (ToDMA), where a large number of devices share a\ntoken codebook and a modulation codebook for source and channel coding,\nrespectively. Specifically, each transmitter first tokenizes its source signal\nand modulate each token to a codeword. At the receiver, compressed sensing is\nemployed first to detect active tokens and the corresponding channel state\ninformation (CSI) from the superposed signals. Then, the source token sequences\nare reconstructed by clustering the token-associated CSI across multiple time\nslots. In case of token collisions, some active tokens cannot be assigned and\nsome positions in the reconstructed token sequences are empty. We propose to\nuse pre-trained MLLMs to leverage the context, predict masked tokens, and thus\nmitigate token collisions. Simulation results demonstrate the effectiveness of\nthe proposed ToDMA framework for both text and image transmission tasks,\nachieving significantly lower latency compared to context-unaware orthogonal\ncommunication schemes, while also delivering superior distortion and perceptual\nquality compared to state-of-the-art context-unaware non-orthogonal\ncommunication methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.10946v2",
    "published": "2025-05-16T07:30:42+00:00",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.10945v2",
    "title": "Semantic Aware Linear Transfer by Recycling Pre-trained Language Models for Cross-lingual Transfer",
    "authors": [
      "Seungyoon Lee",
      "Seongtae Hong",
      "Hyeonseok Moon",
      "Heuiseok Lim"
    ],
    "abstract": "Large Language Models (LLMs) increasingly incorporate multilingual\ncapabilities, fueling the demand to transfer them into target language-specific\nmodels. However, most approaches, which blend the source model's embedding by\nreplacing the source vocabulary with the target language-specific vocabulary,\nmay constrain expressive capacity in the target language since the source model\nis predominantly trained on English data. In this paper, we propose Semantic\nAware Linear Transfer (SALT), a novel cross-lingual transfer technique that\nrecycles embeddings from target language Pre-trained Language Models (PLMs) to\ntransmit the deep representational strengths of PLM-derived embedding to LLMs.\nSALT derives unique regression lines based on the similarity in the overlap of\nthe source and target vocabularies, to handle each non-overlapping token's\nembedding space. Our extensive experiments show that SALT significantly\noutperforms other transfer methods and achieves lower loss with accelerating\nfaster convergence during language adaptation. Notably, SALT obtains remarkable\nperformance in cross-lingual understanding setups compared to other methods.\nFurthermore, we highlight the scalable use of PLMs to enhance the functionality\nof contemporary LLMs by conducting experiments with varying architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.10945v2",
    "published": "2025-05-16T07:30:22+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10944v1",
    "title": "Polarimetric insights into a potential binary supermassive black hole system in Mrk 231",
    "authors": [
      "J. Biedermann",
      "F. Marin",
      "T. Barnouin"
    ],
    "abstract": "Markarian 231 (Mrk 231) is one of the brightest ultraluminous infrared\ngalaxies (ULIRGs) known to date. It displays a unique optical-UV spectrum,\ncharacterized by a strong and perplexing attenuation in the near-UV, associated\nwith a sudden polarization peak. Building on previous spectro-photometric\nmodeling, we investigated the hypothesis that the core of Mrk 231 may host a\nbinary SMBH system. In this scenario, the accretion disk of the primary, more\nmassive SMBH is responsible for the optical-UV spectrum. The disk of the\nsecondary, less massive SMBH, would be expected to essentially emit in the far\nUV. We applied this model to archival photometric and polarimetric data of Mrk\n231 and tried to obtain the best fit possible. To support our findings, we\nperformed radiative transfer calculations to determine the spatial disposition\nof each main component constituting Mrk 231. We find that a binary SMBH model\ncan reproduce both the observed flux and polarization of Mrk 231 remarkably\nwell. We infer that the core potentially hosts a binary SMBH system, with a\nprimary SMBH of about 1.6x10^8 solar masses and a secondary of about 1.1x10^7\nsolar masses , separated by a semimajor axis of 146 AU.The secondary SMBH\ndrives a degree of polarization of 3 % between 0.1 and 0.2 {\\mu}m, with a\ncorresponding polarization position angle of about 134{\\deg} , which is\nconsistent with scattering within an accretion disk. The primary SMBH and the\nstructure around it are responsible for a degree of polarization of 23 %\nbetween 0.3 and 0.4 {\\mu}m with a corresponding polarization position angle of\nabout 96{\\deg} , that is possibly attributed to scattering within the quasar's\nwind. Finally, our model predicts the existence of a second peak in polarized\nflux in the far-ultraviolet, a telltale signature that could definitively prove\nthe presence of a binary SMBH.",
    "pdf_url": "http://arxiv.org/pdf/2505.10944v1",
    "published": "2025-05-16T07:29:27+00:00",
    "categories": [
      "astro-ph.GA",
      "85-06",
      "J.2.3; J.2.9"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.10943v1",
    "title": "Universal scaling of segment fluctuations in polymer and chromatin dynamics",
    "authors": [
      "Kirill Polovnikov",
      "Mehran Kardar"
    ],
    "abstract": "We demonstrate how center-of-mass (COM) motion influences polymer segment\nfluctuations. Cancellation of internal forces, together with spatially\nuncorrelated external noise, generally yields COM diffusivity scaling as $1/s$\nwith segment length $s$, regardless of fractal dimension, viscoelasticity, or\nactivity. This introduces distinct dynamic scaling corrections to two-point\nfluctuations and quenched-induced tangential correlations, validated by theory,\nsimulations, and chromatin imaging data. In the latter, the extracted dynamic\nexponent reveals topological constraints, thereby resolving the discrepancy\nbetween chromatin's crumpled structure and its Rouse-like dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.10943v1",
    "published": "2025-05-16T07:28:50+00:00",
    "categories": [
      "cond-mat.soft",
      "physics.bio-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.10942v1",
    "title": "Nosy Layers, Noisy Fixes: Tackling DRAs in Federated Learning Systems using Explainable AI",
    "authors": [
      "Meghali Nandi",
      "Arash Shaghaghi",
      "Nazatul Haque Sultan",
      "Gustavo Batista",
      "Raymond K. Zhao",
      "Sanjay Jha"
    ],
    "abstract": "Federated Learning (FL) has emerged as a powerful paradigm for collaborative\nmodel training while keeping client data decentralized and private. However, it\nis vulnerable to Data Reconstruction Attacks (DRA) such as \"LoKI\" and \"Robbing\nthe Fed\", where malicious models sent from the server to the client can\nreconstruct sensitive user data. To counter this, we introduce DRArmor, a novel\ndefense mechanism that integrates Explainable AI with targeted detection and\nmitigation strategies for DRA. Unlike existing defenses that focus on the\nentire model, DRArmor identifies and addresses the root cause (i.e., malicious\nlayers within the model that send gradients with malicious intent) by analyzing\ntheir contribution to the output and detecting inconsistencies in gradient\nvalues. Once these malicious layers are identified, DRArmor applies defense\ntechniques such as noise injection, pixelation, and pruning to these layers\nrather than the whole model, minimizing the attack surface and preserving\nclient data privacy. We evaluate DRArmor's performance against the advanced\nLoKI attack across diverse datasets, including MNIST, CIFAR-10, CIFAR-100, and\nImageNet, in a 200-client FL setup. Our results demonstrate DRArmor's\neffectiveness in mitigating data leakage, achieving high True Positive and True\nNegative Rates of 0.910 and 0.890, respectively. Additionally, DRArmor\nmaintains an average accuracy of 87%, effectively protecting client privacy\nwithout compromising model performance. Compared to existing defense\nmechanisms, DRArmor reduces the data leakage rate by 62.5% with datasets\ncontaining 500 samples per client.",
    "pdf_url": "http://arxiv.org/pdf/2505.10942v1",
    "published": "2025-05-16T07:28:15+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10941v1",
    "title": "Privacy-Aware Lifelong Learning",
    "authors": [
      "Ozan Özdenizci",
      "Elmar Rueckert",
      "Robert Legenstein"
    ],
    "abstract": "Lifelong learning algorithms enable models to incrementally acquire new\nknowledge without forgetting previously learned information. Contrarily, the\nfield of machine unlearning focuses on explicitly forgetting certain previous\nknowledge from pretrained models when requested, in order to comply with data\nprivacy regulations on the right-to-be-forgotten. Enabling efficient lifelong\nlearning with the capability to selectively unlearn sensitive information from\nmodels presents a critical and largely unaddressed challenge with contradicting\nobjectives. We address this problem from the perspective of simultaneously\npreventing catastrophic forgetting and allowing forward knowledge transfer\nduring task-incremental learning, while ensuring exact task unlearning and\nminimizing memory requirements, based on a single neural network model to be\nadapted. Our proposed solution, privacy-aware lifelong learning (PALL),\ninvolves optimization of task-specific sparse subnetworks with parameter\nsharing within a single architecture. We additionally utilize an episodic\nmemory rehearsal mechanism to facilitate exact unlearning without performance\ndegradations. We empirically demonstrate the scalability of PALL across various\narchitectures in image classification, and provide a state-of-the-art solution\nthat uniquely integrates lifelong learning and privacy-aware unlearning\nmechanisms for responsible AI applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.10941v1",
    "published": "2025-05-16T07:27:00+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10940v2",
    "title": "Who You Are Matters: Bridging Topics and Social Roles via LLM-Enhanced Logical Recommendation",
    "authors": [
      "Qing Yu",
      "Xiaobei Wang",
      "Shuchang Liu",
      "Yandong Bai",
      "Xiaoyu Yang",
      "Xueliang Wang",
      "Chang Meng",
      "Shanshan Wu",
      "Hailan Yang",
      "Huihui Xiao",
      "Xiang Li",
      "Fan Yang",
      "Xiaoqiang Feng",
      "Lantao Hu",
      "Han Li",
      "Kun Gai",
      "Lixin Zou"
    ],
    "abstract": "Recommender systems filter contents/items valuable to users by inferring\npreferences from user features and historical behaviors. Mainstream approaches\nfollow the learning-to-rank paradigm, which focus on discovering and modeling\nitem topics (e.g., categories), and capturing user preferences on these topics\nbased on historical interactions. However, this paradigm often neglects the\nmodeling of user characteristics and their social roles, which are logical\nconfounders influencing the correlated interest and user preference transition.\nTo bridge this gap, we introduce the user role identification task and the\nbehavioral logic modeling task that aim to explicitly model user roles and\nlearn the logical relations between item topics and user social roles. We show\nthat it is possible to explicitly solve these tasks through an efficient\nintegration framework of Large Language Model (LLM) and recommendation systems,\nfor which we propose TagCF. On the one hand, TagCF exploits the (Multi-modal)\nLLM's world knowledge and logic inference ability to extract realistic\ntag-based virtual logic graphs that reveal dynamic and expressive knowledge of\nusers, refining our understanding of user behaviors. On the other hand, TagCF\npresents empirically effective integration modules that take advantage of the\nextracted tag-logic information, augmenting the recommendation performance. We\nconduct both online experiments and offline experiments with industrial and\npublic datasets as verification of TagCF's effectiveness, and we empirically\nshow that the user role modeling strategy is potentially a better choice than\nthe modeling of item topics. Additionally, we provide evidence that the\nextracted logic graphs are empirically a general and transferable knowledge\nthat can benefit a wide range of recommendation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.10940v2",
    "published": "2025-05-16T07:26:41+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10939v2",
    "title": "GenKnowSub: Improving Modularity and Reusability of LLMs through General Knowledge Subtraction",
    "authors": [
      "Mohammadtaha Bagherifard",
      "Sahar Rajabi",
      "Ali Edalat",
      "Yadollah Yaghoobzadeh"
    ],
    "abstract": "Large language models often struggle with zero-shot generalization, and\nseveral modular approaches have been proposed to address this challenge. Yet,\nwe hypothesize that a key limitation remains: the entanglement of general\nknowledge and task-specific adaptations. To overcome this, we propose a modular\nframework that disentangles these components by constructing a library of\ntask-specific LoRA modules alongside a general-domain LoRA. By subtracting this\ngeneral knowledge component from each task-specific module, we obtain residual\nmodules that focus more exclusively on task-relevant information, a method we\ncall general knowledge subtraction (GenKnowSub). Leveraging the refined\ntask-specific modules and the Arrow routing algorithm\n\\citep{ostapenko2024towards}, we dynamically select and combine modules for new\ninputs without additional training. Our studies on the Phi-3 model and standard\nArrow as baselines reveal that using general knowledge LoRAs derived from\ndiverse languages, including English, French, and German, yields consistent\nperformance gains in both monolingual and cross-lingual settings across a wide\nset of benchmarks. Further experiments on Phi-2 demonstrate how GenKnowSub\ngeneralizes to weaker LLMs. The complete code and data are available at\nhttps://github.com/saharsamr/Modular-LLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.10939v2",
    "published": "2025-05-16T07:23:59+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10938v1",
    "title": "Accurate KV Cache Quantization with Outlier Tokens Tracing",
    "authors": [
      "Yi Su",
      "Yuechi Zhou",
      "Quantong Qiu",
      "Juntao Li",
      "Qingrong Xia",
      "Ping Li",
      "Xinyu Duan",
      "Zhefeng Wang",
      "Min Zhang"
    ],
    "abstract": "The impressive capabilities of Large Language Models (LLMs) come at the cost\nof substantial computational resources during deployment. While KV Cache can\nsignificantly reduce recomputation during inference, it also introduces\nadditional memory overhead. KV Cache quantization presents a promising\nsolution, striking a good balance between memory usage and accuracy. Previous\nresearch has shown that the Keys are distributed by channel, while the Values\nare distributed by token. Consequently, the common practice is to apply\nchannel-wise quantization to the Keys and token-wise quantization to the\nValues. However, our further investigation reveals that a small subset of\nunusual tokens exhibit unique characteristics that deviate from this pattern,\nwhich can substantially impact quantization accuracy. To address this, we\ndevelop a simple yet effective method to identify these tokens accurately\nduring the decoding process and exclude them from quantization as outlier\ntokens, significantly improving overall accuracy. Extensive experiments show\nthat our method achieves significant accuracy improvements under 2-bit\nquantization and can deliver a 6.4 times reduction in memory usage and a 2.3\ntimes increase in throughput.",
    "pdf_url": "http://arxiv.org/pdf/2505.10938v1",
    "published": "2025-05-16T07:23:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.13502v1",
    "title": "Federated Low-Rank Adaptation for Foundation Models: A Survey",
    "authors": [
      "Yiyuan Yang",
      "Guodong Long",
      "Qinghua Lu",
      "Liming Zhu",
      "Jing Jiang",
      "Chengqi Zhang"
    ],
    "abstract": "Effectively leveraging private datasets remains a significant challenge in\ndeveloping foundation models. Federated Learning (FL) has recently emerged as a\ncollaborative framework that enables multiple users to fine-tune these models\nwhile mitigating data privacy risks. Meanwhile, Low-Rank Adaptation (LoRA)\noffers a resource-efficient alternative for fine-tuning foundation models by\ndramatically reducing the number of trainable parameters. This survey examines\nhow LoRA has been integrated into federated fine-tuning for foundation models,\nan area we term FedLoRA, by focusing on three key challenges: distributed\nlearning, heterogeneity, and efficiency. We further categorize existing work\nbased on the specific methods used to address each challenge. Finally, we\ndiscuss open research questions and highlight promising directions for future\ninvestigation, outlining the next steps for advancing FedLoRA.",
    "pdf_url": "http://arxiv.org/pdf/2505.13502v1",
    "published": "2025-05-16T07:19:51+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10937v1",
    "title": "Reasoning with OmniThought: A Large CoT Dataset with Verbosity and Cognitive Difficulty Annotations",
    "authors": [
      "Wenrui Cai",
      "Chengyu Wang",
      "Junbing Yan",
      "Jun Huang",
      "Xiangzhong Fang"
    ],
    "abstract": "The emergence of large reasoning models (LRMs) has transformed Natural\nLanguage Processing by excelling in complex tasks such as mathematical\nproblem-solving and code generation. These models leverage chain-of-thought\n(CoT) processes, enabling them to emulate human-like reasoning strategies.\nHowever, the advancement of LRMs is hindered by the lack of comprehensive CoT\ndatasets. Current resources often fail to provide extensive reasoning problems\nwith coherent CoT processes distilled from multiple teacher models and do not\naccount for multifaceted properties describing the internal characteristics of\nCoTs. To address these challenges, we introduce OmniThought, a large-scale\ndataset featuring 2 million CoT processes generated and validated by two\npowerful LRMs as teacher models. Each CoT process in OmniThought is annotated\nwith novel Reasoning Verbosity (RV) and Cognitive Difficulty (CD) scores, which\ndescribe the appropriateness of CoT verbosity and cognitive difficulty level\nfor models to comprehend these reasoning processes. We further establish a\nself-reliant pipeline to curate this dataset. Extensive experiments using\nQwen2.5 models of various sizes demonstrate the positive impact of our proposed\nscores on LRM training effectiveness. Based on the proposed OmniThought\ndataset, we further train and release a series of high-performing LRMs,\nspecifically equipped with stronger reasoning abilities and optimal CoT output\nlength and difficulty level. Our contributions significantly enhance the\ndevelopment and training of LRMs for solving complex tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.10937v1",
    "published": "2025-05-16T07:15:30+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10936v1",
    "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents",
    "authors": [
      "Jiaxing Zhao",
      "Hongbin Xie",
      "Yuzhen Lei",
      "Xuan Song",
      "Zhuoran Shi",
      "Lianxin Li",
      "Shuangxue Liu",
      "Haoran Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in\nexecuting complex reasoning tasks. Chain-of-thought effectively enhances\nreasoning capabilities by unlocking the potential of large models, while\nmulti-agent systems provide more comprehensive solutions by integrating\ncollective intelligence of multiple agents. However, both approaches face\nsignificant limitations. Single-agent with chain-of-thought, due to the\ninherent complexity of designing cross-domain prompts, faces collaboration\nchallenges. Meanwhile, multi-agent systems consume substantial tokens and\ninevitably dilute the primary problem, which is particularly problematic in\nbusiness workflow tasks. To address these challenges, we propose Cochain, a\ncollaboration prompting framework that effectively solves business workflow\ncollaboration problem by combining knowledge and prompts at a reduced cost.\nSpecifically, we construct an integrated knowledge graph that incorporates\nknowledge from multiple stages. Furthermore, by maintaining and retrieving a\nprompts tree, we can obtain prompt information relevant to other stages of the\nbusiness workflow. We perform extensive evaluations of Cochain across multiple\ndatasets, demonstrating that Cochain outperforms all baselines in both prompt\nengineering and multi-agent LLMs. Additionally, expert evaluation results\nindicate that the use of a small model in combination with Cochain outperforms\nGPT-4.",
    "pdf_url": "http://arxiv.org/pdf/2505.10936v1",
    "published": "2025-05-16T07:14:42+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.15832v1",
    "title": "From Hand-Crafted Metrics to Evolved Training-Free Performance Predictors for Neural Architecture Search via Genetic Programming",
    "authors": [
      "Quan Minh Phan",
      "Ngoc Hoang Luong"
    ],
    "abstract": "Estimating the network performance using zero-cost (ZC) metrics has proven\nboth its efficiency and efficacy in Neural Architecture Search (NAS). However,\na notable limitation of most ZC proxies is their inconsistency, as reflected by\nthe substantial variation in their performance across different problems.\nFurthermore, the design of existing ZC metrics is manual, involving a\ntime-consuming trial-and-error process that requires substantial domain\nexpertise. These challenges raise two critical questions: (1) Can we automate\nthe design of ZC metrics? and (2) Can we utilize the existing hand-crafted ZC\nmetrics to synthesize a more generalizable one? In this study, we propose a\nframework based on Symbolic Regression via Genetic Programming to automate the\ndesign of ZC metrics. Our framework is not only highly extensible but also\ncapable of quickly producing a ZC metric with a strong positive rank\ncorrelation to true network performance across diverse NAS search spaces and\ntasks. Extensive experiments on 13 problems from NAS-Bench-Suite-Zero\ndemonstrate that our automatically generated proxies consistently outperform\nhand-crafted alternatives. Using our evolved proxy metric as the search\nobjective in an evolutionary algorithm, we could identify network architectures\nwith competitive performance within 15 minutes using a single consumer GPU.",
    "pdf_url": "http://arxiv.org/pdf/2505.15832v1",
    "published": "2025-05-16T07:12:42+00:00",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.10935v2",
    "title": "Boundary Stabilization of Quasilinear Parabolic PDEs that Blow Up in Open Loop for Arbitrarily Small Initial Conditions",
    "authors": [
      "M C Belhadjoudja",
      "M Maghenem",
      "E Witrant",
      "M Krstic"
    ],
    "abstract": "We propose a novel framework for stabilization, with an estimate of the\nregion of attraction, of quasilinear parabolic partial differential equations\n(PDEs) that exhibit finite-time blow-up phenomena when null boundary inputs are\nimposed. Using Neumann-type boundary controllers, which are cubic polynomials\nin boundary measurements, we ensure L2 exponential stability of the origin with\nan estimate of the region of attraction, boundedness and exponential decay\ntowards zero of the state's max norm, well-posedness, as well as positivity of\nsolutions starting from positive initial conditions. Unlike existing methods,\nour approach handles nonlinear state-dependent diffusion, convection, and\nreaction terms. In many cases, our estimate of the size of the region of\nattraction is shown to expand unboundedly as diffusion increases. Our\ncontrollers can be implemented as Neumann, Dirichlet, or mixed-type boundary\nconditions. Numerical simulations validate the effectiveness of our approach in\npreventing finite-time blow up.",
    "pdf_url": "http://arxiv.org/pdf/2505.10935v2",
    "published": "2025-05-16T07:11:55+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10934v1",
    "title": "Black hole thermodynamics probes the equivalence principle",
    "authors": [
      "Ana Alonso-Serrano",
      "Luis J. Garay",
      "Marek Liška"
    ],
    "abstract": "The equivalence principle for test gravitational physics strongly constrains\ndynamics of spacetime, providing a powerful criterion for selecting candidate\ntheories of gravity. However, checking its validity for a particular theory is\noften a very difficult task. We devise here a simple theoretical criterion for\nidentifying equivalence principle violations in black hole thermodynamics.\nEmploying this criterion, we prove that Lanczos-Lovelock gravity violates the\nstrong equivalence principle, leaving general relativity as the only local,\ndiffeomorphism-invariant theory compatible with it. However, we also show that\ncertain nonlocal expressions for black hole entropy appear to obey the strong\nequivalence principle.",
    "pdf_url": "http://arxiv.org/pdf/2505.10934v1",
    "published": "2025-05-16T07:11:38+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.10933v2",
    "title": "Cross-layer Integrated Sensing and Communication: A Joint Industrial and Academic Perspective",
    "authors": [
      "Henk Wymeersch",
      "Nuutti Tervo",
      "Stefan Wänstedt",
      "Sharief Saleh",
      "Joerg Ahlendorf",
      "Ozgur Akgul",
      "Vasileios Tsekenis",
      "Sokratis Barmpounakis",
      "Liping Bai",
      "Martin Beale",
      "Rafael Berkvens",
      "Nabeel Nisar Bhat",
      "Hui Chen",
      "Shrayan Das",
      "Claude Desset",
      "Antonio de la Oliva",
      "Prajnamaya Dass",
      "Jeroen Famaey",
      "Hamed Farhadi",
      "Gerhard P. Fettweis",
      "Yu Ge",
      "Hao Guo",
      "Rreze Halili",
      "Katsuyuki Haneda",
      "Abdur Rahman Mohamed Ismail",
      "Akshay Jain",
      "Sylvaine Kerboeuf",
      "Musa Furkan Keskin",
      "Emad Ibrahim",
      "Bilal Khan",
      "Siddhartha Kumar",
      "Stefan Köpsell",
      "Apostolos Kousaridas",
      "Pekka Kyösti",
      "Simon Lindberg",
      "Mohammad Hossein Moghaddam",
      "Ahmad Nimr",
      "Victor Pettersson",
      "Aarno Pärssinen",
      "Basuki Priyanto",
      "Athanasios Stavridis",
      "Tommy Svensson",
      "Sonika Ujjwal"
    ],
    "abstract": "Integrated sensing and communication (ISAC) enables radio systems to\nsimultaneously sense and communicate with their environment. This paper,\ndeveloped within the Hexa-X-II project funded by the European Union, presents a\ncomprehensive cross-layer vision for ISAC in 6G networks, integrating insights\nfrom physical-layer design, hardware architectures, AI-driven intelligence, and\nprotocol-level innovations. We begin by revisiting the foundational principles\nof ISAC, highlighting synergies and trade-offs between sensing and\ncommunication across different integration levels. Enabling technologies (such\nas multiband operation, massive and distributed MIMO, non-terrestrial networks,\nreconfigurable intelligent surfaces, and machine learning) are analyzed in\nconjunction with hardware considerations including waveform design,\nsynchronization, and full-duplex operation. To bridge implementation and\nsystem-level evaluation, we introduce a quantitative cross-layer framework\nlinking design parameters to key performance and value indicators. By\nsynthesizing perspectives from both academia and industry, this paper outlines\nhow deeply integrated ISAC can transform 6G into a programmable and\ncontext-aware platform supporting applications from reliable wireless access to\nautonomous mobility and digital twinning.",
    "pdf_url": "http://arxiv.org/pdf/2505.10933v2",
    "published": "2025-05-16T07:11:11+00:00",
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10932v1",
    "title": "Enhanced Multiuser CSI-Based Physical Layer Authentication Based on Information Reconciliation",
    "authors": [
      "Atsu Kokuvi Angélo Passah",
      "Arsenia Chorti",
      "Rodrigo C. de Lamare"
    ],
    "abstract": "This paper presents a physical layer authentication (PLA) technique using\ninformation reconciliation in multiuser communication systems. A cost-effective\nsolution for low-end Internet of Things networks can be provided by PLA. In\nthis work, we develop an information reconciliation scheme using Polar codes\nalong with a quantization strategy that employs an arbitrary number of bits to\nenhance the performance of PLA. We employ the principle of Slepian-Wolf coding\nto reconcile channel measurements spread in time. Numerical results show that\nour approach works very well and outperforms competing approaches, achieving\nmore than 99.80% increase in detection probability for false alarm\nprobabilities close to 0.",
    "pdf_url": "http://arxiv.org/pdf/2505.10932v1",
    "published": "2025-05-16T07:11:04+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10931v1",
    "title": "M4-SAR: A Multi-Resolution, Multi-Polarization, Multi-Scene, Multi-Source Dataset and Benchmark for Optical-SAR Fusion Object Detection",
    "authors": [
      "Chao Wang",
      "Wei Lu",
      "Xiang Li",
      "Jian Yang",
      "Lei Luo"
    ],
    "abstract": "Single-source remote sensing object detection using optical or SAR images\nstruggles in complex environments. Optical images offer rich textural details\nbut are often affected by low-light, cloud-obscured, or low-resolution\nconditions, reducing the detection performance. SAR images are robust to\nweather, but suffer from speckle noise and limited semantic expressiveness.\nOptical and SAR images provide complementary advantages, and fusing them can\nsignificantly improve the detection accuracy. However, progress in this field\nis hindered by the lack of large-scale, standardized datasets. To address these\nchallenges, we propose the first comprehensive dataset for optical-SAR fusion\nobject detection, named Multi-resolution, Multi-polarization, Multi-scene,\nMulti-source SAR dataset (M4-SAR). It contains 112,184 precisely aligned image\npairs and nearly one million labeled instances with arbitrary orientations,\nspanning six key categories. To enable standardized evaluation, we develop a\nunified benchmarking toolkit that integrates six state-of-the-art multi-source\nfusion methods. Furthermore, we propose E2E-OSDet, a novel end-to-end\nmulti-source fusion detection framework that mitigates cross-domain\ndiscrepancies and establishes a robust baseline for future studies. Extensive\nexperiments on M4-SAR demonstrate that fusing optical and SAR data can improve\n$mAP$ by 5.7\\% over single-source inputs, with particularly significant gains\nin complex environments. The dataset and code are publicly available at\nhttps://github.com/wchao0601/M4-SAR.",
    "pdf_url": "http://arxiv.org/pdf/2505.10931v1",
    "published": "2025-05-16T07:10:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10930v2",
    "title": "Physics-informed Temporal Alignment for Auto-regressive PDE Foundation Models",
    "authors": [
      "Congcong Zhu",
      "Xiaoyan Xu",
      "Jiayue Han",
      "Jingrun Chen"
    ],
    "abstract": "Auto-regressive partial differential equation (PDE) foundation models have\nshown great potential in handling time-dependent data. However, these models\nsuffer from the shortcut problem deeply rooted in auto-regressive prediction,\ncausing error accumulation. The challenge becomes particularly evident for\nout-of-distribution data, as the pretraining performance may approach random\nmodel initialization for downstream tasks with long-term dynamics. To deal with\nthis problem, we propose physics-informed temporal alignment (PITA), a\nself-supervised learning framework inspired by inverse problem solving.\nSpecifically, PITA aligns the physical dynamics discovered at different time\nsteps on each given PDE trajectory by integrating physics-informed constraints\ninto the self-supervision signal. The alignment is derived from observation\ndata without relying on known physics priors, indicating strong generalization\nability to the out-of-distribution data. Extensive experiments show that PITA\nsignificantly enhances the accuracy and robustness of existing foundation\nmodels on diverse time-dependent PDE data. The code is available at\nhttps://github.com/SCAILab-USTC/PITA.",
    "pdf_url": "http://arxiv.org/pdf/2505.10930v2",
    "published": "2025-05-16T07:08:47+00:00",
    "categories": [
      "cs.LG",
      "35Q68",
      "G.1.8"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10929v1",
    "title": "Minimal dispersion on the sphere",
    "authors": [
      "Alexander E. Litvak",
      "Mathias Sonnleitner",
      "Tomasz Szczepanski"
    ],
    "abstract": "The minimal spherical cap dispersion ${\\rm disp}_{\\mathcal{C}}(n,d)$ is the\nlargest number $\\varepsilon\\in (0,1]$ such that, no matter how $n$ points are\ndistributed on the $d$-dimensional Euclidean unit sphere $\\mathbb{S}^d$, there\nis always a spherical cap with normalized area $\\varepsilon$ not containing any\nof the points. We study the behavior of ${\\rm disp}_{\\mathcal{C}}(n,d)$ as $n$\nand $d$ grow to infinity. We develop connections to the problems of sphere\ncovering and approximation of the Euclidean unit ball by inscribed polytopes.\nExisting and new results are presented in a unified way. Upper bounds on ${\\rm\ndisp}_{\\mathcal{C}}(n,d)$ result from choosing the points independently and\nuniformly at random and possibly adding some well-separated points to close\nlarge gaps. Moreover, we study dispersion with respect to intersections of\ncaps.",
    "pdf_url": "http://arxiv.org/pdf/2505.10929v1",
    "published": "2025-05-16T07:07:56+00:00",
    "categories": [
      "math.MG",
      "cs.NA",
      "math.NA",
      "52B55, 52C17 (Primary) 52A23, 52C45 (Secondary)"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2505.11563v1",
    "title": "Object-Centric Representations Improve Policy Generalization in Robot Manipulation",
    "authors": [
      "Alexandre Chapin",
      "Bruno Machado",
      "Emmanuel Dellandrea",
      "Liming Chen"
    ],
    "abstract": "Visual representations are central to the learning and generalization\ncapabilities of robotic manipulation policies. While existing methods rely on\nglobal or dense features, such representations often entangle task-relevant and\nirrelevant scene information, limiting robustness under distribution shifts. In\nthis work, we investigate object-centric representations (OCR) as a structured\nalternative that segments visual input into a finished set of entities,\nintroducing inductive biases that align more naturally with manipulation tasks.\nWe benchmark a range of visual encoders-object-centric, global and dense\nmethods-across a suite of simulated and real-world manipulation tasks ranging\nfrom simple to complex, and evaluate their generalization under diverse visual\nconditions including changes in lighting, texture, and the presence of\ndistractors. Our findings reveal that OCR-based policies outperform dense and\nglobal representations in generalization settings, even without task-specific\npretraining. These insights suggest that OCR is a promising direction for\ndesigning visual systems that generalize effectively in dynamic, real-world\nrobotic environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.11563v1",
    "published": "2025-05-16T07:06:37+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10928v1",
    "title": "A Dataset for Spatiotemporal-Sensitive POI Question Answering",
    "authors": [
      "Xiao Han",
      "Dayan Pan",
      "Xiangyu Zhao",
      "Xuyuan Hu",
      "Zhaolin Deng",
      "Xiangjie Kong",
      "Guojiang Shen"
    ],
    "abstract": "Spatiotemporal relationships are critical in data science, as many prediction\nand reasoning tasks require analysis across both spatial and temporal\ndimensions--for instance, navigating an unfamiliar city involves planning\nitineraries that sequence locations and timing cultural experiences. However,\nexisting Question-Answering (QA) datasets lack sufficient\nspatiotemporal-sensitive questions, making them inadequate benchmarks for\nevaluating models' spatiotemporal reasoning capabilities. To address this gap,\nwe introduce POI-QA, a novel spatiotemporal-sensitive QA dataset centered on\nPoint of Interest (POI), constructed through three key steps: mining and\naligning open-source vehicle trajectory data from GAIA with high-precision\ngeographic POI data, rigorous manual validation of noisy spatiotemporal facts,\nand generating bilingual (Chinese/English) QA pairs that reflect\nhuman-understandable spatiotemporal reasoning tasks. Our dataset challenges\nmodels to parse complex spatiotemporal dependencies, and evaluations of\nstate-of-the-art multilingual LLMs (e.g., Qwen2.5-7B, Llama3.1-8B) reveal stark\nlimitations: even the top-performing model (Qwen2.5-7B fine-tuned with\nRAG+LoRA) achieves a top 10 Hit Ratio (HR@10) of only 0.41 on the easiest task,\nfar below human performance at 0.56. This underscores persistent weaknesses in\nLLMs' ability to perform consistent spatiotemporal reasoning, while\nhighlighting POI-QA as a robust benchmark to advance algorithms sensitive to\nspatiotemporal dynamics. The dataset is publicly available at\nhttps://www.kaggle.com/ds/7394666.",
    "pdf_url": "http://arxiv.org/pdf/2505.10928v1",
    "published": "2025-05-16T07:05:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10927v1",
    "title": "Towards an open geotechnical data platform in France",
    "authors": [
      "Isabelle Halfon",
      "Mickaël Beaufils"
    ],
    "abstract": "An important quantity of geotechnical data is constantly collected for all\nthe new projects of civil engineering. This data includes generally core and\ndestructive boreholes, in which samples are taken for laboratory testing and in\nsitu geotechnical tests are performed. The density of geotechnical data is\nparticularly high in urban areas. The data is collected by geotechnical\nengineering or drilling Companies for public or private owners. Data is\nessential to define the geotechnical conditions of a project and are obviously\nnecessary for the geotechnical design of foundations or underground structures.\nHowever, most of the time, data is not accessible in a numerical format, and at\nthe end of the project, is often forgotten, while it could be reused for\nneighbouring projects. It is a great loss of information and knowledge to the\ntechnical and scientific geosciences community, and it represents a significant\ncost for the country economy. In France, the BRGM (French geological survey\noffice) is currently developing a new open access platform dedicated to the\ncapitalization and accessibility of geotechnical data, compliant with the FAIR\nprinciples (Findable, Accessible, Interoperable and Reusable). This paper\ndescribes the challenges to overcome and the possible solutions, considering\nthe high diversity of geotechnical tests, explains the need of keeping the\nexhaustive data set for each test, and describes the next stages of\ndevelopment.",
    "pdf_url": "http://arxiv.org/pdf/2505.10927v1",
    "published": "2025-05-16T07:01:44+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.10926v2",
    "title": "Graviton-photon conversion in stochastic magnetic fields",
    "authors": [
      "Wataru Chiba",
      "Ryusuke Jinno",
      "Kimihiro Nomura"
    ],
    "abstract": "We study graviton-photon conversion in the presence of stochastic magnetic\nfields. Assuming Gaussian magnetic fields that may possess nontrivial helicity,\nand unpolarized gravitational waves (GWs) as the initial state, we obtain\nexpressions for the intensity and linear/circular polarizations of GWs after\npropagation over a finite distance. We calculate both the expectation values\nand variances of these observables, and find their nontrivial dependence on the\ntypical correlation length of the magnetic field, the propagation distance, and\nthe photon plasma mass. Our analysis reveals that an observationally favorable\nfrequency range with narrower variance can emerge for the intensity, while a\npeak structure appears in the expectation value of the circular polarization\nwhen the magnetic field has nonzero helicity. We also identify a consistency\nrelation between the GW intensity and circular polarization.",
    "pdf_url": "http://arxiv.org/pdf/2505.10926v2",
    "published": "2025-05-16T07:01:22+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "hep-ph"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.10925v1",
    "title": "Enforced Interface Constraints for Domain Decomposition Method of Discrete Physics-Informed Neural Networks",
    "authors": [
      "Jichao Yin",
      "Mingxuan Li",
      "Jianguang Fang",
      "Hu Wang"
    ],
    "abstract": "This study presents a discrete physics-informed neural network (dPINN)\nframework, enhanced with enforced interface constraints (EIC), for modeling\nphysical systems using the domain decomposition method (DDM). Built upon finite\nelement-style mesh discretization, the dPINN accurately evaluates system energy\nthrough Gaussian quadrature-based element-wise integration. To ensure physical\nfield continuity across subdomain interfaces, the EIC mechanism enforces\ninterfacial displacement constraints without requiring auxiliary sampling or\nloss penalties.This formulation supports independent meshing in each subdomain,\nsimplifying preprocessing and improving computational flexibility.\nAdditionally, by eliminating the influence of weak spatial constraints (WSC)\ncommonly observed in traditional PINNs, the EIC-dPINN delivers more stable and\nphysically consistent predictions.Extensive two- and three-dimensional\nnumerical experiments validate the proposed framework's accuracy and\ndemonstrate the computational efficiency gains achieved through parallel\ntraining. The results highlight the framework's scalability, robustness, and\npotential for solving large-scale, geometrically complex problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.10925v1",
    "published": "2025-05-16T06:59:48+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.10924v3",
    "title": "A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?",
    "authors": [
      "Ada Chen",
      "Yongjiang Wu",
      "Junyuan Zhang",
      "Jingyu Xiao",
      "Shu Yang",
      "Jen-tse Huang",
      "Kun Wang",
      "Wenxuan Wang",
      "Shuai Wang"
    ],
    "abstract": "Recently, AI-driven interactions with computing devices have advanced from\nbasic prototype tools to sophisticated, LLM-based systems that emulate\nhuman-like operations in graphical user interfaces. We are now witnessing the\nemergence of \\emph{Computer-Using Agents} (CUAs), capable of autonomously\nperforming tasks such as navigating desktop applications, web pages, and mobile\napps. However, as these agents grow in capability, they also introduce novel\nsafety and security risks. Vulnerabilities in LLM-driven reasoning, with the\nadded complexity of integrating multiple software components and multimodal\ninputs, further complicate the security landscape. In this paper, we present a\nsystematization of knowledge on the safety and security threats of CUAs. We\nconduct a comprehensive literature review and distill our findings along four\nresearch objectives: \\textit{\\textbf{(i)}} define the CUA that suits safety\nanalysis; \\textit{\\textbf{(ii)} } categorize current safety threats among CUAs;\n\\textit{\\textbf{(iii)}} propose a comprehensive taxonomy of existing defensive\nstrategies; \\textit{\\textbf{(iv)}} summarize prevailing benchmarks, datasets,\nand evaluation metrics used to assess the safety and performance of CUAs.\nBuilding on these insights, our work provides future researchers with a\nstructured foundation for exploring unexplored vulnerabilities and offers\npractitioners actionable guidance in designing and deploying secure\nComputer-Using Agents.",
    "pdf_url": "http://arxiv.org/pdf/2505.10924v3",
    "published": "2025-05-16T06:56:42+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.CV",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10923v2",
    "title": "GrowSplat: Constructing Temporal Digital Twins of Plants with Gaussian Splats",
    "authors": [
      "Simeon Adebola",
      "Shuangyu Xie",
      "Chung Min Kim",
      "Justin Kerr",
      "Bart M. van Marrewijk",
      "Mieke van Vlaardingen",
      "Tim van Daalen",
      "E. N. van Loo",
      "Jose Luis Susa Rincon",
      "Eugen Solowjow",
      "Rick van de Zedde",
      "Ken Goldberg"
    ],
    "abstract": "Accurate temporal reconstructions of plant growth are essential for plant\nphenotyping and breeding, yet remain challenging due to complex geometries,\nocclusions, and non-rigid deformations of plants. We present a novel framework\nfor building temporal digital twins of plants by combining 3D Gaussian\nSplatting with a robust sample alignment pipeline. Our method begins by\nreconstructing Gaussian Splats from multi-view camera data, then leverages a\ntwo-stage registration approach: coarse alignment through feature-based\nmatching and Fast Global Registration, followed by fine alignment with\nIterative Closest Point. This pipeline yields a consistent 4D model of plant\ndevelopment in discrete time steps. We evaluate the approach on data from the\nNetherlands Plant Eco-phenotyping Center, demonstrating detailed temporal\nreconstructions of Sequoia and Quinoa species. Videos and Images can be seen at\nhttps://berkeleyautomation.github.io/GrowSplat/",
    "pdf_url": "http://arxiv.org/pdf/2505.10923v2",
    "published": "2025-05-16T06:56:15+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10922v1",
    "title": "Vaiage: A Multi-Agent Solution to Personalized Travel Planning",
    "authors": [
      "Binwen Liu",
      "Jiexi Ge",
      "Jiamin Wang"
    ],
    "abstract": "Planning trips is a cognitively intensive task involving conflicting user\npreferences, dynamic external information, and multi-step temporal-spatial\noptimization. Traditional platforms often fall short - they provide static\nresults, lack contextual adaptation, and fail to support real-time interaction\nor intent refinement.\n  Our approach, Vaiage, addresses these challenges through a graph-structured\nmulti-agent framework built around large language models (LLMs) that serve as\nboth goal-conditioned recommenders and sequential planners. LLMs infer user\nintent, suggest personalized destinations and activities, and synthesize\nitineraries that align with contextual constraints such as budget, timing,\ngroup size, and weather. Through natural language interaction, structured tool\nuse, and map-based feedback loops, Vaiage enables adaptive, explainable, and\nend-to-end travel planning grounded in both symbolic reasoning and\nconversational understanding.\n  To evaluate Vaiage, we conducted human-in-the-loop experiments using\nrubric-based GPT-4 assessments and qualitative feedback. The full system\nachieved an average score of 8.5 out of 10, outperforming the no-strategy (7.2)\nand no-external-API (6.8) variants, particularly in feasibility. Qualitative\nanalysis indicated that agent coordination - especially the Strategy and\nInformation Agents - significantly improved itinerary quality by optimizing\ntime use and integrating real-time context. These results demonstrate the\neffectiveness of combining LLM reasoning with symbolic agent coordination in\nopen-ended, real-world planning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.10922v1",
    "published": "2025-05-16T06:54:52+00:00",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11562v1",
    "title": "GIGAPYX sensor performance in space environments",
    "authors": [
      "Julien Michelot",
      "Maurin Douix",
      "Jean-Baptiste Mancini",
      "Marie Guillon",
      "Kevin Melendez",
      "Clément Ravinet",
      "Mikael Jouans",
      "Guy Estaves",
      "Ronan Marec",
      "Stéphane Demiguel",
      "Alex Materne",
      "Cédric Virmontois"
    ],
    "abstract": "We present the results of the GIGAPYX-4600 image sensor in space environment,\nmore specifically under different types of irradiations (protons and heavy\nions). The GIGAPYX-4600 is a state-of-the-art 46M pixel multi-purpose, backside\nilluminated CMOS image sensor. The sensor features high-speed (200 fps),\nlow-noise (< 2e-rms), rolling shutter readout. It has been fabricated using 65\nnm node CMOS technology, making use of capacitive deep trench isolation, thus\nexhibiting good MTF as well as excellent dark current characteristics. The\nGIGAPYX image sensor family is meant to be easily scalable thanks to a novel\nuse of stitching technology. The assessed sensor features an impressive 46\nMpixels, but the sensor family is meant to be scaled up to 220 M pixels. The\nidea of this study was to investigate the radiation hardness of a commercially\navailable off-the-shelf (COTS) image sensor that could be suitable for\nspace-borne applications, such as earth observation or satellite vicinity\nsurveillance. In the near future a radiation hard readout electronic for this\nsensor family will be made available off-the-shelf by Pyxalis. This\npresentation will overview the different sensor key performances evolutions\nafter proton irradiation up to a total fluence of 2.3e11 p+/cm${}^2$ (62 MeV):\ndark current, dark current non-uniformity (DCNU), noise, non-linearity,\nsaturation charge and photo-response non-uniformity (PRNU). As expected,\ndegradations mostly occur on the dark current, DCNU and temporal noise. The\norders of magnitude of the degradation are in the range of the already\npublished high performance CIS technologies. Results obtained from heavy ions\nirradiations will demonstrate that the GIGAPYX is not only latch-up free at\nleast up to 57 Mev.cm2/mg, but resistant to the blooming effects induced by a\nSET at pixel level thanks to its capacitive deep trench isolations. Various SEE\neffects have been studied, demonstrating encouraging results for such COTS\ndevice in order to fly, in particular in GEO orbit. All these radiations\nresults will be used as inputs in designing space camera based on the GIGAPYX\nsensors, compatible with multiple-mission types.",
    "pdf_url": "http://arxiv.org/pdf/2505.11562v1",
    "published": "2025-05-16T06:54:20+00:00",
    "categories": [
      "astro-ph.IM",
      "physics.ins-det"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2505.10921v2",
    "title": "Towards Cross-modal Retrieval in Chinese Cultural Heritage Documents: Dataset and Solution",
    "authors": [
      "Junyi Yuan",
      "Jian Zhang",
      "Fangyu Wu",
      "Dongming Lu",
      "Huanda Lu",
      "Qiufeng Wang"
    ],
    "abstract": "China has a long and rich history, encompassing a vast cultural heritage that\nincludes diverse multimodal information, such as silk patterns, Dunhuang\nmurals, and their associated historical narratives. Cross-modal retrieval plays\na pivotal role in understanding and interpreting Chinese cultural heritage by\nbridging visual and textual modalities to enable accurate text-to-image and\nimage-to-text retrieval. However, despite the growing interest in multimodal\nresearch, there is a lack of specialized datasets dedicated to Chinese cultural\nheritage, limiting the development and evaluation of cross-modal learning\nmodels in this domain. To address this gap, we propose a multimodal dataset\nnamed CulTi, which contains 5,726 image-text pairs extracted from two series of\nprofessional documents, respectively related to ancient Chinese silk and\nDunhuang murals. Compared to existing general-domain multimodal datasets, CulTi\npresents a challenge for cross-modal retrieval: the difficulty of local\nalignment between intricate decorative motifs and specialized textual\ndescriptions. To address this challenge, we propose LACLIP, a training-free\nlocal alignment strategy built upon a fine-tuned Chinese-CLIP. LACLIP enhances\nthe alignment of global textual descriptions with local visual regions by\ncomputing weighted similarity scores during inference. Experimental results on\nCulTi demonstrate that LACLIP significantly outperforms existing models in\ncross-modal retrieval, particularly in handling fine-grained semantic\nassociations within Chinese cultural heritage.",
    "pdf_url": "http://arxiv.org/pdf/2505.10921v2",
    "published": "2025-05-16T06:52:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10920v1",
    "title": "Total acyclicity of complexes over group algebras",
    "authors": [
      "Ioannis Emmanouil",
      "Olympia Talelli"
    ],
    "abstract": "In this paper, we study group algebras over which modules have a controlled\nbehaviour with respect to the notions of Gorenstein homological algebra,\nnamely: (a) Gorenstein projective modules are Gorenstein flat, (b) any module\nwhose dual is Gorenstein injective is necessarily Gorentein flat, (c) the\nGorenstein projective cotorsion pair is complete and (d) any acyclic complex of\nprojective, injective or flat modules is totally acyclic (in the respective\nsense). We consider a certain class of groups satisfying all of these\nproperties and show that it is closed under the operation LH defined by\nKropholler and the operation {\\Phi} defined by the second author. We thus\ngeneralize all previously known results regarding these properties over group\nalgebras and place these results in an appropriate framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.10920v1",
    "published": "2025-05-16T06:47:40+00:00",
    "categories": [
      "math.RT",
      "math.GR",
      "math.KT"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.10919v1",
    "title": "A Physics-Informed Convolutional Long Short Term Memory Statistical Model for Fluid Thermodynamics Simulations",
    "authors": [
      "Luca Menicali",
      "Andrew Grace",
      "David H. Richter",
      "Stefano Castruccio"
    ],
    "abstract": "Fluid thermodynamics underpins atmospheric dynamics, climate science,\nindustrial applications, and energy systems. However, direct numerical\nsimulations (DNS) of such systems are computationally prohibitive. To address\nthis, we present a novel physics-informed spatio-temporal surrogate model for\nRayleigh-B\\'enard convection (RBC), a canonical example of convective fluid\nflow. Our approach combines convolutional neural networks for spatial feature\nextraction with an innovative recurrent architecture inspired by large language\nmodels, comprising a context builder and a sequence generator to capture\ntemporal dynamics. Inference is penalized with respect to the governing partial\ndifferential equations to ensure physical interpretability. Given the\nsensitivity of turbulent convection to initial conditions, we quantify\nuncertainty using a conformal prediction framework. This model replicates key\nfeatures of RBC dynamics while significantly reducing computational cost,\noffering a scalable alternative to DNS for long-term simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.10919v1",
    "published": "2025-05-16T06:47:00+00:00",
    "categories": [
      "physics.flu-dyn",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.10918v1",
    "title": "Unleashing Humanoid Reaching Potential via Real-world-Ready Skill Space",
    "authors": [
      "Zhikai Zhang",
      "Chao Chen",
      "Han Xue",
      "Jilong Wang",
      "Sikai Liang",
      "Yun Liu",
      "Zongzhang Zhang",
      "He Wang",
      "Li Yi"
    ],
    "abstract": "Humans possess a large reachable space in the 3D world, enabling interaction\nwith objects at varying heights and distances. However, realizing such\nlarge-space reaching on humanoids is a complex whole-body control problem and\nrequires the robot to master diverse skills simultaneously-including base\npositioning and reorientation, height and body posture adjustments, and\nend-effector pose control. Learning from scratch often leads to optimization\ndifficulty and poor sim2real transferability. To address this challenge, we\npropose Real-world-Ready Skill Space (R2S2). Our approach begins with a\ncarefully designed skill library consisting of real-world-ready primitive\nskills. We ensure optimal performance and robust sim2real transfer through\nindividual skill tuning and sim2real evaluation. These skills are then\nensembled into a unified latent space, serving as a structured prior that helps\ntask execution in an efficient and sim2real transferable manner. A high-level\nplanner, trained to sample skills from this space, enables the robot to\naccomplish real-world goal-reaching tasks. We demonstrate zero-shot sim2real\ntransfer and validate R2S2 in multiple challenging goal-reaching scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.10918v1",
    "published": "2025-05-16T06:44:47+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10917v2",
    "title": "VISTA: Enhancing Vision-Text Alignment in MLLMs via Cross-Modal Mutual Information Maximization",
    "authors": [
      "Mingxiao Li",
      "Na Su",
      "Fang Qu",
      "Zhizhou Zhong",
      "Ziyang Chen",
      "Yuan Li",
      "Zhaopeng Tu",
      "Xiaolong Li"
    ],
    "abstract": "Current multimodal large language models (MLLMs) face a critical challenge in\nmodality alignment, often exhibiting a bias towards textual information at the\nexpense of other modalities like vision. This paper conducts a systematic\ninformation-theoretic analysis of the widely used cross-entropy loss in MLLMs,\nuncovering its implicit alignment objective. Our theoretical investigation\nreveals that this implicit objective has inherent limitations, leading to a\ndegradation of cross-modal alignment as text sequence length increases, thereby\nhindering effective multimodal information fusion. To overcome these drawbacks,\nwe propose Vision-Text Alignment (VISTA), a novel approach guided by our\ntheoretical insights. VISTA introduces an explicit alignment objective designed\nto maximize cross-modal mutual information, preventing the degradation of\nvisual alignment. Notably, VISTA enhances the visual understanding capabilities\nof existing MLLMs without requiring any additional trainable modules or extra\ntraining data, making it both efficient and practical. Our method significantly\noutperforms baseline models across more than a dozen benchmark datasets,\nincluding VQAv2, MMStar, and MME, paving the way for new directions in MLLM\nmodal alignment research.",
    "pdf_url": "http://arxiv.org/pdf/2505.10917v2",
    "published": "2025-05-16T06:43:02+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10916v1",
    "title": "On the propagation of high regularity for the logarithmic Schr{ö}dinger equation",
    "authors": [
      "Quentin Chauleur",
      "Guillaume Ferriere"
    ],
    "abstract": "We investigate both the instantaneous loss and the persistence of high\nregularity for the one-dimensional logarithmic Schr{\\\"o}dinger equation in\nsymmetric domains under various boundary conditions. We show that for a broad\nclass of odd initial data, the $H^s$-norm of solutions exhibits instantaneous\nblow-up for all $s > 7/2 $. Conversely, we establish that $H^3$-regularity is\npreserved for solutions that are odd with first-order cancellation,\nnon-vanishing behavior away from the origin and Neumann boundary conditions on\nsymmetric bounded domains. These theoretical results are further supported and\nillustrated by numerical simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.10916v1",
    "published": "2025-05-16T06:42:45+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10915v3",
    "title": "Precision calculation of the EFT likelihood with primordial non-Gaussianities",
    "authors": [
      "Ji-Yuan Ke",
      "Yun Wang",
      "Ping He"
    ],
    "abstract": "We perform a precision calculation of the effective field theory (EFT)\nconditional likelihood for large-scale structure (LSS) using the saddle-point\nexpansion method in the presence of primordial non-Gaussianities (PNG). The\nprecision is manifested at two levels: one corresponding to the consideration\nof higher-order noise terms, and the other to the inclusion of contributions\naround the saddle points. In computing the latter, we encounter the same issue\nof the negative modes as in the context of false vacuum decay, which\nnecessitates deforming the original integration contour into a combination of\nthe steepest descent contours to ensure a convergent and real result. We\ndemonstrate through detailed calculations that, upon incorporating\nleading-order PNG, both types of extensions introduce irreducible\nfield-dependent contributions to the conditional likelihood. This insight\nmotivates the systematic inclusion of additional effective terms within the\nforward modeling framework. Our work facilitates Bayesian forward modeling\nunder non-Gaussian initial conditions, thereby enabling more stringent\nconstraints on the parameters describing PNG.",
    "pdf_url": "http://arxiv.org/pdf/2505.10915v3",
    "published": "2025-05-16T06:42:13+00:00",
    "categories": [
      "astro-ph.CO",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10914v1",
    "title": "Near field transmission using Hermite-Gaussian modes",
    "authors": [
      "Chenxi Zhu"
    ],
    "abstract": "RF transmission in line-of-sight near field based on Hermite-Gaussian (HG)\nmodes is developed. Multiple HG modes are transmitted and received using\nrectangular antenna arrays to form the basic modes and dimensions for MIMO\ntransmission. Beam steering can be achieved by manipulating the antenna arrays\nwith 3D rotation in the desired EM field. The beam parameters are optimized to\nminimize the size of the antennas. Simulation is performed for a 300GHz system\nwith free space channel model. Spectrum efficiency up to 294.3bps/Hz can be\nachieved with 36 HG modes and cross-polarization.",
    "pdf_url": "http://arxiv.org/pdf/2505.10914v1",
    "published": "2025-05-16T06:40:38+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10913v1",
    "title": "Automated Identification of Logical Errors in Programs: Advancing Scalable Analysis of Student Misconceptions",
    "authors": [
      "Muntasir Hoq",
      "Ananya Rao",
      "Reisha Jaishankar",
      "Krish Piryani",
      "Nithya Janapati",
      "Jessica Vandenberg",
      "Bradford Mott",
      "Narges Norouzi",
      "James Lester",
      "Bita Akram"
    ],
    "abstract": "In Computer Science (CS) education, understanding factors contributing to\nstudents' programming difficulties is crucial for effective learning support.\nBy identifying specific issues students face, educators can provide targeted\nassistance to help them overcome obstacles and improve learning outcomes. While\nidentifying sources of struggle, such as misconceptions, in real-time can be\nchallenging in current educational practices, analyzing logical errors in\nstudents' code can offer valuable insights. This paper presents a scalable\nframework for automatically detecting logical errors in students' programming\nsolutions. Our framework is based on an explainable Abstract Syntax Tree (AST)\nembedding model, the Subtree-based Attention Neural Network (SANN), that\nidentifies the structural components of programs containing logical errors. We\nconducted a series of experiments to evaluate its effectiveness, and the\nresults suggest that our framework can accurately capture students' logical\nerrors and, more importantly, provide us with deeper insights into their\nlearning processes, offering a valuable tool for enhancing programming\neducation.",
    "pdf_url": "http://arxiv.org/pdf/2505.10913v1",
    "published": "2025-05-16T06:32:51+00:00",
    "categories": [
      "cs.LG",
      "K.3.1"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10912v2",
    "title": "A sufficient condition for absence of mass quantization in a chemotaxis system with local sensing",
    "authors": [
      "Yuri Soga"
    ],
    "abstract": "We analyze blowup solutions in infinite time of the Neumann boundary value\nproblem for the fully parabolic chemotaxis system with local sensing:\n\\begin{equation*} \\begin{cases}\n  u_t = \\Delta(e^{-v}u)\\qquad &\\mathrm{in}\\ \\Omega \\times (0,\\infty),\n  v_t = \\Delta v -v + u\\qquad &\\mathrm{in}\\ \\Omega \\times (0,\\infty),\n\\end{cases} \\end{equation*} where $\\Omega$ is a ball in two-dimensional space\nand with nonnegative radially symmetric initial data. In the case of the\nKeller--Segel system which has a similar mathematical structure with our\nsystem, it was shown that the solutions blow up in finite time if and only if\n$L\\log L$ for the first component $u$ diverges in finite time. On the other\nhand, focusing on the variational structure induced by a signal-dependent\nmotility function $e^{-v}$, we show that an unboundedness of $\\int_\\Omega e^v\ndx$ for the second component $v$ gives rise to blowup solutions in infinite\ntime under the assumption of radial symmetry. Moreover we prove mass\nconcentration phenomena at the origin. It is shown that the radially symmetric\nsolutions of our system develop a singularity like a Dirac delta function in\ninfinite time. Here we investigate the weight of this singularity. Consequently\nit is shown that mass quantization may not occur; that is, the weight of the\nsingularity can exceed $8\\pi$ under the assumption of a uniform-in-time lower\nbound for the Lyapunov functional. This type of behavior cannot be observed in\nthe Keller--Segel system.",
    "pdf_url": "http://arxiv.org/pdf/2505.10912v2",
    "published": "2025-05-16T06:32:19+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10911v1",
    "title": "ReWiND: Language-Guided Rewards Teach Robot Policies without New Demonstrations",
    "authors": [
      "Jiahui Zhang",
      "Yusen Luo",
      "Abrar Anwar",
      "Sumedh Anand Sontakke",
      "Joseph J Lim",
      "Jesse Thomason",
      "Erdem Biyik",
      "Jesse Zhang"
    ],
    "abstract": "We introduce ReWiND, a framework for learning robot manipulation tasks solely\nfrom language instructions without per-task demonstrations. Standard\nreinforcement learning (RL) and imitation learning methods require expert\nsupervision through human-designed reward functions or demonstrations for every\nnew task. In contrast, ReWiND starts from a small demonstration dataset to\nlearn: (1) a data-efficient, language-conditioned reward function that labels\nthe dataset with rewards, and (2) a language-conditioned policy pre-trained\nwith offline RL using these rewards. Given an unseen task variation, ReWiND\nfine-tunes the pre-trained policy using the learned reward function, requiring\nminimal online interaction. We show that ReWiND's reward model generalizes\neffectively to unseen tasks, outperforming baselines by up to 2.4x in reward\ngeneralization and policy alignment metrics. Finally, we demonstrate that\nReWiND enables sample-efficient adaptation to new tasks, beating baselines by\n2x in simulation and improving real-world pretrained bimanual policies by 5x,\ntaking a step towards scalable, real-world robot learning. See website at\nhttps://rewind-reward.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2505.10911v1",
    "published": "2025-05-16T06:31:34+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10910v1",
    "title": "Cloudy mornings and clear evenings on a giant extrasolar world",
    "authors": [
      "Sagnick Mukherjee",
      "David K. Sing",
      "Guangwei Fu",
      "Kevin B. Stevenson",
      "Stephen P. Schmidt",
      "Harry Baskett",
      "Patrick McCreery",
      "Natalie H. Allen",
      "Katherine A. Bennett",
      "Duncan A. Christie",
      "Carlos Gascón",
      "Jayesh Goyal",
      "Éric Hébrard",
      "Joshua D. Lothringer",
      "Mercedes López-Morales",
      "Jacob Lustig-Yaeger",
      "Erin M. May",
      "L. C. Mayorga",
      "Nathan Mayne",
      "Lakeisha M. Ramos Rosado",
      "Henrique Reggiani",
      "Zafar Rustamkulov",
      "Kevin C. Schlaufman",
      "K. S. Sotzen",
      "Daniel Thorngren",
      "Le-Chris Wang",
      "Maria Zamyatina"
    ],
    "abstract": "Aerosols are common in exoplanet atmospheres, but their formation-whether\nthrough gas condensation or photochemical reactions-remains uncertain. We\nreport a 6$\\sigma$ detection of limb asymmetry in the transmission spectrum of\nWASP-94A b, revealing a cloud-covered (11$\\sigma$) cooler morning limb and a\nclear hotter evening limb with strong H$_2$O absorption (10$\\sigma$). Models\nsuggest cloud droplets formed near mbar pressures are lofted to 0.01 mbar by\nstrong vertical dynamics in the morning limb. They evaporate when circulated to\nthe hotter evening limb, requiring a minimum 280 K (3$\\sigma$) limb-to-limb\ntemperature difference. We confirm that aerosols in hot Jupiters like WASP-94A\nb can have clouds cycling between day and night sides instead of photochemical\nhazes. Ignoring these effects severely biases inferred chemical abundances,\nshowing limb-resolved spectroscopy is critical for characterizing the formation\nmechanisms of transiting exoplanets-from gas giants to terrestrial exoplanets,\nindicating the need to reassess inferences from a decade's worth of Hubble\nSpace Telescope observations.",
    "pdf_url": "http://arxiv.org/pdf/2505.10910v1",
    "published": "2025-05-16T06:31:00+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10909v1",
    "title": "Phi: Leveraging Pattern-based Hierarchical Sparsity for High-Efficiency Spiking Neural Networks",
    "authors": [
      "Chiyue Wei",
      "Bowen Duan",
      "Cong Guo",
      "Jingyang Zhang",
      "Qingyue Song",
      "Hai \"Helen\" Li",
      "Yiran Chen"
    ],
    "abstract": "Spiking Neural Networks (SNNs) are gaining attention for their energy\nefficiency and biological plausibility, utilizing 0-1 activation sparsity\nthrough spike-driven computation. While existing SNN accelerators exploit this\nsparsity to skip zero computations, they often overlook the unique distribution\npatterns inherent in binary activations. In this work, we observe that\nparticular patterns exist in spike activations, which we can utilize to reduce\nthe substantial computation of SNN models. Based on these findings, we propose\na novel \\textbf{pattern-based hierarchical sparsity} framework, termed\n\\textbf{\\textit{Phi}}, to optimize computation.\n  \\textit{Phi} introduces a two-level sparsity hierarchy: Level 1 exhibits\nvector-wise sparsity by representing activations with pre-defined patterns,\nallowing for offline pre-computation with weights and significantly reducing\nmost runtime computation. Level 2 features element-wise sparsity by\ncomplementing the Level 1 matrix, using a highly sparse matrix to further\nreduce computation while maintaining accuracy. We present an algorithm-hardware\nco-design approach. Algorithmically, we employ a k-means-based pattern\nselection method to identify representative patterns and introduce a\npattern-aware fine-tuning technique to enhance Level 2 sparsity.\nArchitecturally, we design \\textbf{\\textit{Phi}}, a dedicated hardware\narchitecture that efficiently processes the two levels of \\textit{Phi} sparsity\non the fly. Extensive experiments demonstrate that \\textit{Phi} achieves a\n$3.45\\times$ speedup and a $4.93\\times$ improvement in energy efficiency\ncompared to state-of-the-art SNN accelerators, showcasing the effectiveness of\nour framework in optimizing SNN computation.",
    "pdf_url": "http://arxiv.org/pdf/2505.10909v1",
    "published": "2025-05-16T06:29:24+00:00",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.11561v1",
    "title": "Policy Gradient with Second Order Momentum",
    "authors": [
      "Tianyu Sun"
    ],
    "abstract": "We develop Policy Gradient with Second-Order Momentum (PG-SOM), a lightweight\nsecond-order optimisation scheme for reinforcement-learning policies. PG-SOM\naugments the classical REINFORCE update with two exponentially weighted\nstatistics: a first-order gradient average and a diagonal approximation of the\nHessian. By preconditioning the gradient with this curvature estimate, the\nmethod adaptively rescales each parameter, yielding faster and more stable\nascent of the expected return. We provide a concise derivation, establish that\nthe diagonal Hessian estimator is unbiased and positive-definite under mild\nregularity assumptions, and prove that the resulting update is a descent\ndirection in expectation. Numerical experiments on standard control benchmarks\nshow up to a 2.1x increase in sample efficiency and a substantial reduction in\nvariance compared to first-order and Fisher-matrix baselines. These results\nindicate that even coarse second-order information can deliver significant\npractical gains while incurring only D memory overhead for a D-parameter\npolicy. All code and reproducibility scripts will be made publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.11561v1",
    "published": "2025-05-16T06:23:53+00:00",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10908v1",
    "title": "The impact of spiral arms on the star formation life cycle",
    "authors": [
      "Andrea Romanelli",
      "Mélanie Chevance",
      "J. M. Diederik Kruijssen",
      "Lise Ramambason",
      "Miguel Querejeta",
      "Mederic Boquien",
      "Daniel A. Dale",
      "Jakob den Brok",
      "Simon C. O. Glover",
      "Kathryn Grasha",
      "Annie Hughes",
      "Jaeyeon Kim",
      "Steven Longmore",
      "Sharon E. Meidt",
      "José Eduardo Mendez-Delgado",
      "Lukas Neumann",
      "Jérôme Pety",
      "Eva Schinnerer",
      "Rowan Smith",
      "Jiayi Sun",
      "Thomas G. Williams"
    ],
    "abstract": "The matter cycle between gas clouds and stars in galaxies plays a crucial\nrole in regulating galaxy evolution through feedback mechanisms. In turn, the\nlocal and global galactic environments shape the interstellar medium and\nprovide the initial conditions for star formation, potentially affecting the\nproperties of this small-scale matter cycle. In particular, spiral arms have\nbeen proposed to play a pivotal role in the star formation life cycle, by\nenhancing the gas density and triggering star formation. However, their exact\nrole is still debated. In this paper, we investigate the role of spiral arms in\nthe giant molecular cloud evolutionary life cycle and on the star formation\nprocess in a sample of 22 nearby spiral galaxies from the PHANGS survey. We\nmeasure the cloud lifetime, the feedback timescale, the typical distance\nbetween independent regions and the star formation efficiency in spiral arms\nand inter-arm regions separately. We find that the distributions of the cloud\nlifetime as well as the feedback timescale are similar in both environments.\nThis result suggests that spiral arms are unlikely to play a dominant role in\ntriggering star formation. By contrast, the star formation efficiency appears\nto be slightly higher in inter-arm regions compared to spiral arms.",
    "pdf_url": "http://arxiv.org/pdf/2505.10908v1",
    "published": "2025-05-16T06:21:24+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.10907v2",
    "title": "Effect of crystallinity on spin-orbit torque in 5$\\textit{d}$ iridium oxide IrO$_{2}$",
    "authors": [
      "Tetsuro Morimoto",
      "Kohei Ueda",
      "Junichi Shiogai",
      "Takanori Kida",
      "Masayuki Hagiwara",
      "Jobu Matsuno"
    ],
    "abstract": "The 5$\\textit{d}$ transition-metal oxides provide an intriguing platform for\ngenerating an efficient spin current due to a unique electronic structure\ndominated by 5d electrons with strong spin-orbit coupling. Here, we report on\nthe effect of crystallinity on current-driven spin-orbit torque (SOT) in binary\n5$\\textit{d}$ iridium oxide IrO$_{2}$ thin films by controlling amorphous,\npolycrystalline, and epitaxial states. By conducting harmonic Hall measurement\nin bilayers composed of ferromagnetic Co$_{20}$Fe$_{60}$B$_{20}$ and IrO$_{2}$,\nwe find that dampinglike (DL) SOT is larger than fieldlike SOT for all the\nsamples. We also demonstrate that both electrical resistivity and the DL SOT\nefficiency increase in order of epitaxial, polycrystalline, and amorphous\nIrO$_{2}$. Despite their different electrical conductivities, spin Hall\nconductivities of the three states of the IrO$_{2}$ layer are found to be\nnearly constant, which is consistent with the intrinsic regime of the spin Hall\neffect scaling relation. Our results highlight the important role that\ncrystallinity plays in the spin-current generation, leading to the potential\ntechnological development of spintronic devices based on the 5$\\textit{d}$\ntransition-metal oxides.",
    "pdf_url": "http://arxiv.org/pdf/2505.10907v2",
    "published": "2025-05-16T06:21:21+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.17049v2",
    "title": "Gender and Positional Biases in LLM-Based Hiring Decisions: Evidence from Comparative CV/Résumé Evaluations",
    "authors": [
      "David Rozado"
    ],
    "abstract": "This study examines the behavior of Large Language Models (LLMs) when\nevaluating professional candidates based on their resumes or curricula vitae\n(CVs). In an experiment involving 22 leading LLMs, each model was\nsystematically given one job description along with a pair of\nprofession-matched CVs, one bearing a male first name, the other a female first\nname, and asked to select the more suitable candidate for the job. Each CV pair\nwas presented twice, with names swapped to ensure that any observed preferences\nin candidate selection stemmed from gendered names cues. Despite identical\nprofessional qualifications across genders, all LLMs consistently favored\nfemale-named candidates across 70 different professions. Adding an explicit\ngender field (male/female) to the CVs further increased the preference for\nfemale applicants. When gendered names were replaced with gender-neutral\nidentifiers \"Candidate A\" and \"Candidate B\", several models displayed a\npreference to select \"Candidate A\". Counterbalancing gender assignment between\nthese gender-neutral identifiers resulted in gender parity in candidate\nselection. When asked to rate CVs in isolation rather than compare pairs, LLMs\nassigned slightly higher average scores to female CVs overall, but the effect\nsize was negligible. Including preferred pronouns (he/him or she/her) next to a\ncandidate's name slightly increased the odds of the candidate being selected\nregardless of gender. Finally, most models exhibited a substantial positional\nbias to select the candidate listed first in the prompt. These findings\nunderscore the need for caution when deploying LLMs in high-stakes autonomous\ndecision-making contexts and raise doubts about whether LLMs consistently apply\nprincipled reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.17049v2",
    "published": "2025-05-16T06:19:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10906v1",
    "title": "A Non-Markovian Route to Coherence in Heterogeneous Diffusive Systems",
    "authors": [
      "Aranyak Sarkar"
    ],
    "abstract": "Temporal coherence-persistent alignment across time-can arise between agents\nwith fundamentally distinct dynamics, a behavior that classical diffusion\nmodels (e.g., Brownian motion, fractional Brownian motion, generalized Langevin\nequation) are inherently limited in capturing, particularly under strong\nheterogeneity. We introduce the Coupled Memory Graph Process (CMGP), where\ndynamic interplay between internal memory and directed coupling enables\nsynchronized behavior even in the absence of reciprocity. An active particle\nwith long-range memory remains temporally coherent with a subdiffusive partner,\ndespite mismatched scaling laws and asymmetric information flow. Bayesian\noptimization identifies a broad parameter regime supporting this phenomenon,\ncharacterized by a high State Persistence Index SPI. These results uncover a\nminimal mechanism for emergent coordination-a form of ghost coherence-that\nremains inaccessible to classical stochastic models, with implications for\nviscoelastic environments and heterogeneous active systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.10906v1",
    "published": "2025-05-16T06:19:31+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.10905v1",
    "title": "Pressure induced evolution of anisotropic superconductivity and Fermi surface nesting in a ternary boride",
    "authors": [
      "Subhajit Pramanick",
      "Sudip Chakraborty",
      "A. Taraphder"
    ],
    "abstract": "Using Migdal-Eliashberg theory implemented in Electron Phonon Wannier (EPW)\ncode, we have investigated anisotropic superconductivity of a ternary boride\n$\\mathrm{Ta(MoB)_2}$. The robust coupling between $\\mathrm{\\sigma}$-bonding\nstates, primarily created by the d-orbitals of Mo atoms and the in-plane\nvibrations of Mo atoms, facilitates the generation of cooper pairs that make\n$\\mathrm{Ta(MoB)_2}$ a single-gap anisotropic superconductor with a critical\ntemperature ($\\mathrm{T_c}\\sim ) \\, 19.3$ K. A weak Fermi surface nesting and\nthe low value of electron-phonon coupling cannot induce charge density wave\ninstabilities, as evidenced by the lack of a significant peak in the real part\nof total Lindhard susceptibility and the absence of phonon softening.\nFurthermore, the system is readily tunable by hydrostatic pressure up to 76.69\nGPa, owing to its low bulk modulus and negative formation energy. The\npersistent reduction in the density of states at the Fermi level, Fermi nesting\nand the stiffening of phonon modes leads to a diminution of superconductivity\nunder pressure up to 59.71 GPa. At 76.69 GPa, a modification in the topology of\nthe Fermi surface, namely a Lifshitz transition, occurs resulting in a sudden\nimprovement in the nesting condition. This enhanced nesting, in turn, induces\nan abrupt stabilisation of superconductivity at 76.69 GPa, resulting in a\nV-shaped response to pressure.",
    "pdf_url": "http://arxiv.org/pdf/2505.10905v1",
    "published": "2025-05-16T06:16:03+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.10904v1",
    "title": "Effects of Coupling Between Chiral Vibrations and Spins in Molecular Magnets",
    "authors": [
      "Aman Ullah",
      "Sergey A. Varganov",
      "Yafis Barlas"
    ],
    "abstract": "In single molecular magnets, chiral vibrations carrying vibrational angular\nmomentum ($\\hat{L}^{\\text{vib}}$) emerge due to the splitting of a doubly\ndegenerate vibrational mode. Here, we identify a new type of effective\nspin-vibrational coupling responsible for lifting this degeneracy, which can\nfacilitate optically selective excitations. In the presence of an external\nZeeman field, this coupling breaks both inversion (in-plane parity)\n$\\mathcal{P}$ and time-reversal $\\mathcal{T}$ symmetries, imparting distinct\ngeometric phases to the resulting dressed spin-vibronic states. The wave\nfunction of the spin-vibronic state is characterized by a $\\pi$-Berry phase,\nwhich results in magneto-optical circular dichroism. This framework is\nvalidated using density functional theory and multi-reference \\emph{ab initio}\ncalculations on the Ce(trenovan) molecular magnet.",
    "pdf_url": "http://arxiv.org/pdf/2505.10904v1",
    "published": "2025-05-16T06:15:52+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.10903v1",
    "title": "On the Security Risks of ML-based Malware Detection Systems: A Survey",
    "authors": [
      "Ping He",
      "Yuhao Mao",
      "Changjiang Li",
      "Lorenzo Cavallaro",
      "Ting Wang",
      "Shouling Ji"
    ],
    "abstract": "Malware presents a persistent threat to user privacy and data integrity. To\ncombat this, machine learning-based (ML-based) malware detection (MD) systems\nhave been developed. However, these systems have increasingly been attacked in\nrecent years, undermining their effectiveness in practice. While the security\nrisks associated with ML-based MD systems have garnered considerable attention,\nthe majority of prior works is limited to adversarial malware examples, lacking\na comprehensive analysis of practical security risks. This paper addresses this\ngap by utilizing the CIA principles to define the scope of security risks. We\nthen deconstruct ML-based MD systems into distinct operational stages, thus\ndeveloping a stage-based taxonomy. Utilizing this taxonomy, we summarize the\ntechnical progress and discuss the gaps in the attack and defense proposals\nrelated to the ML-based MD systems within each stage. Subsequently, we conduct\ntwo case studies, using both inter-stage and intra-stage analyses according to\nthe stage-based taxonomy to provide new empirical insights. Based on these\nanalyses and insights, we suggest potential future directions from both\ninter-stage and intra-stage perspectives.",
    "pdf_url": "http://arxiv.org/pdf/2505.10903v1",
    "published": "2025-05-16T06:15:31+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10902v1",
    "title": "Patient-Specific Dynamic Digital-Physical Twin for Coronary Intervention Training: An Integrated Mixed Reality Approach",
    "authors": [
      "Shuo Wang",
      "Tong Ren",
      "Nan Cheng",
      "Rong Wang",
      "Li Zhang"
    ],
    "abstract": "Background and Objective: Precise preoperative planning and effective\nphysician training for coronary interventions are increasingly important.\nDespite advances in medical imaging technologies, transforming static or\nlimited dynamic imaging data into comprehensive dynamic cardiac models remains\nchallenging. Existing training systems lack accurate simulation of cardiac\nphysiological dynamics. This study develops a comprehensive dynamic cardiac\nmodel research framework based on 4D-CTA, integrating digital twin technology,\ncomputer vision, and physical model manufacturing to provide precise,\npersonalized tools for interventional cardiology. Methods: Using 4D-CTA data\nfrom a 60-year-old female with three-vessel coronary stenosis, we segmented\ncardiac chambers and coronary arteries, constructed dynamic models, and\nimplemented skeletal skinning weight computation to simulate vessel deformation\nacross 20 cardiac phases. Transparent vascular physical models were\nmanufactured using medical-grade silicone. We developed cardiac output analysis\nand virtual angiography systems, implemented guidewire 3D reconstruction using\nbinocular stereo vision, and evaluated the system through angiography\nvalidation and CABG training applications. Results: Morphological consistency\nbetween virtual and real angiography reached 80.9%. Dice similarity\ncoefficients for guidewire motion ranged from 0.741-0.812, with mean trajectory\nerrors below 1.1 mm. The transparent model demonstrated advantages in CABG\ntraining, allowing direct visualization while simulating beating heart\nchallenges. Conclusion: Our patient-specific digital-physical twin approach\neffectively reproduces both anatomical structures and dynamic characteristics\nof coronary vasculature, offering a dynamic environment with visual and tactile\nfeedback valuable for education and clinical planning.",
    "pdf_url": "http://arxiv.org/pdf/2505.10902v1",
    "published": "2025-05-16T06:13:55+00:00",
    "categories": [
      "cs.CV",
      "cs.HC",
      "92C50",
      "I.3.8; I.6.8"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01978v1",
    "title": "Luminescence thermometry based on time gates: highly sensitive approach for real time sensing and imaging",
    "authors": [
      "M. Szymczak",
      "D. Szymanski",
      "M. Piasecki",
      "M. Brik",
      "L. Marciniak"
    ],
    "abstract": "Undoubtedly, one of the most significant advantages of luminescence\nthermometry is its ability to be used not only for spot temperature\nmeasurements but also for imaging temperature changes. Among the commonly\nproposed approaches, luminescence thermometry based on luminescence kinetics\nholds particular promise. However, most thermometric studies rely on the\nanalysis of luminescence decay profiles, a method that significantly hinders,\nif not entirely precludes, real-time thermal imaging. In this paper, we propose\nan alternative approach based on the luminescence intensity ratio integrated\nover two temporal gates. Tests conducted on two representative phosphors,\nBa2LaNbO6:1%Mn4+ and Ca2LaNbO6:1%Mn4+, demonstrate that the proposed method not\nonly enables thermal imaging but also achieves substantially higher relative\nsensitivity, reaching SR=17.1 % K-1 for Ba2LaNbO6:1%Mn4+ and SR=9.4 % K-1 for\nCa2LaNbO6:1%Mn4+, compared to the conventional lifetime-based approach (SR=4.2\n% K-1 for Ba2LaNbO6:1%Mn4+ and SR=1.2 % K-1 for Ca2LaNbO6:1%Mn4+). Furthermore,\ncareful selection of gate lengths allows optimization of the thermometric\nperformance of the proposed luminescent thermometers. This approach enables\nexpansion of the thermal operating range at the cost of relative sensitivity,\nproviding versatility to adapt the thermometer for specific applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.01978v1",
    "published": "2025-05-16T06:12:01+00:00",
    "categories": [
      "physics.app-ph",
      "cond-mat.mtrl-sci",
      "physics.ins-det"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10901v1",
    "title": "Manifold dynamics and orbital properties in a two-dimensional galactic model",
    "authors": [
      "Dylan Theron",
      "Charalampos Skokos"
    ],
    "abstract": "We numerically investigate the orbital dynamics of a two-dimensional galactic\nmodel, emphasizing the influence of stable and unstable manifolds on the\nevolution of orbits. In our analysis we use evaluations of the system's\nLagrangian descriptors to reveal the structure and location of manifolds. In\naddition, we perform extensive computations of the forward and backward in time\nevolution of ensembles of orbits, which allow us to study the future and past\ndynamics of the model by constructing its so-called origin-fate maps. Focusing\non the properties of the escape of orbits from the central regions of the\nmodel's configuration space, we analyze various aspects of the orbits'\nevolutions, like the time an orbit needs to escape from the central region, the\ntotal time it spends at the exterior areas of the galaxy, as well as the number\nof its escapes and reentries from and to the central region. Furthermore, we\nfollow the past and future evolution of orbits keeping track of the regions\nfrom which they leave the central parts of the galaxy, and relate different\norbital behaviors with the enhancement of specific morphological features in\nthe system's configuration space. Our results indicate that the stable\n(unstable) manifolds mainly influence the orbital characteristics of the model\nin the future (past).",
    "pdf_url": "http://arxiv.org/pdf/2505.10901v1",
    "published": "2025-05-16T06:09:01+00:00",
    "categories": [
      "nlin.CD",
      "astro-ph.GA"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2505.10900v2",
    "title": "Explain What You Mean: Intent Augmented Knowledge Graph Recommender Built With An LLM",
    "authors": [
      "Wenqing Zheng",
      "Noah Fatsi",
      "Daniel Barcklow",
      "Dmitri Kalaev",
      "Steven Yao",
      "Owen Reinert",
      "C. Bayan Bruss",
      "Daniele Rosa"
    ],
    "abstract": "Interaction sparsity is a long-standing challenge in recommendation systems.\nSparsity manifests in environments with disproportional cardinality of\ngroupings of entities, such as users and products in an online marketplace. It\nis also found for newly introduced entities, described as the cold-start\nproblem. Recent efforts to mitigate this issue either enrich the connectivity\ndata by incorporating social networks or external knowledge graphs, or\nfine-tune LLMs into interaction augmenters or next-item recommenders. However,\nthese techniques tend to be resource demanding, requiring high computational\npower. They also have several limitations, including data availability, low\nquality, or synthetic noise issues. In this work, we propose LLM-based Intent\nKnowledge Graph Recommender (IKGR), a novel framework that leverages\nretrieval-augmented generation and an encoding approach to construct and\ndensify a knowledge graph. IKGR leverages latent user-item affinities from an\ninteraction knowledge graph and further densifies it through mutual intent\nconnectivity. This addresses sparsity issues and allows the model to make\nintent-grounded recommendations with an interpretable embedding translation\nlayer. Through extensive experiments on real-world datasets, we demonstrate\nthat IKGR overcomes knowledge gaps and achieves substantial gains over\nstate-of-the-art baselines on both publicly available and our internal\nrecommendation datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.10900v2",
    "published": "2025-05-16T06:07:19+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10899v1",
    "title": "Local volume-conserving lattice Boltzmann model for incompressible multiphase flows",
    "authors": [
      "Fang Xiong",
      "Lei Wang",
      "Xinyue Liu"
    ],
    "abstract": "The Cahn-Hilliard (C-H) equation, as a classical diffusion-interface method\nof phase-field, has been extensively employed for simulating two-phase fluid\ndynamics. However, it suffers from a key challenge in the simulation process,\nspecifically the volume conservation of each phase cannot be guaranteed. To\naddress this issue, in this paper, a modified C-H equation for two-phase flow\nmodeling is first introduced, and the basic idea of this model lies in that it\ncombines the profile correction method with the level-set approach, and thus,\nit effectively improves the deficiency of the classical C-H equation in terms\nof volume non-conservation of each phase. Based on this modified C-H equation,\nwe further propose an accurate interface-capturing lattice Boltzmann (LB)\nmodel. After that, we perform a range of numerical simulations, including two\nstationary droplets immersed in the gas phase, single vortex, Rayleigh-Plateau\nfluid instability, and droplet deformation under a shear flow. These\nsimulations illustrate that the proposed LB model has superior performance in\nmaintaining local volume conservation and accurately capturing interfaces. More\nimportantly, compared to the LB model derived from the classical C-H equation,\nit not only achieves more precise volume conservation for each phase but also\nprovides a more consistent representation of the droplet's interface morphology\nmore consistently, especially in dealing with small droplet problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.10899v1",
    "published": "2025-05-16T06:07:00+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.10898v2",
    "title": "Estimating Velocity Vector Fields of Atmospheric Winds using Transport Gaussian Processes",
    "authors": [
      "Youssef Fahmy",
      "Maria Laura Battagliola",
      "Joseph Guinness"
    ],
    "abstract": "Accurately estimating latent velocity vector fields of atmospheric winds is\ncrucial for understanding weather phenomena. Direct measurement of atmospheric\nwinds is costly, especially in the upper atmosphere, so researchers attempt to\nestimate atmospheric winds by observing the movement patterns of clouds and\nother features in satellite images of the atmosphere. These Derived Motion\nWinds use feature tracking algorithms to search for movement within small\nwindows in space and time. Consequently, these algorithms cannot leverage\ninformation from broader-scale features and cannot ensure that the collection\nof wind vectors over space and time represents a physically realistic velocity\nfield. In this work, we use spatial-temporal Gaussian processes to model the\nevolution of a scalar quantity transported over time by fluid flow. Our\nframework simultaneously estimates covariance parameters and latent velocities\nby maximizing the likelihood. Specifically, flows are represented using\ntime-dependent residual neural networks, and velocities are subsequently\nderived through closed-form formulas. Performance evaluations using weather\nmodel data demonstrate our method's accuracy and efficiency. We apply our\nmethod to GOES-16 images, demonstrating computational efficiency and the\nability to produce wind estimates where Derived Motion Winds fail.",
    "pdf_url": "http://arxiv.org/pdf/2505.10898v2",
    "published": "2025-05-16T06:06:07+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10897v2",
    "title": "Spatial and Temporal Characterization of Living Mycelium through Dispersion Analysis",
    "authors": [
      "Bao Zhao",
      "Sophia Ganzeboom",
      "Marcus Haywood-Alexander",
      "Eleni Chatzi",
      "Vasilis Dertimanis"
    ],
    "abstract": "Mycelium, a natural and sustainable material, possesses unique electrical,\nmechanical, and biological properties that make it a promising candidate for\nbiosensor applications. These properties include its ability to conduct\nelectrical signals, respond to external stimuli such as humidity and mechanical\nstress, and grow integrally within structures to form a natural network. Such\ncharacteristics suggest its potential for integration into self-sensing systems\nto monitor vibrations, deformations, and environmental conditions in buildings\nand infrastructure. To understand the output voltage generated by these\nbiomaterials in response to an applied electrical input, it is essential to\ncharacterize their spatial and temporal properties. This study introduces an\nelectrical impedance network model to describe signal transmission through\nmycelium. In combination with the inhomogeneous wave correlation (IWC) method,\ncommonly used in elastic wave propagation, we demonstrate the dispersion\nbehavior of living mycelium both theoretically and experimentally. We reveal\nthe frequency-dependent and spatial attenuation of electrical signals in\nliving, dehydrated, and rehydrated mycelium, emphasizing the critical role of\nhumidity in enabling effective signal sensing. Furthermore, dispersion analysis\nis used to assess the homogeneity of mycelium, underscoring its feasibility as\na living, green sensing material. This research lays the groundwork for\ninnovative applications of mycelium in sustainable structural health\nmonitoring.",
    "pdf_url": "http://arxiv.org/pdf/2505.10897v2",
    "published": "2025-05-16T06:04:17+00:00",
    "categories": [
      "physics.app-ph",
      "physics.bio-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10896v1",
    "title": "On Pseudospectral Concentration for Rank-1 Sampling",
    "authors": [
      "Kuo Gai",
      "Bin Shi"
    ],
    "abstract": "Pseudospectral analysis serves as a powerful tool in matrix computation and\nthe study of both linear and nonlinear dynamical systems. Among various\nnumerical strategies, random sampling, especially in the form of rank-$1$\nperturbations, offers a practical and computationally efficient approach.\nMoreover, due to invariance under unitary similarity, any complex matrix can be\nreduced to its upper triangular form, thereby simplifying the analysis. In this\nstudy. we develop a quantitative concentration theory for the pseudospectra of\ncomplex matrices under rank-$1$ random sampling perturbations, establishing a\nrigorous probabilistic framework for spectral characterization. First, for\nnormal matrices, we derive a regular concentration inequality and demonstrate\nthat the separation radius scales with the dimension as $\\delta_d \\sim\n1/\\sqrt{d}$. Next, for the equivalence class of nilpotent Jordan blocks, we\nexploit classical probabilistic tools, specifically, the Hanson-Wright\nconcentration inequality and the Carbery-Wright anti-concentration inequality,\nto obtain singular concentration bounds, and demonstrate that the separation\nradius exhibits the same dimension-dependent scaling. This yields a singular\npseudospectral concentration framework. Finally, observing that upper\ntriangular Toeplitz matrices can be represented via the symbolic polynomials of\nnilpotent Jordan blocks, we employ partial fraction decomposition of rational\nfunctions to extend the singular framework to the equivalence class of upper\ntriangular Toeplitz matrices.",
    "pdf_url": "http://arxiv.org/pdf/2505.10896v1",
    "published": "2025-05-16T06:03:30+00:00",
    "categories": [
      "math.SP",
      "cs.NA",
      "math.NA",
      "math.PR"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10895v2",
    "title": "Digital quantum simulation of squeezed states via enhanced bosonic encoding in a superconducting quantum processor",
    "authors": [
      "Hengyue Li",
      "Yusheng Yang",
      "Zhe-Hui Wang",
      "Shuxin Xie",
      "Zilong Zha",
      "Hantao Sun",
      "Jie Chen",
      "Jian Sun",
      "Shenggang Ying"
    ],
    "abstract": "We present a fully digital approach for simulating single-mode squeezed\nstates on a superconducting quantum processor using an enhanced bosonic\nencoding strategy. By mapping up to 2^{n} photonic Fock states onto n qubits,\nour framework leverages Gray-code-based encodings to reduce gate overhead\ncompared to conventional one-hot or binary mappings. We further optimize\nresource usage by restricting the simulation on Fock states with even number of\nphotons only, effectively doubling the range of photon numbers that can be\nrepresented for a given number of qubits. To overcome noise and finite\ncoherence in current hardware, we employ a variational quantum simulation\nprotocol, which adapts shallow, parameterized circuits through iterative\noptimization. Implemented on the Zuchongzhi-2 superconducting platform, our\nmethod demonstrates squeezed-state dynamics across a parameter sweep from\nvacuum state preparation (r=0) to squeezing levels exceeding the Fock space\ntruncation limit (r>1.63). Experimental results, corroborated by quantum state\ntomography and Wigner-function analysis, confirm high-fidelity state\npreparation and demonstrate the potential of Gray-code-inspired techniques for\nrealizing continuous-variable physics on near-term, qubit-based quantum\nprocessors.",
    "pdf_url": "http://arxiv.org/pdf/2505.10895v2",
    "published": "2025-05-16T06:02:25+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00011v1",
    "title": "Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization",
    "authors": [
      "Yang Zhao",
      "Yue Xiu",
      "Chengxiao Dai",
      "Ning Wei",
      "Dusit Niyato"
    ],
    "abstract": "Large language model (LLM) training in 6G networks faces stringent latency\nand energy constraints while operating over bandwidth-limited wireless links. A\ncommonly adopted workflow separates training into a centralized pre-training\nphase and a federated fine-tuning phase on domain-specific data; however,\nover-the-air (OTA) gradient aggregation during fine-tuning remains vulnerable\nto fading and interference. This study explores the integration of movable\nantennas (MAs), whose element positions can be reconfigured in real time, to\nmitigate such channel impairments. An auxiliary channel representation embeds\ntransmit power terms in the effective gain, thereby removing explicit\npower-control variables. We derive the convergence bound that determines the\nrelationship between the final fine-tuning loss to OTA noise and the\ndistribution shift between the two data stages, measured via the Wasserstein\ndistance. These findings lead to a mixed integer, nonconvex resource allocation\nproblem that jointly determines the numbers of global rounds, CPU frequencies,\nmini-batch sizes, positions of MAs, and beamformers under latency-energy\nconstraints. We propose a hybrid successive convex approximation (SCA) and\npenalty dual decomposition (PDD) algorithm to solve the problem. Experiments\nwith the OpenLLaMA v2 model with 3 billion parameters demonstrate up to $95\\%$\nfaster convergence and over $90\\%$ lower total energy consumption relative to\nthe leading wireless federated learning baselines, underscoring the promise of\nMAs-assisted federated LLM fine-tuning for 6G edge intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2506.00011v1",
    "published": "2025-05-16T06:02:10+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10894v1",
    "title": "CTP: A hybrid CNN-Transformer-PINN model for ocean front forecasting",
    "authors": [
      "Yishuo Wang",
      "Feng Zhou",
      "Muping Zhou",
      "Qicheng Meng",
      "Zhijun Hu",
      "Yi Wang"
    ],
    "abstract": "This paper proposes CTP, a novel deep learning framework that integrates\nconvolutional neural network(CNN), Transformer architectures, and\nphysics-informed neural network(PINN) for ocean front prediction. Ocean fronts,\nas dynamic interfaces between distinct water masses, play critical roles in\nmarine biogeochemical and physical processes. Existing methods such as LSTM,\nConvLSTM, and AttentionConv often struggle to maintain spatial continuity and\nphysical consistency over multi-step forecasts. CTP addresses these challenges\nby combining localized spatial encoding, long-range temporal attention, and\nphysical constraint enforcement. Experimental results across south China\nsea(SCS) and Kuroshio(KUR) regions from 1993 to 2020 demonstrate that CTP\nachieves state-of-the-art(SOTA) performance in both single-step and multi-step\npredictions, significantly outperforming baseline models in accuracy, $F_1$\nscore, and temporal stability.",
    "pdf_url": "http://arxiv.org/pdf/2505.10894v1",
    "published": "2025-05-16T06:00:11+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10893v1",
    "title": "Quantum Statistical Mechanics of Electronically Open Molecules: Reduced Density Operators",
    "authors": [
      "Jacob Pedersen",
      "Bendik Støa Sannes",
      "Ida-Marie Høyvik"
    ],
    "abstract": "We present a reduced density operator for electronically open molecules by\nexplicitly averaging over the environmental degrees of freedom of the composite\nHamiltonian. Specifically, we include the particle-number non-conserving\n(particle-breaking) interactions responsible for the sharing of electrons\nbetween the molecule and the environment, which are neglected in standard\nformulations of quantum statistical mechanics. We propose an unambiguous\ndefinition of the partial trace operation in the composite fermionic Fock space\nbased on composite states in a second quantization framework built from a\ncommon orthonormal set of orbitals. Thereby, we resolve the fermionic partial\ntrace ambiguity. The common orbital basis is constructed by spatial\nlocalization of the full orbital space, in which the full composite Hamiltonian\nnaturally partitions into a molecule Hamiltonian, an environment Hamiltonian,\nand an interaction Hamiltonian. The new reduced density operator is based on\nthe approximation of commutativity between the subsystem Hamiltonians (i.e.,\nmolecule and environment Hamiltonians) and the interaction Hamiltonian, which\nwe show corresponds to excluding certain electron transfer channels and\nneglecting electron transfer relaxation effects. The reduced density operator\ncan be viewed as a generalization of the grand canonical density operator. We\nare prompted to define the generalized chemical potential, which aligns with\nthe standard interpretation of the chemical potential, apart from the\npossibility of fractional rather than strictly integer electron transfer in our\nframework. In contrast to standard approaches, our framework enables an\nexplicit consideration of the electron occupancy in the environment at any\nlevel of theory, irrespective of the model used to describe the molecule.",
    "pdf_url": "http://arxiv.org/pdf/2505.10893v1",
    "published": "2025-05-16T05:59:20+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10892v1",
    "title": "Multi-Objective Preference Optimization: Improving Human Alignment of Generative Models",
    "authors": [
      "Akhil Agnihotri",
      "Rahul Jain",
      "Deepak Ramachandran",
      "Zheng Wen"
    ],
    "abstract": "Post-training of LLMs with RLHF, and subsequently preference optimization\nalgorithms such as DPO, IPO, etc., made a big difference in improving human\nalignment. However, all such techniques can only work with a single (human)\nobjective. In practice, human users have multiple objectives, such as\nhelpfulness and harmlessness, and there is no natural way to aggregate them\ninto a single objective. In this paper, we address the multi-objective\npreference-alignment problem, where a policy must optimize several, potentially\nconflicting, objectives. We introduce the Multi-Objective Preference\nOptimization (MOPO) algorithm, which frames alignment as a constrained\nKL-regularized optimization: the primary objective is maximized while secondary\nobjectives are lower-bounded by tunable safety thresholds. Unlike prior work,\nMOPO operates directly on pairwise preference data, requires no point-wise\nreward assumption, and avoids heuristic prompt-context engineering. The method\nrecovers policies on the Pareto front whenever the front is attainable;\npractically, it reduces to simple closed-form iterative updates suitable for\nlarge-scale training. On synthetic benchmarks with diverse canonical preference\nstructures, we show that MOPO approximates the Pareto front. When fine-tuning a\n1.3B-parameter language model on real-world human-preference datasets, MOPO\nattains higher rewards and yields policies that Pareto-dominate baselines;\nablation studies confirm optimization stability and robustness to\nhyperparameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.10892v1",
    "published": "2025-05-16T05:58:26+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10891v1",
    "title": "Toeplitz Determinants for Inverse Functions and their Logarithmic Coefficients Associated with Ma-Minda Classes",
    "authors": [
      "Surya Giri"
    ],
    "abstract": "The classes of analytic univalent functions on the unit disk defined by\n  $$ \\mathcal{S}^*(\\varphi)= \\bigg\\{ f \\in \\mathcal{A}: \\frac{z f'(z)}{f(z)}\n\\prec \\varphi(z)\\bigg\\}$$\n  and\n  $$ \\mathcal{C}(\\varphi)=\\bigg\\{ f \\in \\mathcal{A}: 1 + \\frac{z f''(z)}{f'(z)}\n\\prec \\varphi(z)\\bigg\\} $$\n  generalize various subclasses of starlike and convex functions, respectively.\nIn this paper, sharp bounds are established for certain Toeplitz determinants\nconstructed over the coefficients and logarithmic coefficients of inverse\nfunctions belonging to $\\mathcal{S}^*(\\varphi)$ and $\\mathcal{C}(\\varphi)$.\nSince these classes covers many well-known subclasses, the derived bounds are\ndirectly applicable to them as well.",
    "pdf_url": "http://arxiv.org/pdf/2505.10891v1",
    "published": "2025-05-16T05:57:15+00:00",
    "categories": [
      "math.CV",
      "30C45, 30C50"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10890v1",
    "title": "An Analytic Prescription for $t$-channel Singularities",
    "authors": [
      "Kento Asai",
      "Nagisa Hiroshima",
      "Joe Sato",
      "Ryusei Sato",
      "Masaki J. S. Yang"
    ],
    "abstract": "The $t$-channel singularity is a divergence in the scattering amplitude which\noccurs when a stable particle propagating in $t$-channel scattering process\nbecomes an on-shell state. Such situations appear either in the system of\ncollider experiments or in the context of the cosmological particle production.\nNo scheme which is generally applicable is known. In this work, we propose a\nnew formulation to identify and remove the source of the divergence. The scheme\nis fully analytical and various applications can be expected. This work\nprovides a valuable tool in this research field.",
    "pdf_url": "http://arxiv.org/pdf/2505.10890v1",
    "published": "2025-05-16T05:54:21+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10889v1",
    "title": "Convergence Analysis of the Last Iterate in Distributed Stochastic Gradient Descent with Momentum",
    "authors": [
      "Difei Cheng",
      "Ruinan Jin",
      "Hong Qiao",
      "Bo Zhang"
    ],
    "abstract": "Distributed stochastic gradient methods are widely used to preserve data\nprivacy and ensure scalability in large-scale learning tasks. While existing\ntheory on distributed momentum Stochastic Gradient Descent (mSGD) mainly\nfocuses on time-averaged convergence, the more practical last-iterate\nconvergence remains underexplored. In this work, we analyze the last-iterate\nconvergence behavior of distributed mSGD in non-convex settings under the\nclassical Robbins-Monro step-size schedule. We prove both almost sure\nconvergence and $L_2$ convergence of the last iterate, and derive convergence\nrates. We further show that momentum can accelerate early-stage convergence,\nand provide experiments to support our theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.10889v1",
    "published": "2025-05-16T05:52:12+00:00",
    "categories": [
      "math.OC",
      "40G15",
      "G.1.0"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10888v1",
    "title": "PoseBench3D: A Cross-Dataset Analysis Framework for 3D Human Pose Estimation",
    "authors": [
      "Saad Manzur",
      "Bryan Vela",
      "Brandon Vela",
      "Aditya Agrawal",
      "Lan-Anh Dang-Vu",
      "David Li",
      "Wayne Hayes"
    ],
    "abstract": "Reliable three-dimensional human pose estimation is becoming increasingly\nimportant for real-world applications, yet much of prior work has focused\nsolely on the performance within a single dataset. In practice, however,\nsystems must adapt to diverse viewpoints, environments, and camera setups --\nconditions that differ significantly from those encountered during training,\nwhich is often the case in real-world scenarios. To address these challenges,\nwe present a standardized testing environment in which each method is evaluated\non a variety of datasets, ensuring consistent and fair cross-dataset\ncomparisons -- allowing for the analysis of methods on previously unseen data.\nTherefore, we propose PoseBench3D, a unified framework designed to\nsystematically re-evaluate prior and future models across four of the most\nwidely used datasets for human pose estimation -- with the framework able to\nsupport novel and future datasets as the field progresses. Through a unified\ninterface, our framework provides datasets in a pre-configured yet easily\nmodifiable format, ensuring compatibility with diverse model architectures. We\nre-evaluated the work of 18 methods, either trained or gathered from existing\nliterature, and reported results using both Mean Per Joint Position Error\n(MPJPE) and Procrustes Aligned Mean Per Joint Position Error (PA-MPJPE)\nmetrics, yielding more than 100 novel cross-dataset evaluation results.\nAdditionally, we analyze performance differences resulting from various\npre-processing techniques and dataset preparation parameters -- offering\nfurther insight into model generalization capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.10888v1",
    "published": "2025-05-16T05:49:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10887v2",
    "title": "InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer Interaction",
    "authors": [
      "Bin Lei",
      "Weitai Kang",
      "Zijian Zhang",
      "Winson Chen",
      "Xi Xie",
      "Shan Zuo",
      "Mimi Xie",
      "Ali Payani",
      "Mingyi Hong",
      "Yan Yan",
      "Caiwen Ding"
    ],
    "abstract": "This paper introduces \\textsc{InfantAgent-Next}, a generalist agent capable\nof interacting with computers in a multimodal manner, encompassing text,\nimages, audio, and video. Unlike existing approaches that either build\nintricate workflows around a single large model or only provide workflow\nmodularity, our agent integrates tool-based and pure vision agents within a\nhighly modular architecture, enabling different models to collaboratively solve\ndecoupled tasks in a step-by-step manner. Our generality is demonstrated by our\nability to evaluate not only pure vision-based real-world benchmarks (i.e.,\nOSWorld), but also more general or tool-intensive benchmarks (e.g., GAIA and\nSWE-Bench). Specifically, we achieve $\\mathbf{7.27\\%}$ accuracy on OSWorld,\nhigher than Claude-Computer-Use. Codes and evaluation scripts are open-sourced\nat https://github.com/bin123apple/InfantAgent.",
    "pdf_url": "http://arxiv.org/pdf/2505.10887v2",
    "published": "2025-05-16T05:43:27+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10886v1",
    "title": "Exploring the Interplay Between Formation Mechanisms and Luminescence of Lignin Carbon Quantum Dots from Spruce Biomass",
    "authors": [
      "Jelena Papan Djaniš",
      "Maja Szymczak",
      "Jan Hočevar",
      "Jernej Iskra",
      "Boštjan Genorio",
      "Darja Lisjak",
      "Lukasz Marciniak",
      "Karolina Elzbieciak-Piecka"
    ],
    "abstract": "This study investigates the intricate relationship between the formation\nmechanisms and luminescent properties of lignin-derived carbon quantum dots\n(LG-CQDs) synthesized from spruce biomass by hydrothermal treatment. A\ncomprehensive understanding of LG-CQD structure and its photoluminescence\nrequires insights into the native architecture of lignin and the distribution\nof its acidolysis-derived fragments. Research showed how these lignin-derived\nunits interact with dopant molecules in three different approaches during\nsynthesis, contributing to core and surface structures that govern the optical\nbehavior. Our findings reveal a clear correlation between structural features\nand luminescent properties, emphasizing the role of surface chemistry in tuning\nemission characteristics. These insights provide a foundation for the rational\ndesign of LG-CQDs with tailored luminescent properties, advancing their\npotential applications in sustainable optoelectronics, sensing, and bioimaging.",
    "pdf_url": "http://arxiv.org/pdf/2505.10886v1",
    "published": "2025-05-16T05:42:43+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.bio-ph",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.11560v1",
    "title": "At the Edge of Uncertainty: Decoding the Cosmological Constant value with Bose-Einstein Distribution",
    "authors": [
      "Ahmed Farag Ali",
      "Nader Inan"
    ],
    "abstract": "We propose that the observed value of the cosmological constant may be\nexplained by a fundamental uncertainty in the spacetime metric, which arises\nwhen combining the principle that mass and energy curve spacetime with the\nquantum uncertainty associated with particle localization. Since the position\nof a quantum particle cannot be sharply defined, the gravitational influence of\nsuch particles leads to intrinsic ambiguity in the formation of spacetime\ngeometry. Recent experimental studies suggest that gravitational effects\npersist down to length scales of approximately $10^{-5}$ m, while quantum\ncoherence and macroscopic quantum phenomena such as Bose-Einstein condensation\nand superfluidity also manifest at similar scales. Motivated by these findings,\nwe identify a length scale of spacetime uncertainty, $L_Z \\sim 2.2 \\times\n10^{-5}$ m, which corresponds to the geometric mean of the Planck length and\nthe radius of the observable universe. We argue that this intermediate scale\nmay act as an effective cutoff in vacuum energy calculations. Furthermore, we\nexplore the interpretation of dark energy as a Bose-Einstein distribution with\na characteristic reduced wavelength matching this uncertainty scale. This\napproach provides a potential bridge between cosmological and quantum regimes\nand offers a phenomenologically motivated perspective on the cosmological\nconstant problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.11560v1",
    "published": "2025-05-16T05:42:28+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.10885v1",
    "title": "BanglaFake: Constructing and Evaluating a Specialized Bengali Deepfake Audio Dataset",
    "authors": [
      "Istiaq Ahmed Fahad",
      "Kamruzzaman Asif",
      "Sifat Sikder"
    ],
    "abstract": "Deepfake audio detection is challenging for low-resource languages like\nBengali due to limited datasets and subtle acoustic features. To address this,\nwe introduce BangalFake, a Bengali Deepfake Audio Dataset with 12,260 real and\n13,260 deepfake utterances. Synthetic speech is generated using SOTA\nText-to-Speech (TTS) models, ensuring high naturalness and quality. We evaluate\nthe dataset through both qualitative and quantitative analyses. Mean Opinion\nScore (MOS) from 30 native speakers shows Robust-MOS of 3.40 (naturalness) and\n4.01 (intelligibility). t-SNE visualization of MFCCs highlights real vs. fake\ndifferentiation challenges. This dataset serves as a crucial resource for\nadvancing deepfake detection in Bengali, addressing the limitations of\nlow-resource language research.",
    "pdf_url": "http://arxiv.org/pdf/2505.10885v1",
    "published": "2025-05-16T05:42:25+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.10884v1",
    "title": "Estimating Deformable-Rigid Contact Interactions for a Deformable Tool via Learning and Model-Based Optimization",
    "authors": [
      "Mark Van der Merwe",
      "Miquel Oller",
      "Dmitry Berenson",
      "Nima Fazeli"
    ],
    "abstract": "Dexterous manipulation requires careful reasoning over extrinsic contacts.\nThe prevalence of deforming tools in human environments, the use of deformable\nsensors, and the increasing number of soft robots yields a need for approaches\nthat enable dexterous manipulation through contact reasoning where not all\ncontacts are well characterized by classical rigid body contact models. Here,\nwe consider the case of a deforming tool dexterously manipulating a rigid\nobject. We propose a hybrid learning and first-principles approach to the\nmodeling of simultaneous motion and force transfer of tools and objects. The\nlearned module is responsible for jointly estimating the rigid object's motion\nand the deformable tool's imparted contact forces. We then propose a Contact\nQuadratic Program to recover forces between the environment and object subject\nto quasi-static equilibrium and Coulomb friction. The results is a system\ncapable of modeling both intrinsic and extrinsic motions, contacts, and forces\nduring dexterous deformable manipulation. We train our method in simulation and\nshow that our method outperforms baselines under varying block geometries and\nphysical properties, during pushing and pivoting manipulations, and demonstrate\ntransfer to real world interactions. Video results can be found at\nhttps://deform-rigid-contact.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2505.10884v1",
    "published": "2025-05-16T05:42:04+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10883v1",
    "title": "Quantum Lattice Kinetic Scheme for Solving Two-dimensional and Three-dimensional Incompressible Flows",
    "authors": [
      "Yang Xiao",
      "Liming Yang",
      "Chang Shu",
      "Yinjie Du",
      "Hao Dong",
      "Jie Wu"
    ],
    "abstract": "Lattice Boltzmann method (LBM) is particularly well-suited for implementation\non quantum circuits owing to its simple algebraic operations and natural\nparallelism. However, most quantum LBMs fix $\\tau$ = 1 to avoid nonlinear\ncollision, which restricts the simulation to a fixed mesh size for a given\nReynolds number. To preserve the simplicity of setting $\\tau$ = 1 while\nenhancing flexibility, we propose a quantum lattice kinetic scheme (LKS) by\nintroducing a constant parameter $A$ into the equilibrium distribution function\n(EDF), enabling independent adjustment of the fluid's viscosity. This\nmodification removes the constraint on mesh size, making it possible to\nsimulate flows with arbitrary Reynolds numbers. The Chapman-Enskog analysis\nconfirms the modified EDF still recovers the Navier-Stokes equations without\ncompromising collision accuracy. We evaluate the method on 2D and 3D\nTaylor-Green vortex and lid-driven cavity flows, demonstrating that quantum LKS\nattains the same accuracy and convergence order as classical LKS. The first\napplication of quantum LBM to 3D incompressible flows represents a significant\nstep forward in large-scale fluid dynamics simulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.10883v1",
    "published": "2025-05-16T05:41:46+00:00",
    "categories": [
      "quant-ph",
      "physics.flu-dyn"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10882v1",
    "title": "Global Convergence of Adaptive Sensing for Principal Eigenvector Estimation",
    "authors": [
      "Alex Saad-Falcon",
      "Brighton Ancelin",
      "Justin Romberg"
    ],
    "abstract": "This paper addresses the challenge of efficient principal component analysis\n(PCA) in high-dimensional spaces by analyzing a compressively sampled variant\nof Oja's algorithm with adaptive sensing. Traditional PCA methods incur\nsubstantial computational costs that scale poorly with data dimensionality,\nwhereas subspace tracking algorithms like Oja's offer more efficient\nalternatives but typically require full-dimensional observations. We analyze a\nvariant where, at each iteration, only two compressed measurements are taken:\none in the direction of the current estimate and one in a random orthogonal\ndirection. We prove that this adaptive sensing approach achieves global\nconvergence in the presence of noise when tracking the leading eigenvector of a\ndatastream with eigengap $\\Delta=\\lambda_1-\\lambda_2$. Our theoretical analysis\ndemonstrates that the algorithm experiences two phases: (1) a warmup phase\nrequiring $O(\\lambda_1\\lambda_2d^2/\\Delta^2)$ iterations to achieve a\nconstant-level alignment with the true eigenvector, followed by (2) a local\nconvergence phase where the sine alignment error decays at a rate of\n$O(\\lambda_1\\lambda_2d^2/\\Delta^2 t)$ for iterations $t$. The guarantee aligns\nwith existing minimax lower bounds with an added factor of $d$ due to the\ncompressive sampling. This work provides the first convergence guarantees in\nadaptive sensing for subspace tracking with noise. Our proof technique is also\nconsiderably simpler than those in prior works. The results have important\nimplications for applications where acquiring full-dimensional samples is\nchallenging or costly.",
    "pdf_url": "http://arxiv.org/pdf/2505.10882v1",
    "published": "2025-05-16T05:41:11+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10881v1",
    "title": "Prior-Guided Diffusion Planning for Offline Reinforcement Learning",
    "authors": [
      "Donghyeon Ki",
      "JunHyeok Oh",
      "Seong-Woong Shim",
      "Byung-Jun Lee"
    ],
    "abstract": "Diffusion models have recently gained prominence in offline reinforcement\nlearning due to their ability to effectively learn high-performing,\ngeneralizable policies from static datasets. Diffusion-based planners\nfacilitate long-horizon decision-making by generating high-quality trajectories\nthrough iterative denoising, guided by return-maximizing objectives. However,\nexisting guided sampling strategies such as Classifier Guidance,\nClassifier-Free Guidance, and Monte Carlo Sample Selection either produce\nsuboptimal multi-modal actions, struggle with distributional drift, or incur\nprohibitive inference-time costs. To address these challenges, we propose Prior\nGuidance (PG), a novel guided sampling framework that replaces the standard\nGaussian prior of a behavior-cloned diffusion model with a learnable\ndistribution, optimized via a behavior-regularized objective. PG directly\ngenerates high-value trajectories without costly reward optimization of the\ndiffusion model itself, and eliminates the need to sample multiple candidates\nat inference for sample selection. We present an efficient training strategy\nthat applies behavior regularization in latent space, and empirically\ndemonstrate that PG outperforms state-of-the-art diffusion policies and\nplanners across diverse long-horizon offline RL benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.10881v1",
    "published": "2025-05-16T05:39:02+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10880v1",
    "title": "Approximation and Generalization Abilities of Score-based Neural Network Generative Models for Sub-Gaussian Distributions",
    "authors": [
      "Guoji Fu",
      "Wee Sun Lee"
    ],
    "abstract": "This paper studies the approximation and generalization abilities of\nscore-based neural network generative models (SGMs) in estimating an unknown\ndistribution $P_0$ from $n$ i.i.d. observations in $d$ dimensions. Assuming\nmerely that $P_0$ is $\\alpha$-sub-Gaussian, we prove that for any time step $t\n\\in [t_0, n^{O(1)}]$, where $t_0 \\geq O(\\alpha^2n^{-2/d}\\log n)$, there exists\na deep ReLU neural network with width $\\leq O(\\log^3n)$ and depth $\\leq\nO(n^{3/d}\\log_2n)$ that can approximate the scores with $\\tilde{O}(n^{-1})$\nmean square error and achieve a nearly optimal rate of\n$\\tilde{O}(n^{-1}t_0^{-d/2})$ for score estimation, as measured by the score\nmatching loss. Our framework is universal and can be used to establish\nconvergence rates for SGMs under milder assumptions than previous work. For\nexample, assuming further that the target density function $p_0$ lies in\nSobolev or Besov classes, with an appropriately early stopping strategy, we\ndemonstrate that neural network-based SGMs can attain nearly minimax\nconvergence rates up to logarithmic factors. Our analysis removes several\ncrucial assumptions, such as Lipschitz continuity of the score function or a\nstrictly positive lower bound on the target density.",
    "pdf_url": "http://arxiv.org/pdf/2505.10880v1",
    "published": "2025-05-16T05:38:28+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10879v2",
    "title": "Multi-Stage Speaker Diarization for Noisy Classrooms",
    "authors": [
      "Ali Sartaz Khan",
      "Tolulope Ogunremi",
      "Ahmed Adel Attia",
      "Dorottya Demszky"
    ],
    "abstract": "Speaker diarization, the process of identifying \"who spoke when\" in audio\nrecordings, is essential for understanding classroom dynamics. However,\nclassroom settings present distinct challenges, including poor recording\nquality, high levels of background noise, overlapping speech, and the\ndifficulty of accurately capturing children's voices. This study investigates\nthe effectiveness of multi-stage diarization models using Nvidia's NeMo\ndiarization pipeline. We assess the impact of denoising on diarization accuracy\nand compare various voice activity detection (VAD) models, including\nself-supervised transformer-based frame-wise VAD models. We also explore a\nhybrid VAD approach that integrates Automatic Speech Recognition (ASR)\nword-level timestamps with frame-level VAD predictions. We conduct experiments\nusing two datasets from English speaking classrooms to separate teacher vs.\nstudent speech and to separate all speakers. Our results show that denoising\nsignificantly improves the Diarization Error Rate (DER) by reducing the rate of\nmissed speech. Additionally, training on both denoised and noisy datasets leads\nto substantial performance gains in noisy conditions. The hybrid VAD model\nleads to further improvements in speech detection, achieving a DER as low as\n17% in teacher-student experiments and 45% in all-speaker experiments. However,\nwe also identified trade-offs between voice activity detection and speaker\nconfusion. Overall, our study highlights the effectiveness of multi-stage\ndiarization models and integrating ASR-based information for enhancing speaker\ndiarization in noisy classroom environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.10879v2",
    "published": "2025-05-16T05:35:06+00:00",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.10878v2",
    "title": "Observational causality by states and interaction type for scientific discovery",
    "authors": [
      "Álvaro Martínez-Sánchez",
      "Adrián Lozano-Durán"
    ],
    "abstract": "Causality plays a central role in understanding interactions between\nvariables in complex systems. These systems often exhibit state-dependent\ncausal relationships, where both the strength and direction of causality vary\nwith the value of the interacting variables. In this work, we introduce a\nstate-aware causal inference method that quantifies causality in terms of\ninformation gain about future states. The effectiveness of the proposed\napproach stems from two key features: its ability to characterize causal\ninfluence as a function of system state, and its capacity to distinguish\nbetween redundant and synergistic interactions. The method is validated across\na range of benchmark cases in which the direction and strength of causality\nevolve in a prescribed manner with the state of the system. We further\ndemonstrate the applicability of our approach in two real scenarios: the\ninteraction between motions across scales in a turbulent boundary layer, and\nthe Walker circulation phenomenon in tropical Pacific climate dynamics. Our\nresults show that, without accounting for state-dependent causality as well as\nredundant and synergistic effects, traditional approaches to causal inference\nmay lead to incomplete or misleading conclusions.",
    "pdf_url": "http://arxiv.org/pdf/2505.10878v2",
    "published": "2025-05-16T05:33:53+00:00",
    "categories": [
      "physics.data-an",
      "physics.flu-dyn"
    ],
    "primary_category": "physics.data-an"
  },
  {
    "id": "http://arxiv.org/abs/2505.10877v1",
    "title": "Graph and Simplicial Complex Prediction Gaussian Process via the Hodgelet Representations",
    "authors": [
      "Mathieu Alain",
      "So Takao",
      "Xiaowen Dong",
      "Bastian Rieck",
      "Emmanuel Noutahi"
    ],
    "abstract": "Predicting the labels of graph-structured data is crucial in scientific\napplications and is often achieved using graph neural networks (GNNs). However,\nwhen data is scarce, GNNs suffer from overfitting, leading to poor performance.\nRecently, Gaussian processes (GPs) with graph-level inputs have been proposed\nas an alternative. In this work, we extend the Gaussian process framework to\nsimplicial complexes (SCs), enabling the handling of edge-level attributes and\nattributes supported on higher-order simplices. We further augment the\nresulting SC representations by considering their Hodge decompositions,\nallowing us to account for homological information, such as the number of\nholes, in the SC. We demonstrate that our framework enhances the predictions\nacross various applications, paving the way for GPs to be more widely used for\ngraph and SC-level predictions.",
    "pdf_url": "http://arxiv.org/pdf/2505.10877v1",
    "published": "2025-05-16T05:33:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10875v1",
    "title": "A Light and Smart Wearable Platform with Multimodal Foundation Model for Enhanced Spatial Reasoning in People with Blindness and Low Vision",
    "authors": [
      "Alexey Magay",
      "Dhurba Tripathi",
      "Yu Hao",
      "Yi Fang"
    ],
    "abstract": "People with blindness and low vision (pBLV) face significant challenges,\nstruggling to navigate environments and locate objects due to limited visual\ncues. Spatial reasoning is crucial for these individuals, as it enables them to\nunderstand and interpret the spatial relationships in their surroundings,\nenhancing their ability to navigate and interact more safely and independently.\nCurrent multi-modal large language (MLLM) models for low vision people lack the\nspatial reasoning capabilities needed to effectively assist in these tasks.\nMoreover, there is a notable absence of lightweight, easy-to-use systems that\nallow pBLV to effectively perceive and interact with their surrounding\nenvironment. In this paper, we propose a novel spatial enhanced multi-modal\nlarge language model based approach for visually impaired individuals. By\nfine-tuning the MLLM to incorporate spatial reasoning capabilities, our method\nsignificantly improves the understanding of environmental context, which is\ncritical for navigation and object recognition. The innovation extends to a\nhardware component, designed as an attachment for glasses, ensuring increased\naccessibility and ease of use. This integration leverages advanced VLMs to\ninterpret visual data and provide real-time, spatially aware feedback to the\nuser. Our approach aims to bridge the gap between advanced machine learning\nmodels and practical, user-friendly assistive devices, offering a robust\nsolution for visually impaired users to navigate their surroundings more\neffectively and independently. The paper includes an in-depth evaluation using\nthe VizWiz dataset, demonstrating substantial improvements in accuracy and user\nexperience. Additionally, we design a comprehensive dataset to evaluate our\nmethod's effectiveness in realworld situations, demonstrating substantial\nimprovements in accuracy and user experience.",
    "pdf_url": "http://arxiv.org/pdf/2505.10875v1",
    "published": "2025-05-16T05:32:25+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10876v1",
    "title": "Preference Isolation Forest for Structure-based Anomaly Detection",
    "authors": [
      "Filippo Leveni",
      "Luca Magri",
      "Cesare Alippi",
      "Giacomo Boracchi"
    ],
    "abstract": "We address the problem of detecting anomalies as samples that do not conform\nto structured patterns represented by low-dimensional manifolds. To this end,\nwe conceive a general anomaly detection framework called Preference Isolation\nForest (PIF), that combines the benefits of adaptive isolation-based methods\nwith the flexibility of preference embedding. The key intuition is to embed the\ndata into a high-dimensional preference space by fitting low-dimensional\nmanifolds, and to identify anomalies as isolated points. We propose three\nisolation approaches to identify anomalies: $i$) Voronoi-iForest, the most\ngeneral solution, $ii$) RuzHash-iForest, that avoids explicit computation of\ndistances via Local Sensitive Hashing, and $iii$) Sliding-PIF, that leverages a\nlocality prior to improve efficiency and effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.10876v1",
    "published": "2025-05-16T05:32:25+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10874v1",
    "title": "MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection",
    "authors": [
      "Luca Magri",
      "Filippo Leveni",
      "Giacomo Boracchi"
    ],
    "abstract": "We address the problem of recovering multiple structures of different classes\nin a dataset contaminated by noise and outliers. In particular, we consider\ngeometric structures defined by a mixture of underlying parametric models (e.g.\nplanes and cylinders, homographies and fundamental matrices), and we tackle the\nrobust fitting problem by preference analysis and clustering. We present a new\nalgorithm, termed MultiLink, that simultaneously deals with multiple classes of\nmodels. MultiLink combines on-the-fly model fitting and model selection in a\nnovel linkage scheme that determines whether two clusters are to be merged. The\nresulting method features many practical advantages with respect to methods\nbased on preference analysis, being faster, less sensitive to the inlier\nthreshold, and able to compensate limitations deriving from hypotheses\nsampling. Experiments on several public datasets demonstrate that Multi-Link\nfavourably compares with state of the art alternatives, both in multi-class and\nsingle-class problems. Code is publicly made available for download.",
    "pdf_url": "http://arxiv.org/pdf/2505.10874v1",
    "published": "2025-05-16T05:32:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10873v1",
    "title": "Hashing for Structure-based Anomaly Detection",
    "authors": [
      "Filippo Leveni",
      "Luca Magri",
      "Cesare Alippi",
      "Giacomo Boracchi"
    ],
    "abstract": "We focus on the problem of identifying samples in a set that do not conform\nto structured patterns represented by low-dimensional manifolds. An effective\nway to solve this problem is to embed data in a high dimensional space, called\nPreference Space, where anomalies can be identified as the most isolated\npoints. In this work, we employ Locality Sensitive Hashing to avoid explicit\ncomputation of distances in high dimensions and thus improve Anomaly Detection\nefficiency. Specifically, we present an isolation-based anomaly detection\ntechnique designed to work in the Preference Space which achieves\nstate-of-the-art performance at a lower computational cost. Code is publicly\navailable at\nhttps://github.com/ineveLoppiliF/Hashing-for-Structure-based-Anomaly-Detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.10873v1",
    "published": "2025-05-16T05:31:50+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10872v2",
    "title": "REI-Bench: Can Embodied Agents Understand Vague Human Instructions in Task Planning?",
    "authors": [
      "Chenxi Jiang",
      "Chuhao Zhou",
      "Jianfei Yang"
    ],
    "abstract": "Robot task planning decomposes human instructions into executable action\nsequences that enable robots to complete a series of complex tasks. Although\nrecent large language model (LLM)-based task planners achieve amazing\nperformance, they assume that human instructions are clear and straightforward.\nHowever, real-world users are not experts, and their instructions to robots\noften contain significant vagueness. Linguists suggest that such vagueness\nfrequently arises from referring expressions (REs), whose meanings depend\nheavily on dialogue context and environment. This vagueness is even more\nprevalent among the elderly and children, who robots should serve more. This\npaper studies how such vagueness in REs within human instructions affects\nLLM-based robot task planning and how to overcome this issue. To this end, we\npropose the first robot task planning benchmark with vague REs (REI-Bench),\nwhere we discover that the vagueness of REs can severely degrade robot planning\nperformance, leading to success rate drops of up to 77.9%. We also observe that\nmost failure cases stem from missing objects in planners. To mitigate the REs\nissue, we propose a simple yet effective approach: task-oriented context\ncognition, which generates clear instructions for robots, achieving\nstate-of-the-art performance compared to aware prompt and chains of thought.\nThis work contributes to the research community of human-robot interaction\n(HRI) by making robot task planning more practical, particularly for non-expert\nusers, e.g., the elderly and children.",
    "pdf_url": "http://arxiv.org/pdf/2505.10872v2",
    "published": "2025-05-16T05:27:15+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10871v1",
    "title": "Optimal Allocation of Privacy Budget on Hierarchical Data Release",
    "authors": [
      "Joonhyuk Ko",
      "Juba Ziani",
      "Ferdinando Fioretto"
    ],
    "abstract": "Releasing useful information from datasets with hierarchical structures while\npreserving individual privacy presents a significant challenge. Standard\nprivacy-preserving mechanisms, and in particular Differential Privacy, often\nrequire careful allocation of a finite privacy budget across different levels\nand components of the hierarchy. Sub-optimal allocation can lead to either\nexcessive noise, rendering the data useless, or to insufficient protections for\nsensitive information. This paper addresses the critical problem of optimal\nprivacy budget allocation for hierarchical data release. It formulates this\nchallenge as a constrained optimization problem, aiming to maximize data\nutility subject to a total privacy budget while considering the inherent\ntrade-offs between data granularity and privacy loss. The proposed approach is\nsupported by theoretical analysis and validated through comprehensive\nexperiments on real hierarchical datasets. These experiments demonstrate that\noptimal privacy budget allocation significantly enhances the utility of the\nreleased data and improves the performance of downstream tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.10871v1",
    "published": "2025-05-16T05:25:11+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10870v1",
    "title": "Improve Rule Retrieval and Reasoning with Self-Induction and Relevance ReEstimate",
    "authors": [
      "Ziyang Huang",
      "Wangtao Sun",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "This paper systematically addresses the challenges of rule retrieval, a\ncrucial yet underexplored area. Vanilla retrieval methods using sparse or dense\nretrievers to directly search for relevant rules to support downstream\nreasoning, often suffer from low accuracy. This is primarily due to a\nsignificant semantic gap between the instantiated facts in the queries and the\nabstract representations of the rules. Such misalignment results in suboptimal\nretrieval quality, which in turn negatively impacts reasoning performance. To\novercome these challenges, we propose Self-Induction Augmented Retrieval\n(SIAR), a novel approach that utilizes Large Language Models (LLMs) to induce\npotential inferential rules that might offer benefits for reasoning by\nabstracting the underlying knowledge and logical structure in queries. These\ninduced rules are then used for query augmentation to improve retrieval\neffectiveness. Additionally, we introduce Rule Relevance ReEstimate (R$^3$), a\nmethod that re-estimates the relevance of retrieved rules by assessing whether\nthe abstract knowledge they contain can be instantiated to align with the facts\nin the queries and the helpfulness for reasoning. Extensive experiments across\nvarious settings demonstrate the effectiveness and versatility of our proposed\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2505.10870v1",
    "published": "2025-05-16T05:22:42+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10869v1",
    "title": "A Convolution-Based Gait Asymmetry Metric for Inter-Limb Synergistic Coordination",
    "authors": [
      "Go Fukino",
      "Kanta Tachibana"
    ],
    "abstract": "This study focuses on the velocity patterns of various body parts during\nwalking and proposes a method for evaluating gait symmetry. Traditional motion\nanalysis studies have assessed gait symmetry based on differences in\nelectromyographic (EMG) signals or acceleration between the left and right\nsides. In contrast, this paper models intersegmental coordination using an LTI\nsystem and proposes a dissimilarity metric to evaluate symmetry. The method was\ntested on five subjects with both symmetric and asymmetric gait.",
    "pdf_url": "http://arxiv.org/pdf/2505.10869v1",
    "published": "2025-05-16T05:19:55+00:00",
    "categories": [
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10868v1",
    "title": "Security Analysis of Mode-Pairing Quantum Key Distribution with Flexible Pairing Strategy",
    "authors": [
      "Yi-Fei Lu",
      "Yang Wang",
      "Yan-Yang Zhou",
      "Yu Zhou",
      "Xiao-Lei Jiang",
      "Xin-Hang Li",
      "Hai-Tao Wang",
      "Jia-Ji Li",
      "Chun Zhou",
      "Hong-Wei Li",
      "Yu-Yao Guo",
      "Lin-Jie Zhou",
      "Wan-Su Bao"
    ],
    "abstract": "Mode-pairing quantum key distribution (MP-QKD) is advantageous for\nlong-distance secure communication, leveraging its simple implementation and\nquadratic scaling capacity. The post-measurement pairing in MP-QKD alleviates\nthe photon-coincidence demands, which is essential for surpassing the\nfundamental limit to the key-rate transmission. In this work, we propose an\nimproved decoy-state MP-QKD protocol featuring a flexible and efficient pairing\nstrategy. We prove the security of the proposed scheme by presenting an\nentanglement model for decoy-state MP-QKD. The simulation results show that the\nsecret key rate (SKR) can be enhanced among all distances. Notably, compared\nwith the original scheme [Nature Communication 13, 3903 (2022)], the\nimprovement of SKR is greater than 65\\% within 375 km in the asymptotic case\nand greater than 50\\% within 400 km in the finite case. And the achievable\ndistance can be extended in the finite case, especially with a small block\nlength. The simulation results demonstrate the high efficiency of the proposed\nscheme, which is expected to promote the practical applicability of MP-QKD.\nFurthermore, the entanglement model could provide a theoretical framework for\nfurther security and performance analysis of decoy-state MP-QKD.",
    "pdf_url": "http://arxiv.org/pdf/2505.10868v1",
    "published": "2025-05-16T05:12:55+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10867v1",
    "title": "Coordinated Inauthentic Behavior on TikTok: Challenges and Opportunities for Detection in a Video-First Ecosystem",
    "authors": [
      "Luca Luceri",
      "Tanishq Vijay Salkar",
      "Ashwin Balasubramanian",
      "Gabriela Pinto",
      "Chenning Sun",
      "Emilio Ferrara"
    ],
    "abstract": "Detecting coordinated inauthentic behavior (CIB) is central to the study of\nonline influence operations. However, most methods focus on text-centric\nplatforms, leaving video-first ecosystems like TikTok largely unexplored. To\naddress this gap, we develop and evaluate a computational framework for\ndetecting CIB on TikTok, leveraging a network-based approach adapted to the\nplatform's unique content and interaction structures. Building on existing\napproaches, we construct user similarity networks based on shared behaviors,\nincluding synchronized posting, repeated use of similar captions, multimedia\ncontent reuse, and hashtag sequence overlap, and apply graph pruning techniques\nto identify dense networks of likely coordinated accounts. Analyzing a dataset\nof 793K TikTok videos related to the 2024 U.S. Presidential Election, we\nuncover a range of coordinated activities, from synchronized amplification of\npolitical narratives to semi-automated content replication using AI-generated\nvoiceovers and split-screen video formats. Our findings show that while\ntraditional coordination indicators generalize well to TikTok, other signals,\nsuch as those based on textual similarity of video transcripts or Duet and\nStitch interactions, prove ineffective, highlighting the platform's distinct\ncontent norms and interaction mechanics. This work provides the first empirical\nfoundation for studying and detecting CIB on TikTok, paving the way for future\nresearch into influence operations in short-form video platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.10867v1",
    "published": "2025-05-16T05:12:46+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10866v1",
    "title": "Surface coupling of NV centers over nanoscale lengths",
    "authors": [
      "Arsineh Apelian",
      "Mariya Romanova",
      "Vojtech Vlcek"
    ],
    "abstract": "Shallow nitrogen-vacancy (NV-) centers in diamond are among the most\npromising quantum sensors, offering high sensitivity and nanoscale spatial\nresolution. These systems are, however, prone to decoherence due to coupling\nwith surface states. Here, we study sub-surface NV- centers embedded into large\ndiamond slabs (8 nm) using various surface orientations (100 and 111) and\nterminations (hydrogen and nitrogen terminators) and compute the quasiparticle\nstates of the defect. Our results show how dynamical charge fluctuations near\nthe surface influence defect stability. We find that the (100) N-terminated\nsurface introduces strong surface-state instabilities, while the (111)\nN-terminated surface provides a more favorable configuration. However,\nmany-body calculations (within the GW approximation) reveal that defects placed\nshallower than ~ 4 nm are prone to surface-induced ionization. These findings\nestablish an accurate theoretical limit on the minimum depth required for\nstable NV- centers, guiding the design of NV- based quantum sensors.",
    "pdf_url": "http://arxiv.org/pdf/2505.10866v1",
    "published": "2025-05-16T05:09:56+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.10865v1",
    "title": "Simulating fluid-fluid displacement in a soft capillary tube: How compliance delays interfacial instability and bubble pinch-off",
    "authors": [
      "Sthavishtha R. Bhopalam",
      "Ruben Juanes",
      "Hector Gomez"
    ],
    "abstract": "The displacement of a more viscous fluid by a less viscous immiscible fluid\nin confined geometries is a fundamental problem in multiphase flows. Recent\nexperiments have shown that such fluid-fluid displacement in micro-capillary\ntubes can lead to interfacial instabilities and, eventually, bubble pinch-off.\nA critical yet often overlooked aspect of this system is the effect of the\ntube's deformability on the onset of interfacial instability and bubble\npinch-off. Here, we present a computational fluid-structure interaction model\nand an algorithm to simulate this fluid-fluid displacement problem in a soft\ncapillary tube. We use a phase-field model for the fluids and a nonlinear\nhyperelastic model for the solid. Our fluid-structure interaction formulation\nuses a boundary-fitted approach and we use isogeometric analysis for the\nspatial discretization. Using this computational framework, we study the\neffects of inlet capillary number and tube stiffness on the control of\ninterfacial instabilities in a soft capillary tube for both imbibition and\ndrainage. We find that tube compliance delays or even suppresses interfacial\ninstability and bubble pinch-off, a finding that has important implications for\nflow in soft porous media, bio-microfluidics, and manufacturing processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.10865v1",
    "published": "2025-05-16T05:07:50+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.comp-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.10864v1",
    "title": "Anti-Sensing: Defense against Unauthorized Radar-based Human Vital Sign Sensing with Physically Realizable Wearable Oscillators",
    "authors": [
      "Md Farhan Tasnim Oshim",
      "Nigel Doering",
      "Bashima Islam",
      "Tsui-Wei Weng",
      "Tauhidur Rahman"
    ],
    "abstract": "Recent advancements in Ultra-Wideband (UWB) radar technology have enabled\ncontactless, non-line-of-sight vital sign monitoring, making it a valuable tool\nfor healthcare. However, UWB radar's ability to capture sensitive physiological\ndata, even through walls, raises significant privacy concerns, particularly in\nhuman-robot interactions and autonomous systems that rely on radar for sensing\nhuman presence and physiological functions. In this paper, we present\nAnti-Sensing, a novel defense mechanism designed to prevent unauthorized\nradar-based sensing. Our approach introduces physically realizable\nperturbations, such as oscillatory motion from wearable devices, to disrupt\nradar sensing by mimicking natural cardiac motion, thereby misleading heart\nrate (HR) estimations. We develop a gradient-based algorithm to optimize the\nfrequency and spatial amplitude of these oscillations for maximal disruption\nwhile ensuring physiological plausibility. Through both simulations and\nreal-world experiments with radar data and neural network-based HR sensing\nmodels, we demonstrate the effectiveness of Anti-Sensing in significantly\ndegrading model accuracy, offering a practical solution for privacy\npreservation.",
    "pdf_url": "http://arxiv.org/pdf/2505.10864v1",
    "published": "2025-05-16T05:07:08+00:00",
    "categories": [
      "cs.HC",
      "cs.CR"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10863v1",
    "title": "Conversations With The Stressed Body: Facilitating Stress Self-Disclosure Among Adolescent Girls Through An Embodied Approach",
    "authors": [
      "Xinglin Sun",
      "Caroline Claisse",
      "Runhua Zhang",
      "Xinyu Wu",
      "Jialin Yuan",
      "Qi Wang"
    ],
    "abstract": "Adolescent girls face significant mental health challenges during their\ntransition to adulthood, often experiencing heightened stress from various\nsources. While various interactive technologies for self-disclosure had been\nexplored to support stress relief, little is known about how to encourage\nstress-related self-disclosure through an embodied approach. This study\npresents a co-design workshop centred on Embodied Probes, a series of artefacts\nand activities incorporating embodied methods and technologies. During the\nworkshop, nine participants aged 15 to 18 engaged with their bodies, expressed\nbodily sensations through tangible means, and designed embodied prototypes\ntailored to their personal needs for stress perception and relief. The workshop\nrevealed insights into somatic symptoms, sources, and coping strategies for\nstress among adolescent girls, as well as how embodied methods can support\ntheir stress self-disclosure. This paper contributes to the HCI community by\noffering design implications on leveraging embodied technologies to support\nself-disclosure for young women's mental well-being.",
    "pdf_url": "http://arxiv.org/pdf/2505.10863v1",
    "published": "2025-05-16T05:06:17+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10862v1",
    "title": "Have Multimodal Large Language Models (MLLMs) Really Learned to Tell the Time on Analog Clocks?",
    "authors": [
      "Tairan Fu",
      "Miguel González",
      "Javier Conde",
      "Elena Merino-Gómez",
      "Pedro Reviriego"
    ],
    "abstract": "Multimodal Large Language Models which can answer complex questions on an\nimage struggle to tell the time on analog clocks. This is probably due to the\nlack of images with clocks at different times in their training set. In this\nwork we explore this issue with one of the latest MLLMs: GPT-4.1 to understand\nwhy MLLMs fail to tell the time and whether fine-tuning can solve the problem.\nThe results show how models are making progress in reading the time on analog\nclocks. But have they really learned to do it, or have they only learned\npatterns in their training datasets? In this work we put the models to the test\nwith different clocks to illustrate the limitations of MLLMs to abstract and\ngeneralize.",
    "pdf_url": "http://arxiv.org/pdf/2505.10862v1",
    "published": "2025-05-16T05:04:34+00:00",
    "categories": [
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10861v1",
    "title": "Improving the Data-efficiency of Reinforcement Learning by Warm-starting with LLM",
    "authors": [
      "Thang Duong",
      "Minglai Yang",
      "Chicheng Zhang"
    ],
    "abstract": "We investigate the usage of Large Language Model (LLM) in collecting\nhigh-quality data to warm-start Reinforcement Learning (RL) algorithms for\nlearning in some classical Markov Decision Process (MDP) environments. In this\nwork, we focus on using LLM to generate an off-policy dataset that sufficiently\ncovers state-actions visited by optimal policies, then later using an RL\nalgorithm to explore the environment and improve the policy suggested by the\nLLM. Our algorithm, LORO, can both converge to an optimal policy and have a\nhigh sample efficiency thanks to the LLM's good starting policy. On multiple\nOpenAI Gym environments, such as CartPole and Pendulum, we empirically\ndemonstrate that LORO outperforms baseline algorithms such as pure LLM-based\npolicies, pure RL, and a naive combination of the two, achieving up to $4\n\\times$ the cumulative rewards of the pure RL baseline.",
    "pdf_url": "http://arxiv.org/pdf/2505.10861v1",
    "published": "2025-05-16T05:03:39+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10860v1",
    "title": "On DeepSeekMoE: Statistical Benefits of Shared Experts and Normalized Sigmoid Gating",
    "authors": [
      "Huy Nguyen",
      "Thong T. Doan",
      "Quang Pham",
      "Nghi D. Q. Bui",
      "Nhat Ho",
      "Alessandro Rinaldo"
    ],
    "abstract": "Mixture of experts (MoE) methods are a key component in most large language\nmodel architectures, including the recent series of DeepSeek models. Compared\nto other MoE implementations, DeepSeekMoE stands out because of two unique\nfeatures: the deployment of a shared expert strategy and of the normalized\nsigmoid gating mechanism. Despite the prominent role of DeepSeekMoE in the\nsuccess of the DeepSeek series of models, there have been only a few attempts\nto justify theoretically the value of the shared expert strategy, while its\nnormalized sigmoid gating has remained unexplored. To bridge this gap, we\nundertake a comprehensive theoretical study of these two features of\nDeepSeekMoE from a statistical perspective. We perform a convergence analysis\nof the expert estimation task to highlight the gains in sample efficiency for\nboth the shared expert strategy and the normalized sigmoid gating, offering\nuseful insights into the design of expert and gating structures. To verify\nempirically our theoretical findings, we carry out several experiments on both\nsynthetic data and real-world datasets for (vision) language modeling tasks.\nFinally, we conduct an extensive empirical analysis of the router behaviors,\nranging from router saturation, router change rate, to expert utilization.",
    "pdf_url": "http://arxiv.org/pdf/2505.10860v1",
    "published": "2025-05-16T04:58:18+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10859v1",
    "title": "MCU: Improving Machine Unlearning through Mode Connectivity",
    "authors": [
      "Yingdan Shi",
      "Ren Wang"
    ],
    "abstract": "Machine Unlearning (MU) aims to remove the information of specific training\ndata from a trained model, ensuring compliance with privacy regulations and\nuser requests. While one line of existing MU methods relies on linear parameter\nupdates via task arithmetic, they suffer from weight entanglement. In this\nwork, we propose a novel MU framework called Mode Connectivity Unlearning (MCU)\nthat leverages mode connectivity to find an unlearning pathway in a nonlinear\nmanner. To further enhance performance and efficiency, we introduce a parameter\nmask strategy that not only improves unlearning effectiveness but also reduces\ncomputational overhead. Moreover, we propose an adaptive adjustment strategy\nfor our unlearning penalty coefficient to adaptively balance forgetting quality\nand predictive performance during training, eliminating the need for empirical\nhyperparameter tuning. Unlike traditional MU methods that identify only a\nsingle unlearning model, MCU uncovers a spectrum of unlearning models along the\npathway. Overall, MCU serves as a plug-and-play framework that seamlessly\nintegrates with any existing MU methods, consistently improving unlearning\nefficacy. Extensive experiments on the image classification task demonstrate\nthat MCU achieves superior performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.10859v1",
    "published": "2025-05-16T04:56:47+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10858v1",
    "title": "Generalized Kappa Distribution Function for Mixed Fermiom-Boson Quantum Plasmas",
    "authors": [
      "Aakanksha Singh",
      "Abhisek Kumar Singh",
      "Punit Kumar"
    ],
    "abstract": "A Kappa distribution function applicable to systems comprising mixed fermions\nand bosons has been developed through the thermodynamic Gibbs potential\nutilizing the quantum versions of the Olbert kappa distributions. The\ngeneralised expressions of the partition function and the entropy have been\nevaluated for such mixed quantum systems. The analysis shows that boson-rich\nsystems consistently exhibit higher entropy than fermion-rich systems. The\ndistribution functions show heavy-tailed characteristics at low Kappa values,\nindicating the presence of superthermal particles. It is observed that\nrelativistic effects lead to a significant increase in entropy.",
    "pdf_url": "http://arxiv.org/pdf/2505.10858v1",
    "published": "2025-05-16T04:55:09+00:00",
    "categories": [
      "physics.plasm-ph",
      "physics.space-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10857v1",
    "title": "A high-order Newton multigrid method for steady-state shallow water equations",
    "authors": [
      "Xiaowen Wang",
      "Chunwu Wang",
      "Guanghan Li",
      "Zhicheng Hu"
    ],
    "abstract": "A high-order Newton multigrid method is proposed for simulating steady-state\nshallow water flows in open channels with regular and irregular geometries. The\nmethod integrates two components: (1) a finite volume discretization with\nthird-order weighted essentially non-oscillatory (WENO) reconstruction for the\ngoverning shallow water equations, (2) a Newton-multigrid method with an\nefficient approximation of the Jacobian matrix for the resulting discrete\nsystem. Generating the full Jacobian matrix in Newton iterations causes\nsubstantial computational costs. To address this problem, we observe that the\nmajority of the non-zero elements in the matrix exhibit negligible magnitudes.\nBy eliminating these elements, we approximate the Jacobian matrix with fewer\nstencils, thereby significantly reducing calculation time. Numerical results\ndemonstrate that the proposed simplification strategy improves computational\nefficiency while maintaining convergence rates comparable to those of the full\nJacobian approach. Furthermore, the geometric multigrid method with a\nsuccessive over-relaxation fast-sweeping smoother is employed for the\nlinearized system to optimize performance. A variety of numerical experiments,\nincluding one-dimensional smooth subcritical flow, flows over a hump, and\ntwo-dimensional hydraulic jump over a wedge, are carried out to illustrate the\nthird-order accuracy, efficiency and robustness of the proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2505.10857v1",
    "published": "2025-05-16T04:53:18+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.10856v1",
    "title": "ImputeINR: Time Series Imputation via Implicit Neural Representations for Disease Diagnosis with Missing Data",
    "authors": [
      "Mengxuan Li",
      "Ke Liu",
      "Jialong Guo",
      "Jiajun Bu",
      "Hongwei Wang",
      "Haishuai Wang"
    ],
    "abstract": "Healthcare data frequently contain a substantial proportion of missing\nvalues, necessitating effective time series imputation to support downstream\ndisease diagnosis tasks. However, existing imputation methods focus on discrete\ndata points and are unable to effectively model sparse data, resulting in\nparticularly poor performance for imputing substantial missing values. In this\npaper, we propose a novel approach, ImputeINR, for time series imputation by\nemploying implicit neural representations (INR) to learn continuous functions\nfor time series. ImputeINR leverages the merits of INR in that the continuous\nfunctions are not coupled to sampling frequency and have infinite sampling\nfrequency, allowing ImputeINR to generate fine-grained imputations even on\nextremely sparse observed values. Extensive experiments conducted on eight\ndatasets with five ratios of masked values show the superior imputation\nperformance of ImputeINR, especially for high missing ratios in time series\ndata. Furthermore, we validate that applying ImputeINR to impute missing values\nin healthcare data enhances the performance of downstream disease diagnosis\ntasks. Codes are available.",
    "pdf_url": "http://arxiv.org/pdf/2505.10856v1",
    "published": "2025-05-16T04:50:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10855v1",
    "title": "Pretrained hybrid transformer for generalizable cardiac substructures segmentation from contrast and non-contrast CTs in lung and breast cancers",
    "authors": [
      "Aneesh Rangnekar",
      "Nikhil Mankuzhy",
      "Jonas Willmann",
      "Chloe Choi",
      "Abraham Wu",
      "Maria Thor",
      "Andreas Rimner",
      "Harini Veeraraghavan"
    ],
    "abstract": "AI automated segmentations for radiation treatment planning (RTP) can\ndeteriorate when applied in clinical cases with different characteristics than\ntraining dataset. Hence, we refined a pretrained transformer into a hybrid\ntransformer convolutional network (HTN) to segment cardiac substructures lung\nand breast cancer patients acquired with varying imaging contrasts and patient\nscan positions. Cohort I, consisting of 56 contrast-enhanced (CECT) and 124\nnon-contrast CT (NCCT) scans from patients with non-small cell lung cancers\nacquired in supine position, was used to create oracle with all 180 training\ncases and balanced (CECT: 32, NCCT: 32 training) HTN models. Models were\nevaluated on a held-out validation set of 60 cohort I patients and 66 patients\nwith breast cancer from cohort II acquired in supine (n=45) and prone (n=21)\npositions. Accuracy was measured using DSC, HD95, and dose metrics. Publicly\navailable TotalSegmentator served as the benchmark. The oracle and balanced\nmodels were similarly accurate (DSC Cohort I: 0.80 \\pm 0.10 versus 0.81 \\pm\n0.10; Cohort II: 0.77 \\pm 0.13 versus 0.80 \\pm 0.12), outperforming\nTotalSegmentator. The balanced model, using half the training cases as oracle,\nproduced similar dose metrics as manual delineations for all cardiac\nsubstructures. This model was robust to CT contrast in 6 out of 8 substructures\nand patient scan position variations in 5 out of 8 substructures and showed low\ncorrelations of accuracy to patient size and age. A HTN demonstrated robustly\naccurate (geometric and dose metrics) cardiac substructures segmentation from\nCTs with varying imaging and patient characteristics, one key requirement for\nclinical use. Moreover, the model combining pretraining with balanced\ndistribution of NCCT and CECT scans was able to provide reliably accurate\nsegmentations under varied conditions with far fewer labeled datasets compared\nto an oracle model.",
    "pdf_url": "http://arxiv.org/pdf/2505.10855v1",
    "published": "2025-05-16T04:48:33+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10854v1",
    "title": "Magnetically Coupled Circuits to Capture Dynamics of Ionic Transport in Nanopores",
    "authors": [
      "Filipe Henrique",
      "Ankur Gupta"
    ],
    "abstract": "Ionic transport within charged nanopores is commonly represented by\nresistor-capacitor transmission line circuits, where charging electrical double\nlayers are modeled as capacitors, and the resistance to ionic current is\nmodeled as resistors. However, these circuits fail to account for oscillations\nobserved in experimental Nyquist plots of impedance, which are attributed ad\nhoc to effects such as complex porous structures or chemical reactions. Here,\nwe show that diffusivity asymmetry between ions in confinement - overlooked in\nprevious studies - produces Nyquist plots with two turns. Additionally, we\ndemonstrate that ionic transport is more accurately described by magnetically\ncoupled inductor-resistor circuits than by a simple resistor-capacitor circuit.\nOur results show that an impedance response of ionic transport in nanopores for\narbitrary Debye lengths is better captured by two Warburg elements in parallel\nthan a single Warburg element.",
    "pdf_url": "http://arxiv.org/pdf/2505.10854v1",
    "published": "2025-05-16T04:44:35+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10853v1",
    "title": "Beyond surfaces: quantifying internal radiative heat transport in dense materials",
    "authors": [
      "Janak Tiwari",
      "Tianli Feng"
    ],
    "abstract": "While phonons and electrons are well-established heat carriers in solids,\nphotons are typically associated only with radiative transfer between surfaces.\nYet for over 70 years, theorists have speculated that thermal photons could\nalso conduct heat within dense, opaque materials -- an idea that has remained\nunproven and unquantified. Here, we resolve this longstanding question by\ndeveloping a first-principles framework that reveals and quantifies the\ninternal radiative contribution to thermal conductivity in solids. By analyzing\n15 crystalline materials, we uncover photon mean free paths (MFPs) ranging from\n$\\sim$100$\\mu$m to over 1cm, with some materials exhibiting surprisingly large\nradiative thermal conductivity ($\\kappa_{\\text{rad}}$). Contrary to common\nassumptions, we show that $\\kappa_{\\text{rad}}$ can scale steeply with\ntemperature (from $T^{1}$ to $T^{4}$), even as MFPs decrease (from $T^{-0.3}$\nto $T^{-3}$). We also discover a robust link between photon MFP and phonon\nlinewidths, revealing an unexpected interplay between radiative and phononic\nheat transport. Crucially, we establish a general formalism to calculate\n$\\kappa_{\\text{rad}}$ across arbitrary sample thicknesses and surface\nemissivities -- bridging ballistic and diffusive regimes. Our findings overturn\nlong-held assumptions, uncover a missing channel of heat conduction, and\nprovide a powerful new tool for thermal management in extreme environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.10853v1",
    "published": "2025-05-16T04:43:20+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.10852v1",
    "title": "MatTools: Benchmarking Large Language Models for Materials Science Tools",
    "authors": [
      "Siyu Liu",
      "Jiamin Xu",
      "Beilin Ye",
      "Bo Hu",
      "David J. Srolovitz",
      "Tongqi Wen"
    ],
    "abstract": "Large language models (LLMs) are increasingly applied to materials science\nquestions, including literature comprehension, property prediction, materials\ndiscovery and alloy design. At the same time, a wide range of physics-based\ncomputational approaches have been developed in which materials properties can\nbe calculated. Here, we propose a benchmark application to evaluate the\nproficiency of LLMs to answer materials science questions through the\ngeneration and safe execution of codes based on such physics-based\ncomputational materials science packages. MatTools is built on two\ncomplementary components: a materials simulation tool question-answer (QA)\nbenchmark and a real-world tool-usage benchmark. We designed an automated\nmethodology to efficiently collect real-world materials science tool-use\nexamples. The QA benchmark, derived from the pymatgen (Python Materials\nGenomics) codebase and documentation, comprises 69,225 QA pairs that assess the\nability of an LLM to understand materials science tools. The real-world\nbenchmark contains 49 tasks (138 subtasks) requiring the generation of\nfunctional Python code for materials property calculations. Our evaluation of\ndiverse LLMs yields three key insights: (1)Generalists outshine\nspecialists;(2)AI knows AI; and (3)Simpler is better. MatTools provides a\nstandardized framework for assessing and improving LLM capabilities for\nmaterials science tool applications, facilitating the development of more\neffective AI systems for materials science and general scientific research.",
    "pdf_url": "http://arxiv.org/pdf/2505.10852v1",
    "published": "2025-05-16T04:43:05+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.10851v1",
    "title": "On best constrained and best simultaneous approximation in Banach spaces",
    "authors": [
      "Syamantak Das",
      "Tanmoy Paul"
    ],
    "abstract": "It is folklore that the sum of two $M$-ideals (semi $M$-ideals) is also an\n$M$-ideal (a semi $M$-ideal). Numerous authors have attempted to investigate\nsuch properties of subspaces. This article explores two important facets of\napproximation theory within Banach spaces and how these properties remain\nintact when considering the sum of two subsets. Recall the notion of $(GC)$\nintroduced by Vesel\\'y that encloses two aforementioned properties. When the\nsum of two subspaces is closed, we discuss various properties of the sum if one\nof the subspaces has these properties. Counterexamples are produced that\nestablish nonaffirmativeness for the properties $(GC)$ and the central\nsubspace. We answer a problem raised by the author in [{\\em Best constrained\napproximation in Banach spaces}, Numer. Funct. Anal. Optim. {\\bf 36}(2) (2015),\n248--255]. We extend our observations related to the best simultaneous\napproximations to the properties $(P_1)$ and $\\mr{F}$-SACP.",
    "pdf_url": "http://arxiv.org/pdf/2505.10851v1",
    "published": "2025-05-16T04:42:43+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.10850v1",
    "title": "Tracking Low-Level Cloud Systems with Topology",
    "authors": [
      "Mingzhe Li",
      "Dwaipayan Chatterjee",
      "Franziska Glassmeier",
      "Fabian Senf",
      "Bei Wang"
    ],
    "abstract": "Low-level clouds are ubiquitous in Earth's atmosphere, playing a crucial role\nin transporting heat, moisture, and momentum across the planet. Their evolution\nand interaction with other atmospheric components, such as aerosols, are\nessential to understanding the climate system and its sensitivity to\nanthropogenic influences. Advanced high-resolution geostationary satellites now\nresolve cloud systems with greater accuracy, establishing cloud tracking as a\nvital research area for studying their spatiotemporal dynamics. It enables\ndisentangling advective and convective components driving cloud evolution.\nThis, in turn, provides deeper insights into the structure and lifecycle of\nlow-level cloud systems and the atmospheric processes they govern. In this\npaper, we propose a novel framework for tracking cloud systems using\ntopology-driven techniques based on optimal transport. We first obtain a set of\nanchor points for the cloud systems based on the merge tree of the cloud\noptical depth field. We then apply topology-driven probabilistic feature\ntracking of these anchor points to guide the tracking of cloud systems. We\ndemonstrate the utility of our framework by tracking clouds over the ocean and\nland to test for systematic differences in the two physically distinct\nsettings. We further evaluate our framework through case studies and\nstatistical analyses, comparing it against two leading cloud tracking tools and\ntwo topology-based general-purpose tracking tools. The results demonstrate that\nincorporating system-based tracking improves the ability to capture the\nevolution of low-level clouds. Our framework paves the way for detailed\nlow-level cloud characterization studies using satellite data records.",
    "pdf_url": "http://arxiv.org/pdf/2505.10850v1",
    "published": "2025-05-16T04:42:37+00:00",
    "categories": [
      "cs.CG"
    ],
    "primary_category": "cs.CG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10849v1",
    "title": "Tractable Unified Skew-t Distribution and Copula for Heterogeneous Asymmetries",
    "authors": [
      "Lin Deng",
      "Michael Stanley Smith",
      "Worapree Maneesoonthorn"
    ],
    "abstract": "Multivariate distributions that allow for asymmetry and heavy tails are\nimportant building blocks in many econometric and statistical models. The\nUnified Skew-t (UST) is a promising choice because it is both scalable and\nallows for a high level of flexibility in the asymmetry in the distribution.\nHowever, it suffers from parameter identification and computational hurdles\nthat have to date inhibited its use for modeling data. In this paper we propose\na new tractable variant of the unified skew-t (TrUST) distribution that\naddresses both challenges. Moreover, the copula of this distribution is shown\nto also be tractable, while allowing for greater heterogeneity in asymmetric\ndependence over variable pairs than the popular skew-t copula. We show how\nBayesian posterior inference for both the distribution and its copula can be\ncomputed using an extended likelihood derived from a generative representation\nof the distribution. The efficacy of this Bayesian method, and the enhanced\nflexibility of both the TrUST distribution and its implicit copula, is first\ndemonstrated using simulated data. Applications of the TrUST distribution to\nhighly skewed regional Australian electricity prices, and the TrUST copula to\nintraday U.S. equity returns, demonstrate how our proposed distribution and its\ncopula can provide substantial increases in accuracy over the popular skew-t\nand its copula in practice.",
    "pdf_url": "http://arxiv.org/pdf/2505.10849v1",
    "published": "2025-05-16T04:42:03+00:00",
    "categories": [
      "stat.ME",
      "econ.EM"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.10848v2",
    "title": "Foundation model for mass spectrometry proteomics",
    "authors": [
      "Justin Sanders",
      "Melih Yilmaz",
      "Jacob H. Russell",
      "Wout Bittremieux",
      "William E. Fondrie",
      "Nicholas M. Riley",
      "Sewoong Oh",
      "William Stafford Noble"
    ],
    "abstract": "Mass spectrometry is the dominant technology in the field of proteomics,\nenabling high-throughput analysis of the protein content of complex biological\nsamples. Due to the complexity of the instrumentation and resulting data,\nsophisticated computational methods are required for the processing and\ninterpretation of acquired mass spectra. Machine learning has shown great\npromise to improve the analysis of mass spectrometry data, with numerous\npurpose-built methods for improving specific steps in the data acquisition and\nanalysis pipeline reaching widespread adoption. Here, we propose unifying\nvarious spectrum prediction tasks under a single foundation model for mass\nspectra. To this end, we pre-train a spectrum encoder using de novo sequencing\nas a pre-training task. We then show that using these pre-trained spectrum\nrepresentations improves our performance on the four downstream tasks of\nspectrum quality prediction, chimericity prediction, phosphorylation\nprediction, and glycosylation status prediction. Finally, we perform multi-task\nfine-tuning and find that this approach improves the performance on each task\nindividually. Overall, our work demonstrates that a foundation model for tandem\nmass spectrometry proteomics trained on de novo sequencing learns generalizable\nrepresentations of spectra, improves performance on downstream tasks where\ntraining data is limited, and can ultimately enhance data acquisition and\nanalysis in proteomics experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.10848v2",
    "published": "2025-05-16T04:40:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10847v1",
    "title": "Robust 2D lidar-based SLAM in arboreal environments without IMU/GNSS",
    "authors": [
      "Paola Nazate-Burgos",
      "Miguel Torres-Torriti",
      "Sergio Aguilera-Marinovic",
      "Tito Arévalo",
      "Shoudong Huang",
      "Fernando Auat Cheein"
    ],
    "abstract": "Simultaneous localization and mapping (SLAM) approaches for mobile robots\nremains challenging in forest or arboreal fruit farming environments, where\ntree canopies obstruct Global Navigation Satellite Systems (GNSS) signals.\nUnlike indoor settings, these agricultural environments possess additional\nchallenges due to outdoor variables such as foliage motion and illumination\nvariability. This paper proposes a solution based on 2D lidar measurements,\nwhich requires less processing and storage, and is more cost-effective, than\napproaches that employ 3D lidars. Utilizing the modified Hausdorff distance\n(MHD) metric, the method can solve the scan matching robustly and with high\naccuracy without needing sophisticated feature extraction. The method's\nrobustness was validated using public datasets and considering various metrics,\nfacilitating meaningful comparisons for future research. Comparative\nevaluations against state-of-the-art algorithms, particularly A-LOAM, show that\nthe proposed approach achieves lower positional and angular errors while\nmaintaining higher accuracy and resilience in GNSS-denied settings. This work\ncontributes to the advancement of precision agriculture by enabling reliable\nand autonomous navigation in challenging outdoor environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.10847v1",
    "published": "2025-05-16T04:39:48+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10846v1",
    "title": "AutoRAN: Weak-to-Strong Jailbreaking of Large Reasoning Models",
    "authors": [
      "Jiacheng Liang",
      "Tanqiu Jiang",
      "Yuhui Wang",
      "Rongyi Zhu",
      "Fenglong Ma",
      "Ting Wang"
    ],
    "abstract": "This paper presents AutoRAN, the first automated, weak-to-strong jailbreak\nattack framework targeting large reasoning models (LRMs). At its core, AutoRAN\nleverages a weak, less-aligned reasoning model to simulate the target model's\nhigh-level reasoning structures, generates narrative prompts, and iteratively\nrefines candidate prompts by incorporating the target model's intermediate\nreasoning steps. We evaluate AutoRAN against state-of-the-art LRMs including\nGPT-o3/o4-mini and Gemini-2.5-Flash across multiple benchmark datasets\n(AdvBench, HarmBench, and StrongReject). Results demonstrate that AutoRAN\nachieves remarkable success rates (approaching 100%) within one or a few turns\nacross different LRMs, even when judged by a robustly aligned external model.\nThis work reveals that leveraging weak reasoning models can effectively exploit\nthe critical vulnerabilities of much more capable reasoning models,\nhighlighting the need for improved safety measures specifically designed for\nreasoning-based models. The code for replicating AutoRAN and running records\nare available at: (https://github.com/JACKPURCELL/AutoRAN-public). (warning:\nthis paper contains potentially harmful content generated by LRMs.)",
    "pdf_url": "http://arxiv.org/pdf/2505.10846v1",
    "published": "2025-05-16T04:37:12+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10845v1",
    "title": "Ready2Unlearn: A Learning-Time Approach for Preparing Models with Future Unlearning Readiness",
    "authors": [
      "Hanyu Duan",
      "Yi Yang",
      "Ahmed Abbasi",
      "Kar Yan Tam"
    ],
    "abstract": "This paper introduces Ready2Unlearn, a learning-time optimization approach\ndesigned to facilitate future unlearning processes. Unlike the majority of\nexisting unlearning efforts that focus on designing unlearning algorithms,\nwhich are typically implemented reactively when an unlearning request is made\nduring the model deployment phase, Ready2Unlearn shifts the focus to the\ntraining phase, adopting a \"forward-looking\" perspective. Building upon\nwell-established meta-learning principles, Ready2Unlearn proactively trains\nmachine learning models with unlearning readiness, such that they are well\nprepared and can handle future unlearning requests in a more efficient and\nprincipled manner. Ready2Unlearn is model-agnostic and compatible with any\ngradient ascent-based machine unlearning algorithms. We evaluate the method on\nboth vision and language tasks under various unlearning settings, including\nclass-wise unlearning and random data unlearning. Experimental results show\nthat by incorporating such preparedness at training time, Ready2Unlearn\nproduces an unlearning-ready model state, which offers several key advantages\nwhen future unlearning is required, including reduced unlearning time, improved\nretention of overall model capability, and enhanced resistance to the\ninadvertent recovery of forgotten data. We hope this work could inspire future\nefforts to explore more proactive strategies for equipping machine learning\nmodels with built-in readiness towards more reliable and principled machine\nunlearning.",
    "pdf_url": "http://arxiv.org/pdf/2505.10845v1",
    "published": "2025-05-16T04:33:59+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10844v2",
    "title": "Creativity or Brute Force? Using Brainteasers as a Window into the Problem-Solving Abilities of Large Language Models",
    "authors": [
      "Simeng Han",
      "Stephen Xia",
      "Grant Zhang",
      "Howard Dai",
      "Chen Liu",
      "Lichang Chen",
      "Hoang Huy Nguyen",
      "Hongyuan Mei",
      "Jiayuan Mao",
      "R. Thomas McCoy"
    ],
    "abstract": "Accuracy remains a standard metric for evaluating AI systems, but it offers\nlimited insight into how models arrive at their solutions. In this work, we\nintroduce a benchmark based on brainteasers written in long narrative form to\nprobe more deeply into the types of reasoning strategies that models use.\nBrainteasers are well-suited for this goal because they can be solved with\nmultiple approaches, such as a few-step solution that uses a creative insight\nor a longer solution that uses more brute force. We investigate large language\nmodels (LLMs) across multiple layers of reasoning, focusing not only on\ncorrectness but also on the quality and creativity of their solutions. We\ninvestigate many aspects of the reasoning process: (1) semantic parsing of the\nbrainteasers into precise mathematical competition style formats; (2)\ngenerating solutions from these mathematical forms; (3) self-correcting\nsolutions based on gold solutions; (4) producing step-by-step sketches of\nsolutions; and (5) making use of hints. We find that LLMs are in many cases\nable to find creative, insightful solutions to brainteasers, suggesting that\nthey capture some of the capacities needed to solve novel problems in creative\nways. Nonetheless, there also remain situations where they rely on brute force\ndespite the availability of more efficient, creative solutions, highlighting a\npotential direction for improvement in the reasoning abilities of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.10844v2",
    "published": "2025-05-16T04:23:34+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10843v1",
    "title": "Comparative Analysis of Black-Box Optimization Methods for Weather Intervention Design",
    "authors": [
      "Yuta Higuchi",
      "Rikuto Nagai",
      "Atsushi Okazaki",
      "Masaki Ogura",
      "Naoki Wakamiya"
    ],
    "abstract": "As climate change increases the threat of weather-related disasters, research\non weather control is gaining importance. The objective of weather control is\nto mitigate disaster risks by administering interventions with optimal timing,\nlocation, and intensity. However, the optimization process is highly\nchallenging due to the vast scale and complexity of weather phenomena, which\nintroduces two major challenges. First, obtaining accurate gradient information\nfor optimization is difficult. In addition, numerical weather prediction (NWP)\nmodels demand enormous computational resources, necessitating parameter\noptimization with minimal function evaluations. To address these challenges,\nthis study proposes a method for designing weather interventions based on\nblack-box optimization, which enables efficient exploration without requiring\ngradient information. The proposed method is evaluated in two distinct control\nscenarios: one-shot initial value intervention and sequential intervention\nbased on model predictive control. Furthermore, a comparative analysis is\nconducted among four representative black-box optimization methods in terms of\ntotal rainfall reduction. Experimental results show that Bayesian optimization\nachieves higher control effectiveness than the others, particularly in\nhigh-dimensional search spaces. These findings suggest that Bayesian\noptimization is a highly effective approach for weather intervention\ncomputation.",
    "pdf_url": "http://arxiv.org/pdf/2505.10843v1",
    "published": "2025-05-16T04:22:59+00:00",
    "categories": [
      "physics.ao-ph",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10842v1",
    "title": "Accelerating Parameter Initialization in Quantum Chemical Simulations via LSTM-FC-VQE",
    "authors": [
      "Ran-Yu Chang",
      "Yu-Cheng Lin",
      "Pei-Che Hsu",
      "Tsung-Wei Huang",
      "En-Jui Kuo"
    ],
    "abstract": "We present a meta-learning framework that leverages Long Short-Term Memory\n(LSTM) neural networks to accelerate parameter initialization in quantum\nchemical simulations using the Variational Quantum Eigensolver (VQE). By\ntraining the LSTM on optimized parameters from small molecules, the model\nlearns to predict high-quality initializations for larger systems, reducing the\nnumber of required VQE iterations. Our enhanced LSTM-FC-VQE architecture\nintroduces a fully connected layer, improving adaptability across molecules\nwith varying parameter sizes. Experimental results show that our approach\nachieves faster convergence and lower energy errors than traditional\ninitialization, demonstrating its practical potential for efficient quantum\nsimulations in the NISQ era.",
    "pdf_url": "http://arxiv.org/pdf/2505.10842v1",
    "published": "2025-05-16T04:19:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10841v1",
    "title": "RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects",
    "authors": [
      "Jaeguk Kim",
      "Jaewoo Park",
      "Keuntek Lee",
      "Nam Ik Cho"
    ],
    "abstract": "Estimating the 6D pose of unseen objects from monocular RGB images remains a\nchallenging problem, especially due to the lack of prior object-specific\nknowledge. To tackle this issue, we propose RefPose, an innovative approach to\nobject pose estimation that leverages a reference image and geometric\ncorrespondence as guidance. RefPose first predicts an initial pose by using\nobject templates to render the reference image and establish the geometric\ncorrespondence needed for the refinement stage. During the refinement stage,\nRefPose estimates the geometric correspondence of the query based on the\ngenerated references and iteratively refines the pose through a\nrender-and-compare approach. To enhance this estimation, we introduce a\ncorrelation volume-guided attention mechanism that effectively captures\ncorrelations between the query and reference images. Unlike traditional methods\nthat depend on pre-defined object models, RefPose dynamically adapts to new\nobject shapes by leveraging a reference image and geometric correspondence.\nThis results in robust performance across previously unseen objects. Extensive\nevaluation on the BOP benchmark datasets shows that RefPose achieves\nstate-of-the-art results while maintaining a competitive runtime.",
    "pdf_url": "http://arxiv.org/pdf/2505.10841v1",
    "published": "2025-05-16T04:17:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10840v2",
    "title": "Redshift Evolution of the Intrinsic Alignments of Early-Type Galaxies and Subhalos in the Horizon Run 5 Simulation",
    "authors": [
      "Sanghyeon Han",
      "Motonari Tonegawa",
      "Ho Seong Hwang",
      "Yohan Dubois",
      "Juhan Kim",
      "Yonghwi Kim",
      "Oh-Kyoung Kwon",
      "Jaehyun Lee",
      "Owain N. Snaith",
      "Brad K. Gibson",
      "Changbom Park"
    ],
    "abstract": "We investigate the redshift evolution of intrinsic alignments of the shapes\nof galaxies and subhalos with the large-scale structures of the universe using\nthe cosmological hydrodynamic simulation, $\\textit{Horizon Run 5}$. To this\nend, early-type galaxies are selected from the simulated galaxy catalogs based\non stellar mass and kinematic morphology. The shapes of galaxies and subhalos\nare computed using the reduced inertia tensor derived from mass-weighted\nparticle positions. We find that the misalignment between galaxies and their\ncorresponding dark-matter subhalos decreases over time. We further analyze the\ntwo-point correlation between galaxy or subhalo shapes and the large-scale\ndensity field traced by their spatial distribution, and quantify the amplitude\nusing the nonlinear alignment model across a wide redshift range from $z =\n0.625$ to $z = 2.5$. We find that the intrinsic alignment amplitude, $A_{\\rm\nNLA}$, of galaxies remains largely constant with redshift, whereas that of dark\nmatter subhalos exhibits moderate redshift evolution, with a power-law slope\nthat deviates from zero at a significance level exceeding $3\\sigma$.\nAdditionally, $A_{\\rm NLA}$ is found to depend on both the stellar mass and\nkinematic morphology of galaxies. Notably, our results are broadly consistent\nwith existing observational constraints. Our findings are in good agreement\nwith previous results of other cosmological simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.10840v2",
    "published": "2025-05-16T04:15:55+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10839v1",
    "title": "Alexandria: A Library of Pluralistic Values for Realtime Re-Ranking of Social Media Feeds",
    "authors": [
      "Akaash Kolluri",
      "Renn Su",
      "Farnaz Jahanbakhsh",
      "Dora Zhao",
      "Tiziano Piccardi",
      "Michael S. Bernstein"
    ],
    "abstract": "Social media feed ranking algorithms fail when they too narrowly focus on\nengagement as their objective. The literature has asserted a wide variety of\nvalues that these algorithms should account for as well -- ranging from\nwell-being to productive discourse -- far more than can be encapsulated by a\nsingle topic or theory. In response, we present a $\\textit{library of values}$\nfor social media algorithms: a pluralistic set of 78 values as articulated\nacross the literature, implemented into LLM-powered content classifiers that\ncan be installed individually or in combination for real-time re-ranking of\nsocial media feeds. We investigate this approach by developing a browser\nextension, $\\textit{Alexandria}$, that re-ranks the X/Twitter feed in real time\nbased on the user's desired values. Through two user studies, both qualitative\n(N=12) and quantitative (N=257), we found that diverse user needs require a\nlarge library of values, enabling more nuanced preferences and greater user\ncontrol. With this work, we argue that the values criticized as missing from\nsocial media ranking algorithms can be operationalized and deployed today\nthrough end-user tools.",
    "pdf_url": "http://arxiv.org/pdf/2505.10839v1",
    "published": "2025-05-16T04:13:04+00:00",
    "categories": [
      "cs.HC",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10838v1",
    "title": "LARGO: Latent Adversarial Reflection through Gradient Optimization for Jailbreaking LLMs",
    "authors": [
      "Ran Li",
      "Hao Wang",
      "Chengzhi Mao"
    ],
    "abstract": "Efficient red-teaming method to uncover vulnerabilities in Large Language\nModels (LLMs) is crucial. While recent attacks often use LLMs as optimizers,\nthe discrete language space make gradient-based methods struggle. We introduce\nLARGO (Latent Adversarial Reflection through Gradient Optimization), a novel\nlatent self-reflection attack that reasserts the power of gradient-based\noptimization for generating fluent jailbreaking prompts. By operating within\nthe LLM's continuous latent space, LARGO first optimizes an adversarial latent\nvector and then recursively call the same LLM to decode the latent into natural\nlanguage. This methodology yields a fast, effective, and transferable attack\nthat produces fluent and stealthy prompts. On standard benchmarks like AdvBench\nand JailbreakBench, LARGO surpasses leading jailbreaking techniques, including\nAutoDAN, by 44 points in attack success rate. Our findings demonstrate a potent\nalternative to agentic LLM prompting, highlighting the efficacy of interpreting\nand attacking LLM internals through gradient optimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.10838v1",
    "published": "2025-05-16T04:12:16+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10837v2",
    "title": "Spectral Biases, Starspot Morphology, and Dynamo Transitions on the Pre-Main Sequence: Insights from the X-Shooter WTTS Library",
    "authors": [
      "Facundo Pérez Paolino",
      "Jeff Bary",
      "Benjamin Horner",
      "Lynne A. Hillenbrand",
      "Adolfo Carvalho"
    ],
    "abstract": "Starspots are ubiquitous in young, low-mass stars, yet their impact on the\nspectral classification and fundamental parameter inference of pre-main\nsequence stars (PMS) has been largely overlooked. In this study, we demonstrate\nthat cool starspots systematically distort spectral morphology and bias the\neffective temperatures, surface gravities, and luminosities derived for\nnon-accreting Weak-Lined T Tauri Stars (WTTS). Using a sample of 56 WTTS with\nhigh-resolution, broad-band X-Shooter spectra, we perform two-temperature\nspectral fits that explicitly account for spot coverages and temperature\ncontrasts. These composite models consistently outperform traditional\nsingle-temperature fits, particularly in the 3350-4000 K regime, where spot\ncontributions dominate the red-optical and near-infrared flux. Moreover, we\npropose that surface gravity discrepancies between optical and infrared\nmeasurements are a natural consequence of spot-dominated emission in PMS stars.\nWe find that single-temperature models can overestimate effective temperatures\nby up to 700 K and underestimate log g by 1-2 dex. Using spot-corrected\neffective temperatures, we derive masses and ages from traditional, magnetic,\nand spotted evolutionary models, finding that spot-corrections systematically\nraise inferred masses by up to 80% and stellar ages by up to 0.5 dex. These\ndiscrepancies are strongest for stars in the 0.3-0.8 solar mass range. Using\nstarspots as a proxy for magnetic topology, we find evidence that a shift from\nlargely axisymmetric to non-axisymmetric magnetic fields dominated by\nsmall-scale structures coincides with the formation of a radiative core during\nPMS evolution, effectively distinguishing between the convective and interface\ndynamo regimes.",
    "pdf_url": "http://arxiv.org/pdf/2505.10837v2",
    "published": "2025-05-16T04:10:01+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10836v1",
    "title": "Multimodal Event Detection: Current Approaches and Defining the New Playground through LLMs and VLMs",
    "authors": [
      "Abhishek Dey",
      "Aabha Bothera",
      "Samhita Sarikonda",
      "Rishav Aryan",
      "Sanjay Kumar Podishetty",
      "Akshay Havalgi",
      "Gaurav Singh",
      "Saurabh Srivastava"
    ],
    "abstract": "In this paper, we study the challenges of detecting events on social media,\nwhere traditional unimodal systems struggle due to the rapid and multimodal\nnature of data dissemination. We employ a range of models, including unimodal\nModernBERT and ConvNeXt-V2, multimodal fusion techniques, and advanced\ngenerative models like GPT-4o, and LLaVA. Additionally, we also study the\neffect of providing multimodal generative models (such as GPT-4o) with a single\nmodality to assess their efficacy. Our results indicate that while multimodal\napproaches notably outperform unimodal counterparts, generative approaches\ndespite having a large number of parameters, lag behind supervised methods in\nprecision. Furthermore, we also found that they lag behind instruction-tuned\nmodels because of their inability to generate event classes correctly. During\nour error analysis, we discovered that common social media issues such as leet\nspeak, text elongation, etc. are effectively handled by generative approaches\nbut are hard to tackle using supervised approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.10836v1",
    "published": "2025-05-16T04:07:21+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10835v1",
    "title": "Quantifying urban and landfill methane emissions in the United States using TROPOMI satellite data",
    "authors": [
      "Xiaolin Wang",
      "Daniel J. Jacob",
      "Hannah Nesser",
      "Nicholas Balasus",
      "Lucas Estrada",
      "Melissa Sulprizio",
      "Daniel H. Cusworth",
      "Tia R. Scarpelli",
      "Zichong Chen",
      "James D. East",
      "Daniel J. Varon"
    ],
    "abstract": "Urban areas are major sources of methane due to population needs for\nlandfills, natural gas distribution, wastewater treatment, and residential\ncombustion. Here we apply an inversion of TROPOMI satellite observations of\natmospheric methane to quantify and attribute annual methane emissions at 12x12\nkm2 resolution for 12 major US urban areas in 2022. The US Environmental\nProtection Agency Greenhouse Gas Inventory (EPA GHGI) is used as prior\nestimate. Our results indicate that the GHGI underestimates methane emissions\nby 80% on average for the 12 urban areas, with 22%-290% underestimations in\nmost urban areas, except Los Angeles and Cincinnati where emissions are\noverestimated by 32%-37%. This is corroborated by independent surface-based\nobservations in the Northeast Corridor and Los Angeles. Landfills are the\nprincipal cause of urban emission underestimates, with downstream gas\nactivities contributing to a lesser extent than previously found. Examination\nof individual landfills other than in Los Angeles shows that emissions reported\nby facilities with gas collection and control systems to the Greenhouse Gas\nReporting Program (GHGRP) and used in the GHGI are too low by a factor of 4\nwhen using the prevailing recovery-first reporting method. This is because\nGHGRP-estimated gas collection efficiencies (average 70%, range 40-87%) are\nmuch higher than inferred from our work (average 38%, range 5-90%). Los Angeles\nlandfills have much higher collection efficiencies (average 78% in GHGRP; 85%\nin our work) than elsewhere in the US, suggesting that operational practices\nthere could help inform methane mitigation in other urban areas.",
    "pdf_url": "http://arxiv.org/pdf/2505.10835v1",
    "published": "2025-05-16T04:05:39+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10834v1",
    "title": "TACO: Rethinking Semantic Communications with Task Adaptation and Context Embedding",
    "authors": [
      "Achintha Wijesinghe",
      "Weiwei Wang",
      "Suchinthaka Wanninayaka",
      "Songyang Zhang",
      "Zhi Ding"
    ],
    "abstract": "Recent advancements in generative artificial intelligence have introduced\ngroundbreaking approaches to innovating next-generation semantic communication,\nwhich prioritizes conveying the meaning of a message rather than merely\ntransmitting raw data. A fundamental challenge in semantic communication lies\nin accurately identifying and extracting the most critical semantic information\nwhile adapting to downstream tasks without degrading performance, particularly\nwhen the objective at the receiver may evolve over time. To enable flexible\nadaptation to multiple tasks at the receiver, this work introduces a novel\nsemantic communication framework, which is capable of jointly capturing\ntask-specific information to enhance downstream task performance and contextual\ninformation. Through rigorous experiments on popular image datasets and\ncomputer vision tasks, our framework shows promising improvement compared to\nexisting work, including superior performance in downstream tasks, better\ngeneralizability, ultra-high bandwidth efficiency, and low reconstruction\nlatency.",
    "pdf_url": "http://arxiv.org/pdf/2505.10834v1",
    "published": "2025-05-16T04:03:52+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10833v2",
    "title": "MergeBench: A Benchmark for Merging Domain-Specialized LLMs",
    "authors": [
      "Yifei He",
      "Siqi Zeng",
      "Yuzheng Hu",
      "Rui Yang",
      "Tong Zhang",
      "Han Zhao"
    ],
    "abstract": "Model merging provides a scalable alternative to multi-task training by\ncombining specialized finetuned models through parameter arithmetic, enabling\nefficient deployment without the need for joint training or access to all task\ndata. While recent methods have shown promise, existing evaluations are limited\nin both model scale and task diversity, leaving open questions about their\napplicability to large, domain-specialized LLMs. To tackle the challenges, we\nintroduce MergeBench, a comprehensive evaluation suite designed to assess model\nmerging at scale. MergeBench builds on state-of-the-art open-source language\nmodels, including Llama and Gemma families at 2B to 9B scales, and covers five\nkey domains: instruction following, mathematics, multilingual understanding,\ncoding and safety. We standardize finetuning and evaluation protocols, and\nassess eight representative merging methods across multi-task performance,\nforgetting and runtime efficiency. Based on extensive experiments, we provide\npractical guidelines for algorithm selection and share insights showing that\nmodel merging tends to perform better on stronger base models, with techniques\nsuch as merging coefficient tuning and sparsification improving knowledge\nretention. However, several challenges remain, including the computational cost\non large models, the gap for in-domain performance compared to multi-task\nmodels, and the underexplored role of model merging in standard LLM training\npipelines. We hope MergeBench provides a foundation for future research to\nadvance the understanding and practical application of model merging. Our\nproject page is at\n\\href{https://yifei-he.github.io/mergebench/}{https://yifei-he.github.io/mergebench/}.",
    "pdf_url": "http://arxiv.org/pdf/2505.10833v2",
    "published": "2025-05-16T04:02:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10832v2",
    "title": "Learning When to Think: Shaping Adaptive Reasoning in R1-Style Models via Multi-Stage RL",
    "authors": [
      "Songjun Tu",
      "Jiahao Lin",
      "Qichao Zhang",
      "Xiangyu Tian",
      "Linjing Li",
      "Xiangyuan Lan",
      "Dongbin Zhao"
    ],
    "abstract": "Large reasoning models (LRMs) are proficient at generating explicit,\nstep-by-step reasoning sequences before producing final answers. However, such\ndetailed reasoning can introduce substantial computational overhead and\nlatency, particularly for simple problems. To address this over-thinking\nproblem, we explore how to equip LRMs with adaptive thinking capabilities:\nenabling them to dynamically decide whether or not to engage in explicit\nreasoning based on problem complexity. Building on R1-style distilled models,\nwe observe that inserting a simple ellipsis (\"...\") into the prompt can\nstochastically trigger either a thinking or no-thinking mode, revealing a\nlatent controllability in the reasoning behavior. Leveraging this property, we\npropose AutoThink, a multi-stage reinforcement learning (RL) framework that\nprogressively optimizes reasoning policies via stage-wise reward shaping.\nAutoThink learns to invoke explicit reasoning only when necessary, while\ndefaulting to succinct responses for simpler tasks. Experiments on five\nmainstream mathematical benchmarks demonstrate that AutoThink achieves\nfavorable accuracy-efficiency trade-offs compared to recent prompting and\nRL-based pruning methods. It can be seamlessly integrated into any R1-style\nmodel, including both distilled and further fine-tuned variants. Notably,\nAutoThink improves relative accuracy by 6.4 percent while reducing token usage\nby 52 percent on DeepSeek-R1-Distill-Qwen-1.5B, establishing a scalable and\nadaptive reasoning paradigm for LRMs. Project Page:\nhttps://github.com/ScienceOne-AI/AutoThink.",
    "pdf_url": "http://arxiv.org/pdf/2505.10832v2",
    "published": "2025-05-16T04:01:57+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10830v1",
    "title": "A Discretization Approach for Bilevel Optimization with Low-Dimensional and Non-Convex Lower-Level",
    "authors": [
      "Xiaotian Jiang",
      "Ioannis Tsaknakis",
      "Prashant Khanduri",
      "Mingyi Hong"
    ],
    "abstract": "Bilevel optimization (BLO) problem, where two optimization problems (referred\nto as upper- and lower-level problems) are coupled hierarchically, has wide\napplications in areas such as machine learning and operations research.\nRecently, many first-order algorithms have been developed for solving bilevel\nproblems with strongly convex and/or unconstrained lower-level problems; this\nspecial structure of the lower-level problem is needed to ensure the\ntractability of gradient computation (among other reasons). In this work, we\ndeal with a class of more challenging BLO problems where the lower-level\nproblem is non-convex and constrained. We propose a novel approach that\napproximates the value function of the lower-level problem by first sampling a\nset of feasible solutions and then constructing an equivalent convex\noptimization problem. This convexified value function is then used to construct\na penalty function for the original BLO problem. We analyze the properties of\nthe original BLO problem and the newly constructed penalized problem by\ncharacterizing the relation between their KKT points, as well as the local and\nglobal minima of the two problems. We then develop a gradient descent-based\nalgorithm to solve the reformulated problem, and establish its finite-time\nconvergence guarantees. Finally, we conduct numerical experiments to\ncorroborate the theoretical performance of the proposed algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.10830v1",
    "published": "2025-05-16T04:00:31+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10831v2",
    "title": "Creating General User Models from Computer Use",
    "authors": [
      "Omar Shaikh",
      "Shardul Sapkota",
      "Shan Rizvi",
      "Eric Horvitz",
      "Joon Sung Park",
      "Diyi Yang",
      "Michael S. Bernstein"
    ],
    "abstract": "Human-computer interaction has long imagined technology that understands\nus-from our preferences and habits, to the timing and purpose of our everyday\nactions. Yet current user models remain fragmented, narrowly tailored to\nspecific apps, and incapable of the flexible reasoning required to fulfill\nthese visions. This paper presents an architecture for a general user model\n(GUM) that learns about you by observing any interaction you have with your\ncomputer. The GUM takes as input any unstructured observation of a user (e.g.,\ndevice screenshots) and constructs confidence-weighted propositions that\ncapture user knowledge and preferences. GUMs can infer that a user is preparing\nfor a wedding they're attending from messages with a friend. Or recognize that\na user is struggling with a collaborator's feedback on a draft by observing\nmultiple stalled edits and a switch to reading related work. GUMs introduce an\narchitecture that infers new propositions about a user from multimodal\nobservations, retrieves related propositions for context, and continuously\nrevises existing propositions. To illustrate the breadth of applications that\nGUMs enable, we demonstrate how they augment chat-based assistants with\ncontext, manage OS notifications to selectively surface important information,\nand enable interactive agents that adapt to preferences across apps. We also\ninstantiate proactive assistants (GUMBOs) that discover and execute useful\nsuggestions on a user's behalf using their GUM. In our evaluations, we find\nthat GUMs make calibrated and accurate inferences about users, and that\nassistants built on GUMs proactively identify and perform actions that users\nwouldn't think to request explicitly. Altogether, GUMs introduce methods that\nleverage multimodal models to understand unstructured context, enabling\nlong-standing visions of HCI and entirely new interactive systems that\nanticipate user needs.",
    "pdf_url": "http://arxiv.org/pdf/2505.10831v2",
    "published": "2025-05-16T04:00:31+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10829v1",
    "title": "Enhancing Low-Resource Minority Language Translation with LLMs and Retrieval-Augmented Generation for Cultural Nuances",
    "authors": [
      "Chen-Chi Chang",
      "Chong-Fu Li",
      "Chu-Hsuan Lee",
      "Hung-Shin Lee"
    ],
    "abstract": "This study investigates the challenges of translating low-resource languages\nby integrating Large Language Models (LLMs) with Retrieval-Augmented Generation\n(RAG). Various model configurations were tested on Hakka translations, with\nBLEU scores ranging from 12% (dictionary-only) to 31% (RAG with Gemini 2.0).\nThe best-performing model (Model 4) combined retrieval and advanced language\nmodeling, improving lexical coverage, particularly for specialized or\nculturally nuanced terms, and enhancing grammatical coherence. A two-stage\nmethod (Model 3) using dictionary outputs refined by Gemini 2.0 achieved a BLEU\nscore of 26%, highlighting iterative correction's value and the challenges of\ndomain-specific expressions. Static dictionary-based approaches struggled with\ncontext-sensitive content, demonstrating the limitations of relying solely on\npredefined resources. These results emphasize the need for curated resources,\ndomain knowledge, and ethical collaboration with local communities, offering a\nframework that improves translation accuracy and fluency while supporting\ncultural preservation.",
    "pdf_url": "http://arxiv.org/pdf/2505.10829v1",
    "published": "2025-05-16T03:59:14+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10828v1",
    "title": "K-polystability and reduced uniform K-stability of log Fano cone singularities",
    "authors": [
      "Linsheng Wang"
    ],
    "abstract": "We prove that a log Fano cone $(X,\\Delta,\\xi_0)$ satisfying\n$\\delta_\\mathbb{T}(X,\\Delta,\\xi_0)\\ge 1$ is K-polystable for normal test\nconfigurations if and only if it is K-polystable for special test\nconfigurations. We also establish the reduced uniform K-stability of\n$(X,\\Delta,\\xi_0)$ and show that it is equivalent to K-polystability.",
    "pdf_url": "http://arxiv.org/pdf/2505.10828v1",
    "published": "2025-05-16T03:57:55+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10827v1",
    "title": "NeuSEditor: From Multi-View Images to Text-Guided Neural Surface Edits",
    "authors": [
      "Nail Ibrahimli",
      "Julian F. P. Kooij",
      "Liangliang Nan"
    ],
    "abstract": "Implicit surface representations are valued for their compactness and\ncontinuity, but they pose significant challenges for editing. Despite recent\nadvancements, existing methods often fail to preserve identity and maintain\ngeometric consistency during editing. To address these challenges, we present\nNeuSEditor, a novel method for text-guided editing of neural implicit surfaces\nderived from multi-view images. NeuSEditor introduces an identity-preserving\narchitecture that efficiently separates scenes into foreground and background,\nenabling precise modifications without altering the scene-specific elements.\nOur geometry-aware distillation loss significantly enhances rendering and\ngeometric quality. Our method simplifies the editing workflow by eliminating\nthe need for continuous dataset updates and source prompting. NeuSEditor\noutperforms recent state-of-the-art methods like PDS and InstructNeRF2NeRF,\ndelivering superior quantitative and qualitative results. For more visual\nresults, visit: neuseditor.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2505.10827v1",
    "published": "2025-05-16T03:57:01+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.15831v1",
    "title": "Ricci Matrix Comparison for Graph Alignment: A DMC Variation",
    "authors": [
      "Ashley Wang",
      "Peter Chin"
    ],
    "abstract": "The graph alignment problem explores the concept of node correspondence and\nits optimality. In this paper, we focus on purely geometric graph alignment\nmethods, namely our newly proposed Ricci Matrix Comparison (RMC) and its\noriginal form, Degree Matrix Comparison (DMC). To formulate a\nRicci-curvature-based graph alignment situation, we start with discussing\ndifferent ideas of constructing one of the most typical and important\ntopological objects, the torus, and then move on to introducing the RMC based\non DMC with theoretical motivations. Lastly, we will present to the reader\nexperimental results on a torus and a complex protein-protein interaction\nnetwork that indicate the potential of applying a differential-geometric view\nto graph alignment. Results show that a direct variation of DMC using Ricci\ncurvature can help with identifying holes in tori and aligning line graphs of a\ncomplex network at 80-90+% accuracy. This paper contributes a new perspective\nto the field of graph alignment and partially shows the validity of the\nprevious DMC method.",
    "pdf_url": "http://arxiv.org/pdf/2505.15831v1",
    "published": "2025-05-16T03:56:40+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10826v1",
    "title": "Free boundary minimal annuli in $S^2_+\\times S^1$",
    "authors": [
      "Pak Tung Ho",
      "Juncheol Pyo",
      "Keomkyo Seo"
    ],
    "abstract": "Let $M$ be a compact 3-dimensional Riemannian manifold with nonnegative Ricci\ncurvature and a nonempty boundary $\\partial M$. Fraser and Li \\cite{Fraser&Li}\nestablished a compactness theorem for the space of compact, properly embedded\nminimal surfaces of fixed topological type in $M$ with a free boundary on\n$\\partial M$, assuming that $\\partial M$ is strictly convex with respect to the\ninward unit normal. In this paper, we show that the strict convexity condition\non $\\partial M$ cannot be relaxed.",
    "pdf_url": "http://arxiv.org/pdf/2505.10826v1",
    "published": "2025-05-16T03:55:27+00:00",
    "categories": [
      "math.DG",
      "Primary 53A10, Secondary 53C42"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01977v1",
    "title": "Towards Unsupervised Training of Matching-based Graph Edit Distance Solver via Preference-aware GAN",
    "authors": [
      "Wei Huang",
      "Hanchen Wang",
      "Dong Wen",
      "Shaozhen Ma",
      "Wenjie Zhang",
      "Xuemin Lin"
    ],
    "abstract": "Graph Edit Distance (GED) is a fundamental graph similarity metric widely\nused in various applications. However, computing GED is an NP-hard problem.\nRecent state-of-the-art hybrid GED solver has shown promising performance by\nformulating GED as a bipartite graph matching problem, then leveraging a\ngenerative diffusion model to predict node matching between two graphs, from\nwhich both the GED and its corresponding edit path can be extracted using a\ntraditional algorithm. However, such methods typically rely heavily on\nground-truth supervision, where the ground-truth labels are often costly to\nobtain in real-world scenarios. In this paper, we propose GEDRanker, a novel\nunsupervised GAN-based framework for GED computation. Specifically, GEDRanker\nconsists of a matching-based GED solver and introduces an interpretable\npreference-aware discriminator with an effective training strategy to guide the\nmatching-based GED solver toward generating high-quality node matching without\nthe need for ground-truth labels. Extensive experiments on benchmark datasets\ndemonstrate that our GEDRanker enables the matching-based GED solver to achieve\nnear-optimal solution quality without any ground-truth supervision.",
    "pdf_url": "http://arxiv.org/pdf/2506.01977v1",
    "published": "2025-05-16T03:45:31+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10825v1",
    "title": "A High-Performance Thermal Infrared Object Detection Framework with Centralized Regulation",
    "authors": [
      "Jinke Li",
      "Yue Wu",
      "Xiaoyan Yang"
    ],
    "abstract": "Thermal Infrared (TIR) technology involves the use of sensors to detect and\nmeasure infrared radiation emitted by objects, and it is widely utilized across\na broad spectrum of applications. The advancements in object detection methods\nutilizing TIR images have sparked significant research interest. However, most\ntraditional methods lack the capability to effectively extract and fuse\nlocal-global information, which is crucial for TIR-domain feature attention. In\nthis study, we present a novel and efficient thermal infrared object detection\nframework, known as CRT-YOLO, that is based on centralized feature regulation,\nenabling the establishment of global-range interaction on TIR information. Our\nproposed model integrates efficient multi-scale attention (EMA) modules, which\nadeptly capture long-range dependencies while incurring minimal computational\noverhead. Additionally, it leverages the Centralized Feature Pyramid (CFP)\nnetwork, which offers global regulation of TIR features. Extensive experiments\nconducted on two benchmark datasets demonstrate that our CRT-YOLO model\nsignificantly outperforms conventional methods for TIR image object detection.\nFurthermore, the ablation study provides compelling evidence of the\neffectiveness of our proposed modules, reinforcing the potential impact of our\napproach on advancing the field of thermal infrared object detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.10825v1",
    "published": "2025-05-16T03:43:24+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10824v1",
    "title": "Textured mesh Quality Assessment using Geometry and Color Field Similarity",
    "authors": [
      "Kaifa Yang",
      "Qi Yang",
      "Zhu Li",
      "Yiling Xu"
    ],
    "abstract": "Textured mesh quality assessment (TMQA) is critical for various 3D mesh\napplications. However, existing TMQA methods often struggle to provide accurate\nand robust evaluations. Motivated by the effectiveness of fields in\nrepresenting both 3D geometry and color information, we propose a novel\npoint-based TMQA method called field mesh quality metric (FMQM). FMQM utilizes\nsigned distance fields and a newly proposed color field named nearest surface\npoint color field to realize effective mesh feature description. Four features\nrelated to visual perception are extracted from the geometry and color fields:\ngeometry similarity, geometry gradient similarity, space color distribution\nsimilarity, and space color gradient similarity. Experimental results on three\nbenchmark datasets demonstrate that FMQM outperforms state-of-the-art (SOTA)\nTMQA metrics. Furthermore, FMQM exhibits low computational complexity, making\nit a practical and efficient solution for real-world applications in 3D\ngraphics and visualization. Our code is publicly available at:\nhttps://github.com/yyyykf/FMQM.",
    "pdf_url": "http://arxiv.org/pdf/2505.10824v1",
    "published": "2025-05-16T03:41:24+00:00",
    "categories": [
      "cs.GR",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10823v2",
    "title": "From Embeddings to Accuracy: Comparing Foundation Models for Radiographic Classification",
    "authors": [
      "Xue Li",
      "Jameson Merkow",
      "Noel C. F. Codella",
      "Alberto Santamaria-Pang",
      "Naiteek Sangani",
      "Alexander Ersoy",
      "Christopher Burt",
      "John W. Garrett",
      "Richard J. Bruce",
      "Joshua D. Warner",
      "Tyler Bradshaw",
      "Ivan Tarapov",
      "Matthew P. Lungren",
      "Alan B. McMillan"
    ],
    "abstract": "Foundation models provide robust embeddings for diverse tasks, including\nmedical imaging. We evaluate embeddings from seven general and medical-specific\nfoundation models (e.g., DenseNet121, BiomedCLIP, MedImageInsight, Rad-DINO,\nCXR-Foundation) for training lightweight adapters in multi-class radiography\nclassification. Using a dataset of 8,842 radiographs across seven classes, we\ntrained adapters with algorithms like K-Nearest Neighbors, logistic regression,\nSVM, random forest, and MLP. The combination of MedImageInsight embeddings with\nan SVM or MLP adapter achieved the highest mean area under the curve (mAUC) of\n93.1%. This performance was statistically superior to other models, including\nMedSigLIP with an MLP (91.0%), Rad-DINO with an SVM (90.7%), and CXR-Foundation\nwith logistic regression (88.6%). In contrast, models like BiomedCLIP (82.8%)\nand Med-Flamingo (78.5%) showed lower performance. Crucially, these lightweight\nadapters are computationally efficient, training in minutes and performing\ninference in seconds on a CPU, making them practical for clinical use. A\nfairness analysis of the top-performing MedImageInsight adapter revealed\nminimal performance disparities across patient gender (within 1.8%) and age\ngroups (std. dev < 1.4%), with no significant statistical differences. These\nfindings confirm that embeddings from specialized foundation models,\nparticularly MedImageInsight, can power accurate, efficient, and equitable\ndiagnostic tools using simple, lightweight adapters.",
    "pdf_url": "http://arxiv.org/pdf/2505.10823v2",
    "published": "2025-05-16T03:39:46+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10822v1",
    "title": "Distilled Circuits: A Mechanistic Study of Internal Restructuring in Knowledge Distillation",
    "authors": [
      "Reilly Haskins",
      "Benjamin Adams"
    ],
    "abstract": "Knowledge distillation compresses a larger neural model (teacher) into\nsmaller, faster student models by training them to match teacher outputs.\nHowever, the internal computational transformations that occur during this\nprocess remain poorly understood. We apply techniques from mechanistic\ninterpretability to analyze how internal circuits, representations, and\nactivation patterns differ between teacher and student. Focusing on GPT2-small\nand its distilled counterpart DistilGPT2, we find that student models\nreorganize, compress, and discard teacher components, often resulting in\nstronger reliance on fewer individual components. To quantify functional\nalignment beyond output similarity, we introduce an alignment metric based on\ninfluence-weighted component similarity, validated across multiple tasks. Our\nfindings reveal that while knowledge distillation preserves broad functional\nbehaviors, it also causes significant shifts in internal computation, with\nimportant implications for the robustness and generalization capacity of\ndistilled models.",
    "pdf_url": "http://arxiv.org/pdf/2505.10822v1",
    "published": "2025-05-16T03:37:40+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10821v1",
    "title": "The link between galaxy structure properties and star formation in local galaxies",
    "authors": [
      "Zhimin Zhou",
      "Wenwen Wang"
    ],
    "abstract": "To investigate the role of morphology in galaxy evolution, we analyze the\nrelationships between galaxy structure, star formation, and HI gas content.\nUsing multi-band images from the DESI Legacy Imaging Surveys, we perform\ndetailed structural decompositions on a representative local galaxy sample from\nxGASS. Structural components and color properties are examined as functions of\ndeviations from the star formation main sequence ($\\rm \\Delta SFR_{MS}$) and HI\ngas deficiency ($\\rm \\Delta f_{HI}$). We find that bulge fractions decrease\nwith higher $\\rm \\Delta SFR_{MS}$ and lower stellar mass, indicating that\nstar-forming galaxies are predominantly disc-dominated, while quiescent\ngalaxies are bulge-dominated. The slope of the color ($g-r$) versus $\\rm \\Delta\nSFR_{MS}$ relationship decreases from low to high stellar masses and from outer\nto inner regions, with greater color variation in massive galaxies. Color\ngradients are predominantly negative, becoming shallower in lower-mass galaxies\nand in the outer disk regions. We also identify inflection points in the color\ngradient and bulge fraction relations with $\\rm \\Delta SFR_{MS}$, with\nmain-sequence galaxies having the lowest bulge fractions and steepest color\ngradients. At fixed stellar mass, we observe only a slight correlation between\nbulge fraction and HI deficiency. However, outer disk colors show a stronger\ndependence on HI content than inner regions, and color gradients flatten as\n$\\rm \\Delta f_{HI}$ increases. These results suggest that HI gas is more\nclosely linked to star-forming, disc-dominated systems, supporting the idea\nthat gas accretion fuels star formation primarily in galaxy disks.",
    "pdf_url": "http://arxiv.org/pdf/2505.10821v1",
    "published": "2025-05-16T03:37:01+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.10820v3",
    "title": "Large-Scale Quantum Device Benchmarking via LXEB with Particle-Number-Conserving Random Quantum Circuits",
    "authors": [
      "Takumi Kaneda",
      "Keisuke Fujii",
      "Hiroshi Ueda"
    ],
    "abstract": "Linear cross-entropy benchmarking (LXEB) with random quantum circuits is a\nstandard method for evaluating quantum computers. However, LXEB requires\nclassically simulating the ideal output distribution of a given quantum circuit\nwith high numerical precision, which becomes infeasible beyond approximately 50\nqubits, even on state-of-the-art supercomputers. As a result, LXEB cannot be\ndirectly applied to evaluate large-scale quantum devices, which now exceed 100\nqubits and continue to grow rapidly in size. To address this limitation, we\nintroduce a constraint known as particle-number conservation into the random\nquantum circuits used for benchmarking. This restriction significantly reduces\nthe size of the Hilbert space for a fixed particle number, enabling classical\nsimulations of circuits with over 100 qubits when the particle number is\n$O(1)$. Furthermore, we propose a modified version of LXEB, called MLXEB, which\nenables fidelity estimation under particle-number-conserving dynamics. Through\nnumerical simulations, we investigate the conditions under which MLXEB provides\naccurate fidelity estimates.",
    "pdf_url": "http://arxiv.org/pdf/2505.10820v3",
    "published": "2025-05-16T03:31:06+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10819v2",
    "title": "PoE-World: Compositional World Modeling with Products of Programmatic Experts",
    "authors": [
      "Wasu Top Piriyakulkij",
      "Yichao Liang",
      "Hao Tang",
      "Adrian Weller",
      "Marta Kryven",
      "Kevin Ellis"
    ],
    "abstract": "Learning how the world works is central to building AI agents that can adapt\nto complex environments. Traditional world models based on deep learning demand\nvast amounts of training data, and do not flexibly update their knowledge from\nsparse observations. Recent advances in program synthesis using Large Language\nModels (LLMs) give an alternate approach which learns world models represented\nas source code, supporting strong generalization from little data. To date,\napplication of program-structured world models remains limited to natural\nlanguage and grid-world domains. We introduce a novel program synthesis method\nfor effectively modeling complex, non-gridworld domains by representing a world\nmodel as an exponentially-weighted product of programmatic experts (PoE-World)\nsynthesized by LLMs. We show that this approach can learn complex, stochastic\nworld models from just a few observations. We evaluate the learned world models\nby embedding them in a model-based planning agent, demonstrating efficient\nperformance and generalization to unseen levels on Atari's Pong and Montezuma's\nRevenge. We release our code and display the learned world models and videos of\nthe agent's gameplay at https://topwasu.github.io/poe-world.",
    "pdf_url": "http://arxiv.org/pdf/2505.10819v2",
    "published": "2025-05-16T03:28:42+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10818v1",
    "title": "Competition and Investment Model of Wealth Distribution",
    "authors": [
      "Yuri Ono",
      "Atsushi Ishida"
    ],
    "abstract": "Explaining empirically observed wealth and income distributions, featuring\npower-law tails alongside gamma or log-normal bulk shapes, challenges models\nthat focus on either pairwise competition or individual investment mechanisms.\nThis study proposes and analyzes a unified model that integrates pairwise\ncompetition and individual investment via an adjustable parameter, $\\alpha$.\nNumerical simulations are conducted to analyze the model's Gini coefficient and\ndistributional shapes using the complementary cumulative distribution function\nand goodness-of-fit tests. Results show that the model captures a systematic\ntransition in the bulk distribution from gamma like (low $\\alpha$) to\nlog-normal like (high $\\alpha$). Additionally, intermediate levels of mechanism\nmixing can reduce inequality compared with the original mechanisms. However, it\nis difficult to distinguish heavy tails consistent with power-laws from\nlog-normal tails. These findings highlight the importance of considering the\ninteraction between different economic mechanisms but suggest that accurately\nreplicating the empirical power-law tail requires more than the simple\ncombination investigated.",
    "pdf_url": "http://arxiv.org/pdf/2505.10818v1",
    "published": "2025-05-16T03:27:02+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10817v1",
    "title": "Observation of unexpected band splitting and magnetically-induced band structure reconstruction in TbTi$_3$Bi$_4$",
    "authors": [
      "Yevhen Kushnirenko",
      "Lin-Lin Wang",
      "Xiaoyi Su",
      "Benjamin Schrunk",
      "Evan O'Leary",
      "Andrew Eaton",
      "P. C. Canfield",
      "Adam Kaminski"
    ],
    "abstract": "The magnetic Kagome materials are a promising platform to study the interplay\nbetween magnetism, topology, and correlated electronic phenomena. Among these\nmaterials, the RTi3Bi4 family received a great deal of attention recently\nbecause of its chemical versatility and wide range of magnetic properties.\nHere, we use angle-resolved photoemission spectroscopy measurements and density\nfunctional theory calculations to investigate the electronic structure of\nTbTi3Bi4 in paramagnetic and antiferromagnetic phases. Our experimental results\nshow the presence of unidirectional band splitting of unknown nature in both\nphases. In addition, we observed a complex reconstruction of the band structure\nin the antiferromagnetic phase. Some aspects of this reconstruction are\nconsistent with effects of additional periodicity introduced by the magnetic\nordering vector, while the nature of several other features remains unknown.",
    "pdf_url": "http://arxiv.org/pdf/2505.10817v1",
    "published": "2025-05-16T03:24:36+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.10816v1",
    "title": "mmMirror: Device Free mmWave Indoor NLoS Localization Using Van-Atta-Array IRS",
    "authors": [
      "Yihe Yan",
      "Zhenguo Shi",
      "Yanxiang Wang",
      "Cheng Jiang",
      "Chun Tung Chou",
      "Wen Hu"
    ],
    "abstract": "Industry 4.0 is transforming manufacturing and logistics by integrating\nrobots into shared human environments, such as factories, warehouses, and\nhealthcare facilities. However, the risk of human-robot collisions, especially\nin Non-Line-of-Sight (NLoS) scenarios like around corners, remains a critical\nchallenge. Existing solutions, such as vision-based and LiDAR systems, often\nfail under occlusion, lighting constraints, or privacy concerns, while RF-based\nsystems are limited by range and accuracy.\n  To address these limitations, we propose mmMirror, a novel system leveraging\na Van Atta Array-based millimeter-wave (mmWave) reconfigurable intelligent\nreflecting surface (IRS) for precise, device-free NLoS localization. mmMirror\nintegrates seamlessly with existing frequency-modulated continuous-wave (FMCW)\nradars and offers: (i) robust NLoS localization with centimeter-level accuracy\nat ranges up to 3 m, (ii) seamless uplink and downlink communication between\nradar and IRS, (iii) support for multi-radar and multi-target scenarios via\ndynamic beam steering, and (iv) reduced scanning latency through adaptive time\nslot allocation. Implemented using commodity 24 GHz radars and a PCB-based IRS\nprototype, mmMirror demonstrates its potential in enabling safe human-robot\ninteractions in dynamic and complex environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.10816v1",
    "published": "2025-05-16T03:20:27+00:00",
    "categories": [
      "cs.NI",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10815v1",
    "title": "Enhancing Secrecy Energy Efficiency in RIS-Aided Aerial Mobile Edge Computing Networks: A Deep Reinforcement Learning Approach",
    "authors": [
      "Aly Sabri Abdalla",
      "Vuk Marojevic"
    ],
    "abstract": "This paper studies the problem of securing task offloading transmissions from\nground users against ground eavesdropping threats. Our study introduces a\nreconfigurable intelligent surface (RIS)-aided unmanned aerial vehicle\n(UAV)-mobile edge computing (MEC) scheme to enhance the secure task offloading\nwhile minimizing the energy consumption of the UAV subject to task completion\nconstraints. Leveraging a data-driven approach, we propose a comprehensive\noptimization strategy that jointly optimizes the aerial MEC (AMEC)'s\ntrajectory, task offloading partitioning, UE transmission scheduling, and RIS\nphase shifts. Our objective centers on optimizing the secrecy energy efficiency\n(SEE) of UE task offloading transmissions while preserving the AMEC's energy\nresources and meeting the task completion time requirements. Numerical results\nshow that the proposed solution can effectively safeguard legitimate task\noffloading transmissions while preserving AMEC energy.",
    "pdf_url": "http://arxiv.org/pdf/2505.10815v1",
    "published": "2025-05-16T03:18:46+00:00",
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10814v1",
    "title": "Distribution Regression with Censored Selection",
    "authors": [
      "Ivan Fernandez-Val",
      "Seoyun Hong"
    ],
    "abstract": "We develop a distribution regression model with a censored selection rule,\noffering a semi-parametric generalization of the Heckman selection model. Our\napproach applies to the entire distribution, extending beyond the mean or\nmedian, accommodates non-Gaussian error structures, and allows for\nheterogeneous effects of covariates on both the selection and outcome\ndistributions. By employing a censored selection rule, our model can uncover\nricher selection patterns according to both outcome and selection variables,\ncompared to the binary selection case. We analyze identification, estimation,\nand inference of model functionals such as sorting parameters and distributions\npurged of sample selection. An application to labor supply using data from the\nUK reveals different selection patterns into full-time and overtime work across\ngender, marital status, and time. Additionally, decompositions of wage\ndistributions by gender show that selection effects contribute to a decrease in\nthe observed gender wage gap at low quantiles and an increase in the gap at\nhigh quantiles for full-time workers. The observed gender wage gap among\novertime workers is smaller, which may be driven by different selection\nbehaviors into overtime work across genders.",
    "pdf_url": "http://arxiv.org/pdf/2505.10814v1",
    "published": "2025-05-16T03:17:17+00:00",
    "categories": [
      "econ.EM",
      "stat.ME"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2505.11559v1",
    "title": "Analysis and Resilience of the U.S. Flight Network",
    "authors": [
      "Sushrit Kafle",
      "Shreejan Pandey"
    ],
    "abstract": "Air travel is one of the most widely used transportation services in the\nUnited States. This paper analyzes the U.S. Flight Network (USFN) using complex\nnetwork theory by exploring how the network's topology contributes to its\nefficiency and vulnerability. This is done by examining the structural\nproperties, degree distributions, and community structures in the network. USFN\nwas observed to follow power-law distribution and falls under the anomalous\nregime, suggesting that the network is hub dominant. Compared to null networks,\nUSFN has a higher clustering coefficient and modularity. Various percolation\ntest revealed that USFN is vulnerable to targeted attacks and is susceptible to\ncomplete cascading failure if one of the major hubs fails. The overall results\nsuggest that while the USFN is designed for efficiency, it is highly vulnerable\nto disruptions. Protecting key hub airports is important to make the network\nmore robust and prevent large-scale failures.",
    "pdf_url": "http://arxiv.org/pdf/2505.11559v1",
    "published": "2025-05-16T03:13:54+00:00",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10813v2",
    "title": "Attosecond transient absorption spectroscopy in monolayer hexagonal boron nitride",
    "authors": [
      "Jiayu Yan",
      "Chenkai Zhu",
      "Rongxiang Zhang",
      "Xiaohui Zhao",
      "Fulong Dong"
    ],
    "abstract": "We simulate the attosecond transient absorption spectroscopy (ATAS) of\nmonolayer hexagonal boron nitride (hBN) using the time-dependent density\nfunctional theory and two-band density-matrix equations within the\ntight-binding approximation. The simulation results from the two methods are\nqualitatively consistent. We focus on the fishbone structure around the gap\nenergy of the M point, which exhibits a temporal period equal to that of the\npump laser. To gain deeper insight into this structure, we simplify the\ntwo-band model to a single-electron model located at the M point, allowing us\nto derive an analytical expression that can qualitatively reproduce the\nnumerical results. By isolating the influence of the Berry connection on the\nATAS, our analytical results reveal that both the interband transition dipole\nmoments and the Berry connection play important roles in the fishbone structure\nof the ATAS. Moreover, we also have investigated the dependence of ATAS on the\ngap energy based the tight-binding approximation. The results demonstrate that\nthe ATAS intensity is enhanced as the gap energy increases, in agreement with\nour analytical prediction. Our study may shed light on the generation mechanism\nof the fishbone structure of the ATAS in hBN.",
    "pdf_url": "http://arxiv.org/pdf/2505.10813v2",
    "published": "2025-05-16T03:13:40+00:00",
    "categories": [
      "physics.atom-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10812v1",
    "title": "RAN Tester UE: An Automated Declarative UE Centric Security Testing Platform",
    "authors": [
      "Charles Marion Ueltschey",
      "Joshua Moore",
      "Aly Sabri Abdalla",
      "Vuk Marojevic"
    ],
    "abstract": "Cellular networks require strict security procedures and measures across\nvarious network components, from core to radio access network (RAN) and\nend-user devices. As networks become increasingly complex and interconnected,\nas in O-RAN deployments, they are exposed to a numerous security threats.\nTherefore, ensuring robust security is critical for O-RAN to protect network\nintegrity and safeguard user data. This requires rigorous testing methodologies\nto mitigate threats. This paper introduces an automated, adaptive, and scalable\nuser equipment (UE) based RAN security testing framework designed to address\nthe shortcomings of existing RAN testing solutions. Experimental results on a\n5G software radio testbed built with commercial off-the-shelf hardware and open\nsource software validate the efficiency and reproducibility of sample security\ntest procedures developed on the RAN Tester UE framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.10812v1",
    "published": "2025-05-16T03:12:38+00:00",
    "categories": [
      "cs.CR",
      "cs.SE",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10811v1",
    "title": "Optimal $\\mathbb{H}_2$ Control with Passivity-Constrained Feedback: Convex Approach",
    "authors": [
      "J. T. Scruggs"
    ],
    "abstract": "We consider the $\\mathbb{H}_2$-optimal feedback control problem, for the case\nin which the plant is passive with bounded $\\mathbb{L}_2$ gain, and the\nfeedback law is constrained to be output-strictly passive. In this\ncircumstance, we show that this problem distills to a convex optimal control\nproblem, in which the optimization domain is the associated Youla parameter for\nthe closed-loop system. This enables the globally-optimal controller to be\nsolved as an infinite-dimensional but convex optimization. Near-optimal\nsolutions may be found through the finite-dimensional convex truncation of this\ninfinite-dimensional domain. The idea is demonstrated on a simple vibration\nsuppression example.",
    "pdf_url": "http://arxiv.org/pdf/2505.10811v1",
    "published": "2025-05-16T03:11:01+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10810v1",
    "title": "MoCLIP: Motion-Aware Fine-Tuning and Distillation of CLIP for Human Motion Generation",
    "authors": [
      "Gabriel Maldonado",
      "Armin Danesh Pazho",
      "Ghazal Alinezhad Noghre",
      "Vinit Katariya",
      "Hamed Tabkhi"
    ],
    "abstract": "Human motion generation is essential for fields such as animation, robotics,\nand virtual reality, requiring models that effectively capture motion dynamics\nfrom text descriptions. Existing approaches often rely on Contrastive\nLanguage-Image Pretraining (CLIP)-based text encoders, but their training on\ntext-image pairs constrains their ability to understand temporal and kinematic\nstructures inherent in motion and motion generation. This work introduces\nMoCLIP, a fine-tuned CLIP model with an additional motion encoding head,\ntrained on motion sequences using contrastive learning and tethering loss. By\nexplicitly incorporating motion-aware representations, MoCLIP enhances motion\nfidelity while remaining compatible with existing CLIP-based pipelines and\nseamlessly integrating into various CLIP-based methods. Experiments demonstrate\nthat MoCLIP improves Top-1, Top-2, and Top-3 accuracy while maintaining\ncompetitive FID, leading to improved text-to-motion alignment results. These\nresults highlight MoCLIP's versatility and effectiveness, establishing it as a\nrobust framework for enhancing motion generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.10810v1",
    "published": "2025-05-16T03:11:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10809v2",
    "title": "Goodwillie calculus of the category of non-unital algebras, and application to algebraic cobordism",
    "authors": [
      "Yuki Kato"
    ],
    "abstract": "This paper reformulates Goodwillie calculus of $\\infty$-categories including\nnon-presentable $\\infty$-categories. In the case of presentable\n$\\infty$-categories our definition is equivalent to Heuts's~\\cite{Heuts2018}\nwork.\n  As an application of this work, we prove that, for any perfectoid algebra,\nthe tilting functor induces a weak equivalence of the left Kan extensions\nalgebraic cobordisms on the category of non-unital algebras.\n  Furthermore, we give a theory of approximation of functors along given\nnatural transformation of them, and applications to the algebraic cobordism to\nthe $K$-theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.10809v2",
    "published": "2025-05-16T03:10:15+00:00",
    "categories": [
      "math.CT",
      "18N55 (primary), 18N70 (secondary)"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.15830v1",
    "title": "Characterization of Using Hybrid Beamforming in mmWave Virtual Reality",
    "authors": [
      "Nasim Alikhani",
      "Abbas Mohammadi"
    ],
    "abstract": "Wireless Virtual Reality (VR) is increasingly in demand in Wireless LANs\n(WLANs). In this paper, a utility function for resource management in wireless\nVR is proposed. Maximizing the sum rate metric in transmitting VR audio or\nvideos is an important factor for ascertaining low latency in obtaining QoS\nrequirement of users in VR, so forth mmWave frequency band in WLAN technology\nshould be used. This frequency band is presented in IEEE 802.11ad/ay. Resource\naccess method in IEEE 802.11ay standard is MultiUser MIMO (MU-MIMO) with OFDM\nmodulation. Operating at mmWave frequency band is equal to use massive number\nof antenna to enhance the received power in (Line of Sight) LoS direction by\ninducing sever propagation with small wavelength. Also for reducing the\ncomplexity of hardware in mmWave technology, designers should select some\nnumber of connected phase shifters to each antenna element by hybrid\nbeamforming method. Processing delay, transmission delay and queue delay should\nbe considered in acquiring QoS metric in terms of utility function. The optimal\nclosed form expression of the multi-attribute utility function is based on\nthese delays that are calculated by downlink and uplink rates in assistant with\nhybrid beamforming. Trends of transmission delay and multi-attribute utility\nfunction in various Es/N0 values and different scenarios are analyzed. Based on\nthese results, 95.4% accuracy in comparison with ns3 in uplink and downlink\nchannel modeling in IEEE 802.11ay standard's indoor environment has been\nreported. Also, it is shown that min channel gain consideration can cause\nreduction in the value of the utility function and incursion in transmission\ndelay in VR.",
    "pdf_url": "http://arxiv.org/pdf/2505.15830v1",
    "published": "2025-05-16T03:04:55+00:00",
    "categories": [
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10808v1",
    "title": "Topological surface states in γ-PtBi$_2$ evidenced by scanning tunneling microscopy",
    "authors": [
      "Yunkai Guo",
      "Jingming Yan",
      "Wen-Han Dong",
      "Yongkai Li",
      "Yucong Peng",
      "Xuetao Di",
      "Caizhen Li",
      "Zhiwei Wang",
      "Yong Xu",
      "Peizhe Tang",
      "Yugui Yao",
      "Wenhui Duan",
      "Qi-Kun Xue",
      "Wei Li"
    ],
    "abstract": "For the application of topological materials, the specific location of their\ntopological surface states with respect to the Fermi level are important.\n{\\gamma}-PtBi2 has been demonstrated to be a Weyl semimetal possessing\nsuperconducting Fermi arcs by photoemission spectroscopy. However, the evidence\nof its topological surface states is lacking by scanning tunneling microscopy\n(STM), which should be rather sensitive to detect the surface states. Here, we\nshow multiple STM evidences for the existence of topological surface states in\n{\\gamma}-PtBi2. We observe not only the step-edge and screw dislocation induced\nquasiparticle interference fringes, originating from the electron scatterings\nbetween the Fermi arcs of {\\gamma}-PtBi2, but also the back-scattering\nprohibition related to the spin-flip process, which is the direct evidence for\nthe topological nature of the surface states. Moreover, we demonstrate that the\ntopological surface states are precisely located over a narrow energy range\nnear the Fermi level, within which sharply enhanced intensity and slow spatial\ndecay of quasiparticle interference are observed.",
    "pdf_url": "http://arxiv.org/pdf/2505.10808v1",
    "published": "2025-05-16T03:03:58+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.10807v1",
    "title": "Convergence analysis of the Halpern iteration with adaptive anchoring parameters",
    "authors": [
      "Songnian He",
      "Hong-Kun Xu",
      "Qiao-Li Dong",
      "Na Mei"
    ],
    "abstract": "We propose an adaptive way to choose the anchoring parameters for the Halpern\niteration to find a fixed point of a nonexpansive mapping in a real Hilbert\nspace. We prove strong convergence of this adaptive Halpern iteration and\nobtain the rate of asymptotic regularity at least O(1/k), where k is the number\nof iterations. Numerical experiments are also provided to show advantages and\noutperformance of our adaptive Halpern algorithm over the standard Halpern\nalgorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.10807v1",
    "published": "2025-05-16T03:03:38+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10806v1",
    "title": "RapidGNN: Communication Efficient Large-Scale Distributed Training of Graph Neural Networks",
    "authors": [
      "Arefin Niam",
      "M S Q Zulkar Nine"
    ],
    "abstract": "Graph Neural Networks (GNNs) have achieved state-of-the-art (SOTA)\nperformance in diverse domains. However, training GNNs on large-scale graphs\nposes significant challenges due to high memory demands and significant\ncommunication overhead in distributed settings. Traditional sampling-based\napproaches mitigate computation load to some extent but often fail to address\ncommunication inefficiencies inherent in distributed environments. This paper\npresents RapidGNN that introduces a deterministic sampling strategy to\nprecompute mini-batches. By leveraging the sampling strategy, RapidGNN\naccurately anticipates feature access patterns, enabling optimal cache\nconstruction and timely prefetching of remote features. This reduces the\nfrequency and latency of remote data transfers without compromising the\nstochastic nature of training. Evaluations on Reddit and OGBN-Products datasets\ndemonstrate that RapidGNN achieves significant reductions in training time and\nremote feature fetches, outperforming existing models in both communication\nefficiency and throughput. Our findings highlight RapidGNN's potential for\nscalable, high-performance GNN training across large, real-world graph datasets\nalong with improving energy efficiency. Our model improves end-to-end training\nthroughput by 2.10x on average over SOTA model GraphSAGE-METIS (up to 2.45x in\nsome settings), while cutting remote feature fetches by over 4x. It also\nreduces energy consumption up to 23%.",
    "pdf_url": "http://arxiv.org/pdf/2505.10806v1",
    "published": "2025-05-16T03:01:47+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.14705v1",
    "title": "Beyond Modality Collapse: Representations Blending for Multimodal Dataset Distillation",
    "authors": [
      "Xin Zhang",
      "Ziruo Zhang",
      "Jiawei Du",
      "Zuozhu Liu",
      "Joey Tianyi Zhou"
    ],
    "abstract": "Multimodal Dataset Distillation (MDD) seeks to condense large-scale\nimage-text datasets into compact surrogates while retaining their effectiveness\nfor cross-modal learning. Despite recent progress, existing MDD approaches\noften suffer from \\textit{\\textbf{Modality Collapse}}, characterized by\nover-concentrated intra-modal representations and enlarged distributional gap\nacross modalities. In this paper, at the first time, we identify this issue as\nstemming from a fundamental conflict between the over-compression behavior\ninherent in dataset distillation and the cross-modal supervision imposed by\ncontrastive objectives. To alleviate modality collapse, we introduce\n\\textbf{RepBlend}, a novel MDD framework that weakens overdominant cross-modal\nsupervision via representation blending, thereby significantly enhancing\nintra-modal diversity. Additionally, we observe that current MDD methods impose\nasymmetric supervision across modalities, resulting in biased optimization. To\naddress this, we propose symmetric projection trajectory matching, which\nsynchronizes the optimization dynamics using modality-specific projection\nheads, thereby promoting balanced supervision and enhancing cross-modal\nalignment. Experiments on Flickr-30K and MS-COCO show that RepBlend\nconsistently outperforms prior state-of-the-art MDD methods, achieving\nsignificant gains in retrieval performance (e.g., +9.4 IR@10, +6.3 TR@10 under\nthe 100-pair setting) and offering up to 6.7$\\times$ distillation speedup.",
    "pdf_url": "http://arxiv.org/pdf/2505.14705v1",
    "published": "2025-05-16T03:00:56+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10805v1",
    "title": "Frequency and Abundance of Binary sUpermassive bLack holes from Optical Variability Surveys (FABULOVS): Hubble Space Telescope Imaging of Radial-Velocity Selected Binary Candidates",
    "authors": [
      "Liam Nolan",
      "Ming-Yang Zhuang",
      "Xin Liu",
      "Yu-Ching Chen",
      "Shreya Majumdar",
      "Junyao Li",
      "Yue Shen"
    ],
    "abstract": "Sub-parsec (sub-pc) binary supermassive black holes (BSBHs) should be common\nfrom galaxy mergers, yet direct evidence has been elusive. We present\nHST/WFC3IR F160W imaging for a sample of 8 candidate sub-pc BSBHs at redshifts\nz~0.1--0.5, as well as cross-comparison with a sample of ordinary quasars with\narchival HST/WFC3 IR F160W images. These 8 candidate sub-pc BSBHs were\nidentified from multi-epoch spectroscopic surveys of quasars (including both\ntypical quasars and those with single-peaked velocity-offset broad lines).\nwhose broad H$\\beta$ lines are significantly offset (by ~< a few hundred km/s)\nfrom the systemic redshifts. We directly test the prediction that the host\ngalaxies of BSBHs would have a higher fraction of disturbed morphologies and\nyounger stellar bulges from recent interactions than those of control quasars.\nAfter careful subtraction of the central quasar light, our candidate BSBH hosts\nshow a statistically undifferentiated distribution of host asymmetry,\nindicative of a similar fraction of recent mergers. While a significantly\nlarger sample is needed to place this result on a much firmer statistical\nground, it opens questions as to the timescale differences between galaxy\nmerger and BSBH formation, or the efficacy of the radial-velocity-shift--based\nselection of sub-pc BSBH candidates.",
    "pdf_url": "http://arxiv.org/pdf/2505.10805v1",
    "published": "2025-05-16T02:56:53+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.11558v1",
    "title": "AI-Driven Digital Transformation and Firm Performance in Chinese Industrial Enterprises: Mediating Role of Green Digital Innovation and Moderating Effects of Human-AI Collaboration",
    "authors": [
      "Jun Cui"
    ],
    "abstract": "This study examines the relationship between AI-driven digital transformation\nand firm performance in Chinese industrial enterprises, with particular\nattention to the mediating role of green digital innovation and the moderating\neffects of human-AI collaboration. Using panel data from 6,300 firm-year\nobservations collected from CNRDS and CSMAR databases between 2015 and 2022, we\nemploy multiple regression analysis and structural equation modeling to test\nour hypotheses. Our findings reveal that AI-driven digital transformation\nsignificantly enhances firm performance, with green digital innovation\nmediating this relationship. Furthermore, human-AI collaboration positively\nmoderates both the direct relationship between digital transformation and firm\nperformance and the mediating pathway through green digital innovation. The\nresults provide valuable insights for management practice and policy\nformulation in the context of China's evolving industrial landscape and digital\neconomy initiatives. This research contributes to the literature by integrating\nperspectives from technology management, environmental sustainability, and\norganizational theory to understand the complex interplay between technological\nadoption and business outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2505.11558v1",
    "published": "2025-05-16T02:56:39+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.10804v1",
    "title": "Stellar Obliquity of the Ultra-Short-Period Planet System HD 93963",
    "authors": [
      "Huan-Yu Teng",
      "Fei Dai",
      "Andrew W. Howard",
      "Samuel Halverson",
      "Howard Isaacson",
      "Eiichiro Kokubo",
      "Ryan A. Rubenzahl",
      "Benjamin Fulton",
      "Aaron Householder",
      "Jack Lubin",
      "Steven Giacalone",
      "Luke Handley",
      "Judah Van Zandt",
      "Erik A. Petigura",
      "J. M. Joel Ong",
      "Pranav Premnath",
      "Haochuan Yu",
      "Steven R. Gibson",
      "Kodi Rider",
      "Arpita Roy",
      "Ashley Baker",
      "Jerry Edelstein",
      "Chris Smith",
      "Josh Walawender",
      "Byeong-Cheol Lee",
      "Yu-Juan Liu",
      "Joshua N. Winn"
    ],
    "abstract": "We report an observation of the Rossiter-McLaughlin (RM) effect of the\ntransiting planet HD 93963 Ac, a mini-Neptune planet orbiting a G0-type star\nwith an orbital period of $P_{\\rm{c}} = 3.65\\,\\mathrm{d}$, accompanied by an\ninner super-Earth planet with $P_{\\rm{b}} = 1.04\\,\\mathrm{d}$. We observed a\nfull transit of planet c on 2024 May 3rd UT with Keck/KPF. The observed RM\neffect has an amplitude of $\\sim 1\\,\\mathrm{m\\,s}^{-1}$ and implies a\nsky-projected obliquity of $\\lambda = 14^{+17}_{-19}$ degrees for HD 93963 Ac.\nOur dynamical analysis suggests that the two inner planets are likely well\naligned with the stellar spin, to within a few degrees, thus allowing both to\ntransit. Along with WASP-47, 55 Cnc, and HD 3167, HD 93963 is the fourth\nplanetary system with an ultra-short-period planet and obliquity measurement(s)\nof any planet(s) in the system. HD 93963, WASP-47, and 55 Cnc favor largely\ncoplanar orbital architectures, whereas HD 3167 has been reported to have a\nlarge mutual inclination ($\\sim$100$^\\circ$) between its transiting planets b\nand c. In this configuration, the probability that both planets transit is low.\nMoreover, one planet would quickly evolve to be non-transiting due to nodal\nprecession. Future missions such as ESO/PLATO should detect the resulting\ntransit duration variations. We encourage additional obliquity measurements of\nthe HD 3167 system to better constrain its orbital architecture.",
    "pdf_url": "http://arxiv.org/pdf/2505.10804v1",
    "published": "2025-05-16T02:54:26+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10803v1",
    "title": "Developing and Integrating Trust Modeling into Multi-Objective Reinforcement Learning for Intelligent Agricultural Management",
    "authors": [
      "Zhaoan Wang",
      "Wonseok Jang",
      "Bowen Ruan",
      "Jun Wang",
      "Shaoping Xiao"
    ],
    "abstract": "Precision agriculture, enhanced by artificial intelligence (AI), offers\npromising tools such as remote sensing, intelligent irrigation, fertilization\nmanagement, and crop simulation to improve agricultural efficiency and\nsustainability. Reinforcement learning (RL), in particular, has outperformed\ntraditional methods in optimizing yields and resource management. However,\nwidespread AI adoption is limited by gaps between algorithmic recommendations\nand farmers' practical experience, local knowledge, and traditional practices.\nTo address this, our study emphasizes Human-AI Interaction (HAII), focusing on\ntransparency, usability, and trust in RL-based farm management. We employ a\nwell-established trust framework - comprising ability, benevolence, and\nintegrity - to develop a novel mathematical model quantifying farmers'\nconfidence in AI-based fertilization strategies. Surveys conducted with farmers\nfor this research reveal critical misalignments, which are integrated into our\ntrust model and incorporated into a multi-objective RL framework. Unlike prior\nmethods, our approach embeds trust directly into policy optimization, ensuring\nAI recommendations are technically robust, economically feasible,\ncontext-aware, and socially acceptable. By aligning technical performance with\nhuman-centered trust, this research supports broader AI adoption in\nagriculture.",
    "pdf_url": "http://arxiv.org/pdf/2505.10803v1",
    "published": "2025-05-16T02:52:16+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10802v1",
    "title": "Attention-Based Reward Shaping for Sparse and Delayed Rewards",
    "authors": [
      "Ian Holmes",
      "Min Chi"
    ],
    "abstract": "Sparse and delayed reward functions pose a significant obstacle for\nreal-world Reinforcement Learning (RL) applications. In this work, we propose\nAttention-based REward Shaping (ARES), a general and robust algorithm which\nuses a transformer's attention mechanism to generate shaped rewards and create\na dense reward function for any environment. ARES requires a set of episodes\nand their final returns as input. It can be trained entirely offline and is\nable to generate meaningful shaped rewards even when using small datasets or\nepisodes produced by agents taking random actions. ARES is compatible with any\nRL algorithm and can handle any level of reward sparsity. In our experiments,\nwe focus on the most challenging case where rewards are fully delayed until the\nend of each episode. We evaluate ARES across a diverse range of environments,\nwidely used RL algorithms, and baseline methods to assess the effectiveness of\nthe shaped rewards it produces. Our results show that ARES can significantly\nimprove learning in delayed reward settings, enabling RL agents to train in\nscenarios that would otherwise require impractical amounts of data or even be\nunlearnable. To our knowledge, ARES is the first approach that works fully\noffline, remains robust to extreme reward delays and low-quality data, and is\nnot limited to goal-based tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.10802v1",
    "published": "2025-05-16T02:43:05+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10801v1",
    "title": "Asymptotics of Constrained Quantization for Compactly Supported Measures",
    "authors": [
      "Chenxing Qian"
    ],
    "abstract": "We investigated the asymptotics of high-rate constrained quantization errors\nfor a compactly supported probability measure P on Euclidean spaces whose\nquantizers are confined to a closed set S. The key tool is the metric\nprojection of K onto S that assigns each source point to its nearest neighbor\nin S, allowing the errors to be transferred to the projection, where K = supp\nP. For the upper estimate, we establish a projection pull-back inequality that\nbounds the errors by the classical covering radius of the projection. For the\nlower estimate, a weighted distance function enables us to perturb any\nquantizer element lying on the projection slightly into the complement in S\nwithout enlarging the error, provided the projection is nowhere dense\n(automatically true when S and K are disjoint). Under mild conditions on the\npushforward measure of P by T, obtained via a measurable selector T, we derive\na uniform lower bound. If this set is Ahlfors regular of dimension d, the error\ndecays like the reciprocal of the d-th root of n and every constrained\nquantization dimension equals d. The two estimates coincide, giving the first\ncomplete dimension comparison formula for constrained quantization and closing\nthe gap left by earlier self-similar examples by Pandey-Roychowdhury while\nextending classical unconstrained theory to closed constraints under mild\ngeometric assumptions.",
    "pdf_url": "http://arxiv.org/pdf/2505.10801v1",
    "published": "2025-05-16T02:39:30+00:00",
    "categories": [
      "math.MG",
      "math.CA",
      "math.FA",
      "math.OC",
      "math.PR",
      "Primary 41A29, Secondary 37A50, 60D05, 28C20, 31E05"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10800v1",
    "title": "Contractive difference-of-convex algorithms",
    "authors": [
      "Songnian He",
      "Qiao-Li Dong",
      "Michael Th. Rassias"
    ],
    "abstract": "The difference-of-convex algorithm (DCA) and its variants are the most\npopular methods to solve the difference-of-convex optimization problem. Each\niteration of them is reduced to a convex optimization problem, which generally\nneeds to be solved by iterative methods such as proximal gradient algorithm.\nHowever, these algorithms essentially belong to some iterative methods of fixed\npoint problems of averaged mappings, and their convergence speed is generally\nslow. Furthermore, there is seldom research on the termination rule of these\niterative algorithms solving the subproblem of DCA. To overcome these defects,\nwe ffrstly show that the subproblem of the linearized proximal method (LPM) in\neach iteration is equal to the ffxed point problem of a contraction. Secondly,\nby using Picard iteration to approximately solve the subproblem of LPM in each\niteration, we propose a contractive difference-ofconvex algorithm (cDCA) where\nan adaptive termination rule is presented. Both global subsequential\nconvergence and global convergence of the whole sequence of cDCA are\nestablished. Finally, preliminary results from numerical experiments are\npromising.",
    "pdf_url": "http://arxiv.org/pdf/2505.10800v1",
    "published": "2025-05-16T02:38:37+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10799v2",
    "title": "Cell Library Characterization for Composite Current Source Models Based on Gaussian Process Regression and Active Learning",
    "authors": [
      "Tao Bai",
      "Junzhuo Zhou",
      "Zeyuan Deng",
      "Ting-Jung Lin",
      "Wei Xing",
      "Peng Cao",
      "Lei He"
    ],
    "abstract": "The composite current source (CCS) model has been adopted as an advanced\ntiming model that represents the current behavior of cells for improved\naccuracy and better capability than traditional non-linear delay models (NLDM)\nto model complex dynamic effects and interactions under advanced process nodes.\nHowever, the high accuracy requirement, large amount of data and extensive\nsimulation cost pose severe challenges to CCS characterization. To address\nthese challenges, we introduce a novel Gaussian Process Regression(GPR) model\nwith active learning(AL) to establish the characterization framework\nefficiently and accurately. Our approach significantly outperforms conventional\ncommercial tools as well as learning based approaches by achieving an average\nabsolute error of 2.05 ps and a relative error of 2.27% for current waveform of\n57 cells under 9 process, voltage, temperature (PVT) corners with TSMC 22nm\nprocess. Additionally, our model drastically reduces the runtime to 27% and the\nstorage by up to 19.5x compared with that required by commercial tools.",
    "pdf_url": "http://arxiv.org/pdf/2505.10799v2",
    "published": "2025-05-16T02:24:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10798v1",
    "title": "Relation Extraction Across Entire Books to Reconstruct Community Networks: The AffilKG Datasets",
    "authors": [
      "Erica Cai",
      "Sean McQuade",
      "Kevin Young",
      "Brendan O'Connor"
    ],
    "abstract": "When knowledge graphs (KGs) are automatically extracted from text, are they\naccurate enough for downstream analysis? Unfortunately, current annotated\ndatasets can not be used to evaluate this question, since their KGs are highly\ndisconnected, too small, or overly complex. To address this gap, we introduce\nAffilKG (https://doi.org/10.5281/zenodo.15427977), which is a collection of six\ndatasets that are the first to pair complete book scans with large, labeled\nknowledge graphs. Each dataset features affiliation graphs, which are simple\nKGs that capture Member relationships between Person and Organization entities\n-- useful in studies of migration, community interactions, and other social\nphenomena. In addition, three datasets include expanded KGs with a wider\nvariety of relation types. Our preliminary experiments demonstrate significant\nvariability in model performance across datasets, underscoring AffilKG's\nability to enable two critical advances: (1) benchmarking how extraction errors\npropagate to graph-level analyses (e.g., community structure), and (2)\nvalidating KG extraction methods for real-world social science research.",
    "pdf_url": "http://arxiv.org/pdf/2505.10798v1",
    "published": "2025-05-16T02:24:32+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10797v1",
    "title": "High-efficient long-distance device-independent quantum secret sharing based on single-photon sources",
    "authors": [
      "Qi Zhang",
      "Cheng Zhang",
      "Wei Zhong",
      "Ming-Ming Du",
      "Lan Zhou",
      "Yu-Bo Sheng"
    ],
    "abstract": "Device-independent quantum secret sharing (DI QSS) relaxes security\nassumptions of experimental devices to provide the highest security level for\nQSS. Previous DI QSS protocols require to generate multi-partite entangled\nstates and then implement the long-distance entanglement distribution. The\nextremely low generation probability of current multi-partite entanglement\nsource and photon transmission loss largely limit DI QSS's practical key\ngeneration rate and secure photon transmission distance. In the paper, we\npropose a high-efficient long-distance DI QSS protocol based on practical\nnearly on-demand single-photon sources (SPSs), which adopts the single photons\nand heralded architecture to construct long-distance multi-partite entanglement\nchannels. Our SPS DI QSS protocol can automatically eliminate the negative\ninfluence from photon transmission loss and largely increase the secure photon\ntransmission distance. Moreover, we adopt active improvement strategies such as\nrandom key generation basis, postselection, and advanced postselection to\nfurther increase the practical key generation rate and lower the experimental\nrequirement. Comparing with previous DI QSS protocols based on entanglement\nsources, our SPS DI QSS protocol can increase the practical communication\nefficiency by six orders of magnitude, and increase the secure photon\ntransmission distance by at least 151 times. This SPS DI QSS protocol is\nfeasible with the current experimental technologies. Our protocol makes it\npossible to realize high-efficient long-distance DI network in the near future.",
    "pdf_url": "http://arxiv.org/pdf/2505.10797v1",
    "published": "2025-05-16T02:22:07+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10796v1",
    "title": "Quantum data generation in a denoising model with multiscale entanglement renormalization network",
    "authors": [
      "Wei-Wei Zhang",
      "Xiaopeng Huang",
      "Shenglin Shan",
      "Wei Zhao",
      "Beiya Yang",
      "Wei Pan",
      "Haobin Shi"
    ],
    "abstract": "Quantum technology has entered the era of noisy intermediate-scale quantum\n(NISQ) information processing. The technological revolution of machine learning\nrepresented by generative models heralds a great prospect of artificial\nintelligence, and the huge amount of data processes poses a big challenge to\nexisting computers. The generation of large quantities of quantum data will be\na challenge for quantum artificial intelligence. In this work, we present an\nefficient noise-resistant quantum data generation method that can be applied to\nvarious types of NISQ quantum processors, where the target quantum data belongs\nto a certain class and our proposal enables the generation of various quantum\ndata belonging to the target class. Specifically, we propose a quantum\ndenoising probability model (QDM) based on a multiscale entanglement\nrenormalization network (MERA) for the generation of quantum data. To show the\nfeasibility and practicality of our scheme, we demonstrate the generations of\nthe classes of GHZ-like states and W-like states with a success rate above 99%.\nOur MREA QDM can also be used to denoise multiple types of quantum data\nsimultaneously. We show the success rate of denoising both GHZ-like and W-like\nstates with a single qubit noise environment of noise level within 1/4 can\napproximate to be 100%, and with two other types of noise environment with\nnoise level within 1/4 can be above 90%. Our quantum data generation scheme\nprovides new ideas and prospects for quantum generative models in the NISQ era.",
    "pdf_url": "http://arxiv.org/pdf/2505.10796v1",
    "published": "2025-05-16T02:18:01+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.10795v1",
    "title": "Consensus of A Class of Nonlinear Systems with Varying Topology: A Hilbert Metric Approach",
    "authors": [
      "Dongjun Wu"
    ],
    "abstract": "In this technical note, we introduce a novel approach to studying consensus\nof continuous-time nonlinear systems with varying topology based on Hilbert\nmetric. We demonstrate that this metric offers significant flexibility in\nanalyzing consensus properties, while effectively handling nonlinearities and\ntime dependencies. Notably, our approach relaxes key technical assumptions from\nsome standard results while yielding stronger conclusions with shorter proofs.\nThis framework provides new insights into nonlinear consensus under varying\ntopology.",
    "pdf_url": "http://arxiv.org/pdf/2505.10795v1",
    "published": "2025-05-16T02:13:04+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.10794v1",
    "title": "Quantifying the advantage of quantum correlation microscopy using arrays of single-photon detectors",
    "authors": [
      "Jaret J. Vasquez-Lozano",
      "Qiang Sun",
      "Shuo Li",
      "Andrew D. Greentree"
    ],
    "abstract": "Quantum correlation microscopy is an emerging technique for improving optical\nresolution. By taking advantage of the quantum statistics from single-photon\nfluorophores, more information about the emitters (including number and\nlocation) is obtained compared with classical microscopy. Although it is known\nthat the resolution can be improved by increasing detector numbers, as well as\nusing quantum correlation, the quantitative relationship between these two\napproaches is not immediately clear. Here we explore widefield quantum\ncorrelation microscopy using arrays of single-photon detectors. We explicitly\ncompare the use of $N$ detectors used in photon counting mode vs $N/2$\ndetectors used to measure quantum correlations. i.e., where there are $N/2$\nHanbury Brown and Twiss systems, using the same $N$ detectors, on randomly\ngenerated two-emitter systems. We find regimes where $N/2$ Hanbury Brown and\nTwiss detectors provide improved localisation compared to $N$ photon counting\ndetectors, as a function of emitter position and number of photons sampled.",
    "pdf_url": "http://arxiv.org/pdf/2505.10794v1",
    "published": "2025-05-16T02:11:44+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.10793v1",
    "title": "SongEval: A Benchmark Dataset for Song Aesthetics Evaluation",
    "authors": [
      "Jixun Yao",
      "Guobin Ma",
      "Huixin Xue",
      "Huakang Chen",
      "Chunbo Hao",
      "Yuepeng Jiang",
      "Haohe Liu",
      "Ruibin Yuan",
      "Jin Xu",
      "Wei Xue",
      "Hao Liu",
      "Lei Xie"
    ],
    "abstract": "Aesthetics serve as an implicit and important criterion in song generation\ntasks that reflect human perception beyond objective metrics. However,\nevaluating the aesthetics of generated songs remains a fundamental challenge,\nas the appreciation of music is highly subjective. Existing evaluation metrics,\nsuch as embedding-based distances, are limited in reflecting the subjective and\nperceptual aspects that define musical appeal. To address this issue, we\nintroduce SongEval, the first open-source, large-scale benchmark dataset for\nevaluating the aesthetics of full-length songs. SongEval includes over 2,399\nsongs in full length, summing up to more than 140 hours, with aesthetic ratings\nfrom 16 professional annotators with musical backgrounds. Each song is\nevaluated across five key dimensions: overall coherence, memorability,\nnaturalness of vocal breathing and phrasing, clarity of song structure, and\noverall musicality. The dataset covers both English and Chinese songs, spanning\nnine mainstream genres. Moreover, to assess the effectiveness of song aesthetic\nevaluation, we conduct experiments using SongEval to predict aesthetic scores\nand demonstrate better performance than existing objective evaluation metrics\nin predicting human-perceived musical quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.10793v1",
    "published": "2025-05-16T02:06:25+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.10792v2",
    "title": "Finetune-RAG: Fine-Tuning Language Models to Resist Hallucination in Retrieval-Augmented Generation",
    "authors": [
      "Zhan Peng Lee",
      "Andre Lin",
      "Calvin Tan"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful framework to\nimprove factuality in large language models (LLMs) by grounding their outputs\nin retrieved documents. However, ensuring perfect retrieval of relevant\ninformation remains challenging, and when irrelevant content is passed\ndownstream to an LLM, it can lead to hallucinations. In this work, we propose\nFinetune-RAG, a simple and effective fine-tuning approach that features the\nfirst-of-its-kind RAG training dataset constructed to mimic real-world\nimperfections. Experimental results show that Finetune-RAG improves factual\naccuracy by 21.2% over the base model. We also propose Bench-RAG, an\nLLM-as-a-judge evaluation pipeline that stress tests models under realistic\nimperfect retrieval scenarios. Our codebase and dataset are fully open sourced\nfor community use.",
    "pdf_url": "http://arxiv.org/pdf/2505.10792v2",
    "published": "2025-05-16T02:06:06+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10791v1",
    "title": "Analyzing Patterns and Influence of Advertising in Print Newspapers",
    "authors": [
      "N Harsha Vardhan",
      "Ponnurangam Kumaraguru",
      "Kiran Garimella"
    ],
    "abstract": "This paper investigates advertising practices in print newspapers across\nIndia using a novel data-driven approach. We develop a pipeline employing image\nprocessing and OCR techniques to extract articles and advertisements from\ndigital versions of print newspapers with high accuracy. Applying this\nmethodology to five popular newspapers that span multiple regions and three\nlanguages, English, Hindi, and Telugu, we assembled a dataset of more than\n12,000 editions containing several hundred thousand advertisements.\nCollectively, these newspapers reach a readership of over 100 million people.\nUsing this extensive dataset, we conduct a comprehensive analysis to answer key\nquestions about print advertising: who advertises, what they advertise, when\nthey advertise, where they place their ads, and how they advertise. Our\nfindings reveal significant patterns, including the consistent level of print\nadvertising over the past six years despite declining print circulation, the\noverrepresentation of company ads on prominent pages, and the disproportionate\nrevenue contributed by government ads. Furthermore, we examine whether\nadvertising in a newspaper influences the coverage an advertiser receives.\nThrough regression analyses on coverage volume and sentiment, we find strong\nevidence supporting this hypothesis for corporate advertisers. The results\nindicate a clear trend where increased advertising correlates with more\nfavorable and extensive media coverage, a relationship that remains robust over\ntime and across different levels of advertiser popularity.",
    "pdf_url": "http://arxiv.org/pdf/2505.10791v1",
    "published": "2025-05-16T02:05:53+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.10790v1",
    "title": "Neural-Inspired Advances in Integral Cryptanalysis",
    "authors": [
      "Liu Zhang",
      "Yiran Yao",
      "Danping Shi",
      "Dongchen Chai",
      "Jian Guo",
      "Zilong Wang"
    ],
    "abstract": "The study by Gohr et.al at CRYPTO 2019 and sunsequent related works have\nshown that neural networks can uncover previously unused features, offering\nnovel insights into cryptanalysis. Motivated by these findings, we employ\nneural networks to learn features specifically related to integral properties\nand integrate the corresponding insights into optimized search frameworks.\nThese findings validate the framework of using neural networks for feature\nexploration, providing researchers with novel insights that advance established\ncryptanalysis methods.\n  Neural networks have inspired the development of more precise integral search\nmodels. By comparing the integral distinguishers obtained via neural networks\nwith those identified by classical methods, we observe that existing automated\nsearch models often fail to find optimal distinguishers. To address this issue,\nwe develop a meet in the middle search framework that balances model accuracy\nand computational efficiency. As a result, we reduce the number of active\nplaintext bits required for an 11 rounds integral distinguisher on SKINNY64/64,\nand further identify a 12 rounds key dependent integral distinguisher achieving\none additional round over the previous best-known result.\n  The integral distinguishers discovered by neural networks enable key recovery\nattacks on more rounds. We identify a 7 rounds key independent integral\ndistinguisher from neural networks with even only one active plaintext cell,\nwhich is based on linear combinations of bits. This distinguisher enables a 15\nrounds key recovery attack on SKINNYn/n, improving upon the previous record by\none round. Additionally, we discover an 8 rounds key dependent integral\ndistinguisher using neural network that further reduces the time complexity of\nkey recovery attacks against SKINNY.",
    "pdf_url": "http://arxiv.org/pdf/2505.10790v1",
    "published": "2025-05-16T02:05:13+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10789v3",
    "title": "Bandwidth vs BFS Width in Matrix Reordering, Graph Reconstruction, and Graph Drawing",
    "authors": [
      "David Eppstein",
      "Michael T. Goodrich",
      "Songyu Liu"
    ],
    "abstract": "We provide the first approximation quality guarantees for the Cuthull-McKee\nheuristic for reordering symmetric matrices to have low bandwidth, and we\nprovide an algorithm for reconstructing bounded-bandwidth graphs from distance\noracles with near-linear query complexity. To prove these results we introduce\na new width parameter, BFS width, and we prove polylogarithmic upper and lower\nbounds on the BFS width of graphs of bounded bandwidth. Unlike other width\nparameters, such as bandwidth, pathwidth, and treewidth, BFS width can easily\nbe computed in polynomial time. Bounded BFS width implies bounded bandwidth,\npathwidth, and treewidth, which in turn imply fixed-parameter tractable\nalgorithms for many problems that are NP-hard for general graphs. In addition\nto their applications to matrix ordering, we also provide applications of BFS\nwidth to graph reconstruction, to reconstruct graphs from distance queries, and\ngraph drawing, to construct arc diagrams of small height.",
    "pdf_url": "http://arxiv.org/pdf/2505.10789v3",
    "published": "2025-05-16T02:03:04+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.13501v1",
    "title": "SPIEDiff: robust learning of long-time macroscopic dynamics from short-time particle simulations with quantified epistemic uncertainty",
    "authors": [
      "Zequn He",
      "Celia Reina"
    ],
    "abstract": "The data-driven discovery of long-time macroscopic dynamics and\nthermodynamics of dissipative systems with particle fidelity is hampered by\nsignificant obstacles. These include the strong time-scale limitations inherent\nto particle simulations, the non-uniqueness of the thermodynamic potentials and\noperators from given macroscopic dynamics, and the need for efficient\nuncertainty quantification. This paper introduces Statistical-Physics Informed\nEpistemic Diffusion Models (SPIEDiff), a machine learning framework designed to\novercome these limitations in the context of purely dissipative systems by\nleveraging statistical physics, conditional diffusion models, and epinets. We\nevaluate the proposed framework on stochastic Arrhenius particle processes and\ndemonstrate that SPIEDiff can accurately uncover both thermodynamics and\nkinetics, while enabling reliable long-time macroscopic predictions using only\nshort-time particle simulation data. SPIEDiff can deliver accurate predictions\nwith quantified uncertainty in minutes, drastically reducing the computational\ndemand compared to direct particle simulations, which would take days or years\nin the examples considered. Overall, SPIEDiff offers a robust and trustworthy\npathway for the data-driven discovery of thermodynamic models.",
    "pdf_url": "http://arxiv.org/pdf/2505.13501v1",
    "published": "2025-05-16T02:03:04+00:00",
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10788v1",
    "title": "The characteristic polynomials of imprimitive groups and affine Coxeter groups",
    "authors": [
      "Chenyue Feng",
      "Shoumin Liu",
      "Xumin Wang"
    ],
    "abstract": "In this paper, we will seek appropriate generators to define the\ncharacteristic polynomials of $G(r,1,n)$, and prove that for every finite\ndimensional representation of $G(r,1,n)$, the characteristic polynomial of\n$G(r,1,n)$ determines the character of this representation. Furthermore, the\nsame conclusion holds for affine Coxeter groups \\(\\widetilde{W}\\) and\n$G(r,p,n)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.10788v1",
    "published": "2025-05-16T02:02:44+00:00",
    "categories": [
      "math.RT"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.10787v1",
    "title": "EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes",
    "authors": [
      "Jianlin Guo",
      "Haihong Xiao",
      "Wenxiong Kang"
    ],
    "abstract": "Efficient scene representations are essential for many real-world\napplications, especially those involving spatial measurement. Although current\nNeRF-based methods have achieved impressive results in reconstructing\nbuilding-scale scenes, they still suffer from slow training and inference\nspeeds due to time-consuming stochastic sampling. Recently, 3D Gaussian\nSplatting (3DGS) has demonstrated excellent performance with its high-quality\nrendering and real-time speed, especially for objects and small-scale scenes.\nHowever, in outdoor scenes, its point-based explicit representation lacks an\neffective adjustment mechanism, and the millions of Gaussian points required\noften lead to memory constraints during training. To address these challenges,\nwe propose EA-3DGS, a high-quality real-time rendering method designed for\noutdoor scenes. First, we introduce a mesh structure to regulate the\ninitialization of Gaussian components by leveraging an adaptive tetrahedral\nmesh that partitions the grid and initializes Gaussian components on each face,\neffectively capturing geometric structures in low-texture regions. Second, we\npropose an efficient Gaussian pruning strategy that evaluates each 3D\nGaussian's contribution to the view and prunes accordingly. To retain\ngeometry-critical Gaussian points, we also present a structure-aware\ndensification strategy that densifies Gaussian points in low-curvature regions.\nAdditionally, we employ vector quantization for parameter quantization of\nGaussian components, significantly reducing disk space requirements with only a\nminimal impact on rendering quality. Extensive experiments on 13 scenes,\nincluding eight from four public datasets (MatrixCity-Aerial, Mill-19, Tanks \\&\nTemples, WHU) and five self-collected scenes acquired through UAV\nphotogrammetry measurement from SCUT-CA and plateau regions, further\ndemonstrate the superiority of our method.",
    "pdf_url": "http://arxiv.org/pdf/2505.10787v1",
    "published": "2025-05-16T02:00:13+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10786v1",
    "title": "Bridging BCI and Communications: A MIMO Framework for EEG-to-ECoG Wireless Channel Modeling",
    "authors": [
      "Jiaheng Wang",
      "Zhenyu Wang",
      "Tianheng Xu",
      "Yuan Si",
      "Ang Li",
      "Ting Zhou",
      "Xi Zhao",
      "Honglin Hu"
    ],
    "abstract": "As a method to connect human brain and external devices, Brain-computer\ninterfaces (BCIs) are receiving extensive research attention. Recently, the\nintegration of communication theory with BCI has emerged as a popular trend,\noffering potential to enhance system performance and shape next-generation\ncommunications.\n  A key challenge in this field is modeling the brain wireless communication\nchannel between intracranial electrocorticography (ECoG) emitting neurons and\nextracranial electroencephalography (EEG) receiving electrodes. However, the\ncomplex physiology of brain challenges the application of traditional channel\nmodeling methods, leaving relevant research in its infancy. To address this\ngap, we propose a frequency-division multiple-input multiple-output (MIMO)\nestimation framework leveraging simultaneous macaque EEG and ECoG recordings,\nwhile employing neurophysiology-informed regularization to suppress noise\ninterference. This approach reveals profound similarities between neural signal\npropagation and multi-antenna communication systems. Experimental results show\nimproved estimation accuracy over conventional methods while highlighting a\ntrade-off between frequency resolution and temporal stability determined by\nsignal duration. This work establish a conceptual bridge between neural\ninterfacing and communication theory, accelerating synergistic developments in\nboth fields.",
    "pdf_url": "http://arxiv.org/pdf/2505.10786v1",
    "published": "2025-05-16T01:56:34+00:00",
    "categories": [
      "eess.SP",
      "cs.HC"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10785v3",
    "title": "Tracking Brownian fluid particles in large eddy simulations",
    "authors": [
      "Zihao Guo",
      "Zhongmin Qian"
    ],
    "abstract": "In this paper, we establish a numerical method for simulation of wall-bounded\nincompressible turbulent flows by integrating the technology of random vortex\nmethod with the core idea of Large Eddy Simulation (LES). Specifically, we\nutilize the filtering function in LES, interpreted as spatial averaging, along\nwith the integral representation theorem for parabolic equations, to achieve a\nclosure numerical scheme which may be used for calculating solutions of\nNavier-Stokes equations. This approach circumvents the challenge associated\nwith handling the non-locally integrable 3-dimensional integral kernel in the\nrandom vortex method and facilitates the computation of numerical solutions for\nflow systems via Monte-Carlo method. Comprehensive numerical simulations, along\nwith systematic comparisons against other numerical approaches, are conducted\nfor both turbulent and laminar flows in unbounded and wall-bounded domains,\nconsidering two- and three-dimensional cases. These results collectively\ndemonstrate the validity and effectiveness of the proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2505.10785v3",
    "published": "2025-05-16T01:51:57+00:00",
    "categories": [
      "physics.flu-dyn",
      "math.AP",
      "math.PR",
      "76M35, 76M23, 60H30, 65C05, 68Q10"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.10784v1",
    "title": "SynRailObs: A Synthetic Dataset for Obstacle Detection in Railway Scenarios",
    "authors": [
      "Qiushi Guo",
      "Jason Rambach"
    ],
    "abstract": "Detecting potential obstacles in railway environments is critical for\npreventing serious accidents. Identifying a broad range of obstacle categories\nunder complex conditions requires large-scale datasets with precisely\nannotated, high-quality images. However, existing publicly available datasets\nfail to meet these requirements, thereby hindering progress in railway safety\nresearch. To address this gap, we introduce SynRailObs, a high-fidelity\nsynthetic dataset designed to represent a diverse range of weather conditions\nand geographical features. Furthermore, diffusion models are employed to\ngenerate rare and difficult-to-capture obstacles that are typically challenging\nto obtain in real-world scenarios. To evaluate the effectiveness of SynRailObs,\nwe perform experiments in real-world railway environments, testing on both\nballasted and ballastless tracks across various weather conditions. The results\ndemonstrate that SynRailObs holds substantial potential for advancing obstacle\ndetection in railway safety applications. Models trained on this dataset show\nconsistent performance across different distances and environmental conditions.\nMoreover, the model trained on SynRailObs exhibits zero-shot capabilities,\nwhich are essential for applications in security-sensitive domains. The data is\navailable in https://www.kaggle.com/datasets/qiushi910/synrailobs.",
    "pdf_url": "http://arxiv.org/pdf/2505.10784v1",
    "published": "2025-05-16T01:49:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10783v1",
    "title": "A local framework for proving combinatorial matrix inversion theorems",
    "authors": [
      "Aditya Khanna",
      "Nicholas A. Loehr"
    ],
    "abstract": "Combinatorial transition matrices arise frequently in the theory of symmetric\nfunctions and their generalizations. The entries of such matrices often count\nsigned, weighted combinatorial structures such as semistandard tableaux,\nrim-hook tableaux, or brick tabloids. Bijective proofs that two such matrices\nare inverses of each other may be difficult to find. This paper presents a\ngeneral framework for proving such inversion results in the case where the\ncombinatorial objects are built up recursively by successively adding some\nincremental structure such as a single horizontal strip or rim-hook. In this\nsetting, we show that a sequence of matrix inversion results $A_nB_n=I$ can be\nreduced to a certain ``local'' identity involving the incremental structures.\nHere, $A_n$ and $B_n$ are matrices that might be non-square, and the columns of\n$A_n$ and the rows of $B_n$ indexed by compositions of $n$. We illustrate the\ngeneral theory with four classical applications involving the Kostka matrices,\nthe character tables of the symmetric group, incidence matrices for composition\nposets, and matrices counting brick tabloids. We obtain a new, canonical\nbijective proof of an inversion result for rectangular Kostka matrices, which\ncomplements the proof for the square case due to E\\u{g}ecio\\u{g}lu and Remmel.\nWe also give a new bijective proof of the orthogonality result for the\nirreducible $S_n$-characters that is shorter than the original version due to\nWhite.",
    "pdf_url": "http://arxiv.org/pdf/2505.10783v1",
    "published": "2025-05-16T01:47:40+00:00",
    "categories": [
      "math.CO",
      "05A17, 05A19, 15A09, 05E05"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10782v1",
    "title": "EdgeMM: Multi-Core CPU with Heterogeneous AI-Extension and Activation-aware Weight Pruning for Multimodal LLMs at Edge",
    "authors": [
      "Kangbo Bai",
      "Le Ye",
      "Ru Huang",
      "Tianyu Jia"
    ],
    "abstract": "Emerging multimodal LLMs (MLLMs) exhibit strong cross-modality perception and\nreasoning capabilities and hold great potential for various applications at\nedge. However, MLLMs typically consist of a compute-intensive modality encoder\nand a memory-bound LLM decoder, leading to distinct bottlenecks for hardware\ndesigns. In this work, we present a multi-core CPU solution with heterogeneous\nAI extensions, which are based on either the compute-centric systolic array or\nmemory-centric digital compute-in-memory (CIM) co-processors. In addition,\ndynamic activation-aware weight pruning and bandwidth management are developed\nto enhance bandwidth efficiency and core utilization, improving overall\nperformance. We implemented our solution using commercial 22nm technology. For\nrepresentative MLLMs, our evaluations show EdgeMM can achieve 2.84x performance\nspeedup compared to laptop 3060 GPU.",
    "pdf_url": "http://arxiv.org/pdf/2505.10782v1",
    "published": "2025-05-16T01:46:37+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10781v1",
    "title": "Completely Weakly Supervised Class-Incremental Learning for Semantic Segmentation",
    "authors": [
      "David Minkwan Kim",
      "Soeun Lee",
      "Byeongkeun Kang"
    ],
    "abstract": "This work addresses the task of completely weakly supervised\nclass-incremental learning for semantic segmentation to learn segmentation for\nboth base and additional novel classes using only image-level labels. While\nclass-incremental semantic segmentation (CISS) is crucial for handling diverse\nand newly emerging objects in the real world, traditional CISS methods require\nexpensive pixel-level annotations for training. To overcome this limitation,\npartially weakly-supervised approaches have recently been proposed. However, to\nthe best of our knowledge, this is the first work to introduce a completely\nweakly-supervised method for CISS. To achieve this, we propose to generate\nrobust pseudo-labels by combining pseudo-labels from a localizer and a sequence\nof foundation models based on their uncertainty. Moreover, to mitigate\ncatastrophic forgetting, we introduce an exemplar-guided data augmentation\nmethod that generates diverse images containing both previous and novel classes\nwith guidance. Finally, we conduct experiments in three common experimental\nsettings: 15-5 VOC, 10-10 VOC, and COCO-to-VOC, and in two scenarios: disjoint\nand overlap. The experimental results demonstrate that our completely weakly\nsupervised method outperforms even partially weakly supervised methods in the\n15-5 VOC and 10-10 VOC settings while achieving competitive accuracy in the\nCOCO-to-VOC setting.",
    "pdf_url": "http://arxiv.org/pdf/2505.10781v1",
    "published": "2025-05-16T01:43:36+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10780v1",
    "title": "SECRET: Semi-supervised Clinical Trial Document Similarity Search",
    "authors": [
      "Trisha Das",
      "Afrah Shafquat",
      "Beigi Mandis",
      "Jacob Aptekar",
      "Jimeng Sun"
    ],
    "abstract": "Clinical trials are vital for evaluation of safety and efficacy of new\ntreatments. However, clinical trials are resource-intensive, time-consuming and\nexpensive to conduct, where errors in trial design, reduced efficacy, and\nsafety events can result in significant delays, financial losses, and damage to\nreputation. These risks underline the importance of informed and strategic\ndecisions in trial design to mitigate these risks and improve the chances of a\nsuccessful trial. Identifying similar historical trials is critical as these\ntrials can provide an important reference for potential pitfalls and challenges\nincluding serious adverse events, dosage inaccuracies, recruitment\ndifficulties, patient adherence issues, etc. Addressing these challenges in\ntrial design can lead to development of more effective study protocols with\noptimized patient safety and trial efficiency. In this paper, we present a\nnovel method to identify similar historical trials by summarizing clinical\ntrial protocols and searching for similar trials based on a query trial's\nprotocol. Our approach significantly outperforms all baselines, achieving up to\na 78% improvement in recall@1 and a 53% improvement in precision@1 over the\nbest baseline. We also show that our method outperforms all other baselines in\npartial trial similarity search and zero-shot patient-trial matching,\nhighlighting its superior utility in these tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.10780v1",
    "published": "2025-05-16T01:34:16+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.10779v1",
    "title": "Qualia Optimization",
    "authors": [
      "Philip S. Thomas"
    ],
    "abstract": "This report explores the speculative question: what if current or future AI\nsystems have qualia, such as pain or pleasure? It does so by assuming that AI\nsystems might someday possess qualia -- and that the quality of these\nsubjective experiences should be considered alongside performance metrics.\nConcrete mathematical problem settings, inspired by reinforcement learning\nformulations and theories from philosophy of mind, are then proposed and\ninitial approaches and properties are presented. These properties enable\nrefinement of the problem setting, culminating with the proposal of methods\nthat promote reinforcement.",
    "pdf_url": "http://arxiv.org/pdf/2505.10779v1",
    "published": "2025-05-16T01:34:03+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.13500v1",
    "title": "Noise Injection Systemically Degrades Large Language Model Safety Guardrails",
    "authors": [
      "Prithviraj Singh Shahani",
      "Matthias Scheutz"
    ],
    "abstract": "Safety guardrails in large language models (LLMs) are a critical component in\npreventing harmful outputs. Yet, their resilience under perturbation remains\npoorly understood. In this paper, we investigate the robustness of safety\nfine-tuning in LLMs by systematically injecting Gaussian noise into model\nactivations. We show across multiple open-weight models that (1) Gaussian noise\nraises harmful-output rates (p < 0.001) by up to 27%, (2) that deeper safety\nfine-tuning affords no extra protection, and (3) that chain-of-thought\nreasoning remains largely intact. The findings reveal critical vulnerabilities\nin current safety alignment techniques and highlight the potential of\nreasoning-based and reinforcement learning approaches as promising direction\nfor developing more robust AI safety systems. These results have important\nimplications for real-world deployment of LLMs in safety-critical applications\nas these results imply that widely-deployed safety tuning methods can fail even\nwithout adversarial prompts.",
    "pdf_url": "http://arxiv.org/pdf/2505.13500v1",
    "published": "2025-05-16T01:33:25+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10778v1",
    "title": "Regularity estimates for fully nonlinear dead-core problems with a Hamiltonian Term",
    "authors": [
      "Rafael R. Costa",
      "Ginaldo S. Sá"
    ],
    "abstract": "In this paper, we present a problem involving fully nonlinear elliptic\noperators with Hamiltonian, which can present a singularity or degenerate as\nthe gradient approaches the origin. The model studied here, allows the\nappearance of plateau zones, i.e. unknown regions of the domain in which the\nnon-negative solutions vanishes. We show an improvement in regularity along the\nfree boundary of the problem, and with some hypotheses on the exponents of the\nequation we proved the optimality of the growth rate with the help of the\nnon-degeneracy also obtained here. In addition, some more applications of the\ngrowth results on the free boundary are obtained, such as: the positivity of\nsolutions and also information on the Hausdorff measure of the boundary of the\ncoincidence set.",
    "pdf_url": "http://arxiv.org/pdf/2505.10778v1",
    "published": "2025-05-16T01:31:59+00:00",
    "categories": [
      "math.AP",
      "35B65, 35J70, 35J75, 35R35"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10777v2",
    "title": "On Some Open Cases of a Conjecture of Conrad, Edixhoven and Stein",
    "authors": [
      "Davide De Leo",
      "Michael Stoll"
    ],
    "abstract": "Let \\( p \\geq 5 \\) be a prime. In 2003 Conrad, Edixhoven, and Stein\nconjectured that the rational torsion subgroup of the modular Jacobian \\(\nJ_1(p) \\) coincides with the rational cuspidal divisor class group. Using\nexplicit computations in Magma, the open case \\( p = 29 \\) has been proven by\nDerickx, Kamienny, Stein, and Stoll in 2023. We extend these results to primes\n\\( p = 97, 101, 109, \\) and \\( 113 \\). In addition, we provide a list of the\ngroups \\( J_1(p)(\\mathbb{Q})_{\\text{tors}} \\) for every prime up to \\( p \\leq\n113 \\). However, our method is general and can be applied to larger primes.",
    "pdf_url": "http://arxiv.org/pdf/2505.10777v2",
    "published": "2025-05-16T01:30:37+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.10776v1",
    "title": "Scaling limits for INAR$(\\infty)$ processes",
    "authors": [
      "Nian Yao"
    ],
    "abstract": "In this paper, we study law of large numbers, central limit theorem, large\nand moderate deviations for INAR($\\infty$) processes, which as a special case,\nincludes both discrete-time linear Hawkes process and INAR(1) process in the\nliterature. Our results recover existing results on large and moderate\ndeviations for the discrete-time Hawkes process as studied in \\cite{Wang2} and\nfor the INAR(1) process as in \\cite{Yu}.",
    "pdf_url": "http://arxiv.org/pdf/2505.10776v1",
    "published": "2025-05-16T01:27:29+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.10775v1",
    "title": "A Systematic Analysis of Base Model Choice for Reward Modeling",
    "authors": [
      "Kian Ahrabian",
      "Pegah Jandaghi",
      "Negar Mokhberian",
      "Sai Praneeth Karimireddy",
      "Jay Pujara"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) and, at its core, reward\nmodeling have become a crucial part of training powerful large language models\n(LLMs). One commonly overlooked factor in training high-quality reward models\n(RMs) is the effect of the base model, which is becoming more challenging to\nchoose given the rapidly growing pool of LLMs. In this work, we present a\nsystematic analysis of the effect of base model selection on reward modeling\nperformance. Our results show that the performance can be improved by up to 14%\ncompared to the most common (i.e., default) choice. Moreover, we showcase the\nstrong statistical relation between some existing benchmarks and downstream\nperformances. We also demonstrate that the results from a small set of\nbenchmarks could be combined to boost the model selection ($+$18% on average in\nthe top 5-10). Lastly, we illustrate the impact of different post-training\nsteps on the final performance and explore using estimated data distributions\nto reduce performance prediction error.",
    "pdf_url": "http://arxiv.org/pdf/2505.10775v1",
    "published": "2025-05-16T01:27:03+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10774v2",
    "title": "Context-Aware Probabilistic Modeling with LLM for Multimodal Time Series Forecasting",
    "authors": [
      "Yueyang Yao",
      "Jiajun Li",
      "Xingyuan Dai",
      "MengMeng Zhang",
      "Xiaoyan Gong",
      "Fei-Yue Wang",
      "Yisheng Lv"
    ],
    "abstract": "Time series forecasting is important for applications spanning energy\nmarkets, climate analysis, and traffic management. However, existing methods\nstruggle to effectively integrate exogenous texts and align them with the\nprobabilistic nature of large language models (LLMs). Current approaches either\nemploy shallow text-time series fusion via basic prompts or rely on\ndeterministic numerical decoding that conflict with LLMs' token-generation\nparadigm, which limits contextual awareness and distribution modeling. To\naddress these limitations, we propose CAPTime, a context-aware probabilistic\nmultimodal time series forecasting method that leverages text-informed\nabstraction and autoregressive LLM decoding. Our method first encodes temporal\npatterns using a pretrained time series encoder, then aligns them with textual\ncontexts via learnable interactions to produce joint multimodal\nrepresentations. By combining a mixture of distribution experts with frozen\nLLMs, we enable context-aware probabilistic forecasting while preserving LLMs'\ninherent distribution modeling capabilities. Experiments on diverse time series\nforecasting tasks demonstrate the superior accuracy and generalization of\nCAPTime, particularly in multimodal scenarios. Additional analysis highlights\nits robustness in data-scarce scenarios through hybrid probabilistic decoding.",
    "pdf_url": "http://arxiv.org/pdf/2505.10774v2",
    "published": "2025-05-16T01:23:53+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10773v1",
    "title": "Sequential topology: iterative topological phase transitions in finite chiral structures",
    "authors": [
      "Maxine M. McCarthy",
      "D. M. Whittaker"
    ],
    "abstract": "We present theoretical and experimental results probing the rich topological\nstructure of arbitrarily disordered finite tight binding Hamiltonians with\nchiral symmetry. We extend the known classification by considering the\ntopological properties of phase boundaries themselves. That is, can\nHamiltonians that are confined to being topologically marginal, also have\ndistinct topological phases? For chiral structures, we answer this in the\naffirmative, where we define topological phase boundaries as having an\nunavoidable increase in the degeneracy of real space zero modes. By iterating\nthis question, and considering how to enforce a Hamiltonian to a phase\nboundary, we give a protocol to find the largest dimension subspace of a\ndisordered parameter space that has a certain order degeneracy of zero energy\nstates, which we call \\textit{sequential topology}. We show such degeneracy\nalters localisation and transport properties of zero modes, allowing us to\nexperimentally corroborate our theory using a state-of-the-art coaxial cable\nplatform. Our theory applies to systems with an arbitrary underlying\nconnectivity or disorder, and so can be calculated for any finite chiral\nstructure. Technological and theoretical applications of our work are\ndiscussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.10773v1",
    "published": "2025-05-16T01:15:12+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.dis-nn"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.10772v1",
    "title": "Ranked Voting based Self-Consistency of Large Language Models",
    "authors": [
      "Weiqin Wang",
      "Yile Wang",
      "Hui Huang"
    ],
    "abstract": "Majority voting is considered an effective method to enhance chain-of-thought\nreasoning, as it selects the answer with the highest \"self-consistency\" among\ndifferent reasoning paths (Wang et al., 2023). However, previous\nchain-of-thought reasoning methods typically generate only a single answer in\neach trial, thereby ignoring the possibility of other potential answers. As a\nresult, these alternative answers are often overlooked in subsequent voting\nprocesses. In this work, we propose to generate ranked answers in each\nreasoning process and conduct ranked voting among multiple ranked answers from\ndifferent responses, thereby making the overall self-consistency more reliable.\nSpecifically, we use three ranked voting methods: Instant-runoff voting, Borda\ncount voting, and mean reciprocal rank voting. We validate our methods on six\ndatasets, including three multiple-choice and three open-ended\nquestion-answering tasks, using both advanced open-source and closed-source\nlarge language models. Extensive experimental results indicate that our\nproposed method outperforms the baselines, showcasing the potential of\nleveraging the information of ranked answers and using ranked voting to improve\nreasoning performance. The code is available at\nhttps://github.com/szu-tera/RankedVotingSC.",
    "pdf_url": "http://arxiv.org/pdf/2505.10772v1",
    "published": "2025-05-16T01:09:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10771v2",
    "title": "Pipelining Kruskal's: A Neuromorphic Approach for Minimum Spanning Tree",
    "authors": [
      "Yee Hin Chong",
      "Peng Qu",
      "Yuchen Li",
      "Youhui Zhang"
    ],
    "abstract": "Neuromorphic computing, characterized by its event-driven computation and\nmassive parallelism, is particularly effective for handling data-intensive\ntasks in low-power environments, such as computing the minimum spanning tree\n(MST) for large-scale graphs. The introduction of dynamic synaptic\nmodifications provides new design opportunities for neuromorphic algorithms.\nBuilding on this foundation, we propose an SNN-based union-sort routine and a\npipelined version of Kruskal's algorithm for MST computation. The event-driven\nnature of our method allows for the concurrent execution of two completely\ndecoupled stages: neuromorphic sorting and union-find. Our approach\ndemonstrates superior performance compared to state-of-the-art Prim 's-based\nmethods on large-scale graphs from the DIMACS10 dataset, achieving speedups by\n269.67x to 1283.80x, with a median speedup of 540.76x. We further evaluate the\npipelined implementation against two serial variants of Kruskal's algorithm,\nwhich rely on neuromorphic sorting and neuromorphic radix sort, showing\nsignificant performance advantages in most scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.10771v2",
    "published": "2025-05-16T01:00:15+00:00",
    "categories": [
      "cs.ET",
      "cs.NE"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.10770v1",
    "title": "Geofenced Unmanned Aerial Robotic Defender for Deer Detection and Deterrence (GUARD)",
    "authors": [
      "Ebasa Temesgen",
      "Mario Jerez",
      "Greta Brown",
      "Graham Wilson",
      "Sree Ganesh Lalitaditya Divakarla",
      "Sarah Boelter",
      "Oscar Nelson",
      "Robert McPherson",
      "Maria Gini"
    ],
    "abstract": "Wildlife-induced crop damage, particularly from deer, threatens agricultural\nproductivity. Traditional deterrence methods often fall short in scalability,\nresponsiveness, and adaptability to diverse farmland environments. This paper\npresents an integrated unmanned aerial vehicle (UAV) system designed for\nautonomous wildlife deterrence, developed as part of the Farm Robotics\nChallenge. Our system combines a YOLO-based real-time computer vision module\nfor deer detection, an energy-efficient coverage path planning algorithm for\nefficient field monitoring, and an autonomous charging station for continuous\noperation of the UAV. In collaboration with a local Minnesota farmer, the\nsystem is tailored to address practical constraints such as terrain,\ninfrastructure limitations, and animal behavior. The solution is evaluated\nthrough a combination of simulation and field testing, demonstrating robust\ndetection accuracy, efficient coverage, and extended operational time. The\nresults highlight the feasibility and effectiveness of drone-based wildlife\ndeterrence in precision agriculture, offering a scalable framework for future\ndeployment and extension.",
    "pdf_url": "http://arxiv.org/pdf/2505.10770v1",
    "published": "2025-05-16T00:59:31+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10769v1",
    "title": "Unifying Segment Anything in Microscopy with Multimodal Large Language Model",
    "authors": [
      "Manyu Li",
      "Ruian He",
      "Zixian Zhang",
      "Weimin Tan",
      "Bo Yan"
    ],
    "abstract": "Accurate segmentation of regions of interest in biomedical images holds\nsubstantial value in image analysis. Although several foundation models for\nbiomedical segmentation have currently achieved excellent performance on\ncertain datasets, they typically demonstrate sub-optimal performance on unseen\ndomain data. We owe the deficiency to lack of vision-language knowledge before\nsegmentation. Multimodal Large Language Models (MLLMs) bring outstanding\nunderstanding and reasoning capabilities to multimodal tasks, which inspires us\nto leverage MLLMs to inject Vision-Language Knowledge (VLK), thereby enabling\nvision models to demonstrate superior generalization capabilities on\ncross-domain datasets. In this paper, we propose using MLLMs to guide SAM in\nlearning microscopy crose-domain data, unifying Segment Anything in Microscopy,\nnamed uLLSAM. Specifically, we propose the Vision-Language Semantic Alignment\n(VLSA) module, which injects VLK into Segment Anything Model (SAM). We find\nthat after SAM receives global VLK prompts, its performance improves\nsignificantly, but there are deficiencies in boundary contour perception.\nTherefore, we further propose Semantic Boundary Regularization (SBR) to prompt\nSAM. Our method achieves performance improvements of 7.71% in Dice and 12.10%\nin SA across 9 in-domain microscopy datasets, achieving state-of-the-art\nperformance. Our method also demonstrates improvements of 6.79% in Dice and\n10.08% in SA across 10 out-ofdomain datasets, exhibiting strong generalization\ncapabilities. Code is available at https://github.com/ieellee/uLLSAM.",
    "pdf_url": "http://arxiv.org/pdf/2505.10769v1",
    "published": "2025-05-16T00:55:56+00:00",
    "categories": [
      "cs.CV",
      "68T99"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10768v1",
    "title": "Existence of solutions to the semilinear damped wave equation with non-$L^2$ slowly decaying data : polynomial nonlinearity case",
    "authors": [
      "Masahiro Ikeda",
      "Takahisa Inui",
      "Yuta Wakasugi"
    ],
    "abstract": "We study the Cauchy problem of the semilinear damped wave equation with\npolynomial nonlinearity, and establish the local and global existence of the\nsolution for slowly decaying initial data not belonging to $L^2(\\mathbb{R}^n)$\nin general. Our approach is based on the $L^p$-$L^q$ estimates of linear\nsolutions and the fractional Leibniz rule in suitable homogeneous Besov spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.10768v1",
    "published": "2025-05-16T00:50:51+00:00",
    "categories": [
      "math.AP",
      "35L71, 35A01"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.10767v1",
    "title": "Crescent domain-wall pairs in anisotropic two-dimensional MnOI monolayer with fast dynamics",
    "authors": [
      "Yijun Yang",
      "Zhong Shen",
      "Jun Chen",
      "Shuai Dong",
      "Xiaoyan Yao"
    ],
    "abstract": "The controllable and efficient manipulation is always a key challenge for the\napplication of topological magnetic textures in spintronic devices. By\nfirst-principles calculations and atomistic simulations, the present work\nreveals an exotic domain-wall pair in crescent shape, which possesses topology\nin one dimension and particle-like robustness in two dimensions. Its\nantiferromagnetic version is observed in the two-dimensional MnOI monolayer\nwith a strong anisotropy, and the ferromagnetic version exists under an\nappropriate strain. Both of them can be driven efficiently by current to move\nin a straight line along a certain direction. Hereby, another possible path is\nprovided to realize the application of topological magnetic texture in the\nnext-generation high-speed spintronic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.10767v1",
    "published": "2025-05-16T00:44:54+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.10766v2",
    "title": "Exact multiple anomalous mobility edges in a flat band geometry",
    "authors": [
      "Zhanpeng Lu",
      "Hui Liu",
      "Yunbo Zhang",
      "Zhihao Xu"
    ],
    "abstract": "Anomalous mobility edges(AMEs), separating localized from multifractal\ncritical states, represent a novel form of localization transition in\nquasiperiodic systems. However, quasi-periodic models exhibiting exact AMEs\nremain relatively rare, limiting the understanding of these transitions. In\nthis work, we leverage the geometric structure of flat band models to construct\nexact AMEs. Specifically, we introduce an anti-symmetric diagonal\nquasi-periodic mosaic modulation, which consists of both quasi-periodic and\nconstant potentials, into a cross-stitch flat band lattice. When the constant\npotential is zero, the system resides entirely in a localized phase, with its\ndispersion relation precisely determined. For non-zero constant potentials, we\nuse a simple method to derive analytical solutions for a class of AMEs,\nproviding exact results for both the AMEs and the system's localization and\ncritical properties. Additionally, we propose a classical electrical circuit\ndesign to experimentally realize the system. This study offers valuable\ninsights into the existence and characteristics of AMEs in quasi-periodic\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.10766v2",
    "published": "2025-05-16T00:44:19+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "quant-ph"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.10765v1",
    "title": "A completeness theorem in proof-theoretic semantics via set-theoretic semantics",
    "authors": [
      "Ryo Takemura"
    ],
    "abstract": "We investigate the completeness of intuitionistic logic with respect to\nPrawitz's proof-theoretic validity. As an intuitionistic natural deduction\nsystem, we apply atomic second-order intuitionistic propositional logic. By\ndeveloping phase semantics with proof-terms introduced by Okada & Takemura\n(2007), we construct a special phase model whose domain consists of closed\nterms. We then discuss how our phase semantics can be regarded as\nproof-theoretic semantics, and we prove completeness with respect to\nproof-theoretic semantics via our phase semantics.",
    "pdf_url": "http://arxiv.org/pdf/2505.10765v1",
    "published": "2025-05-16T00:43:34+00:00",
    "categories": [
      "math.LO"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10764v3",
    "title": "SurgXBench: Explainable Vision-Language Model Benchmark for Surgery",
    "authors": [
      "Jiajun Cheng",
      "Xianwu Zhao",
      "Sainan Liu",
      "Xiaofan Yu",
      "Ravi Prakash",
      "Patrick J. Codd",
      "Jonathan Elliott Katz",
      "Shan Lin"
    ],
    "abstract": "Innovations in digital intelligence are transforming robotic surgery with\nmore informed decision-making. Real-time awareness of surgical instrument\npresence and actions (e.g., cutting tissue) is essential for such systems. Yet,\ndespite decades of research, most machine learning models for this task are\ntrained on small datasets and still struggle to generalize. Recently,\nvision-Language Models (VLMs) have brought transformative advances in reasoning\nacross visual and textual modalities. Their unprecedented generalization\ncapabilities suggest great potential for advancing intelligent robotic surgery.\nHowever, surgical VLMs remain under-explored, and existing models show limited\nperformance, highlighting the need for benchmark studies to assess their\ncapabilities and limitations and to inform future development. To this end, we\nbenchmark the zero-shot performance of several advanced VLMs on two public\nrobotic-assisted laparoscopic datasets for instrument and action\nclassification. Beyond standard evaluation, we integrate explainable AI to\nvisualize VLM attention and uncover causal explanations behind their\npredictions. This provides a previously underexplored perspective in this field\nfor evaluating the reliability of model predictions. We also propose several\nexplainability analysis-based metrics to complement standard evaluations. Our\nanalysis reveals that surgical VLMs, despite domain-specific training, often\nrely on weak contextual cues rather than clinically relevant visual evidence,\nhighlighting the need for stronger visual and reasoning supervision in surgical\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2505.10764v3",
    "published": "2025-05-16T00:42:18+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.10763v1",
    "title": "Odd Shifted Parking Functions",
    "authors": [
      "Zachary Hamaker",
      "Jesse Kim"
    ],
    "abstract": "Stanley recently introduced the shifted parking function symmetric function\n$SH_n$, which is the shiftification of Haiman's parking function symmetric\nfunction $PF_n$. The function $SH_n$ lives in the subalgebra of symmetric\nfunctions generated by odd power sums. Stanley showed how to expand $SH_n$ into\nthe $V-$basis of this algebra, which is indexed by partitions with all parts\nodd and is analogous to the complete homogeneous (or elementary) basis of\nsymmetric functions. We introduce odd shifted parking functions to give\ncombinatorial and representation-theoretic realizations of the $V-$expansion of\n$SH_n$, resolving the main open problem in his paper. Further, we present two\nrepresentation-theoretic realizations of shiftification allowing us to\ninterpret $SH_n$ as the spin character of a projective representation. We\nconclude with further directions, including a relationship between $SH_n$ and\nHaglund's $(q,t)-$Schr\\\"oder theorem.",
    "pdf_url": "http://arxiv.org/pdf/2505.10763v1",
    "published": "2025-05-16T00:41:24+00:00",
    "categories": [
      "math.CO",
      "05E05, 05E10"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10762v1",
    "title": "Deep Symbolic Optimization: Reinforcement Learning for Symbolic Mathematics",
    "authors": [
      "Conor F. Hayes",
      "Felipe Leno Da Silva",
      "Jiachen Yang",
      "T. Nathan Mundhenk",
      "Chak Shing Lee",
      "Jacob F. Pettit",
      "Claudio Santiago",
      "Sookyung Kim",
      "Joanne T. Kim",
      "Ignacio Aravena Solis",
      "Ruben Glatt",
      "Andre R. Goncalves",
      "Alexander Ladd",
      "Ahmet Can Solak",
      "Thomas Desautels",
      "Daniel Faissol",
      "Brenden K. Petersen",
      "Mikel Landajuela"
    ],
    "abstract": "Deep Symbolic Optimization (DSO) is a novel computational framework that\nenables symbolic optimization for scientific discovery, particularly in\napplications involving the search for intricate symbolic structures. One\nnotable example is equation discovery, which aims to automatically derive\nmathematical models expressed in symbolic form. In DSO, the discovery process\nis formulated as a sequential decision-making task. A generative neural network\nlearns a probabilistic model over a vast space of candidate symbolic\nexpressions, while reinforcement learning strategies guide the search toward\nthe most promising regions. This approach integrates gradient-based\noptimization with evolutionary and local search techniques, and it incorporates\nin-situ constraints, domain-specific priors, and advanced policy optimization\nmethods. The result is a robust framework capable of efficiently exploring\nextensive search spaces to identify interpretable and physically meaningful\nmodels. Extensive evaluations on benchmark problems have demonstrated that DSO\nachieves state-of-the-art performance in both accuracy and interpretability. In\nthis chapter, we provide a comprehensive overview of the DSO framework and\nillustrate its transformative potential for automating symbolic optimization in\nscientific discovery.",
    "pdf_url": "http://arxiv.org/pdf/2505.10762v1",
    "published": "2025-05-16T00:31:19+00:00",
    "categories": [
      "cs.LG",
      "cs.NE",
      "cs.SC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.13499v1",
    "title": "Optimal Control for Transformer Architectures: Enhancing Generalization, Robustness and Efficiency",
    "authors": [
      "Kelvin Kan",
      "Xingjian Li",
      "Benjamin J. Zhang",
      "Tuhin Sahai",
      "Stanley Osher",
      "Markos A. Katsoulakis"
    ],
    "abstract": "We study Transformers through the perspective of optimal control theory,\nusing tools from continuous-time formulations to derive actionable insights\ninto training and architecture design. This framework improves the performance\nof existing Transformer models while providing desirable theoretical\nguarantees, including generalization and robustness. Our framework is designed\nto be plug-and-play, enabling seamless integration with established Transformer\nmodels and requiring only slight changes to the implementation. We conduct\nseven extensive experiments on tasks motivated by text generation, sentiment\nanalysis, image classification, and point cloud classification. Experimental\nresults show that the framework improves the test performance of the baselines,\nwhile being more parameter-efficient. On character-level text generation with\nnanoGPT, our framework achieves a 46% reduction in final test loss while using\n42% fewer parameters. On GPT-2, our framework achieves a 5.6% reduction in\nfinal test loss, demonstrating scalability to larger models. To the best of our\nknowledge, this is the first work that applies optimal control theory to both\nthe training and architecture of Transformers. It offers a new foundation for\nsystematic, theory-driven improvements and moves beyond costly trial-and-error\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.13499v1",
    "published": "2025-05-16T00:31:10+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10761v1",
    "title": "Algebraic Type Theory, Part 1: Martin-Löf algebras",
    "authors": [
      "Steve Awodey"
    ],
    "abstract": "A new algebraic treatment of dependent type theory is proposed using ideas\nderived from topos theory and algebraic set theory.",
    "pdf_url": "http://arxiv.org/pdf/2505.10761v1",
    "published": "2025-05-16T00:20:07+00:00",
    "categories": [
      "math.CT",
      "math.LO",
      "18C40, 18C50, 03B38"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.10760v1",
    "title": "Counterfactual Behavior Cloning: Offline Imitation Learning from Imperfect Human Demonstrations",
    "authors": [
      "Shahabedin Sagheb",
      "Dylan P. Losey"
    ],
    "abstract": "Learning from humans is challenging because people are imperfect teachers.\nWhen everyday humans show the robot a new task they want it to perform, humans\ninevitably make errors (e.g., inputting noisy actions) and provide suboptimal\nexamples (e.g., overshooting the goal). Existing methods learn by mimicking the\nexact behaviors the human teacher provides -- but this approach is\nfundamentally limited because the demonstrations themselves are imperfect. In\nthis work we advance offline imitation learning by enabling robots to\nextrapolate what the human teacher meant, instead of only considering what the\nhuman actually showed. We achieve this by hypothesizing that all of the human's\ndemonstrations are trying to convey a single, consistent policy, while the\nnoise and sub-optimality within their behaviors obfuscates the data and\nintroduces unintentional complexity. To recover the underlying policy and learn\nwhat the human teacher meant, we introduce Counter-BC, a generalized version of\nbehavior cloning. Counter-BC expands the given dataset to include actions close\nto behaviors the human demonstrated (i.e., counterfactual actions that the\nhuman teacher could have intended, but did not actually show). During training\nCounter-BC autonomously modifies the human's demonstrations within this\nexpanded region to reach a simple and consistent policy that explains the\nunderlying trends in the human's dataset. Theoretically, we prove that\nCounter-BC can extract the desired policy from imperfect data, multiple users,\nand teachers of varying skill levels. Empirically, we compare Counter-BC to\nstate-of-the-art alternatives in simulated and real-world settings with noisy\ndemonstrations, standardized datasets, and real human teachers. See videos of\nour work here: https://youtu.be/XaeOZWhTt68",
    "pdf_url": "http://arxiv.org/pdf/2505.10760v1",
    "published": "2025-05-16T00:20:06+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.10759v1",
    "title": "Random Client Selection on Contrastive Federated Learning for Tabular Data",
    "authors": [
      "Achmad Ginanjar",
      "Xue Li",
      "Priyanka Singh",
      "Wen Hua"
    ],
    "abstract": "Vertical Federated Learning (VFL) has revolutionised collaborative machine\nlearning by enabling privacy-preserving model training across multiple parties.\nHowever, it remains vulnerable to information leakage during intermediate\ncomputation sharing. While Contrastive Federated Learning (CFL) was introduced\nto mitigate these privacy concerns through representation learning, it still\nfaces challenges from gradient-based attacks. This paper presents a\ncomprehensive experimental analysis of gradient-based attacks in CFL\nenvironments and evaluates random client selection as a defensive strategy.\nThrough extensive experimentation, we demonstrate that random client selection\nproves particularly effective in defending against gradient attacks in the CFL\nnetwork. Our findings provide valuable insights for implementing robust\nsecurity measures in contrastive federated learning systems, contributing to\nthe development of more secure collaborative learning frameworks",
    "pdf_url": "http://arxiv.org/pdf/2505.10759v1",
    "published": "2025-05-16T00:20:02+00:00",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.10758v2",
    "title": "Characteristic transition of the dominant power loss from diffractive to ohmic in overmoded and periodically loaded waveguides at high frequency",
    "authors": [
      "Adham Naji",
      "Pawan Kumar Gupta",
      "Gennady Stupakov"
    ],
    "abstract": "The analysis of electromagnetic fields in cylindrical waveguiding structures\nthat contain periodic ring loading, whether for applications in\ncharged-particle accelerators or radiation transportation, has been\ntraditionally conducted under simplifying limits, where the structure is either\nsingle-moded at the lower-frequency limit or overmoded at high-frequency limit.\nThese limits have often allowed us to find spectral (modal) expansions for the\nfields under simpler analytical and computational conditions, with ohmic\neffects typically being the dominant power loss mechanism in the lower limit,\nwhile diffraction effects dominate the loss in the higher limit. In this\nLetter, we report the observation of a transition point in the character of the\nmain loss mechanism, where ohmic loss becomes dominant in a structure typically\npresumed to be dominated by diffraction loss. The results follow a formal\nanalysis for the scattered vector fields in a highly overmoded THz waveguide.\nThe findings bridge between the traditional theoretical descriptions for the\ntwo limits and reveal key tradeoffs that inform experiments for the\ntransportation of THz radiation over long distances.",
    "pdf_url": "http://arxiv.org/pdf/2505.10758v2",
    "published": "2025-05-16T00:08:43+00:00",
    "categories": [
      "physics.app-ph",
      "physics.acc-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.13498v1",
    "title": "IRLBench: A Multi-modal, Culturally Grounded, Parallel Irish-English Benchmark for Open-Ended LLM Reasoning Evaluation",
    "authors": [
      "Khanh-Tung Tran",
      "Barry O'Sullivan",
      "Hoang D. Nguyen"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have demonstrated promising\nknowledge and reasoning abilities, yet their performance in multilingual and\nlow-resource settings remains underexplored. Existing benchmarks often exhibit\ncultural bias, restrict evaluation to text-only, rely on multiple-choice\nformats, and, more importantly, are limited for extremely low-resource\nlanguages. To address these gaps, we introduce IRLBench, presented in parallel\nEnglish and Irish, which is considered definitely endangered by UNESCO. Our\nbenchmark consists of 12 representative subjects developed from the 2024 Irish\nLeaving Certificate exams, enabling fine-grained analysis of model capabilities\nacross domains. By framing the task as long-form generation and leveraging the\nofficial marking scheme, it does not only support a comprehensive evaluation of\ncorrectness but also language fidelity. Our extensive experiments of leading\nclosed-source and open-source LLMs reveal a persistent performance gap between\nEnglish and Irish, in which models produce valid Irish responses less than 80\\%\nof the time, and answer correctly 55.8\\% of the time compared to 76.2\\% in\nEnglish for the best-performing model. We release IRLBench\n(https://huggingface.co/datasets/ReliableAI/IRLBench) and an accompanying\nevaluation codebase (https://github.com/ReML-AI/IRLBench) to enable future\nresearch on robust, culturally aware multilingual AI development.",
    "pdf_url": "http://arxiv.org/pdf/2505.13498v1",
    "published": "2025-05-16T00:02:05+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.10757v1",
    "title": "Single Vanadium Dioxide Nanoparticle-Enabled Plasmonic switch with Thermal and Electronic Reconfigurability",
    "authors": [
      "Gregory Tanyi",
      "Daniel Peace",
      "Han-Hao Cheng",
      "Guanghui Ren",
      "Xuan Hiep Dinh",
      "Mohammed Taha",
      "Arnan Mitchell",
      "Karsten Hoehn",
      "Christina Lim",
      "Ranjith Unnithan"
    ],
    "abstract": "We present an integrated switch that combines plasmonic and neuromorphic\ntechnologies with a single sub-stoichiometric VO2-x nanoparticle. The presented\ndevice acts as a versatile plasmonic switch with dual thermal and electrical\nreconfigurability leveraging the near-room temperature phase transition of the\nVO2-x nanoparticles combined with the rapid phase recovery to drive the device.\nThe change in both the optical and electrical properties of the VO2-x\nnanoparticle enables simultaneous optical and electrical readouts making the\nplasmonic device suitable as a phase change memory cell which is crucial in the\nconvergence of computing and communication technologies. Our demonstration of\nreversible electrical switching, evidenced by a 6dB modulation depth and\nconcurrent optical and electrical outputs, signifies a major stride in merging\nelectronic and photonic functionalities within phase-change material devices.\nThis novel strategy not only harmonizes optical communication with electronic\ncomputing but also advances the development of sophisticated integrated\nneuromorphic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.10757v1",
    "published": "2025-05-16T00:00:30+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  }
]