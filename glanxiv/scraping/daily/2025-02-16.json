[
  {
    "id": "http://arxiv.org/abs/2502.15775v1",
    "title": "Serverless Edge Computing: A Taxonomy, Systematic Literature Review, Current Trends and Research Challenges",
    "authors": [
      "Iqra Batool",
      "Sania Kanwal"
    ],
    "abstract": "In recent years, the rapid expansion of Internet of Things (IoT) nodes and\ndevices has seamlessly integrated technology into everyday life, amplifying the\ndemand for optimized computing solutions. To meet the critical Quality of\nService (QoS) requirements such as reduced latency, efficient bandwidth usage,\nswift reaction times, scalability, privacy, and security serverless edge\ncomputing has emerged as a transformative paradigm. This systematic literature\nreview explores the current landscape of serverless edge computing, analyzing\nrecent studies to uncover the present state of this technology. The review\nidentifies the essential features of serverless edge computing, focusing on\narchitectural designs, QoS metrics, implementation specifics, practical\napplications, and communication modalities central to this paradigm.\nFurthermore, we propose a comprehensive taxonomy that categorizes existing\nresearch efforts, providing a comparative analysis based on these\nclassifications. The paper concludes with an in depth discussion of open\nresearch challenges and highlights promising future directions that hold\npotential for advancing serverless edge computing research.",
    "pdf_url": "http://arxiv.org/pdf/2502.15775v1",
    "published": "2025-02-16T23:40:27+00:00",
    "categories": [
      "cs.NI",
      "cs.ET"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11318v1",
    "title": "Alias4SBML: A Python Package for Generating Alias Nodes in SBML Models",
    "authors": [
      "Adel Heydarabadipour",
      "Herbert M Sauro"
    ],
    "abstract": "Interpreting biological networks becomes challenging when molecular\ncomponents, such as genes or proteins, participate in numerous interactions,\nresulting in densely connected regions and overlapping interactions that\nobscure functional relationships and biological insights. To address this, we\nintroduce Alias4SBML, a Python package that enhances SBML model visualizations\nby generating alias nodes-duplicate representations of highly connected\nmolecular components-to redistribute interactions and reduce visual congestion.\nApplying Alias4SBML to the SBML models, including one with 59 species and 41\nreactions and another with 701 species and 505 reactions, demonstrated\nsignificant improvements in readability, with edge length reductions of up to\n50.88 %. Our approach preserves the structural integrity of the network while\nfacilitating clearer interpretation of complex biological systems, offering a\nflexible and scalable solution for visualizing biological models more\nefficiently.",
    "pdf_url": "http://arxiv.org/pdf/2502.11318v1",
    "published": "2025-02-16T23:32:58+00:00",
    "categories": [
      "q-bio.MN"
    ],
    "primary_category": "q-bio.MN"
  },
  {
    "id": "http://arxiv.org/abs/2502.12208v1",
    "title": "AI-Augmented Metamorphic Testing for Comprehensive Validation of Autonomous Vehicles",
    "authors": [
      "Tony Zhang",
      "Burak Kantarci",
      "Umair Siddique"
    ],
    "abstract": "Self-driving cars have the potential to revolutionize transportation, but\nensuring their safety remains a significant challenge. These systems must\nnavigate a variety of unexpected scenarios on the road, and their complexity\nposes substantial difficulties for thorough testing. Conventional testing\nmethodologies face critical limitations, including the oracle problem\ndetermining whether the systems behavior is correct and the inability to\nexhaustively recreate a range of situations a self-driving car may encounter.\nWhile Metamorphic Testing (MT) offers a partial solution to these challenges,\nits application is often limited by simplistic modifications to test scenarios.\nIn this position paper, we propose enhancing MT by integrating AI-driven image\ngeneration tools, such as Stable Diffusion, to improve testing methodologies.\nThese tools can generate nuanced variations of driving scenarios within the\noperational design domain (ODD)for example, altering weather conditions,\nmodifying environmental elements, or adjusting lane markings while preserving\nthe critical features necessary for system evaluation. This approach enables\nreproducible testing, efficient reuse of test criteria, and comprehensive\nevaluation of a self-driving systems performance across diverse scenarios,\nthereby addressing key gaps in current testing practices.",
    "pdf_url": "http://arxiv.org/pdf/2502.12208v1",
    "published": "2025-02-16T23:31:59+00:00",
    "categories": [
      "cs.SE",
      "cs.RO"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11317v1",
    "title": "Time-dependent approach to the X-ray photoemission problem",
    "authors": [
      "F. D. Picoli",
      "G. Diniz",
      "M. P. Lenzarini",
      "I. D'Amico",
      "L. N. Oliveira"
    ],
    "abstract": "X-ray photoemission from simple metals has been thoroughly studied,\nexperimentally, and theoretically, in the frequency domain. Here we investigate\nthe same problem in the time domain, with the ultimate purpose of improving the\nnumerical renormalization-group method. We focus our study on the time\ndependence of the photoemission current $\\mathcal{F}(t)$, a fidelity, in the\nterminology of quantum information. To establish benchmarks, we first calculate\n$\\mathcal{F}(t)$ analytically and numerically for a tight-binding model.\nAnalytically, we derive an approximate expression that becomes very precise at\nlarge times. Numerically, we diagonalize the tight-binding Hamiltonian and\ncompute $\\mathcal{F}(t)$ from its eigenvalues and eigenvectors, a\nstraightforward procedure that covers the segment of the $t$ axis in which the\nanalytical expression is less accurate. The time dependence shows features of\nphysical interest that have received little attention because they are\ninconspicuous in the frequency domain; the analytical expression provides a\nsimple interpretation and traces them to an unusual form of interference. We\nthen turn to eNRG, a recently proposed real-space variant that is more flexible\nthan Wilson's NRG method, and present two complementary time-dependent\nalgorithms. Comparison with the benchmarks shows that one of the eNRG\nalgorithms yields virtually exact photocurrents with a small fraction of the\ncomputational effort to diagonalize the tight-binding Hamiltonian. The second\nalgorithm is computationally less demanding and produces precise results at\nlong times. In contemplation of extensions to correlated-impurity models, we\nidentify sources of deviation and discuss the virtues and drawbacks of the two\nprocedures.",
    "pdf_url": "http://arxiv.org/pdf/2502.11317v1",
    "published": "2025-02-16T23:31:47+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11316v2",
    "title": "Standalone FPGA-Based QAOA Emulator for Weighted-MaxCut on Embedded Devices",
    "authors": [
      "Seonghyun Choi",
      "Kyeongwon Lee",
      "Jae-Jin Lee",
      "Woojoo Lee"
    ],
    "abstract": "Quantum computing QC emulation is crucial for advancing QC applications,\nespecially given the scalability constraints of current devices. FPGA-based\ndesigns offer an efficient and scalable alternative to traditional large-scale\nplatforms, but most are tightly integrated with high-performance systems,\nlimiting their use in mobile and edge environments. This study introduces a\ncompact, standalone FPGA-based QC emulator designed for embedded systems,\nleveraging the Quantum Approximate Optimization Algorithm (QAOA) to solve the\nWeighted-MaxCut problem. By restructuring QAOA operations for hardware\ncompatibility, the proposed design reduces time complexity from O(N^2) to O(N),\nwhere N equals 2^n for n qubits. This reduction, coupled with a pipeline\narchitecture, significantly minimizes resource consumption, enabling support\nfor up to nine qubits on mid-tier FPGAs, roughly three times more than\ncomparable designs. Additionally, the emulator achieved energy savings ranging\nfrom 1.53 times for two-qubit configurations to up to 852 times for nine-qubit\nconfigurations, compared to software-based QAOA on embedded processors. These\nresults highlight the practical scalability and resource efficiency of the\nproposed design, providing a robust foundation for QC emulation in\nresource-constrained edge devices.",
    "pdf_url": "http://arxiv.org/pdf/2502.11316v2",
    "published": "2025-02-16T23:30:16+00:00",
    "categories": [
      "cs.ET",
      "quant-ph"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2502.11315v1",
    "title": "Microscopic contact line dynamics dictate the emergent behaviors of particle rafts",
    "authors": [
      "Ranit Mukherjee",
      "Zih-Yin Chen",
      "Xiang Cheng",
      "Sungyon Lee"
    ],
    "abstract": "Fluid-fluid interfaces laden with discrete particles behave curiously like\ncontinuous elastic sheets, leading to their applications in emulsion and foam\nstabilization. Although existing continuum models can qualitatively capture the\nelastic buckling of these particle-laden interfaces -- often referred to as\nparticle rafts -- under compression, they fail to link their macroscopic\ncollective properties to the microscopic behaviors of individual particles.\nThus, phenomena such as particle expulsion from the compressed rafts remain\nunexplained. Here, by combining systematic experiments with first-principle\nmodeling, we reveal how the macroscopic mechanical properties of particle rafts\nemerge from particle-scale interactions. We construct a phase diagram that\ndelineates the conditions under which a particle raft collapses via collective\nfolding versus single-particle expulsion. Guided by this theoretical framework,\nwe demonstrate control over the raft's failure mode by tuning the\nphysicochemical properties of individual particles. Our study highlights the\npreviously overlooked dual nature of particle rafts and exemplifies how\ncollective dynamics can arise from discrete components with simple\ninteractions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11315v1",
    "published": "2025-02-16T23:24:50+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2502.11314v1",
    "title": "A note on some high-dimensional handlebodies",
    "authors": [
      "Geunyoung Kim"
    ],
    "abstract": "For $k \\geq 0$ and $n \\geq 2k+1$, we show that every $n$-dimensional\n$k$-handlebody is the product of a $2k$-dimensional $k$-handlebody and the\nstandard $(n-2k)$-ball. For $k \\geq 2$ and $n \\geq 2k$, we introduce\n$(n,k)$-Kirby diagrams for some $n$-dimensional $k$-handlebodies, where\n$(4,2)$-Kirby diagrams correspond to the original Kirby diagrams for\n$4$-dimensional $2$-handlebodies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11314v1",
    "published": "2025-02-16T23:22:36+00:00",
    "categories": [
      "math.GT",
      "57K45, 57K50, 57R65"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11313v1",
    "title": "Tracking Adiabaticity in Non-Equilibrium Many-Body Systems: The Hard Case of the X-ray Photoemission in Metals",
    "authors": [
      "G. Diniz",
      "F. D. Picoli",
      "L. N. Oliveira",
      "I. D'Amico"
    ],
    "abstract": "The level of adiabaticity determines many properties of time-dependent\nquantum systems. However, a reliable and easy-to-apply criterion to check and\ntrack it remains an open question, especially for complex many-body systems.\nHere we test techniques based on metrics which have been recently proposed to\nquantitatively characterize and track adiabaticity. We investigate the time\nevolution of x-ray photoemission in metals, which displays a strongly\nout-of-equilibrium character, continuum energy spectrum, and experiences the\nAnderson orthogonality catastrophe: a nightmarish scenario for this type of\ntest. Our results show that the metrics-based methods remains valid. In\nparticular, we demonstrate that the natural local density distance is able not\nonly to track adiabaticity, but also to provide information not captured by the\ncorresponding Bures' or trace distances about the system's dynamics. In the\nprocess, we establish an explicit upper limit for this local density distance\nin terms of the trace distance, and derive a simple analytical solution that\naccurately describes the time evolution of a Fermi gas with a localized\nscattering potential for a large range of parameters. We also demonstrate that,\nfor x-ray photoemission, the quantum adiabatic criterion, as commonly used,\nfails to predict and track adiabaticity. The local particle density is\ntypically much simpler to compute than the corresponding quantum state and it\nis experimentally measurable: this makes the method tested extremely appealing.",
    "pdf_url": "http://arxiv.org/pdf/2502.11313v1",
    "published": "2025-02-16T23:19:52+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11312v1",
    "title": "AI Generations: From AI 1.0 to AI 4.0",
    "authors": [
      "Jiahao Wu",
      "Hengxu You",
      "Jing Du"
    ],
    "abstract": "This paper proposes that Artificial Intelligence (AI) progresses through\nseveral overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI),\nAI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious AI). Each of\nthese AI generations is driven by shifting priorities among algorithms,\ncomputing power, and data. AI 1.0 ushered in breakthroughs in pattern\nrecognition and information processing, fueling advances in computer vision,\nnatural language processing, and recommendation systems. AI 2.0 built on these\nfoundations through real-time decision-making in digital environments,\nleveraging reinforcement learning and adaptive planning for agentic AI\napplications. AI 3.0 extended intelligence into physical contexts, integrating\nrobotics, autonomous vehicles, and sensor-fused control systems to act in\nuncertain real-world settings. Building on these developments, AI 4.0 puts\nforward the bold vision of self-directed AI capable of setting its own goals,\norchestrating complex training regimens, and possibly exhibiting elements of\nmachine consciousness. This paper traces the historical foundations of AI\nacross roughly seventy years, mapping how changes in technological bottlenecks\nfrom algorithmic innovation to high-performance computing to specialized data,\nhave spurred each generational leap. It further highlights the ongoing\nsynergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical,\nregulatory, and philosophical challenges that arise when artificial systems\napproach (or aspire to) human-like autonomy. Ultimately, understanding these\nevolutions and their interdependencies is pivotal for guiding future research,\ncrafting responsible governance, and ensuring that AI transformative potential\nbenefits society as a whole.",
    "pdf_url": "http://arxiv.org/pdf/2502.11312v1",
    "published": "2025-02-16T23:19:44+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11311v1",
    "title": "On a new proof of the key step in the proof of Brouwer's fixed point theorem",
    "authors": [
      "N. V. Krylov"
    ],
    "abstract": "We present a solution of Exercise 1.2.1 of [2] which yields a short new proof\nof a key step in one of proofs of Brouwer's fixed point theorem, 1910. A few\npeople asked the author about the details of the solution and they might be\ninteresting to a broader audience. Our approach is absolutely different from\nthe ones using algebraic or differential topology or differential calculus and\nis based on a simple observation which somehow escaped many authors treating\nthis theorem in the past.",
    "pdf_url": "http://arxiv.org/pdf/2502.11311v1",
    "published": "2025-02-16T23:14:15+00:00",
    "categories": [
      "math.CA",
      "math.FA",
      "47H10"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11310v2",
    "title": "Generalized Factor Neural Network Model for High-dimensional Regression",
    "authors": [
      "Zichuan Guo",
      "Mihai Cucuringu",
      "Alexander Y. Shestopaloff"
    ],
    "abstract": "We tackle the challenges of modeling high-dimensional data sets, particularly\nthose with latent low-dimensional structures hidden within complex, non-linear,\nand noisy relationships. Our approach enables a seamless integration of\nconcepts from non-parametric regression, factor models, and neural networks for\nhigh-dimensional regression. Our approach introduces PCA and Soft PCA layers,\nwhich can be embedded at any stage of a neural network architecture, allowing\nthe model to alternate between factor modeling and non-linear transformations.\nThis flexibility makes our method especially effective for processing\nhierarchical compositional data. We explore ours and other techniques for\nimposing low-rank structures on neural networks and examine how architectural\ndesign impacts model performance. The effectiveness of our method is\ndemonstrated through simulation studies, as well as applications to forecasting\nfuture price movements of equity ETF indices and nowcasting with macroeconomic\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2502.11310v2",
    "published": "2025-02-16T23:13:55+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "q-fin.ST",
      "62G08, 68T07"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2502.11309v1",
    "title": "Wake transition and aerodynamics of a dragonfly-inspired airfoil",
    "authors": [
      "Alessandro Chiarini",
      "Gabriele Nastro"
    ],
    "abstract": "We investigate the dynamics and the stability of the incompressible flow past\na corrugated dragonfly-inspired airfoil in the two-dimensional (2D) $\\alpha-Re$\nparameter space, where $\\alpha$ is the angle of attack and $Re$ is the Reynolds\nnumber. The angle of attack is varied between $-5^\\circ \\le \\alpha \\le\n10^\\circ$, and $Re$ (based on the free-stream velocity and the airfoil chord)\nis increased up to $Re=6000$. The study relies on linear stability analyses and\nthree-dimensional (3D) nonlinear direct numerical simulations. For all $\\alpha$\nthe primary instability consists of a Hopf bifurcation towards a periodic\nregime. The linear stability analysis reveals that two distinct modes drive the\nflow bifurcation for positive and negative $\\alpha$, being characterised by a\ndifferent frequency and a distinct triggering mechanism. The critical $Re$\ndecreases as $|\\alpha|$ increases, and scales as a power law for large\npositive/negative $\\alpha$. At intermediate $Re$, different limit cycles arise\ndepending on $\\alpha$, each one characterised by a distinctive vortex\ninteraction, leading thus to secondary instabilities of different nature. For\nintermediate positive/negative $\\alpha$ vortices are shed from both the\ntop/bottom leading- and trailing-edge shear layers, and the two phenomena are\nfrequency locked. By means of Floquet stability analysis, we show that the\nsecondary instability consists of a 2D subharmonic bifurcation for large\nnegative $\\alpha$, of a 2D Neimark--Sacker bifurcation for small negative\n$\\alpha$, of a 3D pitchfork bifurcation for small positive $\\alpha$, and of a\n3D subharmonic bifurcation for large positive $\\alpha$. The aerodynamic\nperformance of the dragonfly-inspired airfoil is discussed in relation to the\ndifferent flow regimes emerging in the $\\alpha-Re$ space of parameters.",
    "pdf_url": "http://arxiv.org/pdf/2502.11309v1",
    "published": "2025-02-16T23:12:11+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11308v2",
    "title": "ALGEN: Few-shot Inversion Attacks on Textual Embeddings using Alignment and Generation",
    "authors": [
      "Yiyi Chen",
      "Qiongkai Xu",
      "Johannes Bjerva"
    ],
    "abstract": "With the growing popularity of Large Language Models (LLMs) and vector\ndatabases, private textual data is increasingly processed and stored as\nnumerical embeddings. However, recent studies have proven that such embeddings\nare vulnerable to inversion attacks, where original text is reconstructed to\nreveal sensitive information. Previous research has largely assumed access to\nmillions of sentences to train attack models, e.g., through data leakage or\nnearly unrestricted API access. With our method, a single data point is\nsufficient for a partially successful inversion attack. With as little as 1k\ndata samples, performance reaches an optimum across a range of black-box\nencoders, without training on leaked data. We present a Few-shot Textual\nEmbedding Inversion Attack using ALignment and GENeration (ALGEN), by aligning\nvictim embeddings to the attack space and using a generative model to\nreconstruct text. We find that ALGEN attacks can be effectively transferred\nacross domains and languages, revealing key information. We further examine a\nvariety of defense mechanisms against ALGEN, and find that none are effective,\nhighlighting the vulnerabilities posed by inversion attacks. By significantly\nlowering the cost of inversion and proving that embedding spaces can be aligned\nthrough one-step optimization, we establish a new textual embedding inversion\nparadigm with broader applications for embedding alignment in NLP.",
    "pdf_url": "http://arxiv.org/pdf/2502.11308v2",
    "published": "2025-02-16T23:11:13+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "I.2; J.6"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11307v1",
    "title": "Exploiting Point-Language Models with Dual-Prompts for 3D Anomaly Detection",
    "authors": [
      "Jiaxiang Wang",
      "Haote Xu",
      "Xiaolu Chen",
      "Haodi Xu",
      "Yue Huang",
      "Xinghao Ding",
      "Xiaotong Tu"
    ],
    "abstract": "Anomaly detection (AD) in 3D point clouds is crucial in a wide range of\nindustrial applications, especially in various forms of precision\nmanufacturing. Considering the industrial demand for reliable 3D AD, several\nmethods have been developed. However, most of these approaches typically\nrequire training separate models for each category, which is memory-intensive\nand lacks flexibility. In this paper, we propose a novel Point-Language model\nwith dual-prompts for 3D ANomaly dEtection (PLANE). The approach leverages\nmulti-modal prompts to extend the strong generalization capabilities of\npre-trained Point-Language Models (PLMs) to the domain of 3D point cloud AD,\nachieving impressive detection performance across multiple categories using a\nsingle model. Specifically, we propose a dual-prompt learning method,\nincorporating both text and point cloud prompts. The method utilizes a dynamic\nprompt creator module (DPCM) to produce sample-specific dynamic prompts, which\nare then integrated with class-specific static prompts for each modality,\neffectively driving the PLMs. Additionally, based on the characteristics of\npoint cloud data, we propose a pseudo 3D anomaly generation method (Ano3D) to\nimprove the model's detection capabilities in an unsupervised setting.\nExperimental results demonstrate that the proposed method, which is under the\nmulti-class-one-model paradigm, achieves a +8.7%/+17% gain on anomaly detection\nand localization performance as compared to the state-of-the-art\none-class-one-model methods for the Anomaly-ShapeNet dataset, and obtains\n+4.3%/+4.1% gain for the Real3D-AD dataset. Code will be available upon\npublication.",
    "pdf_url": "http://arxiv.org/pdf/2502.11307v1",
    "published": "2025-02-16T23:10:57+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11306v1",
    "title": "Smoothing Out Hallucinations: Mitigating LLM Hallucination with Smoothed Knowledge Distillation",
    "authors": [
      "Hieu Nguyen",
      "Zihao He",
      "Shoumik Atul Gandre",
      "Ujjwal Pasupulety",
      "Sharanya Kumari Shivakumar",
      "Kristina Lerman"
    ],
    "abstract": "Large language models (LLMs) often suffer from hallucination, generating\nfactually incorrect or ungrounded content, which limits their reliability in\nhigh-stakes applications. A key factor contributing to hallucination is the use\nof hard labels during training, which enforce deterministic supervision,\nencourage overconfidence, and disregard the uncertainty inherent in natural\nlanguage. To address this, we propose mitigating hallucination through\nknowledge distillation (KD), where a teacher model provides smoothed soft\nlabels to a student model, reducing overconfidence and improving factual\ngrounding. We apply KD during supervised finetuning on instructional data,\nevaluating its effectiveness across LLMs from different families. Experimental\nresults on summarization benchmarks demonstrate that KD reduces hallucination\ncompared to standard finetuning while preserving performance on general NLP\ntasks. These findings highlight KD as a promising approach for mitigating\nhallucination in LLMs and improving model reliability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11306v1",
    "published": "2025-02-16T23:05:36+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11305v1",
    "title": "Non-Uniform Memory Sampling in Experience Replay",
    "authors": [
      "Andrii Krutsylo"
    ],
    "abstract": "Continual learning is the process of training machine learning models on a\nsequence of tasks where data distributions change over time. A well-known\nobstacle in this setting is catastrophic forgetting, a phenomenon in which a\nmodel drastically loses performance on previously learned tasks when learning\nnew ones. A popular strategy to alleviate this problem is experience replay, in\nwhich a subset of old samples is stored in a memory buffer and replayed with\nnew data. Despite continual learning advances focusing on which examples to\nstore and how to incorporate them into the training loss, most approaches\nassume that sampling from this buffer is uniform by default.\n  We challenge the assumption that uniform sampling is necessarily optimal. We\nconduct an experiment in which the memory buffer updates the same way in every\ntrial, but the replay probability of each stored sample changes between trials\nbased on different random weight distributions. Specifically, we generate 50\ndifferent non-uniform sampling probability weights for each trial and compare\ntheir final accuracy to the uniform sampling baseline. We find that there is\nalways at least one distribution that significantly outperforms the baseline\nacross multiple buffer sizes, models, and datasets. These results suggest that\nmore principled adaptive replay policies could yield further gains. We discuss\nhow exploiting this insight could inspire new research on non-uniform memory\nsampling in continual learning to better mitigate catastrophic forgetting.\n  The code supporting this study is available at\n$\\href{https://github.com/DentonJC/memory-sampling}{https://github.com/DentonJC/memory-sampling}$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11305v1",
    "published": "2025-02-16T23:04:16+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11304v1",
    "title": "Leveraging Multimodal-LLMs Assisted by Instance Segmentation for Intelligent Traffic Monitoring",
    "authors": [
      "Murat Arda Onsu",
      "Poonam Lohan",
      "Burak Kantarci",
      "Aisha Syed",
      "Matthew Andrews",
      "Sean Kennedy"
    ],
    "abstract": "A robust and efficient traffic monitoring system is essential for smart\ncities and Intelligent Transportation Systems (ITS), using sensors and cameras\nto track vehicle movements, optimize traffic flow, reduce congestion, enhance\nroad safety, and enable real-time adaptive traffic control. Traffic monitoring\nmodels must comprehensively understand dynamic urban conditions and provide an\nintuitive user interface for effective management. This research leverages the\nLLaVA visual grounding multimodal large language model (LLM) for traffic\nmonitoring tasks on the real-time Quanser Interactive Lab simulation platform,\ncovering scenarios like intersections, congestion, and collisions. Cameras\nplaced at multiple urban locations collect real-time images from the\nsimulation, which are fed into the LLaVA model with queries for analysis. An\ninstance segmentation model integrated into the cameras highlights key elements\nsuch as vehicles and pedestrians, enhancing training and throughput. The system\nachieves 84.3% accuracy in recognizing vehicle locations and 76.4% in\ndetermining steering direction, outperforming traditional models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11304v1",
    "published": "2025-02-16T23:03:26+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11303v2",
    "title": "Prescribed-Time and Hyperexponential Concurrent Learning with Partially Corrupted Datasets: A Hybrid Dynamical Systems Approach",
    "authors": [
      "Daniel E. Ochoa",
      "Jorge I. Poveda"
    ],
    "abstract": "We introduce a class of concurrent learning (CL) algorithms designed to solve\nparameter estimation problems with convergence rates ranging from\nhyperexponential to prescribed-time while utilizing alternating datasets during\nthe learning process. The proposed algorithm employs a broad class of dynamic\ngains, from exponentially growing to finite-time blow-up gains, enabling either\nenhanced convergence rates or user-prescribed convergence time independent of\nthe dataset's richness. The CL algorithm can handle applications involving\nswitching between multiple datasets that may have varying degrees of richness\nand potential corruption. The main result establishes convergence rates faster\nthan any exponential while guaranteeing uniform global ultimate boundedness in\nthe presence of disturbances, with an ultimate bound that shrinks to zero as\nthe magnitude of measurement disturbances and corrupted data decreases. The\nstability analysis leverages tools from hybrid dynamical systems theory, along\nwith a dilation/contraction argument on the hybrid time domains of the\nsolutions. The algorithm and main results are illustrated via a numerical\nexample.",
    "pdf_url": "http://arxiv.org/pdf/2502.11303v2",
    "published": "2025-02-16T23:03:11+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11302v1",
    "title": "An Interior-Point Algorithm for Continuous Nonlinearly Constrained Optimization with Noisy Function and Derivative Evaluations",
    "authors": [
      "Frank E. Curtis",
      "Shima Dezfulian",
      "Andreas Waechter"
    ],
    "abstract": "An algorithm based on the interior-point methodology for solving continuous\nnonlinearly constrained optimization problems is proposed, analyzed, and\ntested. The distinguishing feature of the algorithm is that it presumes that\nonly noisy values of the objective and constraint functions and their\nfirst-order derivatives are available. The algorithm is based on a combination\nof a previously proposed interior-point algorithm that allows inexact\nsubproblem solutions and recently proposed algorithms for solving bound- and\nequality-constrained optimization problems with only noisy function and\nderivative values. It is shown that the new interior-point algorithm drives a\nstationarity measure below a threshold that depends on bounds on the noise in\nthe function and derivative values. The results of numerical experiments show\nthat the algorithm is effective across a wide range of problems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11302v1",
    "published": "2025-02-16T23:02:37+00:00",
    "categories": [
      "math.OC",
      "cs.NA",
      "math.NA",
      "65K05, 49M37, 90C53, 90C30, 90C51"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11301v1",
    "title": "Proton and neutron electromagnetic form factors using $N_f$=2+1+1 twisted-mass fermions with physical values of the quark masses",
    "authors": [
      "Constantia Alexandrou",
      "Simone Bacchio",
      "Giannis Koutsou",
      "Bhavna Prasad",
      "Gregoris Spanoudes"
    ],
    "abstract": "We compute the electromagnetic form factors of the proton and neutron using\nlattice QCD with $N_f = 2 + 1 + 1$ twisted mass clover-improved fermions and\nquark masses tuned to their physical values. Three ensembles with lattice\nspacings of $a$=0.080 fm, 0.068 fm, and 0.057 fm, and approximately the same\nphysical volume allow us to obtain the continuum limit directly at the physical\npion mass. Several values of the source-sink time separation ranging from 0.5\nfm to 1.5 fm are used, enabling a thorough analysis of excited state effects\nvia multi-state fits. The disconnected contributions are analyzed using high\nstatistics for the two-point functions combined with low-mode deflation and\nhierarchical probing for the fermion loop estimation. We study the momentum\ndependence of the form factors using the z-expansion and dipole Ansaetze,\nthereby enabling the extraction of the electric and magnetic radii, as well as\nthe magnetic moments in the continuum limit, for which we provide preliminary\nresults.",
    "pdf_url": "http://arxiv.org/pdf/2502.11301v1",
    "published": "2025-02-16T23:02:17+00:00",
    "categories": [
      "hep-lat"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2502.11300v2",
    "title": "CORDIAL: Can Multimodal Large Language Models Effectively Understand Coherence Relationships?",
    "authors": [
      "Aashish Anantha Ramakrishnan",
      "Aadarsh Anantha Ramakrishnan",
      "Dongwon Lee"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) are renowned for their superior\ninstruction-following and reasoning capabilities across diverse problem\ndomains. However, existing benchmarks primarily focus on assessing factual and\nlogical correctness in downstream tasks, with limited emphasis on evaluating\nMLLMs' ability to interpret pragmatic cues and intermodal relationships. To\naddress this gap, we assess the competency of MLLMs in performing Multimodal\nDiscourse Analysis (MDA) using Coherence Relations. Our benchmark, CORDIAL,\nencompasses a broad spectrum of Coherence Relations across 3 different\ndiscourse domains at varying levels of granularity. Through our experiments on\n10+ MLLMs employing different prompting strategies, we show that even top\nmodels like Gemini 1.5 Pro and GPT-4o fail to match the performance of simple\nclassifier-based baselines. This study emphasizes the need to move beyond\nsimilarity-based metrics and adopt a discourse-driven framework for evaluating\nMLLMs, providing a more nuanced assessment of their capabilities. The benchmark\nand code are available at: https://aashish2000.github.io/CORDIAL/",
    "pdf_url": "http://arxiv.org/pdf/2502.11300v2",
    "published": "2025-02-16T22:54:44+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "I.2.7; I.2.10"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11299v4",
    "title": "Grassroots Platforms with Atomic Transactions: Social Networks, Cryptocurrencies, and Democratic Federations",
    "authors": [
      "Ehud Shapiro"
    ],
    "abstract": "Grassroots platforms aim to offer an egalitarian alternative to global\nplatforms. Whereas global platforms can have only a single instance, grassroots\nplatforms can have multiple instances that emerge and operate independently of\neach other and of any global resource except the network, and can interoperate\nand coalesce into ever-larger instances once interconnected. Key grassroots\nplatforms include grassroots social networks, grassroots cryptocurrencies, and\ngrassroots democratic federations. Previously, grassroots platforms were\ndefined formally and proven grassroots using unary distributed transition\nsystems, in which each transition is carried out by a single agent. However,\ngrassroots platforms cater for a more abstract specification using transactions\ncarried out atomically by multiple agents, something that cannot be expressed\nby unary transition systems. As a result, their original specifications and\nproofs were unnecessarily cumbersome and opaque.\n  We enhance the notion of a distributed transition system to include atomic\ntransactions and revisit the notion of grassroots platforms within this new\nfoundation; present crisp specifications of key grassroots platforms using\natomic transactions: befriending and defriending for grassroots social\nnetworks, coin swaps for grassroots cryptocurrencies, and communities forming,\njoining, and leaving a federation for grassroots democratic federations; prove\na general theorem that a platform specified by atomic transactions that are\nso-called interactive is grassroots; show that the atomic transactions used to\nspecify all three platforms are interactive; and conclude that the platforms\nthus specified are indeed grassroots. We thus provide a crisp mathematical\nfoundation for grassroots platforms and a solid and clear starting point from\nwhich their implementation can commence.",
    "pdf_url": "http://arxiv.org/pdf/2502.11299v4",
    "published": "2025-02-16T22:53:48+00:00",
    "categories": [
      "cs.DC",
      "cs.NI",
      "cs.SI"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11298v1",
    "title": "Integrating Language Models for Enhanced Network State Monitoring in DRL-Based SFC Provisioning",
    "authors": [
      "Parisa Fard Moshiri",
      "Murat Arda Onsu",
      "Poonam Lohan",
      "Burak Kantarci",
      "Emil Janulewicz"
    ],
    "abstract": "Efficient Service Function Chain (SFC) provisioning and Virtual Network\nFunction (VNF) placement are critical for enhancing network performance in\nmodern architectures such as Software-Defined Networking (SDN) and Network\nFunction Virtualization (NFV). While Deep Reinforcement Learning (DRL) aids\ndecision-making in dynamic network environments, its reliance on structured\ninputs and predefined rules limits adaptability in unforeseen scenarios.\nAdditionally, incorrect actions by a DRL agent may require numerous training\niterations to correct, potentially reinforcing suboptimal policies and\ndegrading performance. This paper integrates DRL with Language Models (LMs),\nspecifically Bidirectional Encoder Representations from Transformers (BERT) and\nDistilBERT, to enhance network management. By feeding final VNF allocations\nfrom DRL into the LM, the system can process and respond to queries related to\nSFCs, DCs, and VNFs, enabling real-time insights into resource utilization,\nbottleneck detection, and future demand planning. The LMs are fine-tuned to our\ndomain-specific dataset using Low-Rank Adaptation (LoRA). Results show that\nBERT outperforms DistilBERT with a lower test loss (0.28 compared to 0.36) and\nhigher confidence (0.83 compared to 0.74), though BERT requires approximately\n46% more processing time.",
    "pdf_url": "http://arxiv.org/pdf/2502.11298v1",
    "published": "2025-02-16T22:52:14+00:00",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11297v2",
    "title": "Tri-layer SiN-on-Si 8x8 Optical Switches with Thermo-optic and Electro-optic Actuators",
    "authors": [
      "Bohao Sun",
      "Chunhui Yao",
      "Tongyun Li",
      "Ziyao Zhang",
      "Peng Bao",
      "Minjia Chen",
      "Alan Yilun Yuan",
      "Chenxi Tan",
      "Zhitian Shi",
      "Adrian Wonfor",
      "Seb Savory",
      "Keren Bergman",
      "Richard Penty",
      "Qixiang Cheng"
    ],
    "abstract": "We present two spatial-multiplexed switch-and-select (S&S) 8x8 optical\nswitches incorporating a tri-layer SiN-on-Si platform, one equipped with\nthermo-optic (T-O) and the other electro-optic (E-O) switching elements. To the\nbest of our knowledge, the electro-optic switch fabric is the first-of-its-kind\ndevice assembled in such a multi-layer platform. The shuffle between the\nmultiplexer and demultiplexer array is established via a tri-layer Si-SiN-SiN\nstructure, creating a three-dimensional crossing-free photonic shuffle network.\nAt the same time, the implementation of the S&S topology can effectively\nsuppress the first-order crosstalk. The measured on-chip losses for the T-O\nswitch range from 2.1 to 11.5 dB, with a 5.2 dB average, while the E-O device\nexhibits losses between 8.7 to 19.6 dB, with a 15.1 dB average. Both switches\ndemonstrate ultra-low crosstalk, with measured ranges of 38.9 to 50.8 dB and\n42.8 to 51.9 dB, for the T-O and E-O devices respectively. The switching times\nare 17.6 us for the T-O switch and 5.9 ns with the E-O actuated one. These\nperformance metrics highlight the potential of these switches for\nnext-generation data center applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11297v2",
    "published": "2025-02-16T22:45:35+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.11296v2",
    "title": "Active Solids: Topological Defect Self-Propulsion Without Flow",
    "authors": [
      "Fridtjof Brauns",
      "Myles O'Leary",
      "Arthur Hernandez",
      "Mark J. Bowick",
      "M. Cristina Marchetti"
    ],
    "abstract": "The self-propulsion of +1/2 topological defects is a hallmark of active\nnematic fluids, where the defects are advected by the flow field they\nthemselves generate. In this paper we propose a minimal model for defect\nself-propulsion in a nematic active solid: a linear elastic medium with an\nembedded nematic texture that generates active stress and associated elastic\nstrains. We show that such coupling gives rise to self-propelled +1/2 defects\nthat move relative to the elastic medium by local remodeling of the nematic\ntexture without advection. This mechanism is fundamentally different from the\nfluid case and can lead to unbinding of defect pairs and stabilization of +1\ndefects. Our findings might help explain how orientational order, of, for\nexample, muscle fibers, is reconfigured during morphogenesis in solid-like\ntissues. The proposed mechanism may, for instance, control motility and merging\nof +1/2 defects, which play a crucial role in setting up the body axis during\nHydra regeneration.",
    "pdf_url": "http://arxiv.org/pdf/2502.11296v2",
    "published": "2025-02-16T22:38:56+00:00",
    "categories": [
      "cond-mat.soft",
      "nlin.PS"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2502.11295v1",
    "title": "Game-Of-Goals: Using adversarial games to achieve strategic resilience",
    "authors": [
      "Aditya Ghose",
      "Asjad Khan"
    ],
    "abstract": "Our objective in this paper is to develop a machinery that makes a given\norganizational strategic plan resilient to the actions of competitor agents\n(adverse environmental actions). We assume that we are given a goal tree\nrepresenting strategic goals (can also be seen business requirements for a\nsoftware systems) with the assumption that competitor agents are behaving in a\nmaximally adversarial fashion(opposing actions against our sub goals or goals\nin general). We use game tree search methods (such as minimax) to select an\noptimal execution strategy(at a given point in time), such that it can maximize\nour chances of achieving our (high level) strategic goals. Our machinery helps\nus determine which path to follow(strategy selection) to achieve the best end\noutcome. This is done by comparing alternative execution strategies available\nto us via an evaluation function. Our evaluation function is based on the idea\nthat we want to make our execution plans defensible(future-proof) by selecting\nexecution strategies that make us least vulnerable to adversarial actions by\nthe competitor agents. i.e we want to select an execution strategy such that\nits leaves minimum room(or options) for the adversary to cause\nimpediment/damage to our business goals/plans.",
    "pdf_url": "http://arxiv.org/pdf/2502.11295v1",
    "published": "2025-02-16T22:34:59+00:00",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11294v2",
    "title": "Tunnels Under Geometries (or Instantons Know Their Algebras)",
    "authors": [
      "Dmitry Galakhov",
      "Alexei Morozov"
    ],
    "abstract": "In the tight binding model with multiple degenerate vacua we might treat wave\nfunction overlaps as instanton tunnelings between different wells (vacua). An\namplitude for such a tunneling process might be constructed as\n$\\mathsf{T}_{i\\to j}\\sim e^{-S_{\\mathrm{\ninst}}}{\\mathbf{v}}_j^{+}{\\mathbf{v}}_i^{-}$, where there is canonical\ninstanton action suppression, and $\\mathbf{v}_i^{-}$ annihilates a particle in\nthe $i^{\\mathrm{th}}$ vacuum, whereas $\\mathbf{v}_j^{+}$ creates a particle in\nthe $j^{\\mathrm{th}}$ vacuum. Adiabatic change of the wells leads to a\nBerry-phase evolution of the couplings, which is described by the\nzero-curvature Gauss-Manin connection i.e. by a quantum $R$-matrix.\nZero-curvature is actually a consequence of level repulsion or topological\nprotection, and its implication is the Yang-Baxter relation for the\n$R$-matrices. In the simplest case the story is pure Abelian and not very\nexciting. But when the model becomes more involved, incorporates supersymmetry,\ngauge and other symmetries, such amplitudes obtain more intricate structures.\nOperators $\\mathbf{v}_i^{-}$, $\\mathbf{v}_j^{+}$ might also evolve from\nordinary Heisenberg operators into a more sophisticated algebraic object -- a\n``tunneling algebra''. The result for the tunneling algebra would depend\nstrongly on geometry of the QFT we started with, and, unfortunately, at the\nmoment we are unable to solve the reverse engineering problem. In this note we\nrevise few successful cases of the aforementioned correspondence: quantum\nalgebras $U_q(\\mathfrak{g})$ and affine Yangians $Y(\\hat{\\mathfrak{g}})$. For\naffine Yangians we demonstrate explicitly how instantons ``perform''\nequivariant integrals over associated quiver moduli spaces appearing in the\nalternative geometric construction.",
    "pdf_url": "http://arxiv.org/pdf/2502.11294v2",
    "published": "2025-02-16T22:34:09+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP",
      "math.QA",
      "math.RT"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.11293v2",
    "title": "Uncertainty-permitting machine learning reveals sources of dynamic sea level predictability across daily-to-seasonal timescales",
    "authors": [
      "Andrew Brettin",
      "Laure Zanna",
      "Elizabeth A. Barnes"
    ],
    "abstract": "Reliable dynamic sea level forecasts are hindered by numerous sources of\nuncertainty on daily-to-seasonal timescales (1-180 days) due to atmospheric\nboundary conditions and internal ocean variability. Studies have demonstrated\nthat certain initial states can extend predictability horizons; thus,\nidentifying these initial conditions may help improve forecast skill. Here, we\nidentify sources of dynamic sea level predictability on daily-to-seasonal\ntimescales using neural networks trained on CESM2 large ensemble data to\nforecast dynamic sea level. The forecasts yield not only a point estimate for\nsea level but also a standard deviation to quantify forecast uncertainty based\non the initial conditions. Forecasted uncertainties can be leveraged to\nidentify state-dependent sources of predictability at most locations and\nforecast leads. Network forecasts, particularly in the low-latitude\nIndo-Pacific, exhibit skillful deterministic predictions and skillfully\nforecast exceedance probabilities relative to local linear baselines. For\nnetworks trained at Guam and in the western Indian Ocean, the transfer of\nsources of predictability from local sources to remote sources is presented by\nthe deteriorating utility of initial condition information for predicting\nexceedance events. Propagating Rossby waves are identified as a potential\nsource of predictability for dynamic sea level at Guam. In the Indian Ocean,\npersistence of thermosteric sea level anomalies from the Indian Ocean Dipole\nmay be a source of predictability on subseasonal timescales, but El Ni\\~no\ndrives predictability on seasonal timescales. This work shows how\nuncertainty-quantifying machine learning can help identify changes in sources\nof state-dependent predictability over a range of forecast leads.",
    "pdf_url": "http://arxiv.org/pdf/2502.11293v2",
    "published": "2025-02-16T22:33:49+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11292v1",
    "title": "Discussion on \"Resurrecting a Neglected Measurement Technique for Air-Water Flows\"",
    "authors": [
      "Matthias Kramer",
      "Hang Wang",
      "Daniel B. Bung"
    ],
    "abstract": "Over the last years, there has been a renewed interest in differentiating\nvarious contributions to the air concentration in high Froude-number\nself-aerated flows, see for example Kramer (2024), comprising entrained and\nentrapped air. The former is characterized by entrained air packets and\nbubbles, while entrapped air corresponds to air transported along wave peaks\nand troughs. Entrapped air was first measured by Killen (1968) using a\nso-called dipping probe, while a physical interpretation of the dipping probe\nsignals was provided only later by Wilhelms and Gulliver (2005).\n  Since then, it has been commonly accepted that two different measurement\ninstruments, for example a dipping probe and a common phase-detection probe,\nare required to fully quantify entrained and entrapped air. Recently, an\narticle entitled \"Resurrecting a Neglected Measurement Technique for Air-Water\nFlows\" was published by Wilhelms and Gulliver (2024), who re-iterated the\nimportance of applying these concepts for cavitation prevention and air-water\ngas transfer, as well as the need for two separate measurement instruments. The\nauthors are congratulated for their seminal works on entrained and entrapped\nair (Wilhelms and Gulliver 2005; Wilhelms and Gulliver 2024), and it is\nstipulated that these concepts have been overlooked in the last two decades.\n  In this discussion, a simple discrimination technique for phase-detection\nprobe signals is proposed, which allows to differentiate entrained and\nentrapped air from existing datasets, recorded with a state-of-the-art dual-tip\nphase-detection probe. It is believed that this novel signal processing method\nwill make Killen's (1968) dipping probe redundant, and that it will be useful\nfor the validation of non-intrusive measurements of entrapped air, as well as\nfor the development of physics-based models for air-water mass transfer in\nself-aerated flows.",
    "pdf_url": "http://arxiv.org/pdf/2502.11292v1",
    "published": "2025-02-16T22:27:16+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11291v1",
    "title": "Dialogue-based Explanations for Logical Reasoning using Structured Argumentation",
    "authors": [
      "Loan Ho",
      "Stefan Schlobach"
    ],
    "abstract": "The problem of explaining inconsistency-tolerant reasoning in knowledge bases\n(KBs) is a prominent topic in Artificial Intelligence (AI). While there is some\nwork on this problem, the explanations provided by existing approaches often\nlack critical information or fail to be expressive enough for non-binary\nconflicts. In this paper, we identify structural weaknesses of the\nstate-of-the-art and propose a generic argumentation-based approach to address\nthese problems. This approach is defined for logics involving reasoning with\nmaximal consistent subsets and shows how any such logic can be translated to\nargumentation. Our work provides dialogue models as dialectic-proof procedures\nto compute and explain a query answer wrt inconsistency-tolerant semantics.\nThis allows us to construct dialectical proof trees as explanations, which are\nmore expressive and arguably more intuitive than existing explanation\nformalisms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11291v1",
    "published": "2025-02-16T22:26:18+00:00",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.HC",
      "cs.LO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11290v1",
    "title": "Orbifold Floer theory for global quotients and Hamiltonian dynamics",
    "authors": [
      "Cheuk Yu Mak",
      "Sobhan Seyfaddini",
      "Ivan Smith"
    ],
    "abstract": "We use global Kuranishi charts to construct bulk-deformed orbifold\nHamiltonian Floer theory for a global quotient orbifold. We then explain a\nstrategy, based on spectral invariants on symmetric product orbifolds, for\nproving the smooth closing lemma for Hamiltonian diffeomorphisms of a\nsymplectic manifold when the orbifold quantum cohomologies of its symmetric\nproducts possess suitable idempotents. We relate the existence of such\nidempotents to the manifold containing a sequence of Lagrangian links, whose\nnumber of components tends to infinity, satisfying a number of properties. We\nillustrate this strategy by giving a new proof of the smooth closing lemma for\narea-preserving diffeomorphisms of the 2-sphere. The construction of suitable\nLagrangian links in higher dimensions remains an intriguing open problem.",
    "pdf_url": "http://arxiv.org/pdf/2502.11290v1",
    "published": "2025-02-16T22:24:13+00:00",
    "categories": [
      "math.SG",
      "math.DS"
    ],
    "primary_category": "math.SG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11289v2",
    "title": "A large data semi-global existence and convergence theorem for vacuum Einstein's equations",
    "authors": [
      "Puskar Mondal"
    ],
    "abstract": "We prove a convergence theorem for the $(3+1)$-dimensional vacuum Einstein\nequations with positive cosmological constant on spacetimes $\\widetilde{M}\n\\cong M \\times \\mathbb{R}$, where $M$ is a closed, connected, oriented\nthree-manifold of negative Yamabe type. In constant mean curvature transported\nspatial coordinates, we show that solutions arising from arbitrarily large\ninitial data converge to a Riemannian metric of constant negative scalar\ncurvature in infinite Newtonian-like' time'. As a consequence, the\nEinstein-$\\Lambda$ flow generically fails to produce geometrization in the\nsense of Thurston and violates the cosmological principle. Our results affirm a\nconjecture of Ringstr\\\"om concerning the asymptotic indistinguishability of\nspatial topology in the large data regime. A related result is established for\npositive Yamabe type under a technical condition.",
    "pdf_url": "http://arxiv.org/pdf/2502.11289v2",
    "published": "2025-02-16T22:22:05+00:00",
    "categories": [
      "gr-qc",
      "math-ph",
      "math.AP",
      "math.DG",
      "math.MP"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11288v2",
    "title": "Abelian varieties analogs of two results about algebraic curves",
    "authors": [
      "Nelson Alvarado",
      "Giuseppe Pareschi"
    ],
    "abstract": "We characterize decomposable principally polarized abelian varieties of the\nform $E\\times B$, with $E$ an elliptic curve, in two different ways, which are\ncompletely analogous to classical results of curve theory concerning\nhyperelliptic curves. The first one is by the failure of a normal generation\nproperty, namely the generation in degree zero of a certain graded module over\nthe symmetric algebra over $H^0(2\\Theta)$. This appears to be the first result\nof this type in the realm of p.p.a.v.'s. The second characterization is by the\nfailure of surjectivity of a second order gaussian maps associated to line\nbundles corresponding to $6\\Theta$, or, equivalently, by the fact that the line\nbundle corresponding to $3\\Theta$ fails to separate $2$-jets at every point. We\nalso show that this last result is equivalent to an effective version of a\ntheorem of Nakamaye characterizing the above decomposable abelian varieties as\nthose computing the minimal Seshadri constant. Finally we propose some\nconjectural generalizations relating $p$-jets separation thresholds, higher\ngaussian maps sujectivity thresholds, and Seshadri constants.",
    "pdf_url": "http://arxiv.org/pdf/2502.11288v2",
    "published": "2025-02-16T22:21:55+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11287v1",
    "title": "MC-BEVRO: Multi-Camera Bird Eye View Road Occupancy Detection for Traffic Monitoring",
    "authors": [
      "Arpitsinh Vaghela",
      "Duo Lu",
      "Aayush Atul Verma",
      "Bharatesh Chakravarthi",
      "Hua Wei",
      "Yezhou Yang"
    ],
    "abstract": "Single camera 3D perception for traffic monitoring faces significant\nchallenges due to occlusion and limited field of view. Moreover, fusing\ninformation from multiple cameras at the image feature level is difficult\nbecause of different view angles. Further, the necessity for practical\nimplementation and compatibility with existing traffic infrastructure compounds\nthese challenges. To address these issues, this paper introduces a novel\nBird's-Eye-View road occupancy detection framework that leverages multiple\nroadside cameras to overcome the aforementioned limitations. To facilitate the\nframework's development and evaluation, a synthetic dataset featuring diverse\nscenes and varying camera configurations is generated using the CARLA\nsimulator. A late fusion and three early fusion methods were implemented within\nthe proposed framework, with performance further enhanced by integrating\nbackgrounds. Extensive evaluations were conducted to analyze the impact of\nmulti-camera inputs and varying BEV occupancy map sizes on model performance.\nAdditionally, a real-world data collection pipeline was developed to assess the\nmodel's ability to generalize to real-world environments. The sim-to-real\ncapabilities of the model were evaluated using zero-shot and few-shot\nfine-tuning, demonstrating its potential for practical application. This\nresearch aims to advance perception systems in traffic monitoring, contributing\nto improved traffic management, operational efficiency, and road safety.",
    "pdf_url": "http://arxiv.org/pdf/2502.11287v1",
    "published": "2025-02-16T22:03:03+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11286v3",
    "title": "Predicted versatile topological nodal magnons in Tb-based icosahedral quasicrystal 1/1 approximants",
    "authors": [
      "Rintaro Eto",
      "Masahito Mochizuki",
      "Shinji Watanabe"
    ],
    "abstract": "Using a recently-established band representation analysis, we discover two\ndistinct types of topological nodal magnons in the real-space antiferroic\nordering of whirling spin arrangements in the Tb-based icosahedral quasicrystal\n1/1 approximants, both of which originate from a composite band\n(co-)representation $A\\uparrow P_In\\bar{3}(24)$ and its constituent elementary\nband representations. The first type is doubly-degenerate nodal line network\nand nodal planes associated with two-dimensional irreducible band\nrepresentation, while the second type is a nodal line network due to accidental\nband inversions. Since our analysis, which relies solely on magnetocrystalline\nsymmetry, is valid for a wide range of materials and spin textures belonging to\nthe same magnetic space group irrespective of composition, these findings offer\nnew universal insights into the research of Tb-based quasicrystal approximants\nas well as a contribution to broadening the range of topological magnon-hosting\nmaterials.",
    "pdf_url": "http://arxiv.org/pdf/2502.11286v3",
    "published": "2025-02-16T22:02:17+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11285v1",
    "title": "Quantum Error Mitigation for Sampling Algorithms",
    "authors": [
      "Kecheng Liu",
      "Zhenyu Cai"
    ],
    "abstract": "Recent experimental breakthroughs have signalled the imminent arrival of the\nearly fault-tolerant era. However, for a considerable period in the foreseeable\nfuture, relying solely on quantum error correction for full error suppression\nwill remain extremely challenging due to its substantial hardware overhead.\nAdditional help from quantum error mitigation (QEM) is essential for bridging\nthis gap towards achieving quantum advantage. The application of QEM has so far\nbeen restricted to expectation value estimation, leaving its extension to\nsampling-based algorithms -- which is expected to play a pivotal role in the\nearly fault-tolerant era -- an unresolved challenge. In this work, we present a\nframework for applying any QEM techniques to obtain the error-mitigated output\ndistribution, showing that this incurs no greater cost than estimating a single\nobservable. We also devised a way to sample from this distribution and\nconstructed an explicit scheme for applying any QEM methods to quantum phase\nestimation, which can be generalised to other sampling algorithms. Numerical\nexperiments were conducted to validate the efficacy of these methods. We\nbelieve our methods significantly broaden the scope of QEM, extending its\napplicability to most algorithms of practical interest and forming a crucial\nstep towards realising quantum advantage.",
    "pdf_url": "http://arxiv.org/pdf/2502.11285v1",
    "published": "2025-02-16T22:00:59+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11284v1",
    "title": "Balancing the Budget: Understanding Trade-offs Between Supervised and Preference-Based Finetuning",
    "authors": [
      "Mohit Raghavendra",
      "Junmo Kang",
      "Alan Ritter"
    ],
    "abstract": "Post-training of Large Language Models often involves a pipeline of\nSupervised Finetuning (SFT) followed by Preference Finetuning (PFT) using\nmethods like Direct Preference Optimization. Both stages require annotated data\nthat are very different in structure and costs. We study how to optimally\nallocate a fixed training data budget between the two stages, through extensive\nexperiments spanning four diverse tasks, multiple model sizes and various data\nannotation costs. Our findings reveal that just SFT on the base model dominates\nperformance in low-data regimes ($<1,000$ annotated examples). With larger\ndata-budgets, we observe that a combination of SFT and PFT, often with\nincreasing portions allocated towards preference data yields optimal\nperformance. However, completely eliminating SFT and running PFT directly on\nthe base model yields suboptimal performance, described as the cold start\nproblem on tasks like mathematics. We observe that this is due to the\ndistribution shift arising from using DPO directly on the base model to elicit\nstep-by-step reasoning. This limitation can be effectively addressed by\nallocating even a small portion ($<10$%) of the budget to SFT first, resulting\nin performance improvements of $15-20$% on analytical benchmarks like GSM8k.\nThese results provide actionable insights for researchers and practitioners\noptimizing model development under budget constraints, where high-quality data\ncuration often represents a significant portion of the total costs of model\ndevelopment.",
    "pdf_url": "http://arxiv.org/pdf/2502.11284v1",
    "published": "2025-02-16T21:57:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11283v1",
    "title": "Set-Based Position Ambiguity Reduction Method for Zonotope Shadow Matching in Urban Areas Using Estimated Multipath Errors",
    "authors": [
      "Sanghyun Kim",
      "Jiwon Seo"
    ],
    "abstract": "In urban areas, the quality of global navigation satellite system (GNSS)\nsignals deteriorates, leading to reduced positioning accuracy. To address this\nissue, 3D-mapping-aided (3DMA) techniques, such as shadow matching and zonotope\nshadow matching (ZSM), have been proposed. However, these methods can introduce\na problem known as multi-modal position ambiguity, making it challenging to\nselect the exact mode in which the receiver is located. Accurately selecting\nthe correct mode is essential for improving positioning accuracy. A previous\nstudy proposed a method that uses satellite-pseudorange consistency (SPC),\ncalculated from pseudorange measurements, to select the mode containing the\nreceiver. This method achieved a mode selection accuracy of approximately 78%.\nTo further enhance accuracy, the study utilized pseudorange measurements\ncollected at multiple timesteps from a fixed location and a trained\nline-of-sight (LOS) classifier. However, in practice, collecting data at\nmultiple timesteps from the same location in dynamic environments is\nchallenging. Moreover, the performance of the trained LOS classifier heavily\ndepends on the surrounding environment, leading to low reliability. In this\nstudy, we propose a method that estimates and corrects multipath errors based\non the mode distribution obtained from the output of ZSM and extract an\nenhanced SPC using the corrected pseudorange measurements. This enables high\nmode selection accuracy using only single-timestep pseudorange measurements,\nwithout requiring a trained LOS classifier.",
    "pdf_url": "http://arxiv.org/pdf/2502.11283v1",
    "published": "2025-02-16T21:53:22+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11282v1",
    "title": "Directional Transport in Rydberg Atom Arrays via Kinetic Constraints and Temporal Modulation",
    "authors": [
      "Yupeng Wang",
      "Junjie Wang",
      "Aishik Panja",
      "Xinghan Wang",
      "Qi-Yu Liang"
    ],
    "abstract": "We propose an experimentally feasible scheme to achieve directional transport\nof Rydberg excitations and entangled states in atomic arrays with unequal\nspacings. By leveraging distance-dependent Rydberg-Rydberg interactions and\ntemporally modulated laser detunings, our method directs excitation flow\nwithout requiring local addressing. Numerical simulations demonstrate robust\nand coherent transport under experimentally realistic conditions. Additionally,\nwe show that this scheme enables controlled transport of Bell pairs and\npreserves entanglement during propagation. The approach provides a versatile\nplatform for programmable directional transport, with potential applications in\nquantum simulation, entanglement distribution, and the design of scalable\nquantum processors and networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11282v1",
    "published": "2025-02-16T21:47:00+00:00",
    "categories": [
      "quant-ph",
      "physics.atom-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11281v1",
    "title": "Coherent Spin Pumping Originated from Sub-Terahertz Nel Vector Dynamics in Easy Plane -Fe2O3/Pt",
    "authors": [
      "Gregory Fritjofson",
      "Atul Regmi",
      "Jacob Hanson-Flores",
      "Justin Michel",
      "Junyu Tang",
      "Fengyuan Yang",
      "Ran Cheng",
      "Enrique Del Barco"
    ],
    "abstract": "We present a thorough study of spin-to-charge current interconversion in bulk\nand thin films of (0001) {\\alpha}-Fe2O3 /Pt heterostructures by means of\nall-optical polarization-controlled microwave excitation at sub-Terahertz\nfrequencies. Our results demonstrate that coherent spin pumping is generated\nthrough excitations of both the acoustic and optical modes of antiferromagnetic\nresonance, provided that the corresponding selection rules are met for the\nrelative orientation between the microwave magnetic field h_ac and the magnetic\nmoment m_0 of the Hematite. In particular, our results unanimously show that\nwhile a microwave field with h_ac perpendicular to m_0 pumps a net spin angular\nmomentum from the acoustic mode, spin pumping from the optical mode is only\nenabled when h_ac parallel to m_0, as expected from the selection rules imposed\nby the Neel vector dynamics. Our results support the current understanding of\nspin mixing conductance in antiferromagnetic/non-magnetic interfaces, contrary\nto recent reports where the absence of spin pumping from the optical mode in\nHematite was interpreted as a cancellation effect between the diagonal and\noff-diagonal components of the spin mixing conductance. We also provide an\nexplanation for the previously reported observations and show how the optical\nspin pumping actually vanishes for thin films, which we speculate being either\ndue to an increased level of inhomogeneities or to insufficient film thickness\nfor the optical mode to fully realize.",
    "pdf_url": "http://arxiv.org/pdf/2502.11281v1",
    "published": "2025-02-16T21:43:35+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11280v1",
    "title": "Single-Impulse Reachable Set in Arbitrary Dynamics Using Polynomials",
    "authors": [
      "Xingyu Zhou",
      "Roberto Armellin",
      "Dong Qiao",
      "Xiangyu Li"
    ],
    "abstract": "This paper presents a method to determine the reachable set (RS) of\nspacecraft after a single velocity impulse with an arbitrary direction, which\nis appropriate for the RS in both the state and observation spaces under\narbitrary dynamics, extending the applications of current RS methods from\ntwo-body to arbitrary dynamics. First, the single-impulse RS model is\ngeneralized as a family of two-variable parameterized polynomials in the\ndifferential algebra scheme. Then, using the envelope theory, the boundary of\nRS is identified by solving the envelope equation. A framework is proposed to\nreduce the complexity of solving the envelope equation by converting it to the\nproblem of searching the root of a one-variable polynomial. Moreover, a\nhigh-order local polynomial approximation for the RS envelope is derived to\nimprove computational efficiency. The method successfully determines the RSs of\ntwo near-rectilinear halo orbits in the cislunar space. Simulation results show\nthat the RSs in both state and observation spaces can be accurately\napproximated under the three-body dynamics, with relative errors of less than\n0.0658%. In addition, using the local polynomial approximation, the\ncomputational time for solving the envelope equation is reduced by more than\n84%.",
    "pdf_url": "http://arxiv.org/pdf/2502.11280v1",
    "published": "2025-02-16T21:42:33+00:00",
    "categories": [
      "astro-ph.IM",
      "math.DS"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2502.11279v1",
    "title": "Neural Operators for Stochastic Modeling of Nonlinear Structural System Response to Natural Hazards",
    "authors": [
      "Somdatta Goswami",
      "Dimitris G. Giovanis",
      "Bowei Li",
      "Seymour M. J. Spence",
      "Michael D. Shields"
    ],
    "abstract": "Traditionally, neural networks have been employed to learn the mapping\nbetween finite-dimensional Euclidean spaces. However, recent research has\nopened up new horizons, focusing on the utilization of deep neural networks to\nlearn operators capable of mapping infinite-dimensional function spaces. In\nthis work, we employ two state-of-the-art neural operators, the deep operator\nnetwork (DeepONet) and the Fourier neural operator (FNO) for the prediction of\nthe nonlinear time history response of structural systems exposed to natural\nhazards, such as earthquakes and wind. Specifically, we propose two\narchitectures, a self-adaptive FNO and a Fast Fourier Transform-based DeepONet\n(DeepFNOnet), where we employ a FNO beyond the DeepONet to learn the\ndiscrepancy between the ground truth and the solution predicted by the\nDeepONet. To demonstrate the efficiency and applicability of the architectures,\ntwo problems are considered. In the first, we use the proposed model to predict\nthe seismic nonlinear dynamic response of a six-story shear building subject to\nstochastic ground motions. In the second problem, we employ the operators to\npredict the wind-induced nonlinear dynamic response of a high-rise building\nwhile explicitly accounting for the stochastic nature of the wind excitation.\nIn both cases, the trained metamodels achieve high accuracy while being orders\nof magnitude faster than their corresponding high-fidelity models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11279v1",
    "published": "2025-02-16T21:41:36+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11278v1",
    "title": "Reducing Computational Complexity of Rigidity-Based UAV Trajectory Optimization for Real-Time Cooperative Target Localization",
    "authors": [
      "Halim Lee",
      "Jiwon Seo"
    ],
    "abstract": "Accurate and swift localization of the target is crucial in emergencies.\nHowever, accurate position data of a target mobile device, typically obtained\nfrom global navigation satellite systems (GNSS), cellular networks, or WiFi,\nmay not always be accessible to first responders. For instance, 1) accuracy and\navailability can be limited in challenging signal reception environments, and\n2) in regions where emergency location services are not mandatory, certain\nmobile devices may not transmit their location during emergencies. As an\nalternative localization method, a network of unmanned aerial vehicles (UAVs)\ncan be employed to passively locate targets by collecting radio frequency (RF)\nsignal measurements, such as received signal strength (RSS). In these\nsituations, UAV trajectories play a critical role in localization performance,\ninfluencing both accuracy and search time. Previous studies optimized UAV\ntrajectories using the determinant of the Fisher information matrix (FIM), but\nits performance declines under unfavorable geometric conditions, such as when\nUAVs start from a single base, leading to position ambiguity. To address this,\nour prior work introduced a rigidity-based approach, which improved the search\ntime compared to FIM-based methods in our simulation case. However, the high\ncomputational cost of rigidity-based optimization, primarily due to singular\nvalue decomposition (SVD), limits its practicality. In this paper, we applied\ntechniques to reduce computational complexity, including randomized SVD, smooth\nSVD, and vertex pruning.",
    "pdf_url": "http://arxiv.org/pdf/2502.11278v1",
    "published": "2025-02-16T21:40:48+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.15774v1",
    "title": "Deep Reinforcement Learning-Based Bidding Strategies for Prosumers Trading in Double Auction-Based Transactive Energy Market",
    "authors": [
      "Jun Jiang",
      "Yuanliang Li",
      "Luyang Hou",
      "Mohsen Ghafouri",
      "Peng Zhang",
      "Jun Yan",
      "Yuhong Liu"
    ],
    "abstract": "With the large number of prosumers deploying distributed energy resources\n(DERs), integrating these prosumers into a transactive energy market (TEM) is a\ntrend for the future smart grid. A community-based double auction market is\nconsidered a promising TEM that can encourage prosumers to participate and\nmaximize social welfare. However, the traditional TEM is challenging to model\nexplicitly due to the random bidding behavior of prosumers and uncertainties\ncaused by the energy operation of DERs. Furthermore, although reinforcement\nlearning algorithms provide a model-free solution to optimize prosumers'\nbidding strategies, their use in TEM is still challenging due to their\nscalability, stability, and privacy protection limitations. To address the\nabove challenges, in this study, we design a double auction-based TEM with\nmultiple DERs-equipped prosumers to transparently and efficiently manage energy\ntransactions. We also propose a deep reinforcement learning (DRL) model with\ndistributed learning and execution to ensure the scalability and privacy of the\nmarket environment. Additionally, the design of two bidding actions (i.e.,\nbidding price and quantity) optimizes the bidding strategies for prosumers.\nSimulation results show that (1) the designed TEM and DRL model are robust; (2)\nthe proposed DRL model effectively balances the energy payment and comfort\nsatisfaction for prosumers and outperforms the state-of-the-art methods in\noptimizing the bidding strategies.",
    "pdf_url": "http://arxiv.org/pdf/2502.15774v1",
    "published": "2025-02-16T21:38:21+00:00",
    "categories": [
      "eess.SY",
      "cs.GT",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2502.15773v1",
    "title": "JExplore: Design Space Exploration Tool for Nvidia Jetson Boards",
    "authors": [
      "Basar Kutukcu",
      "Sinan Xie",
      "Sabur Baidya",
      "Sujit Dey"
    ],
    "abstract": "Nvidia Jetson boards are powerful systems for executing artificial\nintelligence workloads in edge and mobile environments due to their effective\nGPU hardware and widely supported software stack. In addition to these\nbenefits, Nvidia Jetson boards provide large configurability by giving the user\nthe choice to modify many hardware parameters. This large space of\nconfigurability creates the need of searching the optimal configurations based\non the user's requirements. In this work, we propose JExplore, a multi-board\nsoftware and hardware design space exploration tool. JExplore can be integrated\nwith any search tool, hence creating a common benchmarking ground for the\nsearch algorithms. Moreover, it accelerates the exploration of user application\nand Nvidia Jetson configurations for researchers and engineers by encapsulating\nhost-client communication, configuration management, and metric measurement.",
    "pdf_url": "http://arxiv.org/pdf/2502.15773v1",
    "published": "2025-02-16T21:37:01+00:00",
    "categories": [
      "cs.AR",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11277v2",
    "title": "\"When I lost it, they dragged me out\": How Care Encounters Empower Marginalized Young Adults' Aspiration and Mental Health Care-Seeking",
    "authors": [
      "Jiaying \"Lizzy\" Liu",
      "Yan Zhang"
    ],
    "abstract": "Mental health care-seeking among marginalized young adults has received\nlimited attention in CSCW research. Through in-depth interviews and visual\nelicitation methods with 18 diverse U.S. participants, our study reveals how\nmarginalized identities shape mental health care-seeking journeys, often\ncharacterized by low aspirations and passive care-seeking influenced by lived\nexperiences of marginalization. However, we found the transformative function\nof \"care encounters\" - serendipitous interactions with mental health resources\nthat occur when individuals are not actively seeking support. These encounters\nserve as critical turning points, catalyzing shifts in aspiration and enabling\nmore proactive care-seeking behaviors. Our analysis identifies both the\ninfrastructural conditions that enable transformative care encounters and the\naspiration breakdowns that impede care-seeking processes. This work makes\nconceptual contributions by supplementing traditional motivation-based\ncare-seeking models with a reconceptualization of \"care encounters\" that\naccounts for the infrastructural and serendipitous nature of mental health\naccess. We advance understanding of how marginalized identity uniquely\ninfluences care-seeking behaviors while providing actionable design\nimplications for embedding technology-mediated \"care encounters\" into\nsocio-technical interventions that can better support mental health care access\nfor vulnerable populations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11277v2",
    "published": "2025-02-16T21:36:45+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11276v1",
    "title": "The Rotary Position Embedding May Cause Dimension Inefficiency in Attention Heads for Long-Distance Retrieval",
    "authors": [
      "Ting-Rui Chiang",
      "Dani Yogatama"
    ],
    "abstract": "The Rotary Position Embedding (RoPE) is widely used in the attention heads of\nmany large language models (LLM). It rotates dimensions in the query and the\nkey vectors by different angles according to their positions in the input\nsequence. For long context modeling, the range of positions may vary a lot, and\nthus RoPE rotates some dimensions by a great range of angles. We hypothesize\nthat the wide range of rotation angles may prevent LLMs from utilizing those\ndimensions. To validate this hypothesis, we present a controlled experiment\nshowing that applying RoPE causes low utility of certain dimensions. Our\nanalyses on three LLMs also indicate that these dimensions do not help LLMs do\nlong-context question answering.",
    "pdf_url": "http://arxiv.org/pdf/2502.11276v1",
    "published": "2025-02-16T21:32:29+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11275v1",
    "title": "Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM's Nest",
    "authors": [
      "Letian Peng",
      "Zilong Wang",
      "Feng Yao",
      "Jingbo Shang"
    ],
    "abstract": "Massive high-quality data, both pre-training raw texts and post-training\nannotations, have been carefully prepared to incubate advanced large language\nmodels (LLMs). In contrast, for information extraction (IE), pre-training data,\nsuch as BIO-tagged sequences, are hard to scale up. We show that IE models can\nact as free riders on LLM resources by reframing next-token \\emph{prediction}\ninto \\emph{extraction} for tokens already present in the context. Specifically,\nour proposed next tokens extraction (NTE) paradigm learns a versatile IE model,\n\\emph{Cuckoo}, with 102.6M extractive data converted from LLM's pre-training\nand post-training data. Under the few-shot setting, Cuckoo adapts effectively\nto traditional and complex instruction-following IE with better performance\nthan existing pre-trained IE models. As a free rider, Cuckoo can naturally\nevolve with the ongoing advancements in LLM data preparation, benefiting from\nimprovements in LLM training pipelines without additional manual effort.",
    "pdf_url": "http://arxiv.org/pdf/2502.11275v1",
    "published": "2025-02-16T21:32:20+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11274v4",
    "title": "Perturbing the vortex: quasinormal and quasibound spectra of rotating acoustic geometries",
    "authors": [
      "H. S. Vieira",
      "Kyriakos Destounis",
      "Kostas D. Kokkotas"
    ],
    "abstract": "Strong-field gravity simulators are laboratory experiments that can\ninvestigate a wide range of both classical and quantum phenomena occurring in\nnature. In this work, we introduce an effective geometry that captures most of\nthe characteristics of the strong-field regime of astrophysical, rotating black\nholes. This geometry can represent a vortex made from a variety of fluid and\nsuperfluid profiles with zero viscosity, making it a promising\nfinite-temperature quantum-field-theory simulator for rotating curved\nspacetimes. Our geometry includes not only the typical radial flow which gives\nrise to an acoustic horizon, but also azimuthal circulation of the fluid. We\ncompute the quasinormal modes, semi-analytically, and the exact quasibound\nstates of acoustic excitations interacting with this effective geometry. The\nresulting spectra can be identified for both co-rotating and counter-rotating\nsurface acoustic waves. In particular, the behavior of our acoustic geometry\nwith circulation aligns with the phenomenology observed in recent experiments\nthat include superfluids.",
    "pdf_url": "http://arxiv.org/pdf/2502.11274v4",
    "published": "2025-02-16T21:31:07+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11273v2",
    "title": "FairFare: A Tool for Crowdsourcing Rideshare Data to Empower Labor Organizers",
    "authors": [
      "Dana Calacci",
      "Varun Nagaraj Rao",
      "Samantha Dalal",
      "Catherine Di",
      "Kok-Wei Pua",
      "Andrew Schwartz",
      "Danny Spitzberg",
      "Andrs Monroy-Hernndez"
    ],
    "abstract": "Rideshare workers experience unpredictable working conditions due to gig work\nplatforms' reliance on opaque AI and algorithmic systems. In response to these\nchallenges, we found that labor organizers want data to help them advocate for\nlegislation to increase the transparency and accountability of these platforms.\nTo address this need, we collaborated with a Colorado-based rideshare union to\ndevelop FairFare, a tool that crowdsources and analyzes workers' data to\nestimate the take rate -- the percentage of the rider price retained by the\nrideshare platform. We deployed FairFare with our partner organization that\ncollaborated with us in collecting data on 76,000+ trips from 45 drivers over\n18 months. During evaluation interviews, organizers reported that FairFare\nhelped influence the bill language and passage of Colorado Senate Bill 24-75,\ncalling for greater transparency and data disclosure of platform operations,\nand create a national narrative. Finally, we reflect on complexities of\ntranslating quantitative data into policy outcomes, nature of community based\naudits, and design implications for future transparency tools.",
    "pdf_url": "http://arxiv.org/pdf/2502.11273v2",
    "published": "2025-02-16T21:30:26+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11272v1",
    "title": "Zip shift Space",
    "authors": [
      "Sanaz Lamei",
      "Pouya Mehdipour"
    ],
    "abstract": "We introduce a new extension in symbolic dynamics on two sets of alphabets,\ncalled the zip shift space. In finite case, it represents a finite-to-1 local\nhomeomorphism called zip shift map. Such extension, offers a conjugacy between\nsome endomorphisms and some zip shift map over two-sided space with finite sets\nof alphabets. As an application, the topological conjugacy of an N-to-1\nuniformly hyperbolic horseshoe map with a zip shift map and its orbit structure\nis investigated. Moreover, the pre-image studies over zip shift space and the\nconcepts of stable and unstable sets and homoclinic orbits, with a precise\ndescription for N-to-1 horseshoe are illustrated.",
    "pdf_url": "http://arxiv.org/pdf/2502.11272v1",
    "published": "2025-02-16T21:24:12+00:00",
    "categories": [
      "math.DS",
      "math-ph",
      "math.MP",
      "nlin.CD",
      "Primary 37B10, Secondary 37D05, 37C29"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11271v1",
    "title": "OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning",
    "authors": [
      "Pan Lu",
      "Bowen Chen",
      "Sheng Liu",
      "Rahul Thapa",
      "Joseph Boen",
      "James Zou"
    ],
    "abstract": "Solving complex reasoning tasks may involve visual understanding, domain\nknowledge retrieval, numerical calculation, and multi-step reasoning. Existing\nmethods augment large language models (LLMs) with external tools but are\nrestricted to specialized domains, limited tool types, or require additional\ntraining data. In this paper, we introduce OctoTools, a training-free,\nuser-friendly, and easily extensible open-source agentic framework designed to\ntackle complex reasoning across diverse domains. OctoTools introduces\nstandardized tool cards to encapsulate tool functionality, a planner for both\nhigh-level and low-level planning, and an executor to carry out tool usage. We\nvalidate OctoTools' generality across 16 diverse tasks (including MathVista,\nMMLU-Pro, MedQA, and GAIA-Text), achieving substantial average accuracy gains\nof 9.3% over GPT-4o. Furthermore, OctoTools outperforms AutoGen, GPT-Functions\nand LangChain by up to 10.6% when given the same set of tools. Through\ncomprehensive analysis and ablations, OctoTools demonstrates advantages in task\nplanning, effective tool usage, and multi-step problem solving.",
    "pdf_url": "http://arxiv.org/pdf/2502.11271v1",
    "published": "2025-02-16T21:18:47+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV",
      "cs.MA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11270v2",
    "title": "Site-Decorated Model for Unconventional Frustrated Magnets: Ultranarrow Phase Crossover and Spin Reversal Transition",
    "authors": [
      "Weiguo Yin"
    ],
    "abstract": "The site-decorated Ising model is introduced to advance the understanding and\nexperimental realization of the recently discovered one-dimensional\nfinite-temperature ultranarrow phase crossover in an external magnetic field,\nwhile mitigating the geometric complexities of traditional bond-decorated\nmodels. Furthermore, although higher-dimensional Ising models in an external\nfield remain unsolved, an exact solution for a novel spin-reversal transition\n-- driven by an exotic, hidden ``half-ice, half-fire'' state induced by site\ndecoration -- is derived. This transition, triggered by a slight variation in\ntemperature or magnetic field even in the weak-field limit, offers a promising\nroute toward energy-efficient applications such as data storage and processing.\nThe results establish site decoration as a compelling new avenue for materials\nand device design, particularly in systems such as mixed $d$-$f$ compounds,\noptical lattices, and neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11270v2",
    "published": "2025-02-16T21:10:42+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2502.11269v1",
    "title": "Unlocking the Potential of Generative AI through Neuro-Symbolic Architectures: Benefits and Limitations",
    "authors": [
      "Oualid Bougzime",
      "Samir Jabbar",
      "Christophe Cruz",
      "Frdric Demoly"
    ],
    "abstract": "Neuro-symbolic artificial intelligence (NSAI) represents a transformative\napproach in artificial intelligence (AI) by combining deep learning's ability\nto handle large-scale and unstructured data with the structured reasoning of\nsymbolic methods. By leveraging their complementary strengths, NSAI enhances\ngeneralization, reasoning, and scalability while addressing key challenges such\nas transparency and data efficiency. This paper systematically studies diverse\nNSAI architectures, highlighting their unique approaches to integrating neural\nand symbolic components. It examines the alignment of contemporary AI\ntechniques such as retrieval-augmented generation, graph neural networks,\nreinforcement learning, and multi-agent systems with NSAI paradigms. This study\nthen evaluates these architectures against comprehensive set of criteria,\nincluding generalization, reasoning capabilities, transferability, and\ninterpretability, therefore providing a comparative analysis of their\nrespective strengths and limitations. Notably, the Neuro > Symbolic < Neuro\nmodel consistently outperforms its counterparts across all evaluation metrics.\nThis result aligns with state-of-the-art research that highlight the efficacy\nof such architectures in harnessing advanced technologies like multi-agent\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11269v1",
    "published": "2025-02-16T21:06:33+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11268v3",
    "title": "Improved Unbiased Watermark for Large Language Models",
    "authors": [
      "Ruibo Chen",
      "Yihan Wu",
      "Junfeng Guo",
      "Heng Huang"
    ],
    "abstract": "As artificial intelligence surpasses human capabilities in text generation,\nthe necessity to authenticate the origins of AI-generated content has become\nparamount. Unbiased watermarks offer a powerful solution by embedding\nstatistical signals into language model-generated text without distorting the\nquality. In this paper, we introduce MCmark, a family of unbiased,\nMulti-Channel-based watermarks. MCmark works by partitioning the model's\nvocabulary into segments and promoting token probabilities within a selected\nsegment based on a watermark key. We demonstrate that MCmark not only preserves\nthe original distribution of the language model but also offers significant\nimprovements in detectability and robustness over existing unbiased watermarks.\nOur experiments with widely-used language models demonstrate an improvement in\ndetectability of over 10% using MCmark, compared to existing state-of-the-art\nunbiased watermarks. This advancement underscores MCmark's potential in\nenhancing the practical application of watermarking in AI-generated texts.",
    "pdf_url": "http://arxiv.org/pdf/2502.11268v3",
    "published": "2025-02-16T21:02:36+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11267v1",
    "title": "Prompting in the Dark: Assessing Human Performance in Prompt Engineering for Data Labeling When Gold Labels Are Absent",
    "authors": [
      "Zeyu He",
      "Saniya Naphade",
      "Ting-Hao 'Kenneth' Huang"
    ],
    "abstract": "Millions of users prompt large language models (LLMs) for various tasks, but\nhow good are people at prompt engineering? Do users actually get closer to\ntheir desired outcome over multiple iterations of their prompts? These\nquestions are crucial when no gold-standard labels are available to measure\nprogress. This paper investigates a scenario in LLM-powered data labeling,\n\"prompting in the dark,\" where users iteratively prompt LLMs to label data\nwithout using manually-labeled benchmarks. We developed PromptingSheet, a\nGoogle Sheets add-on that enables users to compose, revise, and iteratively\nlabel data through spreadsheets. Through a study with 20 participants, we found\nthat prompting in the dark was highly unreliable -- only 9 participants\nimproved labeling accuracy after four or more iterations. Automated prompt\noptimization tools like DSPy also struggled when few gold labels were\navailable. Our findings highlight the importance of gold labels and the needs,\nas well as the risks, of automated support in human prompt engineering,\nproviding insights for future tool design.",
    "pdf_url": "http://arxiv.org/pdf/2502.11267v1",
    "published": "2025-02-16T20:54:26+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11266v1",
    "title": "The Shrinking Landscape of Linguistic Diversity in the Age of Large Language Models",
    "authors": [
      "Zhivar Sourati",
      "Farzan Karimi-Malekabadi",
      "Meltem Ozcan",
      "Colin McDaniel",
      "Alireza Ziabari",
      "Jackson Trager",
      "Ala Tak",
      "Meng Chen",
      "Fred Morstatter",
      "Morteza Dehghani"
    ],
    "abstract": "Language is far more than a communication tool. A wealth of information -\nincluding but not limited to the identities, psychological states, and social\ncontexts of its users - can be gleaned through linguistic markers, and such\ninsights are routinely leveraged across diverse fields ranging from product\ndevelopment and marketing to healthcare. In four studies utilizing experimental\nand observational methods, we demonstrate that the widespread adoption of large\nlanguage models (LLMs) as writing assistants is linked to notable declines in\nlinguistic diversity and may interfere with the societal and psychological\ninsights language provides. We show that while the core content of texts is\nretained when LLMs polish and rewrite texts, not only do they homogenize\nwriting styles, but they also alter stylistic elements in a way that\nselectively amplifies certain dominant characteristics or biases while\nsuppressing others - emphasizing conformity over individuality. By varying\nLLMs, prompts, classifiers, and contexts, we show that these trends are robust\nand consistent. Our findings highlight a wide array of risks associated with\nlinguistic homogenization, including compromised diagnostic processes and\npersonalization efforts, the exacerbation of existing divides and barriers to\nequity in settings like personnel selection where language plays a critical\nrole in assessing candidates' qualifications, communication skills, and\ncultural fit, and the undermining of efforts for cultural preservation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11266v1",
    "published": "2025-02-16T20:51:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.14890v1",
    "title": "WeedVision: Multi-Stage Growth and Classification of Weeds using DETR and RetinaNet for Precision Agriculture",
    "authors": [
      "Taminul Islam",
      "Toqi Tahamid Sarker",
      "Khaled R Ahmed",
      "Cristiana Bernardi Rankrape",
      "Karla Gage"
    ],
    "abstract": "Weed management remains a critical challenge in agriculture, where weeds\ncompete with crops for essential resources, leading to significant yield\nlosses. Accurate detection of weeds at various growth stages is crucial for\neffective management yet challenging for farmers, as it requires identifying\ndifferent species at multiple growth phases. This research addresses these\nchallenges by utilizing advanced object detection models, specifically, the\nDetection Transformer (DETR) with a ResNet50 backbone and RetinaNet with a\nResNeXt101 backbone, to identify and classify 16 weed species of economic\nconcern across 174 classes, spanning their 11 weeks growth stages from seedling\nto maturity. A robust dataset comprising 203,567 images was developed,\nmeticulously labeled by species and growth stage. The models were rigorously\ntrained and evaluated, with RetinaNet demonstrating superior performance,\nachieving a mean Average Precision (mAP) of 0.907 on the training set and 0.904\non the test set, compared to DETR's mAP of 0.854 and 0.840, respectively.\nRetinaNet also outperformed DETR in recall and inference speed of 7.28 FPS,\nmaking it more suitable for real time applications. Both models showed improved\naccuracy as plants matured. This research provides crucial insights for\ndeveloping precise, sustainable, and automated weed management strategies,\npaving the way for real time species specific detection systems and advancing\nAI-assisted agriculture through continued innovation in model development and\nearly detection accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2502.14890v1",
    "published": "2025-02-16T20:49:22+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11265v1",
    "title": "Towards Automatic Identification of Missing Tissues using a Geometric-Learning Correspondence Model",
    "authors": [
      "Eliana M. Vasquez Osorio",
      "Edward Henderson"
    ],
    "abstract": "Missing tissue presents a big challenge for dose mapping, e.g., in the\nreirradiation setting. We propose a pipeline to identify missing tissue on\nintra-patient structure meshes using a previously trained geometric-learning\ncorrespondence model. For our application, we relied on the prediction\ndiscrepancies between forward and backward correspondences of the input meshes,\nquantified using a correspondence-based Inverse Consistency Error (cICE). We\noptimised the threshold applied to cICE to identify missing points in a dataset\nof 35 simulated mandible resections. Our identified threshold, 5.5 mm, produced\na balanced accuracy score of 0.883 in the training data, using an ensemble\napproach. This pipeline produced plausible results for a real case where ~25%\nof the mandible was removed after a surgical intervention. The pipeline,\nhowever, failed on a more extreme case where ~50% of the mandible was removed.\nThis is the first time geometric-learning modelling is proposed to identify\nmissing points in corresponding anatomy.",
    "pdf_url": "http://arxiv.org/pdf/2502.11265v1",
    "published": "2025-02-16T20:43:53+00:00",
    "categories": [
      "cs.CV",
      "physics.med-ph"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11264v1",
    "title": "Strategic Wealth Accumulation Under Transformative AI Expectations",
    "authors": [
      "Caleb Maresca"
    ],
    "abstract": "This paper analyzes how expectations of Transformative AI (TAI) affect\ncurrent economic behavior by introducing a novel mechanism where automation\nredirects labor income from workers to those controlling AI systems, with the\nshare of automated labor controlled by each household depending on their wealth\nat the time of invention. Using a modified neoclassical growth model calibrated\nto contemporary AI timeline forecasts, I find that even moderate assumptions\nabout wealth-based allocation of AI labor generate substantial increases in\npre-TAI interest rates. Under baseline scenarios with proportional wealth-based\nallocation, one-year interest rates rise to 10-16% compared to approximately 3%\nwithout strategic competition. The model reveals a notable divergence between\ninterest rates and capital rental rates, as households accept lower productive\nreturns in exchange for the strategic value of wealth accumulation. These\nfindings suggest that evolving beliefs about TAI could create significant\nupward pressure on interest rates well before any technological breakthrough\noccurs, with important implications for monetary policy and financial\nstability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11264v1",
    "published": "2025-02-16T20:41:42+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2502.11263v2",
    "title": "Bilinear maps on the ring of strictly upper triangular matrices",
    "authors": [
      "Jordan Bounds",
      "Samuel Dayton",
      "Regan Richardson",
      "Yeeka Yau"
    ],
    "abstract": "Let $R$ be a 2-torsion free unital ring and $N_n=N_n(R)$ the ring of strictly\nupper triangular matrices with entries in $R$ and center $Z=Z(N_n)$. It has\nbeen previously shown that any linear map $f:N_n\\rightarrow N_n$ satisfying the\ncondition $[f(X),X]=0$ must be of the form $f(X)=\\lambda X+\\mu(X)$ for some\n$\\lambda\\in R$ and additive map $\\mu$ defined on $N_n$. We extend these known\nresults by providing a complete description of the bilinear maps $f:N_n\\times\nN_n\\rightarrow N_n$ satisfying the identity $[f(X,X),X]=0$ for all $X\\in N_n$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11263v2",
    "published": "2025-02-16T20:35:20+00:00",
    "categories": [
      "math.RA"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11262v1",
    "title": "Generating Skyline Datasets for Data Science Models",
    "authors": [
      "Mengying Wang",
      "Hanchao Ma",
      "Yiyang Bian",
      "Yangxin Fan",
      "Yinghui Wu"
    ],
    "abstract": "Preparing high-quality datasets required by various data-driven AI and\nmachine learning models has become a cornerstone task in data-driven analysis.\nConventional data discovery methods typically integrate datasets towards a\nsingle pre-defined quality measure that may lead to bias for downstream tasks.\nThis paper introduces MODis, a framework that discovers datasets by optimizing\nmultiple user-defined, model-performance measures. Given a set of data sources\nand a model, MODis selects and integrates data sources into a skyline dataset,\nover which the model is expected to have the desired performance in all the\nperformance measures. We formulate MODis as a multi-goal finite state\ntransducer, and derive three feasible algorithms to generate skyline datasets.\nOur first algorithm adopts a \"reduce-from-universal\" strategy, that starts with\na universal schema and iteratively prunes unpromising data. Our second\nalgorithm further reduces the cost with a bi-directional strategy that\ninterleaves data augmentation and reduction. We also introduce a\ndiversification algorithm to mitigate the bias in skyline datasets. We\nexperimentally verify the efficiency and effectiveness of our skyline data\ndiscovery algorithms, and showcase their applications in optimizing data\nscience pipelines.",
    "pdf_url": "http://arxiv.org/pdf/2502.11262v1",
    "published": "2025-02-16T20:33:59+00:00",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2502.11261v2",
    "title": "Comment on Consequences of the single-pair measurement of the Bell parameter",
    "authors": [
      "Marian Kupczynski"
    ],
    "abstract": "Genovese and Piacentini [Phys.Rev.A 111, 022204 (2025)] claim that in a\nrecent experiment[S.Virz\\`i et al., Quantum Sci. Technol. 9, 045027 (2024)] the\nBell parameter was measured on a single pair of photons thus it challenges\nseveral conclusions and discussions on the meaning of Bell inequalities as well\nas certain QM interpretations. We explain that the parameter measured in Virzi\net al. experiment it is not the Bell parameter S which was discussed and\nestimated in many loophole free tests. Therefore, this experiment neither\nchallenges our understanding of Bell Tests nor allows having doubts about Bohr\ncomplementarity and contextuality.",
    "pdf_url": "http://arxiv.org/pdf/2502.11261v2",
    "published": "2025-02-16T20:28:49+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11260v2",
    "title": "Scalable Multi-Agent Offline Reinforcement Learning and the Role of Information",
    "authors": [
      "Riccardo Zamboni",
      "Enrico Brunetti",
      "Marcello Restelli"
    ],
    "abstract": "Offline Reinforcement Learning (RL) focuses on learning policies solely from\na batch of previously collected data. offering the potential to leverage such\ndatasets effectively without the need for costly or risky active exploration.\nWhile recent advances in Offline Multi-Agent RL (MARL) have shown promise, most\nexisting methods either rely on large datasets jointly collected by all agents\nor agent-specific datasets collected independently. The former approach ensures\nstrong performance but raises scalability concerns, while the latter emphasizes\nscalability at the expense of performance guarantees. In this work, we propose\na novel scalable routine for both dataset collection and offline learning.\nAgents first collect diverse datasets coherently with a pre-specified\ninformation-sharing network and subsequently learn coherent localized policies\nwithout requiring either full observability or falling back to complete\ndecentralization. We theoretically demonstrate that this structured approach\nallows a multi-agent extension of the seminal Fitted Q-Iteration (FQI)\nalgorithm to globally converge, in high probability, to near-optimal policies.\nThe convergence is subject to error terms that depend on the informativeness of\nthe shared information. Furthermore, we show how this approach allows to bound\nthe inherent error of the supervised-learning phase of FQI with the mutual\ninformation between shared and unshared information. Our algorithm, SCAlable\nMulti-agent FQI (SCAM-FQI), is then evaluated on a distributed decision-making\nproblem. The empirical results align with our theoretical findings, supporting\nthe effectiveness of SCAM-FQI in achieving a balance between scalability and\npolicy performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11260v2",
    "published": "2025-02-16T20:28:42+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11259v1",
    "title": "Exploiting network optimization stability for enhanced PET image denoising using deep image prior",
    "authors": [
      "Fumio Hashimoto",
      "Kibo Ote",
      "Yuya Onishi",
      "Hideaki Tashima",
      "Go Akamatsu",
      "Yuma Iwao",
      "Miwako Takahashi",
      "Taiga Yamaya"
    ],
    "abstract": "PET is affected by statistical noise due to constraints on tracer dose and\nscan duration, impacting both diagnostic performance and quantitative accuracy.\nWhile deep learning (DL)-based PET denoising methods have been used to improve\nimage quality, they may introduce over-smoothing, compromising quantitative\naccuracy. We propose a method for making a DL solution more reliable and apply\nit to the conditional deep image prior (DIP). We introduce the idea of\nstability information in the optimization process of conditional DIP, enabling\nthe identification of unstable regions within the network's optimization\ntrajectory. Our method incorporates a stability map, which is derived from\nmultiple intermediate outputs of moderate network at different optimization\nsteps. The final denoised image is then obtained by computing linear\ncombination of the DIP output and the original reconstructed image, weighted by\nthe stability map. Our method effectively reduces noise while preserving small\nstructure details in brain FDG images. Results demonstrated that our approach\noutperformed existing methods in peak-to-valley ratio and noise suppression\nacross various low-dose levels. Region-of-interest analysis confirmed that the\nproposed method maintains quantitative accuracy without introducing under- or\nover-estimation. We applied our method to full-dose PET data to assess its\nimpact on image quality. The results revealed that the proposed method\nsignificantly reduced background noise while preserving the peak-to-valley\nratio at a level comparable to that of unfiltered full-dose PET images. The\nproposed method introduces a robust approach to DL-based PET denoising,\nenhancing its reliability and preserving quantitative accuracy. This strategy\nhas the potential to advance performance in high-sensitivity PET scanners,\ndemonstrating that DL can extend PET imaging capabilities beyond low-dose\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11259v1",
    "published": "2025-02-16T20:27:56+00:00",
    "categories": [
      "physics.med-ph",
      "cs.CV"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11258v2",
    "title": "Leveraging Conditional Mutual Information to Improve Large Language Model Fine-Tuning For Classification",
    "authors": [
      "Thanushon Sivakaran",
      "En-Hui Yang"
    ],
    "abstract": "Although large language models (LLMs) have demonstrated remarkable\ncapabilities in recent years, the potential of information theory (IT) to\nenhance LLM development remains underexplored. This paper introduces the\ninformation theoretic principle of Conditional Mutual Information (CMI) to LLM\nfine-tuning for classification tasks, exploring its promise in two main ways:\nminimizing CMI to improve a model's standalone performance and maximizing CMI\nto enhance knowledge distillation (KD) for more capable student models. To\napply CMI in LLM fine-tuning, we adapt the recently proposed CMI-constrained\ndeep learning framework, which was initially developed for image\nclassification, with some modification. By minimizing CMI during LLM\nfine-tuning, we achieve superior performance gains on 6 of 8 GLUE\nclassification tasks compared to BERT. Additionally, maximizing CMI during the\nKD process results in significant performance improvements in 6 of 8 GLUE\nclassification tasks compared to DistilBERT. These findings demonstrate CMI's\nadaptability for optimizing both standalone LLMs and student models, showcasing\nits potential as a robust framework for advancing LLM fine-tuning. Our work\nbridges the gap between information theory and LLM development, offering new\ninsights for building high-performing language models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11258v2",
    "published": "2025-02-16T20:24:00+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11257v1",
    "title": "Eigenvalues of the discrete Schrdinger operator in the large coupling constant limit",
    "authors": [
      "Siyu Gao"
    ],
    "abstract": "Let $(\\lambda_-,\\lambda_+)$ be a spectral gap of a periodic Schr\\\"odinger\noperator $A$ on the lattice ${\\mathbb Z}^d$. Consider the operator\n$A(\\alpha)=A-\\alpha V$ where $V$ is a decaying positive potential on ${\\mathbb\nZ}^d$. We study the asymptotic behavior of the number of eigenvalues of $A(t)$\npassing through a point $\\lambda\\in (\\lambda_-,\\lambda_+)$ as $t$ grows from\n$0$ to $\\alpha$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11257v1",
    "published": "2025-02-16T20:22:46+00:00",
    "categories": [
      "math.SP"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11256v2",
    "title": "Unveiling Environmental Impacts of Large Language Model Serving: A Functional Unit View",
    "authors": [
      "Yanran Wu",
      "Inez Hua",
      "Yi Ding"
    ],
    "abstract": "Large language models (LLMs) offer powerful capabilities but come with\nsignificant environmental impact, particularly in carbon emissions. Existing\nstudies benchmark carbon emissions but lack a standardized basis for comparison\nacross different model configurations. To address this, we introduce the\nconcept of functional unit (FU) as a standardized basis and develop FUEL, the\nfirst FU-based framework for evaluating LLM serving's environmental impact.\nThrough three case studies, we uncover key insights and trade-offs in reducing\ncarbon emissions by optimizing model size, quantization strategy, and hardware\nchoice, paving the way for more sustainable LLM serving. The code is available\nat https://github.com/jojacola/FUEL.",
    "pdf_url": "http://arxiv.org/pdf/2502.11256v2",
    "published": "2025-02-16T20:20:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AR",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11255v1",
    "title": "Regression Modeling of the Count Relational Data with Exchangeable Dependencies",
    "authors": [
      "Wenqin Du",
      "Bailey K. Fosdick",
      "Wen Zhou"
    ],
    "abstract": "Relational data characterized by directed edges with count measurements are\ncommon in social science. Most existing methods either assume the count edges\nare derived from continuous random variables or model the edge dependency by\nparametric distributions. In this paper, we develop a latent multiplicative\nPoisson model for relational data with count edges. Our approach directly\nmodels the edge dependency of count data by the pairwise dependence of latent\nerrors, which are assumed to be weakly exchangeable. This assumption not only\ncovers a variety of common network effects, but also leads to a concise\nrepresentation of the error covariance. In addition, the identification and\ninference of the mean structure, as well as the regression coefficients, depend\non the errors only through their covariance. Such a formulation provides\nsubstantial flexibility for our model. Based on this, we propose a\npseudo-likelihood based estimator for the regression coefficients,\ndemonstrating its consistency and asymptotic normality. The newly suggested\nmethod is applied to a food-sharing network, revealing interesting network\neffects in gift exchange behaviors.",
    "pdf_url": "http://arxiv.org/pdf/2502.11255v1",
    "published": "2025-02-16T20:16:59+00:00",
    "categories": [
      "stat.ME",
      "econ.EM",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.11254v1",
    "title": "3D Electron Diffraction as GIWAXS Alternative for Quantitative Structural Characterization of Organic Solar Cells",
    "authors": [
      "Irene Kraus",
      "Mingjian Wu",
      "Stefanie Rechberger",
      "Johannes Will",
      "Santanu Maiti",
      "Andreas Kuhlmann",
      "Marten Huck",
      "Larry Ler",
      "Florian Bertram",
      "Hans-Georg Steinrck",
      "Tobias Unruh",
      "Christoph J. Brabec",
      "Erdmann Spiecker"
    ],
    "abstract": "We demonstrate elastically filtered 3D Electron Diffraction (3D ED) as a\npowerful alternative technique to Grazing Incidence Wide-Angle X-ray Scattering\n(GIWAXS) for quantitatively characterizing the structure of organic\nsemiconductor films. Using a model material system of solvent vapor annealed\nDRCN5T:PC71BM thin film, which is employed in organic solar cells (OSCs), we\nextract the structural data obtained from 3D ED and compare with that from\nGIWAXS, utilizing both laboratory and synchrotron X-ray sources. Quantitative\nevaluation of the datasets in terms of peak positions, peak widths and\nmosaicity revealed good agreement between both techniques, qualifying 3D ED as\nan alternative tool for analyzing highly beam-sensitive organic thin films.\nFurthermore, the respective advantages and limitations of 3D ED and GIWAXS are\ndiscussed, emphasizing the unique capability of 3D ED to integrate seamlessly\nwith the diverse imaging and spectroscopic modalities in modern TEM. This\nintegration enriches the techniques of structural characterization of OSCs,\npaving the way for deeper insights into their structural properties and\nultimately their performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11254v1",
    "published": "2025-02-16T20:15:10+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11253v2",
    "title": "The Q-Spellbook: Crafting Surface Code Layouts and Magic State Protocols for Large-Scale Quantum Computing",
    "authors": [
      "Avimita Chatterjee",
      "Archisman Ghosh",
      "Swaroop Ghosh"
    ],
    "abstract": "Quantum error correction is a cornerstone of reliable quantum computing, with\nsurface codes emerging as a prominent method for protecting quantum\ninformation. Surface codes are efficient for Clifford gates but require magic\nstate distillation protocols to process non-Clifford gates, such as T gates,\nessential for universal quantum computation. In large-scale quantum\narchitectures capable of correcting arbitrary circuits, specialized surface\ncodes for data qubits and distinct codes for magic state distillation are\nneeded. These architectures can be organized into data blocks and distillation\nblocks. The system works by having distillation blocks produce magic states and\ndata blocks consume them, causing stalls due to either a shortage or excess of\nmagic states. This bottleneck presents an opportunity to optimize quantum space\nby balancing data and distillation blocks. While prior research offers insights\ninto selecting distillation protocols and estimating qubit requirements, it\nlacks a tailored optimization approach. We present a framework for optimizing\nlarge-scale quantum architectures, focusing on data block layouts and magic\nstate distillation protocols. We evaluate three data block layouts and four\ndistillation protocols under three optimization strategies: minimizing tiles,\nminimizing steps, and achieving a balanced trade-off. Through a comparative\nanalysis of brute force, dynamic programming, greedy, and random algorithms, we\nfind that brute force delivers optimal results, while greedy deviates by 7% for\nminimizing steps and dynamic programming matches brute force in tile\nminimization. We observe that total steps increase with columns, while total\ntiles scale with qubits. Finally, we propose a heuristic to help users select\nalgorithms suited to their objectives, enabling scalable and efficient quantum\narchitectures.",
    "pdf_url": "http://arxiv.org/pdf/2502.11253v2",
    "published": "2025-02-16T20:13:51+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11252v1",
    "title": "A Spiral Structure in the Inner Oort Cloud",
    "authors": [
      "David Nesvorny",
      "Luke Dones",
      "David Vokrouhlicky",
      "Hal F. Levison",
      "Cristian Beauge",
      "Jacqueline Faherty",
      "Carter Emmart",
      "Jon P. Parker"
    ],
    "abstract": "As the Galactic tide acts to decouple bodies from the scattered disk it\ncreates a spiral structure in physical space that is roughly 15,000 au in\nlength. The spiral is long-lived and persists in the inner Oort cloud to the\npresent time. Here we discuss dynamics underlying the Oort spiral and (feeble)\nprospects for its observational detection.",
    "pdf_url": "http://arxiv.org/pdf/2502.11252v1",
    "published": "2025-02-16T20:11:43+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11251v1",
    "title": "Explaining Necessary Truths",
    "authors": [
      "Glce Karde",
      "Simon DeDeo"
    ],
    "abstract": "Knowing the truth is rarely enough -- we also seek out reasons why the fact\nis true. While much is known about how we explain contingent truths, we\nunderstand less about how we explain facts, such as those in mathematics, that\nare true as a matter of logical necessity. We present a framework, based in\ncomputational complexity, where explanations for deductive truths co-emerge\nwith discoveries of simplifying steps during the search process. When such\nstructures are missing, we revert, in turn, to error-based reasons, where a\n(corrected) mistake can serve as fictitious, but explanatory,\ncontingency-cause: not making the mistake serves as a reason why the truth\ntakes the form it does. We simulate human subjects, using GPT-4o, presented\nwith SAT puzzles of varying complexity and reasonableness, validating our\ntheory and showing how its predictions can be tested in future human studies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11251v1",
    "published": "2025-02-16T20:11:39+00:00",
    "categories": [
      "cs.AI",
      "cs.CC",
      "math.HO",
      "q-bio.NC",
      "97C30 (Primary), 91E10 (Secondary)"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11250v1",
    "title": "Uncertainty-Aware Step-wise Verification with Generative Reward Models",
    "authors": [
      "Zihuiwen Ye",
      "Luckeciano Carvalho Melo",
      "Younesse Kaddar",
      "Phil Blunsom",
      "Sam Staton",
      "Yarin Gal"
    ],
    "abstract": "Complex multi-step reasoning tasks, such as solving mathematical problems,\nremain challenging for large language models (LLMs). While outcome supervision\nis commonly used, process supervision via process reward models (PRMs) provides\nintermediate rewards to verify step-wise correctness in solution traces.\nHowever, as proxies for human judgement, PRMs suffer from reliability issues,\nincluding susceptibility to reward hacking. In this work, we propose leveraging\nuncertainty quantification (UQ) to enhance the reliability of step-wise\nverification with generative reward models for mathematical reasoning tasks. We\nintroduce CoT Entropy, a novel UQ method that outperforms existing approaches\nin quantifying a PRM's uncertainty in step-wise verification. Our results\ndemonstrate that incorporating uncertainty estimates improves the robustness of\njudge-LM PRMs, leading to more reliable verification.",
    "pdf_url": "http://arxiv.org/pdf/2502.11250v1",
    "published": "2025-02-16T20:00:56+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11249v1",
    "title": "Hadamard's lemma in separable Hilbert spaces",
    "authors": [
      "Arian Brdllima"
    ],
    "abstract": "We extend Hadamard's Lemma to the setting of a separable Hilbert space.",
    "pdf_url": "http://arxiv.org/pdf/2502.11249v1",
    "published": "2025-02-16T19:59:02+00:00",
    "categories": [
      "math.FA",
      "46C05, 26E15, 46G05, 26E35"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11248v2",
    "title": "Synthetic Politics: Prevalence, Spreaders, and Emotional Reception of AI-Generated Political Images on X",
    "authors": [
      "Zhiyi Chen",
      "Jinyi Ye",
      "Beverlyn Tsai",
      "Emilio Ferrara",
      "Luca Luceri"
    ],
    "abstract": "Despite widespread concerns about the risks of AI-generated content (AIGC) to\nthe integrity of social media discourse, little is known about its scale and\nscope, the actors responsible for its dissemination online, and the user\nresponses it elicits. In this work, we measure and characterize the prevalence,\nspreaders, and emotional reception of AI-generated political images. Analyzing\na large-scale dataset from Twitter/X related to the 2024 U.S. Presidential\nElection, we find that approximately 12% of shared images are detected as\nAI-generated, and around 10% of users are responsible for sharing 80% of\nAI-generated images. AIGC superspreaders--defined as the users who not only\nshare a high volume of AI-generated images but also receive substantial\nengagement through retweets--are more likely to be X Premium subscribers, have\na right-leaning orientation, and exhibit automated behavior. Their profiles\ncontain a higher proportion of AI-generated images than non-superspreaders, and\nsome engage in extreme levels of AIGC sharing. Moreover, superspreaders' AI\nimage tweets elicit more positive and less toxic responses than their non-AI\nimage tweets. This study serves as one of the first steps toward understanding\nthe role generative AI plays in shaping online socio-political environments and\noffers implications for platform governance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11248v2",
    "published": "2025-02-16T19:55:29+00:00",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11247v2",
    "title": "Correlative and in situ microscopy investigation of phase transformation, crystal growth and degradation of antimony sulfide thin films",
    "authors": [
      "Mingjian Wu",
      "Massa K. S. Barr",
      "Vanessa M. Koch",
      "Martin Dierner",
      "Tobias Dierke",
      "Penghan Lu",
      "Johannes Will",
      "Rafal Dunin-Borkowski",
      "Janina Maultzsch",
      "Julien Bachmann",
      "Erdmann Spiecker"
    ],
    "abstract": "Antimony sulfide (Sb$_2$S$_3$), a compound of earth-abundant elements with\nhighly anisotropic, quasi-layered crystal structure, triggered growing interest\nas a solar absorber in photovoltaics and as a phase change material in memory\ndevices, yet challenges remain in achieving high-quality thin films with\ncontrolled nucleation and growth for optimal performance. Here, we investigate\nthe phase transformation, crystal structure and properties, growth and\ndegradation of atomic layer deposited Sb$_2$S$_3$ thin films using in situ TEM\nand correlative ex situ analysis. The as-deposited amorphous films crystallized\nat 243{\\deg}C, forming grains with an [100] out-of-plane texture and developed\ninto tens to hundreds of micrometer, leaves-shaped grains. Introducing an\nultra-thin ZnS interfacial layer increased nucleation density, and resulted in\na few micrometer-sized, more uniform grains while retaining the overall [100]\ntexture. In situ observations and subsequent crystal orientation analysis with\ncutting-edge 4D-STEM and EBSD revealed that the grains grew faster along the\n[010] ribbon direction and that the bare films underwent early-stage\ndegradation, forming holes in amorphous regions during annealing. The ZnS\ninterlayer mitigated degradation, stabilizing the films and improving their\nuniformity. These findings offer valuable insights for optimizing Sb$_2$S$_3$\nthin films for applications both as solar cell materials and phase change\nmaterials.",
    "pdf_url": "http://arxiv.org/pdf/2502.11247v2",
    "published": "2025-02-16T19:53:53+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11246v1",
    "title": "MemeSense: An Adaptive In-Context Framework for Social Commonsense Driven Meme Moderation",
    "authors": [
      "Sayantan Adak",
      "Somnath Banerjee",
      "Rajarshi Mandal",
      "Avik Halder",
      "Sayan Layek",
      "Rima Hazra",
      "Animesh Mukherjee"
    ],
    "abstract": "Memes present unique moderation challenges due to their subtle, multimodal\ninterplay of images, text, and social context. Standard systems relying\npredominantly on explicit textual cues often overlook harmful content\ncamouflaged by irony, symbolism, or cultural references. To address this gap,\nwe introduce MemeSense, an adaptive in-context learning framework that fuses\nsocial commonsense reasoning with visually and semantically related reference\nexamples. By encoding crucial task information into a learnable cognitive shift\nvector, MemeSense effectively balances lexical, visual, and ethical\nconsiderations, enabling precise yet context-aware meme intervention. Extensive\nevaluations on a curated set of implicitly harmful memes demonstrate that\nMemeSense substantially outperforms strong baselines, paving the way for safer\nonline communities. Code and data available at:\nhttps://github.com/sayantan11995/MemeSense",
    "pdf_url": "http://arxiv.org/pdf/2502.11246v1",
    "published": "2025-02-16T19:46:24+00:00",
    "categories": [
      "cs.IR",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11245v1",
    "title": "Shortcuts and Identifiability in Concept-based Models from a Neuro-Symbolic Lens",
    "authors": [
      "Samuele Bortolotti",
      "Emanuele Marconato",
      "Paolo Morettin",
      "Andrea Passerini",
      "Stefano Teso"
    ],
    "abstract": "Concept-based Models are neural networks that learn a concept extractor to\nmap inputs to high-level concepts and an inference layer to translate these\ninto predictions. Ensuring these modules produce interpretable concepts and\nbehave reliably in out-of-distribution is crucial, yet the conditions for\nachieving this remain unclear. We study this problem by establishing a novel\nconnection between Concept-based Models and reasoning shortcuts (RSs), a common\nissue where models achieve high accuracy by learning low-quality concepts, even\nwhen the inference layer is fixed and provided upfront. Specifically, we first\nextend RSs to the more complex setting of Concept-based Models and then derive\ntheoretical conditions for identifying both the concepts and the inference\nlayer. Our empirical results highlight the impact of reasoning shortcuts and\nshow that existing methods, even when combined with multiple natural mitigation\nstrategies, often fail to meet these conditions in practice.",
    "pdf_url": "http://arxiv.org/pdf/2502.11245v1",
    "published": "2025-02-16T19:45:09+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11244v2",
    "title": "Soteria: Language-Specific Functional Parameter Steering for Multilingual Safety Alignment",
    "authors": [
      "Somnath Banerjee",
      "Sayan Layek",
      "Pratyush Chatterjee",
      "Animesh Mukherjee",
      "Rima Hazra"
    ],
    "abstract": "Ensuring consistent safety across multiple languages remains a significant\nchallenge for large language models (LLMs). We introduce Soteria, a lightweight\nyet powerful strategy that locates and minimally adjusts the \"functional heads\"\nmost responsible for harmful content generation in each language. By altering\nonly a fraction of parameters, Soteria drastically reduces policy violations\nwithout sacrificing overall model performance, even in low-resource settings.\nTo rigorously evaluate our approach, we also present XThreatBench, a\nspecialized multilingual dataset capturing fine-grained harmful behaviors drawn\nfrom real policy guidelines. Experiments with leading open-source LLMs (e.g.,\nLlama, Qwen, Mistral) show that Soteria consistently improves safety metrics\nacross high-, mid-, and low-resource languages. These findings highlight a\npromising path toward scalable, linguistically attuned, and ethically aligned\nLLMs worldwide.",
    "pdf_url": "http://arxiv.org/pdf/2502.11244v2",
    "published": "2025-02-16T19:44:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11243v1",
    "title": "Narrow Bracketing and Risk in Games",
    "authors": [
      "Fedor Sandomirskiy",
      "Po Hyun Sung",
      "Omer Tamuz",
      "Ben Wincelberg"
    ],
    "abstract": "We study finite normal-form games under a narrow bracketing assumption: when\nplayers play several games simultaneously, they consider each one separately.\nWe show that under mild additional assumptions, players must play either Nash\nequilibria, logit quantal response equilibria, or their generalizations, which\ncapture players with various risk attitudes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11243v1",
    "published": "2025-02-16T19:40:38+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2502.11242v4",
    "title": "LLMs and Childhood Safety: Identifying Risks and Proposing a Protection Framework for Safe Child-LLM Interaction",
    "authors": [
      "Junfeng Jiao",
      "Saleh Afroogh",
      "Kevin Chen",
      "Abhejay Murali",
      "David Atkinson",
      "Amit Dhurandhar"
    ],
    "abstract": "This study examines the growing use of Large Language Models (LLMs) in\nchild-centered applications, highlighting safety and ethical concerns such as\nbias, harmful content, and cultural insensitivity. Despite their potential to\nenhance learning, there is a lack of standardized frameworks to mitigate these\nrisks. Through a systematic literature review, we identify key parental and\nempirical concerns, including toxicity and ethical breaches in AI outputs.\nMoreover, to address these issues, this paper proposes a protection framework\nfor safe Child-LLM interaction, incorporating metrics for content safety,\nbehavioral ethics, and cultural sensitivity. The framework provides practical\ntools for evaluating LLM safety, offering guidance for developers,\npolicymakers, and educators to ensure responsible AI deployment for children.",
    "pdf_url": "http://arxiv.org/pdf/2502.11242v4",
    "published": "2025-02-16T19:39:48+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11241v2",
    "title": "High-pressure floating zone crystal growth of Sr$_2$IrO$_4$",
    "authors": [
      "S. J. Gomez Alvarado",
      "Y. Pang",
      "P. A. Barrera",
      "D. Rout",
      "C. Robison",
      "Z. Porter",
      "H. Z. Porter",
      "E. A. Lawrence",
      "E. N. Bassey",
      "S. D. Wilson"
    ],
    "abstract": "Here we demonstrate the floating zone crystal growth of the\n$J_\\mathrm{eff}=1/2$ Mott insulator Sr$_2$IrO$_4$. Historically, the growth of\niridates from a ternary melt has been precluded by the extreme vapor pressure\nof the metal oxide species and the difficulty of maintaining the correct\noxidation state of Ir at high temperatures. Here, we show that the application\nof a high-pressure oxygen growth environment stabilizes the Sr$_2$IrO$_4$\nphase, leading to the first demonstration of cm$^{3}$-scale crystals. In\ncontrast to the conventional SrCl$_2$ flux growth method, where poor control\nover disorder leads to strong sample dependence, the high-pressure floating\nzone growth enables active control over the homogeneity of the melt. Crystals\ngrown via this technique possess qualitatively similar properties to those\ngrown via flux, with a relatively sharp onset of antiferromagnetic order\nobserved in temperature-dependent magnetization. Further, we demonstrate that\nby tuning the mixing rate of the melt, we are able to grow natively hole-doped\nSr$_2$Ir$_{1-y}$O$_4$, which exhibits a strongly modified magnetic and\nelectronic response.",
    "pdf_url": "http://arxiv.org/pdf/2502.11241v2",
    "published": "2025-02-16T19:38:55+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11240v2",
    "title": "Quantum Dynamical Microscopic Approach to Stellar Carbon Burning",
    "authors": [
      "Grant Close",
      "Paul Stevenson",
      "Alexis Diaz-Torres"
    ],
    "abstract": "The process of carbon burning is vital to understanding late stage stellar\nevolution of massive stars and the conditions of certain supernovae. Carbon\nburning is a complex problem, involving quantum tunnelling and nuclear\nmolecular states. Quantum dynamical calculations of carbon burning are\npresented, combining the time-dependent wave-packet method and the\ndensity-constrained time-dependent Hartree-Fock (DC-TDHF) approach. By limiting\nthe contribution of triaxial molecular configurations to fusion, we demonstrate\nthat the DC-TDHF interaction potential successfully explains the appearance of\nsome resonant structures in the sub-barrier fusion cross-section. This result\nshows the critical role of nucleon-nucleon interactions in the 12C + 12C fusion\nresonances observed at astrophysical energies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11240v2",
    "published": "2025-02-16T19:38:52+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.11239v2",
    "title": "Towards identifying possible fault-tolerant advantage of quantum linear system algorithms in terms of space, time and energy",
    "authors": [
      "Yue Tu",
      "Mark Dubynskyi",
      "Mohammadhossein Mohammadisiahroudi",
      "Ekaterina Riashchentceva",
      "Jinglei Cheng",
      "Dmitry Ryashchentsev",
      "Tams Terlaky",
      "Junyu Liu"
    ],
    "abstract": "Quantum computing, a prominent non-Von Neumann paradigm beyond Moore's law,\ncan offer superpolynomial speedups for certain problems. Yet its advantages in\nefficiency for tasks like machine learning remain under investigation, and\nquantum noise complicates resource estimations and classical comparisons. We\nprovide a detailed estimation of space, time, and energy resources for\nfault-tolerant superconducting devices running the Harrow-Hassidim-Lloyd (HHL)\nalgorithm, a quantum linear system solver relevant to linear algebra and\nmachine learning. Excluding memory and data transfer, possible quantum\nadvantages over the classical conjugate gradient method could emerge at $N\n\\approx 2^{33} \\sim 2^{48}$ or even lower, requiring ${O}(10^5)$ physical\nqubits, ${O}(10^{12}\\sim10^{13})$ Joules, and ${O}(10^6)$ seconds under surface\ncode fault-tolerance with three types of magic state distillation (15-1,\n116-12, 225-1). Key parameters include condition number, sparsity, and\nprecision $\\kappa, s\\approx{O}(10\\sim100)$, $\\epsilon\\sim0.01$, and physical\nerror $10^{-5}$. Our resource estimator adjusts $N, \\kappa, s, \\epsilon$,\nproviding a map of quantum-classical boundaries and revealing where a practical\nquantum advantage may arise. Our work quantitatively determine how advanced a\nfault-tolerant quantum computer should be to achieve possible, significant\nbenefits on problems related to real-world.",
    "pdf_url": "http://arxiv.org/pdf/2502.11239v2",
    "published": "2025-02-16T19:12:32+00:00",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11238v1",
    "title": "Span-Agnostic Optimal Sample Complexity and Oracle Inequalities for Average-Reward RL",
    "authors": [
      "Matthew Zurek",
      "Yudong Chen"
    ],
    "abstract": "We study the sample complexity of finding an $\\varepsilon$-optimal policy in\naverage-reward Markov Decision Processes (MDPs) with a generative model. The\nminimax optimal span-based complexity of $\\widetilde{O}(SAH/\\varepsilon^2)$,\nwhere $H$ is the span of the optimal bias function, has only been achievable\nwith prior knowledge of the value of $H$. Prior-knowledge-free algorithms have\nbeen the objective of intensive research, but several natural approaches\nprovably fail to achieve this goal. We resolve this problem, developing the\nfirst algorithms matching the optimal span-based complexity without $H$\nknowledge, both when the dataset size is fixed and when the suboptimality level\n$\\varepsilon$ is fixed. Our main technique combines the discounted reduction\napproach with a method for automatically tuning the effective horizon based on\nempirical confidence intervals or lower bounds on performance, which we term\nhorizon calibration. We also develop an empirical span penalization approach,\ninspired by sample variance penalization, which satisfies an oracle inequality\nperformance guarantee. In particular this algorithm can outperform the minimax\ncomplexity in benign settings such as when there exist near-optimal policies\nwith span much smaller than $H$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11238v1",
    "published": "2025-02-16T19:10:55+00:00",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11237v1",
    "title": "Probing the sensitivity of semi-visible jets to current LHC measurements using the CONTUR toolkit",
    "authors": [
      "Andy Buckley",
      "Jon Butterworth",
      "Louie Corpe",
      "Caterina Doglioni",
      "Deepak Kar",
      "Clarisse Prat",
      "Sukanya Sinha",
      "Danielle Wilson-Edwards"
    ],
    "abstract": "Semi-visible jets arise from a hypothetical, strongly interacting ``dark\nsector'' -- a dark counterpart of quantum chromodynamics whose partial decays\nback to Standard Model particles introduce new types of collider BSM signature.\nCMS and ATLAS have have searched for semi-visible jets in the resonant and\nnon-resonant production modes and set constraints on mediator mass values. In\nthis work, indirect constraints on various model parameters, such as dark\nhadron masses and coupling strengths, are explored using LHC measurements.",
    "pdf_url": "http://arxiv.org/pdf/2502.11237v1",
    "published": "2025-02-16T19:08:45+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11236v3",
    "title": "Weak mixing angle under $\\text{U}(1, 3)$ colored gravity",
    "authors": [
      "Robert Monjo"
    ],
    "abstract": "Colored gravity, based on $\\text{U}(1,3)$ symmetry, emerges naturally in the\ncomplexification of Lorentzian manifolds and integrates U(1) electromagnetism\nas a subcase. This work explores the viability of also including strong and\nelectroweak interactions under the $\\text{U}(1,3)$ gauge group of colored\ngravity. We identify specific generators linked to leptonic and quark\ninteractions and embed the standard Higgs mechanism. Crucially, the weak mixing\nangle ($\\sin^2\\theta_W$) is predicted to exhibit about $\\sim0.231$ for\nlepton-lepton interactions (close to observations) and $\\sim0.222$ for\nhadron-lepton interactions, which is in 3$\\sigma$ tension with some\nobservations. These findings open pathways for reconciling experimental data\nwith colored gravity and suggest avenues for quantum correction studies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11236v3",
    "published": "2025-02-16T19:04:48+00:00",
    "categories": [
      "hep-ph",
      "gr-qc",
      "hep-th",
      "81V22"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.14889v1",
    "title": "Narrowing Information Bottleneck Theory for Multimodal Image-Text Representations Interpretability",
    "authors": [
      "Zhiyu Zhu",
      "Zhibo Jin",
      "Jiayu Zhang",
      "Nan Yang",
      "Jiahao Huang",
      "Jianlong Zhou",
      "Fang Chen"
    ],
    "abstract": "The task of identifying multimodal image-text representations has garnered\nincreasing attention, particularly with models such as CLIP (Contrastive\nLanguage-Image Pretraining), which demonstrate exceptional performance in\nlearning complex associations between images and text. Despite these\nadvancements, ensuring the interpretability of such models is paramount for\ntheir safe deployment in real-world applications, such as healthcare. While\nnumerous interpretability methods have been developed for unimodal tasks, these\napproaches often fail to transfer effectively to multimodal contexts due to\ninherent differences in the representation structures. Bottleneck methods,\nwell-established in information theory, have been applied to enhance CLIP's\ninterpretability. However, they are often hindered by strong assumptions or\nintrinsic randomness. To overcome these challenges, we propose the Narrowing\nInformation Bottleneck Theory, a novel framework that fundamentally redefines\nthe traditional bottleneck approach. This theory is specifically designed to\nsatisfy contemporary attribution axioms, providing a more robust and reliable\nsolution for improving the interpretability of multimodal models. In our\nexperiments, compared to state-of-the-art methods, our approach enhances image\ninterpretability by an average of 9%, text interpretability by an average of\n58.83%, and accelerates processing speed by 63.95%. Our code is publicly\naccessible at https://github.com/LMBTough/NIB.",
    "pdf_url": "http://arxiv.org/pdf/2502.14889v1",
    "published": "2025-02-16T19:01:37+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12207v4",
    "title": "PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN",
    "authors": [
      "Jiayu Zhang",
      "Zhiyu Zhu",
      "Xinyi Wang",
      "Silin Liao",
      "Zhibo Jin",
      "Flora D. Salim",
      "Huaming Chen"
    ],
    "abstract": "Deep neural networks have demonstrated remarkable performance across various\ndomains. However, they are vulnerable to adversarial examples, which can lead\nto erroneous predictions. Generative Adversarial Networks (GANs) can leverage\nthe generators and discriminators model to quickly produce high-quality\nadversarial examples. Since both modules train in a competitive and\nsimultaneous manner, GAN-based algorithms like AdvGAN can generate adversarial\nexamples with better transferability compared to traditional methods. However,\nthe generation of perturbations is usually limited to a single iteration,\npreventing these examples from fully exploiting the potential of the methods.\nTo tackle this issue, we introduce a novel approach named Progressive\nAuto-Regression AdvGAN (PAR-AdvGAN). It incorporates an auto-regressive\niteration mechanism within a progressive generation network to craft\nadversarial examples with enhanced attack capability. We thoroughly evaluate\nour PAR-AdvGAN method with a large-scale experiment, demonstrating its superior\nperformance over various state-of-the-art black-box adversarial attacks, as\nwell as the original AdvGAN.Moreover, PAR-AdvGAN significantly accelerates the\nadversarial example generation, i.e., achieving the speeds of up to 335.5\nframes per second on Inception-v3 model, outperforming the gradient-based\ntransferable attack algorithms. Our code is available at:\nhttps://github.com/LMBTough/PAR",
    "pdf_url": "http://arxiv.org/pdf/2502.12207v4",
    "published": "2025-02-16T19:00:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11235v1",
    "title": "Disorder-induced liquid-solid phase coexistence in 2D electron systems",
    "authors": [
      "Sandeep Joy",
      "Brian Skinner"
    ],
    "abstract": "Recent imaging experiments show a surprisingly robust regime of liquid-solid\nphase coexistence in a 2D electron system near the quantum melting/freezing\ntransition, with the two phases mixed in mesoscopic domains. Strikingly, the\nexperiments find no noticeable difference in electron density between the\nliquid and solid domains, which is at odds with both microemulsion scenarios\nand scenarios in which phase coexistence is driven by fluctuations of a\nlong-ranged disorder potential. Here, we show that such phase coexistence\nwithout density difference can be induced by random fluctuations of a\nshort-ranged disorder potential. We further show that disorder tends to\nstabilize the Wigner Crystal phase to higher densities, which is also\nconsistent with the experiments.",
    "pdf_url": "http://arxiv.org/pdf/2502.11235v1",
    "published": "2025-02-16T19:00:01+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11234v2",
    "title": "MaskFlow: Discrete Flows For Flexible and Efficient Long Video Generation",
    "authors": [
      "Michael Fuest",
      "Vincent Tao Hu",
      "Bjrn Ommer"
    ],
    "abstract": "Generating long, high-quality videos remains a challenge due to the complex\ninterplay of spatial and temporal dynamics and hardware limitations. In this\nwork, we introduce MaskFlow, a unified video generation framework that combines\ndiscrete representations with flow-matching to enable efficient generation of\nhigh-quality long videos. By leveraging a frame-level masking strategy during\ntraining, MaskFlow conditions on previously generated unmasked frames to\ngenerate videos with lengths ten times beyond that of the training sequences.\nMaskFlow does so very efficiently by enabling the use of fast Masked Generative\nModel (MGM)-style sampling and can be deployed in both fully autoregressive as\nwell as full-sequence generation modes. We validate the quality of our method\non the FaceForensics (FFS) and Deepmind Lab (DMLab) datasets and report Frechet\nVideo Distance (FVD) competitive with state-of-the-art approaches. We also\nprovide a detailed analysis on the sampling efficiency of our method and\ndemonstrate that MaskFlow can be applied to both timestep-dependent and\ntimestep-independent models in a training-free manner.",
    "pdf_url": "http://arxiv.org/pdf/2502.11234v2",
    "published": "2025-02-16T18:59:11+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11233v3",
    "title": "Milstein Approximation for Free Stochastic Differential Equations",
    "authors": [
      "Michael Wibmer",
      "Georg Schlchtermann"
    ],
    "abstract": "This paper derives a new numerical method for approximating Free Stochastic\nDifferential Equations with strong convergence order one. Previously, the\nauthors derived a free variant of the Euler-Maruyama method, which obeys strong\nconvergence order of 0.5. In this paper these results are extended using\nmultiple operator integrals and Taylor expansion of Operator Functions. The new\nmethod can be viewed as the free variant of the Milstein-Method for Stochastic\nDifferential Equations. In addition, we generalize the results of the free\nEuler-Maruyama method to Lp({\\phi}), 1 \\leq p \\leq \\infty.",
    "pdf_url": "http://arxiv.org/pdf/2502.11233v3",
    "published": "2025-02-16T18:59:10+00:00",
    "categories": [
      "math.PR",
      "46L53, 46L54, 60H10, 65C30"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11232v1",
    "title": "Strain engineering of valley-polarized hybrid excitons in a 2D semiconductor",
    "authors": [
      "Abhijeet M. Kumar",
      "Douglas J. Bock",
      "Denis Yagodkin",
      "Edith Wietek",
      "Bianca Hfer",
      "Max Sinner",
      "Pablo Hernndez Lpez",
      "Sebastian Heeg",
      "Cornelius Gahl",
      "Florian Libisch",
      "Alexey Chernikov",
      "Ermin Malic",
      "Roberto Rosati",
      "Kirill I. Bolotin"
    ],
    "abstract": "Encoding and manipulating digital information in quantum degrees of freedom\nis one of the major challenges of today's science and technology. The valley\nindices of excitons in transition metal dichalcogenides (TMDs) are well-suited\nto address this challenge. Here, we demonstrate a new class of strain-tunable,\nvalley-polarized hybrid excitons in monolayer TMDs, comprising a pair of\nenergy-resonant intra- and intervalley excitons. These states combine the\nadvantages of bright intravalley excitons, where the valley index directly\ncouples to light polarization, and dark intervalley excitons, characterized by\nlow depolarization rates. We demonstrate that the hybridized state of dark KK'\nintervalley and defect-localized excitons exhibits a degree of circular\npolarization of emitted photons that is three times higher than that of the\nconstituent species. Moreover, a bright KK intravalley and a dark KQ exciton\nform a coherently coupled hybrid state under energetic resonance, with their\nvalley depolarization dynamics slowed down a hundredfold. Overall, these\nvalley-polarized hybrid excitons with strain-tunable valley character emerge as\nprime candidates for valleytronic applications in future quantum and\ninformation technology.",
    "pdf_url": "http://arxiv.org/pdf/2502.11232v1",
    "published": "2025-02-16T18:57:54+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "physics.optics"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11231v2",
    "title": "Observable-based reformulation of time-delay interferometry",
    "authors": [
      "Kohei Yamamoto",
      "Jan Niklas Reinhardt",
      "Olaf Hartwig"
    ],
    "abstract": "Spaceborne gravitational-wave observatories utilize a postprocessing\ntechnique known as time-delay interferometry (TDI) to reduce the otherwise\noverwhelming laser frequency noise by around 8 orders of magnitude. While, in\nits traditional form, TDI considers the spacecraft as point masses, recent\nstudies have enhanced this simplified scenario by incorporating more realistic\nmetrology chain models, which include onboard optical, electronic, and digital\ndelays. These studies have updated the TDI algorithm to include onboard delays\nobtained from prelaunch and in-flight calibrations. Conversely, the processing\nscheme presented in this article treats onboard delays as an integral part of\nthe TDI combinations: instead of having separate calibration stages, it\ndirectly expresses all delays appearing in the algorithm in terms of onboard\nmeasurements, especially pseudo-random-noise ranging (PRNR) measurements. The\nonly onboard delays that need to be corrected in our processing scheme are PRNR\ndelays in the digital domain, which are determined by commandable\ndigital-signal-processing parameters; hence, they can be easily managed in\npostprocessing. Furthermore, our processing scheme does not require a prior\ninterspacecraft clock synchronization, and it automatically corrects for\npotential relative drifts between the clocks driving local phase measurement\nsystems. The proposed observable-based formulation closely relates TDI to the\nactual metrology system, and it clearly outlines how to manage onboard\nmeasurements in postprocessing. Hence, it is expected to lead to fundamental\nadvancements in TDI, providing both conceptual completeness and unique\npractical benefits.",
    "pdf_url": "http://arxiv.org/pdf/2502.11231v2",
    "published": "2025-02-16T18:53:43+00:00",
    "categories": [
      "astro-ph.IM",
      "gr-qc"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2502.11230v2",
    "title": "Teaching Well-Structured Code: A Literature Review of Instructional Approaches",
    "authors": [
      "Sara Nurollahian",
      "Hieke Keuning",
      "Eliane Wiese"
    ],
    "abstract": "Teaching the software engineers of the future to write high-quality code with\ngood style and structure is important. This systematic literature review\nidentifies existing instructional approaches, their objectives, and the\nstrategies used for measuring their effectiveness. Building on an existing\nmapping study of code quality in education, we identified 53 papers on code\nstructure instruction. We classified these studies into three categories: (1)\nstudies focused on developing or evaluating automated tools and their usage\n(e.g., code analyzers, tutors, and refactoring tools), (2) studies discussing\nother instructional materials, such as learning resources (e.g., refactoring\nlessons and activities), rubrics, and catalogs of violations, and (3) studies\ndiscussing how to integrate code structure into the curriculum through a\nholistic approach to course design to support code quality. While most\napproaches use analyzers that point students to problems in their code,\nincorporating these tools into classrooms is not straightforward. Combined with\nfurther research on code structure instruction in the classroom, we call for\nmore studies on effectiveness. Over 40% of instructional studies had no\nevaluation. Many studies show promise for their interventions by demonstrating\nimprovement in student performance (e.g., reduced violations in student code\nwhen using the intervention compared with code that was written without access\nto the intervention). These interventions warrant further investigation on\nlearning, to see how students apply their knowledge after the instructional\nsupports are removed.",
    "pdf_url": "http://arxiv.org/pdf/2502.11230v2",
    "published": "2025-02-16T18:51:22+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11229v2",
    "title": "Provable and Practical Online Learning Rate Adaptation with Hypergradient Descent",
    "authors": [
      "Ya-Chi Chu",
      "Wenzhi Gao",
      "Yinyu Ye",
      "Madeleine Udell"
    ],
    "abstract": "This paper investigates the convergence properties of the hypergradient\ndescent method (HDM), a 25-year-old heuristic originally proposed for adaptive\nstepsize selection in stochastic first-order methods. We provide the first\nrigorous convergence analysis of HDM using the online learning framework of\n[Gao24] and apply this analysis to develop new state-of-the-art adaptive\ngradient methods with empirical and theoretical support. Notably, HDM\nautomatically identifies the optimal stepsize for the local optimization\nlandscape and achieves local superlinear convergence. Our analysis explains the\ninstability of HDM reported in the literature and proposes efficient strategies\nto address it. We also develop two HDM variants with heavy-ball and Nesterov\nmomentum. Experiments on deterministic convex problems show HDM with heavy-ball\nmomentum (HDM-HB) exhibits robust performance and significantly outperforms\nother adaptive first-order methods. Moreover, HDM-HB often matches the\nperformance of L-BFGS, an efficient and practical quasi-Newton method, using\nless memory and cheaper iterations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11229v2",
    "published": "2025-02-16T18:49:02+00:00",
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.13162v1",
    "title": "ShieldLearner: A New Paradigm for Jailbreak Attack Defense in LLMs",
    "authors": [
      "Ziyi Ni",
      "Hao Wang",
      "Huacan Wang"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in various\ndomains but remain vulnerable to adversarial jailbreak attacks. Existing\nprompt-defense strategies, including parameter-modifying and parameter-free\napproaches, face limitations in adaptability, interpretability, and\ncustomization, constraining their effectiveness against evolving threats. To\naddress these challenges, we propose ShieldLearner, a novel paradigm that\nmimics human learning in defense. Through trial and error, it autonomously\ndistills attack signatures into a Pattern Atlas and synthesizes defense\nheuristics into a Meta-analysis Framework, enabling systematic and\ninterpretable threat detection. Furthermore, we introduce Adaptive Adversarial\nAugmentation to generate adversarial variations of successfully defended\nprompts, enabling continuous self-improvement without model retraining. In\naddition to standard benchmarks, we create a hard test set by curating\nadversarial prompts from the Wildjailbreak dataset, emphasizing more concealed\nmalicious intent. Experimental results show that ShieldLearner achieves a\nsignificantly higher defense success rate than existing baselines on both\nconventional and hard test sets, while also operating with lower computational\noverhead, making it a practical and efficient solution for real-world\nadversarial defense.",
    "pdf_url": "http://arxiv.org/pdf/2502.13162v1",
    "published": "2025-02-16T18:47:41+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11228v2",
    "title": "Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs",
    "authors": [
      "Mohammad Reza Rezaei",
      "Adji Bousso Dieng"
    ],
    "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\nfor domain-specific question-answering (QA) tasks by leveraging external\nknowledge sources. However, traditional RAG systems primarily focus on\nrelevance-based retrieval and often struggle with redundancy, especially when\nreasoning requires connecting information from multiple sources. This paper\nintroduces Vendi-RAG, a framework based on an iterative process that jointly\noptimizes retrieval diversity and answer quality. This joint optimization leads\nto significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages\nthe Vendi Score (VS), a flexible similarity-based diversity metric, to promote\nsemantic diversity in document retrieval. It then uses an LLM judge that\nevaluates candidate answers, generated after a reasoning step, and outputs a\nscore that the retriever uses to balance relevance and diversity among the\nretrieved documents during each iteration. Experiments on three challenging\ndatasets -- HotpotQA, MuSiQue, and 2WikiMultiHopQA -- demonstrate Vendi-RAG's\neffectiveness in multi-hop reasoning tasks. The framework achieves significant\naccuracy improvements over traditional single-step and multi-step RAG\napproaches, with accuracy increases reaching up to +4.2% on HotpotQA, +4.1% on\n2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the current\nbest baseline. The benefits of Vendi-RAG are even more pronounced as the number\nof retrieved documents increases. Finally, we evaluated Vendi-RAG across\ndifferent LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini, and\nobserved consistent improvements, demonstrating that the framework's advantages\nare model-agnostic.",
    "pdf_url": "http://arxiv.org/pdf/2502.11228v2",
    "published": "2025-02-16T18:46:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11227v1",
    "title": "Integrating Retrospective Framework in Multi-Robot Collaboration",
    "authors": [
      "Jiazhao Liang",
      "Hao Huang",
      "Yu Hao",
      "Geeta Chandra Raju Bethala",
      "Congcong Wen",
      "John-Ross Rizzo",
      "Yi Fang"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated\nsubstantial capabilities in enhancing communication and coordination in\nmulti-robot systems. However, existing methods often struggle to achieve\nefficient collaboration and decision-making in dynamic and uncertain\nenvironments, which are common in real-world multi-robot scenarios. To address\nthese challenges, we propose a novel retrospective actor-critic framework for\nmulti-robot collaboration. This framework integrates two key components: (1) an\nactor that performs real-time decision-making based on observations and task\ndirectives, and (2) a critic that retrospectively evaluates the outcomes to\nprovide feedback for continuous refinement, such that the proposed framework\ncan adapt effectively to dynamic conditions. Extensive experiments conducted in\nsimulated environments validate the effectiveness of our approach,\ndemonstrating significant improvements in task performance and adaptability.\nThis work offers a robust solution to persistent challenges in robotic\ncollaboration.",
    "pdf_url": "http://arxiv.org/pdf/2502.11227v1",
    "published": "2025-02-16T18:38:20+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11226v1",
    "title": "The uniform dimension of a monoid with applications to graph algebras",
    "authors": [
      "Luiz Gustavo Cordeiro",
      "Daniel Gonalves",
      "Roozbeh Hazrat"
    ],
    "abstract": "We adapt Goldie's concept of uniform dimensions from module theory over rings\nto $\\Gamma$-monoids. A $\\Gamma$-monoid $M$ is said to have uniform dimension\n$n$ if $n$ is the largest number of pairwise incomparable nonzero\n$\\Gamma$-order ideals contained in $M$.\n  Specializing to the talented monoid of a graph, we show that the uniform\ndimension provides a rough measure of how the graph branches out. Since for any\norder ideal $I$, its orthogonal ideal $I^\\perp$ is the largest ideal\nincomparable to $I$, we study the notions of orthogonality and regularity,\nparticularly when $I^{\\perp\\perp}=I$. We show that the freeness of the action\nof $\\mathbb Z$ on the talented monoid of a graph is preserved under quotienting\nby a regular ideal. Furthermore, we determine the underlying hereditary and\nsaturated sets that generate these ideals. These results unify recent studies\non regular ideals of the corresponding Leavitt path algebras and graph\n$C^*$-algebras.\n  We conclude that for graphs $E$ and $F$, if there is a $\\mathbb Z$-monoid\nisomorphism $T_E\\cong T_F$, then there is a one-to-one correspondence between\nthe regular ideals of the associated Leavitt path algebras $L_K(E)$ and\n$L_K(F)$ (and similarly, $C^*(E)$ and $C^*(F)$). Since the talented monoid\n$T_E$ is the positive cone of the graded Grothendieck group $K_0^{gr}(L_K(E))$,\nthis provides further evidence supporting the Graded Classification Conjecture.",
    "pdf_url": "http://arxiv.org/pdf/2502.11226v1",
    "published": "2025-02-16T18:28:01+00:00",
    "categories": [
      "math.RA",
      "math.OA",
      "16S88"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11225v1",
    "title": "METAFOR: A Hybrid Metaheuristics Software Framework for Single-Objective Continuous Optimization Problems",
    "authors": [
      "Christian Camacho-Villaln",
      "Marco Dorigo",
      "Thomas Sttzle"
    ],
    "abstract": "Hybrid metaheuristics are powerful techniques for solving difficult\noptimization problems that exploit the strengths of different approaches in a\nsingle implementation. For algorithm designers, however, creating hybrid\nmetaheuristic implementations has become increasingly challenging due to the\nvast number of design options available in the literature and the fact that\nthey often rely on their knowledge and intuition to come up with new algorithm\ndesigns. In this paper, we propose a modular metaheuristic software framework,\ncalled METAFOR, that can be coupled with an automatic algorithm configuration\ntool to automatically design hybrid metaheuristics. METAFOR is specifically\ndesigned to hybridize Particle Swarm Optimization, Differential Evolution and\nCovariance Matrix Adaptation-Evolution Strategy, and includes a local search\nmodule that allows their execution to be interleaved with a subordinate local\nsearch. We use the configuration tool irace to automatically generate 17\ndifferent metaheuristic implementations and evaluate their performance on a\ndiverse set of continuous optimization problems. Our results show that, across\nall the considered problem classes, automatically generated hybrid\nimplementations are able to outperform configured single-approach\nimplementations, while these latter offer advantages on specific classes of\nfunctions. We provide useful insights on the type of hybridization that works\nbest for specific problem classes, the algorithm components that contribute to\nthe performance of the algorithms, and the advantages and disadvantages of two\nwell-known instance separation strategies, creating stratified training set\nusing a fix percentage and leave-one-class-out cross-validation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11225v1",
    "published": "2025-02-16T18:24:44+00:00",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11224v1",
    "title": "An introduction to local tropicalization",
    "authors": [
      "Patrick Popescu-Pampu",
      "Dmitry Stepanov"
    ],
    "abstract": "In this paper we explain four viewpoints on the local tropicalization of\nformal subgerms of toric germs, which is a local analog of the global\ntropicalization of subvarieties of algebraic tori. We start by illustrating\nsome of those viewpoints for plane curve singularities, then we pass to\narbitrary dimensions. We conclude by describing several variants and extensions\nof the notion of local tropicalization presented in this paper.",
    "pdf_url": "http://arxiv.org/pdf/2502.11224v1",
    "published": "2025-02-16T18:18:01+00:00",
    "categories": [
      "math.AG",
      "math.CO",
      "14B05 (primary), 14T10, 14T90, 32S25"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.13161v1",
    "title": "Noumenal Labs White Paper: How To Build A Brain",
    "authors": [
      "Maxwell J. D. Ramstead",
      "Candice Pattisapu",
      "Jason Fox",
      "Jeff Beck"
    ],
    "abstract": "This white paper describes some of the design principles for artificial or\nmachine intelligence that guide efforts at Noumenal Labs. These principles are\ndrawn from both nature and from the means by which we come to represent and\nunderstand it. The end goal of research and development in this field should be\nto design machine intelligences that augment our understanding of the world and\nenhance our ability to act in it, without replacing us. In the first two\nsections, we examine the core motivation for our approach: resolving the\ngrounding problem. We argue that the solution to the grounding problem rests in\nthe design of models grounded in the world that we inhabit, not mere word\nmodels. A machine super intelligence that is capable of significantly enhancing\nour understanding of the human world must represent the world as we do and be\ncapable of generating new knowledge, building on what we already know. In other\nwords, it must be properly grounded and explicitly designed for rational,\nempirical inquiry, modeled after the scientific method. A primary implication\nof this design principle is that agents must be capable of engaging\nautonomously in causal physics discovery. We discuss the pragmatic implications\nof this approach, and in particular, the use cases in realistic 3D world\nmodeling and multimodal, multidimensional time series analysis.",
    "pdf_url": "http://arxiv.org/pdf/2502.13161v1",
    "published": "2025-02-16T18:15:37+00:00",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11223v1",
    "title": "Asymmetric Conflict and Synergy in Post-training for LLM-based Multilingual Machine Translation",
    "authors": [
      "Tong Zheng",
      "Yan Wen",
      "Huiwen Bao",
      "Junfeng Guo",
      "Heng Huang"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) has advanced the multilingual\nmachine translation (MMT), yet the Curse of Multilinguality (CoM) remains a\nmajor challenge. Existing work in LLM-based MMT typically mitigates this issue\nvia scaling up training and computation budget, which raises a critical\nquestion: Is scaling up the training and computation budget truly necessary for\nhigh-quality MMT, or can a deeper understanding of CoM provide a more efficient\nsolution? To explore this problem, we analyze the linguistic conflicts and\nsynergy, the underlying mechanism of CoM during post-training phase. We\nidentify an asymmetric phenomenon in linguistic conflicts and synergy: the\ndominance of conflicts and synergy varies in different translation directions,\nleading to sub-optimal adaptation in existing post-training methods. We further\nfind that a significant bottleneck in MMT appears to lie in post-training\nrather than multilingual pre-training, suggesting the need for more effective\nadaptation strategies. Building on these new insights, we propose a\ndirection-aware training approach, combined with group-wise model merging, to\naddress asymmetry in linguistic conflicts and synergy explicitly. Leveraging\nthis strategy, our method fine-tunes X-ALMA-13B-Pretrain-trained only with\nmultilingual pre-training-achieving comparable performance to XALMA-13B (only\nSFT) while using only 20B pretraining tokens and 17B parameters-5.5x fewer\npretraining-tokens and 1.7x fewer model size-with just 0.85 COMET drop on\nFlores-200 testsets of 50 languages.",
    "pdf_url": "http://arxiv.org/pdf/2502.11223v1",
    "published": "2025-02-16T18:06:58+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11222v1",
    "title": "Pythagoras numbers for infinite algebraic fields",
    "authors": [
      "Nicolas Daans",
      "Stevan Gajovi",
      "Siu Hang Man",
      "Pavlo Yatsyna"
    ],
    "abstract": "We prove that the Pythagoras number of the ring of integers of the compositum\nof all real quadratic fields is infinite. The same holds for certain infinite\ntotally real cyclotomic fields. In contrast, we construct infinite degree\ntotally real algebraic fields whose rings of integers have finite Pythagoras\nnumbers, namely, one, two, three, and at least four.",
    "pdf_url": "http://arxiv.org/pdf/2502.11222v1",
    "published": "2025-02-16T18:03:18+00:00",
    "categories": [
      "math.NT",
      "11E08, 11E25, 11R18, 11R20, 11R80, 12D15"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11221v3",
    "title": "PlanGenLLMs: A Modern Survey of LLM Planning Capabilities",
    "authors": [
      "Hui Wei",
      "Zihao Zhang",
      "Shenghua He",
      "Tian Xia",
      "Shijia Pan",
      "Fei Liu"
    ],
    "abstract": "LLMs have immense potential for generating plans, transforming an initial\nworld state into a desired goal state. A large body of research has explored\nthe use of LLMs for various planning tasks, from web navigation to travel\nplanning and database querying. However, many of these systems are tailored to\nspecific problems, making it challenging to compare them or determine the best\napproach for new tasks. There is also a lack of clear and consistent evaluation\ncriteria. Our survey aims to offer a comprehensive overview of current LLM\nplanners to fill this gap. It builds on foundational work by Kartam and Wilkins\n(1990) and examines six key performance criteria: completeness, executability,\noptimality, representation, generalization, and efficiency. For each, we\nprovide a thorough analysis of representative works and highlight their\nstrengths and weaknesses. Our paper also identifies crucial future directions,\nmaking it a valuable resource for both practitioners and newcomers interested\nin leveraging LLM planning to support agentic workflows.",
    "pdf_url": "http://arxiv.org/pdf/2502.11221v3",
    "published": "2025-02-16T17:54:57+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11220v1",
    "title": "Coarse-Graining Cascades Within Food Webs",
    "authors": [
      "Justin D. Yeakel"
    ],
    "abstract": "Quantifying population dynamics is a fundamental challenge in ecology and\nevolutionary biology, particularly for species that are cryptic, microscopic,\nor extinct. Traditional approaches rely on continuous representations of\npopulation size, but in many cases, the precise number of individuals is\nunknowable. Here, we present a coarse-grained population model that simplifies\npopulation dynamics to binary states - high or low - determined by the balance\nof bottom-up resource availability and top-down predation pressure. This\nBoolean framework provides a minimal yet analytically tractable alternative to\ntraditional Lotka-Volterra-based models, enabling direct insights into the role\nof food web structure in shaping community stability. Using this approach, we\ninvestigate how trophic interactions influence population persistence, cyclic\ndynamics, and extinction risk across model food webs. We find that top-down\neffects are a primary driver of cycling, aligning with theoretical expectations\nfrom traditional population models, and that trophic position strongly\ninfluences extinction risk, with higher-trophic species more prone to\npersistent low-population states. Additionally, we explore the role of trophic\nshort-circuits -- direct interactions between apex predators and low-trophic\nprey -- and find that they can buffer cascades and alter extinction patterns in\nways that are often overlooked in classical models. By simplifying population\ndynamics to a two-state system, this framework provides a powerful tool for\ndisentangling the structural drivers of community stability. These results\nhighlight the potential of coarse-grained approaches to complement existing\nmodels, offering new insights into trophic interactions, extinction risks, and\nthe susceptibility of species to trophic cascades.",
    "pdf_url": "http://arxiv.org/pdf/2502.11220v1",
    "published": "2025-02-16T17:44:39+00:00",
    "categories": [
      "q-bio.PE",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11219v1",
    "title": "AudioSpa: Spatializing Sound Events with Text",
    "authors": [
      "Linfeng Feng",
      "Lei Zhao",
      "Boyu Zhu",
      "Xiao-Lei Zhang",
      "Xuelong Li"
    ],
    "abstract": "Text-to-audio (TTA) systems have recently demonstrated strong performance in\nsynthesizing monaural audio from text. However, the task of generating binaural\nspatial audio from text, which provides a more immersive auditory experience by\nincorporating the sense of spatiality, have not been explored yet. In this\nwork, we introduce text-guided binaural audio generation. As an early effort,\nwe focus on the scenario where a monaural reference audio is given\nadditionally. The core problem is to associate specific sound events with their\ndirections, thereby creating binaural spatial audio. The challenge lies in the\ncomplexity of textual descriptions and the limited availability of\nsingle-source sound event datasets. To address this, we propose AudioSpa, an\nend-to-end model that applies large language models to process both acoustic\nand textual information. We employ fusion multi-head attention (FMHA) to\nintegrate text tokens, which enhances the generation capability of the\nmultimodal learning. Additionally, we propose a binaural source localization\nmodel to assess the quality of the generated audio. Finally, we design a data\naugmentation strategy to generate diverse datasets, which enables the model to\nspatialize sound events across various spatial positions. Experimental results\ndemonstrate that our model is able to put sounds at the specified locations\naccurately. It achieves competitive performance in both localization accuracy\nand signal distortion. Our demonstrations are available at\nhttps://linfeng-feng.github.io/AudioSpa-demo.",
    "pdf_url": "http://arxiv.org/pdf/2502.11219v1",
    "published": "2025-02-16T17:41:14+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11217v2",
    "title": "A Catalog of Local Universe Fast Radio Bursts from CHIME/FRB and the KKO Outrigger",
    "authors": [
      "The CHIME/FRB Collaboration",
      ":",
      "Mandana Amiri",
      "Daniel Amouyal",
      "Bridget C. Andersen",
      "Shion Andrew",
      "Kevin Bandura",
      "Mohit Bhardwaj",
      "P. J. Boyle",
      "Charanjot Brar",
      "Alyssa Cassity",
      "Shami Chatterjee",
      "Alice P. Curtin",
      "Matt Dobbs",
      "Fengqiu Adam Dong",
      "Yuxin Dong",
      "Gwendolyn M. Eadie",
      "Tarraneh Eftekhari",
      "Wen-fai Fong",
      "Emmanuel Fonseca",
      "B. M. Gaensler",
      "Mark Halpern",
      "Jason W. T. Hessels",
      "Hans Hopkins",
      "Adaeze L. Ibik",
      "Ronniy C. Joseph",
      "Jane Kaczmarek",
      "Lordrick Kahinga",
      "Victoria Kaspi",
      "Kholoud Khairy",
      "Charles D. Kilpatrick",
      "Adam E. Lanman",
      "Mattias Lazda",
      "Calvin Leung",
      "Robert Main",
      "Lluis Mas-Ribas",
      "Kiyoshi W. Masui",
      "Ryan Mckinven",
      "Juan Mena-Parra",
      "Bradley W. Meyers",
      "Daniele Michilli",
      "Nikola Milutinovic",
      "Kenzie Nimmo",
      "Gavin Noble",
      "Ayush Pandhi",
      "Swarali Shivraj Patil",
      "Aaron B. Pearlman",
      "Emily Petroff",
      "Ziggy Pleunis",
      "J. Xavier Prochaska",
      "Masoud Rafiei-Ravandi",
      "Mubdi Rahman",
      "Andre Renard",
      "Mawson W. Sammons",
      "Ketan R. Sand",
      "Paul Scholz",
      "Vishwangi Shah",
      "Kaitlyn Shin",
      "Seth R. Siegel",
      "Sunil Simha",
      "Kendrick Smith",
      "Ingrid Stairs",
      "Keith Vanderlinde",
      "Haochen Wang",
      "Dallas Wulf",
      "Tarik J. Zegmott"
    ],
    "abstract": "We present the first catalog of fast radio burst (FRB) host galaxies from\nCHIME/FRB Outriggers, selected uniformly in the radio and the optical by\nlocalizing 81 new bursts to 2'' x ~60'' accuracy using CHIME and the KKO\nOutrigger, located 66 km from CHIME. Of the 81 localized bursts, we use the\nProbabilistic Association of Transients to their Hosts (PATH) algorithm to\nsecurely identify 21 new FRB host galaxies, and compile spectroscopic redshifts\nfor 19 systems, 15 of which are newly obtained via spectroscopic observations.\nThe most nearby source is FRB 20231229A, at a distance of 90 Mpc. One burst in\nour sample is from a previously reported repeating source in a galaxy merger\n(FRB 20190303A). Three new FRB host galaxies (FRBs 20230203A, 20230703A, and\n20231206A) are found towards X-ray and optically selected galaxy clusters,\npotentially doubling the sample of known galaxy cluster FRBs. A search for\nradio counterparts reveals that FRB 20231128A is associated with a luminous\npersistent radio source (PRS) candidate with high significance ($P_{cc} \\sim\n10^{-2}$). If its compactness is confirmed, it would be the nearest known\ncompact PRS at $z = 0.1079$. Our catalog significantly increases the statistics\nof the Macquart relation at low redshifts ($z < 0.2$). In the near future, the\ncompleted CHIME/FRB Outriggers array will produce hundreds of FRBs localized\nwith very long baseline interferometry (VLBI). This will significantly expand\nthe known sample and pave the way for future telescopes relying on VLBI for FRB\nlocalization.",
    "pdf_url": "http://arxiv.org/pdf/2502.11217v2",
    "published": "2025-02-16T17:39:14+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11218v1",
    "title": "Bayesian Optimization of the GEKO Turbulence Model for Predicting Flow Separation Over a Smooth Surface",
    "authors": [
      "Nikhila Kalia",
      "Ryley McConkey",
      "Eugene Yee",
      "Fue-Sang Lien"
    ],
    "abstract": "This paper applies Bayesian-optimization-RANS (turbo-RANS) to improve\nReynolds-averaged Navier-Stokes (RANS) turbulence models for a\nconverging-diverging channel, a case with adverse pressure gradients and flow\nseparation. Using Bayesian optimization, the Generalized $k$-$\\omega$ (GEKO)\nmodel was calibrated by tuning $C_\\text{SEP}$ and $C_\\text{NW}$ with sparse\ndirect numerical simulation (DNS) data at $Re = 12,600$. The calibration\nfollowed the Generalized Error Distribution-based Calibration Procedure\n(GEDCP), optimizing coefficients based on pressure recovery ($C_p$) and skin\nfriction ($C_f$). The optimized model was evaluated beyond training data.\nStreamwise velocity ($U$) predictions at $Re = 12,600$ were compared to DNS to\nassess improvements in $C_p$ and $C_f$. To test robustness, comparisons were\nmade against large-eddy simulation (LES) data at $Re = 20,580$ for velocity and\nskin friction. Results show that optimized GEKO (turbo-RANS) improves wall\nquantity predictions, particularly reattachment. Improved velocity profiles at\nboth Reynolds numbers suggest Bayesian-optimized coefficients enhance adverse\npressure gradient modeling. The model retains accuracy across different $Re$,\nshowing turbo-RANS' potential in turbulence model corrections that generalize\nacross flows. While skin friction predictions showed limited improvement due to\nconstraints of two-equation models, this study highlights the role of machine\nlearning-assisted RANS calibration in improving predictive accuracy for complex\nflows. The results suggest optimized coefficients from a single dataset can be\napplied across moderate $Re$ variations, improving turbo-RANS' applicability\nfor turbulence model tuning.",
    "pdf_url": "http://arxiv.org/pdf/2502.11218v1",
    "published": "2025-02-16T17:39:14+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11216v4",
    "title": "Exploring nonlinearities in a positive ion-negative ion (PINI) plasma: can other processes mimic debris-induced effects?",
    "authors": [
      "Hitendra Sarkar",
      "Madhurjya P. Bora"
    ],
    "abstract": "In this work, an analysis of nonlinear waves and structures induced by an\nexternal charged debris in a positive ion-negative ion (PINI) plasma is\npresented. The results obtained are compared with findings from available\nexperiments involving PINI plasma. The process of formation of different\nnonlinear structures is examined theoretically through a forced Korteweg-de\nVries (fKdV) equation, which is also verified with a multi-fluid flux-corrected\ntransport simulation code mFCT. Various processes which are responsible for\ndifferent nonlinear waves and structures excited by differently charged\nexternal debris are pointed out. This work also points out the similarities in\ndifferent nonlinear structures {excited} by an external charged debris and the\nunderlying processes (this work) and those {observed experimentally through\nprocesses that do not involve any external debris.",
    "pdf_url": "http://arxiv.org/pdf/2502.11216v4",
    "published": "2025-02-16T17:37:42+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11215v2",
    "title": "A Possible Four-Month Periodicity in the Activity of FRB 20240209A",
    "authors": [
      "Arpan Pal"
    ],
    "abstract": "Fast Radio Bursts (FRBs) are millisecond-duration radio transients from\ndistant galaxies. While most FRBs are singular events, repeaters emit multiple\nbursts, with only two-FRB 121102 and FRB 180916B-showing periodic activity (160\nand 16 days, respectively). FRB 20240209A, discovered by CHIME-FRB, is\nlocalized to the outskirts of a quiescent elliptical galaxy (z = 0.1384). We\ndiscovered a periodicity of ~ 126 days in the activity of the FRB 20240209A,\npotentially adding to the list of extremely rare periodic repeating FRBs. We\nused auto-correlation and Lomb-Scargle periodogram analyses, validated with\nrandomized control samples, to confirm the periodicity. The FRB's location in\nan old stellar population disfavors young progenitor models, instead pointing\nto scenarios involving globular clusters, late-stage magnetars, or low-mass\nX-ray binaries (LMXBs). Though deep X-ray or polarimetric observations are not\navailable, the localization of the FRB and a possible periodicity points to\nprogenitors likely to be a binary involving a compact object and a stellar\ncompanion or a precessing or rotating old neutron star.",
    "pdf_url": "http://arxiv.org/pdf/2502.11215v2",
    "published": "2025-02-16T17:32:23+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11214v1",
    "title": "Rotating Curzon-Chazy metric",
    "authors": [
      "Bobur Turimovand Odil Yunusov",
      "Shavkat Karshiboev",
      "Ahmadjon Abdujabbarov"
    ],
    "abstract": "We demonstrate that the Curzon metric for a positive mass configuration\npossesses a singular event horizon with infinite area. This singularity has\nsignificant implications, revealing that the three-dimensional spatial\nhypersurfaces, which are orthogonal to the Killing vector field, exhibit a\nmultiply connected structure. Furthermore, we investigate the dynamics of a\ntest particle orbiting a central $\\gamma$-object within this spacetime. It is\nfound that under certain conditions, the particle's velocity can approach the\nspeed of light, leading to an exceptionally high total energy at a specific\nvalue of the deformation parameter governing the spacetime structure. Moreover,\nwe uncover a causality issue for a critical value of the deformation parameter,\nwhere the test particle can exceed the speed of light, potentially offering new\ninsights into the theoretical existence of tachyons. This study contributes to\nthe understanding of relativistic objects in deformed spacetimes and suggests\nthat such violations of causality could play a role in explaining the elusive\nnature of tachyonic phenomena in high-energy physics.",
    "pdf_url": "http://arxiv.org/pdf/2502.11214v1",
    "published": "2025-02-16T17:30:55+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11213v1",
    "title": "Stochastic Optimization of Inventory at Large-scale Supply Chains",
    "authors": [
      "Zhaoyang Larry Jin",
      "Mehdi Maasoumy",
      "Yimin Liu",
      "Zeshi Zheng",
      "Zizhuo Ren"
    ],
    "abstract": "Today's global supply chains face growing challenges due to rapidly changing\nmarket conditions, increased network complexity and inter-dependency, and\ndynamic uncertainties in supply, demand, and other factors. To combat these\nchallenges, organizations employ Material Requirements Planning (MRP) software\nsolutions to set inventory stock buffers - for raw materials, work-in-process\ngoods, and finished products - to help them meet customer service levels.\nHowever, holding excess inventory further complicates operations and can lock\nup millions of dollars of capital that could be otherwise deployed.\nFurthermore, most commercially available MRP solutions fall short in\nconsidering uncertainties and do not result in optimal solutions for modern\nenterprises.\n  At C3 AI, we fundamentally reformulate the inventory management problem as a\nconstrained stochastic optimization. We then propose a simulation-optimization\nframework that minimizes inventory and related costs while maintaining desired\nservice levels. The framework's goal is to find the optimal reorder parameters\nthat minimize costs subject to a pre-defined service-level constraint and all\nother real-world operational constraints. These optimal reorder parameters can\nbe fed back into an MRP system to drive optimal order placement, or used to\nplace optimal orders directly. This approach has proven successful in reducing\ninventory levels by 10-35 percent, resulting in hundreds of millions of dollars\nof economic benefit for major enterprises at a global scale.",
    "pdf_url": "http://arxiv.org/pdf/2502.11213v1",
    "published": "2025-02-16T17:25:50+00:00",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11212v1",
    "title": "Non-negative tensor factorization-based dependence map analysis for local damage detection in presence of non-Gaussian noise",
    "authors": [
      "Anna Michalak",
      "Justyna Hebda-Sobkowicz",
      "Anil Kumar",
      "Radoslaw Zimroz",
      "Rafal Zdunek",
      "Agnieszka Wylomanska"
    ],
    "abstract": "The time-frequency map (TFM) is frequently used in condition monitoring,\nnecessitating further processing to select an informative frequency band (IFB)\nor directly detect damage. However, selecting an IFB is challenging due to the\ncomplexity of spectral structures, non-Gaussian disturbances, and overlapping\nfault signatures in vibration signals. Additionally, dynamic operating\nconditions and low signal-to-noise ratio further complicate the identification\nof relevant features that indicate damage. To solve this problem, the present\nwork proposes a novel method for informative band selection and local damage\ndetection in rolling element bearings, utilizing non-negative tensor\nfactorization (NTF)-based dependence map analysis. The recently introduced\nconcept of the dependence map is leveraged, with a set of these maps being\nfactorized to separate informative components from non-informative ones.\nDependence maps provide valuable information on the auto-similarity of spectral\ncontent, while NTF, a powerful tool commonly used in image processing for\nfeature extraction, enhances this process. The combination of these methods\nallows for the extraction of IFBs, forming the basis for local damage\ndetection. The effectiveness of the proposed method has been validated using\nboth synthetic and real vibration signals corrupted with non-Gaussian\ndisturbances.",
    "pdf_url": "http://arxiv.org/pdf/2502.11212v1",
    "published": "2025-02-16T17:25:01+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11211v2",
    "title": "A Survey of LLM-based Agents in Medicine: How far are we from Baymax?",
    "authors": [
      "Wenxuan Wang",
      "Zizhan Ma",
      "Zheng Wang",
      "Chenghan Wu",
      "Jiaming Ji",
      "Wenting Chen",
      "Xiang Li",
      "Yixuan Yuan"
    ],
    "abstract": "Large Language Models (LLMs) are transforming healthcare through the\ndevelopment of LLM-based agents that can understand, reason about, and assist\nwith medical tasks. This survey provides a comprehensive review of LLM-based\nagents in medicine, examining their architectures, applications, and\nchallenges. We analyze the key components of medical agent systems, including\nsystem profiles, clinical planning mechanisms, medical reasoning frameworks,\nand external capacity enhancement. The survey covers major application\nscenarios such as clinical decision support, medical documentation, training\nsimulations, and healthcare service optimization. We discuss evaluation\nframeworks and metrics used to assess these agents' performance in healthcare\nsettings. While LLM-based agents show promise in enhancing healthcare delivery,\nseveral challenges remain, including hallucination management, multimodal\nintegration, implementation barriers, and ethical considerations. The survey\nconcludes by highlighting future research directions, including advances in\nmedical reasoning inspired by recent developments in LLM architectures,\nintegration with physical systems, and improvements in training simulations.\nThis work provides researchers and practitioners with a structured overview of\nthe current state and future prospects of LLM-based agents in medicine.",
    "pdf_url": "http://arxiv.org/pdf/2502.11211v2",
    "published": "2025-02-16T17:21:05+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11210v1",
    "title": "Analysing geodesic motion in Bocharova-Bronnikov-Melnikov-Bekenstein spacetime",
    "authors": [
      "Bobur Turimov",
      "Ozodbek Rahimov",
      "Akbak Davlataliev",
      "Pulat Tadjimuratov",
      "Mukhiddin Norkobilov",
      "Shakhzoda Rahimova"
    ],
    "abstract": "In this paper, we explored novel feature of the\nBocharova-Bronnikov-Melnikov-Bekenstein (BBMB) black hole by analyzing geodesic\nmotion. We first examined its thermodynamics and showed that Hawking\ntemperature equals to zero. We investigated motion of both massive and massless\nparticles around the BBMB black hole and studied the characteristic radii,\nnamely, marginally stable circular orbit (MSCO) and marginally bound orbit\n(MBO) for massive particles orbiting the BBMB black hole. Additionally, we\nfound that the energy efficiency of massive particles in the BBMB spacetime can\nreach up to $8\\%$. We also studied the capture cross section of massless\n(photon) and massive particles by the BBMB black hole. From the equations of\nmotion, we derived the radial function crucial for determining the critical\nvalue of the impact parameter for photons and particles. Comparing these\nfindings with the Schwarzschild spacetime, we observed significant differences\nin gravitational properties. Specifically, the impact parameter for a photon is\nsmaller in the Schwarzschild field than in the BBMB field, indicating weaker\ngravity around the BBMB black hole, as corroborated by the closer location of\nthe photon sphere in the BBMB spacetime. We derived explicit expressions for\nthe pericentric precession and the deflection angle of light by the BBMB black\nhole, along with the trajectory of massive particles orbiting the black hole.\nWe showed that test particles on elliptical trajectories experience pericenter\nshifts, with pericentric precession in the BBMB spacetime being slightly less\nthan that predicted by Einstein's general theory of relativity.",
    "pdf_url": "http://arxiv.org/pdf/2502.11210v1",
    "published": "2025-02-16T17:19:29+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11209v2",
    "title": "Black-hole spectroscopy from a giant quantum vortex",
    "authors": [
      "Pietro Smaniotto",
      "Leonardo Solidoro",
      "Patrik vanara",
      "Sam Patrick",
      "Maurcio Richartz",
      "Carlo F. Barenghi",
      "Ruth Gregory",
      "Silke Weinfurtner"
    ],
    "abstract": "Black-hole spectroscopy aims to infer physical properties of black holes by\ndetecting the spectrum of quasinormal modes (QNMs) they emit while settling\ntowards equilibrium. Unlike normal modes, which are resonances of\nenergy-conserving systems, QNMs are damped oscillations arising when a system\nloses energy due to open boundaries or via dissipation. The detection of the\nfull QNM spectrum of black holes is challenging due to rapidly decaying\namplitudes of these resonances, limiting observations only to the longest-lived\nmode. Theoretical and numerical studies suggest that environmental confinement\ndue to surrounding plasma or dark matter modify the QNM spectrum. Here, we\nemploy black-hole spectroscopy to show how spatial confinement similarly\naffects the spectrum of nanometre-scale interface waves surrounding a giant\nquantum vortex in superfluid helium-4, an experimentally accessible quantum\nsystem that emulates dynamics in rotating curved spacetime. In the available\nparameter space, we observe regimes in which multiple QNMs emerge from the\ninterface noise spectrum. In agreement with theoretical predictions, their real\nand imaginary frequencies are shifted with respect to those expected in the\nunbounded system. Our results demonstrate the critical role of spatial\nconfinement in shaping the QNM spectrum, highlighting the importance of\nenvironmental effects on spectral stability of astrophysical compact objects.",
    "pdf_url": "http://arxiv.org/pdf/2502.11209v2",
    "published": "2025-02-16T17:15:28+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11208v1",
    "title": "Setting the Course, but Forgetting to Steer: Analyzing Compliance with GDPR's Right of Access to Data by Instagram, TikTok, and YouTube",
    "authors": [
      "Sai Keerthana Karnam",
      "Abhisek Dash",
      "Sepehr Mousavi",
      "Stefan Bechtold",
      "Krishna P. Gummadi",
      "Animesh Mukherjee",
      "Ingmar Weber",
      "Savvas Zannettou"
    ],
    "abstract": "The comprehensibility and reliability of data download packages (DDPs)\nprovided under the General Data Protection Regulation's (GDPR) right of access\nare vital for both individuals and researchers. These DDPs enable users to\nunderstand and control their personal data, yet issues like complexity and\nincomplete information often limit their utility. Also, despite their growing\nuse in research to study emerging online phenomena, little attention has been\ngiven to systematically assessing the reliability and comprehensibility of\nDDPs.\n  To bridge this research gap, in this work, we perform a comparative analysis\nto assess the comprehensibility and reliability of DDPs provided by three major\nsocial media platforms, namely, TikTok, Instagram, and YouTube. By recruiting\n400 participants across four countries, we assess the comprehensibility of DDPs\nacross various requirements, including conciseness, transparency,\nintelligibility, and clear and plain language. Also, by leveraging automated\nbots and user-donated DDPs, we evaluate the reliability of DDPs across the\nthree platforms. Among other things, we find notable differences across the\nthree platforms in the data categories included in DDPs, inconsistencies in\nadherence to the GDPR requirements, and gaps in the reliability of the DDPs\nacross platforms. Finally, using large language models, we demonstrate the\nfeasibility of easily providing more comprehensible DDPs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11208v1",
    "published": "2025-02-16T17:15:11+00:00",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11207v1",
    "title": "Interfacial Dzyaloshinskii-Moriya interaction in nonmagnetic/noncollinear-antiferromagnetic bilayers",
    "authors": [
      "Yuta Yamane",
      "Yasufumi Araki",
      "Shunsuke Fukami"
    ],
    "abstract": "We study Dzyaloshinskii-Moriya interaction (DMI) appearing at the interface\nof a nonmagnetic/noncollinear-antiferromagnetic bilayer. DMI is an\nantisymmetric exchange interaction between neighboring magnetic spins, arising\nin the absence of inversion center between the spins and the explicit\nexpression of which being dictated by system symmetry. We formulate the\ninterfacial DMI for different crystalline orientations of the noncollinear\nantiferromagnet with stacked-Kagome lattice structure. From this formulation,\nwe show that, when the Kagome planes are perpendicular to the sample film\nplane, the DMI serves as a uniaxial magnetic anisotropy for the\nantiferromagnetic order parameter. Our findings reveal a novel physical\nmanifestation of a DMI, shedding a new light on microscopic mechanisms of the\nmagnetic anisotropy in noncollinear antiferromagnets.",
    "pdf_url": "http://arxiv.org/pdf/2502.11207v1",
    "published": "2025-02-16T17:13:09+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11206v4",
    "title": "Vortex Dynamics in Tubular Fluid Membranes",
    "authors": [
      "Udaya Maurya",
      "Surya Teja Gavva",
      "Arpan Saha",
      "Rickmoy Samanta"
    ],
    "abstract": "Thin cylindrical membranes arise in a wide variety of biological systems\nranging from tubular structures on and within cell membranes to in-vitro\nexperiments on artificial vesicles. Motor proteins embedded in such fluidic\nmembranes often induce vortex-like flows. In this work, we construct a class of\n2D vortex flow in a thin tubular membrane, coupled to 3D external embedding\nfluids. The cylinder topology enforces the creation of an additional saddle in\nthe flow field, consistent with Poincar\\'e Index Theorem. In this setup, the\nincompressibility of the membrane fluid can be utilized to cast the dynamics of\na multi-vortex system in the form of a Hamiltonian, This Hamiltonian also\nincorporates the specific couplings of the 2D membrane flow with the 3D\nexternal fluids. The cylinder geometry breaks the in-plane rotational symmetry\nof the membrane and leads to several interesting features in the multi-vortex\ndynamics, such as orbit pinching, For a two-vortex system of same circulation,\nwe observe closed orbits with the inter-vortex separation oscillating in time,\nunlike flat and spherical fluid membranes, where the separation remains\nconstant. Vortex pairs (vortices with opposite circulation) move together along\nhelical geodesics in accordance with a conjecture by Kimura, Proceedings of the\nRoyal Society A, Vol 455 (1999), now extended to tubular geometries. We also\nexplore relative equilibria of multi-vortex systems in this setup and\ndemonstrate vortex leapfrogging via numerical simulations. Our results will be\ninteresting in the context of microfluidic flows arising in nature as well as\nexperimental studies in membrane tubes similar to PNAS 108 (31) 12605-12610\n(2011).",
    "pdf_url": "http://arxiv.org/pdf/2502.11206v4",
    "published": "2025-02-16T17:09:58+00:00",
    "categories": [
      "physics.flu-dyn",
      "cond-mat.soft",
      "physics.bio-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2502.11205v1",
    "title": "Deep Contrastive Learning for Feature Alignment: Insights from Housing-Household Relationship Inference",
    "authors": [
      "Xiao Qian",
      "Shangjia Dong",
      "Rachel Davidson"
    ],
    "abstract": "Housing and household characteristics are key determinants of social and\neconomic well-being, yet our understanding of their interrelationships remains\nlimited. This study addresses this knowledge gap by developing a deep\ncontrastive learning (DCL) model to infer housing-household relationships using\nthe American Community Survey (ACS) Public Use Microdata Sample (PUMS). More\nbroadly, the proposed model is suitable for a class of problems where the goal\nis to learn joint relationships between two distinct entities without\nexplicitly labeled ground truth data. Our proposed dual-encoder DCL approach\nleverages co-occurrence patterns in PUMS and introduces a bisect K-means\nclustering method to overcome the absence of ground truth labels. The\ndual-encoder DCL architecture is designed to handle the semantic differences\nbetween housing (building) and household (people) features while mitigating\nnoise introduced by clustering. To validate the model, we generate a synthetic\nground truth dataset and conduct comprehensive evaluations. The model further\ndemonstrates its superior performance in capturing housing-household\nrelationships in Delaware compared to state-of-the-art methods. A\ntransferability test in North Carolina confirms its generalizability across\ndiverse sociodemographic and geographic contexts. Finally, the post-hoc\nexplainable AI analysis using SHAP values reveals that tenure status and\nmortgage information play a more significant role in housing-household matching\nthan traditionally emphasized factors such as the number of persons and rooms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11205v1",
    "published": "2025-02-16T17:06:06+00:00",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11204v2",
    "title": "Charge Orders in Fully Intercalated Bilayer TaSe$_2$: Dependence on Interlayer Stacking and Intercalation Sites",
    "authors": [
      "Yuhui Yan",
      "Lingxiao Xiong",
      "Feipeng Zheng"
    ],
    "abstract": "Recent advancements have established self-intercalation as a powerful\ntechnique for manipulating quantum material properties, with precisely\ncontrollable intercalation concentrations. Given the inherently rich phase\ndiagrams of transition metal dichalcogenides (TMDCs), studying the\nself-intercalated TMDCs can offer promising candidates for investigating the\ninterplay between various orderings. This work focuses on fully intercalated\nbilayer TaSe$_2$ (Ta$_3$Se$_4$), which has recently been fabricated\nexperimentally. By performing first-principles calculations, we demonstrate the\nsuppression of an intrinsic $3\\times3$ charge density wave (CDW) in parent\nTaSe$_2$ layers, and the emergence of $2\\times 2$, $\\sqrt{3} \\times \\sqrt{3}$,\nor the absence of a CDW in the intercalated layers, depending on the interlayer\nstacking orders and intercalation sites being occupied. Particularly, the\n$2\\times 2$ CDW shows an increase in electronic states at the Fermi level\ncompared to its non-CDW phase. This unusual behavior contrasts with that of\ntypical CDW materials in TMDCs. Furthermore, superconductivity is preserved in\nthese Ta$_3$Se$_4$ structures, with superconducting transition temperatures\ncomparable to or substantially smaller than those of TaSe$_2$. Spin-orbit\ncoupling is found to enhance the density of states at Fermi levels while\nsimultaneously reducing the electron-phonon coupling matrix elements. These two\ncompeting effects result in varying impacts on superconductivity across\ndifferent Ta$_3$Se$_4$ structures. Moreover, our calculations indicate that\nmagnetic order is absent. Our study deepens the understanding of underlying\nphysics in Ta$_3$Se$_4$, and provides experimentally feasible candidates for\nstudying CDW, superconductivity, and their interplay.",
    "pdf_url": "http://arxiv.org/pdf/2502.11204v2",
    "published": "2025-02-16T17:05:21+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11203v2",
    "title": "Multiscale autonomous forecasting of plasma systems' dynamics using neural networks",
    "authors": [
      "Farbod Faraji",
      "Maryam Reza"
    ],
    "abstract": "Plasma systems exhibit complex multiscale dynamics, resolving which poses\nsignificant challenges for conventional numerical simulations. Machine learning\n(ML) offers an alternative by learning data-driven representations of these\ndynamics. Yet existing ML time-stepping models suffer from error accumulation,\ninstability, and limited long-term forecasting horizons. This paper\ndemonstrates the application of a hierarchical multiscale neural network\narchitecture for autonomous plasma forecasting. The framework integrates\nmultiple neural networks trained across different temporal scales to capture\nboth fine-scale and large-scale behaviors while mitigating compounding error in\nrecursive evaluation. Fine-scale networks accurately resolve fast-evolving\nfeatures, while coarse-scale networks provide broader temporal context,\nreducing the frequency of recursive updates and limiting the accumulation of\nsmall prediction errors over time. We first evaluate the method using canonical\nnonlinear dynamical systems and compare its performance against classical\nsingle-scale neural networks. The results demonstrate that single-scale neural\nnetworks experience rapid divergence due to recursive error accumulation,\nwhereas the multiscale approach improves stability and extends prediction\nhorizons. Next, our ML model is applied to two plasma configurations of high\nscientific and applied significance, demonstrating its ability to preserve\nspatial structures and capture multiscale plasma dynamics. By leveraging\nmultiple time-stepping resolutions, the applied framework is shown to\noutperform conventional single-scale networks for the studied plasma test\ncases. The results of this work position the hierarchical multiscale neural\nnetwork as a promising tool for efficient plasma forecasting and digital twin\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11203v2",
    "published": "2025-02-16T17:02:54+00:00",
    "categories": [
      "physics.plasm-ph",
      "cs.LG"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11202v1",
    "title": "Stochastic baryon charge transport in relativistic hydrodynamics",
    "authors": [
      "Nicolas Borghini",
      "Baochi Fu",
      "Sren Schlichting"
    ],
    "abstract": "We utilize 3+1D stochastic hydrodynamics to study correlations and\nfluctuations of baryon charge in high-energy heavy-ion collisions. The baryon\ncharge fluctuations are important observables to probe the QCD phase diagram,\nyet a dynamical description with stochastic hydrodynamics remains challenging\ndue to numerical instabilities and high computational demands. In this work, we\nemploy a linearized approach, allowing us to separately simulate the background\nenergy-momentum evolution of a charge-neutral fluid and the stochastic baryon\ntransport processes, thereby largely reducing computational cost while\nmaintaining sufficient accuracy. We implement this linearized stochastic charge\nevolution in the viscous hydrodynamic code MUSIC, and find that it nicely\ndescribes the two-point correlation of 1+1D analytical solutions for various\nequations of state and transport coefficients. In particular, the hydrodynamic\ncalculations demonstrate how different rapidity separations probe charge\nfluctuations originating at different times of the evolution. We also\ninvestigate the net baryon correlations after the Cooper--Frye freeze out,\nwhich show good consistency with the analytical calculations and indicate that\nthese fluctuation-induced correlations are sensitive to the baryon diffusion\ncoefficient.",
    "pdf_url": "http://arxiv.org/pdf/2502.11202v1",
    "published": "2025-02-16T17:02:00+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.11201v2",
    "title": "Bridging the Gap: Enabling Natural Language Queries for NoSQL Databases through Text-to-NoSQL Translation",
    "authors": [
      "Jinwei Lu",
      "Yuanfeng Song",
      "Zhiqian Qin",
      "Haodi Zhang",
      "Chen Zhang",
      "Raymond Chi-Wing Wong"
    ],
    "abstract": "NoSQL databases have become increasingly popular due to their outstanding\nperformance in handling large-scale, unstructured, and semi-structured data,\nhighlighting the need for user-friendly interfaces to bridge the gap between\nnon-technical users and complex database queries. In this paper, we introduce\nthe Text-to-NoSQL task, which aims to convert natural language queries into\nNoSQL queries, thereby lowering the technical barrier for non-expert users. To\npromote research in this area, we developed a novel automated dataset\nconstruction process and released a large-scale and open-source dataset for\nthis task, named TEND (short for Text-to-NoSQL Dataset). Additionally, we\ndesigned a SLM (Small Language Model)-assisted and RAG (Retrieval-augmented\nGeneration)-assisted multi-step framework called SMART, which is specifically\ndesigned for Text-to-NoSQL conversion. To ensure comprehensive evaluation of\nthe models, we also introduced a detailed set of metrics that assess the\nmodel's performance from both the query itself and its execution results. Our\nexperimental results demonstrate the effectiveness of our approach and\nestablish a benchmark for future research in this emerging field. We believe\nthat our contributions will pave the way for more accessible and intuitive\ninteractions with NoSQL databases.",
    "pdf_url": "http://arxiv.org/pdf/2502.11201v2",
    "published": "2025-02-16T17:01:48+00:00",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2502.11200v1",
    "title": "Towards Precision Oncology: Predicting Mortality and Relapse-Free Survival in Head and Neck Cancer Using Clinical Data",
    "authors": [
      "Naman Dhariwal",
      "Abeyankar Giridharan"
    ],
    "abstract": "Head and neck squamous cell carcinoma (HNSCC) presents significant challenges\nin clinical oncology due to its heterogeneity and high mortality rates. This\nstudy aims to leverage clinical data and machine learning (ML) principles to\npredict key outcomes for HNSCC patients: mortality, and relapse-free survival.\nUtilizing data sourced from the Cancer Imaging Archive, an extensive pipeline\nwas implemented to ensure robust model training and evaluation. Ensemble and\nindividual classifiers, including XGBoost, Random Forest, and Support Vectors,\nwere employed to develop predictive models. The study identified key clinical\nfeatures influencing HNSCC mortality outcomes and achieved predictive accuracy\nand ROC-AUC values exceeding 90\\% across tasks. Support Vector Machine strongly\nexcelled in relapse-free survival, with an recall value of 0.99 and precision\nof 0.97. Key clinical features including loco-regional control, smoking and\ntreatment type, were identified as critical predictors of patient outcomes.\nThis study underscores the medical impact of using ML-driven insights to refine\nprognostic accuracy and optimize personalized treatment strategies in HNSCC.",
    "pdf_url": "http://arxiv.org/pdf/2502.11200v1",
    "published": "2025-02-16T17:00:25+00:00",
    "categories": [
      "q-bio.QM"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2502.11199v2",
    "title": "Artifact Validity in Design Science Research (DSR): A Comparative Analysis of Three Influential Frameworks",
    "authors": [
      "Sylvana Kroop"
    ],
    "abstract": "Although the methodology of Design Science Research (DSR) is playing an\nincreasingly important role with the emergence of the \"sciences of the\nartificial\", the validity of the resulting artifacts is occasionally\nquestioned. This paper compares three influential DSR frameworks to assess\ntheir support for artifact validity. Using five essential validity types\n(instrument validity, technical validity, design validity, purpose validity and\ngeneralization), the qualitative analysis reveals that while purpose validity\nis explicitly emphasized, instrument and design validity remain the least\ndeveloped. Their implicit treatment in all frameworks poses a risk of\noverlooked validation, and the absence of mandatory instrument validity can\nlead to invalid artifacts, threatening research credibility. Beyond these\nfindings, the paper contributes (a) a comparative overview of each framework's\nstrengths and weaknesses and (b) a revised DSR framework incorporating all five\nvalidity types with definitions and examples. This ensures systematic artifact\nevaluation and improvement, reinforcing the rigor of DSR.",
    "pdf_url": "http://arxiv.org/pdf/2502.11199v2",
    "published": "2025-02-16T16:59:22+00:00",
    "categories": [
      "cs.OH",
      "K.3.2; K.6.3"
    ],
    "primary_category": "cs.OH"
  },
  {
    "id": "http://arxiv.org/abs/2502.11198v3",
    "title": "ANCHOLIK-NER: A Benchmark Dataset for Bangla Regional Named Entity Recognition",
    "authors": [
      "Bidyarthi Paul",
      "Faika Fairuj Preotee",
      "Shuvashis Sarker",
      "Shamim Rahim Refat",
      "Shifat Islam",
      "Tashreef Muhammad",
      "Mohammad Ashraful Hoque",
      "Shahriar Manzoor"
    ],
    "abstract": "Named Entity Recognition (NER) in regional dialects is a critical yet\nunderexplored area in Natural Language Processing (NLP), especially for\nlow-resource languages like Bangla. While NER systems for Standard Bangla have\nmade progress, no existing resources or models specifically address the\nchallenge of regional dialects such as Barishal, Chittagong, Mymensingh,\nNoakhali, and Sylhet, which exhibit unique linguistic features that existing\nmodels fail to handle effectively. To fill this gap, we introduce ANCHOLIK-NER,\nthe first benchmark dataset for NER in Bangla regional dialects, comprising\n17,405 sentences distributed across five regions. The dataset was sourced from\npublicly available resources and supplemented with manual translations,\nensuring alignment of named entities across dialects. We evaluate three\ntransformer-based models - Bangla BERT, Bangla BERT Base, and BERT Base\nMultilingual Cased - on this dataset. Our findings demonstrate that BERT Base\nMultilingual Cased performs best in recognizing named entities across regions,\nwith significant performance observed in Mymensingh with an F1-score of\n82.611%. Despite strong overall performance, challenges remain in region like\nChittagong, where the models show lower precision and recall. Since no previous\nNER systems for Bangla regional dialects exist, our work represents a\nfoundational step in addressing this gap. Future work will focus on improving\nmodel performance in underperforming regions and expanding the dataset to\ninclude more dialects, enhancing the development of dialect-aware NER systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11198v3",
    "published": "2025-02-16T16:59:10+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11197v1",
    "title": "CSP: A Simulator For Multi-Agent Ranking Competitions",
    "authors": [
      "Tommy Mordo",
      "Tomer Kordonsky",
      "Haya Nachimovsky",
      "Moshe Tennenholtz",
      "Oren Kurland"
    ],
    "abstract": "In ranking competitions, document authors compete for the highest rankings by\nmodifying their content in response to past rankings. Previous studies focused\non human participants, primarily students, in controlled settings. The rise of\ngenerative AI, particularly Large Language Models (LLMs), introduces a new\nparadigm: using LLMs as document authors. This approach addresses scalability\nconstraints in human-based competitions and reflects the growing role of\nLLM-generated content on the web-a prime example of ranking competition. We\nintroduce a highly configurable ranking competition simulator that leverages\nLLMs as document authors. It includes analytical tools to examine the resulting\ndatasets. We demonstrate its capabilities by generating multiple datasets and\nconducting an extensive analysis. Our code and datasets are publicly available\nfor research.",
    "pdf_url": "http://arxiv.org/pdf/2502.11197v1",
    "published": "2025-02-16T16:56:15+00:00",
    "categories": [
      "cs.IR",
      "cs.GT"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11196v2",
    "title": "How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training",
    "authors": [
      "Yixin Ou",
      "Yunzhi Yao",
      "Ningyu Zhang",
      "Hui Jin",
      "Jiacheng Sun",
      "Shumin Deng",
      "Zhenguo Li",
      "Huajun Chen"
    ],
    "abstract": "Despite exceptional capabilities in knowledge-intensive tasks, Large Language\nModels (LLMs) face a critical gap in understanding how they internalize new\nknowledge, particularly how to structurally embed acquired knowledge in their\nneural computations. We address this issue through the lens of knowledge\ncircuit evolution, identifying computational subgraphs that facilitate\nknowledge storage and processing. Our systematic analysis of circuit evolution\nthroughout continual pre-training reveals several key findings: (1) the\nacquisition of new knowledge is influenced by its relevance to pre-existing\nknowledge; (2) the evolution of knowledge circuits exhibits a distinct phase\nshift from formation to optimization; (3) the evolution of knowledge circuits\nfollows a deep-to-shallow pattern. These insights not only advance our\ntheoretical understanding of the mechanisms of new knowledge acquisition in\nLLMs, but also provide potential implications for improving continual\npre-training strategies to enhance model performance. Code and data will be\navailable at https://github.com/zjunlp/DynamicKnowledgeCircuits.",
    "pdf_url": "http://arxiv.org/pdf/2502.11196v2",
    "published": "2025-02-16T16:55:43+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11195v1",
    "title": "From Deception to Perception: The Surprising Benefits of Deepfakes for Detecting, Measuring, and Mitigating Bias",
    "authors": [
      "Yizhi Liu",
      "Balaji Padmanabhan",
      "Siva Viswanathan"
    ],
    "abstract": "While deepfake technologies have predominantly been criticized for potential\nmisuse, our study demonstrates their significant potential as tools for\ndetecting, measuring, and mitigating biases in key societal domains. By\nemploying deepfake technology to generate controlled facial images, we extend\nthe scope of traditional correspondence studies beyond mere textual\nmanipulations. This enhancement is crucial in scenarios such as pain\nassessments, where subjective biases triggered by sensitive features in facial\nimages can profoundly affect outcomes. Our results reveal that deepfakes not\nonly maintain the effectiveness of correspondence studies but also introduce\ngroundbreaking advancements in bias measurement and correction techniques. This\nstudy emphasizes the constructive role of deepfake technologies as essential\ntools for advancing societal equity and fairness.",
    "pdf_url": "http://arxiv.org/pdf/2502.11195v1",
    "published": "2025-02-16T16:55:28+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.0; I.2.10; I.4.0; J.4; H.4; K.4.1; K.4.2"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11194v1",
    "title": "Sparse Identification for bifurcating phenomena in Computational Fluid Dynamics",
    "authors": [
      "Lorenzo Tomada",
      "Moaad Khamlich",
      "Federico Pichi",
      "Gianluigi Rozza"
    ],
    "abstract": "This work investigates model reduction techniques for nonlinear parameterized\nand time-dependent PDEs, specifically focusing on bifurcating phenomena in\nComputational Fluid Dynamics (CFD). We develop interpretable and non-intrusive\nReduced Order Models (ROMs) capable of capturing dynamics associated with\nbifurcations by identifying a minimal set of coordinates. Our methodology\ncombines the Sparse Identification of Nonlinear Dynamics (SINDy) method with a\ndeep learning framework based on Autoencoder (AE) architectures. To enhance\ndimensionality reduction, we integrate a nested Proper Orthogonal Decomposition\n(POD) with the SINDy-AE architecture. This novel combination enables a sparse\ndiscovery of system dynamics while maintaining efficiency of the reduced model.\nWe demonstrate our approach via two challenging test cases defined on\nsudden-expansion channel geometries: a symmetry-breaking bifurcation and a Hopf\nbifurcation. Starting from a comprehensive analysis of their high-fidelity\nbehavior, i.e. symmetry-breaking phenomena and the rise of unsteady periodic\nsolutions, we validate the accuracy and computational efficiency of our ROMs.\nThe results show successful reconstruction of the bifurcations, accurate\nprediction of system evolution for unseen parameter values, and significant\nspeed-up compared to full-order methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.11194v1",
    "published": "2025-02-16T16:39:47+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.flu-dyn",
      "76-08, 76D05, 37G15, 35B32, 37M20, 65P30, 37N10, 76M10, 76M12, 68T07",
      "G.1.7; G.1.8; J.2; I.2.6; G.1.10"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11193v1",
    "title": "Large Language Models Penetration in Scholarly Writing and Peer Review",
    "authors": [
      "Li Zhou",
      "Ruijie Zhang",
      "Xunlian Dai",
      "Daniel Hershcovich",
      "Haizhou Li"
    ],
    "abstract": "While the widespread use of Large Language Models (LLMs) brings convenience,\nit also raises concerns about the credibility of academic research and\nscholarly processes. To better understand these dynamics, we evaluate the\npenetration of LLMs across academic workflows from multiple perspectives and\ndimensions, providing compelling evidence of their growing influence. We\npropose a framework with two components: \\texttt{ScholarLens}, a curated\ndataset of human- and LLM-generated content across scholarly writing and peer\nreview for multi-perspective evaluation, and \\texttt{LLMetrica}, a tool for\nassessing LLM penetration using rule-based metrics and model-based detectors\nfor multi-dimensional evaluation. Our experiments demonstrate the effectiveness\nof \\texttt{LLMetrica}, revealing the increasing role of LLMs in scholarly\nprocesses. These findings emphasize the need for transparency, accountability,\nand ethical practices in LLM usage to maintain academic credibility.",
    "pdf_url": "http://arxiv.org/pdf/2502.11193v1",
    "published": "2025-02-16T16:37:34+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11192v1",
    "title": "Robust correlation measures for informative frequency band selection in heavy-tailed vibration signal",
    "authors": [
      "Justyna Hebda-Sobkowicz",
      "Radosaw Zimroz",
      "Anil Kumar",
      "Agnieszka Wyomanska"
    ],
    "abstract": "Vibration signals are commonly used to detect local damage in rotating\nmachinery. However, raw signals are often noisy, particularly in crusher\nmachines, where the technological process (falling pieces of rock) generates\nrandom impulses that complicate detection. To address this, signal\npre-filtering (extracting the informative frequency band from noise-affected\nsignals) is necessary. This paper proposes an algorithm for processing\nvibration signals from a bearing used in an ore crusher. Selecting informative\nfrequency bands (IFBs) in the presence of impulsive noise is notably\nchallenging. The approach employs correlation maps to detect cyclic behavior\nwithin specific frequency bands in the time-frequency domain (spectrogram),\nenabling the identification of IFBs. Robust correlation measures and median\nfiltering are applied to enhance the correlation maps and improve the final IFB\nselection. Signal segmentation and the use of averaged results for IFB\nselection are also highlighted. The proposed trimmed and quadrant correlations\nare compablack with the Pearson and Kendall correlations using simulated\nsignal, real vibration signal from crusher in mining industry and acoustic\nsignal measublack on the test rig. Furthermore, the results of real vibration\nanalyses are compablack with established IFB selectors, including the spectral\nkurtosis, the alpha selector and the conditional variance-based selector.",
    "pdf_url": "http://arxiv.org/pdf/2502.11192v1",
    "published": "2025-02-16T16:36:06+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11191v2",
    "title": "Primus: A Pioneering Collection of Open-Source Datasets for Cybersecurity LLM Training",
    "authors": [
      "Yao-Ching Yu",
      "Tsun-Han Chiang",
      "Cheng-Wei Tsai",
      "Chien-Ming Huang",
      "Wen-Kwang Tsao"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable advancements in\nspecialized fields such as finance, law, and medicine. However, in\ncybersecurity, we have noticed a lack of open-source datasets, with a\nparticular lack of high-quality cybersecurity pretraining corpora, even though\nmuch research indicates that LLMs acquire their knowledge during pretraining.\nTo address this, we present a comprehensive suite of datasets covering all\nmajor training stages, including pretraining, instruction fine-tuning, and\nreasoning distillation with cybersecurity-specific self-reflection data.\nExtensive ablation studies demonstrate their effectiveness on public\ncybersecurity benchmarks. In particular, continual pre-training on our dataset\nyields a 15.88% improvement in the aggregate score, while reasoning\ndistillation leads to a 10% gain in security certification (CISSP). We will\nrelease all datasets and trained cybersecurity LLMs under the ODC-BY and MIT\nlicenses to encourage further research in the community. For access to all\ndatasets and model weights, please refer to\nhttps://huggingface.co/collections/trendmicro-ailab/primus-67b1fd27052b802b4af9d243.",
    "pdf_url": "http://arxiv.org/pdf/2502.11191v2",
    "published": "2025-02-16T16:34:49+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11190v3",
    "title": "ReLearn: Unlearning via Learning for Large Language Models",
    "authors": [
      "Haoming Xu",
      "Ningyuan Zhao",
      "Liming Yang",
      "Sendong Zhao",
      "Shumin Deng",
      "Mengru Wang",
      "Bryan Hooi",
      "Nay Oo",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "Current unlearning methods for large language models usually rely on reverse\noptimization to reduce target token probabilities. However, this paradigm\ndisrupts the subsequent tokens prediction, degrading model performance and\nlinguistic coherence. Moreover, existing evaluation metrics overemphasize\ncontextual forgetting while inadequately assessing response fluency and\nrelevance. To address these challenges, we propose ReLearn, a data augmentation\nand fine-tuning pipeline for effective unlearning, along with a comprehensive\nevaluation framework. This framework introduces Knowledge Forgetting Rate (KFR)\nand Knowledge Retention Rate (KRR) to measure knowledge-level preservation, and\nLinguistic Score (LS) to evaluate generation quality. Our experiments show that\nReLearn successfully achieves targeted forgetting while preserving high-quality\noutput. Through mechanistic analysis, we further demonstrate how reverse\noptimization disrupts coherent text generation, while ReLearn preserves this\nessential capability. Code is available at https://github.com/zjunlp/unlearn.",
    "pdf_url": "http://arxiv.org/pdf/2502.11190v3",
    "published": "2025-02-16T16:31:00+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11189v1",
    "title": "Szekeres Universes with GUP corrections",
    "authors": [
      "Andronikos Paliathanasis"
    ],
    "abstract": "We demonstrate that introducing a deformed algebra with a minimum length\nmodifies the field equations for an inhomogeneous spacetime, resulting in the\nemergence of acceleration. Specifically, we examine the analytic effects of the\nGeneralized Uncertainty Principle on the classical field equations of the\nSzekeres system. Our findings show that the deformed algebra leads to a\nmodified Szekeres system capable of describing cosmic acceleration. Moreover,\nthe spatial curvature of the spacetime is influenced by the presence of the\nminimum length.",
    "pdf_url": "http://arxiv.org/pdf/2502.11189v1",
    "published": "2025-02-16T16:29:34+00:00",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.12206v1",
    "title": "Evaluating the Paperclip Maximizer: Are RL-Based Language Models More Likely to Pursue Instrumental Goals?",
    "authors": [
      "Yufei He",
      "Yuexin Li",
      "Jiaying Wu",
      "Yuan Sui",
      "Yulin Chen",
      "Bryan Hooi"
    ],
    "abstract": "As large language models (LLMs) continue to evolve, ensuring their alignment\nwith human goals and values remains a pressing challenge. A key concern is\n\\textit{instrumental convergence}, where an AI system, in optimizing for a\ngiven objective, develops unintended intermediate goals that override the\nultimate objective and deviate from human-intended goals. This issue is\nparticularly relevant in reinforcement learning (RL)-trained models, which can\ngenerate creative but unintended strategies to maximize rewards. In this paper,\nwe explore instrumental convergence in LLMs by comparing models trained with\ndirect RL optimization (e.g., the o1 model) to those trained with reinforcement\nlearning from human feedback (RLHF). We hypothesize that RL-driven models\nexhibit a stronger tendency for instrumental convergence due to their\noptimization of goal-directed behavior in ways that may misalign with human\nintentions. To assess this, we introduce InstrumentalEval, a benchmark for\nevaluating instrumental convergence in RL-trained LLMs. Initial experiments\nreveal cases where a model tasked with making money unexpectedly pursues\ninstrumental objectives, such as self-replication, implying signs of\ninstrumental convergence. Our findings contribute to a deeper understanding of\nalignment challenges in AI systems and the risks posed by unintended model\nbehaviors.",
    "pdf_url": "http://arxiv.org/pdf/2502.12206v1",
    "published": "2025-02-16T16:29:20+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11188v1",
    "title": "Exploring information geometry: Recent Advances and Connections to Topological Field Theory",
    "authors": [
      "Nomie C. Combe",
      "Philippe G. Combe",
      "Hanna K. Nencka"
    ],
    "abstract": "This introductory text arises from a lecture given in G\\\"oteborg, Sweden,\ngiven by the first author and is intended for undergraduate students, as well\nas for any mathematically inclined reader wishing to explore a synthesis of\nideas connecting geometry and statistics. At its core, this work seeks to\nillustrate the profound and yet natural interplay between differential\ngeometry, probability theory, and the rich algebraic structures encoded in\n(pre-)Frobenius manifolds.\n  The exposition is structured into three principal parts. The first part\nprovides a concise introduction to differential topology and geometry,\nemphasizing the role of smooth manifolds, connections, and curvature in the\nformulation of geometric structures. The second part is devoted to probability,\nmeasures, and statistics, where the notion of a probability space is refined\ninto a geometric object, thus paving the way for a deeper mathematical\nunderstanding of statistical models. Finally, in the third part, we introduce\n(pre-)Frobenius manifolds, revealing their surprising connection to exponential\nfamilies of probability distributions and, discuss more broadly, their role in\nthe geometry of information. At the end of those three parts the reader will\nfind stimulating exercises.\n  By bringing together these seemingly distant disciplines, we aim to highlight\nthe natural emergence of geometric structures in statistical theory. This work\ndoes not seek to be exhaustive but rather to provide the reader with a pathway\ninto a domain of mathematics that is still in its formative stages, where many\nfundamental questions remain open. The text is accessible without requiring\nadvanced prerequisites and should serve as an invitation to further\nexploration.",
    "pdf_url": "http://arxiv.org/pdf/2502.11188v1",
    "published": "2025-02-16T16:26:16+00:00",
    "categories": [
      "math.DG",
      "cs.IT",
      "math.AG",
      "math.IT"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11187v3",
    "title": "TituLLMs: A Family of Bangla LLMs with Comprehensive Benchmarking",
    "authors": [
      "Shahriar Kabir Nahin",
      "Rabindra Nath Nandi",
      "Sagor Sarker",
      "Quazi Sarwar Muhtaseem",
      "Md Kowsher",
      "Apu Chandraw Shill",
      "Md Ibrahim",
      "Mehadi Hasan Menon",
      "Tareq Al Muntasir",
      "Firoj Alam"
    ],
    "abstract": "In this paper, we present TituLLMs, the first large pretrained Bangla LLMs,\navailable in 1b and 3b parameter sizes. Due to computational constraints during\nboth training and inference, we focused on smaller models. To train TituLLMs,\nwe collected a pretraining dataset of approximately ~37 billion tokens. We\nextended the Llama-3.2 tokenizer to incorporate language- and culture-specific\nknowledge, which also enables faster training and inference. There was a lack\nof benchmarking datasets to benchmark LLMs for Bangla. To address this gap, we\ndeveloped five benchmarking datasets. We benchmarked various LLMs, including\nTituLLMs, and demonstrated that TituLLMs outperforms its initial multilingual\nversions. However, this is not always the case, highlighting the complexities\nof language adaptation. Our work lays the groundwork for adapting existing\nmultilingual open models to other low-resource languages. To facilitate broader\nadoption and further research, we have made the TituLLMs models and\nbenchmarking datasets publicly available\n(https://huggingface.co/collections/hishab/titulm-llama-family-6718d31fc1b83529276f490a).",
    "pdf_url": "http://arxiv.org/pdf/2502.11187v3",
    "published": "2025-02-16T16:22:23+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2504.05310v1",
    "title": "GRIT: Graph-based Recall Improvement for Task-oriented E-commerce Queries",
    "authors": [
      "Hrishikesh Kulkarni",
      "Surya Kallumadi",
      "Sean MacAvaney",
      "Nazli Goharian",
      "Ophir Frieder"
    ],
    "abstract": "Many e-commerce search pipelines have four stages, namely: retrieval,\nfiltering, ranking, and personalized-reranking. The retrieval stage must be\nefficient and yield high recall because relevant products missed in the first\nstage cannot be considered in later stages. This is challenging for\ntask-oriented queries (queries with actionable intent) where user requirements\nare contextually intensive and difficult to understand. To foster research in\nthe domain of e-commerce, we created a novel benchmark for Task-oriented\nQueries (TQE) by using LLM, which operates over the existing ESCI product\nsearch dataset. Furthermore, we propose a novel method 'Graph-based Recall\nImprovement for Task-oriented queries' (GRIT) to address the most crucial\nfirst-stage recall improvement needs. GRIT leads to robust and statistically\nsignificant improvements over state-of-the-art lexical, dense, and\nlearned-sparse baselines. Our system supports both traditional and\ntask-oriented e-commerce queries, yielding up to 6.3% recall improvement. In\nthe indexing stage, GRIT first builds a product-product similarity graph using\nuser clicks or manual annotation data. During retrieval, it locates neighbors\nwith higher contextual and action relevance and prioritizes them over the less\nrelevant candidates from the initial retrieval. This leads to a more\ncomprehensive and relevant first-stage result set that improves overall system\nrecall. Overall, GRIT leverages the locality relationships and contextual\ninsights provided by the graph using neighboring nodes to enrich the\nfirst-stage retrieval results. We show that the method is not only robust\nacross all introduced parameters, but also works effectively on top of a\nvariety of first-stage retrieval methods.",
    "pdf_url": "http://arxiv.org/pdf/2504.05310v1",
    "published": "2025-02-16T16:21:49+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11186v2",
    "title": "Development of Fast Front-End Electronics for the Muon Trigger Detector in the PSI muEDM Experiment",
    "authors": [
      "Tianqi Hu",
      "Guan Ming Wong",
      "Diego Alejandro Sanz Becerra",
      "Chavdar Dutsov",
      "Siew Yan Hoh",
      "Kim Siang Khaw",
      "Philipp Schmidt-Wellenburg",
      "Yuzhi Shang",
      "Yusuke Takeuchi"
    ],
    "abstract": "This paper outlines the design and development of a fast front-end electronic\nreadout board for the muon trigger detector in the muEDM experiment at the Paul\nScherrer Institute. The trigger detector, which consists of a gate and aperture\ndetector, is strategically located at the end of the superconducting injection\nchannel to generate trigger signals for a magnetic kicker, which activates upon\nthe injection of muons into the central region of the storage solenoid. Within\nthe magnetic field of the solenoid, the system configuration is optimized to\nmeet stringent performance specifications, including minimal signal propagation\ndelays, high detection efficiency, non-magnetic properties, and consistent\noperational stability under varying experimental conditions. Additionally, the\ndesign incorporates robust methods for rejecting positron contamination in the\nmuon beamline. The results presented include performance evaluations from both\nbench testing and actual beam tests, highlighting the effectiveness and\nreliability of the electronic design.",
    "pdf_url": "http://arxiv.org/pdf/2502.11186v2",
    "published": "2025-02-16T16:20:57+00:00",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2502.11185v1",
    "title": "Particles acceleration by Bocharova-Bronnikov-Melnikov-Bekenstein black hole",
    "authors": [
      "Bobur Turimov",
      "Sulton Usanov",
      "Yokubjon Khamroev"
    ],
    "abstract": "We have studied the motion of massive particles under the influence of scalar\nand gravitational fields, with particular emphasis on the BBMB black hole. It\nhas been shown that the radius of the innermost stable circular orbit (ISCO)\nand marginally bound orbit are significantly affected by the scalar coupling\nparameter. We study the energy efficiency of thin accretion disks around BBMB\nblack holes, showing that the efficiency decreases for positive $g_s$ and\nincreases for negative $g_s$, with a maximum of approximately $30\\%$ for\nspecific $g_s$ values. We derive analytical expressions for the angular and\nlinear velocities of orbiting particles, highlighting their dependence on\n$g_s$. The photon sphere is shown to be independent of $g_s$, but the linear\nvelocity at the ISCO position varies significantly, with massive particles\nbehaving like ultra-relativistic particles near the black hole under scalar\nfield influence. Additionally, we examine the center-of-mass energy (CME) of\ncolliding particles near the BBMB black hole, showing that the scalar field can\nlead to infinitely high CME near the horizon, consistent with the BSW process.\nAstrophysical implications include CME values reaching \\(10^{20} \\, {\\rm eV}\\),\ncomparable to the energies of ultra-high-energy cosmic rays (UHECR).",
    "pdf_url": "http://arxiv.org/pdf/2502.11185v1",
    "published": "2025-02-16T16:14:50+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2502.11184v2",
    "title": "Can't See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs",
    "authors": [
      "Wenxuan Wang",
      "Xiaoyuan Liu",
      "Kuiyi Gao",
      "Jen-tse Huang",
      "Youliang Yuan",
      "Pinjia He",
      "Shuai Wang",
      "Zhaopeng Tu"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have expanded the capabilities of\ntraditional language models by enabling interaction through both text and\nimages. However, ensuring the safety of these models remains a significant\nchallenge, particularly in accurately identifying whether multimodal content is\nsafe or unsafe-a capability we term safety awareness. In this paper, we\nintroduce MMSafeAware, the first comprehensive multimodal safety awareness\nbenchmark designed to evaluate MLLMs across 29 safety scenarios with 1500\ncarefully curated image-prompt pairs. MMSafeAware includes both unsafe and\nover-safety subsets to assess models abilities to correctly identify unsafe\ncontent and avoid over-sensitivity that can hinder helpfulness. Evaluating nine\nwidely used MLLMs using MMSafeAware reveals that current models are not\nsufficiently safe and often overly sensitive; for example, GPT-4V misclassifies\n36.1% of unsafe inputs as safe and 59.9% of benign inputs as unsafe. We further\nexplore three methods to improve safety awareness-prompting-based approaches,\nvisual contrastive decoding, and vision-centric reasoning fine-tuning-but find\nthat none achieve satisfactory performance. Our findings highlight the profound\nchallenges in developing MLLMs with robust safety awareness, underscoring the\nneed for further research in this area. All the code and data will be publicly\navailable to facilitate future research.",
    "pdf_url": "http://arxiv.org/pdf/2502.11184v2",
    "published": "2025-02-16T16:12:40+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11183v2",
    "title": "Don't Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming Tree Search Exploration Pitfalls",
    "authors": [
      "Ante Wang",
      "Linfeng Song",
      "Ye Tian",
      "Dian Yu",
      "Haitao Mi",
      "Xiangyu Duan",
      "Zhaopeng Tu",
      "Jinsong Su",
      "Dong Yu"
    ],
    "abstract": "Recent advancements in tree search algorithms guided by verifiers have\nsignificantly enhanced the reasoning capabilities of large language models\n(LLMs), but at the cost of increased computational resources. In this work, we\nidentify two key challenges contributing to this inefficiency:\n$\\textit{over-exploration}$ due to redundant states with semantically\nequivalent content, and $\\textit{under-exploration}$ caused by high variance in\nverifier scoring leading to frequent trajectory switching. To address these\nissues, we propose FETCH, an e$\\textbf{f}$fici$\\textbf{e}$nt $\\textbf{t}$ree\nsear$\\textbf{ch}$ framework, which is a flexible, plug-and-play system\ncompatible with various tree search algorithms. Our framework mitigates\nover-exploration by merging semantically similar states using agglomerative\nclustering of text embeddings obtained from a fine-tuned SimCSE model. To\ntackle under-exploration, we enhance verifiers by incorporating temporal\ndifference learning with adjusted $\\lambda$-returns during training to reduce\nvariance, and employing a verifier ensemble to aggregate scores during\ninference. Experiments on GSM8K, GSM-Plus, and MATH datasets demonstrate that\nour methods significantly improve reasoning accuracy and computational\nefficiency across four different tree search algorithms, paving the way for\nmore practical applications of LLM-based reasoning. The code is available at\nhttps://github.com/Soistesimmer/Fetch.",
    "pdf_url": "http://arxiv.org/pdf/2502.11183v2",
    "published": "2025-02-16T16:12:01+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11182v1",
    "title": "Stacked Intelligent Metasurface-Based Transceiver Design for Near-Field Wideband Systems",
    "authors": [
      "Qingchao Li",
      "Mohammed El-Hajjar",
      "Chao Xu",
      "Jiancheng An",
      "Chau Yuen",
      "Lajos Hanzo"
    ],
    "abstract": "Intelligent metasurfaces may be harnessed for realizing efficient holographic\nmultiple-input and multiple-output (MIMO) systems, at a low hardware-cost and\nhigh energy-efficiency. As part of this family, we propose a hybrid beamforming\ndesign for stacked intelligent metasurfaces (SIM) aided wideband wireless\nsystems relying on the near-field channel model. Specifically, the holographic\nbeamformer is designed based on configuring the phase shifts in each layer of\nthe SIM for maximizing the sum of the baseband eigen-channel gains of all\nusers. To optimize the SIM phase shifts, we propose a layer-by-layer iterative\nalgorithm for optimizing the phase shifts in each layer alternately. Then, the\nminimum mean square error (MMSE) transmit precoding method is employed for the\ndigital beamformer to support multi-user access. Furthermore, the mitigation of\nthe SIM phase tuning error is also taken into account in the digital beamformer\nby exploiting its statistics. The power sharing ratio of each user is designed\nbased on the iterative waterfilling power allocation algorithm. Additionally,\nour analytical results indicate that the spectral efficiency attained saturates\nin the high signal-to-noise ratio (SNR) region due to the phase tuning error\nresulting from the imperfect SIM hardware quality. The simulation results show\nthat the SIM-aided holographic MIMO outperforms the state-of-the-art (SoA)\nsingle-layer holographic MIMO in terms of its achievable rate. We further\ndemonstrate that the near-field channel model allows the SIM-based transceiver\ndesign to support multiple users, since the spatial resources represented both\nby the angle domain and the distance domain can be exploited.",
    "pdf_url": "http://arxiv.org/pdf/2502.11182v1",
    "published": "2025-02-16T16:07:32+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11181v1",
    "title": "Improving Scientific Document Retrieval with Concept Coverage-based Query Set Generation",
    "authors": [
      "SeongKu Kang",
      "Bowen Jin",
      "Wonbin Kweon",
      "Yu Zhang",
      "Dongha Lee",
      "Jiawei Han",
      "Hwanjo Yu"
    ],
    "abstract": "In specialized fields like the scientific domain, constructing large-scale\nhuman-annotated datasets poses a significant challenge due to the need for\ndomain expertise. Recent methods have employed large language models to\ngenerate synthetic queries, which serve as proxies for actual user queries.\nHowever, they lack control over the content generated, often resulting in\nincomplete coverage of academic concepts in documents. We introduce Concept\nCoverage-based Query set Generation (CCQGen) framework, designed to generate a\nset of queries with comprehensive coverage of the document's concepts. A key\ndistinction of CCQGen is that it adaptively adjusts the generation process\nbased on the previously generated queries. We identify concepts not\nsufficiently covered by previous queries, and leverage them as conditions for\nsubsequent query generation. This approach guides each new query to complement\nthe previous ones, aiding in a thorough understanding of the document.\nExtensive experiments demonstrate that CCQGen significantly enhances query\nquality and retrieval performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.11181v1",
    "published": "2025-02-16T15:59:50+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11180v1",
    "title": "New perspectives on MASCARA-1b: A combined analysis of pre- and post-eclipse emission data using CRIRES+",
    "authors": [
      "Swaetha Ramkumar",
      "Neale P. Gibson",
      "Stevanus K. Nugroho",
      "Mark Fortune",
      "Cathal Maguire"
    ],
    "abstract": "We present high-resolution emission spectroscopy observations of the\nultra-hot Jupiter MASCARA-1b with CRIRES+ in the K-band, covering the\npost-eclipse phases of its orbit. These observations complement previously\npublished pre-eclipse data. The stellar and telluric features were removed\nusing SysRem, and the planetary signal was analysed with the cross-correlation\ntechnique. After confirming the presence of chemical species in our atmospheric\nmodel, we combined the pre- and post-eclipse datasets for a joint analysis. By\nemploying a Bayesian retrieval framework, this joint retrieval enabled us to\nconstrain the spatially varying temperature-pressure (T-P) profile and\natmospheric carbon-to-oxygen (C/O) ratio. We detected strong emission\nsignatures of CO and H$_2$O in the post-eclipse and combined datasets. While a\nwell-mixed retrieval model results in a super-solar C/O, allowing for\nvertically varying chemistry yields C/O values consistent with solar. The\nretrieved parameters are not only consistent across the datasets but also\nacross different chemical regimes. We did not identify any significant velocity\nshifts between the detected species or across the datasets, which could\notherwise serve as proxies for possible atmospheric dynamics. We also explored\nphase dependence through the model scaling factor and found no substantial\nchanges in atmospheric properties throughout the observed phases. Due to strong\ndegeneracies between the temperature gradient and chemical abundances, our\nretrieved temperatures are broadly consistent with either a full redistribution\nof heat or strong day-night contrasts. While this complicates direct\ncomparisons with recent Spitzer phase curve analyses suggesting inefficient\nrecirculation, we find no clear evidence of spatial variation in the chemical\nor temperature structure of MASCARA-1b from pre- to post-eclipse, nor temporal\nvariation over $\\approx$2 years.",
    "pdf_url": "http://arxiv.org/pdf/2502.11180v1",
    "published": "2025-02-16T15:59:21+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11179v1",
    "title": "RT-DEMT: A hybrid real-time acupoint detection model combining mamba and transformer",
    "authors": [
      "Shilong Yang",
      "Qi Zang",
      "Chulong Zhang",
      "Lingfeng Huang",
      "Yaoqin Xie"
    ],
    "abstract": "Traditional Chinese acupuncture methods often face controversy in clinical\npractice due to their high subjectivity. Additionally, current\nintelligent-assisted acupuncture systems have two major limitations: slow\nacupoint localization speed and low accuracy. To address these limitations, a\nnew method leverages the excellent inference efficiency of the state-space\nmodel Mamba, while retaining the advantages of the attention mechanism in the\ntraditional DETR architecture, to achieve efficient global information\nintegration and provide high-quality feature information for acupoint\nlocalization tasks. Furthermore, by employing the concept of residual\nlikelihood estimation, it eliminates the need for complex upsampling processes,\nthereby accelerating the acupoint localization task. Our method achieved\nstate-of-the-art (SOTA) accuracy on a private dataset of acupoints on the human\nback, with an average Euclidean distance pixel error (EPE) of 7.792 and an\naverage time consumption of 10.05 milliseconds per localization task. Compared\nto the second-best algorithm, our method improved both accuracy and speed by\napproximately 14\\%. This significant advancement not only enhances the efficacy\nof acupuncture treatment but also demonstrates the commercial potential of\nautomated acupuncture robot systems. Access to our method is available at\nhttps://github.com/Sohyu1/RT-DEMT",
    "pdf_url": "http://arxiv.org/pdf/2502.11179v1",
    "published": "2025-02-16T15:59:06+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11178v2",
    "title": "DA-Mamba: Domain Adaptive Hybrid Mamba-Transformer Based One-Stage Object Detection",
    "authors": [
      "A. Enes Doruk",
      "Hasan F. Ates"
    ],
    "abstract": "Recent 2D CNN-based domain adaptation approaches struggle with long-range\ndependencies due to limited receptive fields, making it difficult to adapt to\ntarget domains with significant spatial distribution changes. While\ntransformer-based domain adaptation methods better capture distant\nrelationships through self-attention mechanisms that facilitate more effective\ncross-domain feature alignment, their quadratic computational complexity makes\npractical deployment challenging for object detection tasks across diverse\ndomains. Inspired by the global modeling and linear computation complexity of\nthe Mamba architecture, we present the first domain-adaptive Mamba-based\none-stage object detection model, termed DA-Mamba. Specifically, we combine\nMamba's efficient state-space modeling with attention mechanisms to address\ndomain-specific spatial and channel-wise variations. Our design leverages\ndomain-adaptive spatial and channel-wise scanning within the Mamba block to\nextract highly transferable representations for efficient sequential\nprocessing, while cross-attention modules generate long-range, mixed-domain\nspatial features to enable robust soft alignment across domains. Besides,\nmotivated by the observation that hybrid architectures introduce feature noise\nin domain adaptation tasks, we propose an entropy-based knowledge distillation\nframework with margin ReLU, which adaptively refines multi-level\nrepresentations by suppressing irrelevant activations and aligning uncertainty\nacross source and target domains. Finally, to prevent overfitting caused by the\nmixed-up features generated through cross-attention mechanisms, we propose\nentropy-driven gating attention with random perturbations that simultaneously\nrefine target features and enhance model generalization.",
    "pdf_url": "http://arxiv.org/pdf/2502.11178v2",
    "published": "2025-02-16T15:58:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11177v5",
    "title": "The Mirage of Model Editing: Revisiting Evaluation in the Wild",
    "authors": [
      "Wanli Yang",
      "Fei Sun",
      "Jiajun Tan",
      "Xinyu Ma",
      "Qi Cao",
      "Dawei Yin",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "Despite near-perfect results reported in the literature, the effectiveness of\nmodel editing in real-world applications remains unclear. To bridge this gap,\nwe introduce QAEdit, a new benchmark aligned with widely used question\nanswering (QA) datasets, and WILD, a task-agnostic evaluation framework\ndesigned to better reflect real-world usage of model editing. Our single\nediting experiments show that current editing methods perform substantially\nworse than previously reported (38.5% vs. 96.8%). We demonstrate that it stems\nfrom issues in the synthetic evaluation practices of prior work. Among them,\nthe most severe is the use of teacher forcing during testing, which leaks both\ncontent and length of the ground truth, leading to overestimated performance.\nFurthermore, we simulate practical deployment by sequential editing, revealing\nthat current approaches fail drastically with only 1000 edits. This work calls\nfor a shift in model editing research toward rigorous evaluation and the\ndevelopment of robust, scalable methods that can reliably update knowledge in\nLLMs for real-world use.",
    "pdf_url": "http://arxiv.org/pdf/2502.11177v5",
    "published": "2025-02-16T15:57:55+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11176v3",
    "title": "LogiDynamics: Unraveling the Dynamics of Logical Inference in Large Language Model Reasoning",
    "authors": [
      "Tianshi Zheng",
      "Jiayang Cheng",
      "Chunyang Li",
      "Haochen Shi",
      "Zihao Wang",
      "Jiaxin Bai",
      "Yangqiu Song",
      "Ginny Y. Wong",
      "Simon See"
    ],
    "abstract": "Modern large language models (LLMs) employ various forms of logical\ninference, both implicitly and explicitly, when addressing reasoning tasks.\nUnderstanding how to optimally leverage these inference paradigms is critical\nfor advancing LLMs' reasoning capabilities. This paper adopts an exploratory\napproach by introducing a controlled evaluation environment for analogical\nreasoning -- a fundamental cognitive task -- that is systematically\nparameterized across three dimensions: modality (textual, visual, symbolic),\ndifficulty (easy, medium, hard), and task format (multiple-choice or free-text\ngeneration). We analyze the comparative dynamics of inductive, abductive, and\ndeductive inference pipelines across these dimensions, and demonstrate that our\nfindings generalize to broader in-context learning tasks. Additionally, we\ninvestigate advanced paradigms such as hypothesis selection, verification, and\nrefinement, revealing their potential to scale up logical inference in LLM\nreasoning. This exploratory study provides a foundation for future research in\nenhancing LLM reasoning through systematic logical inference strategies.\nResources are available at https://github.com/HKUST-KnowComp/LogiDynamics.",
    "pdf_url": "http://arxiv.org/pdf/2502.11176v3",
    "published": "2025-02-16T15:54:53+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11175v4",
    "title": "Investigating Language Preference of Multilingual RAG Systems",
    "authors": [
      "Jeonghyun Park",
      "Hwanhee Lee"
    ],
    "abstract": "Multilingual Retrieval-Augmented Generation (mRAG) systems enhance language\nmodels by integrating external multilingual information to produce\ncontext-aware responses. However, mRAG systems struggle with retrieving\nrelevant information due to linguistic variations between queries and\ndocuments, generating inconsistent responses when multilingual sources\nconflict. In this work, we systematically investigate language preferences in\nboth retrieval and generation of mRAG through a series of experiments. Our\nanalysis indicates that retrievers tend to prefer high-resource and query\nlanguages, yet this preference does not consistently improve generation\nperformance. Moreover, we observe that generators prefer the query language or\nLatin scripts, leading to inconsistent outputs. To overcome these issues, we\npropose Dual Knowledge Multilingual RAG (DKM-RAG), a simple yet effective\nframework that fuses translated multilingual passages with complementary model\nknowledge. Empirical results demonstrate that DKM-RAG mitigates language\npreference in generation and enhances performance across diverse linguistic\nsettings. Code is available at\nhttps://github.com/jeonghyunpark2002/LanguagePreference.git",
    "pdf_url": "http://arxiv.org/pdf/2502.11175v4",
    "published": "2025-02-16T15:54:05+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11174v1",
    "title": "Measurement-Based Entanglement Distillation and Constant-Rate Quantum Repeaters over Arbitrary Distances",
    "authors": [
      "Yu Shi",
      "Ashlesha Patil",
      "Saikat Guha"
    ],
    "abstract": "Measurement-based quantum repeaters employ entanglement distillation and\nswapping across links using locally prepared resource states of minimal size\nand local Bell measurements. In this paper, we introduce a systematic protocol\nfor measurement-based entanglement distillation and its application to\nrepeaters that can leverage any stabilizer code. Given a code, we explicitly\ndefine the corresponding resource state and derive an error-recovery operation\nbased on all Bell measurement outcomes. Our approach offers deeper insights\ninto the impact of resource state noise on repeater performance while also\nproviding strategies for efficient preparation and fault-tolerant preservation\nof resource states. As an application, we propose a measurement-based repeater\nprotocol based on quantum low-density parity-check (QLDPC) codes, enabling\nconstant-yield Bell state distribution over arbitrary distances. Numerical\nsimulations confirm exponential suppression of infidelity with increasing code\nsize while maintaining a fixed code rate. This work establishes a scalable\nbackbone for future global-scale fault-tolerant quantum networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11174v1",
    "published": "2025-02-16T15:53:09+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11173v1",
    "title": "Evaluating the Potential of Quantum Machine Learning in Cybersecurity: A Case-Study on PCA-based Intrusion Detection Systems",
    "authors": [
      "Armando Bellante",
      "Tommaso Fioravanti",
      "Michele Carminati",
      "Stefano Zanero",
      "Alessandro Luongo"
    ],
    "abstract": "Quantum computing promises to revolutionize our understanding of the limits\nof computation, and its implications in cryptography have long been evident.\nToday, cryptographers are actively devising post-quantum solutions to counter\nthe threats posed by quantum-enabled adversaries. Meanwhile, quantum scientists\nare innovating quantum protocols to empower defenders. However, the broader\nimpact of quantum computing and quantum machine learning (QML) on other\ncybersecurity domains still needs to be explored. In this work, we investigate\nthe potential impact of QML on cybersecurity applications of traditional ML.\nFirst, we explore the potential advantages of quantum computing in machine\nlearning problems specifically related to cybersecurity. Then, we describe a\nmethodology to quantify the future impact of fault-tolerant QML algorithms on\nreal-world problems. As a case study, we apply our approach to standard methods\nand datasets in network intrusion detection, one of the most studied\napplications of machine learning in cybersecurity. Our results provide insight\ninto the conditions for obtaining a quantum advantage and the need for future\nquantum hardware and software advancements.",
    "pdf_url": "http://arxiv.org/pdf/2502.11173v1",
    "published": "2025-02-16T15:49:25+00:00",
    "categories": [
      "quant-ph",
      "cs.CR",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11172v4",
    "title": "Prospect for measurement of $C\\!P$-violating observables in $B_s^0 \\to D_s^{\\mp} K^{\\pm}$ decays at a future ${Z}$ factory",
    "authors": [
      "Ji Peng",
      "Mingrui Zhao",
      "Xiaolin Wang",
      "Manqi Ruan",
      "Hengne Li",
      "Shanzhen Chen"
    ],
    "abstract": "A precise determination of the CKM angle $\\gamma$ from $B_s^0$ oscillations\nin $B_s^0 \\to D_s^\\mp K^\\pm$ decays offers a critical test of the Standard\nModel and probes for new physics. We present a comprehensive study on the\nprospects of measuring $\\gamma$ at a future Tera-$Z$ factory, utilizing the\nbaseline detector concept of the Circular Electron Positron Collider (CEPC). A\ntwo-dimensional simultaneous fit framework, incorporating flavor tagging, decay\ntime resolution modeling, and acceptance corrections, is developed using full\nMonte Carlo simulations of $B_s^0 \\to D_s^\\mp \\left(\\to K^\\mp K^\\pm\n\\pi^\\mp\\right) K^\\pm$ decays and inclusive background processes. The effective\nflavor tagging power reaches $23.6\\%$, while the decay time resolution is\ndetermined to be $26\\mathrm{\\,fs}$. Projecting to full statistics of signal\nevents across three dominant $D_s^-$ decay channels, we estimate a statistical\nprecision of $\\sigma(\\gamma) = 0.69^\\circ$, which corresponds to $4.1$ Tera-$Z$\nboson equivalent data. This study establishes the feasibility of sub-degree\nlevel $\\gamma$ measurements at a $Z$-factory, highlighting its unique\nadvantages in time-dependent $C\\!P$ violation studies through ultra-precise\nvertexing and background suppression capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2502.11172v4",
    "published": "2025-02-16T15:48:09+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2502.11171v2",
    "title": "Design and Fabrication of Low Cost Cardiopulmonary Resuscitaion Device | A Novel Mechatronics System",
    "authors": [
      "Nabeel Ahmad Khan Jadoon"
    ],
    "abstract": "Cardiac arrest is very common nowadays. Sudden heart attack is a condition\nwhere the heart suddenly stops beating causing a significant decrease in blood\nflow to the brain. The first step in medical point of view is for a patient\nexperiencing sudden heart attack is Cardiopulmonary Resuscitation\n(CPR).Moreover, compression rate needed for CPR process is far beyond for\nhumans to provide manually. So, there is intense need of mechanical device\nwhich can perform resuscitation. Cardiopulmonary resuscitation device is used\nto augment the blood flow and maintain hemodynamic cycle of human body. CPR\ndevice is proposed to meet the effective and unique blood flow mechanism,\nfeedback system. In term of effective and unique blood flow mechanism design\nand fabrication of low cost cardiopulmonary resuscitation device based on\nprinciple of CPR and two concepts. It is combined Sterno-Thoracic\nCardiopulmonary Resuscitation. The \"cardiac pump\" generates blood flow by\nsqueezing blood out of the heart as the sternum is depressed. The \"thoracic\npump\" increases intrathoracic pressure due to elastic recoil of ribs. In order\nto meet the American Heart Association standard guidelines a feedback system\nhas established through closed loop control system, and integration of\nprocessing controllers. Specifically, a small HMI (Human machine interface)\ndevice has been established to control the whole mechanism which would be used\nfor child, Adults and Senior citizens as a manual intelligence system.\nHenceforth, feedback system act as backbone for this device.",
    "pdf_url": "http://arxiv.org/pdf/2502.11171v2",
    "published": "2025-02-16T15:45:11+00:00",
    "categories": [
      "physics.med-ph"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11170v3",
    "title": "A signless Laplacian spectral Erds-Stone-Simonovits theorem",
    "authors": [
      "Jian Zheng",
      "Honghai Li",
      "Li Su"
    ],
    "abstract": "The celebrated Erd\\H{o}s--Stone--Simonovits theorem states that\n$\\mathrm{ex}(n,F)= \\big(1-\\frac{1}{\\chi(F)-1}+o(1) \\big)\\frac{n^{2}}{2}$, where\n$\\chi(F)$ is the chromatic number of $F$. In 2009, Nikiforov proved a spectral\nextension of the Erd\\H{o}s--Stone--Simonovits theorem in terms of the adjacency\nspectral radius. In this paper, we shall establish a unified extension in terms\nof the signless Laplacian spectral radius. Let $q(G)$ be the signless Laplacian\nspectral radius of $G$ and we denote $\\mathrm{ex}_{q}(n,F) =\\max \\{q(G):|G|=n\n~\\mbox{and}~F\\nsubseteq G\\}$. It is known that the Erd\\H{o}s--Stone--Simonovits\ntype result for the signless Laplacian spectral radius does not hold for even\ncycles. We prove that if $F$ is a graph with $\\chi(F)\\geq 3$, then\n$\\mathrm{ex}_{q}(n,F)=\\big(1-\\frac{1}{\\chi(F)-1}+o(1) \\big)2n$. This solves a\nproblem proposed by Li, Liu and Feng (2022), which gives an entirely\nsatisfactory answer to the problem of estimating $\\mathrm{ex}_q(n,F)$.\nFurthermore, it extends the aforementioned result of Erd\\H{o}s, Stone and\nSimonovits as well as the spectral result of Nikiforov. Our result indicates\nthat the Erd\\H{o}s--Stone--Simonovits type result regarding the signless\nLaplacian spectral radius is valid in general.",
    "pdf_url": "http://arxiv.org/pdf/2502.11170v3",
    "published": "2025-02-16T15:40:47+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11169v2",
    "title": "CMCTS: A Constrained Monte Carlo Tree Search Framework for Mathematical Reasoning in Large Language Model",
    "authors": [
      "Qingwen Lin",
      "Boyan Xu",
      "Guimin Hu",
      "Zijian Li",
      "Zhifeng Hao",
      "Keli Zhang",
      "Ruichu Cai"
    ],
    "abstract": "This paper introduces the Constrained Monte Carlo Tree Search (CMCTS)\nframework to enhance the mathematical reasoning capabilities of Large Language\nModels (LLM). By incorporating a constrained action space, Process Reward Model\n(PRM), and partial order rules, CMCTS effectively addresses the limitations of\nexisting MCTS methods in terms of state space diversity and action selection\nrationality. Specifically, during the expansion phase, CMCTS restricts action\nsampling to a predefined constrained action set to increase candidate state\ndiversity. In the simulation phase, it introduces partial order rules and PRM\nto optimize action selection and prevent unreasonable state transitions.\nExperimental results show that CMCTS performs outstandingly across multiple\nmathematical reasoning benchmarks. Under a zero-shot setting, a 7B-parameter\nmodel achieves an average accuracy of 83.4\\%, surpassing the 72B baseline model\nby 4.8\\%. Ablation studies demonstrate that each component of the framework is\ncrucial for performance improvement, and their combined use fully leverages\ntheir respective strengths. Overall, the CMCTS framework provides an effective\napproach to enhancing LLM mathematical reasoning capabilities, supported by\ntheoretical analysis, and offers novel insights for future reasoning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11169v2",
    "published": "2025-02-16T15:39:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11168v1",
    "title": "Knowing Your Target: Target-Aware Transformer Makes Better Spatio-Temporal Video Grounding",
    "authors": [
      "Xin Gu",
      "Yaojie Shen",
      "Chenxi Luo",
      "Tiejian Luo",
      "Yan Huang",
      "Yuewei Lin",
      "Heng Fan",
      "Libo Zhang"
    ],
    "abstract": "Transformer has attracted increasing interest in STVG, owing to its\nend-to-end pipeline and promising result. Existing Transformer-based STVG\napproaches often leverage a set of object queries, which are initialized simply\nusing zeros and then gradually learn target position information via iterative\ninteractions with multimodal features, for spatial and temporal localization.\nDespite simplicity, these zero object queries, due to lacking target-specific\ncues, are hard to learn discriminative target information from interactions\nwith multimodal features in complicated scenarios (\\e.g., with distractors or\nocclusion), resulting in degradation. Addressing this, we introduce a novel\nTarget-Aware Transformer for STVG (TA-STVG), which seeks to adaptively generate\nobject queries via exploring target-specific cues from the given video-text\npair, for improving STVG. The key lies in two simple yet effective modules,\ncomprising text-guided temporal sampling (TTS) and attribute-aware spatial\nactivation (ASA), working in a cascade. The former focuses on selecting\ntarget-relevant temporal cues from a video utilizing holistic text information,\nwhile the latter aims at further exploiting the fine-grained visual attribute\ninformation of the object from previous target-aware temporal cues, which is\napplied for object query initialization. Compared to existing methods\nleveraging zero-initialized queries, object queries in our TA-STVG, directly\ngenerated from a given video-text pair, naturally carry target-specific cues,\nmaking them adaptive and better interact with multimodal features for learning\nmore discriminative information to improve STVG. In our experiments on three\nbenchmarks, TA-STVG achieves state-of-the-art performance and significantly\noutperforms the baseline, validating its efficacy.",
    "pdf_url": "http://arxiv.org/pdf/2502.11168v1",
    "published": "2025-02-16T15:38:33+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11167v3",
    "title": "SURGE: On the Potential of Large Language Models as General-Purpose Surrogate Code Executors",
    "authors": [
      "Bohan Lyu",
      "Siqiao Huang",
      "Zichen Liang",
      "Qi-An Sun",
      "Jiaming Zhang"
    ],
    "abstract": "Neural surrogate models have emerged as powerful and efficient tools in data\nmining. Meanwhile, large language models (LLMs) have demonstrated remarkable\ncapabilities in code-related tasks. We investigate a novel application: using\nLLMs as surrogate models for code execution prediction. Given LLMs' unique\nability to understand and process diverse programs, they present a promising\ndirection for building general-purpose surrogate models. To systematically\ninvestigate this capability, we introduce SURGE, a comprehensive benchmark with\n$1160$ problems covering $8$ key aspects: multi-language programming tasks,\ncompetition-level programming problems, repository-level code analysis,\nhigh-cost scientific computing, time-complexity-intensive algorithms, buggy\ncode analysis, programs dependent on specific compilers or execution\nenvironments, and formal mathematical proof verification. Through extensive\nempirical analysis of $21$ open-source and proprietary LLMs, we examine scaling\nlaws, data efficiency, and predictive accuracy. Our findings reveal important\ninsights about the feasibility of LLMs as efficient surrogates for\ncomputational processes, with implications for automated software testing,\nprogram analysis, and computational resource optimization in data mining\napplications. Code and dataset are released at\nhttps://github.com/Imbernoulli/SURGE.",
    "pdf_url": "http://arxiv.org/pdf/2502.11167v3",
    "published": "2025-02-16T15:38:19+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11166v1",
    "title": "Sharply k-transitive actions on ultrahomogeneous structures",
    "authors": [
      "J. de la Nuez Gonzlez",
      "Rob Sullivan"
    ],
    "abstract": "Given an action of a group $G$ by automorphisms on an infinite relational\nstructure $\\mathcal{M}$, we say that the action is structurally sharply\n$k$-transitive if, for any two $k$-tuples $\\bar{a}, \\bar{b} \\in M^k$ of\ndistinct elements such that $\\bar{a} \\mapsto \\bar{b}$ is an isomorphism, there\nexists exactly one element of $G$ sending $\\bar{a}$ to $\\bar{b}$. This\ngeneralises the well-known notion of a sharply $k$-transitive action on a set.\nWe show that, for $k \\leq 3$, a wide range of countable ultrahomogeneous\nstructures admit structurally sharply $k$-transitive actions by finitely\ngenerated virtually free groups, giving a substantial answer to a question of\nCameron from the book Oligomorphic Permutation Groups. We also show that the\nrandom $k$-hypertournament admits a structurally sharply $k$-transitive action\nfor $k=4,5$, and that $\\mathbb{Q}$ and several of its reducts admit\nstructurally sharply $k$-transitive actions for all $k$. (This contrasts with\nthe case of sets, where for $k \\geq 4$ there are no sharply $k$-transitive\nactions on infinite sets by results of Tits and Hall.) We also show the\nexistence of sharply $2$-transitive actions of finitely generated virtually\nfree groups on an infinite set, solving the open question of whether such\nactions exist for hyperbolic groups.\n  [Note: this is an early working draft.]",
    "pdf_url": "http://arxiv.org/pdf/2502.11166v1",
    "published": "2025-02-16T15:37:28+00:00",
    "categories": [
      "math.GR",
      "math.LO",
      "20B22, 05E18, 03C15, 20B27"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11165v1",
    "title": "How did Fermat discover his theorem?",
    "authors": [
      "David Pengelley"
    ],
    "abstract": "In 1640 Pierre de Fermat discovered his theorem that if $p$ is prime and $a$\nis not divisible by $p$, then $a^{p-1}-1$ is divisible by $p$; or, as we write\ntoday, $a^{p-1}\\equiv1\\pmod{p}$. This is perhaps the first and the most\nimportant surprising property ever discovered about primes. There is little in\nnumber theory that is not dependent on it or intertwined with it, and its\nsignificance is amply demonstrated by the fact that today, almost four\ncenturies later, Fermat's theorem provides the mathematical foundation for the\nRSA cryptosystem, which is still central to society's communications security\neven after several decades serving as its heart.\n  Fermat's theorem is totally unexpected and truly astonishing. So why and how\ndid he discover it? We know that Fermat was studying perfect numbers from\nclassical Greek mathematics. But exactly how did that lead to his discovery?\nThe secret lies in patterns in prime factorizations of Mersenne numbers, and\nFermat's letters reveal hints of his path. We can reconstruct details of how\nMersenne numbers led to Fermat's discoveries.",
    "pdf_url": "http://arxiv.org/pdf/2502.11165v1",
    "published": "2025-02-16T15:30:56+00:00",
    "categories": [
      "math.HO",
      "math.NT",
      "01A45 (Primary) 11-03, 11A15 (Secondary)"
    ],
    "primary_category": "math.HO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11164v5",
    "title": "Quantifying the Capability Boundary of DeepSeek Models: An Application-Driven Performance Analysis",
    "authors": [
      "Kaikai Zhao",
      "Zhaoxiang Liu",
      "Xuejiao Lei",
      "Jiaojiao Zhao",
      "Zhenhong Long",
      "Zipeng Wang",
      "Ning Wang",
      "Meijuan An",
      "Qingliang Meng",
      "Peijun Yang",
      "Minjie Hua",
      "Chaoyang Ma",
      "Wen Liu",
      "Kai Wang",
      "Shiguo Lian"
    ],
    "abstract": "DeepSeek-R1, known for its low training cost and exceptional reasoning\ncapabilities, has achieved state-of-the-art performance on various benchmarks.\nHowever, detailed evaluations for DeepSeek Series models from the perspective\nof real-world applications are lacking, making it challenging for users to\nselect the most suitable DeepSeek models for their specific needs. To address\nthis gap, we presents the first comprehensive evaluation of the DeepSeek and\nits related models (including DeepSeek-V3, DeepSeek-R1,\nDeepSeek-R1-Distill-Qwen series, DeepSeek-R1-Distill-Llama series, their\ncorresponding 4-bit quantized models, and the reasoning model QwQ-32B) using\nour enhanced A-Eval benchmark, A-Eval-2.0. Our systematic analysis reveals\nseveral key insights: (1) Given identical model architectures and training\ndata, larger parameter models demonstrate superior performance, aligning with\nthe scaling law. However, smaller models may achieve enhanced capabilities when\nemploying optimized training strategies and higher-quality data; (2)\nReasoning-enhanced model show significant performance gains in logical\nreasoning tasks but may underperform in text understanding and generation\ntasks; (3) As the data difficulty increases, distillation or reasoning\nenhancements yield higher performance gains for the models. Interestingly,\nreasoning enhancements can even have a negative impact on simpler problems; (4)\nQuantization impacts different capabilities unevenly, with significant drop on\nlogical reasoning and minimal impact on text generation. Based on these results\nand findings, we design an model selection handbook enabling users to select\nthe most cost-effective models without efforts.",
    "pdf_url": "http://arxiv.org/pdf/2502.11164v5",
    "published": "2025-02-16T15:29:58+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11163v3",
    "title": "AI Sees Your Location, But With A Bias Toward The Wealthy World",
    "authors": [
      "Jingyuan Huang",
      "Jen-tse Huang",
      "Ziyi Liu",
      "Xiaoyuan Liu",
      "Wenxuan Wang",
      "Jieyu Zhao"
    ],
    "abstract": "Visual-Language Models (VLMs) have shown remarkable performance across\nvarious tasks, particularly in recognizing geographic information from images.\nHowever, VLMs still show regional biases in this task. To systematically\nevaluate these issues, we introduce a benchmark consisting of 1,200 images\npaired with detailed geographic metadata. Evaluating four VLMs, we find that\nwhile these models demonstrate the ability to recognize geographic information\nfrom images, achieving up to 53.8% accuracy in city prediction, they exhibit\nsignificant biases. Specifically, performance is substantially higher for\neconomically developed and densely populated regions compared to less developed\n(-12.5%) and sparsely populated (-17.0%) areas. Moreover, regional biases of\nfrequently over-predicting certain locations remain. For instance, they\nconsistently predict Sydney for images taken in Australia, shown by the low\nentropy scores for these countries. The strong performance of VLMs also raises\nprivacy concerns, particularly for users who share images online without the\nintent of being identified. Our code and dataset are publicly available at\nhttps://github.com/uscnlp-lime/FairLocator.",
    "pdf_url": "http://arxiv.org/pdf/2502.11163v3",
    "published": "2025-02-16T15:28:34+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11162v1",
    "title": "Logarithmic Width Suffices for Robust Memorization",
    "authors": [
      "Amitsour Egosi",
      "Gilad Yehudai",
      "Ohad Shamir"
    ],
    "abstract": "The memorization capacity of neural networks with a given architecture has\nbeen thoroughly studied in many works. Specifically, it is well-known that\nmemorizing $N$ samples can be done using a network of constant width,\nindependent of $N$. However, the required constructions are often quite\ndelicate. In this paper, we consider the natural question of how well\nfeedforward ReLU neural networks can memorize robustly, namely while being able\nto withstand adversarial perturbations of a given radius. We establish both\nupper and lower bounds on the possible radius for general $l_p$ norms, implying\n(among other things) that width logarithmic in the number of input samples is\nnecessary and sufficient to achieve robust memorization (with robustness radius\nindependent of $N$).",
    "pdf_url": "http://arxiv.org/pdf/2502.11162v1",
    "published": "2025-02-16T15:28:21+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11161v3",
    "title": "BFA: Best-Feature-Aware Fusion for Multi-View Fine-grained Manipulation",
    "authors": [
      "Zihan Lan",
      "Weixin Mao",
      "Haosheng Li",
      "Le Wang",
      "Tiancai Wang",
      "Haoqiang Fan",
      "Osamu Yoshie"
    ],
    "abstract": "In real-world scenarios, multi-view cameras are typically employed for\nfine-grained manipulation tasks. Existing approaches (e.g., ACT) tend to treat\nmulti-view features equally and directly concatenate them for policy learning.\nHowever, it will introduce redundant visual information and bring higher\ncomputational costs, leading to ineffective manipulation. For a fine-grained\nmanipulation task, it tends to involve multiple stages while the most\ncontributed view for different stages is varied over time. In this paper, we\npropose a plug-and-play best-feature-aware (BFA) fusion strategy for multi-view\nmanipulation tasks, which is adaptable to various policies. Built upon the\nvisual backbone of the policy network, we design a lightweight network to\npredict the importance score of each view. Based on the predicted importance\nscores, the reweighted multi-view features are subsequently fused and input\ninto the end-to-end policy network, enabling seamless integration. Notably, our\nmethod demonstrates outstanding performance in fine-grained manipulations.\nExperimental results show that our approach outperforms multiple baselines by\n22-46% success rate on different tasks. Our work provides new insights and\ninspiration for tackling key challenges in fine-grained manipulations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11161v3",
    "published": "2025-02-16T15:26:21+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11160v2",
    "title": "CSST Cosmological Emulator I: Matter Power Spectrum Emulation with one percent accuracy to k = 10 h/Mpc",
    "authors": [
      "Zhao Chen",
      "Yu Yu",
      "Jiaxin Han",
      "Y. P. Jing"
    ],
    "abstract": "In the near future, the China Space Station Telescope (CSST) will obtain\nunprecedented imaging and spectroscopic data. The statistical errors in the\ncosmological parameter constraints will be reduced significantly. The\ncorresponding theoretical tools must meet the percent-level accuracy required\nto extract as much cosmological information as possible from the observations.\nWe present the CSST Emulator to provide nonlinear power spectrum predictions in\nthe eight cosmological parameter space\n$\\Omega_\\mathrm{cb},\\Omega_\\mathrm{b},H_{0},n_{s},A_{s},w_{0}, w_{a}$, and\n$m_\\nu$. It is constructed based on the Kun simulation suite, consisting of 129\nhigh-resolution simulations with box size $L=1\\,h^{-1} {\\rm Gpc}$ and evolving\n$3072^3$ particles. The determinations of parameter ranges, sampling method,\nand emulation strategy in the whole construction have been optimized\nexquisitely. This enables our prediction for $k\\leq 10\\,h {\\rm Mpc}^{-1}$ and\n$z\\leq 2.0$ to reach $1\\%$ accuracy validated through internal and external\nsimulations. We also compare our results with recent BACCO, EuclidEmulator2,\nand Mira-Titan IV emulators, which demonstrate the CSST Emulator's excellent\nperformance across a wide cosmological parameter range in the nonlinear regime.\nCSST Emulator is publicly released at https://github.com/czymh/csstemu, and\nprovides a fundamental theoretical tool for accurate cosmological inference\nwith future CSST observations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11160v2",
    "published": "2025-02-16T15:22:37+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11159v1",
    "title": "Contributions of $(770,1450)\\to $ for the Cabibbo-favored $D \\to h$ decays",
    "authors": [
      "Wen-Fei Wang",
      "Jiao-Yuan Xu",
      "Si-Hong Zhou",
      "Pan-Pan Shi"
    ],
    "abstract": "Recently, the BESIII Collaboration has observed three-body decays $D_s^+\\to\n\\eta \\omega\\pi^+$, $D^+\\to K^0_S\\pi^+\\omega$ and $D^0\\to K^-\\pi^+\\omega$. In\nthis work, we investigate the contributions of the subprocesses $\\rho^+\\to\n\\omega\\pi^+$ in these Cabibbo-favored decays $D \\to h\\omega\\pi$, with $\\rho^+=\n\\{\\rho(770)^+, \\rho(1450)^+, \\rho(770)^+\\&\\rho(1450)^+\\}$ and $h=\\{ \\eta,\nK^0_S, K^-\\}$, by introducing these subprocesses into the decay amplitudes of\nthe relevant decay processes via the vector form factor $F_{\\omega\\pi}$\nmeasured in the related $\\tau$ and $e^+e^-$ processes; we provide the first\ntheoretical predictions for the branching fractions of the quasi-two-body\ndecays $D_s^+\\to\\eta[\\rho^+\\to]\\omega\\pi^+$, $D^+\\to\nK^0_S[\\rho^+\\to]\\omega\\pi^+$ and $D^0\\to K^-[\\rho^+\\to]\\omega\\pi^+$. Our\nfindings reveal that the contributions from the subprocess\n$\\rho(770)^+\\to\\omega\\pi^+$ are significant in these observed three-body decays\n$D_s^+\\to\\eta \\omega\\pi^+$, $D^+\\to K^0_S \\omega\\pi^+$ and $D^0\\to K^-\n\\omega\\pi^+$, notwithstanding the contributions originating from the\nBreit-Wigner tail effect of $\\rho(770)^+$. The numerical results of this study\nsuggest that these Cabibbo-favored three-body decays are dominated by the\ncontributions come from the $P$-wave intermediate states $\\rho(770)^+$,\n$\\rho(1450)^+$ and their interference effects.",
    "pdf_url": "http://arxiv.org/pdf/2502.11159v1",
    "published": "2025-02-16T15:21:47+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.12205v1",
    "title": "A Rigid Beam Acting in the Shearing Manner to the Quasi-Crystalline Half-Space",
    "authors": [
      "Mohammed Altoumaimi",
      "Voldymyr Loboda"
    ],
    "abstract": "An analytical model describing the action of a rigid beam under shear forces\nto the quasi-crystalline half-space is analyzed. The elasticity theory of\nquasicrystals and the method of complex variables is used. Graphs of stresses\nand displacements for both phonon and phason fields along the edge of the\nhalf-space have been obtained",
    "pdf_url": "http://arxiv.org/pdf/2502.12205v1",
    "published": "2025-02-16T15:20:38+00:00",
    "categories": [
      "physics.class-ph",
      "cond-mat.mtrl-sci",
      "74A45 (Quasicrystals, elasticity theory), 74B05 (Classical linear\n  elasticity), 74G10 (Boundary value problems in solid mechanics)"
    ],
    "primary_category": "physics.class-ph"
  },
  {
    "id": "http://arxiv.org/abs/2503.05883v1",
    "title": "Open Boundary Conditions for Nonlinear Initial Boundary Value Problems",
    "authors": [
      "Jan Nordstrm"
    ],
    "abstract": "We present a straightforward energy stable weak implementation procedure of\nopen boundary conditions for nonlinear initial boundary value problems. It\nsimplifies previous work and its practical implementation.",
    "pdf_url": "http://arxiv.org/pdf/2503.05883v1",
    "published": "2025-02-16T15:20:29+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65 M22",
      "G.1.8"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11158v2",
    "title": "AnyRefill: A Unified, Data-Efficient Framework for Left-Prompt-Guided Vision Tasks",
    "authors": [
      "Ming Xie",
      "Chenjie Cao",
      "Yunuo Cai",
      "Xiangyang Xue",
      "Yu-Gang Jiang",
      "Yanwei Fu"
    ],
    "abstract": "In this paper, we present a novel Left-Prompt-Guided (LPG) paradigm to\naddress a diverse range of reference-based vision tasks. Inspired by the human\ncreative process, we reformulate these tasks using a left-right stitching\nformulation to construct contextual input. Building upon this foundation, we\npropose AnyRefill, an extension of LeftRefill, that effectively adapts\nText-to-Image (T2I) models to various vision tasks. AnyRefill leverages the\ninpainting priors of advanced T2I model based on the Diffusion Transformer\n(DiT) architecture, and incorporates flexible components to enhance its\ncapabilities. By combining task-specific LoRAs with the stitching input,\nAnyRefill unlocks its potential across diverse tasks, including conditional\ngeneration, visual perception, and image editing, without requiring additional\nvisual encoders. Meanwhile, AnyRefill exhibits remarkable data efficiency,\nrequiring minimal task-specific fine-tuning while maintaining high generative\nperformance. Through extensive ablation studies, we demonstrate that AnyRefill\noutperforms other image condition injection methods and achieves competitive\nresults compared to state-of-the-art open-source methods. Notably, AnyRefill\ndelivers results comparable to advanced commercial tools, such as IC-Light and\nSeedEdit, even in challenging scenarios. Comprehensive experiments and ablation\nstudies across versatile tasks validate the strong generation of the proposed\nsimple yet effective LPG formulation, establishing AnyRefill as a unified,\nhighly data-efficient solution for reference-based vision tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11158v2",
    "published": "2025-02-16T15:12:40+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11157v1",
    "title": "Dyve: Thinking Fast and Slow for Dynamic Process Verification",
    "authors": [
      "Jianyuan Zhong",
      "Zeju Li",
      "Zhijian Xu",
      "Xiangyu Wen",
      "Qiang Xu"
    ],
    "abstract": "We present Dyve, a dynamic process verifier that enhances reasoning error\ndetection in large language models by integrating fast and slow thinking,\ninspired by Kahneman's Systems Theory. Dyve adaptively applies immediate\ntoken-level confirmation System 1 for straightforward steps and comprehensive\nanalysis System 2 for complex ones. Leveraging a novel step-wise\nconsensus-filtered process supervision technique, combining Monte Carlo\nestimation with LLM based evaluation, Dyve curates high-quality supervision\nsignals from noisy data. Experimental results on ProcessBench and the MATH\ndataset confirm that Dyve significantly outperforms existing process-based\nverifiers and boosts performance in Best-of-N settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.11157v1",
    "published": "2025-02-16T15:11:19+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11156v1",
    "title": "DLBayesian: An Alternative Bayesian Reconstruction of Limited-view CT by Optimizing Deep Learning Parameters",
    "authors": [
      "Changyu Chen",
      "Li Zhang",
      "Yuxiang Xing",
      "Zhiqiang Chen"
    ],
    "abstract": "Limited-view computed tomography (CT) presents significant potential for\nreducing radiation exposure and expediting the scanning process. While deep\nlearning (DL) methods have exhibited promising results in mitigating streaking\nartifacts caused by a reduced number of projection views, their generalization\nremains challenging. In this work, we proposed a DL-driven alternative Bayesian\nreconstruction method (DLBayesian) that efficiently integrates data-driven\npriors and data consistency constraints. DLBayesian comprises three stages:\ngroup-level embedding, significance evaluation, and individual-level\nconsistency adaptation. Firstly, DL network parameters are optimized to learn\nhow to eliminate the general limited-view artifacts on a large-scale paired\ndataset. Then, we introduced a significance score to quantitatively evaluate\nthe contribution of parameters in DL models as a guide for the subsequent\nindividual-level adaptation. Finally, in the Bayesian adaptation stage, an\nalternative Bayesian reconstruction further optimizes the DL network parameters\nprecisely according to the projection data of the target case. We validated\nDLBayesian with sparse-view (90 views) projections from a circular trajectory\nCT and a special data missing case from a multi-segment linear trajectory CT.\nThe results underscore DLBayesian's superior generalization capabilities across\nvariations in patients, anatomic structures, and data distribution, as well as\nexcelling in contextual structure recovery compared to networks solely trained\nvia supervised loss. Real experiments on a dead rat demonstrate its capability\nin practical CT scans.",
    "pdf_url": "http://arxiv.org/pdf/2502.11156v1",
    "published": "2025-02-16T15:10:56+00:00",
    "categories": [
      "physics.med-ph"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11155v1",
    "title": "Uncertainty-Aware Search and Value Models: Mitigating Search Scaling Flaws in LLMs",
    "authors": [
      "Fei Yu",
      "Yingru Li",
      "Benyou Wang"
    ],
    "abstract": "Value model-guided search is effective in steering the generation but suffers\nfrom scaling flaws: Its superiority diminishes with larger sample sizes,\nunderperforming non-search baselines. This limitation arises from reliability\ndegradation in value models in unseen reasoning paths. To address this, we\npropose an uncertainty-aware search framework that includes two key components:\n(1) uncertainty-aware value models that incorporate uncertainty into\npredictions, and (2) an uncertainty-aware selection process using the proposed\nefficient Group Thompson Sampling algorithm. Experiments on GSM8K show that our\nmethod mitigates search scaling flaws, achieving 90.5% coverage at 16 samples\ncompared to 85.8% for conventional value-guided search. This work establishes\nthe first systematic integration of uncertainty quantification in LLM search\nparadigms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11155v1",
    "published": "2025-02-16T15:10:30+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11154v2",
    "title": "Refined effective bounds for Bloch-Kato Selmer groups associated to hyperelliptic curves",
    "authors": [
      "Lee Berry"
    ],
    "abstract": "We develop refined methods to effectively bound the dimension of Bloch-Kato\nSelmer groups associated to the higher Chow group $\\mathrm{CH}^2(J,1)$, where\n$J$ is the Jacobian of a hyperelliptic curve $X$. This extends the recent work\nof Dogra on explicit $2$-descent for these Selmer groups to include cases where\n$X$ does not have a rational Weierstrass point. Additionally, we develop\nmethods for obtaining sharper dimension bounds under the assumption that $X$\nhas good ordinary reduction at $2$. As a consequence, we establish new criteria\nfor deducing finiteness of the depth $2$ Chabauty-Kim set $X(\\mathbb{Q}_2)_2$,\nand demonstrate the efficacy of these criteria on curves from the LMFDB.",
    "pdf_url": "http://arxiv.org/pdf/2502.11154v2",
    "published": "2025-02-16T15:08:56+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11153v2",
    "title": "SVM/SVR Kernels as Quantum Propagators",
    "authors": [
      "Nan-Hong Kuo",
      "Renata Wong"
    ],
    "abstract": "We establish a mathematical equivalence between Support Vector Machine (SVM)\nkernel functions and quantum propagators represented by time-dependent Green's\nfunctions, which has remained largely unexplored.\n  We demonstrate that many common SVM kernels correspond naturally to Green's\nfunctions via operator inversion theory. The sigmoid kernel does not always\nsatisfy Mercer's theorem, and therefore the corresponding Green's function may\nalso fail to perform optimally.\n  We further introduce a Kernel Polynomial Method (KPM) for designing\ncustomized kernels that align with Green's functions.\n  Our numerical experiments confirm that employing positive-semidefinite\nkernels that correspond to Green's functions significantly improves predictive\naccuracy of SVM models in physical systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11153v2",
    "published": "2025-02-16T14:55:43+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.LG",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11152v2",
    "title": "Error Bound Analysis for the Regularized Loss of Deep Linear Neural Networks",
    "authors": [
      "Po Chen",
      "Rujun Jiang",
      "Peng Wang"
    ],
    "abstract": "The optimization foundations of deep linear networks have received\nsignificant attention lately. However, due to the non-convexity and\nhierarchical structure, analyzing the regularized loss of deep linear networks\nremains a challenging task. In this work, we study the local geometric\nlandscape of the regularized squared loss of deep linear networks, providing a\ndeeper understanding of its optimization properties. Specifically, we\ncharacterize the critical point set and establish an error-bound property for\nall critical points under mild conditions. Notably, we identify the sufficient\nand necessary conditions under which the error bound holds. To support our\ntheoretical findings, we conduct numerical experiments demonstrating that\ngradient descent exhibits linear convergence when optimizing the regularized\nloss of deep linear networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11152v2",
    "published": "2025-02-16T14:53:52+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "90C26, 68T07, 65K10"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11151v1",
    "title": "Unveiling the Power of Complex-Valued Transformers in Wireless Communications",
    "authors": [
      "Yang Leng",
      "Qingfeng Lin",
      "Long-Yin Yung",
      "Jingreng Lei",
      "Yang Li",
      "Yik-Chung Wu"
    ],
    "abstract": "Utilizing complex-valued neural networks (CVNNs) in wireless communication\ntasks has received growing attention for their ability to provide natural and\neffective representation of complex-valued signals and data. However, existing\nstudies typically employ complex-valued versions of simple neural network\narchitectures. Not only they merely scratch the surface of the extensive range\nof modern deep learning techniques, theoretical understanding of the superior\nperformance of CVNNs is missing. To this end, this paper aims to fill both the\ntheoretical and practice gap of employing CVNNs in wireless communications. In\nparticular, we provide a comprehensive description on the various operations in\nCVNNs and theoretically prove that the CVNN requires fewer layers than the\nreal-valued counterpart to achieve a given approximation error of a continuous\nfunction. Furthermore, to advance CVNNs in the field of wireless\ncommunications, this paper focuses on the transformer model, which represents a\nmore sophisticated deep learning architecture and has been shown to have\nexcellent performance in wireless communications but only in its real-valued\nform. In this aspect, we propose a fundamental paradigm of complex-valued\ntransformers for wireless communications. Leveraging this structure, we develop\ncustomized complex-valued transformers for three representative applications in\nwireless communications: channel estimation, user activity detection, and\nprecoding design. These applications utilize transformers with varying levels\nof sophistication and span a variety of tasks, ranging from regression to\nclassification, supervised to unsupervised learning, and specific module design\nto end-to-end design. Experimental results demonstrate the superior performance\nof the complex-valued transformers for the above three applications compared to\nother traditional real-valued neural network-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.11151v1",
    "published": "2025-02-16T14:53:12+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2503.16444v1",
    "title": "Conversational Explanations: Discussing Explainable AI with Non-AI Experts",
    "authors": [
      "Tong Zhang",
      "Mengao Zhang",
      "Wei Yan Low",
      "X. Jessie Yang",
      "Boyang Li"
    ],
    "abstract": "Explainable AI (XAI) aims to provide insights into the decisions made by AI\nmodels. To date, most XAI approaches provide only one-time, static\nexplanations, which cannot cater to users' diverse knowledge levels and\ninformation needs. Conversational explanations have been proposed as an\neffective method to customize XAI explanations. However, building\nconversational explanation systems is hindered by the scarcity of training\ndata. Training with synthetic data faces two main challenges: lack of data\ndiversity and hallucination in the generated data. To alleviate these issues,\nwe introduce a repetition penalty to promote data diversity and exploit a\nhallucination detector to filter out untruthful synthetic conversation turns.\nWe conducted both automatic and human evaluations on the proposed system,\nfEw-shot Multi-round ConvErsational Explanation (EMCEE). For automatic\nevaluation, EMCEE achieves relative improvements of 81.6% in BLEU and 80.5% in\nROUGE compared to the baselines. EMCEE also mitigates the degeneration of data\nquality caused by training on synthetic data. In human evaluations (N=60),\nEMCEE outperforms baseline models and the control group in improving users'\ncomprehension, acceptance, trust, and collaboration with static explanations by\nlarge margins. Through a fine-grained analysis of model responses, we further\ndemonstrate that training on self-generated synthetic data improves the model's\nability to generate more truthful and understandable answers, leading to better\nuser interactions. To the best of our knowledge, this is the first\nconversational explanation method that can answer free-form user questions\nfollowing static explanations.",
    "pdf_url": "http://arxiv.org/pdf/2503.16444v1",
    "published": "2025-02-16T14:52:36+00:00",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11150v2",
    "title": "Eye Tracking Based Cognitive Evaluation of Automatic Readability Assessment Measures",
    "authors": [
      "Keren Gruteke Klein",
      "Shachar Frenkel",
      "Omer Shubi",
      "Yevgeni Berzak"
    ],
    "abstract": "Automated text readability prediction is widely used in many real-world\nscenarios. Over the past century, such measures have primarily been developed\nand evaluated on reading comprehension outcomes and on human annotations of\ntext readability levels. In this work, we propose an alternative, eye\ntracking-based cognitive framework which directly taps into a key aspect of\nreadability: reading ease. We use this framework for evaluating a broad range\nof prominent readability measures, including two systems widely used in\neducation, by quantifying their ability to account for reading facilitation\neffects in text simplification, as well as text reading ease more broadly. Our\nanalyses suggest that existing readability measures are poor predictors of\nreading facilitation and reading ease, outperformed by word properties commonly\nused in psycholinguistics, and in particular by surprisal.",
    "pdf_url": "http://arxiv.org/pdf/2502.11150v2",
    "published": "2025-02-16T14:51:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.14888v3",
    "title": "Multi-Faceted Multimodal Monosemanticity",
    "authors": [
      "Hanqi Yan",
      "Xiangxiang Cui",
      "Lu Yin",
      "Paul Pu Liang",
      "Yulan He",
      "Yifei Wang"
    ],
    "abstract": "Humans experience the world through multiple modalities, such as, vision,\nlanguage, and speech, making it natural to explore the commonality and\ndistinctions among them. In this work, we take a data-driven approach to\naddress this question by analyzing interpretable, monosemantic features\nextracted from deep multimodal models. Specifically, we investigate CLIP, a\nprominent visual-language representation model trained on massive image-text\npairs. Building on prior research in single-modal interpretability, we develop\na set of multi-modal interpretability tools and measures designed to\ndisentangle and analyze features learned from CLIP. Specifically, we introduce\nthe Modality Dominance Score (MDS) to attribute each CLIP feature to a specific\nmodality. We then map CLIP features into a more interpretable space, enabling\nus to categorize them into three distinct classes: vision features\n(single-modal), language features (single-modal), and visual-language features\n(cross-modal). Interestingly, this data-driven categorization closely aligns\nwith human intuitive understandings of different modalities. We further show\nthat this modality decomposition can benefit multiple downstream tasks,\nincluding reducing bias in gender detection, generating cross-modal adversarial\nexamples, and enabling modal-specific feature control in text-to-image\ngeneration. These results indicate that large-scale multimodal models, when\nequipped with task-agnostic interpretability tools, can offer valuable insights\ninto the relationships between different data modalities.",
    "pdf_url": "http://arxiv.org/pdf/2502.14888v3",
    "published": "2025-02-16T14:51:07+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11149v2",
    "title": "Large Language-Geometry Model: When LLM meets Equivariance",
    "authors": [
      "Zongzhao Li",
      "Jiacheng Cen",
      "Bing Su",
      "Wenbing Huang",
      "Tingyang Xu",
      "Yu Rong",
      "Deli Zhao"
    ],
    "abstract": "Accurately predicting 3D structures and dynamics of physical systems is\ncrucial in scientific applications. Existing approaches that rely on geometric\nGraph Neural Networks (GNNs) effectively enforce $\\mathrm{E}(3)$-equivariance,\nbut they often fall in leveraging extensive broader information. While direct\napplication of Large Language Models (LLMs) can incorporate external knowledge,\nthey lack the capability for spatial reasoning with guaranteed equivariance. In\nthis paper, we propose EquiLLM, a novel framework for representing 3D physical\nsystems that seamlessly integrates E(3)-equivariance with LLM capabilities.\nSpecifically, EquiLLM comprises four key components: geometry-aware prompting,\nan equivariant encoder, an LLM, and an equivariant adaptor. Essentially, the\nLLM guided by the instructive prompt serves as a sophisticated invariant\nfeature processor, while 3D directional information is exclusively handled by\nthe equivariant encoder and adaptor modules. Experimental results demonstrate\nthat EquiLLM delivers significant improvements over previous methods across\nmolecular dynamics simulation, human motion simulation, and antibody design,\nhighlighting its promising generalizability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11149v2",
    "published": "2025-02-16T14:50:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11148v1",
    "title": "On the Power of Randomization for Obviously Strategy-Proof Mechanisms",
    "authors": [
      "Shiri Ron",
      "Daniel Schoepflin"
    ],
    "abstract": "We investigate the problem of designing randomized obviously strategy-proof\n(OSP) mechanisms in several canonical auction settings. Obvious\nstrategy-proofness, introduced by Li [American Economic Review, 2017],\nstrengthens the well-known concept of dominant-strategy incentive compatibility\n(DSIC). Loosely speaking, it ensures that even agents who struggle with\ncontingent reasoning can identify that their dominant strategy is optimal.\n  Thus, one would hope to design OSP mechanisms with good approximation\nguarantees. Unfortunately, Ron [SODA,2024] has shown that deterministic OSP\nmechanisms fail to achieve an approximation better than $\\min\\{m,n\\}$ where $m$\nis the number of items and $n$ is the number of bidders, even for the simple\nsettings of additive and unit-demand bidders. We circumvent these\nimpossibilities by showing that randomized mechanisms that are obviously\nstrategy-proof in the universal sense obtain a constant factor approximation\nfor these classes. We show that this phenomenon occurs also for the setting of\na multi-unit auction with single-minded bidders. Thus, our results provide a\nmore positive outlook on the design of OSP mechanisms and exhibit a stark\nseparation between the power of randomized and deterministic OSP mechanisms.\n  To complement the picture, we provide impossibilities for randomized OSP\nmechanisms in each setting. While the deterministic VCG mechanism is well known\nto output an optimal allocation in dominant strategies, we show that even\nrandomized OSP mechanisms cannot obtain more than $87.5\\%$ of the optimal\nwelfare. This further demonstrates that OSP mechanisms are significantly weaker\nthan dominant-strategy mechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11148v1",
    "published": "2025-02-16T14:45:22+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11147v2",
    "title": "RaaS: Reasoning-Aware Attention Sparsity for Efficient LLM Reasoning",
    "authors": [
      "Junhao Hu",
      "Wenrui Huang",
      "Weidong Wang",
      "Zhenwen Li",
      "Tiancheng Hu",
      "Zhixia Liu",
      "Xusheng Chen",
      "Tao Xie",
      "Yizhou Shan"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities across\nvarious domains, with recent advancements in challenging reasoning tasks such\nas mathematics and programming. However, solving reasoning tasks often requires\nan LLM to generate long sequences, incurring $O(N)$ time and memory\ncomplexities per token, where $N$ is the current sequence length. To reduce\ncomplexities, existing sparsity-based algorithms propose to retain Key-Value\n(KV) vectors, the intermediate representations of only the most critical\ntokens. However, these algorithms struggle with the \"impossible trinity\" of\naccuracy, time, and memory. For example, the state-of-the-art algorithm, Quest,\nachieves high accuracy with $O(L)$ time but $O(N)$ memory ($L$ is the cache\nbudget, $L \\ll N$). To address the \"impossible trinity\", in this paper, we\nidentify a new attention pattern during the decode stage of reasoning tasks,\nwhere milestone tokens (analogous to lemmas in mathematical proofs) emerge, are\nutilized, and then become unimportant afterward. Based on this pattern, we\npropose a new algorithm RaaS that identifies milestone tokens and retains their\nKV vectors until they are no longer needed, achieving high accuracy with $O(L)$\ntime and $O(L)$ memory complexities.",
    "pdf_url": "http://arxiv.org/pdf/2502.11147v2",
    "published": "2025-02-16T14:28:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11146v1",
    "title": "Ideal approximation theory in Frobenius categories",
    "authors": [
      "Dandan Sun",
      "Zhongsheng Tan",
      "Qikai Wang",
      "Haiyan Zhu"
    ],
    "abstract": "Let $\\mathcal{A}$ be a Frobenius category and $\\omega$ the full subcategory\nconsisting of projective objects. The relations between special precovering\n(resp., precovering) ideals in $\\mathcal{A}$ and special precovering (resp.,\npreenveloping) ideals in the stable category $\\mathcal{A}/\\omega$ are explored.\nIn combination with a result due to Breaz and Modoi, we conclude that every\nprecovering or preenveloping ideal $\\mathcal{I}$ in $\\mathcal{A}$ with\n$1_{X}\\in{\\mathcal{I}}$ for any $X\\in{\\omega}$ is special. As a consequence, it\nis proved that an ideal cotorsion pair $(\\mathcal{I},\\mathcal{J})$ in\n$\\mathcal{A}$ is complete if and only if $\\mathcal{I}$ is precovering if and\nonly if $\\mathcal{J}$ is preenveloping. This leads to an ideal version of the\nBongartz-Eklof-Trlifaj Lemma in $\\mathcal{A}/\\omega$, which states that an\nideal cotorsion pair in $\\mathcal{A}/\\omega$ generated by a set of morphisms is\ncomplete. As another consequence, we provide some partial answers to the\nquestion about the completeness of cotorsion pairs posed by Fu, Guil Asensio,\nHerzog and Torrecillas.",
    "pdf_url": "http://arxiv.org/pdf/2502.11146v1",
    "published": "2025-02-16T14:26:53+00:00",
    "categories": [
      "math.CT",
      "18G10, 18G25, 16D90"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11145v1",
    "title": "Of pashas, popes, and indivisibles",
    "authors": [
      "Mikhail G. Katz",
      "David Sherry",
      "Monica Ugaglia"
    ],
    "abstract": "The studies of Bonaventura Cavalieri's indivisibles by Giusti, Andersen,\nMancosu and others provide a comprehensive picture of Cavalieri's mathematics,\nas well as of the mathematical objections to it as formulated by Paul Guldin\nand other critics. An issue that has been studied in less detail concerns the\ntheological underpinnings of the contemporary debate over indivisibles, its\nhistorical roots, the geopolitical situation at the time, and its relation to\nthe ultimate suppression of Cavalieri's religious order. We analyze sources\nfrom the 17th through 21st centuries to investigate such a relation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11145v1",
    "published": "2025-02-16T14:26:36+00:00",
    "categories": [
      "math.HO",
      "01A45, 01A61"
    ],
    "primary_category": "math.HO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11144v2",
    "title": "Consistency of heritability estimation from summary statistics in high-dimensional linear models",
    "authors": [
      "David Azriel",
      "Samuel Davenport",
      "Armin Schwartzman"
    ],
    "abstract": "In Genome-Wide Association Studies (GWAS), heritability is defined as the\nfraction of variance of an outcome explained by a large number of genetic\npredictors in a high-dimensional polygenic linear model. This work studies the\nasymptotic properties of the most common estimator of heritability from summary\nstatistics called linkage disequilibrium score (LDSC) regression, together with\na simpler and closely related estimator called GWAS heritability (GWASH). These\nestimators are analyzed in their basic versions and under various modifications\nused in practice including weighting and standardization. We show that, with\nsome variations, two conditions which we call weak dependence (WD) and\nbounded-kurtosis effects (BKE) are sufficient for consistency of both the basic\nLDSC with fixed intercept and GWASH estimators, for both Gaussian and\nnon-Gaussian predictors. For Gaussian predictors it is shown that these\nconditions are also necessary for consistency of GWASH (with truncation) and\nsimulations suggest that necessity holds too when the predictors are\nnon-Gaussian. We also show that, with properly truncated weights, weighting\ndoes not change the consistency results, but standardization of the predictors\nand outcome, as done in practice, introduces bias in both LDSC and GWASH if the\ntwo essential conditions are violated. Finally, we show that, when population\nstratification is present, all the estimators considered are biased, and the\nbias is not remedied by using the LDSC regression estimator with free\nintercept, as originally suggested by the authors of that estimator.",
    "pdf_url": "http://arxiv.org/pdf/2502.11144v2",
    "published": "2025-02-16T14:26:14+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2502.11143v1",
    "title": "VulRG: Multi-Level Explainable Vulnerability Patch Ranking for Complex Systems Using Graphs",
    "authors": [
      "Yuning Jiang",
      "Nay Oo",
      "Qiaoran Meng",
      "Hoon Wei Lim",
      "Biplab Sikdar"
    ],
    "abstract": "As interconnected systems proliferate, safeguarding complex infrastructures\nagainst an escalating array of cyber threats has become an urgent challenge.\nThe increasing number of vulnerabilities, combined with resource constraints,\nmakes addressing every vulnerability impractical, making effective\nprioritization essential. However, existing risk prioritization methods often\nrely on expert judgment or focus solely on exploit likelihood and consequences,\nlacking the granularity and adaptability needed for complex systems. This work\nintroduces a graph-based framework for vulnerability patch prioritization that\noptimizes security by integrating diverse data sources and metrics into a\nuniversally applicable model. Refined risk metrics enable detailed assessments\nat the component, asset, and system levels. The framework employs two key\ngraphs: a network communication graph to model potential attack paths and\nidentify the shortest routes to critical assets, and a system dependency graph\nto capture risk propagation from exploited vulnerabilities across\ninterconnected components. Asset criticality and component dependency rules\nsystematically assess and mitigate risks. Benchmarking against state-of-the-art\nmethods demonstrates superior accuracy in vulnerability patch ranking, with\nenhanced explainability. This framework advances vulnerability management and\nsets the stage for future research in adaptive cybersecurity strategies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11143v1",
    "published": "2025-02-16T14:21:52+00:00",
    "categories": [
      "cs.CR",
      "68M25 (Primary) 68Q99 (Secondary)"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11142v3",
    "title": "NavRAG: Generating User Demand Instructions for Embodied Navigation through Retrieval-Augmented LLM",
    "authors": [
      "Zihan Wang",
      "Yaohui Zhu",
      "Gim Hee Lee",
      "Yachun Fan"
    ],
    "abstract": "Vision-and-Language Navigation (VLN) is an essential skill for embodied\nagents, allowing them to navigate in 3D environments following natural language\ninstructions. High-performance navigation models require a large amount of\ntraining data, the high cost of manually annotating data has seriously hindered\nthis field. Therefore, some previous methods translate trajectory videos into\nstep-by-step instructions for expanding data, but such instructions do not\nmatch well with users' communication styles that briefly describe destinations\nor state specific needs. Moreover, local navigation trajectories overlook\nglobal context and high-level task planning. To address these issues, we\npropose NavRAG, a retrieval-augmented generation (RAG) framework that generates\nuser demand instructions for VLN. NavRAG leverages LLM to build a hierarchical\nscene description tree for 3D scene understanding from global layout to local\ndetails, then simulates various user roles with specific demands to retrieve\nfrom the scene tree, generating diverse instructions with LLM. We annotate over\n2 million navigation instructions across 861 scenes and evaluate the data\nquality and navigation performance of trained models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11142v3",
    "published": "2025-02-16T14:17:36+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.14887v1",
    "title": "Vision-Enhanced Time Series Forecasting via Latent Diffusion Models",
    "authors": [
      "Weilin Ruan",
      "Siru Zhong",
      "Haomin Wen",
      "Yuxuan Liang"
    ],
    "abstract": "Diffusion models have recently emerged as powerful frameworks for generating\nhigh-quality images. While recent studies have explored their application to\ntime series forecasting, these approaches face significant challenges in\ncross-modal modeling and transforming visual information effectively to capture\ntemporal patterns. In this paper, we propose LDM4TS, a novel framework that\nleverages the powerful image reconstruction capabilities of latent diffusion\nmodels for vision-enhanced time series forecasting. Instead of introducing\nexternal visual data, we are the first to use complementary transformation\ntechniques to convert time series into multi-view visual representations,\nallowing the model to exploit the rich feature extraction capabilities of the\npre-trained vision encoder. Subsequently, these representations are\nreconstructed using a latent diffusion model with a cross-modal conditioning\nmechanism as well as a fusion module. Experimental results demonstrate that\nLDM4TS outperforms various specialized forecasting models for time series\nforecasting tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.14887v1",
    "published": "2025-02-16T14:15:06+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11141v2",
    "title": "Cognitive Neural Architecture Search Reveals Hierarchical Entailment",
    "authors": [
      "Lukas Kuhn",
      "Sari Saba-Sadiya",
      "Gemma Roig"
    ],
    "abstract": "Recent research has suggested that the brain is more shallow than previously\nthought, challenging the traditionally assumed hierarchical structure of the\nventral visual pathway. Here, we demonstrate that optimizing convolutional\nnetwork architectures for brain-alignment via evolutionary neural architecture\nsearch results in models with clear representational hierarchies. Despite\nhaving random weights, the identified models achieve brain-alignment scores\nsurpassing even those of pretrained classification models - as measured by both\nregression and representational similarity analysis. Furthermore, through\ntraditional supervised training, architectures optimized for alignment with\nlate ventral regions become competitive classification models. These findings\nsuggest that hierarchical structure is a fundamental mechanism of primate\nvisual processing. Finally, this work demonstrates the potential of neural\narchitecture search as a framework for computational cognitive neuroscience\nresearch that could reduce the field's reliance on manually designed\nconvolutional networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11141v2",
    "published": "2025-02-16T14:13:04+00:00",
    "categories": [
      "cs.NE",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11140v2",
    "title": "Automated Visualization Code Synthesis via Multi-Path Reasoning and Feedback-Driven Optimization",
    "authors": [
      "Wonduk Seo",
      "Seungyong Lee",
      "Daye Kang",
      "Hyunjin An",
      "Zonghao Yuan",
      "Seunghyun Lee"
    ],
    "abstract": "Rapid advancements in Large Language Models (LLMs) have accelerated their\nintegration into automated visualization code generation applications. Despite\nadvancements through few-shot prompting and query expansion, existing methods\nremain limited in handling ambiguous and complex queries, thereby requiring\nmanual intervention. To overcome these limitations, we propose VisPath: a\nMulti-Path Reasoning and Feedback-Driven Optimization Framework for\nVisualization Code Generation. VisPath handles underspecified queries through\nstructured, multi-stage processing. It begins by reformulating the user input\nvia Chain-of-Thought (CoT) prompting, which refers to the initial query while\ngenerating multiple extended queries in parallel, enabling the LLM to capture\ndiverse interpretations of the user intent. These queries then generate\ncandidate visualization scripts, which are executed to produce diverse images.\nBy assessing the visual quality and correctness of each output, VisPath\ngenerates targeted feedback that is aggregated to synthesize an optimal final\nresult. Extensive experiments on widely-used benchmarks including MatPlotBench\nand the Qwen-Agent Code Interpreter Benchmark show that VisPath outperforms\nstate-of-the-art methods, offering a more reliable solution for AI-driven\nvisualization code generation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11140v2",
    "published": "2025-02-16T14:09:42+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11139v1",
    "title": "GJ 2126 b: A highly eccentric Jovian exoplanet",
    "authors": [
      "Arbel Schorr",
      "Avraham Binnenfeld",
      "Shay Zucker"
    ],
    "abstract": "We report the discovery of GJ 2126 b, a highly eccentric (e = 0.85)\nJupiter-like planet orbiting its host star every 272.7 days. The planet was\ndetected and characterized using 112 radial velocity (RV) measurements from\nHARPS (High Accuracy Radial Velocity Planet Searcher), provided by\nHARPS-RVBank. This planet orbits a low-mass star and ranks among the most\neccentric exoplanets discovered, placing it in a unique region of the parameter\nspace of the known exoplanet population. This makes it a valuable addition to\nthe exoplanet demographics, helping to refine our understanding of planetary\nformation and evolution theories.",
    "pdf_url": "http://arxiv.org/pdf/2502.11139v1",
    "published": "2025-02-16T14:09:19+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11138v1",
    "title": "Machine Learning-Based Intrusion Detection and Prevention System for IIoT Smart Metering Networks: Challenges and Solutions",
    "authors": [
      "Sahar Lazim",
      "Qutaiba I. Ali"
    ],
    "abstract": "The Industrial Internet of Things (IIoT) has revolutionized industries by\nenabling automation, real-time data exchange, and smart decision-making.\nHowever, its increased connectivity introduces cybersecurity threats,\nparticularly in smart metering networks, which play a crucial role in\nmonitoring and optimizing energy consumption. This paper explores the\nchallenges associated with securing IIoT-based smart metering networks and\nproposes a Machine Learning (ML)-based Intrusion Detection and Prevention\nSystem (IDPS) for safeguarding edge devices. The study reviews various\nintrusion detection approaches, highlighting the strengths and limitations of\nboth signature-based and anomaly-based detection techniques. The findings\nsuggest that integrating ML-driven IDPS in IIoT smart metering environments\nenhances security, efficiency, and resilience against evolving cyber threats.",
    "pdf_url": "http://arxiv.org/pdf/2502.11138v1",
    "published": "2025-02-16T14:08:59+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11137v3",
    "title": "Safety Evaluation of DeepSeek Models in Chinese Contexts",
    "authors": [
      "Wenjing Zhang",
      "Xuejiao Lei",
      "Zhaoxiang Liu",
      "Ning Wang",
      "Zhenhong Long",
      "Peijun Yang",
      "Jiaojiao Zhao",
      "Minjie Hua",
      "Chaoyang Ma",
      "Kai Wang",
      "Shiguo Lian"
    ],
    "abstract": "Recently, the DeepSeek series of models, leveraging their exceptional\nreasoning capabilities and open-source strategy, is reshaping the global AI\nlandscape. Despite these advantages, they exhibit significant safety\ndeficiencies. Research conducted by Robust Intelligence, a subsidiary of Cisco,\nin collaboration with the University of Pennsylvania, revealed that DeepSeek-R1\nhas a 100\\% attack success rate when processing harmful prompts. Additionally,\nmultiple safety companies and research institutions have confirmed critical\nsafety vulnerabilities in this model. As models demonstrating robust\nperformance in Chinese and English, DeepSeek models require equally crucial\nsafety assessments in both language contexts. However, current research has\npredominantly focused on safety evaluations in English environments, leaving a\ngap in comprehensive assessments of their safety performance in Chinese\ncontexts. In response to this gap, this study introduces CHiSafetyBench, a\nChinese-specific safety evaluation benchmark. This benchmark systematically\nevaluates the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts,\nrevealing their performance across safety categories. The experimental results\nquantify the deficiencies of these two models in Chinese contexts, providing\nkey insights for subsequent improvements. It should be noted that, despite our\nefforts to establish a comprehensive, objective, and authoritative evaluation\nbenchmark, the selection of test samples, characteristics of data distribution,\nand the setting of evaluation criteria may inevitably introduce certain biases\ninto the evaluation results. We will continuously optimize the evaluation\nbenchmark and periodically update this report to provide more comprehensive and\naccurate assessment outcomes. Please refer to the latest version of the paper\nfor the most recent evaluation results and conclusions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11137v3",
    "published": "2025-02-16T14:05:54+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11136v1",
    "title": "Heavy-flavor multimodal fragmentation to $S$-wave pentacharms at next-generation hadron colliders",
    "authors": [
      "Francesco Giovanni Celiberto"
    ],
    "abstract": "We investigate the leading-power fragmentation of fully charmed pentaquark\nstates ($S$-wave $|c\\bar{c}ccc\\rangle$ pentacharms) at hadron colliders. We\nintroduce a new set of hadron-structure-oriented, multimodal collinear\nfragmentation functions, named PQ5Q1.0. They rely on an enhanced calculation of\nthe initial-scale input for the constituent heavy-quark fragmentation channel,\nmaking them well suited to describe the short-distance emission of either a\ncompact multicharm state or a dicharm-charm-dicharm configuration. To explore\nphenomenological implications, we use the (sym)JETHAD multimodular interface to\nstudy NLL/NLO$^+$ semi-inclusive production rates for pentacharm-plus-jet\nsystems at the forthcoming HL-LHC and the future FCC. Our analysis represents a\nfurther step toward bridging the domains of hadronic structure, precision QCD,\nand exotic matter.",
    "pdf_url": "http://arxiv.org/pdf/2502.11136v1",
    "published": "2025-02-16T14:04:31+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-th",
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11135v2",
    "title": "The Holography of the 2D inhomogeneously deformed CFT",
    "authors": [
      "Zhehan Li",
      "Zhifeng Li",
      "Jia Tian"
    ],
    "abstract": "We systematically study inhomogeneous Hamiltonians in two-dimensional\nconformal field theories within the framework of the AdS/CFT correspondence by\nrelating them to two-dimensional curved backgrounds. We propose a\nclassification of inhomogeneous Hamiltonians based on the Virasoro coadjoint\norbit. The corresponding bulk dual geometries are described by the generalized\nBa$\\tilde{\\text{n}}$ados solutions, for which we introduce a generalized\nRoberts mapping to facilitate their study. Our classification provides\npreviously underexplored classes of deformations, offering fresh insights into\ntheir holographic properties. Revisiting the well-known example of the\nM$\\ddot{\\text{o}}$bius Hamiltonian, we establish a connection to the 3D\nC-metric, which describes three-dimensional accelerating solutions.\nFurthermore, we extend our analysis to KdV-type asymptotic boundary conditions,\nrevealing a broader class of solvable inhomogeneous Hamiltonians that are not\nlinear combinations of Virasoro charges but instead involve KdV charges.",
    "pdf_url": "http://arxiv.org/pdf/2502.11135v2",
    "published": "2025-02-16T14:03:50+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2503.05716v1",
    "title": "Normalized Fourier-induced PINN method for solving the wave propagation equation in a non-unitized domain over an extended time range",
    "authors": [
      "Jichao Ma",
      "Dandan Liu",
      "Jinran Wu",
      "Xi'an Li"
    ],
    "abstract": "Physics-Informed Neural Networks (PINNs) have gained significant attention\nfor their simplicity and flexibility in engineering and scientific computing.\nIn this study, we introduce a normalized PINN (NPINN) framework to solve a\nclass of wave propagation equations in non-unitized domains over extended time\nranges. This is achieved through a normalization technique that involves either\nspatial or temporal variable normalization. To enhance the capability of NPINN\nin solving wave equations, we integrate a Fourier-induced deep neural network\nas the solver, leading to a novel architecture termed NFPINN. Furthermore, we\nexplore different normalization strategies for spatial and temporal variables\nand identify the optimal normalization approach for our method. To assess the\neffectiveness and robustness of the proposed NFPINN, we present numerical\nexperiments in both two-dimensional and three-dimensional Euclidean spaces,\nconsidering regular and irregular domains. The results confirm the accuracy and\nstability of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2503.05716v1",
    "published": "2025-02-16T14:03:21+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11134v1",
    "title": "Solving Online Resource-Constrained Scheduling for Follow-Up Observation in Astronomy: a Reinforcement Learning Approach",
    "authors": [
      "Yajie Zhang",
      "Ce Yu",
      "Chao Sun",
      "Jizeng Wei",
      "Junhan Ju",
      "Shanjiang Tang"
    ],
    "abstract": "In the astronomical observation field, determining the allocation of\nobservation resources of the telescope array and planning follow-up\nobservations for targets of opportunity (ToOs) are indispensable components of\nastronomical scientific discovery. This problem is computationally challenging,\ngiven the online observation setting and the abundance of time-varying factors\nthat can affect whether an observation can be conducted. This paper presents\nROARS, a reinforcement learning approach for online astronomical\nresource-constrained scheduling. To capture the structure of the astronomical\nobservation scheduling, we depict every schedule using a directed acyclic graph\n(DAG), illustrating the dependency of timing between different observation\ntasks within the schedule. Deep reinforcement learning is used to learn a\npolicy that can improve the feasible solution by iteratively local rewriting\nuntil convergence. It can solve the challenge of obtaining a complete solution\ndirectly from scratch in astronomical observation scenarios, due to the high\ncomputational complexity resulting from numerous spatial and temporal\nconstraints. A simulation environment is developed based on real-world\nscenarios for experiments, to evaluate the effectiveness of our proposed\nscheduling approach. The experimental results show that ROARS surpasses 5\npopular heuristics, adapts to various observation scenarios and learns\neffective strategies with hindsight.",
    "pdf_url": "http://arxiv.org/pdf/2502.11134v1",
    "published": "2025-02-16T14:01:12+00:00",
    "categories": [
      "cs.AI",
      "astro-ph.IM"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11133v1",
    "title": "MasRouter: Learning to Route LLMs for Multi-Agent Systems",
    "authors": [
      "Yanwei Yue",
      "Guibin Zhang",
      "Boyang Liu",
      "Guancheng Wan",
      "Kun Wang",
      "Dawei Cheng",
      "Yiyan Qi"
    ],
    "abstract": "Multi-agent systems (MAS) powered by Large Language Models (LLMs) have been\ndemonstrated to push the boundaries of LLM capabilities, yet they often incur\nsignificant costs and face challenges in dynamic LLM selection. Current LLM\nrouting methods effectively reduce overhead in single-agent scenarios by\ncustomizing LLM selection for each query, but they overlook the critical\ndecisions regarding collaboration modes and agent roles in MAS. In response to\nthis challenge, we first introduce the problem of Multi-Agent System Routing\n(MASR), which integrates all components of MAS into a unified routing\nframework. Toward this goal, we propose MasRouter, the first high-performing,\ncost-effective, and inductive MASR solution. MasRouter employs collaboration\nmode determination, role allocation, and LLM routing through a cascaded\ncontroller network, progressively constructing a MAS that balances\neffectiveness and efficiency. Extensive experiments demonstrate that MasRouter\nis (1) high-performing, achieving a $1.8\\%\\sim8.2\\%$ improvement over the\nstate-of-the-art method on MBPP; (2) economical, reducing overhead by up to\n$52.07\\%$ compared to SOTA methods on HumanEval; and (3) plug-and-play,\nseamlessly integrating with mainstream MAS frameworks, reducing overhead by\n$17.21\\%\\sim28.17\\%$ via customized routing. The code is available at\nhttps://github.com/yanweiyue/masrouter.",
    "pdf_url": "http://arxiv.org/pdf/2502.11133v1",
    "published": "2025-02-16T14:00:59+00:00",
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11132v1",
    "title": "UNITE-FND: Reframing Multimodal Fake News Detection through Unimodal Scene Translation",
    "authors": [
      "Arka Mukherjee",
      "Shreya Ghosh"
    ],
    "abstract": "Multimodal fake news detection typically demands complex architectures and\nsubstantial computational resources, posing deployment challenges in real-world\nsettings. We introduce UNITE-FND, a novel framework that reframes multimodal\nfake news detection as a unimodal text classification task. We propose six\nspecialized prompting strategies with Gemini 1.5 Pro, converting visual content\ninto structured textual descriptions, and enabling efficient text-only models\nto preserve critical visual information. To benchmark our approach, we\nintroduce Uni-Fakeddit-55k, a curated dataset family of 55,000 samples each,\neach processed through our multimodal-to-unimodal translation framework.\nExperimental results demonstrate that UNITE-FND achieves 92.52% accuracy in\nbinary classification, surpassing prior multimodal models while reducing\ncomputational costs by over 10x (TinyBERT variant: 14.5M parameters vs. 250M+\nin SOTA models). Additionally, we propose a comprehensive suite of five novel\nmetrics to evaluate image-to-text conversion quality, ensuring optimal\ninformation preservation. Our results demonstrate that structured text-based\nrepresentations can replace direct multimodal processing with minimal loss of\naccuracy, making UNITE-FND a practical and scalable alternative for\nresource-constrained environments.",
    "pdf_url": "http://arxiv.org/pdf/2502.11132v1",
    "published": "2025-02-16T14:00:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11131v2",
    "title": "Improving Similar Case Retrieval Ranking Performance By Revisiting RankSVM",
    "authors": [
      "Yuqi Liu",
      "Yan Zheng"
    ],
    "abstract": "Given the rapid development of Legal AI, a lot of attention has been paid to\none of the most important legal AI tasks--similar case retrieval, especially\nwith language models to use. In our paper, however, we try to improve the\nranking performance of current models from the perspective of learning to rank\ninstead of language models. Specifically, we conduct experiments using a\npairwise method--RankSVM as the classifier to substitute a fully connected\nlayer, combined with commonly used language models on similar case retrieval\ndatasets LeCaRDv1 and LeCaRDv2. We finally come to the conclusion that RankSVM\ncould generally help improve the retrieval performance on the LeCaRDv1 and\nLeCaRDv2 datasets compared with original classifiers by optimizing the precise\nranking. It could also help mitigate overfitting owing to class imbalance. Our\ncode is available in https://github.com/liuyuqi123study/RankSVM_for_SLR",
    "pdf_url": "http://arxiv.org/pdf/2502.11131v2",
    "published": "2025-02-16T13:59:00+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11130v1",
    "title": "Advanced 3D-Printed Multiphasic Scaffold with Optimal PRP Dosage for Chondrogenesis of BM-MSCs in Osteochondral Tissue Engineering",
    "authors": [
      "Faezeh Ghobadi",
      "Maryam Mohammadi",
      "Rooja Kalantarzadeh",
      "Ehsan Lotfi",
      "Shokoufeh Borhan",
      "Narendra Pal Singh Chauhan",
      "Ghazaleh Salehi",
      "Sara Simorgh"
    ],
    "abstract": "In osteochondral tissue engineering (OCTE), simultaneously regenerating\nsubchondral bone and cartilage tissue presents a significant challenge.\nMultiphasic scaffolds were created and manufactured using 3D printing to\naddress this issue. Excellent interfacial mechanical properties and\nbiocompatibility enhance the growth and chondrogenic differentiation of bone\nmarrow mesenchymal stem cells (BM-MSCs). The subchondral bone bottom layer is\nmimicked by incorporating varying concentrations of graphene oxide (GO) (0%,\n1%, and 2% w/v) into a bioink composed of alginate (Alg) and gelatin (Gel).\nBased on evaluations of mechanical and biocompatibility properties, 1% GO is\nselected for further studies. Subsequently, the GO concentration is kept\nconstant while varying the platelet-rich plasma (PRP) dosage in the multiphasic\nscaffolds. Different PRP dosages (0%, 1%, 2%, and 3% w/v) are integrated into\nthe Alg-Gel bioink to simulate cartilage tissues. Results indicate that\n3D-printed scaffolds containing 1% or 2% PRP exhibit favorable biomechanical\nproperties, with no significant differences observed. However, BM-MSCs exposed\nto 2% PRP demonstrate enhanced adhesion, growth, and viability. Additionally,\nreal-time PCR and Alcian blue staining confirm increased chondrogenic\nexpression and glycosaminoglycans (GAGs) synthesis. This work highlights the\npromising potential of 3D-printed multiphasic frameworks in the development of\nOCTE.",
    "pdf_url": "http://arxiv.org/pdf/2502.11130v1",
    "published": "2025-02-16T13:56:34+00:00",
    "categories": [
      "q-bio.TO"
    ],
    "primary_category": "q-bio.TO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11129v1",
    "title": "Combining GPU and CPU for accelerating evolutionary computing workloads",
    "authors": [
      "Rustam Eynaliyev",
      "Houcen Liu"
    ],
    "abstract": "Evolutionary computing (EC) has proven to be effective in solving complex\noptimization and robotics problems. Unfortunately, typical Evolutionary\nAlgorithms (EAs) are constrained by the computational capacity available to\nresearchers. More recently, GPUs have been extensively used in speeding up\nworkloads across a variety of fields in AI. This led us to the idea of\nconsidering utilizing GPUs for optimizing ECs, particularly for complex\nproblems such as the evolution of artificial creatures in physics simulations.\nIn this study, we compared the CPU and GPU performance across various\nsimulation models, from simple box environments to more complex models.\nAdditionally, we create and investigate a novel hybrid CPU + GPU scheme that\naims to fully utilize the idle hardware capabilities present on most consumer\ndevices. The strategy involves running simulation workloads on both the GPU and\nthe CPU, dynamically adjusting the distribution of workload between the CPU and\nthe GPU based on benchmark results. Our findings suggest that while the CPU\ndemonstrates superior performance under most conditions, the hybrid CPU + GPU\nstrategy shows promise at higher workloads. However, overall performance\nimprovement is highly sensitive to simulation parameters such as the number of\nvariants, the complexity of the model, and the duration of the simulation.\nThese results demonstrate the potential of creative, dynamic resource\nmanagement for experiments running physics simulations on workstations and\nconsumer devices that have both GPUs and CPUs present.",
    "pdf_url": "http://arxiv.org/pdf/2502.11129v1",
    "published": "2025-02-16T13:54:49+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11128v2",
    "title": "FELLE: Autoregressive Speech Synthesis with Token-Wise Coarse-to-Fine Flow Matching",
    "authors": [
      "Hui Wang",
      "Shujie Liu",
      "Lingwei Meng",
      "Jinyu Li",
      "Yifan Yang",
      "Shiwan Zhao",
      "Haiyang Sun",
      "Yanqing Liu",
      "Haoqin Sun",
      "Jiaming Zhou",
      "Yan Lu",
      "Yong Qin"
    ],
    "abstract": "To advance continuous-valued token modeling and temporal-coherence\nenforcement, we propose FELLE, an autoregressive model that integrates language\nmodeling with token-wise flow matching. By leveraging the autoregressive nature\nof language models and the generative efficacy of flow matching, FELLE\neffectively predicts continuous-valued tokens (mel-spectrograms). For each\ncontinuous-valued token, FELLE modifies the general prior distribution in flow\nmatching by incorporating information from the previous step, improving\ncoherence and stability. Furthermore, to enhance synthesis quality, FELLE\nintroduces a coarse-to-fine flow-matching mechanism, generating\ncontinuous-valued tokens hierarchically, conditioned on the language model's\noutput. Experimental results demonstrate the potential of incorporating\nflow-matching techniques in autoregressive mel-spectrogram modeling, leading to\nsignificant improvements in TTS generation quality, as shown in\nhttps://aka.ms/felle.",
    "pdf_url": "http://arxiv.org/pdf/2502.11128v2",
    "published": "2025-02-16T13:54:32+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11127v1",
    "title": "G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems",
    "authors": [
      "Shilong Wang",
      "Guibin Zhang",
      "Miao Yu",
      "Guancheng Wan",
      "Fanci Meng",
      "Chongye Guo",
      "Kun Wang",
      "Yang Wang"
    ],
    "abstract": "Large Language Model (LLM)-based Multi-agent Systems (MAS) have demonstrated\nremarkable capabilities in various complex tasks, ranging from collaborative\nproblem-solving to autonomous decision-making. However, as these systems become\nincreasingly integrated into critical applications, their vulnerability to\nadversarial attacks, misinformation propagation, and unintended behaviors have\nraised significant concerns. To address this challenge, we introduce\nG-Safeguard, a topology-guided security lens and treatment for robust LLM-MAS,\nwhich leverages graph neural networks to detect anomalies on the multi-agent\nutterance graph and employ topological intervention for attack remediation.\nExtensive experiments demonstrate that G-Safeguard: (I) exhibits significant\neffectiveness under various attack strategies, recovering over 40% of the\nperformance for prompt injection; (II) is highly adaptable to diverse LLM\nbackbones and large-scale MAS; (III) can seamlessly combine with mainstream MAS\nwith security guarantees. The code is available at\nhttps://github.com/wslong20/G-safeguard.",
    "pdf_url": "http://arxiv.org/pdf/2502.11127v1",
    "published": "2025-02-16T13:48:41+00:00",
    "categories": [
      "cs.CR",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11126v3",
    "title": "In Situ Optimization of an Optoelectronic Reservoir Computer with Digital Delayed Feedback",
    "authors": [
      "Fyodor Morozko",
      "Shadad Watad",
      "Amir Naser",
      "Andrey Novitsky",
      "Alina Karabchevsky"
    ],
    "abstract": "Reservoir computing (RC) is an innovative paradigm in neuromorphic computing\nthat leverages fixed, randomized, internal connections to address the challenge\nof overfitting. RC has shown remarkable effectiveness in signal processing and\npattern recognition tasks, making it well-suited for hardware implementations\nacross various physical substrates, which promise enhanced computation speeds\nand reduced energy consumption. However, achieving optimal performance in RC\nsystems requires effective parameter optimization. Traditionally, this\noptimization has relied on software modeling, limiting the practicality of\nphysical computing approaches. Here, we report an \\emph{in situ} optimization\nmethod for an optoelectronic delay-based RC system with digital delayed\nfeedback. By simultaneously optimizing five parameters, normalized mean squared\nerror (NMSE) of 0.028, 0.561, and 0.271 is achieved in three benchmark tasks:\nwaveform classification, time series prediction, and speech recognition\noutperforming simulation-based optimization (NMSE 0.054, 0.543, and 0.329,\nrespectively) in the two of the three tasks. This method marks a significant\nadvancement in physical computing, facilitating the optimization of RC and\nneuromorphic systems without the need for simulation, thus enhancing their\npractical applicability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11126v3",
    "published": "2025-02-16T13:47:53+00:00",
    "categories": [
      "cs.ET",
      "physics.optics"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2502.11125v2",
    "title": "Convergence Analysis of Stochastic Accelerated Gradient Methods for Generalized Smooth Optimizations",
    "authors": [
      "Chenhao Yu",
      "Yusu Hong",
      "Junhong Lin"
    ],
    "abstract": "We investigate the Randomized Stochastic Accelerated Gradient (RSAG) method,\nutilizing either constant or adaptive step sizes, for stochastic optimization\nproblems with generalized smooth objective functions. Under relaxed affine\nvariance assumptions for the stochastic gradient noise, we establish\nhigh-probability convergence rates of order\n$\\tilde{O}\\left(\\sqrt{\\log(1/\\delta)/T}\\right)$ for function value gaps in the\nconvex setting, and for the squared gradient norms in the non-convex setting.\nFurthermore, when the noise parameters are sufficiently small, the convergence\nrate improves to $\\tilde{O}\\left(\\log(1/\\delta)/T\\right)$, where $T$ denotes\nthe total number of iterations and $\\delta$ is the probability margin. Our\nanalysis is also applicable to SGD with both constant and adaptive step sizes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11125v2",
    "published": "2025-02-16T13:46:25+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11124v1",
    "title": "AdaManip: Adaptive Articulated Object Manipulation Environments and Policy Learning",
    "authors": [
      "Yuanfei Wang",
      "Xiaojie Zhang",
      "Ruihai Wu",
      "Yu Li",
      "Yan Shen",
      "Mingdong Wu",
      "Zhaofeng He",
      "Yizhou Wang",
      "Hao Dong"
    ],
    "abstract": "Articulated object manipulation is a critical capability for robots to\nperform various tasks in real-world scenarios. Composed of multiple parts\nconnected by joints, articulated objects are endowed with diverse functional\nmechanisms through complex relative motions. For example, a safe consists of a\ndoor, a handle, and a lock, where the door can only be opened when the latch is\nunlocked. The internal structure, such as the state of a lock or joint angle\nconstraints, cannot be directly observed from visual observation. Consequently,\nsuccessful manipulation of these objects requires adaptive adjustment based on\ntrial and error rather than a one-time visual inference. However, previous\ndatasets and simulation environments for articulated objects have primarily\nfocused on simple manipulation mechanisms where the complete manipulation\nprocess can be inferred from the object's appearance. To enhance the diversity\nand complexity of adaptive manipulation mechanisms, we build a novel\narticulated object manipulation environment and equip it with 9 categories of\nobjects. Based on the environment and objects, we further propose an adaptive\ndemonstration collection and 3D visual diffusion-based imitation learning\npipeline that learns the adaptive manipulation policy. The effectiveness of our\ndesigns and proposed method is validated through both simulation and real-world\nexperiments. Our project page is available at: https://adamanip.github.io",
    "pdf_url": "http://arxiv.org/pdf/2502.11124v1",
    "published": "2025-02-16T13:45:10+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11123v3",
    "title": "DuplexMamba: Enhancing Real-time Speech Conversations with Duplex and Streaming Capabilities",
    "authors": [
      "Xiangyu Lu",
      "Wang Xu",
      "Haoyu Wang",
      "Hongyun Zhou",
      "Haiyan Zhao",
      "Conghui Zhu",
      "Tiejun Zhao",
      "Muyun Yang"
    ],
    "abstract": "Real-time speech conversation is essential for natural and efficient\nhuman-machine interactions, requiring duplex and streaming capabilities.\nTraditional Transformer-based conversational chatbots operate in a turn-based\nmanner and exhibit quadratic computational complexity that grows as the input\nsize increases. In this paper, we propose DuplexMamba, a Mamba-based end-to-end\nmultimodal duplex model for speech-to-text conversation. DuplexMamba enables\nsimultaneous input processing and output generation, dynamically adjusting to\nsupport real-time streaming. Specifically, we develop a Mamba-based speech\nencoder and adapt it with a Mamba-based language model. Furthermore, we\nintroduce a novel duplex decoding strategy that enables DuplexMamba to process\ninput and generate output simultaneously. Experimental results demonstrate that\nDuplexMamba successfully implements duplex and streaming capabilities while\nachieving performance comparable to several recently developed\nTransformer-based models in automatic speech recognition (ASR) tasks and voice\nassistant benchmark evaluations. Our code and model are released.",
    "pdf_url": "http://arxiv.org/pdf/2502.11123v3",
    "published": "2025-02-16T13:42:48+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.15772v2",
    "title": "Rashomon perspective for measuring uncertainty in the survival predictive maintenance models",
    "authors": [
      "Yigitcan Yardimci",
      "Mustafa Cavus"
    ],
    "abstract": "The prediction of the Remaining Useful Life of aircraft engines is a critical\narea in high-reliability sectors such as aerospace and defense. Early failure\npredictions help ensure operational continuity, reduce maintenance costs, and\nprevent unexpected failures. Traditional regression models struggle with\ncensored data, which can lead to biased predictions. Survival models, on the\nother hand, effectively handle censored data, improving predictive accuracy in\nmaintenance processes. This paper introduces a novel approach based on the\nRashomon perspective, which considers multiple models that achieve similar\nperformance rather than relying on a single best model. This enables\nuncertainty quantification in survival probability predictions and enhances\ndecision-making in predictive maintenance. The Rashomon survival curve was\nintroduced to represent the range of survival probability estimates, providing\ninsights into model agreement and uncertainty over time. The results on the\nCMAPSS dataset demonstrate that relying solely on a single model for RUL\nestimation may increase risk in some scenarios. The censoring levels\nsignificantly impact prediction uncertainty, with longer censoring times\nleading to greater variability in survival probabilities. These findings\nunderscore the importance of incorporating model multiplicity in predictive\nmaintenance frameworks to achieve more reliable and robust failure predictions.\nThis paper contributes to uncertainty quantification in RUL prediction and\nhighlights the Rashomon perspective as a powerful tool for predictive modeling.",
    "pdf_url": "http://arxiv.org/pdf/2502.15772v2",
    "published": "2025-02-16T13:36:56+00:00",
    "categories": [
      "stat.AP",
      "cs.LG"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11122v1",
    "title": "Hierarchical Expert Prompt for Large-Language-Model: An Approach Defeat Elite AI in TextStarCraft II for the First Time",
    "authors": [
      "Zongyuan Li",
      "Chang Lu",
      "Xiaojie Xu",
      "Runnan Qi",
      "Yanan Ni",
      "Lumin Jiang",
      "Xiangbei Liu",
      "Xuebo Zhang",
      "Yongchun Fang",
      "Kuihua Huang",
      "Xian Guo"
    ],
    "abstract": "Since the emergence of the Large Language Model (LLM), LLM has been widely\nused in fields such as writing, translating, and searching. However, there is\nstill great potential for LLM-based methods in handling complex tasks such as\ndecision-making in the StarCraft II environment. To address problems such as\nlack of relevant knowledge and poor control over subtasks of varying\nimportance, we propose a Hierarchical Expert Prompt (HEP) for LLM. Our method\nimproves the understanding of game situations through expert-level tactical\nknowledge, improving the processing quality of tasks of varying importance\nthrough a hierarchical framework. Our approach defeated the highest level\n(Elite) standard built-in agent in TextStarCraft II for the first time and\nconsistently outperformed the baseline method in other difficulties. Our\nexperiments suggest that the proposed method is a practical solution for\ntackling complex decision-making challenges. The replay video can be viewed on\nhttps://www.bilibili.com/video/BV1uz42187EF and https://youtu.be/dO3PshWLV5M,\nand our codes have been open-sourced on\nhttps://github.com/luchang1113/HEP-LLM-play-StarCraftII.",
    "pdf_url": "http://arxiv.org/pdf/2502.11122v1",
    "published": "2025-02-16T13:36:31+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11121v1",
    "title": "Reversible Data Hiding over Encrypted Images via Intrinsic Correlation in Block-Based Secret Sharing",
    "authors": [
      "Jianhui Zou",
      "Weijia Cao",
      "Shuang Yi",
      "Yifeng Zheng",
      "Zhongyun Hua"
    ],
    "abstract": "With the rapid advancements in information technology, reversible data hiding\nover encrypted images (RDH-EI) has become essential for secure image management\nin cloud services. However, existing RDH-EI schemes often suffer from high\ncomputational complexity, low embedding rates, and excessive data expansion.\nThis paper addresses these challenges by first analyzing the block-based secret\nsharing in existing schemes, revealing significant data redundancy within image\nblocks. Based on this observation, we propose two space-preserving methods: the\ndirect space-vacating method and the image-shrinking-based space-vacating\nmethod. Using these techniques, we design two novel RDH-EI schemes: a\nhigh-capacity RDH-EI scheme and a size-reduced RDH-EI scheme. The high-capacity\nRDH-EI scheme directly creates embedding space in encrypted images, eliminating\nthe need for complex space-vacating operations and achieving higher and more\nstable embedding rates. In contrast, the size-reduced RDH-EI scheme minimizes\ndata expansion by discarding unnecessary shares, resulting in smaller encrypted\nimages. Experimental results show that the high-capacity RDH-EI scheme\noutperforms existing methods in terms of embedding capacity, while the\nsize-reduced RDH-EI scheme excels in minimizing data expansion. Both schemes\nprovide effective solutions to the challenges in RDH-EI, offering promising\napplications in fields such as medical imaging and cloud storage.",
    "pdf_url": "http://arxiv.org/pdf/2502.11121v1",
    "published": "2025-02-16T13:35:12+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11120v1",
    "title": "Observation-Based Iterative Map for Solar Cycles. II. The Gnevyshev-Ohl Rule and its Generation Mechanism",
    "authors": [
      "Zi-Fan Wang",
      "Jie Jiang",
      "Jing-Xiu Wang"
    ],
    "abstract": "The Gnevyshev-Ohl (G-O) rule, also known as the even-odd effect, is an\nimportant observational phenomenon in solar cycles, suggesting that cycles with\neven indices tend to be followed by stronger cycles. The rule is considered to\nbe related to the solar dynamo, which drives the evolution of the Sun's\nlarge-scale magnetic field. However, observational studies of the G-O rule have\nrevealed inconsistencies, particularly regarding long-term variations and the\nunderlying physical mechanisms. In this study, we use an iterative map derived\nwithin the framework of the Babcock-Leighton (BL) dynamo to analyze the G-O\nrule. We investigate comprehensive and definitive forms of the G-O rule using\nboth a sufficiently large number of solar cycles and a limited number of solar\ncycles. Our findings indicate a higher probability for an arbitrary cycle to be\nfollowed by a stronger cycle instead of weaker, regardless of even or odd. Over\ntime spans comparable to historical observations, cycles exhibit periods that\nfollow both the G-O rule and the reversed G-O rule, without a statistically\nsignificant preference, consistent with the observed variability of the G-O\nrule. The occurrence of the reversed G-O rule is random, rather than periodic.\nThe G-O rule emerges as a result of the nonlinearity and stochasticity inherent\nin the BL mechanism. These results advance our understanding of the solar cycle\nand pave the way for improved solar dynamo modeling.",
    "pdf_url": "http://arxiv.org/pdf/2502.11120v1",
    "published": "2025-02-16T13:31:16+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11119v1",
    "title": "On an article published in the racsam",
    "authors": [
      "Nguyen Sum"
    ],
    "abstract": "In this Note, we provide the comments on the paper [A note on the hit problem\nfor the polynomial algebra in the case of odd primes and its application] which\nwas published in the RACSAM [Rev. Real. Acad. Cienc. Exactas. Fis. Nat. Ser.\nA-Mat. 118, 22 (2024)]. We will show that some of the results in this paper are\nnot new and others are false.",
    "pdf_url": "http://arxiv.org/pdf/2502.11119v1",
    "published": "2025-02-16T13:30:44+00:00",
    "categories": [
      "math.GM",
      "Primary 55S10, 55T15"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2502.17475v3",
    "title": "ECG-Expert-QA: A Benchmark for Evaluating Medical Large Language Models in Heart Disease Diagnosis",
    "authors": [
      "Xu Wang",
      "Jiaju Kang",
      "Puyu Han",
      "Yubao Zhao",
      "Qian Liu",
      "Liwenfei He",
      "Lingqiong Zhang",
      "Lingyun Dai",
      "Yongcheng Wang",
      "Jie Tao"
    ],
    "abstract": "We present ECG-Expert-QA, a comprehensive multimodal dataset for evaluating\ndiagnostic capabilities in electrocardiogram (ECG) interpretation. It combines\nreal-world clinical ECG data with systematically generated synthetic cases,\ncovering 12 essential diagnostic tasks and totaling 47,211 expert-validated QA\npairs. These encompass diverse clinical scenarios, from basic rhythm\nrecognition to complex diagnoses involving rare conditions and temporal\nchanges. A key innovation is the support for multi-turn dialogues, enabling the\ndevelopment of conversational medical AI systems that emulate clinician-patient\nor interprofessional interactions. This allows for more realistic assessment of\nAI models' clinical reasoning, diagnostic accuracy, and knowledge integration.\nConstructed through a knowledge-guided framework with strict quality control,\nECG-Expert-QA ensures linguistic and clinical consistency, making it a\nhigh-quality resource for advancing AI-assisted ECG interpretation. It\nchallenges models with tasks like identifying subtle ischemic changes and\ninterpreting complex arrhythmias in context-rich scenarios. To promote research\ntransparency and collaboration, the dataset, accompanying code, and prompts are\npublicly released at https://github.com/Zaozzz/ECG-Expert-QA",
    "pdf_url": "http://arxiv.org/pdf/2502.17475v3",
    "published": "2025-02-16T13:28:55+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11118v3",
    "title": "Observation-Based Iterative Map for Solar Cycles. I. Nature of Solar Cycle Variability",
    "authors": [
      "Zi-Fan Wang",
      "Jie Jiang",
      "Jing-Xiu Wang"
    ],
    "abstract": "Inter-cycle variations in the series of 11-year solar activity cycles have a\nsignificant impact on both the space environment and climate. Whether solar\ncycle variability is dominated by deterministic chaos or stochastic\nperturbations remains an open question. Distinguishing between the two\nmechanisms is crucial for predicting solar cycles. Here we reduce the solar\ndynamo process responsible for the solar cycle to a one-dimensional iterative\nmap, incorporating recent advance in the observed nonlinearity and\nstochasticity of the cycle. We demonstrate that deterministic chaos is absent\nin the nonlinear system, regardless of model parameters, if the generation of\nthe poloidal field follows an increase-then-saturate pattern as the cycle\nstrength increases. The synthesized solar cycles generated by the iterative map\nexhibit a probability density function (PDF) similar to that of observed normal\ncycles, supporting the dominant role of stochasticity in solar cycle\nvariability. The parameters governing nonlinearity and stochasticity profoundly\ninfluence the PDF. The iterative map provides a quick and effective tool for\npredicting the range, including uncertainty of the subsequent cycle strength\nwhen an ongoing cycle amplitude is known. Due to stochasticity, a solar cycle\nloses almost all its original information within 1 or 2 cycles. Although the\nsimplicity of the iterative map, the behaviors it exhibits are generic for the\nnonlinear system. Our results provide guidelines for analyzing solar dynamo\nmodels in terms of chaos and stochasticity, highlight the limitation in\npredicting solar cycle, and motivate further refinement of observational\nconstraints on nonlinear and stochastic processes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11118v3",
    "published": "2025-02-16T13:28:53+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11117v1",
    "title": "A Second-order method on graded meshes for fractional Laplacian via Riesz fractional derivative with a singular source term",
    "authors": [
      "Minghua Chen",
      "Jianxing Han",
      "Jiankang Shi",
      "Fan Yu"
    ],
    "abstract": "The high-order numerical analysis for fractional Laplacian via the Riesz\nfractional derivative, under the low regularity solution, has presented\nsignificant challenges in the past decades. To fill in this gap, we design a\ngrid mapping function on graded meshes to analyse the local truncation errors,\nwhich are far less than second-order convergence at the boundary layer. To\nrestore the second-order global errors, we construct an appropriate\nright-preconditioner for the resulting matrix algebraic equation. We prove that\nthe proposed scheme achieves second-order convergence on graded meshes even if\nthe source term is singular or hypersingular. Numerical experiments illustrate\nthe theoretical results. The proposed approach is applicable for\nmultidimensional fractional diffusion equations, gradient flows and nonlinear\nequations.",
    "pdf_url": "http://arxiv.org/pdf/2502.11117v1",
    "published": "2025-02-16T13:24:31+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "26A33, 26A30, 65L20"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11116v2",
    "title": "Gumbel Reranking: Differentiable End-to-End Reranker Optimization",
    "authors": [
      "Siyuan Huang",
      "Zhiyuan Ma",
      "Jintao Du",
      "Changhua Meng",
      "Weiqiang Wang",
      "Jingwen Leng",
      "Minyi Guo",
      "Zhouhan Lin"
    ],
    "abstract": "RAG systems rely on rerankers to identify relevant documents. However,\nfine-tuning these models remains challenging due to the scarcity of annotated\nquery-document pairs. Existing distillation-based approaches suffer from\ntraining-inference misalignment and fail to capture interdependencies among\ncandidate documents. To overcome these limitations, we reframe the reranking\nprocess as an attention-mask problem and propose Gumbel Reranking, an\nend-to-end training framework for rerankers aimed at minimizing the\ntraining-inference gap. In our approach, reranker optimization is reformulated\nas learning a stochastic, document-wise Top-$k$ attention mask using the Gumbel\nTrick and Relaxed Top-$k$ Sampling. This formulation enables end-to-end\noptimization by minimizing the overall language loss. Experiments across\nvarious settings consistently demonstrate performance gains, including a 10.4\\%\nimprovement in recall on HotpotQA for distinguishing indirectly relevant\ndocuments.",
    "pdf_url": "http://arxiv.org/pdf/2502.11116v2",
    "published": "2025-02-16T13:23:39+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2503.00009v1",
    "title": "Orbit recovery from invariants of low degree in representations of finite groups",
    "authors": [
      "Dan Edidin",
      "Josh Katz"
    ],
    "abstract": "Motivated by applications to equivariant neural networks and cryo-electron\nmicroscopy we consider the problem of recovering the generic orbit in a\nrepresentation of a finite group from invariants of low degree. The main result\nproved here is that invariants of degree at most three separate generic orbits\nin the regular representation of a finite group defined over any infinite\nfield. This answers a question posed in a 2023 ACHA paper of Bandeira et. al.\nWe also discuss this problem for subregular representations of the dihedral and\nsymmetric groups.",
    "pdf_url": "http://arxiv.org/pdf/2503.00009v1",
    "published": "2025-02-16T13:21:47+00:00",
    "categories": [
      "math.RT",
      "cs.IT",
      "math.IT",
      "94A12, 13A50"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11115v3",
    "title": "Are Generative Models Underconfident? Better Quality Estimation with Boosted Model Probability",
    "authors": [
      "Tu Anh Dinh",
      "Jan Niehues"
    ],
    "abstract": "Quality Estimation (QE) is estimating quality of the model output during\ninference when the ground truth is not available. Deriving output quality from\nthe models' output probability is the most trivial and low-effort way. However,\nwe show that the output probability of text-generation models can appear\nunderconfident. At each output step, there can be multiple correct options,\nmaking the probability distribution spread out more. Thus, lower probability\ndoes not necessarily mean lower output quality. Due to this observation, we\npropose a QE approach called BoostedProb, which boosts the model's confidence\nin cases where there are multiple viable output options. With no increase in\ncomplexity, BoostedProb is notably better than raw model probability in\ndifferent settings, achieving on average +0.194 improvement in Pearson\ncorrelation to ground-truth quality. It also comes close to or outperforms more\ncostly approaches like supervised or ensemble-based QE in certain settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.11115v3",
    "published": "2025-02-16T13:12:31+00:00",
    "categories": [
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11114v2",
    "title": "Beyond Pairwise: Global Zero-shot Temporal Graph Generation",
    "authors": [
      "Alon Eirew",
      "Kfir Bar",
      "Ido Dagan"
    ],
    "abstract": "Temporal relation extraction (TRE) is a fundamental task in natural language\nprocessing (NLP) that involves identifying the temporal relationships between\nevents in a document. Despite the advances in large language models (LLMs),\ntheir application to TRE remains limited. Most existing approaches rely on\npairwise classification, where event pairs are classified in isolation, leading\nto computational inefficiency and a lack of global consistency in the resulting\ntemporal graph. In this work, we propose a novel zero-shot method for TRE that\ngenerates a document's complete temporal graph in a single step, followed by\ntemporal constraint optimization to refine predictions and enforce temporal\nconsistency across relations. Additionally, we introduce OmniTemp, a new\ndataset with complete annotations for all pairs of targeted events within a\ndocument. Through experiments and analyses, we demonstrate that our method\noutperforms existing zero-shot approaches and offers a competitive alternative\nto supervised TRE models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11114v2",
    "published": "2025-02-16T13:06:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11113v2",
    "title": "Valuable Hallucinations: Realizable Non-realistic Propositions",
    "authors": [
      "Qiucheng Chen",
      "Bo Wang"
    ],
    "abstract": "This paper introduces the first formal definition of valuable hallucinations\nin large language models (LLMs), addressing a gap in the existing literature.\nWe provide a systematic definition and analysis of hallucination value,\nproposing methods for enhancing the value of hallucinations. In contrast to\nprevious works, which often treat hallucinations as a broad flaw, we focus on\nthe potential value that certain types of hallucinations can offer in specific\ncontexts. Hallucinations in LLMs generally refer to the generation of\nunfaithful, fabricated, inconsistent, or nonsensical content. Rather than\nviewing all hallucinations negatively, this paper gives formal representations\nand manual judgments of \"valuable hallucinations\" and explores how realizable\nnon-realistic propositions--ideas that are not currently true but could be\nachievable under certain conditions--can have constructive value. We present\nexperiments using the Qwen2.5 model and HalluQA dataset, employing ReAct\nprompting (which involves reasoning, confidence assessment, and answer\nverification) to control and optimize hallucinations. Our findings show that\nReAct prompting results in a 5.12\\% reduction in overall hallucinations and an\nincrease in the proportion of valuable hallucinations from 6.45\\% to 7.92\\%.\nThese results demonstrate that systematically controlling hallucinations can\nimprove their usefulness without compromising factual reliability.",
    "pdf_url": "http://arxiv.org/pdf/2502.11113v2",
    "published": "2025-02-16T12:59:11+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11112v1",
    "title": "Parametric Analysis of Network Evolution Processes",
    "authors": [
      "Peter Williams",
      "Zhan Chen"
    ],
    "abstract": "We present a comprehensive parametric analysis of node and edge lifetimes\nprocesses in two large-scale collaboration networks: the Microsoft Academic\nGraph (1800-2020) and Internet Movie Database (1900-2020). Node and edge\nlifetimes (career and collaboration durations) follow Weibull distributions\nwith consistent shape parameters ($k \\approx 0.2$ for academic, $k \\approx 0.5$\nfor entertainment careers) across centuries of evolution. These distributions\npersist despite dramatic changes in network size and structure. Edge processes\nshow domain-specific evolution: academic collaboration durations increase over\ntime (power-law index $1.6$ to $2.3$) while entertainment collaborations\nmaintain more stable patterns (index $2.6$ to $2.1$). These findings indicate\nthat while career longevity exhibits consistent patterns, collaboration\ndynamics appear to be influenced by domain-specific factors. The results\nprovide new constraints for models of social network evolution, requiring\nincorporation of both universal lifetime distributions and domain-specific\ngrowth dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2502.11112v1",
    "published": "2025-02-16T12:58:03+00:00",
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11111v1",
    "title": "A Novel Quaternary Decoder Design Utilizing 32nm CMOS and GNRFET Technology for Enhanced High-Density Memory Applications",
    "authors": [
      "Anindita Chattopadhyay",
      "Pooja Desai",
      "Vishwas P",
      "Vasundhara Patel K. S"
    ],
    "abstract": "Multi-Valued Logic (MVL) has more than one logic level defined to represent\ndata whereas binary logic has 2 logic levels. It has been shown that the MVL\ncircuits use the circuit resources more effectively at different voltage levels\nwith less circuitry and greater efficiency. Recently, graphene nano-ribbon\nfield effect transistor (GNRFET) has drawn a lot of interest due to its higher\nelectron mobility. This paper presents quaternary decoder implemented in GNRFET\nand analyzed latency, power, performance etc. also compared the power and delay\ncharacteristics of the design implemented both in CMOS and Graphene Nano Ribbon\nField Effect Transistor (GNRFET) in the 32nm technology node.",
    "pdf_url": "http://arxiv.org/pdf/2502.11111v1",
    "published": "2025-02-16T12:54:45+00:00",
    "categories": [
      "cs.DL"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11110v1",
    "title": "Ramp Up NTT in Record Time using GPU-Accelerated Algorithms and LLM-based Code Generation",
    "authors": [
      "Yu Cui",
      "Hang Fu",
      "Licheng Wang",
      "Haibin Zhang"
    ],
    "abstract": "Homomorphic encryption (HE) is a core building block in privacy-preserving\nmachine learning (PPML), but HE is also widely known as its efficiency\nbottleneck. Therefore, many GPU-accelerated cryptographic schemes have been\nproposed to improve the performance of HE. However, these methods often require\ncomplex modifications tailored to specific algorithms and are tightly coupled\nwith specific GPU and operating systems. It is interesting to ask how to\ngenerally offer more practical GPU-accelerated cryptographic algorithm\nimplementations. Given the powerful code generation capabilities of large\nlanguage models (LLMs), we aim to explore their potential to automatically\ngenerate practical GPU-friendly algorithm code using CPU-friendly code. In this\npaper, we focus on number theoretic transform (NTT) -- the core mechanism of\nHE. We first develop and optimize a GPU-friendly NTT (GNTT) family that\nexploits PyTorch's fast matrix computation and precomputation, achieving an\napproximately 62x speedup -- a significant boost over existing ones. Then we\nexplore GPU-friendly code generation using various LLMs, including DeepSeek-R1,\nOpenAI o1 and o3-mini. We discover many interesting findings throughout the\nprocess. For instance, somewhat surprisingly, our experiments demonstrate that\nDeepSeek-R1 significantly outperforms OpenAI o3-mini and o1, but still cannot\nbeat our optimized protocol. The findings provide valuable insights for\nturbocharging PPML and enhancing code generation capabilities of LLMs. Codes\nare available at: https://github.com/LMPC-Lab/GenGPUCrypto.",
    "pdf_url": "http://arxiv.org/pdf/2502.11110v1",
    "published": "2025-02-16T12:53:23+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11109v1",
    "title": "Explosive Growth in Large-Scale Collaboration Networks",
    "authors": [
      "Peter Williams",
      "Zhan Chen"
    ],
    "abstract": "We analyse the evolution of two large collaboration networks: the Microsoft\nAcademic Graph (1800-2020) and Internet Movie Database (1900-2020), comprising\n$2.72 \\times 10^8$ and $1.88 \\times 10^6$ nodes respectively. The networks show\nsuper-linear growth, with node counts following power laws $N(t) \\propto\nt^{\\alpha}$ where $\\alpha = 2.3$ increasing to $3.1$ after 1950 (MAG) and\n$\\alpha = 1.8$ (IMDb). Node and edge processes maintain stable but noisy\ntimescale ratios ($\\tau_N/\\tau_E \\approx 2.8 \\pm 0.3$ MAG, $2.3 \\pm 0.2$ IMDb).\nThe probability of waiting a time $t$ between successive collaborations was\nfound to be scale-free, $P(t) \\propto t^{-\\gamma}$, with indices evolving from\n$\\gamma \\approx 2.3$ to $1.6$ (MAG) and $2.6$ to $2.1$ (IMDb). Academic\ncollaboration sizes increased from $1.2$ to $5.8$ authors per paper, while\nentertainment collaborations remained more stable ($3.2$ to $4.5$ actors).\nThese observations indicate that current network models might be enhanced by\nconsidering accelerating growth, coupled timescales, and environmental\ninfluence, while explaining stable local properties.",
    "pdf_url": "http://arxiv.org/pdf/2502.11109v1",
    "published": "2025-02-16T12:53:03+00:00",
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11108v1",
    "title": "Knowledge Graph-Driven Retrieval-Augmented Generation: Integrating Deepseek-R1 with Weaviate for Advanced Chatbot Applications",
    "authors": [
      "Alexandru Lecu",
      "Adrian Groza",
      "Lezan Hawizy"
    ],
    "abstract": "Large language models (LLMs) have significantly advanced the field of natural\nlanguage generation. However, they frequently generate unverified outputs,\nwhich compromises their reliability in critical applications. In this study, we\npropose an innovative framework that combines structured biomedical knowledge\nwith LLMs through a retrieval-augmented generation technique. Our system\ndevelops a thorough knowledge graph by identifying and refining causal\nrelationships and named entities from medical abstracts related to age-related\nmacular degeneration (AMD). Using a vector-based retrieval process and a\nlocally deployed language model, our framework produces responses that are both\ncontextually relevant and verifiable, with direct references to clinical\nevidence. Experimental results show that this method notably decreases\nhallucinations, enhances factual precision, and improves the clarity of\ngenerated responses, providing a robust solution for advanced biomedical\nchatbot applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11108v1",
    "published": "2025-02-16T12:52:28+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11107v3",
    "title": "Revisiting Weak-to-Strong Generalization in Theory and Practice: Reverse KL vs. Forward KL",
    "authors": [
      "Wei Yao",
      "Wenkai Yang",
      "Ziqiao Wang",
      "Yankai Lin",
      "Yong Liu"
    ],
    "abstract": "As large language models advance toward superhuman performance, ensuring\ntheir alignment with human values and abilities grows increasingly complex.\nWeak-to-strong generalization offers a promising approach by leveraging\npredictions from weaker models to guide stronger systems, but its effectiveness\ncould be constrained by the inherent noise and inaccuracies in these weak\npredictions. To address this, we propose a theoretically grounded approach that\nreplaces forward KL divergence-whose mass-covering behavior risks overfitting\nto imperfect weak signals-with reverse KL divergence. Reverse KL divergence's\nzero-forcing effect prioritizes high-confidence predictions, effectively\nmitigating the influence of unreliable weak supervision. Theoretically, we\nextend existing bounds and derive tighter lower bounds for both forward and\nreverse KL divergence, establishing that reverse KL achieves at least\ncomparable guarantees to forward KL. Notably, when a sufficiently pre-trained\nstrong model is fine-tuned on the last linear layer, reverse KL guarantees that\nit outperforms its weak supervisor by the magnitude of their disagreement.\nEmpirically, we demonstrate that reverse KL and reverse cross-entropy enable\nstrong models to successfully outperform those trained with forward KL and\nstandard cross-entropy across most settings, highlighting the practical\nadvantages of these reverse losses.",
    "pdf_url": "http://arxiv.org/pdf/2502.11107v3",
    "published": "2025-02-16T12:50:20+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11106v1",
    "title": "Point-group symmetry enriched topological orders",
    "authors": [
      "Zhaoyang Ding",
      "Yang Qi"
    ],
    "abstract": "We study the classification of two-dimensional (2D) topological orders\nenriched by point-group symmetries, by generalizing the folding appraoch which\nwas previously developed for mirror-symmetry-enriched topological orders. We\nfold the 2D plane hosting the topological order into the foundamental domain of\nthe group group, which is a sector with an angle $2\\pi/n$ for the cyclic point\ngroup $C_n$ and a sector with an angle $\\pi/n$ for the dihedral point group\n$D_{2n}$, and the point-group symmetries becomes onsite unitary symmetries on\nthe sector. The enrichment of the point-group symmetries is then fully encoded\nat the boundary of the sector and the apex of the section, which forms a\njunction between the two boundaries. The mirror-symmetry enrichment encoded on\nthe boundaries is analyzed by the classification theory of symmetric gapped\nboundaries, and the point-group-symmetry enrichment encoded on the junction is\nanalyzed by a framework for classifying symmetric gapped junctions between\nboundaries which we develop in this work. We show that at the junction, there\nare two potential obstructions, which we refer to as an $H^1$ obstruction and\nan $H^2$ obstruction, respectively. When the obstruction vanishes, the\njunction, and therefore the point-group-symmetry-enriched topological orders,\nare classified by an $H^0$ cohomology class and an $H^1$ cohomology class,\nwhich can be understood as an additional Abelian anyon and a symmetry charge\nattached to the rotation center, respectively. These results are consistent\nwith the classification of onsite-symmetry-enriched topological orders, where\nthe $H^1$ and $H^2$ obstructions and the junction corresponds to the $H^3$ and\n$H^4$ obstructions for onsite symmetries, respectively.",
    "pdf_url": "http://arxiv.org/pdf/2502.11106v1",
    "published": "2025-02-16T12:47:30+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.11105v2",
    "title": "Graceful forgetting: Memory as a process",
    "authors": [
      "Alain de Cheveign"
    ],
    "abstract": "A rational theory of memory is proposed to explain how we can accommodate\nunbounded sensory input within bounded storage space. Memory is stored as\nstatistics, organized into complex structures that are constantly summarized\nand compressed to make room for new input. This process, driven by space\nconstraints, is guided by heuristics that optimize the memory for future needs.\nSensory input is rapidly encoded as simple statistics that are more slowly\nelaborated into more abstract constructs. This theory differs from previous\naccounts of memory by (a) its reliance on statistics, (b) its use of heuristics\nto guide the choice of statistics, and (c) the emphasis on memory as a process\nthat is intensive, complex, and expensive. The theory is intended as an aid to\nmake sense of our extensive knowledge of memory, and bring us closer to an\nunderstanding of memory in functional and mechanistic terms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11105v2",
    "published": "2025-02-16T12:46:34+00:00",
    "categories": [
      "q-bio.NC",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11104v1",
    "title": "Enhancing Cross-Tokenizer Knowledge Distillation with Contextual Dynamical Mapping",
    "authors": [
      "Yijie Chen",
      "Yijin Liu",
      "Fandong Meng",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ],
    "abstract": "Knowledge Distillation (KD) has emerged as a prominent technique for model\ncompression. However, conventional KD approaches primarily focus on homogeneous\narchitectures with identical tokenizers, constraining their applicability in\ncross-architecture scenarios. As for the cross-tokenizer KD, the differences in\nthe tokenizers give rise to two fundamental challenges: (1) sequence\nmisalignment caused by divergent tokenization strategies, and (2) mismatched\nvocabulary size and composition. While existing probability-matching methods\nattempt to address these issues, their efficacy remains limited due to\nsuboptimal alignment in both the sequence and vocabulary aspects. To overcome\nthese limitations, we propose Contextual Dynamic Mapping (CDM), a novel\ncross-tokenizer distillation framework that employs contextual information to\nenhance sequence alignment precision and dynamically improves vocabulary\nmapping. We evaluated the effectiveness of our approach across five advanced\nand widely-used model families (i.e, LLama3, Phi3, Gemma2, OPT and Qwen2),\nwhich were configured into three distinct teacher-student pairs. Our method\nshows significant advantages over existing cross-tokenizer distillation\nbaselines across diverse benchmarks, including instruction-following, code\ngeneration and math. Notably, our analysis reveals that combining conventional\nsame-tokenizer distillation and cross-tokenizer distillation through CDM yields\nfurther performance improvements. The code is available at\nhttps://github.com/pppa2019/ContexualDynamicMapping",
    "pdf_url": "http://arxiv.org/pdf/2502.11104v1",
    "published": "2025-02-16T12:46:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11103v1",
    "title": "Repeating fast radio bursts from synchrotron maser radiation in localized plasma blobs: Application to FRB 20121102A",
    "authors": [
      "Xiao Li",
      "Fen Lyu",
      "Hai Ming Zhang",
      "Can-Min Deng",
      "En-Wei Liang"
    ],
    "abstract": "The radiation physics of repeating fast radio bursts (FRBs) remains\nenigmatic. Motivated by the observed narrow-banded emission spectrum and\nambiguous fringe pattern of the spectral peak frequency ($\\nu_{\\rm pk}$)\ndistribution of some repeating FRBs, such as FRB 20121102A, we propose that the\nbursts from repeating FRBs arise from synchrotron maser radiation in localized\nblobs within weakly magnetized plasma that relativistically moves toward\nobservers. Assuming the plasma moves toward the observers with a bulk Lorentz\nfactor of $\\Gamma=100$ and the electron distribution in an individual blob is\nmonoenergetic ($\\gamma_{\\rm e}\\sim300$), our analysis shows that bright and\nnarrow-banded radio bursts with peak flux density $\\sim$ 1 ${\\rm Jy}$ at peak\nfrequency ($\\nu_{\\rm pk}$) $\\sim 3.85$ GHz can be produced by the synchrotron\nmaser emission if the plasma blob has a magnetization factor of\n$\\sigma\\sim10^{-5}$ and a frequency of $\\nu_{\\rm P}\\sim 4.5$ MHz. The spectrum\nof bursts with lower $\\nu_{\\rm pk}$ tends to be narrower. Applying our model to\nthe bursts of FRB 20121102A, the distributions of both the observed $\\nu_{\\rm\npk}$ and isotropic energy $E_{\\rm iso}$ detected by the Arecibo telescope at\nthe L band and the Green Bank Telescope at the C band are successfully\nreproduced. We find that the $\\nu_{\\rm P}$ distribution exhibits several peaks,\nsimilar to those observed in the $\\nu_{\\rm pk}$ distribution of FRB 20121102A.\nThis implies that the synchrotron maser emission in FRB 20121102A is triggered\nin different plasma blobs with varying $\\nu_{\\rm P}$, likely due to the\ninhomogeneity of relativistic electron number density.",
    "pdf_url": "http://arxiv.org/pdf/2502.11103v1",
    "published": "2025-02-16T12:43:35+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11102v2",
    "title": "OptMATH: A Scalable Bidirectional Data Synthesis Framework for Optimization Modeling",
    "authors": [
      "Hongliang Lu",
      "Zhonglin Xie",
      "Yaoyu Wu",
      "Can Ren",
      "Yuxuan Chen",
      "Zaiwen Wen"
    ],
    "abstract": "Despite the rapid development of large language models (LLMs), a fundamental\nchallenge persists: the lack of high-quality optimization modeling datasets\nhampers LLMs' robust modeling of practical optimization problems from natural\nlanguage descriptions (NL). This data scarcity also contributes to the\ngeneralization difficulties experienced by learning-based methods. To address\nthese challenges, we propose a scalable framework for synthesizing a\nhigh-quality dataset, named OptMATH. Starting from curated seed data with\nmathematical formulations (MF), this framework automatically generates problem\ndata (PD) with controllable complexity. Then, a back-translation step is\nemployed to obtain NL. To verify the correspondence between the NL and the PD,\na forward modeling step followed by rejection sampling is used. The accepted\npairs constitute the training part of OptMATH. Then a collection of rejected\npairs is identified and further filtered. This collection serves as a new\nbenchmark for optimization modeling, containing difficult instances whose\nlengths are much longer than these of NL4OPT and MAMO. Through extensive\nexperiments, we demonstrate that models of various sizes (0.5B-32B parameters)\ntrained on OptMATH achieve superior results on multiple modeling benchmarks,\nthereby validating the effectiveness and scalability of our approach. Our\ndataset is publicly available at https://github.com/AuroraLHL/OptMATH.",
    "pdf_url": "http://arxiv.org/pdf/2502.11102v2",
    "published": "2025-02-16T12:38:37+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.12204v2",
    "title": "Predicting Depression in Screening Interviews from Interactive Multi-Theme Collaboration",
    "authors": [
      "Xianbing Zhao",
      "Yiqing Lyu",
      "Di Wang",
      "Buzhou Tang"
    ],
    "abstract": "Automatic depression detection provides cues for early clinical intervention\nby clinicians. Clinical interviews for depression detection involve dialogues\ncentered around multiple themes. Existing studies primarily design end-to-end\nneural network models to capture the hierarchical structure of clinical\ninterview dialogues. However, these methods exhibit defects in modeling the\nthematic content of clinical interviews: 1) they fail to capture intra-theme\nand inter-theme correlation explicitly, and 2) they do not allow clinicians to\nintervene and focus on themes of interest. To address these issues, this paper\nintroduces an interactive depression detection framework. This framework\nleverages in-context learning techniques to identify themes in clinical\ninterviews and then models both intra-theme and inter-theme correlation.\nAdditionally, it employs AI-driven feedback to simulate the interests of\nclinicians, enabling interactive adjustment of theme importance. PDIMC achieves\nabsolute improvements of 35\\% and 12\\% compared to the state-of-the-art on the\ndepression detection dataset DAIC-WOZ, which demonstrates the effectiveness of\nmodeling theme correlation and incorporating interactive external feedback.",
    "pdf_url": "http://arxiv.org/pdf/2502.12204v2",
    "published": "2025-02-16T12:37:16+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11101v1",
    "title": "CacheFocus: Dynamic Cache Re-Positioning for Efficient Retrieval-Augmented Generation",
    "authors": [
      "Kun-Hui Lee",
      "Eunhwan Park",
      "Donghoon Han",
      "Seung-Hoon Na"
    ],
    "abstract": "Large Language Models (LLMs) excel across a variety of language tasks yet are\nconstrained by limited input lengths and high computational costs. Existing\napproaches\\textemdash such as relative positional encodings (e.g., RoPE, ALiBi)\nand sliding window mechanisms\\textemdash partially alleviate these issues but\noften require additional training or suffer from performance degradation with\nlonger inputs. In this paper, we introduce \\textbf{\\textit{CacheFocus}}, a\nmethod that enhances length normalization and reduces inference latency without\nany further training. Our approach leverages query-independent, offline caching\nto efficiently reuse a Context KV Cache Store. We address the amplification of\nabnormal token distributions problem by re-positioning cached keys and\nintroducing Layer-Adaptive Cache Pruning to discard low-relevance caches during\npre-filling. Additionally, our Adaptive Positional Allocation Strategy\ndynamically reassigns cache positions to maximize the use of the available\npositional encoding range. Experiments on the Natural Questions and TriviaQA\ndatasets demonstrate that CacheFocus outperforms alternative methods even when\ninputs exceed the $4$K limit of the \\texttt{LLaMA-2} model, emphasizing its\npractical effectiveness for long-context LLMs. Moreover, even with large\nmaximum input length of \\texttt{Qwen2}, the performance of CacheFocus shows\nthat it maintains consistent performance even as the number of documents\nincreases, effectively managing long-text generation without degradation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11101v1",
    "published": "2025-02-16T12:33:16+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12203v1",
    "title": "An Interpretable Automated Mechanism Design Framework with Large Language Models",
    "authors": [
      "Jiayuan Liu",
      "Mingyu Guo",
      "Vincent Conitzer"
    ],
    "abstract": "Mechanism design has long been a cornerstone of economic theory, with\ntraditional approaches relying on mathematical derivations. Recently, automated\napproaches, including differentiable economics with neural networks, have\nemerged for designing payments and allocations. While both analytical and\nautomated methods have advanced the field, they each face significant\nweaknesses: mathematical derivations are not automated and often struggle to\nscale to complex problems, while automated and especially neural-network-based\napproaches suffer from limited interpretability. To address these challenges,\nwe introduce a novel framework that reformulates mechanism design as a code\ngeneration task. Using large language models (LLMs), we generate heuristic\nmechanisms described in code and evolve them to optimize over some evaluation\nmetrics while ensuring key design criteria (e.g., strategy-proofness) through a\nproblem-specific fixing process. This fixing process ensures any mechanism\nviolating the design criteria is adjusted to satisfy them, albeit with some\ntrade-offs in performance metrics. These trade-offs are factored in during the\nLLM-based evolution process. The code generation capabilities of LLMs enable\nthe discovery of novel and interpretable solutions, bridging the symbolic logic\nof mechanism design and the generative power of modern AI. Through rigorous\nexperimentation, we demonstrate that LLM-generated mechanisms achieve\ncompetitive performance while offering greater interpretability compared to\nprevious approaches. Notably, our framework can rediscover existing manually\ndesigned mechanisms and provide insights into neural-network based solutions\nthrough Programming-by-Example. These results highlight the potential of LLMs\nto not only automate but also enhance the transparency and scalability of\nmechanism design, ensuring safe deployment of the mechanisms in society.",
    "pdf_url": "http://arxiv.org/pdf/2502.12203v1",
    "published": "2025-02-16T12:33:03+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11100v3",
    "title": "Towards Achieving Concept Completeness for Textual Concept Bottleneck Models",
    "authors": [
      "Milan Bhan",
      "Yann Choho",
      "Pierre Moreau",
      "Jean-Noel Vittaut",
      "Nicolas Chesneau",
      "Marie-Jeanne Lesot"
    ],
    "abstract": "Textual Concept Bottleneck Models (TCBMs) are interpretable-by-design models\nfor text classification that predict a set of salient concepts before making\nthe final prediction. This paper proposes Complete Textual Concept Bottleneck\nModel (CT-CBM), a novel TCBM generator building concept labels in a fully\nunsupervised manner using a small language model, eliminating both the need for\npredefined human labeled concepts and LLM annotations. CT-CBM iteratively\ntargets and adds important and identifiable concepts in the bottleneck layer to\ncreate a complete concept basis. CT-CBM achieves striking results against\ncompetitors in terms of concept basis completeness and concept detection\naccuracy, offering a promising solution to reliably enhance interpretability of\nNLP classifiers.",
    "pdf_url": "http://arxiv.org/pdf/2502.11100v3",
    "published": "2025-02-16T12:28:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11099v1",
    "title": "Branching fraction, $CP$ asymmetry, and polarization in $B\\to$ decays with the modified perturbative QCD approach",
    "authors": [
      "Ru-Xuan Wang",
      "Mao-Zhi Yang"
    ],
    "abstract": "In this work, we examine the observables associated with the $B\\to\\rho\\rho$\ndecays, including branching fractions, $CP$ asymmetry parameters, and\nlongitudinal polarization fractions in the perturbative QCD (PQCD) approach\nwith a few improvements. The essential distinction between this study and\nprevious works lies in the introduction of an infrared cutoff at the critical\nscale $\\mu_c$, which is approximately at the scale of $1\\;\\text{GeV}$. The\ncontributions above the critical scale are calculated using the PQCD approach,\nconsistent with earlier studies, while the contributions below the scale\n$\\mu_c$ are regarded as nonperturbative and represented by some soft form\nfactors. In addition, the distribution amplitude of the $B$ meson, derived from\nthe relativistic potential model, and the contributions from the color-octet\nquark-antiquark components are also taken into account. With these\nmodifications, we find that the theoretical results agree well with the\nexperimental measurements for most observables, the introduction of the\ninfrared cutoff enhances the reliability of the perturbation calculations, and\nthe color-octet contributions play a key role in explaining the experimental\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2502.11099v1",
    "published": "2025-02-16T12:28:37+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11098v1",
    "title": "Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems",
    "authors": [
      "Zhao Wang",
      "Sota Moriyama",
      "Wei-Yao Wang",
      "Briti Gangopadhyay",
      "Shingo Takamatsu"
    ],
    "abstract": "Recent advancements in LLM-based multi-agent (LLM-MA) systems have shown\npromise, yet significant challenges remain in managing communication and\nrefinement when agents collaborate on complex tasks. In this paper, we propose\n\\textit{Talk Structurally, Act Hierarchically (TalkHier)}, a novel framework\nthat introduces a structured communication protocol for context-rich exchanges\nand a hierarchical refinement system to address issues such as incorrect\noutputs, falsehoods, and biases. \\textit{TalkHier} surpasses various types of\nSoTA, including inference scaling model (OpenAI-o1), open-source multi-agent\nmodels (e.g., AgentVerse), and majority voting strategies on current LLM and\nsingle-agent baselines (e.g., ReAct, GPT4o), across diverse tasks, including\nopen-domain question answering, domain-specific selective questioning, and\npractical advertisement text generation. These results highlight its potential\nto set a new standard for LLM-MA systems, paving the way for more effective,\nadaptable, and collaborative multi-agent frameworks. The code is available\nhttps://github.com/sony/talkhier.",
    "pdf_url": "http://arxiv.org/pdf/2502.11098v1",
    "published": "2025-02-16T12:26:58+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11097v1",
    "title": "Shear Particle Acceleration in Structured Gamma-Ray Burst Jets: II. Viewing Angle Effect on the Prompt Emission and Application to GRB 170817A",
    "authors": [
      "Zi-Qi Wang",
      "Xiao-Li Huang",
      "En-Wei Liang"
    ],
    "abstract": "Multi-messenger observations suggest that the gamma-ray burst on Aug. 17,\n2017 (GRB 170817A) resulted from off-axial observations of its structured jet,\nwhich consists of a narrow ultra-relativistic jet core surrounded by a wide\nmild-relativistic cocoon. In a serious paper, we explore the emission of\nshear-accelerated electrons in the mixed jet-cocoon (MJC) region in a series of\npapers. This paper focuses on the viewing angle effect for a structured jet by\nconsidering the emission from the shear-accelerated electrons. It is found that\nthe observed synchrotron emission peaks at the Infrared band and the\nsynchrotron self-Compton (SSC) emission peaks at the band of hundreds of keV.\nThey are not sensitive to the viewing angle. In the off-axis observations\nscenario, the prompt emission spectrum is dominated by the emission of the\nshear-accelerated electrons. The prompt gamma-ray spectrum of GRB 170817A can\nbe well explained with our model by setting the velocity of the inner edge of\nthe cocoon region as 0.9c, the magnetic field strength as 21 G, the injected\ninitial electron Lorentz factor as $10^3$, and the viewing angle as 0.44 rad.\nWe argue that the joint observations in the Infrared/optical and X-ray bands\nare critical to verify our model.",
    "pdf_url": "http://arxiv.org/pdf/2502.11097v1",
    "published": "2025-02-16T12:26:33+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11096v1",
    "title": "Mixture of Tunable Experts -- Behavior Modification of DeepSeek-R1 at Inference Time",
    "authors": [
      "Robert Dahlke",
      "Henrik Klagges",
      "Dan Zecha",
      "Benjamin Merkel",
      "Sven Rohr",
      "Fabian Klemm"
    ],
    "abstract": "We present the Mixture-of-Tunable-Experts (MoTE), a method that extends the\nMixture-of-Experts architecture of Large Language Models (LLMs). Without\nadditional training, MoTE enables meaningful and focused behavior changes in\nLLMs on-the-fly during inference time. By analyzing the digital LLM brain of\nDeepSeek-R1 using a technique we dub 'functional Token Resonance Imaging'\n(fTRI) -- inspired by fMRI and using prompts designed to elicit specific\nbehavior (e.g., 'What happened {time}{place}?') -- we empirically identify\ndistinctive experts associated with behaviors like refusal responses. Using\nMoTE we are able to intervene and control such specific behavior. We switched\noff the top 10 most refusal-relevant experts (0.07% of R1's 14,848 routed\nexperts), achieving a 52% refusal reduction on sensitive reference prompts\nwithout performance degradation on MT-Bench. Random expert deactivation\nresulted in smaller behavioral shifts with increased noise, whereas forced\nexpert activation led to significantly higher refusal rates. Our approach\nshares similarities with sparse autoencoders (SAEs) in terms of explainability\nand steerability. Unlike SAEs, MoTE does not require large training efforts, as\nwithin MoEs with a vast number of experts, specialization already emerged\nnaturally during pretraining. Our findings suggest that significant functional\nmechanisms in Mixture-of-Experts architectures can at least partially be\nlocalized in a small number of specific experts, rather than being distributed\nthroughout the model's weights. Expert subgroups can be tuned to trigger\nsignificant behavior variations, providing insights into the inner workings of\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11096v1",
    "published": "2025-02-16T12:24:39+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11095v3",
    "title": "A Survey of Large Language Models in Psychotherapy: Current Landscape and Future Directions",
    "authors": [
      "Hongbin Na",
      "Yining Hua",
      "Zimu Wang",
      "Tao Shen",
      "Beibei Yu",
      "Lilin Wang",
      "Wei Wang",
      "John Torous",
      "Ling Chen"
    ],
    "abstract": "Mental health is increasingly critical in contemporary healthcare, with\npsychotherapy demanding dynamic, context-sensitive interactions that\ntraditional NLP methods struggle to capture. Large Language Models (LLMs) offer\nsignificant potential for addressing this gap due to their ability to handle\nextensive context and multi-turn reasoning. This review introduces a conceptual\ntaxonomy dividing psychotherapy into interconnected stages--assessment,\ndiagnosis, and treatment--to systematically examine LLM advancements and\nchallenges. Our comprehensive analysis reveals imbalances in current research,\nsuch as a focus on common disorders, linguistic biases, fragmented methods, and\nlimited theoretical integration. We identify critical challenges including\ncapturing dynamic symptom fluctuations, overcoming linguistic and cultural\nbiases, and ensuring diagnostic reliability. Highlighting future directions, we\nadvocate for continuous multi-stage modeling, real-time adaptive systems\ngrounded in psychological theory, and diversified research covering broader\nmental disorders and therapeutic approaches, aiming toward more holistic and\nclinically integrated psychotherapy LLMs systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11095v3",
    "published": "2025-02-16T12:18:40+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11094v1",
    "title": "SyncSpeech: Low-Latency and Efficient Dual-Stream Text-to-Speech based on Temporal Masked Transformer",
    "authors": [
      "Zhengyan Sheng",
      "Zhihao Du",
      "Shiliang Zhang",
      "Zhijie Yan",
      "Yexin Yang",
      "Zhenhua Ling"
    ],
    "abstract": "This paper presents a dual-stream text-to-speech (TTS) model, SyncSpeech,\ncapable of receiving streaming text input from upstream models while\nsimultaneously generating streaming speech, facilitating seamless interaction\nwith large language models. SyncSpeech has the following advantages: Low\nlatency, as it begins generating streaming speech upon receiving the second\ntext token; High efficiency, as it decodes all speech tokens corresponding to\nthe each arrived text token in one step. To achieve this, we propose a temporal\nmasked transformer as the backbone of SyncSpeech, combined with token-level\nduration prediction to predict speech tokens and the duration for the next\nstep. Additionally, we design a two-stage training strategy to improve training\nefficiency and the quality of generated speech. We evaluated the SyncSpeech on\nboth English and Mandarin datasets. Compared to the recent dual-stream TTS\nmodels, SyncSpeech significantly reduces the first packet delay of speech\ntokens and accelerates the real-time factor. Moreover, with the same data\nscale, SyncSpeech achieves performance comparable to that of traditional\nautoregressive-based TTS models in terms of both speech quality and robustness.\nSpeech samples are available at\nhttps://SyncSpeech.github.io/}{https://SyncSpeech.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2502.11094v1",
    "published": "2025-02-16T12:14:17+00:00",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2502.11093v2",
    "title": "Text-Promptable Propagation for Referring Medical Image Sequence Segmentation",
    "authors": [
      "Runtian Yuan",
      "Mohan Chen",
      "Jilan Xu",
      "Ling Zhou",
      "Qingqiu Li",
      "Yuejie Zhang",
      "Rui Feng",
      "Tao Zhang",
      "Shang Gao"
    ],
    "abstract": "Referring Medical Image Sequence Segmentation (Ref-MISS) is a novel and\nchallenging task that aims to segment anatomical structures in medical image\nsequences (\\emph{e.g.} endoscopy, ultrasound, CT, and MRI) based on natural\nlanguage descriptions. This task holds significant clinical potential and\noffers a user-friendly advancement in medical imaging interpretation. Existing\n2D and 3D segmentation models struggle to explicitly track objects of interest\nacross medical image sequences, and lack support for nteractive, text-driven\nguidance. To address these limitations, we propose Text-Promptable Propagation\n(TPP), a model designed for referring medical image sequence segmentation. TPP\ncaptures the intrinsic relationships among sequential images along with their\nassociated textual descriptions. Specifically, it enables the recognition of\nreferred objects through cross-modal referring interaction, and maintains\ncontinuous tracking across the sequence via Transformer-based triple\npropagation, using text embeddings as queries. To support this task, we curate\na large-scale benchmark, Ref-MISS-Bench, which covers 4 imaging modalities and\n20 different organs and lesions. Experimental results on this benchmark\ndemonstrate that TPP consistently outperforms state-of-the-art methods in both\nmedical segmentation and referring video object segmentation.",
    "pdf_url": "http://arxiv.org/pdf/2502.11093v2",
    "published": "2025-02-16T12:13:11+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11092v1",
    "title": "Storing quantum coherence in a quantum dot nuclear spin ensemble for over 100 milliseconds",
    "authors": [
      "Harry E. Dyte",
      "Santanu Manna",
      "Saimon F. Covre da Silva",
      "Armando Rastelli",
      "Evgeny A. Chekhovich"
    ],
    "abstract": "States with long coherence are a crucial requirement for qubits and quantum\nmemories. Nuclear spins in epitaxial quantum dots are a great candidate,\noffering excellent isolation from external environments and on-demand coupling\nto optical flying qubits. However, coherence times are limited to $\\lesssim1$\nms by the dipole-dipole interactions between the nuclei and their quadrupolar\ncoupling to inhomogeneous crystal strain. Here, we combine strain engineering\nof the nuclear spin ensemble and tailored dynamical decoupling sequences to\nachieve nuclear spin coherence times exceeding 100 ms. Recently, a reversible\ntransfer of quantum information into nuclear spin ensembles has been\ndemonstrated in quantum dots. Our results provide a path to develop this\nconcept into a functioning solid-state quantum memory suitable for quantum\nrepeaters in optical quantum communication networks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11092v1",
    "published": "2025-02-16T12:13:03+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11091v1",
    "title": "A Program Logic for Under-approximating Worst-case Resource Usage",
    "authors": [
      "Ziyue Jin",
      "Di Wang"
    ],
    "abstract": "Understanding and predicting the worst-case resource usage is crucial for\nsoftware quality; however, existing methods either over-approximate with\npotentially loose bounds or under-approximate without asymptotic guarantees.\nThis paper presents a program logic to under-approximate worst-case resource\nusage, adapting incorrectness logic (IL) to reason quantitatively about\nresource consumption. We propose quantitative forward and backward\nunder-approximate (QFUA and QBUA) triples, which generalize IL to identify\nexecution paths leading to high resource usage. We also introduce a variant of\nQBUA that supports reasoning about high-water marks. Our logic is proven sound\nand complete with respect to a simple IMP-like language, and we demonstrate its\nutility through case studies involving arrays, pointers, and procedure calls.",
    "pdf_url": "http://arxiv.org/pdf/2502.11091v1",
    "published": "2025-02-16T12:11:05+00:00",
    "categories": [
      "cs.LO",
      "cs.PL"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11090v2",
    "title": "SafeDialBench: A Fine-Grained Safety Benchmark for Large Language Models in Multi-Turn Dialogues with Diverse Jailbreak Attacks",
    "authors": [
      "Hongye Cao",
      "Yanming Wang",
      "Sijia Jing",
      "Ziyue Peng",
      "Zhixin Bai",
      "Zhe Cao",
      "Meng Fang",
      "Fan Feng",
      "Boyan Wang",
      "Jiaheng Liu",
      "Tianpei Yang",
      "Jing Huo",
      "Yang Gao",
      "Fanyu Meng",
      "Xi Yang",
      "Chao Deng",
      "Junlan Feng"
    ],
    "abstract": "With the rapid advancement of Large Language Models (LLMs), the safety of\nLLMs has been a critical concern requiring precise assessment. Current\nbenchmarks primarily concentrate on single-turn dialogues or a single jailbreak\nattack method to assess the safety. Additionally, these benchmarks have not\ntaken into account the LLM's capability of identifying and handling unsafe\ninformation in detail. To address these issues, we propose a fine-grained\nbenchmark SafeDialBench for evaluating the safety of LLMs across various\njailbreak attacks in multi-turn dialogues. Specifically, we design a two-tier\nhierarchical safety taxonomy that considers 6 safety dimensions and generates\nmore than 4000 multi-turn dialogues in both Chinese and English under 22\ndialogue scenarios. We employ 7 jailbreak attack strategies, such as reference\nattack and purpose reverse, to enhance the dataset quality for dialogue\ngeneration. Notably, we construct an innovative assessment framework of LLMs,\nmeasuring capabilities in detecting, and handling unsafe information and\nmaintaining consistency when facing jailbreak attacks. Experimental results\nacross 17 LLMs reveal that Yi-34B-Chat and GLM4-9B-Chat demonstrate superior\nsafety performance, while Llama3.1-8B-Instruct and o3-mini exhibit safety\nvulnerabilities.",
    "pdf_url": "http://arxiv.org/pdf/2502.11090v2",
    "published": "2025-02-16T12:08:08+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11089v2",
    "title": "Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention",
    "authors": [
      "Jingyang Yuan",
      "Huazuo Gao",
      "Damai Dai",
      "Junyu Luo",
      "Liang Zhao",
      "Zhengyan Zhang",
      "Zhenda Xie",
      "Y. X. Wei",
      "Lean Wang",
      "Zhiping Xiao",
      "Yuqing Wang",
      "Chong Ruan",
      "Ming Zhang",
      "Wenfeng Liang",
      "Wangding Zeng"
    ],
    "abstract": "Long-context modeling is crucial for next-generation language models, yet the\nhigh computational cost of standard attention mechanisms poses significant\ncomputational challenges. Sparse attention offers a promising direction for\nimproving efficiency while maintaining model capabilities. We present NSA, a\nNatively trainable Sparse Attention mechanism that integrates algorithmic\ninnovations with hardware-aligned optimizations to achieve efficient\nlong-context modeling. NSA employs a dynamic hierarchical sparse strategy,\ncombining coarse-grained token compression with fine-grained token selection to\npreserve both global context awareness and local precision. Our approach\nadvances sparse attention design with two key innovations: (1) We achieve\nsubstantial speedups through arithmetic intensity-balanced algorithm design,\nwith implementation optimizations for modern hardware. (2) We enable end-to-end\ntraining, reducing pretraining computation without sacrificing model\nperformance. As shown in Figure 1, experiments show the model pretrained with\nNSA maintains or exceeds Full Attention models across general benchmarks,\nlong-context tasks, and instruction-based reasoning. Meanwhile, NSA achieves\nsubstantial speedups over Full Attention on 64k-length sequences across\ndecoding, forward propagation, and backward propagation, validating its\nefficiency throughout the model lifecycle.",
    "pdf_url": "http://arxiv.org/pdf/2502.11089v2",
    "published": "2025-02-16T11:53:44+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11088v1",
    "title": "Towards high-fidelity wind farm layout optimization using polynomial chaos expansion and Kriging model",
    "authors": [
      "Yi-Xiao Shao",
      "Zhen-Fan Wang",
      "Shine Win Naung",
      "Kai Zhang",
      "Yufeng Yao",
      "Dai Zhou"
    ],
    "abstract": "This paper presents a wind farm layout optimization framework that integrates\npolynomial chaos expansion, a Kriging model, and the expected improvement\nalgorithm. The proposed framework addresses the computational challenges\nassociated with high-fidelity wind farm simulations by significantly reducing\nthe number of function evaluations required for accurate annual energy\nproduction predictions. The polynomial chaos expansion-based prediction method\nachieves exceptional accuracy with reduced computational cost for over 96%,\nsignificantly lowering the expense of training the ensuing surrogate model. The\nKriging model, combined with a genetic algorithm, is used for surrogate-based\noptimization, achieving comparable performance to direct optimization at a\nmuch-reduced computational cost. The integration of the expected improvement\nalgorithm enhances the global optimization capability of the framework,\nallowing it to escape local optima and achieve results that are either nearly\nidentical to or even outperform those obtained through direct optimization. The\nfeasibility of the polynomial chaos expansion-Kriging framework is demonstrated\nthrough four case studies, including the optimization of wind farms with 8, 16,\nand 32 turbines using low-fidelity wake models, and a high-fidelity case using\ncomputational fluid dynamics simulations. The results show that the proposed\nframework is highly effective in optimizing wind farm layouts, significantly\nreducing computational costs while maintaining or improving the accuracy of\nannual energy production predictions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11088v1",
    "published": "2025-02-16T11:49:42+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11087v1",
    "title": "Stability for the Sobolev inequality in cones",
    "authors": [
      "Filomena Pacella",
      "Giulio Ciraolo",
      "Camilla Chiara Polvara"
    ],
    "abstract": "We prove a quantitative Sobolev inequality in cones of Bianchi-Egnell type,\nwhich implies a stability property. Our result holds for any cone as long as\nthe minimizers of the Sobolev quotient are nondegenerate, which is the case of\nmost cones. When the minimizers are the classical bubbles we have more precise\nresults. Finally, we show that local estimates are not enough to get the\noptimal constant for the quantitative Sobolev inequality.",
    "pdf_url": "http://arxiv.org/pdf/2502.11087v1",
    "published": "2025-02-16T11:49:09+00:00",
    "categories": [
      "math.AP",
      "49J40, 26D10, 35A23, 35J91, 35B33"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11086v1",
    "title": "Data Ecofeminism",
    "authors": [
      "Ana Valdivia"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI) is driving significant\nenvironmental impacts. The rapid development and deployment of increasingly\nlarger algorithmic models capable of analysing vast amounts of data are\ncontributing to rising carbon emissions, water withdrawal, and waste\ngeneration. Generative models often consume substantially more energy than\ntraditional models, with major tech firms increasingly turning to nuclear power\nto sustain these systems -- an approach that could have profound environmental\nconsequences.\n  This paper introduces seven data ecofeminist principles delineating a pathway\nfor developing technological alternatives of eco-societal transformations\nwithin the AI research context. Rooted in data feminism and ecofeminist\nframeworks, which interrogate about the historical and social construction of\nepistemologies underlying the hegemonic development of science and technology\nthat disrupt communities and nature, these principles emphasise the integration\nof social and environmental justice within a critical AI agenda. The paper\ncalls for an urgent reassessment of the GenAI innovation race, advocating for\necofeminist algorithmic and infrastructural projects that prioritise and\nrespect life, the people, and the planet.",
    "pdf_url": "http://arxiv.org/pdf/2502.11086v1",
    "published": "2025-02-16T11:47:50+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11085v1",
    "title": "Towards Data-Efficient Pretraining for Atomic Property Prediction",
    "authors": [
      "Yasir Ghunaim",
      "Hasan Abed Al Kader Hammoud",
      "Bernard Ghanem"
    ],
    "abstract": "This paper challenges the recent paradigm in atomic property prediction that\nlinks progress to growing dataset sizes and computational resources. We show\nthat pretraining on a carefully selected, task-relevant dataset can match or\neven surpass large-scale pretraining, while using as little as 1/24th of the\ncomputational cost. We introduce the Chemical Similarity Index (CSI), a novel\nmetric inspired by computer vision's Fr\\'echet Inception Distance, for\nmolecular graphs which quantifies the alignment between upstream pretraining\ndatasets and downstream tasks. By selecting the most relevant dataset with\nminimal CSI distance, we show that models pretrained on a smaller, focused\ndataset consistently outperform those pretrained on massive, mixed datasets\nsuch as JMP, even when those larger datasets include the relevant dataset.\nCounterintuitively, we also find that indiscriminately adding more data can\ndegrade model performance when the additional data poorly aligns with the task\nat hand. Our findings highlight that quality often outperforms quantity in\npretraining for atomic property prediction.",
    "pdf_url": "http://arxiv.org/pdf/2502.11085v1",
    "published": "2025-02-16T11:46:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11084v2",
    "title": "Rewrite to Jailbreak: Discover Learnable and Transferable Implicit Harmfulness Instruction",
    "authors": [
      "Yuting Huang",
      "Chengyuan Liu",
      "Yifeng Feng",
      "Yiquan Wu",
      "Chao Wu",
      "Fei Wu",
      "Kun Kuang"
    ],
    "abstract": "As Large Language Models (LLMs) are widely applied in various domains, the\nsafety of LLMs is increasingly attracting attention to avoid their powerful\ncapabilities being misused. Existing jailbreak methods create a forced\ninstruction-following scenario, or search adversarial prompts with prefix or\nsuffix tokens to achieve a specific representation manually or automatically.\nHowever, they suffer from low efficiency and explicit jailbreak patterns, far\nfrom the real deployment of mass attacks to LLMs. In this paper, we point out\nthat simply rewriting the original instruction can achieve a jailbreak, and we\nfind that this rewriting approach is learnable and transferable. We propose the\nRewrite to Jailbreak (R2J) approach, a transferable black-box jailbreak method\nto attack LLMs by iteratively exploring the weakness of the LLMs and\nautomatically improving the attacking strategy. The jailbreak is more efficient\nand hard to identify since no additional features are introduced. Extensive\nexperiments and analysis demonstrate the effectiveness of R2J, and we find that\nthe jailbreak is also transferable to multiple datasets and various types of\nmodels with only a few queries. We hope our work motivates further\ninvestigation of LLM safety. The code can be found at\nhttps://github.com/ythuang02/R2J/.",
    "pdf_url": "http://arxiv.org/pdf/2502.11084v2",
    "published": "2025-02-16T11:43:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2503.05715v1",
    "title": "The Butterfly Effect of Technology: How Various Factors accelerate or hinder the Arrival of Technological Singularity",
    "authors": [
      "Hooman Shababi"
    ],
    "abstract": "This article explores the concept of technological singularity and the\nfactors that could accelerate or hinder its arrival. The butterfly effect is\nused as a framework to understand how seemingly small changes in complex\nsystems can have significant and unpredictable outcomes. In section II, we\ndiscuss the various factors that could hasten the arrival of technological\nsingularity, such as advances in artificial intelligence and machine learning,\nbreakthroughs in quantum computing, progress in brain-computer interfaces and\nhuman augmentation, and development of nanotechnology and 3D printing. In\nsection III, we examine the factors that could delay or impede the arrival of\ntechnological singularity, including technical limitations and setbacks in AI\nand machine learning, ethical and societal concerns around AI and its impact on\njobs and privacy, lack of sufficient investment in research and development,\nand regulatory barriers and political instability. Section IV explores the\ninterplay of these factors and how they can impact the butterfly effect.\nFinally, in the conclusion, we summarize the key points discussed and emphasize\nthe importance of considering the butterfly effect in predicting the future of\ntechnology. We call for continued research and investment in technology to\nshape its future and mitigate potential risks.",
    "pdf_url": "http://arxiv.org/pdf/2503.05715v1",
    "published": "2025-02-16T11:38:35+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11083v1",
    "title": "Streamlining the Collaborative Chain of Models into A Single Forward Pass in Generation-Based Tasks",
    "authors": [
      "Yuanjie Lyu",
      "Chao Zhang",
      "Yuhao Chen",
      "Yong Chen",
      "Tong Xu"
    ],
    "abstract": "In Retrieval-Augmented Generation (RAG) and agent-based frameworks, the\n\"Chain of Models\" approach is widely used, where multiple specialized models\nwork sequentially on distinct sub-tasks. This approach is effective but\nincreases resource demands as each model must be deployed separately. Recent\nadvancements attempt to address this by applying prompt tuning, which allows a\nshared base model to adapt to multiple tasks with minimal parameter changes.\nHowever, a key challenge remains: intermediate outputs, passed between models\nas plain text, require recomputation of hidden states (i.e., Key and Value (KV)\nstates in Transformers) during inference. In this paper, we introduce FTHSS, a\nnovel prompt-tuning method that enables models to share KV hidden states,\neliminating redundant forward passes and reducing KV cache storage. By\nmodifying input and attention masks during training, FTHSS allows models to\neffectively utilize KV hidden states from prior models in both single- and\nmulti-round scenarios. Empirical results on four tasks show that FTHSS matches\nthe performance of traditional model chains while improving inference\nefficiency.",
    "pdf_url": "http://arxiv.org/pdf/2502.11083v1",
    "published": "2025-02-16T11:37:14+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11082v3",
    "title": "Toward Carnot efficient high output power heat engines using bubbly two-phase flow",
    "authors": [
      "Dror Miron",
      "Yuval Neumann",
      "Joseph Cassell",
      "Nir Feintuch",
      "Alexey Shinkarenko",
      "Carmel Rotschild"
    ],
    "abstract": "Thermodynamic gas power cycles achieving Carnot efficiency require isothermal\nexpansion, which is associated with slow processes and results in negligible\npower output. This study proposes a practical method for rapid near-isothermal\ngas expansion, facilitating efficient heat engines without sacrificing power.\nThe method involves bubble expansion in a heat transfer liquid, ensuring\nefficient and near-isothermal heat exchange. The mixture is accelerated through\na converging-diverging nozzle, converting thermal energy into kinetic energy,\nthereby rotating a reaction turbine for electricity generation. Nozzle\nexperiments with air and water yielded a polytropic index <1.052, enabling up\nto 71% more work extraction than adiabatic expansion. Simulations indicate that\nutilizing these nozzles for thrust generation enables decreasing heat transfer\nirreversibilities in the heat engine, consequently resulting in up to 22.6%\nhigher power output than an ideal heat engine based on the organic Rankine\ncycle. This work paves the way for an efficient and high-power heat-to-power\nsolution.",
    "pdf_url": "http://arxiv.org/pdf/2502.11082v3",
    "published": "2025-02-16T11:32:46+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11081v1",
    "title": "Classical elasticity meets quantum complexity: A connection from the holographic lens",
    "authors": [
      "Yuanceng Xu",
      "Wei-Jia Li"
    ],
    "abstract": "In this work, we explore the effects of shear deformations in a wide class of\nholographic amorphous solids. It is found that both the shear stress and the\ncomplexity of formation grow with the increase of the shear strain. Notably, in\nthe regime of very large shear, they exhibit coordinated behavior and adhere to\na universal scaling relation, uncovering a surprising connection between two\nseemingly unrelated aspects of amorphous systems. Furthermore, our findings\nalso provide a counterexample to the previous understanding that the complexity\nscales linearly with the Bekenstein-Hawking entropy for large static black\nholes.",
    "pdf_url": "http://arxiv.org/pdf/2502.11081v1",
    "published": "2025-02-16T11:30:18+00:00",
    "categories": [
      "hep-th",
      "cond-mat.soft",
      "gr-qc",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2502.11080v1",
    "title": "Boundedness of toric foliations",
    "authors": [
      "Chih-Wei Chang",
      "Yen-An Chen"
    ],
    "abstract": "We discuss boundedness of toric Fano foliations and connectedness of its\ndicritical and singular loci. Moreover, we show the set of interpolated\n$\\delta$-lcts for the toric foliations satisfies the descending chain\ncondition.",
    "pdf_url": "http://arxiv.org/pdf/2502.11080v1",
    "published": "2025-02-16T11:29:19+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.15771v2",
    "title": "Learning to Reason from Feedback at Test-Time",
    "authors": [
      "Yanyang Li",
      "Michael Lyu",
      "Liwei Wang"
    ],
    "abstract": "Solving complex tasks in a single attempt is challenging for large language\nmodels (LLMs). Iterative interaction with the environment and feedback is often\nrequired to achieve success, making effective feedback utilization a critical\ntopic. Existing approaches either struggle with length generalization or rely\non naive retries without leveraging prior information. In this paper, we\nintroduce FTTT, a novel paradigm that formulates feedback utilization as an\noptimization problem at test time. Additionally, we propose a learnable\ntest-time optimizer, OpTune, to effectively exploit feedback. Experiments on\ntwo LLMs across four reasoning datasets demonstrate that FTTT and OpTune\nachieve superior scalability and performance.",
    "pdf_url": "http://arxiv.org/pdf/2502.15771v2",
    "published": "2025-02-16T11:05:27+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11079v2",
    "title": "Phantom: Subject-consistent video generation via cross-modal alignment",
    "authors": [
      "Lijie Liu",
      "Tianxiang Ma",
      "Bingchuan Li",
      "Zhuowei Chen",
      "Jiawei Liu",
      "Gen Li",
      "Siyu Zhou",
      "Qian He",
      "Xinglong Wu"
    ],
    "abstract": "The continuous development of foundational models for video generation is\nevolving into various applications, with subject-consistent video generation\nstill in the exploratory stage. We refer to this as Subject-to-Video, which\nextracts subject elements from reference images and generates\nsubject-consistent videos following textual instructions. We believe that the\nessence of subject-to-video lies in balancing the dual-modal prompts of text\nand image, thereby deeply and simultaneously aligning both text and visual\ncontent. To this end, we propose Phantom, a unified video generation framework\nfor both single- and multi-subject references. Building on existing\ntext-to-video and image-to-video architectures, we redesign the joint\ntext-image injection model and drive it to learn cross-modal alignment via\ntext-image-video triplet data. The proposed method achieves high-fidelity\nsubject-consistent video generation while addressing issues of image content\nleakage and multi-subject confusion. Evaluation results indicate that our\nmethod outperforms other state-of-the-art closed-source commercial solutions.\nIn particular, we emphasize subject consistency in human generation, covering\nexisting ID-preserving video generation while offering enhanced advantages.",
    "pdf_url": "http://arxiv.org/pdf/2502.11079v2",
    "published": "2025-02-16T11:02:50+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11078v2",
    "title": "DEEPER Insight into Your User: Directed Persona Refinement for Dynamic Persona Modeling",
    "authors": [
      "Aili Chen",
      "Chengyu Du",
      "Jiangjie Chen",
      "Jinghan Xu",
      "Yikai Zhang",
      "Siyu Yuan",
      "Zulong Chen",
      "Liangyue Li",
      "Yanghua Xiao"
    ],
    "abstract": "To advance personalized applications such as recommendation systems and user\nbehavior prediction, recent research increasingly adopts large language models\n(LLMs) for human -readable persona modeling. In dynamic real -world scenarios,\neffective persona modeling necessitates leveraging streaming behavior data to\ncontinually optimize user personas. However, existing methods -whether\nregenerating personas or incrementally extending them with new behaviors -often\nfail to achieve sustained improvements in persona quality or future behavior\nprediction accuracy. To address this, we propose DEEPER, a novel approach for\ndynamic persona modeling that enables continual persona optimization.\nSpecifically, we enhance the model's direction -search capability through an\niterative reinforcement learning framework, allowing it to automatically\nidentify effective update directions and optimize personas using discrepancies\nbetween user behaviors and model predictions. Extensive experiments on dynamic\npersona modeling involving 4800 users across 10 domains highlight the superior\npersona optimization capabilities of DEEPER, delivering an impressive 32.2%\naverage reduction in user behavior prediction error over four update rounds\n-outperforming the best baseline by a remarkable 22.92%.",
    "pdf_url": "http://arxiv.org/pdf/2502.11078v2",
    "published": "2025-02-16T11:02:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11077v1",
    "title": "Maximum Power Transfer for Nonlinear State Space Systems",
    "authors": [
      "Arjan van der Schaft"
    ],
    "abstract": "The classical Maximum Power Transfer theorem of linear electrical network\ntheory is generalized to the setting of a nonlinear state space system\nconnected to a source. This yields a state space version of the input-output\noperator results of Wyatt (1988). Key tool in the analysis is the formulation\nof a Hamiltonian input-output system, which is closely related to Pontryagin's\nMaximum principle. The adjoint variational system incorporated in this system\ndefines an optimal load. The structure of such an optimal load is investigated\nfor classes of physical systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11077v1",
    "published": "2025-02-16T11:01:58+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11076v1",
    "title": "Imaging current flow and injection in scalable graphene devices through NV-magnetometry",
    "authors": [
      "Kaj Dockx",
      "Michele Buscema",
      "Saravana Kumar",
      "Tijmen van Ree",
      "Abbas Mohtashami",
      "Leon van Dooren",
      "Gabriele Bulgarini",
      "Richard van Rijn",
      "Clara I. Osorio",
      "Toeno van der Sar"
    ],
    "abstract": "The global electronic properties of solid-state devices are strongly affected\nby the microscopic spatial paths of charge carriers. Visualising these paths in\nnovel devices produced by scalable processes would provide a quality assessment\nmethod that can propel the device performance metrics towards commercial use.\nHere, we use high-resolution nitrogen-vacancy (NV) magnetometry to visualise\nthe charge flow in gold-contacted, single-layer graphene devices produced by\nscalable methods. Modulating the majority carrier type via field effect reveals\na strong asymmetry between the spatial current distributions in the electron\nand hole regimes that we attribute to an inhomogeneous microscopic potential\nlandscape, inaccessible to conventional measurement techniques. In addition, we\nobserve large, unexpected, differences in charge flow through nominally\nidentical gold-graphene contacts. Moreover, we find that the current transfer\ninto the graphene occurs several microns before the metal contact edge. Our\nfindings establish high-resolution NV-magnetometry as a key tool for\ncharacterizing scalable 2D material based devices, uncovering quality deficits\nof the material, substrate, and electrical contacts that are invisible to\nconventional methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.11076v1",
    "published": "2025-02-16T10:52:48+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "physics.app-ph",
      "physics.ins-det",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11075v2",
    "title": "Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models",
    "authors": [
      "Haoyang Li",
      "Xuejia Chen",
      "Zhanchao XU",
      "Darian Li",
      "Nicole Hu",
      "Fei Teng",
      "Yiming Li",
      "Luyu Qiu",
      "Chen Jason Zhang",
      "Qing Li",
      "Lei Chen"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nnatural language processing tasks, such as text generation and semantic\nunderstanding. However, their performance on numerical reasoning tasks, such as\nbasic arithmetic, numerical retrieval, and magnitude comparison, remains\nsurprisingly poor. This gap arises from their reliance on surface-level\nstatistical patterns rather than understanding numbers as continuous\nmagnitudes. Existing benchmarks primarily focus on either linguistic competence\nor structured mathematical problem-solving, neglecting fundamental numerical\nreasoning required in real-world scenarios. To bridge this gap, we propose\nNumericBench, a comprehensive benchmark to evaluate six fundamental numerical\ncapabilities: number recognition, arithmetic operations, contextual retrieval,\ncomparison, summary, and logical reasoning. NumericBench includes datasets\nranging from synthetic number lists to the crawled real-world data, addressing\nchallenges like long contexts, noise, and multi-step reasoning. Extensive\nexperiments on state-of-the-art LLMs, including GPT-4 and DeepSeek, reveal\npersistent weaknesses in numerical reasoning, highlighting the urgent need to\nimprove numerically-aware language modeling. The benchmark is released in:\nhttps://github.com/TreeAI-Lab/NumericBench.",
    "pdf_url": "http://arxiv.org/pdf/2502.11075v2",
    "published": "2025-02-16T10:48:28+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11074v1",
    "title": "Trace Ratio vs Ratio Trace methods for multi dimensionality reduction",
    "authors": [
      "Alaeddine Zahir",
      "Franck Dufrenois",
      "Khalide Jbilou",
      "Ahmed Ratnani"
    ],
    "abstract": "In this paper, we introduce a higher order approach for dimension reduction\nbased on the Trace Ratio problem. We show the existence and uniqueness of the\nsolution, and we provide a relationship between the Trace Ratio problem and the\nRatio Trace problem. We also propose a new algorithm to solve the Trace Ratio\nproblem. We apply the approach to generalize the Linear Discriminant Analysis\n(LDA) to higher order tensors. We provide some numerical experiments to\nillustrate the efficiency of the proposed method. The method is based on the\nEinstein product, and it is a generalization of the state-of-the-art trace\nbased DR methods to higher order tensors. The superiority of the Tensor-based\nmethods have been shown experimentally, which motivates us to extend the\nstate-of-the-art Ratio Trace based DR methods to higher order tensors via the\nEinstein product.",
    "pdf_url": "http://arxiv.org/pdf/2502.11074v1",
    "published": "2025-02-16T10:47:29+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.12202v2",
    "title": "To Think or Not to Think: Exploring the Unthinking Vulnerability in Large Reasoning Models",
    "authors": [
      "Zihao Zhu",
      "Hongbao Zhang",
      "Ruotong Wang",
      "Ke Xu",
      "Siwei Lyu",
      "Baoyuan Wu"
    ],
    "abstract": "Large Reasoning Models (LRMs) are designed to solve complex tasks by\ngenerating explicit reasoning traces before producing final answers. However,\nwe reveal a critical vulnerability in LRMs -- termed Unthinking Vulnerability\n-- wherein the thinking process can be bypassed by manipulating special\ndelimiter tokens. It is empirically demonstrated to be widespread across\nmainstream LRMs, posing both a significant risk and potential utility,\ndepending on how it is exploited. In this paper, we systematically investigate\nthis vulnerability from both malicious and beneficial perspectives. On the\nmalicious side, we introduce Breaking of Thought (BoT), a novel attack that\nenables adversaries to bypass the thinking process of LRMs, thereby\ncompromising their reliability and availability. We present two variants of\nBoT: a training-based version that injects backdoor during the fine-tuning\nstage, and a training-free version based on adversarial attack during the\ninference stage. As a potential defense, we propose thinking recovery alignment\nto partially mitigate the vulnerability. On the beneficial side, we introduce\nMonitoring of Thought (MoT), a plug-and-play framework that allows model owners\nto enhance efficiency and safety. It is implemented by leveraging the same\nvulnerability to dynamically terminate redundant or risky reasoning through\nexternal monitoring. Extensive experiments show that BoT poses a significant\nthreat to reasoning reliability, while MoT provides a practical solution for\npreventing overthinking and jailbreaking. Our findings expose an inherent flaw\nin current LRM architectures and underscore the need for more robust reasoning\nsystems in the future.",
    "pdf_url": "http://arxiv.org/pdf/2502.12202v2",
    "published": "2025-02-16T10:45:56+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11073v1",
    "title": "Demystifying Hateful Content: Leveraging Large Multimodal Models for Hateful Meme Detection with Explainable Decisions",
    "authors": [
      "Ming Shan Hee",
      "Roy Ka-Wei Lee"
    ],
    "abstract": "Hateful meme detection presents a significant challenge as a multimodal task\ndue to the complexity of interpreting implicit hate messages and contextual\ncues within memes. Previous approaches have fine-tuned pre-trained\nvision-language models (PT-VLMs), leveraging the knowledge they gained during\npre-training and their attention mechanisms to understand meme content.\nHowever, the reliance of these models on implicit knowledge and complex\nattention mechanisms renders their decisions difficult to explain, which is\ncrucial for building trust in meme classification. In this paper, we introduce\nIntMeme, a novel framework that leverages Large Multimodal Models (LMMs) for\nhateful meme classification with explainable decisions. IntMeme addresses the\ndual challenges of improving both accuracy and explainability in meme\nmoderation. The framework uses LMMs to generate human-like, interpretive\nanalyses of memes, providing deeper insights into multimodal content and\ncontext. Additionally, it uses independent encoding modules for both memes and\ntheir interpretations, which are then combined to enhance classification\nperformance. Our approach addresses the opacity and misclassification issues\nassociated with PT-VLMs, optimizing the use of LMMs for hateful meme detection.\nWe demonstrate the effectiveness of IntMeme through comprehensive experiments\nacross three datasets, showcasing its superiority over state-of-the-art models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11073v1",
    "published": "2025-02-16T10:45:40+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11072v1",
    "title": "Box Confidence Depth: simulation-based inference with hyper-rectangles",
    "authors": [
      "Elena Bortolato",
      "Laura Ventura"
    ],
    "abstract": "This work presents a novel simulation-based approach for constructing\nconfidence regions in parametric models, which is particularly suited for\ngenerative models and situations where limited data and conventional asymptotic\napproximations fail to provide accurate results. The method leverages the\nconcept of data depth and depends on creating random hyper-rectangles, i.e.\nboxes, in the sample space generated through simulations from the model,\nvarying the input parameters. A probabilistic acceptance rule allows to\nretrieve a Depth-Confidence Distribution for the model parameters from which\npoint estimators as well as calibrated confidence sets can be read-off. The\nmethod is designed to address cases where both the parameters and test\nstatistics are multivariate.",
    "pdf_url": "http://arxiv.org/pdf/2502.11072v1",
    "published": "2025-02-16T10:42:37+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.11071v5",
    "title": "Generalization of the Gibbs algorithm with high probability at low temperatures",
    "authors": [
      "Andreas Maurer"
    ],
    "abstract": "The paper gives a bound on the generalization error of the Gibbs algorithm,\nwhich recovers known data-independent bounds for the high temperature range and\nextends to the low-temperature range, where generalization depends critically\non the data-dependent loss-landscape. It is shown, that with high probability\nthe generalization error of a single hypothesis drawn from the Gibbs posterior\ndecreases with the total prior volume of all hypotheses with similar or smaller\nempirical error. This gives theoretical support to the belief in the benefit of\nflat minima. The zero temperature limit is discussed and the bound is extended\nto a class of similar stochastic algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11071v5",
    "published": "2025-02-16T10:40:19+00:00",
    "categories": [
      "cs.LG",
      "stat.ML",
      "68T05",
      "G.3"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11070v1",
    "title": "A Survey on Vulnerability Prioritization: Taxonomy, Metrics, and Research Challenges",
    "authors": [
      "Yuning Jiang",
      "Nay Oo",
      "Qiaoran Meng",
      "Hoon Wei Lim",
      "Biplab Sikdar"
    ],
    "abstract": "In the highly interconnected digital landscape of today, safeguarding complex\ninfrastructures against cyber threats has become increasingly challenging due\nto the exponential growth in the number and complexity of vulnerabilities.\nResource constraints necessitate effective vulnerability prioritization\nstrategies, focusing efforts on the most critical risks. This paper presents a\nsystematic literature review of 82 studies, introducing a novel taxonomy that\ncategorizes metrics into severity, exploitability, contextual factors,\npredictive indicators, and aggregation methods. Our analysis reveals\nsignificant gaps in existing approaches and challenges with multi-domain\napplicability. By emphasizing the need for dynamic, context-aware metrics and\nscalable solutions, we provide actionable insights to bridge the gap between\nresearch and real-world applications. This work contributes to the field by\noffering a comprehensive framework for evaluating vulnerability prioritization\nmethodologies and setting a research agenda to advance the state of practice.",
    "pdf_url": "http://arxiv.org/pdf/2502.11070v1",
    "published": "2025-02-16T10:33:37+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11069v1",
    "title": "Factors influencing the perceived usability of mobile applications",
    "authors": [
      "Pawel Weichbroth"
    ],
    "abstract": "The advent of mobile applications has brought new frontiers to usability\nstudies. So far, the ongoing research has undertaken considerable efforts to\nmodel usability in such new challenging context. One of these endeavors is the\nPACMAD+3 model, which consists of a total of ten unique factors. However, to\nthe best of our knowledge, little or no effort has been made to empirically\nevaluate these factors against perceived influence. With this in mind, the\nobjective of this study is to explore this issue by evaluating the selected\nfactors. To achieve this goal in a reliable and reproducible manner, we took\nadvantage of previous attempts to conceptualize the mobile usability factors,\nbut we contribute by operationalizing these theoretical constructs into\nobservable and measurable phenomena. In this sense, the survey was designed and\ncarried out on the sample of 838 users in order to evaluate the significance of\nthe PACMAD+3 factors on the perceived usability of mobile applications. Our\nfindings show that, on average, users rated efficiency as highly important,\nwhile the remaining seven, namely: cognitive load, errors, learnability,\noperability, effectiveness, memorability, and understandability, were rated as\nmoderately important. The discussed results provide insight into the importance\nof usability attributes and quality criteria from both perspectives, ultimately\nfacilitating and securing the design and development of mobile applications.\nTherefore, our research contributes to the field of human-computer interaction,\nwith both theoretical and practical implications for mobile usability\nresearchers, UX designers, and quality assurance engineers.",
    "pdf_url": "http://arxiv.org/pdf/2502.11069v1",
    "published": "2025-02-16T10:30:33+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11068v1",
    "title": "Accelerating Anchors via Specialization and Feature Transformation",
    "authors": [
      "Haonan Yu",
      "Junhao Liu",
      "Xin Zhang"
    ],
    "abstract": "Anchors is a popular local model-agnostic explanation technique whose\napplicability is limited by its computational inefficiency. To address this\nlimitation, we propose a pre-training-based approach to accelerate Anchors\nwithout compromising the explanation quality. Our approach leverages the\niterative nature of Anchors' algorithm which gradually refines an explanation\nuntil it is precise enough for a given input by providing a general explanation\nthat is obtained through pre-training as Anchors' initial explanation.\nSpecifically, we develop a two-step rule transformation process: the horizontal\ntransformation adapts a pre-trained explanation to the current input by\nreplacing features, and the vertical transformation refines the general\nexplanation until it is precise enough for the input. We evaluate our method\nacross tabular, text, and image datasets, demonstrating that it significantly\nreduces explanation generation time while maintaining fidelity and\ninterpretability, thereby enabling the practical adoption of Anchors in\ntime-sensitive applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.11068v1",
    "published": "2025-02-16T10:30:01+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2503.05714v1",
    "title": "Prosthetics of the Indian State: The e-Shram Portal for Unorganized Workers in India",
    "authors": [
      "Rozin Hasin"
    ],
    "abstract": "This research paper examines the digital portal/database for unorganized\nworkers in the informal sector economy of India today: e-Shram. Using\naffordance theory, I criticize the operationalization of this database for the\nlabourers, alongside problems of accessibility and perception.",
    "pdf_url": "http://arxiv.org/pdf/2503.05714v1",
    "published": "2025-02-16T10:27:29+00:00",
    "categories": [
      "cs.CY",
      "cs.ET",
      "cs.IR",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2502.11067v1",
    "title": "A Survey on Active Feature Acquisition Strategies",
    "authors": [
      "Arman Rahbar",
      "Linus Aronsson",
      "Morteza Haghir Chehreghani"
    ],
    "abstract": "Active feature acquisition studies the challenge of making accurate\npredictions while limiting the cost of collecting complete data. By selectively\nacquiring only the most informative features for each instance, these\nstrategies enable efficient decision-making in scenarios where data collection\nis expensive or time-consuming. This survey reviews recent progress in active\nfeature acquisition, discussing common problem formulations, practical\nchallenges, and key insights. We also highlight open issues and promising\ndirections for future research.",
    "pdf_url": "http://arxiv.org/pdf/2502.11067v1",
    "published": "2025-02-16T10:19:33+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11066v2",
    "title": "CARMA: Enhanced Compositionality in LLMs via Advanced Regularisation and Mutual Information Alignment",
    "authors": [
      "Nura Aljaafari",
      "Danilo S. Carvalho",
      "Andr Freitas"
    ],
    "abstract": "Large language models (LLMs) struggle with compositional generalisation,\nlimiting their ability to systematically combine learned components to\ninterpret novel inputs. While architectural modifications, fine-tuning, and\ndata augmentation improve compositionality, they often have limited\nadaptability, face scalability constraints, or yield diminishing returns on\nreal data. To address this, we propose CARMA, an intervention that enhances the\nstability and robustness of compositional reasoning in LLMs while preserving\nfine-tuned performance. CARMA employs mutual information regularisation and\nlayer-wise stability constraints to mitigate feature fragmentation, ensuring\nstructured representations persist across and within layers. We evaluate CARMA\non inverse dictionary modelling and sentiment classification, measuring its\nimpact on semantic consistency, performance stability, and robustness to\nlexical perturbations. Results show that CARMA reduces the variability\nintroduced by fine-tuning, stabilises token representations, and improves\ncompositional reasoning. While its effectiveness varies across architectures,\nCARMA's key strength lies in reinforcing learned structures rather than\nintroducing new capabilities, making it a scalable auxiliary method. These\nfindings suggest that integrating CARMA with fine-tuning can improve\ncompositional generalisation while maintaining task-specific performance in\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11066v2",
    "published": "2025-02-16T10:18:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11065v1",
    "title": "Optimal Placement of Nature-Based Solutions for Urban Challenges",
    "authors": [
      "Diego Maria Pinto",
      "Davide Donato Russo",
      "Antonio M. Sudoso"
    ],
    "abstract": "Increased urbanization and climate change intensify urban heat islands and\ndegrade air quality, making current mitigation strategies insufficient.\nNature-based solutions (NBSs), such as parks, green walls, roofs, and street\ntrees, offer a promising means to regulate urban temperatures and enhance air\nquality. However, determining their optimal placement to maximize environmental\nbenefits remains a pressing challenge. Leveraging Operational Research (OR)\ntools, we propose a Mixed-Integer Linear Programming (MILP) model that\nintegrates multiple factors, including urban challenges, physical constraints,\nclustering techniques, convolution theory, and fairness considerations. This\nmodel determines the optimal placement of NBSs by addressing metrics such as\nground temperature, air quality, and accessibility to green spaces. Through\nseveral case study analyses, we demonstrate the effectiveness of our approach\nin improving environmental and social indicators. This research holds\nimplications for policy and practice, empowering urban planners and\npolicymakers to make informed decisions regarding NBS implementation. Such\ndecisions ensure that investments in urban greening yield maximum\nenvironmental, social, and economic benefits.",
    "pdf_url": "http://arxiv.org/pdf/2502.11065v1",
    "published": "2025-02-16T10:10:01+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11064v2",
    "title": "Characteristic cycle and wild Lefschetz theorems",
    "authors": [
      "Haoyu Hu",
      "Jean-Baptiste Teyssier"
    ],
    "abstract": "By relying on a new approach to Lefschetz type questions based on Beilinson's\nsingular support and Saito's characteristic cycle, we prove an instance of the\nwild Lefschetz theorem envisioned by Deligne. Our main tool are new finiteness\nresults for the characteristic cycles of perverse sheaves.",
    "pdf_url": "http://arxiv.org/pdf/2502.11064v2",
    "published": "2025-02-16T10:08:32+00:00",
    "categories": [
      "math.AG",
      "math.NT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11063v1",
    "title": "Semi-continuity for conductor divisors of tale sheaves",
    "authors": [
      "Haoyu Hu",
      "Jean-Baptiste Teyssier"
    ],
    "abstract": "In this article, we prove a semi-continuity property for both conductor\ndivisors and logarithmic conductor divisors for \\'etale sheaves on higher\nrelative dimensions in a geometric situation. It generalizes a semi-continuity\nresult for conductors of \\'etale sheaves on relative curves to higher relative\ndimensions, and it can be considered as a higher dimensional $\\ell$-adic\nanalogy of Andr\\'e's result on the semi-continuity of Poincar\\'e-Katz ranks of\nmeromorphic connections on smooth relative curves.",
    "pdf_url": "http://arxiv.org/pdf/2502.11063v1",
    "published": "2025-02-16T10:07:35+00:00",
    "categories": [
      "math.AG",
      "math.NT"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11062v1",
    "title": "Beyond Similarity: A Gradient-based Graph Method for Instruction Tuning Data Selection",
    "authors": [
      "Yang Zhao",
      "Li Du",
      "Xiao Ding",
      "Yangou Ouyang",
      "Hepeng Wang",
      "Kai Xiong",
      "Jinglong Gao",
      "Zhouhao Sun",
      "Dongliang Xu",
      "Yang Qing",
      "Dongchen Li",
      "Bing Qin",
      "Ting Liu"
    ],
    "abstract": "Large language models (LLMs) have shown great potential across various\nindustries due to their remarkable ability to generalize through instruction\ntuning. However, the limited availability of domain-specific data significantly\nhampers their performance on specialized tasks. While existing methods\nprimarily focus on selecting training data from general datasets that are\nsimilar to the target domain, they often fail to consider the joint\ndistribution of instructions, resulting in inefficient learning and suboptimal\nknowledge transfer. To address these challenges, we introduce G2IS\n(Gradient-based Graph Instruction Selection), a novel method that constructs a\nmixed gradient-based instruction graph to capture the joint distribution and\ninterdependencies between instructions. By accounting for the relationships\nbetween instructions, G2IS improves domain adaptation efficiency. Additionally,\nwe propose a gradient walk algorithm to refine the data selection process,\nenhancing both training effectiveness and efficiency. Our experiments\ndemonstrate that G2IS outperforms traditional methods across various domain\nadaptation tasks, yielding significant performance gains, particularly in\ncomplex, data-scarce scenarios. These results underscore the potential of G2IS\nin advancing the development of large, domain-specific models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11062v1",
    "published": "2025-02-16T10:06:00+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2503.05882v1",
    "title": "Practical Topics in Optimization",
    "authors": [
      "Jun Lu"
    ],
    "abstract": "In an era where data-driven decision-making and computational efficiency are\nparamount, optimization plays a foundational role in advancing fields such as\nmathematics, computer science, operations research, machine learning, and\nbeyond. From refining machine learning models to improving resource allocation\nand designing efficient algorithms, optimization techniques serve as essential\ntools for tackling complex problems. This book aims to provide both an\nintroductory guide and a comprehensive reference, equipping readers with the\nnecessary knowledge to understand and apply optimization methods within their\nrespective fields.\n  Our primary goal is to demystify the inner workings of optimization\nalgorithms, including black-box and stochastic optimizers, by offering both\nformal and intuitive explanations. Starting from fundamental mathematical\nprinciples, we derive key results to ensure that readers not only learn how\nthese techniques work but also understand when and why to apply them\neffectively. By striking a careful balance between theoretical depth and\npractical application, this book serves a broad audience, from students and\nresearchers to practitioners seeking robust optimization strategies.",
    "pdf_url": "http://arxiv.org/pdf/2503.05882v1",
    "published": "2025-02-16T10:00:50+00:00",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.NA",
      "math.OC"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11061v1",
    "title": "Dj Vu? Decoding Repeated Reading from Eye Movements",
    "authors": [
      "Yoav Meiri",
      "Omer Shubi",
      "Cfir Avraham Hadar",
      "Ariel Kreisberg Nitzav",
      "Yevgeni Berzak"
    ],
    "abstract": "Be it your favorite novel, a newswire article, a cooking recipe or an\nacademic paper -- in many daily situations we read the same text more than\nonce. In this work, we ask whether it is possible to automatically determine\nwhether the reader has previously encountered a text based on their eye\nmovement patterns. We introduce two variants of this task and address them with\nconsiderable success using both feature-based and neural models. We further\nintroduce a general strategy for enhancing these models with machine generated\nsimulations of eye movements from a cognitive model. Finally, we present an\nanalysis of model performance which on the one hand yields insights on the\ninformation used by the models, and on the other hand leverages predictive\nmodeling as an analytic tool for better characterization of the role of memory\nin repeated reading. Our work advances the understanding of the extent and\nmanner in which eye movements in reading capture memory effects from prior text\nexposure, and paves the way for future applications that involve predictive\nmodeling of repeated reading.",
    "pdf_url": "http://arxiv.org/pdf/2502.11061v1",
    "published": "2025-02-16T09:59:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11060v1",
    "title": "Estimates for Betti numbers and relative Hermite-Minkowski theorem for perverse sheaves",
    "authors": [
      "Haoyu Hu",
      "Jean-Baptiste Teyssier"
    ],
    "abstract": "We prove estimates for the Betti numbers of constructible sheaves in\ncharacteristic p>0 depending only on their rank, stratification and wild\nramification. In particular, given a smooth proper variety of dimension n over\nan algebraically closed field and a divisor D of X, for every $0\\leq i \\leq n$,\nthere is a polynomial $P_i$ of degree $\\max \\{i,2n-i\\}$ such that the i-th\nBetti number of any rank r local system L on X-D is smaller than\n$P_i(lc_D(L))\\cdot r$ where $lc_D(L)$ is the highest logarithmic conductor of L\nat the generic points of D. As application, we show that the Betti numbers of\nthe inverse and higher direct images of a local system are controlled by the\nrank and the highest logarithmic conductor. We also reprove Deligne's\nfiniteness for simple $\\ell$-adic local systems with bounded rank and\nramification on a smooth variety over a finite field and extend it in two\ndifferent directions. In particular, perverse sheaves over arbitrary singular\nschemes are allowed and the bounds we obtain are uniform in algebraic families\nand do not depend on $\\ell$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11060v1",
    "published": "2025-02-16T09:59:03+00:00",
    "categories": [
      "math.AG",
      "math.NT",
      "14F20, 11S15, 14F08"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11059v1",
    "title": "ClimateLLM: Efficient Weather Forecasting via Frequency-Aware Large Language Models",
    "authors": [
      "Shixuan Li",
      "Wei Yang",
      "Peiyu Zhang",
      "Xiongye Xiao",
      "Defu Cao",
      "Yuehan Qin",
      "Xiaole Zhang",
      "Yue Zhao",
      "Paul Bogdan"
    ],
    "abstract": "Weather forecasting is crucial for public safety, disaster prevention and\nmitigation, agricultural production, and energy management, with global\nrelevance. Although deep learning has significantly advanced weather\nprediction, current methods face critical limitations: (i) they often struggle\nto capture both dynamic temporal dependencies and short-term abrupt changes,\nmaking extreme weather modeling difficult; (ii) they incur high computational\ncosts due to extensive training and resource requirements; (iii) they have\nlimited adaptability to multi-scale frequencies, leading to challenges when\nseparating global trends from local fluctuations. To address these issues, we\npropose ClimateLLM, a foundation model for weather forecasting. It captures\nspatiotemporal dependencies via a cross-temporal and cross-spatial\ncollaborative modeling framework that integrates Fourier-based frequency\ndecomposition with Large Language Models (LLMs) to strengthen spatial and\ntemporal modeling. Our framework uses a Mixture-of-Experts (MoE) mechanism that\nadaptively processes different frequency components, enabling efficient\nhandling of both global signals and localized extreme events. In addition, we\nintroduce a cross-temporal and cross-spatial dynamic prompting mechanism,\nallowing LLMs to incorporate meteorological patterns across multiple scales\neffectively. Extensive experiments on real-world datasets show that ClimateLLM\noutperforms state-of-the-art approaches in accuracy and efficiency, as a\nscalable solution for global weather forecasting.",
    "pdf_url": "http://arxiv.org/pdf/2502.11059v1",
    "published": "2025-02-16T09:57:50+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11058v1",
    "title": "DreamDDP: Accelerating Data Parallel Distributed LLM Training with Layer-wise Scheduled Partial Synchronization",
    "authors": [
      "Zhenheng Tang",
      "Zichen Tang",
      "Junlin Huang",
      "Xinglin Pan",
      "Rudan Yan",
      "Yuxin Wang",
      "Amelie Chi Zhou",
      "Shaohuai Shi",
      "Xiaowen Chu",
      "Bo Li"
    ],
    "abstract": "The growth of large language models (LLMs) increases challenges of\naccelerating distributed training across multiple GPUs in different data\ncenters. Moreover, concerns about data privacy and data exhaustion have\nheightened interest in geo-distributed data centers. Communication in\ngeo-distributed data parallel training (DDP) with stochastic gradient descent\n(S-SGD) is the main bottleneck in low-bandwidth environments. Local SGD\nmitigates communication overhead by reducing synchronization frequency, and\nrecent studies have successfully applied it to geo-distributedly pre-train\nLLMs. However, we identify that its model synchronization mechanism prevents\noverlapping communication and computation, which makes the system lose\nopportunities to overlap communication and computation.\n  To overcome this limitation, we expand the design space of local SGD by\nlayer-wisely decoupling model synchronization. In each iteration, only some\nlayers are synchronized instead of the entire model after a specific number of\niterations. Leveraging this methodology, we introduce DreamDDP, a training\nframework to accelerate low-bandwidth distributed training with three key\ninnovations: (1) partial local SGD with theoretical assurances of convergence\nrates comparable to S-SGD; (2) overlapping parameter synchronization with\ncomputation without extra GPU memory occupation; (3) identifying and exploiting\nthree properties to schedule the communication and computation to reduce the\ntraining time based on fine-grained profiling of layer-wise communication and\ncomputation time. Empirical evaluations conducted on 32 GPUs using prominent\ndeep learning models, including ResNet-18, ResNet-50, GPT-2, and Llama-2,\ndemonstrate that DreamDDP enhances the convergence properties of Local SGD (and\nAdam) and achieves speedups ranging from $1.49\\times$ to $3.91\\times$ over\nleading baseline methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.11058v1",
    "published": "2025-02-16T09:51:57+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11057v3",
    "title": "A Physics-Informed Machine Learning Framework for Safe and Optimal Control of Autonomous Systems",
    "authors": [
      "Manan Tayal",
      "Aditya Singh",
      "Shishir Kolathaya",
      "Somil Bansal"
    ],
    "abstract": "As autonomous systems become more ubiquitous in daily life, ensuring high\nperformance with guaranteed safety is crucial. However, safety and performance\ncould be competing objectives, which makes their co-optimization difficult.\nLearning-based methods, such as Constrained Reinforcement Learning (CRL),\nachieve strong performance but lack formal safety guarantees due to safety\nbeing enforced as soft constraints, limiting their use in safety-critical\nsettings. Conversely, formal methods such as Hamilton-Jacobi (HJ) Reachability\nAnalysis and Control Barrier Functions (CBFs) provide rigorous safety\nassurances but often neglect performance, resulting in overly conservative\ncontrollers. To bridge this gap, we formulate the co-optimization of safety and\nperformance as a state-constrained optimal control problem, where performance\nobjectives are encoded via a cost function and safety requirements are imposed\nas state constraints. We demonstrate that the resultant value function\nsatisfies a Hamilton-Jacobi-Bellman (HJB) equation, which we approximate\nefficiently using a novel physics-informed machine learning framework. In\naddition, we introduce a conformal prediction-based verification strategy to\nquantify the learning errors, recovering a high-confidence safety value\nfunction, along with a probabilistic error bound on performance degradation.\nThrough several case studies, we demonstrate the efficacy of the proposed\nframework in enabling scalable learning of safe and performant controllers for\ncomplex, high-dimensional autonomous systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11057v3",
    "published": "2025-02-16T09:46:17+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11056v1",
    "title": "Accelerated engineering of topological interface states in one-dimensional phononic crystals via deep learning",
    "authors": [
      "Xue-Qian Zhang",
      "Yi-Da Liu",
      "Xiao-Shuang Li",
      "Tian-Xue Ma",
      "Yue-Sheng Wang",
      "Zhuo Zhuang"
    ],
    "abstract": "Topological interface states (TISs) in phononic crystals (PnCs) are robust\nacoustic modes against external perturbations, which are of great significance\nin scientific and engineering communities. However, designing a pair of PnCs\nwith specified band gaps (BGs) and TIS frequency remains a challenging problem.\nIn this work, deep learning (DL) approaches are used for the engineering of\none-dimensional (1D) PnCs with high design freedoms. The considered 1D PnCs are\ncomposed of periodic solid scatterers embedded in the air background, whose\nunit cell is divided into a matrix with 32 * 32 pixels. First, the variational\nautoencoder is applied to reduce the dimensionality of unit cell images,\nallowing accurate reconstruction of PnC images with different numbers of\nscatterers. Subsequently, the multilayer perceptron and the tandem neural\nnetwork are used to realize the property prediction and customized design of 1D\nPnCs, respectively. The correlation coefficients for the property prediction\nand inverse design are more than 97%. The unit cell images of 1D PnCs with\nspecific BG properties could be successfully and instantaneously designed.\nImportantly, the implementation of a \"one-to-many\" design of PnC pairs with\nspecific TIS frequencies is realized. Furthermore, the reliability and\nrobustness of the constructed networks are confirmed by randomly specifying the\ndesign targets as well as the experimental verification. This study\ndemonstrates the broad application prospects of DL approaches in the field of\nPnC design and provides new ideas and methods for the intelligent design of\nartificially functional materials.",
    "pdf_url": "http://arxiv.org/pdf/2502.11056v1",
    "published": "2025-02-16T09:45:01+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11055v2",
    "title": "Bounding ramification with coherent sheaves",
    "authors": [
      "Haoyu Hu",
      "Jean-Baptiste Teyssier"
    ],
    "abstract": "Given a coherent sheaf E on a scheme of finite type X over a perfect field,\nwe introduce a category of complexes of \\'etale sheaves on X with logarithmic\nconductors bounded by E and study its compatibilities with finite push-forward.",
    "pdf_url": "http://arxiv.org/pdf/2502.11055v2",
    "published": "2025-02-16T09:36:55+00:00",
    "categories": [
      "math.AG",
      "math.NT",
      "11S15, 14F20"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.19435v1",
    "title": "Arrival flow profile estimation and predication for urban arterials using license plate recognition data",
    "authors": [
      "Hao Wu",
      "Jiarong Yao",
      "Peize Kang",
      "Chaopeng Tan",
      "Yang Cai",
      "Junjie Zhou",
      "Edward Chung",
      "Keshuang Tang"
    ],
    "abstract": "Arrival flow profiles enable precise assessment of urban arterial dynamics,\naiding signal control optimization. License Plate Recognition (LPR) data, with\nits comprehensive coverage and event-based detection, is promising for\nreconstructing arrival flow profiles. This paper introduces an arrival flow\nprofile estimation and prediction method for urban arterials using LPR data.\nUnlike conventional methods that assume traffic homogeneity and overlook\ndetailed traffic wave features and signal timing impacts, our approach employs\na time partition algorithm and platoon dispersion model to calculate arrival\nflow, considering traffic variations and driving behaviors using only boundary\ndata. Shockwave theory quantifies the piecewise function between arrival flow\nand profile. We derive the relationship between arrival flow profiles and\ntraffic dissipation at downstream intersections, enabling recursive\ncalculations for all intersections. This approach allows prediction of arrival\nflow profiles under any signal timing schemes. Validation through simulation\nand empirical cases demonstrates promising performance and robustness under\nvarious conditions.",
    "pdf_url": "http://arxiv.org/pdf/2502.19435v1",
    "published": "2025-02-16T09:28:00+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11054v4",
    "title": "Reasoning-Augmented Conversation for Multi-Turn Jailbreak Attacks on Large Language Models",
    "authors": [
      "Zonghao Ying",
      "Deyue Zhang",
      "Zonglei Jing",
      "Yisong Xiao",
      "Quanchen Zou",
      "Aishan Liu",
      "Siyuan Liang",
      "Xiangzheng Zhang",
      "Xianglong Liu",
      "Dacheng Tao"
    ],
    "abstract": "Multi-turn jailbreak attacks simulate real-world human interactions by\nengaging large language models (LLMs) in iterative dialogues, exposing critical\nsafety vulnerabilities. However, existing methods often struggle to balance\nsemantic coherence with attack effectiveness, resulting in either benign\nsemantic drift or ineffective detection evasion. To address this challenge, we\npropose Reasoning-Augmented Conversation, a novel multi-turn jailbreak\nframework that reformulates harmful queries into benign reasoning tasks and\nleverages LLMs' strong reasoning capabilities to compromise safety alignment.\nSpecifically, we introduce an attack state machine framework to systematically\nmodel problem translation and iterative reasoning, ensuring coherent query\ngeneration across multiple turns. Building on this framework, we design\ngain-guided exploration, self-play, and rejection feedback modules to preserve\nattack semantics, enhance effectiveness, and sustain reasoning-driven attack\nprogression. Extensive experiments on multiple LLMs demonstrate that RACE\nachieves state-of-the-art attack effectiveness in complex conversational\nscenarios, with attack success rates (ASRs) increasing by up to 96%. Notably,\nour approach achieves ASRs of 82% and 92% against leading commercial models,\nOpenAI o1 and DeepSeek R1, underscoring its potency. We release our code at\nhttps://github.com/NY1024/RACE to facilitate further research in this critical\ndomain.",
    "pdf_url": "http://arxiv.org/pdf/2502.11054v4",
    "published": "2025-02-16T09:27:44+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11053v2",
    "title": "Demystifying 5G Polar and LDPC Codes: A Comprehensive Review and Foundations",
    "authors": [
      "Mody Sy"
    ],
    "abstract": "This paper serves as a comprehensive guide for practitioners and scholars\naiming to understand the channel coding and decoding schemes integral to the 5G\nNR standard, with a particular focus on LDPC and polar codes. We start by\nexplaining the design procedures that underlie these channel codes, offering\nfundamental information from the perspectives of both encoding and decoding. In\norder to determine the present status of research in this area, we also provide\na thorough literature review. Notably, we add comprehensive, standard-specific\ninformation to these foundational evaluations that is frequently difficult to\nextract from technical specification documents. The significance of reviewing\nand refining the foundations of the aforementioned codes lies in their\npotential to serve as candidate error-correcting codes for the future 6G\nstandard and beyond.",
    "pdf_url": "http://arxiv.org/pdf/2502.11053v2",
    "published": "2025-02-16T09:27:42+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11052v1",
    "title": "Time-consistent portfolio selection with strictly monotone mean-variance preference",
    "authors": [
      "Yike Wang",
      "Yusha Chen"
    ],
    "abstract": "This paper is devoted to time-consistent control problems of portfolio\nselection with strictly monotone mean-variance preferences. These preferences\nare variational modifications of the conventional mean-variance preferences,\nand remain time-inconsistent as in mean-variance optimization problems. To\ntackle the time-inconsistency, we study the Nash equilibrium controls of both\nthe open-loop type and the closed-loop type, and characterize them within a\nrandom parameter setting. The problem is reduced to solving a flow of\nforward-backward stochastic differential equations for open-loop equilibria,\nand to solving extended Hamilton-Jacobi-Bellman equations for closed-loop\nequilibria. In particular, we derive semi-closed-form solutions for these two\ntypes of equilibria under a deterministic parameter setting. Both solutions are\nrepresented by the same function, which is independent of wealth state and\nrandom path. This function can be expressed as the conventional time-consistent\nmean-variance portfolio strategy multiplied by a factor greater than one.\nFurthermore, we find that the state-independent closed-loop Nash equilibrium\ncontrol is a strong equilibrium strategy in a constant parameter setting only\nwhen the interest rate is sufficiently large.",
    "pdf_url": "http://arxiv.org/pdf/2502.11052v1",
    "published": "2025-02-16T09:27:35+00:00",
    "categories": [
      "math.OC",
      "q-fin.PM",
      "Primary: 91G10, 49N10, Secondary: 91B05, 49N90"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11051v4",
    "title": "MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models",
    "authors": [
      "Jiahao Huo",
      "Yibo Yan",
      "Xu Zheng",
      "Yuanhuiyi Lyu",
      "Xin Zou",
      "Zhihua Wei",
      "Xuming Hu"
    ],
    "abstract": "Recent progress in Machine Unlearning (MU) has introduced solutions for the\nselective removal of private or sensitive information encoded within deep\nneural networks. Nonetheless, MU for Multimodal Large Language Models (MLLMs)\nremains in its nascent phase. Therefore, we propose to reformulate the task of\nmultimodal MU in the era of MLLMs, which aims to erase only the visual patterns\nassociated with a given entity while preserving the corresponding textual\nknowledge encoded within the original parameters of the language model\nbackbone. Furthermore, we develop a novel geometry-constrained gradient ascent\nmethod MMUnlearner. It updates the weights of MLLMs with a weight saliency map\njointly restricted by the remaining concepts and textual knowledge during\nunlearning, thereby preserving parameters essential for non-target knowledge.\nExtensive experiments demonstrate that MMUnlearner surpasses baselines that\nfinetuning MLLMs with VQA data directly through Gradient Ascent (GA) or\nNegative Preference Optimization (NPO), across all evaluation dimensions. Our\ncode can be found in [this URL](https://github.com/Z1zs/MMUnlearner).",
    "pdf_url": "http://arxiv.org/pdf/2502.11051v4",
    "published": "2025-02-16T09:23:50+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11050v3",
    "title": "Spin-chirality-driven second-harmonic generation in two-dimensional magnet CrSBr",
    "authors": [
      "Dezhao Wu",
      "Yong Xu",
      "Meng Ye",
      "Wenhui Duan"
    ],
    "abstract": "The interplay between magnetism and light can create abundant optical\nphenomena. Here, we demonstrate the emergence of an unconventional\nmagnetization-induced second-harmonic generation (MSHG) stemming from vector\nspin chirality, denoted as chiral second-harmonic generation (SHG). Taking the\nantiferromagnetic (AFM) CrSBr bilayer as a prototype, we theoretically show\nthat, via spin canting, the chiral SHG can be continuously tuned from zero to a\nvalue one order of magnitude larger than its intrinsic MSHG. Chiral SHG is\nfound to be proportional to spin chirality and spin-canting-induced electric\npolarization, while intrinsic MSHG is proportional to the N\\'eel vector,\ndemonstrating their different physical mechanisms. Additionally, we reveal a\nunique interference effect between these two types of MSHG under the reversal\nof spin-canting direction, generating a giant modulation of SHG signals. Our\nwork not only uncovers a unique SHG with exceptional tunability but also\npromotes the applications of AFM optical devices and magnetoelectric detection\ntechniques.",
    "pdf_url": "http://arxiv.org/pdf/2502.11050v3",
    "published": "2025-02-16T09:23:47+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11049v1",
    "title": "Faces of Fairness: Examining Bias in Facial Expression Recognition Datasets and Models",
    "authors": [
      "Mohammad Mehdi Hosseini",
      "Ali Pourramezan Fard",
      "Mohammad H. Mahoor"
    ],
    "abstract": "Building AI systems, including Facial Expression Recognition (FER), involves\ntwo critical aspects: data and model design. Both components significantly\ninfluence bias and fairness in FER tasks. Issues related to bias and fairness\nin FER datasets and models remain underexplored. This study investigates bias\nsources in FER datasets and models. Four common FER datasets--AffectNet, ExpW,\nFer2013, and RAF-DB--are analyzed. The findings demonstrate that AffectNet and\nExpW exhibit high generalizability despite data imbalances. Additionally, this\nresearch evaluates the bias and fairness of six deep models, including three\nstate-of-the-art convolutional neural network (CNN) models: MobileNet, ResNet,\nXceptionNet, as well as three transformer-based models: ViT, CLIP, and\nGPT-4o-mini. Experimental results reveal that while GPT-4o-mini and ViT achieve\nthe highest accuracy scores, they also display the highest levels of bias.\nThese findings underscore the urgent need for developing new methodologies to\nmitigate bias and ensure fairness in datasets and models, particularly in\naffective computing applications. See our implementation details at\nhttps://github.com/MMHosseini/bias_in_FER.",
    "pdf_url": "http://arxiv.org/pdf/2502.11049v1",
    "published": "2025-02-16T09:23:16+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2504.05309v1",
    "title": "IterQR: An Iterative Framework for LLM-based Query Rewrite in e-Commercial Search System",
    "authors": [
      "Shangyu Chen",
      "Xinyu Jia",
      "Yingfei Zhang",
      "Shuai Zhang",
      "Xiang Li",
      "Wei Lin"
    ],
    "abstract": "The essence of modern e-Commercial search system lies in matching user's\nintent and available candidates depending on user's query, providing\npersonalized and precise service. However, user's query may be incorrect due to\nambiguous input and typo, leading to inaccurate search. These cases may be\nreleased by query rewrite: modify query to other representation or expansion.\nHowever, traditional query rewrite replies on static rewrite vocabulary, which\nis manually established meanwhile lacks interaction with both domain knowledge\nin e-Commercial system and common knowledge in the real world. In this paper,\nwith the ability to generate text content of Large Language Models (LLMs), we\nprovide an iterative framework to generate query rewrite. The framework\nincorporates a 3-stage procedure in each iteration: Rewrite Generation with\ndomain knowledge by Retrieval-Augmented Generation (RAG) and query\nunderstanding by Chain-of-Thoughts (CoT); Online Signal Collection with\nautomatic positive rewrite update; Post-training of LLM with multi task\nobjective to generate new rewrites. Our work (named as IterQR) provides a\ncomprehensive framework to generate \\textbf{Q}uery \\textbf{R}ewrite with both\ndomain / real-world knowledge. It automatically update and self-correct the\nrewrites during \\textbf{iter}ations. \\method{} has been deployed in Meituan\nDelivery's search system (China's leading food delivery platform), providing\nservice for users with significant improvement.",
    "pdf_url": "http://arxiv.org/pdf/2504.05309v1",
    "published": "2025-02-16T09:20:13+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11048v1",
    "title": "Electrothermal manipulation of current-induced phase transitions in ferrimagnetic Mn$_3$Si$_2$Te$_6$",
    "authors": [
      "Jiaqi Fang",
      "Jiawei Hu",
      "Xintian Chen",
      "Yaotian Liu",
      "Zheng Yin",
      "Zhe Ying",
      "Yunhao Wang",
      "Ziqiang Wang",
      "Zhilin Li",
      "Shiyu Zhu",
      "Yang Xu",
      "Sokrates T. Pantelides",
      "Hong-Jun Gao"
    ],
    "abstract": "Phase transitions driven by external stimuli are central to condensed matter\nphysics, providing critical insights into symmetry breaking and emergent\nphenomena. Recently, ferrimagnetic (FiM) Mn$_3$Si$_2$Te$_6$ has attracted\nconsiderable attention for its magnetic-field-induced insulator-metal\ntransitions (IMTs) and unconventional current-driven phase transitions, yet the\nrole of applied currents in the magnetic phase remains poorly understood. Here,\nby combining local magnetization probes and time-resolved transport\nmeasurements, we uncover an electrothermal origin for the current-induced\nfirst-order-like phase transitions, characterized by abrupt voltage jumps and\ndistinct magnetic domain evolution. Current-voltage (I-V) characteristics\nmeasured under triangular waveforms exhibit strong non-reciprocal and\nhysteretic behaviors, which are significantly suppressed at frequencies ~1000\nHz. Time-resolved studies using rectangular pulsed currents demonstrate that\nthe resistance dynamics closely mirror the equilibrium resistance-temperature\nprofile, directly implicating Joule heating as the driving mechanism.\nFurthermore, we reveal that the intrinsic I-V response adheres to Ohm's law,\ndisplaying linearity across various magnetic fields and temperatures. Our work\nadvocates for a cautious approach in distinguishing between genuine\ncurrent-induced nonequilibrium quantum states and thermal effects.",
    "pdf_url": "http://arxiv.org/pdf/2502.11048v1",
    "published": "2025-02-16T09:19:32+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11047v1",
    "title": "Search for the Cabibbo-suppressed decays $_c^{+}\\to^0K^{+}^{0}$ and $_c^{+}\\to^0K^{+}^{+}^{-}$",
    "authors": [
      "BESIII Collaboration",
      "M. Ablikim",
      "M. N. Achasov",
      "P. Adlarson",
      "X. C. Ai",
      "R. Aliberti",
      "A. Amoroso",
      "Q. An",
      "Y. Bai",
      "O. Bakina",
      "Y. Ban",
      "H. -R. Bao",
      "V. Batozskaya",
      "K. Begzsuren",
      "N. Berger",
      "M. Berlowski",
      "M. Bertani",
      "D. Bettoni",
      "F. Bianchi",
      "E. Bianco",
      "A. Bortone",
      "I. Boyko",
      "R. A. Briere",
      "A. Brueggemann",
      "H. Cai",
      "M. H. Cai",
      "X. Cai",
      "A. Calcaterra",
      "G. F. Cao",
      "N. Cao",
      "S. A. Cetin",
      "X. Y. Chai",
      "J. F. Chang",
      "G. R. Che",
      "Y. Z. Che",
      "G. Chelkov",
      "C. Chen",
      "C. H. Chen",
      "Chao Chen",
      "G. Chen",
      "H. S. Chen",
      "H. Y. Chen",
      "M. L. Chen",
      "S. J. Chen",
      "S. L. Chen",
      "S. M. Chen",
      "T. Chen",
      "X. R. Chen",
      "X. T. Chen",
      "X. Y. Chen",
      "Y. B. Chen",
      "Y. Q. Chen",
      "Y. Q. Chen",
      "Z. J. Chen",
      "Z. K. Chen",
      "S. K. Choi",
      "X. Chu",
      "G. Cibinetto",
      "F. Cossio",
      "J. J. Cui",
      "H. L. Dai",
      "J. P. Dai",
      "A. Dbeyssi",
      "R. E. de Boer",
      "D. Dedovich",
      "C. Q. Deng",
      "Z. Y. Deng",
      "A. Denig",
      "I. Denysenko",
      "M. Destefanis",
      "F. De Mori",
      "B. Ding",
      "X. X. Ding",
      "Y. Ding",
      "Y. Ding",
      "Y. X. Ding",
      "J. Dong",
      "L. Y. Dong",
      "M. Y. Dong",
      "X. Dong",
      "M. C. Du",
      "S. X. Du",
      "S. X. Du",
      "Y. Y. Duan",
      "Z. H. Duan",
      "P. Egorov",
      "G. F. Fan",
      "J. J. Fan",
      "Y. H. Fan",
      "J. Fang",
      "J. Fang",
      "S. S. Fang",
      "W. X. Fang",
      "Y. Q. Fang",
      "R. Farinelli",
      "L. Fava",
      "F. Feldbauer",
      "G. Felici",
      "C. Q. Feng",
      "J. H. Feng",
      "Y. T. Feng",
      "M. Fritsch",
      "C. D. Fu",
      "J. L. Fu",
      "Y. W. Fu",
      "H. Gao",
      "X. B. Gao",
      "Y. Gao",
      "Y. N. Gao",
      "Y. N. Gao",
      "Y. Y. Gao",
      "S. Garbolino",
      "I. Garzia",
      "P. T. Ge",
      "Z. W. Ge",
      "C. Geng",
      "E. M. Gersabeck",
      "A. Gilman",
      "K. Goetzen",
      "L. Gong",
      "W. X. Gong",
      "W. Gradl",
      "S. Gramigna",
      "M. Greco",
      "M. H. Gu",
      "Y. T. Gu",
      "C. Y. Guan",
      "A. Q. Guo",
      "L. B. Guo",
      "M. J. Guo",
      "R. P. Guo",
      "Y. P. Guo",
      "A. Guskov",
      "J. Gutierrez",
      "K. L. Han",
      "T. T. Han",
      "F. Hanisch",
      "K. D. Hao",
      "X. Q. Hao",
      "F. A. Harris",
      "K. K. He",
      "K. L. He",
      "F. H. Heinsius",
      "C. H. Heinz",
      "Y. K. Heng",
      "C. Herold",
      "T. Holtmann",
      "P. C. Hong",
      "G. Y. Hou",
      "X. T. Hou",
      "Y. R. Hou",
      "Z. L. Hou",
      "H. M. Hu",
      "J. F. Hu",
      "Q. P. Hu",
      "S. L. Hu",
      "T. Hu",
      "Y. Hu",
      "Z. M. Hu",
      "G. S. Huang",
      "K. X. Huang",
      "L. Q. Huang",
      "P. Huang",
      "X. T. Huang",
      "Y. P. Huang",
      "Y. S. Huang",
      "T. Hussain",
      "N. Hsken",
      "N. in der Wiesche",
      "J. Jackson",
      "Q. Ji",
      "Q. P. Ji",
      "W. Ji",
      "X. B. Ji",
      "X. L. Ji",
      "Y. Y. Ji",
      "Z. K. Jia",
      "D. Jiang",
      "H. B. Jiang",
      "P. C. Jiang",
      "S. J. Jiang",
      "T. J. Jiang",
      "X. S. Jiang",
      "Y. Jiang",
      "J. B. Jiao",
      "J. K. Jiao",
      "Z. Jiao",
      "S. Jin",
      "Y. Jin",
      "M. Q. Jing",
      "X. M. Jing",
      "T. Johansson",
      "S. Kabana",
      "N. Kalantar-Nayestanaki",
      "X. L. Kang",
      "X. S. Kang",
      "M. Kavatsyuk",
      "B. C. Ke",
      "V. Khachatryan",
      "A. Khoukaz",
      "R. Kiuchi",
      "O. B. Kolcu",
      "B. Kopf",
      "M. Kuessner",
      "X. Kui",
      "N. Kumar",
      "A. Kupsc",
      "W. Khn",
      "Q. Lan",
      "W. N. Lan",
      "T. T. Lei",
      "M. Lellmann",
      "T. Lenz",
      "C. Li",
      "C. Li",
      "C. Li",
      "C. H. Li",
      "C. K. Li",
      "D. M. Li",
      "F. Li",
      "G. Li",
      "H. B. Li",
      "H. J. Li",
      "H. N. Li",
      "Hui Li",
      "J. R. Li",
      "J. S. Li",
      "K. Li",
      "K. L. Li",
      "K. L. Li",
      "L. J. Li",
      "Lei Li",
      "M. H. Li",
      "M. R. Li",
      "P. L. Li",
      "P. R. Li",
      "Q. M. Li",
      "Q. X. Li",
      "R. Li",
      "S. X. Li",
      "T. Li",
      "T. Y. Li",
      "W. D. Li",
      "W. G. Li",
      "X. Li",
      "X. H. Li",
      "X. L. Li",
      "X. Y. Li",
      "X. Z. Li",
      "Y. Li",
      "Y. G. Li",
      "Z. J. Li",
      "Z. Y. Li",
      "C. Liang",
      "H. Liang",
      "Y. F. Liang",
      "Y. T. Liang",
      "G. R. Liao",
      "L. B. Liao",
      "M. H. Liao",
      "Y. P. Liao",
      "J. Libby",
      "A. Limphirat",
      "C. C. Lin",
      "C. X. Lin",
      "D. X. Lin",
      "L. Q. Lin",
      "T. Lin",
      "B. J. Liu",
      "B. X. Liu",
      "C. Liu",
      "C. X. Liu",
      "F. Liu",
      "F. H. Liu",
      "Feng Liu",
      "G. M. Liu",
      "H. Liu",
      "H. B. Liu",
      "H. H. Liu",
      "H. M. Liu",
      "Huihui Liu",
      "J. B. Liu",
      "J. J. Liu",
      "K. Liu",
      "K. Liu",
      "K. Y. Liu",
      "Ke Liu",
      "L. Liu",
      "L. C. Liu",
      "Lu Liu",
      "M. H. Liu",
      "P. L. Liu",
      "Q. Liu",
      "S. B. Liu",
      "T. Liu",
      "W. K. Liu",
      "W. M. Liu",
      "W. T. Liu",
      "X. Liu",
      "X. Liu",
      "X. Y. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. B. Liu",
      "Z. A. Liu",
      "Z. D. Liu",
      "Z. Q. Liu",
      "X. C. Lou",
      "F. X. Lu",
      "H. J. Lu",
      "J. G. Lu",
      "X. L. Lu",
      "Y. Lu",
      "Y. H. Lu",
      "Y. P. Lu",
      "Z. H. Lu",
      "C. L. Luo",
      "J. R. Luo",
      "J. S. Luo",
      "M. X. Luo",
      "T. Luo",
      "X. L. Luo",
      "Z. Y. Lv",
      "X. R. Lyu",
      "Y. F. Lyu",
      "Y. H. Lyu",
      "F. C. Ma",
      "H. Ma",
      "H. L. Ma",
      "J. L. Ma",
      "L. L. Ma",
      "L. R. Ma",
      "Q. M. Ma",
      "R. Q. Ma",
      "R. Y. Ma",
      "T. Ma",
      "X. T. Ma",
      "X. Y. Ma",
      "Y. M. Ma",
      "F. E. Maas",
      "I. MacKay",
      "M. Maggiora",
      "S. Malde",
      "Q. A. Malik",
      "Y. J. Mao",
      "Z. P. Mao",
      "S. Marcello",
      "Y. H. Meng",
      "Z. X. Meng",
      "J. G. Messchendorp",
      "G. Mezzadri",
      "H. Miao",
      "T. J. Min",
      "R. E. Mitchell",
      "X. H. Mo",
      "B. Moses",
      "N. Yu. Muchnoi",
      "J. Muskalla",
      "Y. Nefedov",
      "F. Nerling",
      "L. S. Nie",
      "I. B. Nikolaev",
      "Z. Ning",
      "S. Nisar",
      "Q. L. Niu",
      "W. D. Niu",
      "S. L. Olsen",
      "Q. Ouyang",
      "S. Pacetti",
      "X. Pan",
      "Y. Pan",
      "A. Pathak",
      "Y. P. Pei",
      "M. Pelizaeus",
      "H. P. Peng",
      "Y. Y. Peng",
      "K. Peters",
      "J. L. Ping",
      "R. G. Ping",
      "S. Plura",
      "F. Z. Qi",
      "H. R. Qi",
      "M. Qi",
      "S. Qian",
      "W. B. Qian",
      "C. F. Qiao",
      "J. H. Qiao",
      "J. J. Qin",
      "J. L. Qin",
      "L. Q. Qin",
      "L. Y. Qin",
      "P. B. Qin",
      "X. P. Qin",
      "X. S. Qin",
      "Z. H. Qin",
      "J. F. Qiu",
      "Z. H. Qu",
      "C. F. Redmer",
      "A. Rivetti",
      "M. Rolo",
      "G. Rong",
      "S. S. Rong",
      "Ch. Rosner",
      "M. Q. Ruan",
      "S. N. Ruan",
      "N. Salone",
      "A. Sarantsev",
      "Y. Schelhaas",
      "K. Schoenning",
      "M. Scodeggio",
      "K. Y. Shan",
      "W. Shan",
      "X. Y. Shan",
      "Z. J. Shang",
      "J. F. Shangguan",
      "L. G. Shao",
      "M. Shao",
      "C. P. Shen",
      "H. F. Shen",
      "W. H. Shen",
      "X. Y. Shen",
      "B. A. Shi",
      "H. Shi",
      "J. L. Shi",
      "J. Y. Shi",
      "S. Y. Shi",
      "X. Shi",
      "H. L. Song",
      "J. J. Song",
      "T. Z. Song",
      "W. M. Song",
      "Y. J. Song",
      "Y. X. Song",
      "S. Sosio",
      "S. Spataro",
      "F. Stieler",
      "S. S Su",
      "Y. J. Su",
      "G. B. Sun",
      "G. X. Sun",
      "H. Sun",
      "H. K. Sun",
      "J. F. Sun",
      "K. Sun",
      "L. Sun",
      "S. S. Sun",
      "T. Sun",
      "Y. C. Sun",
      "Y. H. Sun",
      "Y. J. Sun",
      "Y. Z. Sun",
      "Z. Q. Sun",
      "Z. T. Sun",
      "C. J. Tang",
      "G. Y. Tang",
      "J. Tang",
      "J. J. Tang",
      "L. F. Tang",
      "Y. A. Tang",
      "L. Y. Tao",
      "M. Tat",
      "J. X. Teng",
      "J. Y. Tian",
      "W. H. Tian",
      "Y. Tian",
      "Z. F. Tian",
      "I. Uman",
      "B. Wang",
      "B. Wang",
      "Bo Wang",
      "C. Wang",
      "Cong Wang",
      "D. Y. Wang",
      "H. J. Wang",
      "J. J. Wang",
      "K. Wang",
      "L. L. Wang",
      "L. W. Wang",
      "M. Wang",
      "M. Wang",
      "N. Y. Wang",
      "S. Wang",
      "S. Wang",
      "T. Wang",
      "T. J. Wang",
      "W. Wang",
      "W. Wang",
      "W. P. Wang",
      "X. Wang",
      "X. F. Wang",
      "X. J. Wang",
      "X. L. Wang",
      "X. N. Wang",
      "Y. Wang",
      "Y. D. Wang",
      "Y. F. Wang",
      "Y. H. Wang",
      "Y. J. Wang",
      "Y. L. Wang",
      "Y. N. Wang",
      "Y. Q. Wang",
      "Yaqian Wang",
      "Yi Wang",
      "Yuan Wang",
      "Z. Wang",
      "Z. L. Wang",
      "Z. L. Wang",
      "Z. Q. Wang",
      "Z. Y. Wang",
      "D. H. Wei",
      "F. Weidner",
      "S. P. Wen",
      "Y. R. Wen",
      "U. Wiedner",
      "G. Wilkinson",
      "M. Wolke",
      "C. Wu",
      "J. F. Wu",
      "L. H. Wu",
      "L. J. Wu",
      "L. J. Wu",
      "Lianjie Wu",
      "S. G. Wu",
      "S. M. Wu",
      "X. Wu",
      "X. H. Wu",
      "Y. J. Wu",
      "Z. Wu",
      "L. Xia",
      "X. M. Xian",
      "B. H. Xiang",
      "D. Xiao",
      "G. Y. Xiao",
      "H. Xiao",
      "Y. L. Xiao",
      "Z. J. Xiao",
      "C. Xie",
      "K. J. Xie",
      "X. H. Xie",
      "Y. Xie",
      "Y. G. Xie",
      "Y. H. Xie",
      "Z. P. Xie",
      "T. Y. Xing",
      "C. F. Xu",
      "C. J. Xu",
      "G. F. Xu",
      "H. Y. Xu",
      "H. Y. Xu",
      "M. Xu",
      "Q. J. Xu",
      "Q. N. Xu",
      "T. D. Xu",
      "W. Xu",
      "W. L. Xu",
      "X. P. Xu",
      "Y. Xu",
      "Y. Xu",
      "Y. C. Xu",
      "Z. S. Xu",
      "F. Yan",
      "H. Y. Yan",
      "L. Yan",
      "W. B. Yan",
      "W. C. Yan",
      "W. H. Yan",
      "W. P. Yan",
      "X. Q. Yan",
      "H. J. Yang",
      "H. L. Yang",
      "H. X. Yang",
      "J. H. Yang",
      "R. J. Yang",
      "T. Yang",
      "Y. Yang",
      "Y. F. Yang",
      "Y. H. Yang",
      "Y. Q. Yang",
      "Y. X. Yang",
      "Y. Z. Yang",
      "M. Ye",
      "M. H. Ye",
      "Junhao Yin",
      "Z. Y. You",
      "B. X. Yu",
      "C. X. Yu",
      "G. Yu",
      "J. S. Yu",
      "L. Q. Yu",
      "M. C. Yu",
      "T. Yu",
      "X. D. Yu",
      "Y. C. Yu",
      "C. Z. Yuan",
      "H. Yuan",
      "J. Yuan",
      "J. Yuan",
      "L. Yuan",
      "S. C. Yuan",
      "X. Q. Yuan",
      "Y. Yuan",
      "Z. Y. Yuan",
      "C. X. Yue",
      "Ying Yue",
      "A. A. Zafar",
      "S. H. Zeng",
      "X. Zeng",
      "Y. Zeng",
      "Y. J. Zeng",
      "Y. J. Zeng",
      "X. Y. Zhai",
      "Y. H. Zhan",
      "A. Q. Zhang",
      "B. L. Zhang",
      "B. X. Zhang",
      "D. H. Zhang",
      "G. Y. Zhang",
      "G. Y. Zhang",
      "H. Zhang",
      "H. Zhang",
      "H. C. Zhang",
      "H. H. Zhang",
      "H. Q. Zhang",
      "H. R. Zhang",
      "H. Y. Zhang",
      "J. Zhang",
      "J. Zhang",
      "J. J. Zhang",
      "J. L. Zhang",
      "J. Q. Zhang",
      "J. S. Zhang",
      "J. W. Zhang",
      "J. X. Zhang",
      "J. Y. Zhang",
      "J. Z. Zhang",
      "Jianyu Zhang",
      "L. M. Zhang",
      "Lei Zhang",
      "N. Zhang",
      "P. Zhang",
      "Q. Zhang",
      "Q. Y. Zhang",
      "R. Y. Zhang",
      "S. H. Zhang",
      "Shulei Zhang",
      "X. M. Zhang",
      "X. Y Zhang",
      "X. Y. Zhang",
      "Y. Zhang",
      "Y. Zhang",
      "Y. T. Zhang",
      "Y. H. Zhang",
      "Y. M. Zhang",
      "Y. P. Zhang",
      "Z. D. Zhang",
      "Z. H. Zhang",
      "Z. L. Zhang",
      "Z. L. Zhang",
      "Z. X. Zhang",
      "Z. Y. Zhang",
      "Z. Y. Zhang",
      "Z. Z. Zhang",
      "Zh. Zh. Zhang",
      "G. Zhao",
      "J. Y. Zhao",
      "J. Z. Zhao",
      "L. Zhao",
      "L. Zhao",
      "M. G. Zhao",
      "N. Zhao",
      "R. P. Zhao",
      "S. J. Zhao",
      "Y. B. Zhao",
      "Y. L. Zhao",
      "Y. X. Zhao",
      "Z. G. Zhao",
      "A. Zhemchugov",
      "B. Zheng",
      "B. M. Zheng",
      "J. P. Zheng",
      "W. J. Zheng",
      "X. R. Zheng",
      "Y. H. Zheng",
      "B. Zhong",
      "C. Zhong",
      "H. Zhou",
      "J. Y. Zhou",
      "S. Zhou",
      "X. Zhou",
      "X. K. Zhou",
      "X. R. Zhou",
      "X. Y. Zhou",
      "Y. Z. Zhou",
      "A. N. Zhu",
      "J. Zhu",
      "K. Zhu",
      "K. J. Zhu",
      "K. S. Zhu",
      "L. Zhu",
      "L. X. Zhu",
      "S. H. Zhu",
      "T. J. Zhu",
      "W. D. Zhu",
      "W. D. Zhu",
      "W. J. Zhu",
      "W. Z. Zhu",
      "Y. C. Zhu",
      "Z. A. Zhu",
      "X. Y. Zhuang",
      "J. H. Zou",
      "J. Zu"
    ],
    "abstract": "Utilizing 4.5 $fb^-$ of $e^+e^-$ annihilation data collected at\ncenter-of-mass energies ranging from 4599.53 MeV to 4698.82 MeV by the BESIII\ndetector at the BEPCII collider, we search for the singly Cabibbo-suppressed\nhadronic decays $\\Lambda_{c}^{+}\\to\\Sigma^{0} K^{+}\\pi^{0}$ and\n$\\Lambda_{c}^{+}\\to\\Sigma^{0}K^{+}\\pi^+\\pi^-$ with a single-tag method. No\nsignificant signals are observed for both decays. The upper limits on the\nbranching fractions at the $90\\%$ confidence level are determined to be\n$5.0\\times 10^{-4}$ for $\\Lambda_{c}^{+}\\to\\Sigma^{0} K^{+}\\pi^{0}$ and\n$6.5\\times 10^{-4}$ for $\\Lambda_c^{+}\\to\\Sigma^0K^{+}\\pi^{+}\\pi^{-}$.",
    "pdf_url": "http://arxiv.org/pdf/2502.11047v1",
    "published": "2025-02-16T09:09:25+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2502.11046v2",
    "title": "Enabling Efficient Transaction Processing on CXL-Based Memory Sharing",
    "authors": [
      "Zhao Wang",
      "Yiqi Chen",
      "Cong Li",
      "Dimin Niu",
      "Tianchan Guan",
      "Zhaoyang Du",
      "Xingda Wei",
      "Guangyu Sun"
    ],
    "abstract": "Transaction processing systems are the crux for modern data-center\napplications, yet current multi-node systems are slow due to network overheads.\nThis paper advocates for Compute Express Link (CXL) as a network alternative,\nwhich enables low-latency and cache-coherent shared memory accesses. However,\ndirectly adopting standard CXL primitives leads to performance degradation due\nto the high cost of maintaining cross-node cache coherence. To address the CXL\nchallenges, this paper introduces CtXnL, a software-hardware co-designed system\nthat implements a novel hybrid coherence primitive tailored to the loosely\ncoherent nature of transactional data. The core innovation of CtXnL is\nempowering transaction system developers with the ability to selectively\nachieve data coherence. Our evaluations on OLTP workloads demonstrate that\nCtXnL enhances performance, outperforming current network-based systems and\nachieves with up to 2.08x greater throughput than vanilla CXL memory sharing\narchitectures across universal transaction processing policies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11046v2",
    "published": "2025-02-16T09:08:36+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11045v2",
    "title": "The Towers of Fibonacci, Lucas, Pell, and Jacobsthal",
    "authors": [
      "El-Mehdi Mehiri",
      "Saad Mneimneh",
      "Hacne Belbachir"
    ],
    "abstract": "We present in this paper four new variants of the Tower of Hanoi problem, the\noptimal solution of each of these variants is related to one of the four known\nnumbers Fibonacci, Lucas, Pell, and Jacobsthal. We give an optimal solution to\neach of these variants, and we present their associated graphs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11045v2",
    "published": "2025-02-16T09:07:05+00:00",
    "categories": [
      "math.CO",
      "cs.DM",
      "05C57, 00A08, 03Dxx, 11B39"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11044v1",
    "title": "Detecting Cadastral Boundary from Satellite Images Using U-Net model",
    "authors": [
      "Neda Rahimpour Anaraki",
      "Maryam Tahmasbi",
      "Saeed Reza Kheradpisheh"
    ],
    "abstract": "Finding the cadastral boundaries of farmlands is a crucial concern for land\nadministration. Therefore, using deep learning methods to expedite and simplify\nthe extraction of cadastral boundaries from satellite and unmanned aerial\nvehicle (UAV) images is critical. In this paper, we employ transfer learning to\ntrain a U-Net model with a ResNet34 backbone to detect cadastral boundaries\nthrough three-class semantic segmentation: \"boundary\", \"field\", and\n\"background\". We evaluate the performance on two satellite images from\nfarmlands in Iran using \"precision\", \"recall\", and \"F-score\", achieving high\nvalues of 88%, 75%, and 81%, respectively, which indicate promising results.",
    "pdf_url": "http://arxiv.org/pdf/2502.11044v1",
    "published": "2025-02-16T09:04:37+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11043v1",
    "title": "Analysis of the autocorrelation function for time series with higher-order temporal correlations: An exponential case",
    "authors": [
      "Min-ho Yu",
      "Hang-Hyun Jo"
    ],
    "abstract": "Temporal correlations in the time series observed in various systems have\nbeen characterized by the autocorrelation function. Such correlations can be\nexplained by heavy-tailed interevent time distributions as well as by\ncorrelations between interevent times. The latter is called higher-order\ntemporal correlations, and they have been captured by the notion of bursts; a\nburst indicates a set of consecutive events that rapidly occur within a short\ntime period and are separated from other bursts by long time intervals. The\nnumber of events in the burst is called a burst size. Some empirical analyses\nhave shown that consecutive burst sizes are correlated with each other. To\nstudy the impact of such correlations on the autocorrelation function, we\ndevise a model generating a time series with higher-order temporal correlations\nby employing the copula method. We successfully derive the analytical solution\nof the autocorrelation function of the model time series for arbitrary\ndistributions of interevent times and burst sizes when consecutive burst sizes\nare correlated. For the demonstration of our analysis, we adopt exponential\ndistributions of interevent times and burst sizes to understand how the\ncorrelations between consecutive burst sizes affect the decaying behavior of\nthe autocorrelation function.",
    "pdf_url": "http://arxiv.org/pdf/2502.11043v1",
    "published": "2025-02-16T09:03:42+00:00",
    "categories": [
      "physics.comp-ph",
      "physics.data-an"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11042v1",
    "title": "Improved VMD Based Remote Heartbeat Estimation Utilizing 60GHz mmWave Radar",
    "authors": [
      "Boyuan Gu",
      "Yanhui Yang",
      "Siyu You",
      "Haiyang Sun",
      "Jiahui Sun",
      "Shisheng Guo"
    ],
    "abstract": "This study introduces an improved VMD based signal decomposition methodology\nfor non-contact heartbeat estimation using millimeterwave (mmWave) radar.\nSpecifically, we first analyze the signal model of the mmWave radar system. The\nVariational Mode Decomposition (VMD) integrated with the Newton-Raphson-based\noptimizer (NRBO) algorithm are sequentially utilized for cardiac mechanic\nsignal (CMS) reconstruction. The estimation accuracy is enhanced by adaptively\noptimizing the VMD parameters including intrinsic mode functions (IMFs) and\npenalty factor. Eventually, the experimental results of 18 subjects validate\nthe effectiveness of the proposed method by comparing with three commonly used\nbaselines.",
    "pdf_url": "http://arxiv.org/pdf/2502.11042v1",
    "published": "2025-02-16T09:01:32+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11041v1",
    "title": "Exploring the stellar streams and satellites around the giant low surface brightness galaxy Malin 1",
    "authors": [
      "Roy O. E. Bustos-Espinoza",
      "Matias Blaa",
      "Gaspar Galaz",
      "Marcelo Mora",
      "Junais",
      "Mousumi Das",
      "Sudhanshu Barway",
      "Ankit Kumar",
      "Evelyn J. Johnston",
      "Thomas Puzia"
    ],
    "abstract": "Context. Giant Low Surface Brightness galaxies, such as Malin 1, host\nextended stellar and gaseous disks exceeding 100 kpc in radius. Their formation\nand evolution remain debated, with interactions with satellite galaxies and\naccretion streams proposed as key contributors. Malin 1 has multiple\nsatellites, including Malin 1A, Malin 1B, and the newly reported Malin 1C,\nalong with eM1 at 350 kpc. Additionally, it exhibits two giant stellar streams,\nthe largest extending 200 kpc, likely linked to past interactions.\n  Aims. We investigate the orbital dynamics of Malin 1's satellites and their\nrelationship with the observed stellar streams, testing their consistency with\ndifferent formation scenarios.\n  Methods. We constructed gravitational potentials using optical and H I\nrotation curve data, using stellar, gaseous, and dark matter components. We\nexplored a wide parameter space to see if the candidate progenitors of the\nstellar streams could have originated from past interactions, testing both NFW\nand isothermal halo profiles.\n  Results. Among ten explored scenarios, seven produced bound orbital\nsolutions. The isothermal halo model, with a virial mass of 3.8 x 10^12 solar\nmasses and a virial radius of approximately 323 kpc, favors bound satellite\norbits more than the NFW model (1.7 x 10^12 solar masses). We find that eM1\nprobably had a pericenter passage 1.3 Gyr ago, Malin 1A around 1.4 Gyr ago, and\nMalin 1B's leading arm may be experiencing one now. Malin 1C displays both\nleading and trailing arms. Furthermore, we identify three unbound orbital\nsolutions that could link eM1, Malin 1A, or Malin 1B to the streams.\n  Conclusions. The alignment of satellites and streams supports the idea that\npast interactions contributed to Malin 1's morphology, enriched its gas\nreservoir, and influenced the development of its extended disk, providing\ninsights into the evolution of gLSBGs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11041v1",
    "published": "2025-02-16T08:58:11+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.15770v2",
    "title": "Performance Review on LLM for solving leetcode problems",
    "authors": [
      "Lun Wang",
      "Chuanqi Shi",
      "Shaoshui Du",
      "Yiyi Tao",
      "Yixian Shen",
      "Hang Zheng",
      "Yanxin Shen",
      "Xinyu Qiu"
    ],
    "abstract": "This paper presents a comprehensive performance evaluation of Large Language\nModels (LLMs) in solving programming challenges from Leetcode, a widely used\nplatform for algorithm practice and technical interviews. We began by crawling\nthe Leetcode website to collect a diverse set of problems encompassing various\ndifficulty levels and topics. Using this dataset, we generated solutions with\nmultiple LLMs, including GPT-4 and GPT-3.5-turbo (ChatGPT-turbo). The generated\nsolutions were systematically evaluated for correctness and efficiency. We\nemployed the pass@k metric to assess the success rates within a given number of\nattempts and analyzed the runtime performance of the solutions. Our results\nhighlight the strengths and limitations of current LLMs [10] in code generation\nand problem-solving tasks, providing insights into their potential applications\nand areas for improvement in automated programming assistance.",
    "pdf_url": "http://arxiv.org/pdf/2502.15770v2",
    "published": "2025-02-16T08:52:45+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.11040v1",
    "title": "Nonlocal Electrical Detection of Reciprocal Orbital Edelstein Effect",
    "authors": [
      "Weiguang Gao",
      "Liyang Liao",
      "Hironari Isshiki",
      "Nico Budai",
      "Junyeon Kim",
      "Hyun-Woo Lee",
      "Kyung-Jin Lee",
      "Dongwook Go",
      "Yuriy Mokrousov",
      "Shinji Miwa",
      "Yoshichika Otani"
    ],
    "abstract": "Spin-Orbitronics leverages the spin and orbital degrees of freedom in solids\nfor information processing. The orbital Edelstein effect and orbital Hall\neffect, where the charge current induces a nonequilibrium orbital angular\nmomentum, offer a promising method to manipulate nanomagnets efficiently using\nlight elements. Despite extensive research, understanding the Onsager\nreciprocity of orbital transport, fundamentally rooted in the second law of\nthermodynamics and time-reversal symmetry, remains elusive. In this study, we\nexperimentally demonstrate the Onsager reciprocity of orbital transport in an\norbital Edelstein system by utilizing nonlocal measurements. This method\nenables the precise identification of the chemical potential generated by\norbital accumulation, avoiding the limitations associated with local\nmeasurements. Remarkably, we observe that the direct and inverse orbital-charge\nconversion processes produce identical electric voltages, confirming Onsager\nreciprocity in orbital transport. Additionally, we find that the orbital decay\nlength, approximately 100 nm at room temperature, is independent of Cu\nthickness and decreases with lowering temperature, revealing a distinct\ncontrast to spin transport behavior. Our findings provide valuable insights\ninto both the reciprocity of the charge-orbital interconversion and the\nnonlocal correlation of orbital degree of freedom, laying the ground for\norbitronics devices with long-range interconnections.",
    "pdf_url": "http://arxiv.org/pdf/2502.11040v1",
    "published": "2025-02-16T08:52:34+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11039v1",
    "title": "Compact four-manifolds with pinched self-dual Weyl curvature",
    "authors": [
      "Inyoung Kim"
    ],
    "abstract": "We consider compact four-manifolds with harmonic self-dual Weyl curvature in\naddition to a pinching condition.",
    "pdf_url": "http://arxiv.org/pdf/2502.11039v1",
    "published": "2025-02-16T08:42:39+00:00",
    "categories": [
      "math.DG",
      "53C20, 53C21, 53C55"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11038v1",
    "title": "A robust and p-hacking-proof significance test under variance uncertainty",
    "authors": [
      "Xifeng Li",
      "Shuzhen Yang",
      "Jianfeng Yao"
    ],
    "abstract": "P-hacking poses challenges to traditional hypothesis testing. In this paper,\nwe propose a robust method for the one-sample significance test that can\nprotect against p-hacking from sample manipulation. Precisely, assuming a\nsequential arrival of the data whose variance can be time-varying and for which\nonly lower and upper bounds are assumed to exist with possibly unknown values,\nwe use the modern theory of sublinear expectation to build a testing procedure\nwhich is robust under such variance uncertainty, and can protect the\nsignificance level against potential data manipulation by an experimenter. It\nis shown that our new method can effectively control the type I error while\npreserving a satisfactory power, yet a traditional rejection criterion performs\npoorly under such variance uncertainty. Our theoretical results are well\nconfirmed by a detailed simulation study.",
    "pdf_url": "http://arxiv.org/pdf/2502.11038v1",
    "published": "2025-02-16T08:37:40+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2502.11037v2",
    "title": "Deep Incomplete Multi-view Learning via Cyclic Permutation of VAEs",
    "authors": [
      "Xin Gao",
      "Jian Pu"
    ],
    "abstract": "Multi-View Representation Learning (MVRL) aims to derive a unified\nrepresentation from multi-view data by leveraging shared and complementary\ninformation across views. However, when views are irregularly missing, the\nincomplete data can lead to representations that lack sufficiency and\nconsistency. To address this, we propose Multi-View Permutation of Variational\nAuto-Encoders (MVP), which excavates invariant relationships between views in\nincomplete data. MVP establishes inter-view correspondences in the latent space\nof Variational Auto-Encoders, enabling the inference of missing views and the\naggregation of more sufficient information. To derive a valid Evidence Lower\nBound (ELBO) for learning, we apply permutations to randomly reorder variables\nfor cross-view generation and then partition them by views to maintain\ninvariant meanings under permutations. Additionally, we enhance consistency by\nintroducing an informational prior with cyclic permutations of posteriors,\nwhich turns the regularization term into a similarity measure across\ndistributions. We demonstrate the effectiveness of our approach on seven\ndiverse datasets with varying missing ratios, achieving superior performance in\nmulti-view clustering and generation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11037v2",
    "published": "2025-02-16T08:36:43+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11036v2",
    "title": "A Survey: Potential Dimensionality Reduction Methods",
    "authors": [
      "Yuan-chin Ivan Chang"
    ],
    "abstract": "Dimensionality reduction is a fundamental technique in machine learning and\ndata analysis, enabling efficient representation and visualization of\nhigh-dimensional data. This paper explores five key methods: Principal\nComponent Analysis (PCA), Kernel PCA (KPCA), Sparse Kernel PCA, t-Distributed\nStochastic Neighbor Embedding (t-SNE), and Uniform Manifold Approximation and\nProjection (UMAP). PCA provides a linear approach to capturing variance,\nwhereas KPCA and Sparse KPCA extend this concept to non-linear structures using\nkernel functions. Meanwhile, t-SNE and UMAP focus on preserving local\nrelationships, making them effective for data visualization. Each method is\nexamined in terms of its mathematical formulation, computational complexity,\nstrengths, and limitations. The trade-offs between global structure\npreservation, computational efficiency, and interpretability are discussed to\nguide practitioners in selecting the appropriate technique based on their\napplication needs.",
    "pdf_url": "http://arxiv.org/pdf/2502.11036v2",
    "published": "2025-02-16T08:28:33+00:00",
    "categories": [
      "stat.OT"
    ],
    "primary_category": "stat.OT"
  },
  {
    "id": "http://arxiv.org/abs/2502.11035v1",
    "title": "Organometallic-Inorganic Hybrid MXenes with Tunable Superconductivity",
    "authors": [
      "Qi Fan",
      "Tao Bo",
      "Wei Guo",
      "Minghua Chen",
      "Qing Tang",
      "Yicong Yang",
      "Mian Li",
      "Ke Chen",
      "Fangfang Ge",
      "Jialu Li",
      "Sicong Qiao",
      "Changda Wang",
      "Li Song",
      "Lijing Yu",
      "Jinghua Guo",
      "Michael Naguib",
      "Zhifang Chai",
      "Qing Huang",
      "Chaochao Dun",
      "Ning Kang",
      "Yury Gogotsi",
      "Kun Liang"
    ],
    "abstract": "Ti-based two-dimensional transition-metal carbides (MXenes) have attracted\nattention due to their superior properties and are being explored across\nvarious applications1,2. Despite their versatile properties, superconductivity\nhas never been demonstrated, not even predicted, for this important group of 2D\nmaterials. In this work, we have introduced an electrochemical intercalation\nprotocol to construct versatile organometallic-inorganic hybrid MXenes and\nachieved tunable superconductivity in the metallocene-modified layered\ncrystals. Through structural editing of MXene matrix at atomic scale and\nmeticulously modulated intercalation route, Ti3C2Tx intercalated with\nmetallocene species exhibits a superconductive transition temperature (Tc) of\n10.2 K. Guest intercalation induced electron filling and strain engineering are\nresponsible for the emerging superconductivity in this intrinsically\nnon-superconducting material. Theoretically, simulated electron-phonon\ninteraction effects further elucidate the nature of the changes in Tc.\nFurthermore, the Tc of crafted artificial superlattices beyond Ti-based MXenes\nhave been predicted, offering a general strategy for engineering\nsuperconductivity and magnetism in layered hybrid materials.",
    "pdf_url": "http://arxiv.org/pdf/2502.11035v1",
    "published": "2025-02-16T08:27:24+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2502.11034v1",
    "title": "AdaGC: Improving Training Stability for Large Language Model Pretraining",
    "authors": [
      "Guoxia Wang",
      "Shuai Li",
      "Congliang Chen",
      "Jinle Zeng",
      "Jiabin Yang",
      "Tao Sun",
      "Yanjun Ma",
      "Dianhai Yu",
      "Li Shen"
    ],
    "abstract": "Large Language Models (LLMs) face increasing loss spikes during scaling,\nundermining training stability and final performance. While gradient clipping\nmitigates this issue, traditional global approaches poorly handle\nparameter-specific gradient variations and decaying gradient norms. We propose\n**AdaGC**, an adaptive gradient clipping framework that automatically adjusts\nlocal thresholds per parameter through exponential moving average of gradient\nnorms. Theoretical analysis proves AdaGC's convergence under non-convex\nconditions. Extensive experiments demonstrate significant improvements: On\nLlama-2 7B/13B, AdaGC completely eliminates loss spikes while reducing WikiText\nperplexity by 3.5% (+0.14pp LAMBADA accuracy) for 7B and achieving 0.65% lower\ntraining loss with 1.47% reduced validation perplexity for 13B compared to\nglobal clipping. For CLIP ViT-Base, AdaGC converges 25% faster than StableAdamW\nwith full spike elimination. The method shows universal effectiveness across\narchitectures (Llama-2 7B/13B) and modalities (CLIP), with successful\nintegration into diverse optimizers like AdamW and Lion. Source code will be\nreleased on GitHub.",
    "pdf_url": "http://arxiv.org/pdf/2502.11034v1",
    "published": "2025-02-16T08:13:23+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11033v3",
    "title": "Convergence of Policy Mirror Descent Beyond Compatible Function Approximation",
    "authors": [
      "Uri Sherman",
      "Tomer Koren",
      "Yishay Mansour"
    ],
    "abstract": "Modern policy optimization methods roughly follow the policy mirror descent\n(PMD) algorithmic template, for which there are by now numerous theoretical\nconvergence results. However, most of these either target tabular environments,\nor can be applied effectively only when the class of policies being optimized\nover satisfies strong closure conditions, which is typically not the case when\nworking with parametric policy classes in large-scale environments. In this\nwork, we develop a theoretical framework for PMD for general policy classes\nwhere we replace the closure conditions with a strictly weaker variational\ngradient dominance assumption, and obtain upper bounds on the rate of\nconvergence to the best-in-class policy. Our main result leverages a novel\nnotion of smoothness with respect to a local norm induced by the occupancy\nmeasure of the current policy, and casts PMD as a particular instance of smooth\nnon-convex optimization in non-Euclidean space.",
    "pdf_url": "http://arxiv.org/pdf/2502.11033v3",
    "published": "2025-02-16T08:05:46+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11032v1",
    "title": "Exact variance estimation for model-assisted survey estimators using U- and V-statistics",
    "authors": [
      "Ameer Dharamshi",
      "Peter Gao",
      "Jon Wakefield"
    ],
    "abstract": "Model-assisted estimation combines sample survey data with auxiliary\ninformation to increase precision when estimating finite population quantities.\nAccurately estimating the variance of model-assisted estimators is challenging:\nthe classical approach ignores uncertainty from estimating the working model\nfor the functional relationship between survey and auxiliary variables. This\napproach may be asymptotically valid, but can underestimate variance in\npractical settings with limited sample sizes. In this work, we develop a\nconnection between model-assisted estimation and the theory of U- and\nV-statistics. We demonstrate that when predictions from the working model for\nthe variable of interest can be represented as a U- or V-statistic, the\nresulting model-assisted estimator also admits a U- or V-statistic\nrepresentation. We exploit this connection to derive an improved estimator of\nthe exact variance of such model-assisted estimators. The class of working\nmodels for which this strategy can be used is broad, ranging from linear models\nto modern ensemble methods. We apply our approach to the model-assisted\nestimator constructed with a linear regression working model, commonly referred\nto as the generalized regression estimator, show that it can be re-written as a\nU-statistic, and propose an estimator of its exact variance. We illustrate our\nproposal and compare it against the classical asymptotic variance estimator\nusing household survey data from the American Community Survey.",
    "pdf_url": "http://arxiv.org/pdf/2502.11032v1",
    "published": "2025-02-16T07:56:27+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.11031v1",
    "title": "A Critical Review of Predominant Bias in Neural Networks",
    "authors": [
      "Jiazhi Li",
      "Mahyar Khayatkhoei",
      "Jiageng Zhu",
      "Hanchen Xie",
      "Mohamed E. Hussein",
      "Wael AbdAlmageed"
    ],
    "abstract": "Bias issues of neural networks garner significant attention along with its\npromising advancement. Among various bias issues, mitigating two predominant\nbiases is crucial in advancing fair and trustworthy AI: (1) ensuring neural\nnetworks yields even performance across demographic groups, and (2) ensuring\nalgorithmic decision-making does not rely on protected attributes. However,\nupon the investigation of \\pc papers in the relevant literature, we find that\nthere exists a persistent, extensive but under-explored confusion regarding\nthese two types of biases. Furthermore, the confusion has already significantly\nhampered the clarity of the community and subsequent development of debiasing\nmethodologies. Thus, in this work, we aim to restore clarity by providing two\nmathematical definitions for these two predominant biases and leveraging these\ndefinitions to unify a comprehensive list of papers. Next, we highlight the\ncommon phenomena and the possible reasons for the existing confusion. To\nalleviate the confusion, we provide extensive experiments on synthetic, census,\nand image datasets, to validate the distinct nature of these biases,\ndistinguish their different real-world manifestations, and evaluate the\neffectiveness of a comprehensive list of bias assessment metrics in assessing\nthe mitigation of these biases. Further, we compare these two types of biases\nfrom multiple dimensions including the underlying causes, debiasing methods,\nevaluation protocol, prevalent datasets, and future directions. Last, we\nprovide several suggestions aiming to guide researchers engaged in bias-related\nwork to avoid confusion and further enhance clarity in the community.",
    "pdf_url": "http://arxiv.org/pdf/2502.11031v1",
    "published": "2025-02-16T07:55:19+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11030v1",
    "title": "Log-Periodic Power Law Singularities in Landslide Dynamics: Statistical Evidence from 52 Crises",
    "authors": [
      "Qinghua Lei",
      "Didier Sornette"
    ],
    "abstract": "Landslide movements typically show a series of progressively shorter\nquiescent phases, punctuated by sudden bursts during an acceleration crisis. We\npropose that such intermittent rupture phenomena can be described by a\nlog-periodic power law singularity model. Amounting mathematically to a\ngeneralization of the power law exponent from real to complex numbers, this\nmodel captures the partial break of continuous scale invariance to discrete\nscale invariance that is inherent to the intermittent dynamics of damage and\nrupture processes in heterogeneous geomaterials. By performing parametric and\nnonparametric tests on a large dataset of 52 landslides, we present empirical\nevidence and theoretical arguments demonstrating the statistical significance\nof log-periodic oscillations decorating power law finite-time singularities\nduring landslide crises. Log-periodic landslide motions may stem from the\ninteraction between frictional stress drop along geological structures and\nstress corrosion damage in rock bridges, as well as the interplay of inertia,\ndamage, and healing.",
    "pdf_url": "http://arxiv.org/pdf/2502.11030v1",
    "published": "2025-02-16T07:52:54+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11029v1",
    "title": "HawkEye: Statically and Accurately Profiling the Communication Cost of Models in Multi-party Learning",
    "authors": [
      "Wenqiang Ruan",
      "Xin Lin",
      "Ruisheng Zhou",
      "Guopeng Lin",
      "Shui Yu",
      "Weili Han"
    ],
    "abstract": "Multi-party computation (MPC) based machine learning, referred to as\nmulti-party learning (MPL), has become an important technology for utilizing\ndata from multiple parties with privacy preservation. In recent years, in order\nto apply MPL in more practical scenarios, various MPC-friendly models have been\nproposedto reduce the extraordinary communication overhead of MPL. Within the\noptimization of MPC-friendly models, a critical element to tackle the challenge\nis profiling the communication cost of models. However, the current solutions\nmainly depend on manually establishing the profiles to identify communication\nbottlenecks of models, often involving burdensome human efforts in a monotonous\nprocedure.\n  In this paper, we propose HawkEye, a static model communication cost\nprofiling framework, which enables model designers to get the accurate\ncommunication cost of models in MPL frameworks without dynamically running the\nsecure model training or inference processes on a specific MPL framework.\nFirstly, to profile the communication cost of models with complex structures,\nwe propose a static communication cost profiling method based on a prefix\nstructure that records the function calling chain during the static analysis.\nSecondly, HawkEye employs an automatic differentiation library to assist model\ndesigners in profiling the communication cost of models in PyTorch. Finally, we\ncompare the static profiling results of HawkEye against the profiling results\nobtained through dynamically running secure model training and inference\nprocesses on five popular MPL frameworks, CryptFlow2, CrypTen, Delphi, Cheetah,\nand SecretFlow-SEMI2K. The experimental results show that HawkEye can\naccurately profile the model communication cost without dynamic profiling.",
    "pdf_url": "http://arxiv.org/pdf/2502.11029v1",
    "published": "2025-02-16T07:49:27+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11028v2",
    "title": "Mind the Confidence Gap: Overconfidence, Calibration, and Distractor Effects in Large Language Models",
    "authors": [
      "Prateek Chhikara"
    ],
    "abstract": "Large Language Models (LLMs) show remarkable proficiency in natural language\ntasks, yet their frequent overconfidence-misalignment between predicted\nconfidence and true correctness-poses significant risks in critical\ndecision-making applications. We present a comprehensive analysis on\ncalibration in LLMs across nine LLMs and three factual Question-Answering (QA)\ndatasets, systematically comparing standard free-generation settings against\nstructured distractor-augmented prompts. Our evaluation reveals that explicitly\nincorporating distractors can substantially mitigate miscalibration, achieving\nrelative accuracy improvements up to 460% and ECE reductions up to 90%. Despite\ngeneral trends, we uncover nuanced findings: large RLHF-tuned models display\ninherent calibration strengths but can paradoxically suffer increased\nmiscalibration on easier queries, whereas smaller models benefit\ndisproportionately from distractor prompts but remain significantly\nmiscalibrated. Through detailed analyses across question types, we identify\npersistent calibration failures, particularly in person-based queries. We\nconclude with concrete recommendations-targeted fine-tuning, structured\nprompting, and strategic model choice-to ensure reliable, trustworthy LLM\ndeployments.",
    "pdf_url": "http://arxiv.org/pdf/2502.11028v2",
    "published": "2025-02-16T07:46:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2503.00008v1",
    "title": "An Efficient Algorithm for Determining the Equivalence of Zero-one Reaction Networks",
    "authors": [
      "Yue Jiao",
      "Xiaoxian Tang"
    ],
    "abstract": "Zero-one reaction networks play a crucial role in cell signaling. Determining\nthe equivalence of reaction networks is a fundamental computational problem in\nthe field of chemical reaction networks. In this work, we develop an efficient\nmethod for determining the equivalence of zero-one networks. The efficiency\ncomes from several criteria for determining the equivalence of the steady-state\nideals arising from zero-one networks, which helps for cutting down the\nexpenses on computing Grobner bases. Experiments show that our method can\nsuccessfully classify over three million networks according to their\nequivalence in a reasonable time.",
    "pdf_url": "http://arxiv.org/pdf/2503.00008v1",
    "published": "2025-02-16T07:41:58+00:00",
    "categories": [
      "q-bio.MN"
    ],
    "primary_category": "q-bio.MN"
  },
  {
    "id": "http://arxiv.org/abs/2502.11027v2",
    "title": "Diversified Sampling Improves Scaling LLM inference",
    "authors": [
      "Tianchun Wang",
      "Zichuan Liu",
      "Yuanzhou Chen",
      "Jonathan Light",
      "Haifeng Chen",
      "Xiang Zhang",
      "Wei Cheng"
    ],
    "abstract": "While increasing training compute has significantly improved the performance\nof large language models (LLMs), similar gains have not been observed when\nscaling inference compute. We hypothesize that the primary issue lies in the\nuniformity of LLM outputs, which leads to inefficient sampling as models\nrepeatedly generate similar but inaccurate responses. Motivated by an\nintriguing relationship between solution accuracy and response diversity, we\npropose DivSampling -- a novel and versatile sampling technique designed to\nenhance the diversity of candidate solutions by introducing prompt\nperturbations.DivSampling incorporates two categories of perturbations:\ntask-agnostic approaches, which are general and not tailored to any specific\ntask, and task-specific approaches, which are customized based on task content.\nOur theoretical analysis demonstrates that, under mild assumptions, the error\nrates of responses generated from diverse prompts are significantly lower\ncompared to those produced by stationary prompts. Comprehensive evaluations\nacross various tasks -- including reasoning, mathematics, and code generation\n-- highlight the effectiveness of DivSampling in improving solution accuracy.\nThis scalable and efficient approach offers a new perspective on optimizing\ntest-time inference, addressing limitations in current sampling strategies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11027v2",
    "published": "2025-02-16T07:37:58+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.14886v1",
    "title": "Surgical Scene Understanding in the Era of Foundation AI Models: A Comprehensive Review",
    "authors": [
      "Ufaq Khan",
      "Umair Nawaz",
      "Adnan Qayyum",
      "Shazad Ashraf",
      "Muhammad Bilal",
      "Junaid Qadir"
    ],
    "abstract": "Recent advancements in machine learning (ML) and deep learning (DL),\nparticularly through the introduction of foundational models (FMs), have\nsignificantly enhanced surgical scene understanding within minimally invasive\nsurgery (MIS). This paper surveys the integration of state-of-the-art ML and DL\ntechnologies, including Convolutional Neural Networks (CNNs), Vision\nTransformers (ViTs), and foundational models like the Segment Anything Model\n(SAM), into surgical workflows. These technologies improve segmentation\naccuracy, instrument tracking, and phase recognition in surgical endoscopic\nvideo analysis. The paper explores the challenges these technologies face, such\nas data variability and computational demands, and discusses ethical\nconsiderations and integration hurdles in clinical settings. Highlighting the\nroles of FMs, we bridge the technological capabilities with clinical needs and\noutline future research directions to enhance the adaptability, efficiency, and\nethical alignment of AI applications in surgery. Our findings suggest that\nsubstantial progress has been made; however, more focused efforts are required\nto achieve seamless integration of these technologies into clinical workflows,\nensuring they complement surgical practice by enhancing precision, reducing\nrisks, and optimizing patient outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2502.14886v1",
    "published": "2025-02-16T07:27:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11026v2",
    "title": "Simplify RLHF as Reward-Weighted SFT: A Variational Method",
    "authors": [
      "Yuhao Du",
      "Zhuo Li",
      "Pengyu Cheng",
      "Zhihong Chen",
      "Yuejiao Xie",
      "Xiang Wan",
      "Anningzhe Gao"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is crucial for aligning\nLarge Language Models (LLMs) with human values. However, RLHF has been\ncontinuously challenged by its high complexity in implementation and\ncomputation consumption. Even with recent simplifications, such as Direct\nPreference Optimization (DPO) and Advantage Leftover Lunch (A-LoL), the\nproblems of over-fitting and training instability remain hindering the\nalignment process from the expected optimal performance. To address the\nexisting challenges, we propose a novel simplification of RLHF from the\nperspective of variational inference, called $\\textbf{V}$ariational\n$\\textbf{A}$lignment with $\\textbf{R}$e-weighting ($\\textbf{VAR}$). More\nspecifically, by directly minimizing the distribution gap between the learning\nLLM policy and the optimal solution of RLHF, we transform the alignment\nobjective into a reward-driven re-weighted supervised fine-tuning (SFT) form,\nwhich only requires minor adjustment on the SFT loss to obtain noticeable\nimprovement on training stability and effectiveness. On comprehensive alignment\nand generation benchmarks, our VAR method has numerically achieved competitive\nperformance in LLM alignment helpfulness and harmlessness.",
    "pdf_url": "http://arxiv.org/pdf/2502.11026v2",
    "published": "2025-02-16T07:22:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11025v2",
    "title": "The automorphism group of an Apry-Fermi K3 surface",
    "authors": [
      "Ichiro Shimada"
    ],
    "abstract": "An Ap\\'ery-Fermi K3 surface is a complex K3 surface of Picard number 19 that\nis birational to a general member of a certain one-dimensional family of affine\nsurfaces related to the Fermi surface in solid-state physics. This K3 surface\nis also linked to a recurrence relation that appears in the famous proof of the\nirrationality of zeta(3) by Ap\\'ery. We compute the automorphism group Aut(X)\nof the Ap\\'ery-Fermi K3 surface X using Borcherds' method. We describe Aut(X)\nin terms of generators and relations. Moreover, we determine the action of\nAut(X) on the set of ADE-configurations of smooth rational curves on X for some\nADE-types. In particular, we show that Aut(X) acts transitively on the set of\nsmooth rational curves, and that it partitions the set of pairs of disjoint\nsmooth rational curves into two orbits.",
    "pdf_url": "http://arxiv.org/pdf/2502.11025v2",
    "published": "2025-02-16T07:19:50+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11024v1",
    "title": "TPCap: Unlocking Zero-Shot Image Captioning with Trigger-Augmented and Multi-Modal Purification Modules",
    "authors": [
      "Ruoyu Zhang",
      "Lulu Wang",
      "Yi He",
      "Tongling Pan",
      "Zhengtao Yu",
      "Yingna Li"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced the fluency and logical coherence of image captioning.\nRetrieval-Augmented Generation (RAG) is widely adopted to incorporate external\nknowledge into LLMs; however, existing RAG-based methods rely on separate\nretrieval banks, introducing computational overhead and limiting the\nutilization of LLMs' inherent zero-shot capabilities. To address these\nlimitations, we propose TPCap, a novel trigger-augmented and multi-modal\npurification framework for zero-shot image captioning without external\nretrieval libraries. TPCap consists of two key components: trigger-augmented\n(TA) generation and multi-modal purification (MP). The TA module employs a\ntrigger projector with frozen and learnable projections to activate LLMs'\ncontextual reasoning, enhance visual-textual alignment, and mitigate data bias.\nThe MP module further refines the generated entity-related information by\nfiltering noise and enhancing feature quality, ensuring more precise and\nfactually consistent captions. We evaluate TPCap on COCO, NoCaps, Flickr30k,\nand WHOOPS datasets. With only 0.82M trainable parameters and training on a\nsingle NVIDIA RTX 4090 GPU, TPCap achieves competitive performance comparable\nto state-of-the-art models.",
    "pdf_url": "http://arxiv.org/pdf/2502.11024v1",
    "published": "2025-02-16T07:16:03+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11023v1",
    "title": "DT4ECG: A Dual-Task Learning Framework for ECG-Based Human Identity Recognition and Human Activity Detection",
    "authors": [
      "Siyu You",
      "Boyuan Gu",
      "Yanhui Yang",
      "Shiyu Yu",
      "Shisheng Guo"
    ],
    "abstract": "This article introduces DT4ECG, an innovative dual-task learning framework\nfor Electrocardiogram (ECG)-based human identity recognition and activity\ndetection. The framework employs a robust one-dimensional convolutional neural\nnetwork (1D-CNN) backbone integrated with residual blocks to extract\ndiscriminative ECG features. To enhance feature representation, we propose a\nnovel Sequence Channel Attention (SCA) mechanism, which combines channel-wise\nand sequential context attention to prioritize informative features across both\ntemporal and channel dimensions. Furthermore, to address gradient imbalance in\nmulti-task learning, we integrate GradNorm, a technique that dynamically\nadjusts loss weights based on gradient magnitudes, ensuring balanced training\nacross tasks. Experimental results demonstrate the superior performance of our\nmodel, achieving accuracy rates of 99.12% in ID classification and 90.11% in\nactivity classification. These findings underscore the potential of the DT4ECG\nframework in enhancing security and user experience across various applications\nsuch as fitness monitoring and personalized healthcare, thereby presenting a\ntransformative approach to integrating ECG-based biometrics in everyday\ntechnologies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11023v1",
    "published": "2025-02-16T07:13:59+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.11022v1",
    "title": "MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query Translation",
    "authors": [
      "Zhiqian Qin",
      "Yuanfeng Song",
      "Jinwei Lu",
      "Yuanwei Song",
      "Shuaimin Li",
      "Chen Jason Zhang"
    ],
    "abstract": "Natural language interfaces for NoSQL databases are increasingly vital in the\nbig data era, enabling users to interact with complex, unstructured data\nwithout deep technical expertise. However, most recent advancements focus on\nEnglish, leaving a gap for multilingual support. This paper introduces\nMultiTEND, the first and largest multilingual benchmark for natural language to\nNoSQL query generation, covering six languages: English, German, French,\nRussian, Japanese and Mandarin Chinese. Using MultiTEND, we analyze challenges\nin translating natural language to NoSQL queries across diverse linguistic\nstructures, including lexical and syntactic differences. Experiments show that\nperformance accuracy in both English and non-English settings remains\nrelatively low, with a 4%-6% gap across scenarios like fine-tuned SLM,\nzero-shot LLM, and RAG for LLM. To address the aforementioned challenges, we\nintroduce MultiLink, a novel framework that bridges the multilingual input to\nNoSQL query generation gap through a Parallel Linking Process. It breaks down\nthe task into multiple steps, integrating parallel multilingual processing,\nChain-of-Thought (CoT) reasoning, and Retrieval-Augmented Generation (RAG) to\ntackle lexical and structural challenges inherent in multilingual NoSQL\ngeneration. MultiLink shows enhancements in all metrics for every language\nagainst the top baseline, boosting execution accuracy by about 15% for English\nand averaging a 10% improvement for non-English languages.",
    "pdf_url": "http://arxiv.org/pdf/2502.11022v1",
    "published": "2025-02-16T07:12:47+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11021v1",
    "title": "Leveraging Uncertainty Estimation for Efficient LLM Routing",
    "authors": [
      "Tuo Zhang",
      "Asal Mehradfar",
      "Dimitrios Dimitriadis",
      "Salman Avestimehr"
    ],
    "abstract": "Deploying large language models (LLMs) in edge-cloud environments requires an\nefficient routing strategy to balance cost and response quality. Traditional\napproaches prioritize either human-preference data or accuracy metrics from\nbenchmark datasets as routing criteria, but these methods suffer from rigidity\nand subjectivity. Moreover, existing routing frameworks primarily focus on\naccuracy and cost, neglecting response quality from a human preference\nperspective. In this work, we propose the Confidence-Driven LLM Router, a novel\nframework that leverages uncertainty estimation to optimize routing decisions.\nTo comprehensively assess routing performance, we evaluate both system cost\nefficiency and response quality. In particular, we introduce the novel use of\nLLM-as-a-Judge to simulate human rating preferences, providing the first\nsystematic assessment of response quality across different routing strategies.\nExtensive experiments on MT-Bench, GSM8K, and MMLU demonstrate that our\napproach outperforms state-of-the-art routing methods, achieving superior\nresponse quality while maintaining cost efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2502.11021v1",
    "published": "2025-02-16T07:08:47+00:00",
    "categories": [
      "cs.NI",
      "cs.CL"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2502.11020v2",
    "title": "TUMLU: A Unified and Native Language Understanding Benchmark for Turkic Languages",
    "authors": [
      "Jafar Isbarov",
      "Arofat Akhundjanova",
      "Mammad Hajili",
      "Kavsar Huseynova",
      "Dmitry Gaynullin",
      "Anar Rzayev",
      "Osman Tursun",
      "Aizirek Turdubaeva",
      "Ilshat Saetov",
      "Rinat Kharisov",
      "Saule Belginova",
      "Ariana Kenbayeva",
      "Amina Alisheva",
      "Abdullatif Kksal",
      "Samir Rustamov",
      "Duygu Ataman"
    ],
    "abstract": "Being able to thoroughly assess massive multi-task language understanding\n(MMLU) capabilities is essential for advancing the applicability of\nmultilingual language models. However, preparing such benchmarks in high\nquality native language is often costly and therefore limits the\nrepresentativeness of evaluation datasets. While recent efforts focused on\nbuilding more inclusive MMLU benchmarks, these are conventionally built using\nmachine translation from high-resource languages, which may introduce errors\nand fail to account for the linguistic and cultural intricacies of the target\nlanguages. In this paper, we address the lack of native language MMLU benchmark\nespecially in the under-represented Turkic language family with distinct\nmorphosyntactic and cultural characteristics. We propose two benchmarks for\nTurkic language MMLU: TUMLU is a comprehensive, multilingual, and natively\ndeveloped language understanding benchmark specifically designed for Turkic\nlanguages. It consists of middle- and high-school level questions spanning 11\nacademic subjects in Azerbaijani, Crimean Tatar, Karakalpak, Kazakh, Tatar,\nTurkish, Uyghur, and Uzbek. We also present TUMLU-mini, a more concise,\nbalanced, and manually verified subset of the dataset. Using this dataset, we\nsystematically evaluate a diverse range of open and proprietary multilingual\nlarge language models (LLMs), including Claude, Gemini, GPT, and LLaMA,\noffering an in-depth analysis of their performance across different languages,\nsubjects, and alphabets. To promote further research and development in\nmultilingual language understanding, we release TUMLU-mini and all\ncorresponding evaluation scripts.",
    "pdf_url": "http://arxiv.org/pdf/2502.11020v2",
    "published": "2025-02-16T07:07:38+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11019v2",
    "title": "Unlocking the Power of Function Vectors for Characterizing and Mitigating Catastrophic Forgetting in Continual Instruction Tuning",
    "authors": [
      "Gangwei Jiang",
      "Caigao Jiang",
      "Zhaoyi Li",
      "Siqiao Xue",
      "Jun Zhou",
      "Linqi Song",
      "Defu Lian",
      "Ying Wei"
    ],
    "abstract": "Catastrophic forgetting (CF) poses a significant challenge in machine\nlearning, where a model forgets previously learned information upon learning\nnew tasks. Despite the advanced capabilities of Large Language Models (LLMs),\nthey continue to face challenges with CF during continual learning. The\nmajority of existing research focuses on analyzing forgetting patterns through\na singular training sequence, thereby overlooking the intricate effects that\ndiverse tasks have on model behavior. Our study explores CF across various\nsettings, discovering that model forgetting is influenced by both the specific\ntraining tasks and the models themselves. To this end, we interpret forgetting\nby examining the function vector (FV), a compact representation of functions in\nLLMs, offering a model-dependent indicator for the occurrence of CF. Through\ntheoretical and empirical analyses, we demonstrated that CF in LLMs primarily\nstems from biases in function activation rather than the overwriting of task\nprocessing functions. Leveraging these insights, we propose a novel function\nvector guided training methodology, incorporating a regularization technique to\nstabilize the FV and mitigate forgetting. Empirical tests on four benchmarks\nconfirm the effectiveness of our proposed training method, substantiating our\ntheoretical framework concerning CF and model function dynamics. We plan to\nmake our code publicly accessible in the near future.",
    "pdf_url": "http://arxiv.org/pdf/2502.11019v2",
    "published": "2025-02-16T07:06:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11018v2",
    "title": "GRIFFIN: Effective Token Alignment for Faster Speculative Decoding",
    "authors": [
      "Shijing Hu",
      "Jingyang Li",
      "Xingyu Xie",
      "Zhihui Lu",
      "Kim-Chuan Toh",
      "Pan Zhou"
    ],
    "abstract": "Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating multiple draft tokens simultaneously. However, existing methods\noften struggle with token misalignment between the training and decoding\nphases, limiting their performance. To address this, we propose GRIFFIN, a\nnovel framework that incorporates a token-alignable training strategy and a\ntoken-alignable draft model to mitigate misalignment. The training strategy\nemploys a loss masking mechanism to exclude highly misaligned tokens during\ntraining, preventing them from negatively impacting the draft model's\noptimization. The token-alignable draft model introduces input tokens to\ncorrect inconsistencies in generated features. Experiments on LLaMA, Vicuna,\nQwen and Mixtral models demonstrate that GRIFFIN achieves an average acceptance\nlength improvement of over 8% and a speedup ratio exceeding 7%, outperforming\ncurrent speculative decoding state-of-the-art methods. Our code and GRIFFIN's\ndraft models are released publicly in https://github.com/hsj576/GRIFFIN.",
    "pdf_url": "http://arxiv.org/pdf/2502.11018v2",
    "published": "2025-02-16T07:06:00+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.12201v1",
    "title": "Global Ashkin-Teller Phase Diagrams in Two and Three Dimensions: Multicritical Bifurcation versus Double Tricriticality Endpoint",
    "authors": [
      "Ibrahim Kecoglu",
      "A. Nihat Berker"
    ],
    "abstract": "The global phase diagrams of the Askin-Teller model are calculated in d=2 and\n3 by renormalization-group theory that is exact on the hierarchical lattice and\napproximate on the recently improved Migdal-Kadanoff procedure. Three different\nordered phases occur in the dimensionally distinct phase diagrams that reflect\nthree-fold order-parameter permutation symmetry, a closed symmetry line, and a\nquasi-disorder line. First- and second-order phase boundaries are obtained. In\nd=2, second-order phase transitions meeting at a bifurcation point are seen. In\nd=3, first- and second-order phase transitions are separated by tricritical and\ncritical endpoints.",
    "pdf_url": "http://arxiv.org/pdf/2502.12201v1",
    "published": "2025-02-16T06:57:53+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2502.11017v2",
    "title": "Scalable Binary CUR Low-Rank Approximation Algorithm",
    "authors": [
      "Bowen Su"
    ],
    "abstract": "This paper proposes a scalable binary CUR low-rank approximation algorithm\nthat leverages parallel selection of representative rows and columns within a\ndeterministic framework. By employing a blockwise adaptive cross approximation\nstrategy, the algorithm efficiently identifies dominant components in\nlarge-scale matrices, thereby reducing computational costs. Numerical\nexperiments on $16,384 \\times 16,384$ matrices demonstrate a good speed-up,\nwith execution time decreasing from $12.37$ seconds using $2$ processes to\n$1.02$ seconds using $64$ processes. The tests on Hilbert matrices and\nsynthetic low-rank matrices of different size across various sizes demonstrate\nan near-optimal reconstruction accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2502.11017v2",
    "published": "2025-02-16T06:57:32+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "cs.PF"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.11016v1",
    "title": "Global attractivity criteria for a discrete-time Hopfield neural network model with unbounded delays via singular M-matrices",
    "authors": [
      "Jos J. Oliveira",
      "Ana Sofia Teixeira"
    ],
    "abstract": "In this work, we establish two global attractivity criteria for a\nmultidimensional discrete-time non-autonomous Hopfield neural network model\nwith infinite delays and delays in the leakage terms. The first criterion,\nwhich applies when the activation functions are bounded, is based on M-matrices\nthat are not necessarily invertible. The second criterion, relevant for\nunbounded activation functions, requires that a related singular M-matrix be\nirreducible. We contrast our findings with existing results in the literature\nand present numerical simulations to illustrate the efficacy of the proposed\ncriteria.",
    "pdf_url": "http://arxiv.org/pdf/2502.11016v1",
    "published": "2025-02-16T06:52:12+00:00",
    "categories": [
      "math.DS",
      "39A12, 39A30, 39A60, 92B20"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.11015v2",
    "title": "Wireless charging and readout via textile coil for continuous full-body wearable computing",
    "authors": [
      "Ryo Takahashi",
      "Yoshihiro Kawahara"
    ],
    "abstract": "The growing use of wearable devices for activity tracking, healthcare, and\nhaptics faces challenges due to the bulkiness and short lifespan of batteries.\nIntegration of a textile-based wireless charging and readout system into\neveryday clothing can enable seamless power supply and data collection around\nthe body. However, expanding such system to cover the entire body is\nchallenging, as it increases electromagnetic interference with the body,\ndegrading the performance of wireless system. This article introduces a\nmeandered textile coil designed for body-scale, efficient wireless charging and\nreadout. The meander coil can confine a strong inductive field near the body\nsurface, ensuring W-class safe charging and sensitive readout with uW-class low\npower. Moreover, its zigzag design is simple enough for mass production on\nindustrial knitting machines. Therefore, the body-scale meander coil can\ncontinuously operate battery-free wearable devices across the body, leading to\nubiquitous deployment of continuous full-body wearable computing into everyday\nclothing.",
    "pdf_url": "http://arxiv.org/pdf/2502.11015v2",
    "published": "2025-02-16T06:47:40+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2502.11014v1",
    "title": "Leveraging Large Language Models for Cybersecurity: Enhancing SMS Spam Detection with Robust and Context-Aware Text Classification",
    "authors": [
      "Mohsen Ahmadi",
      "Matin Khajavi",
      "Abbas Varmaghani",
      "Ali Ala",
      "Kasra Danesh",
      "Danial Javaheri"
    ],
    "abstract": "This study evaluates the effectiveness of different feature extraction\ntechniques and classification algorithms in detecting spam messages within SMS\ndata. We analyzed six classifiers Naive Bayes, K-Nearest Neighbors, Support\nVector Machines, Linear Discriminant Analysis, Decision Trees, and Deep Neural\nNetworks using two feature extraction methods: bag-of-words and TF-IDF. The\nprimary objective was to determine the most effective classifier-feature\ncombination for SMS spam detection. Our research offers two main contributions:\nfirst, by systematically examining various classifier and feature extraction\npairings, and second, by empirically evaluating their ability to distinguish\nspam messages. Our results demonstrate that the TF-IDF method consistently\noutperforms the bag-of-words approach across all six classifiers. Specifically,\nNaive Bayes with TF-IDF achieved the highest accuracy of 96.2%, with a\nprecision of 0.976 for non-spam and 0.754 for spam messages. Similarly, Support\nVector Machines with TF-IDF exhibited an accuracy of 94.5%, with a precision of\n0.926 for non-spam and 0.891 for spam. Deep Neural Networks using TF-IDF\nyielded an accuracy of 91.0%, with a recall of 0.991 for non-spam and 0.415 for\nspam messages. In contrast, classifiers such as K-Nearest Neighbors, Linear\nDiscriminant Analysis, and Decision Trees showed weaker performance, regardless\nof the feature extraction method employed. Furthermore, we observed substantial\nvariability in classifier effectiveness depending on the chosen feature\nextraction technique. Our findings emphasize the significance of feature\nselection in SMS spam detection and suggest that TF-IDF, when paired with Naive\nBayes, Support Vector Machines, or Deep Neural Networks, provides the most\nreliable performance. These insights provide a foundation for improving SMS\nspam detection through optimized feature extraction and classification methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.11014v1",
    "published": "2025-02-16T06:39:36+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11013v4",
    "title": "Collaborative Deterministic-Probabilistic Forecasting for Real-World Spatiotemporal Systems",
    "authors": [
      "Zhi Sheng",
      "Yuan Yuan",
      "Yudi Zhang",
      "Depeng Jin",
      "Yong Li"
    ],
    "abstract": "Probabilistic forecasting is crucial for real-world spatiotemporal systems,\nsuch as climate, energy, and urban environments, where quantifying uncertainty\nis essential for informed, risk-aware decision-making. While diffusion models\nhave shown promise in capturing complex data distributions, their application\nto spatiotemporal forecasting remains limited due to complex spatiotemporal\ndynamics and high computational demands. In this work, we propose CoST, a novel\nframework that collaborates deterministic and diffusion models for\nspatiotemporal forecasting. CoST formulates a mean-residual decomposition\nstrategy: it leverages a powerful deterministic model to capture the\nconditional mean and a lightweight diffusion model to learn residual\nuncertainties. This collaborative formulation simplifies learning objectives,\nenhances forecasting accuracy, enables uncertainty quantification, and\nsignificantly improves computational efficiency. To address spatial\nheterogeneity, we further design a scale-aware diffusion mechanism to guide the\ndiffusion process. Extensive experiments across ten real-world datasets from\nclimate, energy, communication, and urban systems show that CoST achieves 25%\nperformance gains over state-of-the-art baselines, while significantly reducing\ncomputational cost.",
    "pdf_url": "http://arxiv.org/pdf/2502.11013v4",
    "published": "2025-02-16T06:35:26+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11012v2",
    "title": "The Impact of $^{12}$C($, $)$^{16}$O Reaction on the Presupernova Evolution and Supernova Explodability of Massive Stars",
    "authors": [
      "Wenyu Xin",
      "Ken'ichi Nomoto",
      "Gang Zhao"
    ],
    "abstract": "Among the uncertainties of stellar evolution theory, we investigate how the\n$^{12}$C($\\alpha, \\gamma$)$^{16}$O reaction rate affects the evolution of\nmassive stars for the initial masses of $M ({\\rm ZAMS})=$ 13 - 40 M$_\\odot$ and\nthe solar metallicity. We show that the {\\sl explodability} of these stars,\ni.e., which of a neutron star (NS) or a black hole (BH) is formed, is sensitive\nto the strength of convective shell burning of C and O, and thus the mass\nfractions of C ($X$(C)) and O in the shell. For the small $^{12}$C($\\alpha,\n\\gamma$)$^{16}$O reaction rate that yields larger $X$(C), $X$(C) is further\nenhanced by mixing of C from the overlying layer and then C shell burning is\nstrengthened. The extra heating by C shell burning tends to prevent the\ncontraction of outer layers and decrease the {\\sl compactness parameter} at\n$M_r$ = 2.5 M$_\\odot$. This effect leads to the formation of smaller mass cores\nof Si and Fe and steeper density and pressure gradients at the O burning shell\nin the presupernova models. If the pressure gradient there is steeper, the\nmodel is more likely to explode to form a NS rather than a BH. We describe the\npressure gradient against $M_r$ with $V/U$ and the density drop with $1/U$,\nwhere $U$ and $V$ are non-dimensional variables to describe the stellar\nstructure. We estimate the critical values of $V/U$ and $1/U$ at the O-burning\nshell above which the model is more likely to explode. We conclude that the\nsmaller $^{12}$C($\\alpha, \\gamma$)$^{16}$O reaction rate makes the mass range\nof $M ({\\rm ZAMS})$ that forms a NS larger.",
    "pdf_url": "http://arxiv.org/pdf/2502.11012v2",
    "published": "2025-02-16T06:34:39+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11011v5",
    "title": "RG-stable parameter relations of a scalar field theory in absence of a symmetry",
    "authors": [
      "Howard E. Haber",
      "P. M. Ferreira"
    ],
    "abstract": "The stability of tree-level relations among the parameters of a quantum field\ntheory with respect to renormalization group (RG) running is typically\nexplained by the existence of a symmetry. We examine a toy model of a quantum\nfield theory of two real scalars in which a tree-level relation among the\nsquared-mass parameters of the scalar potential appears to be RG-stable without\nthe presence of an appropriate underlying symmetry. The stability of this\nrelation with respect to renormalization group running can be explained by\ncomplexifying the original scalar field theory. It is then possible to exhibit\na symmetry that guarantees the relations of relevant beta functions of\nsquared-mass parameters of the complexified theory. Among these relations, we\ncan identify equations that are algebraically identical to the corresponding\nequations that guarantee the stability of the relations among the squared-mass\nparameters of the original real scalar field theory where the symmetry of the\ncomplexified theory is no longer present.",
    "pdf_url": "http://arxiv.org/pdf/2502.11011v5",
    "published": "2025-02-16T06:33:21+00:00",
    "categories": [
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11010v2",
    "title": "Topological magnons and domain walls in twisted bilayer MoTe$_2$",
    "authors": [
      "Wen-Xuan Qiu",
      "Fengcheng Wu"
    ],
    "abstract": "We theoretically investigate the magnetic excitations in the quantum\nanomalous Hall insulator phase of twisted bilayer MoTe$_2$ at a hole filling\nfactor of $\\nu=1$, focusing on magnon and domain wall excitations. Using a\ngeneralized interacting Kane-Mele model, we obtain the quantum anomalous Hall\ninsualtor ground state with spin polarization. The magnon spectrum is then\ncomputed via the Bethe-Salpeter equation, revealing two low-energy topological\nmagnon bands with opposite Chern numbers. To further explore the magnon\ntopology, we construct a tight-binding model for the magnon bands, which is\nanalogous to the Haldane model. We also calculate the energy cost of domain\nwalls that separate regions with opposite Chern numbers and bind chiral edge\nstates. Finally, we propose an effective spin model that describes both magnon\nand domain wall excitations, incorporating Heisenberg spin interactions and\nDzyaloshinskii-Moriya interactions. The coupling constants in this model are\ndetermined from the numerical results for magnons and domain walls. This model\naccounts for the Ising anisotropy of the system, captures the magnon topology,\nand allows for the estimation of the magnetic ordering temperature. Our\nfindings provide a comprehensive analysis of magnetic excitations in twisted\nMoTe$_2$ and offer new insights into collective excitations in moir\\'e systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.11010v2",
    "published": "2025-02-16T06:28:11+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.11009v3",
    "title": "Computing Inconsistency Measures Under Differential Privacy",
    "authors": [
      "Shubhankar Mohapatra",
      "Amir Gilad",
      "Xi He",
      "Benny Kimelfeld"
    ],
    "abstract": "Assessing data quality is crucial to knowing whether and how to use the data\nfor different purposes. Specifically, given a collection of integrity\nconstraints, various ways have been proposed to quantify the inconsistency of a\ndatabase. Inconsistency measures are particularly important when we wish to\nassess the quality of private data without revealing sensitive information. We\nstudy the estimation of inconsistency measures for a database protected under\nDifferential Privacy (DP). Such estimation is nontrivial since some measures\nintrinsically query sensitive information, and the computation of others\ninvolves functions on underlying sensitive data. Among five inconsistency\nmeasures that have been proposed in recent work, we identify that two are\nintractable in the DP setting. The major challenge for the other three is high\nsensitivity: adding or removing one tuple from the dataset may significantly\naffect the outcome. To mitigate that, we model the dataset using a conflict\ngraph and investigate private graph statistics to estimate these measures. The\nproposed machinery includes adapting graph-projection techniques with parameter\nselection optimizations on the conflict graph and a DP variant of approximate\nvertex cover size. We experimentally show that we can effectively compute DP\nestimates of the three measures on five real-world datasets with denial\nconstraints, where the density of the conflict graphs highly varies.",
    "pdf_url": "http://arxiv.org/pdf/2502.11009v3",
    "published": "2025-02-16T06:23:11+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2503.04772v1",
    "title": "Generating Millions Of Lean Theorems With Proofs By Exploring State Transition Graphs",
    "authors": [
      "David Yin",
      "Jing Gao"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated significant potential in\ngenerating mathematical proofs. However, a persistent challenge is that LLMs\noccasionally make mistakes, while even a minor mistake can invalidate an entire\nproof. Proof assistants like Lean offer a great remedy. They are designed for\nverifying each step of a proof in a formal language, and in recent years\nresearchers have created AI models to generate proofs in their languages.\nHowever, the scarcity of large-scale datasets of Lean proofs restrict the\nperformance of such Automated Theorem Proving (ATP) models.\n  We developed LeanNavigator, a novel method for generating a large-scale\ndataset of Lean theorems and proofs by finding new ways to prove existing Lean\ntheorems. By leveraging an interactive Lean client and an efficient method for\nproof step generation, LeanNavigator efficiently produces new theorems with\ncorresponding proofs. Applying this approach to Mathlib4, we generated 4.7\nmillion theorems totaling 1 billion tokens, surpassing previous datasets by\nmore than an order of magnitude. Using this extensive dataset, we trained an AI\nmodel that outperforms the state-of-the-art ReProver model in theorem-proving\ntasks. These results confirm our hypothesis and demonstrate the critical role\nof large datasets in improving the performance of automated theorem provers.",
    "pdf_url": "http://arxiv.org/pdf/2503.04772v1",
    "published": "2025-02-16T06:20:39+00:00",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2502.11008v1",
    "title": "CounterBench: A Benchmark for Counterfactuals Reasoning in Large Language Models",
    "authors": [
      "Yuefei Chen",
      "Vivek K. Singh",
      "Jing Ma",
      "Ruxiang Tang"
    ],
    "abstract": "Counterfactual reasoning is widely recognized as one of the most challenging\nand intricate aspects of causality in artificial intelligence. In this paper,\nwe evaluate the performance of large language models (LLMs) in counterfactual\nreasoning. In contrast to previous studies that primarily focus on commonsense\ncausal reasoning, where LLMs often rely on prior knowledge for inference, we\nspecifically assess their ability to perform counterfactual inference using a\nset of formal rules. To support this evaluation, we introduce a new benchmark\ndataset, CounterBench, comprising 1K counterfactual reasoning questions. The\ndataset is designed with varying levels of difficulty, diverse causal graph\nstructures, distinct types of counterfactual questions, and multiple\nnonsensical name variants. Our experiments demonstrate that counterfactual\nreasoning poses a significant challenge for LLMs, with most models performing\nat levels comparable to random guessing. To enhance LLM's counterfactual\nreasoning ability, we propose a novel reasoning paradigm, CoIn, which guides\nLLMs through iterative reasoning and backtracking to systematically explore\ncounterfactual solutions. Experimental results show that our method\nsignificantly improves LLM performance on counterfactual reasoning tasks and\nconsistently enhances performance across different LLMs.Our dataset is\navailable at https://huggingface.co/datasets/CounterBench/CounterBench.",
    "pdf_url": "http://arxiv.org/pdf/2502.11008v1",
    "published": "2025-02-16T06:19:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11007v3",
    "title": "Local-Cloud Inference Offloading for LLMs in Multi-Modal, Multi-Task, Multi-Dialogue Settings",
    "authors": [
      "Liangqi Yuan",
      "Dong-Jun Han",
      "Shiqiang Wang",
      "Christopher G. Brinton"
    ],
    "abstract": "Compared to traditional machine learning models, recent large language models\n(LLMs) can exhibit multi-task-solving capabilities through multiple dialogues\nand multi-modal data sources. These unique characteristics of LLMs, together\nwith their large model size, make their deployment more challenging.\nSpecifically, (i) deploying LLMs on local devices faces computational, memory,\nand energy resource issues, while (ii) deploying them in the cloud cannot\nguarantee real-time service and incurs communication/usage costs. In this\npaper, we design TMO, a local-cloud LLM inference system with Three-M\nOffloading: Multi-modal, Multi-task, and Multi-dialogue. TMO incorporates (i) a\nlightweight local LLM that can process simple tasks at high speed and (ii) a\nlarge-scale cloud LLM that can handle multi-modal data sources. We develop a\nresource-constrained reinforcement learning (RCRL) strategy for TMO that\noptimizes the inference location (i.e., local vs. cloud) and multi-modal data\nsources to use for each task/dialogue, aiming to maximize the long-term reward\n(response quality, latency, and usage cost) while adhering to resource\nconstraints. We also contribute M4A1, a new dataset we curated that contains\nreward and cost metrics across multiple modality, task, dialogue, and LLM\nconfigurations, enabling evaluation of offloading decisions. We demonstrate the\neffectiveness of TMO compared to several exploration-decision and LLM-as-Agent\nbaselines, showing significant improvements in latency, cost, and response\nquality.",
    "pdf_url": "http://arxiv.org/pdf/2502.11007v3",
    "published": "2025-02-16T06:18:28+00:00",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.11006v1",
    "title": "Prompt Inject Detection with Generative Explanation as an Investigative Tool",
    "authors": [
      "Jonathan Pan",
      "Swee Liang Wong",
      "Yidi Yuan",
      "Xin Wei Chia"
    ],
    "abstract": "Large Language Models (LLMs) are vulnerable to adversarial prompt based\ninjects. These injects could jailbreak or exploit vulnerabilities within these\nmodels with explicit prompt requests leading to undesired responses. In the\ncontext of investigating prompt injects, the challenge is the sheer volume of\ninput prompts involved that are likely to be largely benign. This investigative\nchallenge is further complicated by the semantics and subjectivity of the input\nprompts involved in the LLM conversation with its user and the context of the\nenvironment to which the conversation is being carried out. Hence, the\nchallenge for AI security investigators would be two-fold. The first is to\nidentify adversarial prompt injects and then to assess whether the input prompt\nis contextually benign or adversarial. For the first step, this could be done\nusing existing AI security solutions like guardrails to detect and protect the\nLLMs. Guardrails have been developed using a variety of approaches. A popular\napproach is to use signature based. Another popular approach to develop AI\nmodels to classify such prompts include the use of NLP based models like a\nlanguage model. However, in the context of conducting an AI security\ninvestigation of prompt injects, these guardrails lack the ability to aid\ninvestigators in triaging or assessing the identified input prompts. In this\napplied research exploration, we explore the use of a text generation\ncapabilities of LLM to detect prompt injects and generate explanation for its\ndetections to aid AI security investigators in assessing and triaging of such\nprompt inject detections. The practical benefit of such a tool is to ease the\ntask of conducting investigation into prompt injects.",
    "pdf_url": "http://arxiv.org/pdf/2502.11006v1",
    "published": "2025-02-16T06:16:00+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.11005v1",
    "title": "Anisotropic Schottky-barrier-height in high-symmetry 2D WSe$_2$: Momentum-space anisotropy",
    "authors": [
      "Nuo Xu",
      "Xiao-Lin Zhao",
      "Meng-Xue Ren",
      "Ke-Xin Hou",
      "Xiao-huan Lv",
      "Rui-Ning Wang",
      "Xing-Qiang Shi",
      "Jiang-Long Wang"
    ],
    "abstract": "It is usually supposed that only low-symmetry two-dimensional (2D) materials\nexhibit anisotropy, here we show that high-symmetry 2D semiconductors can show\nsignificant anisotropy in momentum space due to the band structure anisotropy\nin k-space. The basic reason is that different k-points in the Brillouin zone\nhave different symmetry. Using 2D semiconductor WSe$_2$ as the example, we\nconstruct lateral heterostructures with zigzag and armchair connections to 2D\nmetal NbSe$_2$, and the electronic structure and contact characteristics of\nthese two connections are analyzed. It is found that both connections exhibit\np-type Schottky barrier height (SBH) but the sizes of SBH are very different\n(of 0.03 eV and 0.50 eV), mainly because the band-edge energies of WSe$_2$ are\ndifferent along the two mutually perpendicular directions in momentum space.\nThere are two factors contributing to the SBH anisotropy: one is the different\ninterface structure and the other is the band edge anisotropy of the 2D\nsemiconductor WSe$_2$. Since the two interface structures give only a\ndifference in interface potential change by less than 0.1 eV, the SBH variation\nof ~0.47 eV is mainly from the band structure anisotropy in momentum-space. So,\nhigh-symmetry 2D materials may exhibit highly anisotropic electronic states in\nmomentum space and this affects the transport properties. Our current work\nextends the research field of 2D material anisotropy to 2D materials with high\nreal-space symmetry, thus greatly expands the candidate materials for\nanisotropic studies and provides new guidance for optimizing the performance of\n2D material devices via controlling transport directions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11005v1",
    "published": "2025-02-16T06:11:48+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.11004v1",
    "title": "Hyperdeterminism? Spacetime 'Analyzed'",
    "authors": [
      "Lu Chen",
      "Tobias Fritz"
    ],
    "abstract": "When modelling spacetime and classical physical fields, one typically assumes\nsmoothness (infinite differentiability). But this assumption and its\nphilosophical implications have not been sufficiently scrutinized. For example,\nwe can appeal to analytic functions instead, which are also often used by\nphysicists. Doing so leads to very different philosophical interpretations of a\ntheory. For instance, our world would be 'hyperdeterministic' with analytic\nfunctions, in the sense that every field configuration is uniquely determined\nby its restriction to an arbitrarily small region. Relatedly, the hole argument\nof general relativity does not get off the ground. We argue that such an appeal\nto analytic functions is technically feasible and, conceptually, not obviously\nobjectionable. The moral is to warn against rushing to draw philosophical\nconclusions from physical theories, given their drastic sensitivity to\nmathematical formalisms.",
    "pdf_url": "http://arxiv.org/pdf/2502.11004v1",
    "published": "2025-02-16T06:08:17+00:00",
    "categories": [
      "physics.hist-ph",
      "gr-qc",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "physics.hist-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.11003v1",
    "title": "FeaKM: Robust Collaborative Perception under Noisy Pose Conditions",
    "authors": [
      "Jiuwu Hao",
      "Liguo Sun",
      "Ti Xiang",
      "Yuting Wan",
      "Haolin Song",
      "Pin Lv"
    ],
    "abstract": "Collaborative perception is essential for networks of agents with limited\nsensing capabilities, enabling them to work together by exchanging information\nto achieve a robust and comprehensive understanding of their environment.\nHowever, localization inaccuracies often lead to significant spatial message\ndisplacement, which undermines the effectiveness of these collaborative\nefforts. To tackle this challenge, we introduce FeaKM, a novel method that\nemploys Feature-level Keypoints Matching to effectively correct pose\ndiscrepancies among collaborating agents. Our approach begins by utilizing a\nconfidence map to identify and extract salient points from intermediate feature\nrepresentations, allowing for the computation of their descriptors. This step\nensures that the system can focus on the most relevant information, enhancing\nthe matching process. We then implement a target-matching strategy that\ngenerates an assignment matrix, correlating the keypoints identified by\ndifferent agents. This is critical for establishing accurate correspondences,\nwhich are essential for effective collaboration. Finally, we employ a\nfine-grained transformation matrix to synchronize the features of all agents\nand ascertain their relative statuses, ensuring coherent communication among\nthem. Our experimental results demonstrate that FeaKM significantly outperforms\nexisting methods on the DAIR-V2X dataset, confirming its robustness even under\nsevere noise conditions. The code and implementation details are available at\nhttps://github.com/uestchjw/FeaKM.",
    "pdf_url": "http://arxiv.org/pdf/2502.11003v1",
    "published": "2025-02-16T06:03:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.11002v1",
    "title": "Adjust Your Focus: Defocus Deblurring From Dual-Pixel Images Using Explicit Multi-Scale Cross-Correlation",
    "authors": [
      "Kunal Swami"
    ],
    "abstract": "Defocus blur is a common problem in photography. It arises when an image is\ncaptured with a wide aperture, resulting in a shallow depth of field. Sometimes\nit is desired, e.g., in portrait effect. Otherwise, it is a problem from both\nan aesthetic point of view and downstream computer vision tasks, such as\nsegmentation and depth estimation. Defocusing an out-of-focus image to obtain\nan all-in-focus image is a highly challenging and often ill-posed problem. A\nrecent work exploited dual-pixel (DP) image information, widely available in\nconsumer DSLRs and high-end smartphones, to solve the problem of defocus\ndeblurring. DP sensors result in two sub-aperture views containing defocus\ndisparity cues. A given pixel's disparity is directly proportional to the\ndistance from the focal plane. However, the existing methods adopt a na\\\"ive\napproach of a channel-wise concatenation of the two DP views without explicitly\nutilizing the disparity cues within the network. In this work, we propose to\nperform an explicit cross-correlation between the two DP views to guide the\nnetwork for appropriate deblurring in different image regions. We adopt\nmulti-scale cross-correlation to handle blur and disparities at different\nscales. Quantitative and qualitative evaluation of our multi-scale\ncross-correlation network (MCCNet) reveals that it achieves better defocus\ndeblurring than existing state-of-the-art methods despite having lesser\ncomputational complexity.",
    "pdf_url": "http://arxiv.org/pdf/2502.11002v1",
    "published": "2025-02-16T05:55:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.12200v1",
    "title": "Efficient and Effective Prompt Tuning via Prompt Decomposition and Compressed Outer Product",
    "authors": [
      "Pengxiang Lan",
      "Haoyu Xu",
      "Enneng Yang",
      "Yuliang Liang",
      "Guibing Guo",
      "Jianzhe Zhao",
      "Xingwei Wang"
    ],
    "abstract": "Prompt tuning (PT) offers a cost-effective alternative to fine-tuning\nlarge-scale pre-trained language models (PLMs), requiring only a few parameters\nin soft prompt tokens added before the input text. However, existing PT\napproaches face two significant issues: (i) They overlook intrinsic semantic\nassociations between soft prompt tokens, leading to high discreteness and\nlimited interactions, thus reducing the model's comprehension and effectiveness\nin complex tasks. (ii) Due to the complexity of downstream tasks, long soft\nprompt is necessitated to improve performance, but prompt length correlates\npositively with memory usage and computational costs. Achieving high efficiency\nand performance remains an ongoing challenge. To address these issues, we\npropose a novel Low-parameters prompt tuning (LAMP) method, which leverages\nprompt decomposition and compressed outer product. Specifically, the prompt\ndecomposition module employs Truncated SVD to reduce training parameters and\nsignificantly lower the dimensionality of the soft prompt parameter space. It\nthen utilizes a compressed outer product module to facilitate multiple\ninteractions among prompt tokens, exploring their intrinsic associations to\nenhance knowledge representation. Finally, LAMP uses average pooling to reduce\nmemory usage and training/inference time. Extensive experiments across six\narchitectures and eight datasets demonstrate that LAMP outperforms\nstate-of-the-art PT-based and LoRA-based methods in performance and efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2502.12200v1",
    "published": "2025-02-16T05:50:12+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.11001v1",
    "title": "CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening",
    "authors": [
      "Gen Zhou",
      "Sugitha Janarthanan",
      "Yutong Lu",
      "Pingzhao Hu"
    ],
    "abstract": "Due to the rise in antimicrobial resistance, identifying novel compounds with\nantibiotic potential is crucial for combatting this global health issue.\nHowever, traditional drug development methods are costly and inefficient.\nRecognizing the pressing need for more effective solutions, researchers have\nturned to machine learning techniques to streamline the prediction and\ndevelopment of novel antibiotic compounds. While foundation models have shown\npromise in antibiotic discovery, current mainstream efforts still fall short of\nfully leveraging the potential of multimodal molecular data. Recent studies\nsuggest that contrastive learning frameworks utilizing multimodal data exhibit\nexcellent performance in representation learning across various domains.\nBuilding upon this, we introduce CL-MFAP, an unsupervised contrastive learning\n(CL)-based multimodal foundation (MF) model specifically tailored for\ndiscovering small molecules with potential antibiotic properties (AP) using\nthree types of molecular data. This model employs 1.6 million bioactive\nmolecules with drug-like properties from the ChEMBL dataset to jointly pretrain\nthree encoders: (1) a transformer-based encoder with rotary position embedding\nfor processing SMILES strings; (2) another transformer-based encoder,\nincorporating a novel bi-level routing attention mechanism to handle molecular\ngraph representations; and (3) a Morgan fingerprint encoder using a multilayer\nperceptron, to achieve the contrastive learning purpose. The CL-MFAP\noutperforms baseline models in antibiotic property prediction by effectively\nutilizing different molecular modalities and demonstrates superior\ndomain-specific performance when fine-tuned for antibiotic-related property\nprediction tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.11001v1",
    "published": "2025-02-16T05:45:19+00:00",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2502.11000v1",
    "title": "Dimension Effect of Nanocarbon Precursors on Diamond Synthesis and Transformation Mechanism under Extreme Conditions",
    "authors": [
      "Jiaxin Ming",
      "Jingyi Tian",
      "Liming Zhao",
      "Jiayin Li",
      "Guoshuai Du",
      "Lixing Kang",
      "Zheng Hu",
      "Yabin Chen"
    ],
    "abstract": "Diamond holds significant promise for a wide range of applications due to its\nexceptional physicochemical properties. Investigating the controlled diamond\npreparation from nanocarbon precursors with varying dimensions is crucial to\noptimize the transition conditions and even elucidate the daunting\ntransformation mechanism, however, this remains outstanding challenge despite\nconsiderable effort. Herein, we report the imperative dimension effect of\nnanocarbon precursors on diamond synthesis and physical mechanism under high\ntemperature and high pressure, by comparing the distinct transition processes\nof zero-dimensional (0D) carbon nanocages (CNCs) and one-dimensional (1D)\ncarbon nanotubes (CNTs) from conventional graphite. The optical and structural\ncharacterizations evidently demonstrated that both 0D CNCs and 1D CNTs first\nundergo collapse and graphitization, followed by the formation of mixed\namorphous carbon with embedded diamond clusters, eventually leading to cubic\ndiamond. The plotted pressure-temperature diagram exhibits the unique dimension\neffect of carbon nanomaterials to diamond transformation. These results provide\nvaluable insights into the phase transition mechanisms of diamond synthesis and\nits derivatives under extreme conditions.",
    "pdf_url": "http://arxiv.org/pdf/2502.11000v1",
    "published": "2025-02-16T05:34:53+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.10999v1",
    "title": "ControlText: Unlocking Controllable Fonts in Multilingual Text Rendering without Font Annotations",
    "authors": [
      "Bowen Jiang",
      "Yuan Yuan",
      "Xinyi Bai",
      "Zhuoqun Hao",
      "Alyson Yin",
      "Yaojie Hu",
      "Wenyu Liao",
      "Lyle Ungar",
      "Camillo J. Taylor"
    ],
    "abstract": "This work demonstrates that diffusion models can achieve font-controllable\nmultilingual text rendering using just raw images without font label\nannotations. Visual text rendering remains a significant challenge. While\nrecent methods condition diffusion on glyphs, it is impossible to retrieve\nexact font annotations from large-scale, real-world datasets, which prevents\nuser-specified font control. To address this, we propose a data-driven solution\nthat integrates the conditional diffusion model with a text segmentation model,\nutilizing segmentation masks to capture and represent fonts in pixel space in a\nself-supervised manner, thereby eliminating the need for any ground-truth\nlabels and enabling users to customize text rendering with any multilingual\nfont of their choice. The experiment provides a proof of concept of our\nalgorithm in zero-shot text and font editing across diverse fonts and\nlanguages, providing valuable insights for the community and industry toward\nachieving generalized visual text rendering.",
    "pdf_url": "http://arxiv.org/pdf/2502.10999v1",
    "published": "2025-02-16T05:30:18+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.10998v1",
    "title": "Self-injection locking dynamics with Raman actions in AlN microresonators",
    "authors": [
      "Yulei Ding",
      "Yifei Wang",
      "Shunyu Yao",
      "Yanan Guo",
      "Jianchang Yan",
      "Junxi Wang",
      "Changxi Yang",
      "Chengying Bao"
    ],
    "abstract": "Self-injection locking (SIL) of semiconductor lasers to on-chip microcavities\nenables significant laser noise purification and diverse nonlinear optical\nactions. Realizing nonlinear SIL in new material platforms is essential for\nadvancing photonic integrated circuits. Here, we demonstrate nonlinear SIL in\nAlN microcavities that generates stimulated Raman lasers (SRLs) and microcombs.\nWe achieve SRL emission with an output power exceeding 10 mW and a fundamental\nlinewidth below 70 Hz in the 1750 nm band. The Kerr effect further mediates\nstimulated emissions at the 2nd-Stokes and anti-Stokes frequencies.\nMulti-time-scale thermal relaxations during turnkey SIL enable GHz-level\nfrequency sweeps of the SRL and pump. Raman actions also render a Stokes\nplaticon microcomb state with co-emission in the pump and Stokes bands.\nHybrid-integrated crystalline microresonators can be a versatile platform to\ninvestigate nonlinear photon-phonon interactions.",
    "pdf_url": "http://arxiv.org/pdf/2502.10998v1",
    "published": "2025-02-16T05:24:29+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.10997v2",
    "title": "Improved Regret in Stochastic Decision-Theoretic Online Learning under Differential Privacy",
    "authors": [
      "Ruihan Wu",
      "Yu-Xiang Wang"
    ],
    "abstract": "Hu and Mehta (2024) posed an open problem: what is the optimal\ninstance-dependent rate for the stochastic decision-theoretic online learning\n(with $K$ actions and $T$ rounds) under $\\varepsilon$-differential privacy?\nBefore, the best known upper bound and lower bound are $O\\left(\\frac{\\log\nK}{\\Delta_{\\min}} + \\frac{\\log K\\log T}{\\varepsilon}\\right)$ and\n$\\Omega\\left(\\frac{\\log K}{\\Delta_{\\min}} + \\frac{\\log K}{\\varepsilon}\\right)$\n(where $\\Delta_{\\min}$ is the gap between the optimal and the second actions).\nIn this paper, we partially address this open problem by having two new\nresults. First, we provide an improved upper bound for this problem\n$O\\left(\\frac{\\log K}{\\Delta_{\\min}} + \\frac{\\log^2K}{\\varepsilon}\\right)$,\nwhich is $T$-independent and only has a log dependency in $K$. Second, to\nfurther understand the gap, we introduce the \\textit{deterministic setting}, a\nweaker setting of this open problem, where the received loss vector is\ndeterministic. At this weaker setting, a direct application of the analysis and\nalgorithms from the original setting still leads to an extra log factor. We\nconduct a novel analysis which proves upper and lower bounds that match at\n$\\Theta(\\frac{\\log K}{\\varepsilon})$.",
    "pdf_url": "http://arxiv.org/pdf/2502.10997v2",
    "published": "2025-02-16T05:13:51+00:00",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.DS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.10996v2",
    "title": "RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation",
    "authors": [
      "Pengcheng Jiang",
      "Lang Cao",
      "Ruike Zhu",
      "Minhao Jiang",
      "Yunyi Zhang",
      "Jimeng Sun",
      "Jiawei Han"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive performance on\nknowledge-intensive tasks, yet they often struggle with multi-step reasoning\ndue to the unstructured nature of retrieved context. While retrieval-augmented\ngeneration (RAG) methods provide external information, the lack of explicit\norganization among retrieved passages limits their effectiveness, leading to\nbrittle reasoning pathways. Recent interpretability studies highlighting the\nimportance of structured intermediate reasoning further align with this\nperspective. We propose Retrieval-And-Structuring (RAS), a framework that\ndynamically constructs query-specific knowledge graphs through iterative\nretrieval and structured knowledge building. RAS interleaves targeted retrieval\nplanning with incremental graph construction, enabling models to assemble and\nreason over evolving knowledge structures tailored to each query. On seven\nknowledge-intensive benchmarks, RAS consistently outperforms strong baselines,\nachieving up to 6.4% and 7.0% gains with open-source and proprietary LLMs,\nrespectively. Our results demonstrate that dynamic, query-specific knowledge\nstructuring offers a robust path to improving reasoning accuracy and robustness\nin language model generation. Our data and code can be found at\nhttps://github.com/pat-jj/RAS.",
    "pdf_url": "http://arxiv.org/pdf/2502.10996v2",
    "published": "2025-02-16T05:01:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.10995v1",
    "title": "Evaluating Large language models on Understanding Korean indirect Speech acts",
    "authors": [
      "Youngeun Koo",
      "Jiwoo Lee",
      "Dojun Park",
      "Seohyun Park",
      "Sungeun Lee"
    ],
    "abstract": "To accurately understand the intention of an utterance is crucial in\nconversational communication. As conversational artificial intelligence models\nare rapidly being developed and applied in various fields, it is important to\nevaluate the LLMs' capabilities of understanding the intentions of user's\nutterance. This study evaluates whether current LLMs can understand the\nintention of an utterance by considering the given conversational context,\nparticularly in cases where the actual intention differs from the\nsurface-leveled, literal intention of the sentence, i.e. indirect speech acts.\nOur findings reveal that Claude3-Opus outperformed the other competing models,\nwith 71.94% in MCQ and 65% in OEQ, showing a clear advantage. In general,\nproprietary models exhibited relatively higher performance compared to\nopen-source models. Nevertheless, no LLMs reached the level of human\nperformance. Most LLMs, except for Claude3-Opus, demonstrated significantly\nlower performance in understanding indirect speech acts compared to direct\nspeech acts, where the intention is explicitly revealed through the utterance.\nThis study not only performs an overall pragmatic evaluation of each LLM's\nlanguage use through the analysis of OEQ response patterns, but also emphasizes\nthe necessity for further research to improve LLMs' understanding of indirect\nspeech acts for more natural communication with humans.",
    "pdf_url": "http://arxiv.org/pdf/2502.10995v1",
    "published": "2025-02-16T04:59:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.10994v1",
    "title": "SSVEP-BiMA: Bifocal Masking Attention Leveraging Native and Symmetric-Antisymmetric Components for Robust SSVEP Decoding",
    "authors": [
      "Yuxin Liu",
      "Zhenxi Song",
      "Guoyang Xu",
      "Zirui Wang",
      "Feng Wan",
      "Yong Hu",
      "Min Zhang",
      "Zhiguo Zhang"
    ],
    "abstract": "Brain-computer interface (BCI) based on steady-state visual evoked potentials\n(SSVEP) is a popular paradigm for its simplicity and high information transfer\nrate (ITR). Accurate and fast SSVEP decoding is crucial for reliable BCI\nperformance. However, conventional decoding methods demand longer time windows,\nand deep learning models typically require subject-specific fine-tuning,\nleaving challenges in achieving optimal performance in cross-subject settings.\nThis paper proposed a biofocal masking attention-based method (SSVEP-BiMA) that\nsynergistically leverages the native and symmetric-antisymmetric components for\ndecoding SSVEP. By utilizing multiple signal representations, the network is\nable to integrate features from a wider range of sample perspectives, leading\nto more generalized and comprehensive feature learning, which enhances both\nprediction accuracy and robustness. We performed experiments on two public\ndatasets, and the results demonstrate that our proposed method surpasses\nbaseline approaches in both accuracy and ITR. We believe that this work will\ncontribute to the development of more efficient SSVEP-based BCI systems.",
    "pdf_url": "http://arxiv.org/pdf/2502.10994v1",
    "published": "2025-02-16T04:58:59+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.10993v1",
    "title": "RoseRAG: Robust Retrieval-augmented Generation with Small-scale LLMs via Margin-aware Preference Optimization",
    "authors": [
      "Tianci Liu",
      "Haoxiang Jiang",
      "Tianze Wang",
      "Ran Xu",
      "Yue Yu",
      "Linjun Zhang",
      "Tuo Zhao",
      "Haoyu Wang"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive performance but face\nhigh computational costs and latency, limiting their deployment in\nresource-constrained settings. In contrast, small-scale LLMs (SLMs) are more\nefficient yet struggle to capture evolving real-world knowledge.\nRetrieval-augmented generation (RAG) helps by integrating external knowledge,\nbut imperfect retrieval can introduce distracting noise that misleads SLMs. We\npropose RoseRAG, a robust RAG framework for SLMs via Margin-aware Preference\nOptimization. RoseRAG employs multi-turn prompting for detailed reasoning,\nrejection sampling for high-quality explanations, and contrastive preference\nselection to refine responses by maximizing the likelihood gap between\npreferred and non-preferred outputs. By integrating these components into a\nmargin-aware optimization process, RoseRAG robustly enhances the accuracy and\nreliability of SLMs for RAG applications. Extensive experiments on three\nopen-domain question answering benchmarks indicate that our innovative RoseRAG\nsurpasses state-of-the-art baselines significantly.",
    "pdf_url": "http://arxiv.org/pdf/2502.10993v1",
    "published": "2025-02-16T04:56:53+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.10992v1",
    "title": "Systematic study of the composition of Type I X-ray burst ashes: Neutron star structure v.s. Reaction rate uncertainties",
    "authors": [
      "Guoqing Zhen",
      "Helei Liu",
      "Akira Dohi",
      "Guoliang L",
      "Nobuya Nishimura",
      "Chunhua Zhu",
      "Renxin Xu"
    ],
    "abstract": "In this study, we calculate for the first time the impacts of neutron\nstar(NS) structure on the type I X-ray burst ashes using the \\texttt{MESA}\ncode. We find an increased mass fraction of the heavier elements with\nincreasing surface gravity (increase mass or decrease radius), resulting in a\nhigher average mass number ($A_{\\rm ash}$) of burst ashes (except for higher\nmass NS due to the competition between the envelope temperature and the\nrecurrence time). The burst strength ($\\alpha$) increases as surface gravity\nincreases, which indicates the positive correlation between $A_{\\rm ash}$ and\n$\\alpha$ with changes in surface gravity. If the $\\alpha$ value is higher,\nheavier $p$-nuclei should be produced by the type I X-ray burst\nnucleosynthesis. Besides, the effects of various burst input parameters, e.g.\nbase heating ($Q_{\\rm b}$), metallicity ($Z$) and some new reaction rates are\ncalculated for comparison. We find that the heavier nuclei synthesis is\ninversely correlated to the base heating/metallicity, the smaller the base\nheating/metallicity, the greater the mass fraction of the heavier elements. The\n$\\alpha$ value decreases as $Q_{\\rm b}$ or $Z$ decreases, which also indicates\nthe positive correlation between $A_{\\rm ash}$ and $\\alpha$ with variation in\n$Q_{\\rm b}$ or $Z$. The new reaction rates from the $(p,\\gamma)$ reactions on\n$^{17}\\rm{F}$, $^{19}\\rm{F}$, $^{26}\\rm{P}$, $^{56}\\rm{Cu}$, $^{65}\\rm{As}$,\nand $(\\alpha,p)$ reaction on $^{22}\\rm{Mg}$ have only minimal effects on burst\nashes. In hydrogen-rich X-ray binary systems, nuclei heavier than\n$^{64}\\rm{Ge}$ are fertile produced with larger NS mass, smaller NS radius,\nsmaller base heating and smaller metallicity.",
    "pdf_url": "http://arxiv.org/pdf/2502.10992v1",
    "published": "2025-02-16T04:42:43+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.10991v2",
    "title": "Itinerant topological magnons and spin excitons in twisted transition metal dichalcogenides: Mapping electron topology to spin counterpart",
    "authors": [
      "Wei-Tao Zhou",
      "Zhao-Yang Dong",
      "Zhao-Long Gu",
      "Jian-Xin Li"
    ],
    "abstract": "Twisted transition metal dichalcogenides (tTMDs) provide a highly tunable\nplatform to explore the interplay between strong correlation and topology.\nAmong them, the properties involving the charge degree of freedom have been\nextensively studied, while those related to spin are much less investigated.\nMotivated by the recent discovery of integer and fractional quantum anomalous\nHall effects in tMoTe$_2$, where the flat-band ferromagnetism is one of the\nessential prerequisites, we investigate theoretically the spin excitations out\nof the flat-band ferromagnetic ground state in tMoTe$_2$. Remarkably, we\nidentify the itinerant magnons and spin excitons with nontrivial topology. We\nelaborate that the topology of these itinerant spin excitations, which are\ndescribed as particle-hole bound states, inherits directly from that of the\nunderlying electrons and is essentially different from that in local spin\nsystems. Thus, we establish a direct relationship of the topology between the\nmany-body excitations and their fundamental constituents. We further\ndemonstrate that by tuning the displacement field, a topological transition for\nboth the magnon and spin exciton happens, leading to a step-like change and\nbifurcation in the thermal Hall conductance, which could serve as unique and\ncompelling evidence to be tested experimentally.",
    "pdf_url": "http://arxiv.org/pdf/2502.10991v2",
    "published": "2025-02-16T04:39:46+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2502.10990v3",
    "title": "FinMTEB: Finance Massive Text Embedding Benchmark",
    "authors": [
      "Yixuan Tang",
      "Yi Yang"
    ],
    "abstract": "Embedding models play a crucial role in representing and retrieving\ninformation across various NLP applications. Recent advances in large language\nmodels (LLMs) have further enhanced the performance of embedding models. While\nthese models are often benchmarked on general-purpose datasets, real-world\napplications demand domain-specific evaluation. In this work, we introduce the\nFinance Massive Text Embedding Benchmark (FinMTEB), a specialized counterpart\nto MTEB designed for the financial domain. FinMTEB comprises 64 financial\ndomain-specific embedding datasets across 7 tasks that cover diverse textual\ntypes in both Chinese and English, such as financial news articles, corporate\nannual reports, ESG reports, regulatory filings, and earnings call transcripts.\nWe also develop a finance-adapted model, Fin-E5, using a persona-based data\nsynthetic method to cover diverse financial embedding tasks for training.\nThrough extensive evaluation of 15 embedding models, including Fin-E5, we show\nthree key findings: (1) performance on general-purpose benchmarks shows limited\ncorrelation with financial domain tasks; (2) domain-adapted models consistently\noutperform their general-purpose counterparts; and (3) surprisingly, a simple\nBag-of-Words (BoW) approach outperforms sophisticated dense embeddings in\nfinancial Semantic Textual Similarity (STS) tasks, underscoring current\nlimitations in dense embedding techniques. Our work establishes a robust\nevaluation framework for financial NLP applications and provides crucial\ninsights for developing domain-specific embedding models.",
    "pdf_url": "http://arxiv.org/pdf/2502.10990v3",
    "published": "2025-02-16T04:23:52+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.10989v1",
    "title": "Linearization of multivariate discrete difference operators",
    "authors": [
      "Yunting Iris Gao"
    ],
    "abstract": "In 2023 in (3), Uwe finds the explicit form of the map which is which is\nsettled in ZN of finite functional degree and14 discusses how to compute its\nusual degree w.r.t to the derivative in the linear form, i.e. the product of\nones formed by15 its orthogonal basis, and also introduces the notion of\nfunctional degree. It is the linear combination of the product of16 binomials.\nAnd this makes a big progress in the development of integer-valued functions.\nAnd this inspires the author17 to discuss this form in the separate form, i.e.\nthe triple of finite set. In (18), Hrycaj discusses these operators in more18\nabstract form. In this paper, we unifies two approaches. Seriously, we prove\nthat the functional degree of integer-valued19 maps on integers which is\ncomputed with respect to its difference operators associated with its standard\nbasis is exactly20 the same with the ones computed with respect to arbitrary\nmix discrete difference operators and we call it as multivariate21 difference\noperators. Since the functional degree agrees with the usual degree of\ninteger-valued maps, we actually achieved22 the linearization of multivariate\ndifference operators",
    "pdf_url": "http://arxiv.org/pdf/2502.10989v1",
    "published": "2025-02-16T04:20:02+00:00",
    "categories": [
      "math.GM",
      "05E18"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2502.10988v2",
    "title": "OMG: Opacity Matters in Material Modeling with Gaussian Splatting",
    "authors": [
      "Silong Yong",
      "Venkata Nagarjun Pudureddiyur Manivannan",
      "Bernhard Kerbl",
      "Zifu Wan",
      "Simon Stepputtis",
      "Katia Sycara",
      "Yaqi Xie"
    ],
    "abstract": "Decomposing geometry, materials and lighting from a set of images, namely\ninverse rendering, has been a long-standing problem in computer vision and\ngraphics. Recent advances in neural rendering enable photo-realistic and\nplausible inverse rendering results. The emergence of 3D Gaussian Splatting has\nboosted it to the next level by showing real-time rendering potentials. An\nintuitive finding is that the models used for inverse rendering do not take\ninto account the dependency of opacity w.r.t. material properties, namely cross\nsection, as suggested by optics. Therefore, we develop a novel approach that\nadds this dependency to the modeling itself. Inspired by radiative transfer, we\naugment the opacity term by introducing a neural network that takes as input\nmaterial properties to provide modeling of cross section and a physically\ncorrect activation function. The gradients for material properties are\ntherefore not only from color but also from opacity, facilitating a constraint\nfor their optimization. Therefore, the proposed method incorporates more\naccurate physical properties compared to previous works. We implement our\nmethod into 3 different baselines that use Gaussian Splatting for inverse\nrendering and achieve significant improvements universally in terms of novel\nview synthesis and material modeling.",
    "pdf_url": "http://arxiv.org/pdf/2502.10988v2",
    "published": "2025-02-16T04:18:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.10987v4",
    "title": "Hypercubic Decomposition of Verma Supermodules and Semibricks Realizing the Khovanov Algebra of Defect One",
    "authors": [
      "Shunsuke Hirota"
    ],
    "abstract": "We study some variants of Verma modules of basic Lie superalgebras obtained\nvia changing Borel subalgebras. These allow us to demonstrate that the\nprincipal block of \\(\\mathfrak{gl}(1|1)\\) is realized as (non-Serre) full\nsubcategories of any atypical block of BGG category \\( \\mathcal{O} \\) of basic\nLie superalgebras.",
    "pdf_url": "http://arxiv.org/pdf/2502.10987v4",
    "published": "2025-02-16T04:15:25+00:00",
    "categories": [
      "math.RT",
      "math.RA",
      "17B55, 18E10"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2502.10986v1",
    "title": "A relaxed proximal point algorithm with double-inertial effects for nonconvex equilibrium problems",
    "authors": [
      "Nam Van Tran"
    ],
    "abstract": "In this paper, we present a relaxation proximal point method with double\ninertial effects to approximate a solution of a non-convex equilibrium problem.\nWe give global\n  convergence results of the iterative sequence generated by our algorithm.\nSome known results are recovered\n  as special cases of our results. Numerical test is given to support the\ntheoretical findings.",
    "pdf_url": "http://arxiv.org/pdf/2502.10986v1",
    "published": "2025-02-16T04:11:01+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2502.10985v1",
    "title": "Is Elo Rating Reliable? A Study Under Model Misspecification",
    "authors": [
      "Shange Tang",
      "Yuanhao Wang",
      "Chi Jin"
    ],
    "abstract": "Elo rating, widely used for skill assessment across diverse domains ranging\nfrom competitive games to large language models, is often understood as an\nincremental update algorithm for estimating a stationary Bradley-Terry (BT)\nmodel. However, our empirical analysis of practical matching datasets reveals\ntwo surprising findings: (1) Most games deviate significantly from the\nassumptions of the BT model and stationarity, raising questions on the\nreliability of Elo. (2) Despite these deviations, Elo frequently outperforms\nmore complex rating systems, such as mElo and pairwise models, which are\nspecifically designed to account for non-BT components in the data,\nparticularly in terms of win rate prediction. This paper explains this\nunexpected phenomenon through three key perspectives: (a) We reinterpret Elo as\nan instance of online gradient descent, which provides no-regret guarantees\neven in misspecified and non-stationary settings. (b) Through extensive\nsynthetic experiments on data generated from transitive but non-BT models, such\nas strongly or weakly stochastic transitive models, we show that the\n''sparsity'' of practical matching data is a critical factor behind Elo's\nsuperior performance in prediction compared to more complex rating systems. (c)\nWe observe a strong correlation between Elo's predictive accuracy and its\nranking performance, further supporting its effectiveness in ranking.",
    "pdf_url": "http://arxiv.org/pdf/2502.10985v1",
    "published": "2025-02-16T04:07:33+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.10984v2",
    "title": "Sound Conveyors for Stealthy Data Transmission",
    "authors": [
      "Sachith Dassanayaka"
    ],
    "abstract": "Hiding messages for countless security purposes has become a highly\nfascinating subject nowadays. Encryption facilitates the data hiding. With the\nexpress development of technology, people tend to figure out a method capable\nof hiding a message and the survival of the message. The present-day study is\nconducted to hide information in an audio file. Generally, steganography\nadvantages are not used among industry and learners even though it is an\nextensively discussed area in the present information world. This\nimplementation aims to hide a document such as txt, doc, and pdf file formats\nin an audio file and retrieve the hidden document when necessary. This system\nis called DeepAudio v1.0. The system supports AES encryption and tolerates both\nwave and MP3 files. The sub-aims of this work were the creation of a free,\nopenly available, bug-free software tool with additional features that are new\nto the area.",
    "pdf_url": "http://arxiv.org/pdf/2502.10984v2",
    "published": "2025-02-16T04:02:56+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2502.10983v2",
    "title": "Learning Quiet Walking for a Small Home Robot",
    "authors": [
      "Ryo Watanabe",
      "Takahiro Miki",
      "Fan Shi",
      "Yuki Kadokawa",
      "Filip Bjelonic",
      "Kento Kawaharazuka",
      "Andrei Cramariuc",
      "Marco Hutter"
    ],
    "abstract": "As home robotics gains traction, robots are increasingly integrated into\nhouseholds, offering companionship and assistance. Quadruped robots,\nparticularly those resembling dogs, have emerged as popular alternatives for\ntraditional pets. However, user feedback highlights concerns about the noise\nthese robots generate during walking at home, particularly the loud footstep\nsound. To address this issue, we propose a sim-to-real based reinforcement\nlearning (RL) approach to minimize the foot contact velocity highly related to\nthe footstep sound. Our framework incorporates three key elements: learning\nvarying PD gains to actively dampen and stiffen each joint, utilizing foot\ncontact sensors, and employing curriculum learning to gradually enforce\npenalties on foot contact velocity. Experiments demonstrate that our learned\npolicy achieves superior quietness compared to a RL baseline and the carefully\nhandcrafted Sony commercial controllers. Furthermore, the trade-off between\nrobustness and quietness is shown. This research contributes to developing\nquieter and more user-friendly robotic companions in home environments.",
    "pdf_url": "http://arxiv.org/pdf/2502.10983v2",
    "published": "2025-02-16T04:00:36+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.10982v3",
    "title": "TEASER: Token Enhanced Spatial Modeling for Expressions Reconstruction",
    "authors": [
      "Yunfei Liu",
      "Lei Zhu",
      "Lijian Lin",
      "Ye Zhu",
      "Ailing Zhang",
      "Yu Li"
    ],
    "abstract": "3D facial reconstruction from a single in-the-wild image is a crucial task in\nhuman-centered computer vision tasks. While existing methods can recover\naccurate facial shapes, there remains significant space for improvement in\nfine-grained expression capture. Current approaches struggle with irregular\nmouth shapes, exaggerated expressions, and asymmetrical facial movements. We\npresent TEASER (Token EnhAnced Spatial modeling for Expressions\nReconstruction), which addresses these challenges and enhances 3D facial\ngeometry performance. TEASER tackles two main limitations of existing methods:\ninsufficient photometric loss for self-reconstruction and inaccurate\nlocalization of subtle expressions. We introduce a multi-scale tokenizer to\nextract facial appearance information. Combined with a neural renderer, these\ntokens provide precise geometric guidance for expression reconstruction.\nFurthermore, TEASER incorporates a pose-dependent landmark loss to further\nimprove geometric performances. Our approach not only significantly enhances\nexpression reconstruction quality but also offers interpretable tokens suitable\nfor various downstream applications, such as photorealistic facial video\ndriving, expression transfer, and identity swapping. Quantitative and\nqualitative experimental results across multiple datasets demonstrate that\nTEASER achieves state-of-the-art performance in precise expression\nreconstruction.",
    "pdf_url": "http://arxiv.org/pdf/2502.10982v3",
    "published": "2025-02-16T04:00:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.10981v1",
    "title": "Minimum forcing numbers of perfect matchings of circular and prismatic graphs",
    "authors": [
      "Qiaoyun Shi",
      "Heping Zhang"
    ],
    "abstract": "Let $G$ be a graph with a perfect matching. Denote by $f(G)$ the minimum size\nof a matching in $G$ which is uniquely extendable to a perfect matching in $G$.\nDiwan (2019) proved by linear algebra that for $d$-hypercube $Q_d$ ($d\\geq 2)$,\n$f(Q_n)=2^{d-2}$, settling a conjecture proposed by Pachter and Kim in 1998.\nRecently Mohammadian generalized this method to obtain a general result: for a\nbipartite graph $G$ on $n$ vertices, if there exists an involutory matrix $A$\non a field $F$ as a weighted adjacency matrix then $f(G\\Box K_2)=\\frac{n}{2}$.\nIn this paper, under the same condition we obtain $f(G\\Box C_{2k})=n ~(k\\ge2)$.\nAlso this method can be applied to some non-balanced bipartite graphs $G$\nwhenever $G$ admit a weighted bi-adjacency matrix with orthogonal rows.",
    "pdf_url": "http://arxiv.org/pdf/2502.10981v1",
    "published": "2025-02-16T03:56:01+00:00",
    "categories": [
      "math.CO",
      "05C70 05C50"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.10980v2",
    "title": "DFM: Deep Fourier Mimic for Expressive Dance Motion Learning",
    "authors": [
      "Ryo Watanabe",
      "Chenhao Li",
      "Marco Hutter"
    ],
    "abstract": "As entertainment robots gain popularity, the demand for natural and\nexpressive motion, particularly in dancing, continues to rise. Traditionally,\ndancing motions have been manually designed by artists, a process that is both\nlabor-intensive and restricted to simple motion playback, lacking the\nflexibility to incorporate additional tasks such as locomotion or gaze control\nduring dancing. To overcome these challenges, we introduce Deep Fourier Mimic\n(DFM), a novel method that combines advanced motion representation with\nReinforcement Learning (RL) to enable smooth transitions between motions while\nconcurrently managing auxiliary tasks during dance sequences. While previous\nfrequency domain based motion representations have successfully encoded dance\nmotions into latent parameters, they often impose overly rigid periodic\nassumptions at the local level, resulting in reduced tracking accuracy and\nmotion expressiveness, which is a critical aspect for entertainment robots. By\nrelaxing these locally periodic constraints, our approach not only enhances\ntracking precision but also facilitates smooth transitions between different\nmotions. Furthermore, the learned RL policy that supports simultaneous base\nactivities, such as locomotion and gaze control, allows entertainment robots to\nengage more dynamically and interactively with users rather than merely\nreplaying static, pre-designed dance routines.",
    "pdf_url": "http://arxiv.org/pdf/2502.10980v2",
    "published": "2025-02-16T03:52:18+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.10979v1",
    "title": "Steven Weinberg: A Scientific Life",
    "authors": [
      "C. P. Burgess",
      "F. Quevedo"
    ],
    "abstract": "Steven Weinberg was a giant of late 20th Century physics on whose shoulders\nwe stand while groping for the science of the 21st Century. This article\nprovides a too-brief summary of a selection of his many achievements -- eight\ndecades of superlative research, eight classic textbooks, eight best-selling\nforays into popular science writing and more.",
    "pdf_url": "http://arxiv.org/pdf/2502.10979v1",
    "published": "2025-02-16T03:47:21+00:00",
    "categories": [
      "physics.hist-ph",
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "physics.hist-ph"
  },
  {
    "id": "http://arxiv.org/abs/2502.10978v1",
    "title": "Agentic LLM Framework for Adaptive Decision Discourse",
    "authors": [
      "Antoine Dolant",
      "Praveen Kumar"
    ],
    "abstract": "Effective decision-making in complex systems requires synthesizing diverse\nperspectives to address multifaceted challenges under uncertainty. This study\nintroduces a real-world inspired agentic Large Language Models (LLMs)\nframework, to simulate and enhance decision discourse-the deliberative process\nthrough which actionable strategies are collaboratively developed. Unlike\ntraditional decision-support tools, the framework emphasizes dialogue,\ntrade-off exploration, and the emergent synergies generated by interactions\namong agents embodying distinct personas. These personas simulate diverse\nstakeholder roles, each bringing unique priorities, expertise, and value-driven\nreasoning to the table. The framework incorporates adaptive and self-governing\nmechanisms, enabling agents to dynamically summon additional expertise and\nrefine their assembly to address evolving challenges. An illustrative\nhypothetical example focused on extreme flooding in a Midwestern township\ndemonstrates the framework's ability to navigate uncertainty, balance competing\npriorities, and propose mitigation and adaptation strategies by considering\nsocial, economic, and environmental dimensions. Results reveal how the\nbreadth-first exploration of alternatives fosters robust and equitable\nrecommendation pathways. This framework transforms how decisions are approached\nin high-stakes scenarios and can be incorporated in digital environments. It\nnot only augments decision-makers' capacity to tackle complexity but also sets\na foundation for scalable and context-aware AI-driven recommendations. This\nresearch explores novel and alternate routes leveraging agentic LLMs for\nadaptive, collaborative, and equitable recommendation processes, with\nimplications across domains where uncertainty and complexity converge.",
    "pdf_url": "http://arxiv.org/pdf/2502.10978v1",
    "published": "2025-02-16T03:46:37+00:00",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.10977v2",
    "title": "The Bathroom Model: A Realistic Approach to Hash Table Algorithm Optimization",
    "authors": [
      "Qiantong Wang"
    ],
    "abstract": "Hash table search strategies have remained a pivotal area of inquiry in\ncomputer science over the past several decades. A prevailing viewpoint asserts\nthat random probing stands as the optimal method for open-addressing hash\ntables. Challenging this long-standing belief, a recent contribution introduces\nan elastic probing technique based on fixed interval thresholds. Although this\nmethod presents improvements over traditional strategies, its dependence on\nstatic thresholds limits its theoretical optimality.\n  In this paper, we propose a new conceptual model for optimizing hash table\nprobing, inspired by human behavior in selecting restroom stalls - dubbed the\n\"Bathroom Model.\" Unlike fixed or purely random approaches, our technique\ndynamically updates probing decisions using previously observed occupancy\npatterns, resulting in a more intelligent and adaptive search process. We\nrigorously formalize this model, analyze its theoretical properties, and\nbenchmark its performance against leading hash table algorithms. Our findings\nindicate that adaptive probing mechanisms can significantly enhance search\nefficiency while keeping computational demands minimal. This work not only\nsheds new light on an extensively studied problem but also points to broader\nalgorithmic opportunities in rethinking classical data structures.",
    "pdf_url": "http://arxiv.org/pdf/2502.10977v2",
    "published": "2025-02-16T03:41:08+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.10976v1",
    "title": "QuOTE: Question-Oriented Text Embeddings",
    "authors": [
      "Andrew Neeser",
      "Kaylen Latimer",
      "Aadyant Khatri",
      "Chris Latimer",
      "Naren Ramakrishnan"
    ],
    "abstract": "We present QuOTE (Question-Oriented Text Embeddings), a novel enhancement to\nretrieval-augmented generation (RAG) systems, aimed at improving document\nrepresentation for accurate and nuanced retrieval. Unlike traditional RAG\npipelines, which rely on embedding raw text chunks, QuOTE augments chunks with\nhypothetical questions that the chunk can potentially answer, enriching the\nrepresentation space. This better aligns document embeddings with user query\nsemantics, and helps address issues such as ambiguity and context-dependent\nrelevance. Through extensive experiments across diverse benchmarks, we\ndemonstrate that QuOTE significantly enhances retrieval accuracy, including in\nmulti-hop question-answering tasks. Our findings highlight the versatility of\nquestion generation as a fundamental indexing strategy, opening new avenues for\nintegrating question generation into retrieval-based AI pipelines.",
    "pdf_url": "http://arxiv.org/pdf/2502.10976v1",
    "published": "2025-02-16T03:37:13+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "H.3"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2502.10975v1",
    "title": "GS-GVINS: A Tightly-integrated GNSS-Visual-Inertial Navigation System Augmented by 3D Gaussian Splatting",
    "authors": [
      "Zelin Zhou",
      "Saurav Uprety",
      "Shichuang Nie",
      "Hongzhou Yang"
    ],
    "abstract": "Recently, the emergence of 3D Gaussian Splatting (3DGS) has drawn significant\nattention in the area of 3D map reconstruction and visual SLAM. While extensive\nresearch has explored 3DGS for indoor trajectory tracking using visual sensor\nalone or in combination with Light Detection and Ranging (LiDAR) and Inertial\nMeasurement Unit (IMU), its integration with GNSS for large-scale outdoor\nnavigation remains underexplored. To address these concerns, we proposed\nGS-GVINS: a tightly-integrated GNSS-Visual-Inertial Navigation System augmented\nby 3DGS. This system leverages 3D Gaussian as a continuous differentiable scene\nrepresentation in largescale outdoor environments, enhancing navigation\nperformance through the constructed 3D Gaussian map. Notably, GS-GVINS is the\nfirst GNSS-Visual-Inertial navigation application that directly utilizes the\nanalytical jacobians of SE3 camera pose with respect to 3D Gaussians. To\nmaintain the quality of 3DGS rendering in extreme dynamic states, we introduce\na motionaware 3D Gaussian pruning mechanism, updating the map based on relative\npose translation and the accumulated opacity along the camera ray. For\nvalidation, we test our system under different driving environments: open-sky,\nsub-urban, and urban. Both self-collected and public datasets are used for\nevaluation. The results demonstrate the effectiveness of GS-GVINS in enhancing\nnavigation accuracy across diverse driving environments.",
    "pdf_url": "http://arxiv.org/pdf/2502.10975v1",
    "published": "2025-02-16T03:29:32+00:00",
    "categories": [
      "cs.RO",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.10974v1",
    "title": "Simultaneous optical power delivery and distributed sensing through cross-band wavelength multiplexing over fiber link",
    "authors": [
      "Tianye Huang",
      "Lu Guo",
      "Xinyu Wang",
      "Yao Chen",
      "Jing Zhang",
      "Ming Zhu",
      "Mingkong Lu",
      "Kaifu Chen",
      "Hanlin Guo",
      "Liangming Xiong",
      "Xiangyun Hu",
      "Perry Ping Shum"
    ],
    "abstract": "Optical fibers offer significant advantages in both power delivery and\ndistributed sensing. In remote areas where stable power supply is not easy to\naccess, the distributed optical fiber sensing (DOFS) which offers long distance\nmonitoring capability and the power-over-fiber (PoF) which can provide energy\nfor connected electronics or other sensors are highly desired simultaneously.\nIn this letter, the PoF-DOFS hybrid system is proposed and experimentally\nverified for the first time. By multiplexing the power channel and sensing\nchannel with large wavelength separation, the cross-talk is greatly reduced.\nThe results show that the Brillouin frequency shift under different temperature\nin the Brillouin optical time domain reflectometry remains unaffected by the\nhigh-power transmission background and the power delivery efficiency up to ~66%\ncan be achieved over 1.3 km fiber link. This work paves the way for further\nresearch on PoF-DOFS hybrid system and gives a valuable solution for creating\nmulti-parameter, multi-scale sensing network without the need for local power\nsource.",
    "pdf_url": "http://arxiv.org/pdf/2502.10974v1",
    "published": "2025-02-16T03:26:19+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.10973v3",
    "title": "Akan Cinematic Emotions (ACE): A Multimodal Multi-party Dataset for Emotion Recognition in Movie Dialogues",
    "authors": [
      "David Sasu",
      "Zehui Wu",
      "Ziwei Gong",
      "Run Chen",
      "Pengyuan Shi",
      "Lin Ai",
      "Julia Hirschberg",
      "Natalie Schluter"
    ],
    "abstract": "In this paper, we introduce the Akan Conversation Emotion (ACE) dataset, the\nfirst multimodal emotion dialogue dataset for an African language, addressing\nthe significant lack of resources for low-resource languages in emotion\nrecognition research. ACE, developed for the Akan language, contains 385\nemotion-labeled dialogues and 6,162 utterances across audio, visual, and\ntextual modalities, along with word-level prosodic prominence annotations. The\npresence of prosodic labels in this dataset also makes it the first\nprosodically annotated African language dataset. We demonstrate the quality and\nutility of ACE through experiments using state-of-the-art emotion recognition\nmethods, establishing solid baselines for future research. We hope ACE inspires\nfurther work on inclusive, linguistically and culturally diverse NLP resources.",
    "pdf_url": "http://arxiv.org/pdf/2502.10973v3",
    "published": "2025-02-16T03:24:33+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.10972v1",
    "title": "Density-dependent spin susceptibility and effective mass in monolayer MoSe2",
    "authors": [
      "Chang Liu",
      "Tongtong Jia",
      "Zheng Sun",
      "Yu Gu",
      "Fan Xu",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Jinfeng Jia",
      "Shiyong Wang",
      "Xiaoxue Liu",
      "Tingxin Li"
    ],
    "abstract": "Atomically thin MoSe2 is a promising platform for investigating quantum\nphenomena due to its large effective mass, high crystal quality, and strong\nspin-orbit coupling. In this work, we demonstrate a triple-gate device design\nwith bismuth contacts, enabling reliable ohmic contact down to low electron\ndensities, with a maximum Hall mobility of approximately 22,000 cm2/Vs.\nLow-temperature transport measurements illustrate metal-insulator transitions,\nand density-dependent quantum oscillation sequences. Enhanced spin\nsusceptibility and density-dependent effective mass are observed, attributed to\ninteraction effects and valley polarization. These findings establish monolayer\nMoSe2 as a versatile platform for further exploring interaction-driven quantum\nstates.",
    "pdf_url": "http://arxiv.org/pdf/2502.10972v1",
    "published": "2025-02-16T03:23:16+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2502.10971v1",
    "title": "Scoring Nim",
    "authors": [
      "Hiromi Oginuma",
      "Masato Shinoda"
    ],
    "abstract": "Nim is a well-known combinatorial game, in which two players alternately\nremove stones from distinct piles. A player who removes the last stone wins\nunder the normal play rule, while a player loses under the mis\\`ere play rule.\nIn this paper, we propose a new variant of Nim with scoring that generalizes\nboth the normal and mis\\`ere play versions of Nim as special cases. We study\nthe theoretical aspects of this extended game and analyze its fundamental\nproperties, such as optimal strategies and payoff functions.",
    "pdf_url": "http://arxiv.org/pdf/2502.10971v1",
    "published": "2025-02-16T03:16:24+00:00",
    "categories": [
      "math.CO",
      "91A46"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.10970v1",
    "title": "Mirror symmetry from families of Calabi-Yau manifolds",
    "authors": [
      "Shinobu Hosono",
      "Hiromichi Takagi"
    ],
    "abstract": "We report interesting examples of Calabi-Yau threefolds where birational\ngeometry and geometry of Fourier-Mukai partners of a Calabi-Yau manifold arise\nnaturally from studying its mirror family of Calabi-Yau manifolds. We define\nmirror symmetry in terms of families of Calabi-Yau manifolds in general. We\nwill find for our examples that all expected geometry of Calabi-Yau manifolds\narises from special boundary points, called LCSL points, in the parameter space\nof mirror Calabi-Yau manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2502.10970v1",
    "published": "2025-02-16T03:11:19+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.10969v2",
    "title": "Moser's twist theorem revisited",
    "authors": [
      "Yi Liu",
      "Lin Wang"
    ],
    "abstract": "Inspired by the work of Katznelson and Ornstein, we present a short way to\nachieve the almost optimal regularity in Moser's twist theorem. Specifically,\nfor an integrable area-preserving twist map, the invariant circle with a given\nconstant type frequency $\\alpha$ persists under a small perturbation (dependent\non $\\alpha$) of class $C^{3+\\epsilon}$. This result was initially established\nindependently by Herman and R\\\"{u}ssmann in 1983. Our method differs\nessentially from their approaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.10969v2",
    "published": "2025-02-16T03:07:01+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2502.13160v3",
    "title": "Attention Mechanism for LLM-based Agents Dynamic Diffusion under Information Asymmetry",
    "authors": [
      "Yiwen Zhang",
      "Yifu Wu",
      "Wenyue Hua",
      "Xiang Lu",
      "Xuming Hu"
    ],
    "abstract": "Large language models have been used to simulate human society using\nmulti-agent systems. Most current social simulation research emphasizes\ninteractive behaviors in fixed environments, ignoring information opacity,\nrelationship variability, and diffusion diversity. In this paper, we first\npropose a general framework for exploring multi-agent information diffusion. We\nidentified LLMs' deficiency in the perception and utilization of social\nrelationships, as well as diverse actions. Then, we designed a dynamic\nattention mechanism to help agents allocate attention to different information,\naddressing the limitations of the LLM attention mechanism. Agents start by\nresponding to external information stimuli within a five-agent group,\nincreasing group size and forming information circles while developing\nrelationships and sharing information. Additionally, we explore the information\ndiffusion features in the asymmetric open environment by observing the\nevolution of information gaps, diffusion patterns, and the accumulation of\nsocial capital, which are closely linked to psychological, sociological, and\ncommunication theories.",
    "pdf_url": "http://arxiv.org/pdf/2502.13160v3",
    "published": "2025-02-16T03:02:48+00:00",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2502.10968v1",
    "title": "Construction and Properties of the Ground State of Natural Phenomena",
    "authors": [
      "Renaud Gauthier"
    ],
    "abstract": "We construct an $\\infty$-category $\\mathcal{G}$ as a model for the Ground\nState of physical phenomena and we provide properties of its manifestations\n$\\chi = \\text{Fun}(\\mathcal{G}, \\text{Cat}_{\\infty})$ in $\\text{Cat}_{\\infty}$\nas well as of its $\\infty$-category of spectra $\\text{Sp}(\\chi)$.",
    "pdf_url": "http://arxiv.org/pdf/2502.10968v1",
    "published": "2025-02-16T03:02:25+00:00",
    "categories": [
      "math.CT",
      "math-ph",
      "math.MP",
      "68P30, 18N60, 55P42, 18G80, 18E35"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2502.10967v1",
    "title": "Open-Set Cross-Network Node Classification via Unknown-Excluded Adversarial Graph Domain Alignment",
    "authors": [
      "Xiao Shen",
      "Zhihao Chen",
      "Shirui Pan",
      "Shuang Zhou",
      "Laurence T. Yang",
      "Xi Zhou"
    ],
    "abstract": "Existing cross-network node classification methods are mainly proposed for\nclosed-set setting, where the source network and the target network share\nexactly the same label space. Such a setting is restricted in real-world\napplications, since the target network might contain additional classes that\nare not present in the source. In this work, we study a more realistic open-set\ncross-network node classification (O-CNNC) problem, where the target network\ncontains all the known classes in the source and further contains several\ntarget-private classes unseen in the source. Borrowing the concept from\nopen-set domain adaptation, all target-private classes are defined as an\nadditional unknown class. To address the challenging O-CNNC problem, we propose\nan unknown-excluded adversarial graph domain alignment (UAGA) model with a\nseparate-adapt training strategy. Firstly, UAGA roughly separates known classes\nfrom unknown class, by training a graph neural network encoder and a\nneighborhood-aggregation node classifier in an adversarial framework. Then,\nunknown-excluded adversarial domain alignment is customized to align only\ntarget nodes from known classes with the source, while pushing target nodes\nfrom unknown class far away from the source, by assigning positive and negative\ndomain adaptation coefficient to known class nodes and unknown class nodes.\nExtensive experiments on real-world datasets demonstrate significant\noutperformance of the proposed UAGA over state-of-the-art methods on O-CNNC.",
    "pdf_url": "http://arxiv.org/pdf/2502.10967v1",
    "published": "2025-02-16T03:00:42+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2502.10966v1",
    "title": "Neural Networks Remember More: The Power of Parameter Isolation and Combination",
    "authors": [
      "Biqing Zeng",
      "Zehan Li",
      "Aladdin Ayesh"
    ],
    "abstract": "Catastrophic forgetting is a pervasive issue for pre-trained language models\n(PLMs) during continual learning, where models lose previously acquired\nknowledge when sequentially trained on a series of tasks. The model's ability\nto retain old tasks is referred to as stability, while its adaptability to new\ntasks is called plasticity. Therefore, the key to solving this problem is to\nfind a trade-off between the plasticity and stability of the model. To address\nthis issue, in this paper, we propose a novel method to achieve a balance\nbetween model stability and plasticity, thereby mitigating catastrophic\nforgetting. More specifically, our proposed approach leverages parameter\nisolation and a subsequent combination strategy. Initially, in the training\nstage, the model adapts to each downstream task via a parameter isolation\nmethod to prevent potential interference among different tasks. We then combine\nall trained parameters, which contain acquired knowledge, using the task\narithmetic method and finally apply them to the backbone model. Empirical\nevaluations on continual language learning benchmarks substantiate the\neffectiveness of our approach, revealing a marked enhancement over existing\nstate-of-the-art approaches.",
    "pdf_url": "http://arxiv.org/pdf/2502.10966v1",
    "published": "2025-02-16T02:58:57+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.13159v1",
    "title": "Accelerated Fatigue Strength Prediction via Additive Manufactured Functionally Graded Materials and High-Throughput Plasticity Quantification",
    "authors": [
      "C. Bean",
      "M. Calvat",
      "Y. Nie",
      "R. L Black",
      "N. Velisavljevic",
      "D. Anjaria",
      "M. A. Charpagne",
      "J. C. Stinville"
    ],
    "abstract": "Recent improvements in additive manufacturing and high-throughput material\nsynthesis have enabled the discovery of novel metallic materials for extreme\nenvironments. However, high-fidelity testing of advanced mechanical properties\nsuch as fatigue strength, has often been the most time-consuming and\nresource-intensive step of material discovery, thereby slowing down the\nadoption of novel materials. This work presents a new method for rapid\ncharacterization of the fatigue properties of many compositions while only\ntesting a single specimen. The approach utilizes high-resolution digital image\ncorrelation along with a computer vision model to extract the relationship\nbetween localized plastic deformation events and associated mechanical\nproperties. The approach is initially validated on an additive manufactured\n316L dataset, then applied to a functionally graded additive manufactured\nspecimen with a composition gradient across the gauge length. This allows for\nthe characterization of multiple compositions, orders of magnitude faster than\ntraditional methods.",
    "pdf_url": "http://arxiv.org/pdf/2502.13159v1",
    "published": "2025-02-16T02:54:15+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2502.10965v1",
    "title": "Higher Rank Macdonald Polynomials",
    "authors": [
      "Milo Bechtloff Weising"
    ],
    "abstract": "In this paper, we introduce higher rank generalizations of Macdonald\npolynomials. The higher rank non-symmetric Macdonald polynomials are Laurent\npolynomials in several sets of variables which form weight bases for higher\nrank polynomial representations of double affine Hecke algebras with respect to\nhigher rank Cherednik operators. We prove that these polynomials satisfy\ngeneralized versions of the classical Knop--Sahi relations and we give\ncombinatorial descriptions of their weights. The higher rank symmetric\nMacdonald polynomials are defined as Hecke-symmetrizations of the higher rank\nnon-symmetric Macdonald polynomials and form eigenbases for the spaces of\nHecke-invariant higher rank polynomials with respect to generalized finite\nvariable Macdonald operators. We prove that the higher rank symmetric Macdonald\npolynomials satisfy stability properties allowing for the construction of\ninfinite variable limits. These higher rank symmetric Macdonald functions form\neigenbases for certain representations of the (positive) elliptic Hall algebra\nwith respect to generalized infinite variable Macdonald operators. Lastly, we\nshow that the higher rank polynomial representations may be used to construct\nhigher rank polynomial representations of the double Dyck path algebra. This is\na copy of the author's accepted extended abstract for FPSAC2025.",
    "pdf_url": "http://arxiv.org/pdf/2502.10965v1",
    "published": "2025-02-16T02:53:04+00:00",
    "categories": [
      "math.CO",
      "math.QA",
      "math.RT"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.10964v1",
    "title": "The equivariant degree and an enriched count of rational cubics",
    "authors": [
      "Candace Bethea",
      "Kirsten Wickelgren"
    ],
    "abstract": "We define the equivariant degree and local degree of a proper $G$-equivariant\nmap between smooth $G$-manifolds when $G$ is a compact Lie group and prove a\nlocal to global result. We show the local degree can be used to compute the\nequivariant Euler characteristic of a smooth, compact $G$-manifold and the\nEuler number of a relatively oriented $G$-equivariant vector bundle when $G$ is\nfinite. As an application, we give an equivariantly enriched count of rational\nplane cubics through a $G$-invariant set of 8 general points in\n$\\mathbb{C}\\mathbb{P}^2$, valued in the representation ring and Burnside ring\nof a finite group. When $\\mathbb{Z}/2$ acts by pointwise complex conjugation\nthis recovers a signed count of real rational cubics.",
    "pdf_url": "http://arxiv.org/pdf/2502.10964v1",
    "published": "2025-02-16T02:52:33+00:00",
    "categories": [
      "math.AT",
      "math.AG"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2502.10963v1",
    "title": "Noncommutative metasurfaces enabled diverse quantum path entanglement of structured photons",
    "authors": [
      "Yan Wang",
      "Yichang Shou",
      "Jiawei Liu",
      "Qiang Yang",
      "Shizhen Chen",
      "Weixing Shu",
      "Shuangchun Wen",
      "Hailu Luo"
    ],
    "abstract": "Quantum entanglement, a fundamental concept in quantum mechanics, lies at the\nheart of many current and future quantum technologies. A pivotal task is\ngeneration and control of diverse quantum entangled states in a more compact\nand flexible manner. Here, we introduce an approach to achieve diverse path\nentanglement by exploiting the interaction between noncommutative metasurfaces\nand entangled photons. Different from other path entanglement, our quantum path\nentanglement is evolvement path entanglement of photons on Poincar\\'e sphere.\nDue to quantum entanglement between idler photons and structured signal\nphotons, evolvement path of idler photons on the fundamental Poincar\\'e sphere\ncan be nonlocally mirrored by structured signal photons on any high-order\nPoincar\\'e sphere, resulting in quantum path entanglement. Benefiting from\nnoncommutative metasurfaces, diverse quantum path entanglement can be switched\nacross different higher-order Poincar\\'e spheres using distinct combination\nsequences of metasurfaces. Our method allows for the tuning of diverse quantum\npath entanglement across a broad spectrum of quantum states, offering a\nsignificant advancement in the manipulation of quantum entanglement.",
    "pdf_url": "http://arxiv.org/pdf/2502.10963v1",
    "published": "2025-02-16T02:51:47+00:00",
    "categories": [
      "physics.optics",
      "quant-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.10962v1",
    "title": "Orbital Signatures of Density Wave Transition in La3Ni2O7-delta and La2PrNi2O7-delta RP-Nickelates Probed via in-situ X-ray Absorption Near-edge Spectroscopy",
    "authors": [
      "Mingtao Li",
      "Mingxin Zhang",
      "Yiming Wang",
      "Jiayi Guan",
      "Nana Li",
      "Cuiying Pei",
      "N-Diaye Adama",
      "Qingyu Kong",
      "Yanpeng Qi",
      "Wenge Yang"
    ],
    "abstract": "The report of superconductivity (SC) with Tc~80 K in bilayer\nRuddlesden-Popper (RP) nickelate La3Ni2O7-delta have sparked considerable\ninvestigations on its normal state properties and SC mechanism under pressure\nand at low temperature. It is believed that the density wave (DW) at ~150 K\nplays an important role in SC emergence, but its nature remains largely\nunderexplored. Here, we utilized temperature-dependent in-situ Ni K-edge X-ray\nAbsorption Near-edge Spectroscopy (XANES) to probe the Ni-3d/4p electronic\nstates of La3Ni2O7-delta and La2PrNi2O7-delta samples down to 4.8 K, enabling\nus to witness the evolution of both in-plane d_(x^2-y^2)/p_x (p_y) and\nout-of-plane d_(3z^2-r^2)/p_z orbitals of NiO6 octahedron across the DW\ntransition. Main edge energy associated with Ni 4p orbital shows an anomalous\ndecline near DW transition, signifying the occurrence of lattice distortions as\na hallmark of charge density wave. Below DW transition, the enlarged crystal\nfield splitting (CFS) indicates an enhanced NiO6 octahedral distortion.\nIntriguingly, magnetic Pr substituents could activate the mutual interplay of\nd_(x^2-y^2) and d_(3z^2-r^2) orbitals. We discussed its relevance to the\nfavored bulk SC in the pressurized polycrystalline La2PrNi2O7-delta than\npristine.",
    "pdf_url": "http://arxiv.org/pdf/2502.10962v1",
    "published": "2025-02-16T02:50:22+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2502.10961v1",
    "title": "Graders should cheat: privileged information enables expert-level automated evaluations",
    "authors": [
      "Jin Peng Zhou",
      "Sbastien M. R. Arnold",
      "Nan Ding",
      "Kilian Q. Weinberger",
      "Nan Hua",
      "Fei Sha"
    ],
    "abstract": "Auto-evaluating language models (LMs), i.e., using a grader LM to evaluate\nthe candidate LM, is an appealing way to accelerate the evaluation process and\nthe cost associated with it. But this presents a paradox: how can we trust the\ngrader LM, which is presumably weaker than the candidate LM, to assess problems\nthat are beyond the frontier of the capabilities of either model or both? For\ninstance, today's LMs struggle on graduate-level physics and Olympiad-level\nmath, making them unreliable graders in these domains.\n  We show that providing privileged information -- such as ground-truth\nsolutions or problem-specific guidelines -- improves automated evaluations on\nsuch frontier problems. This approach offers two key advantages. First, it\nexpands the range of problems where LMs graders apply. Specifically, weaker\nmodels can now rate the predictions of stronger models. Second, privileged\ninformation can be used to devise easier variations of challenging problems\nwhich improves the separability of different LMs on tasks where their\nperformance is generally low. With this approach, general-purpose LM graders\nmatch the state of the art performance on RewardBench, surpassing almost all\nthe specially-tuned models. LM graders also outperform individual human raters\non Vibe-Eval, and approach human expert graders on Olympiad-level math\nproblems.",
    "pdf_url": "http://arxiv.org/pdf/2502.10961v1",
    "published": "2025-02-16T02:47:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.12199v1",
    "title": "Discrete isoperimetric inequalities on the strong products of paths",
    "authors": [
      "Runze Wang"
    ],
    "abstract": "For a graph $G=(V,\\ E)$ and a nonempty set $S\\subseteq V$, the \\emph{vertex\nboundary} of $S$, denoted by $\\partial_G(S)$, is defined to be the set of\nvertices that are not in $S$ but are adjacent to some vertex in $S$. In this\npaper, we focus on the strong products of paths, and study when the size of the\nvertex boundary of a set of $k$ vertices is minimized. We give a conjecture\nregarding the $n$-dimensional strong product of infinite paths, and prove it\nfor the $2$-dimensional case. Also, we determine when $|\\partial_G(S)|$ is\nminimized if $G$ is a $2$-dimensional strong product of finite paths.",
    "pdf_url": "http://arxiv.org/pdf/2502.12199v1",
    "published": "2025-02-16T02:46:53+00:00",
    "categories": [
      "math.CO",
      "05C35"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2502.10960v2",
    "title": "Convergence of rescaled \"true\" self-avoiding walks to the Tth-Werner \"true\" self-repelling motion",
    "authors": [
      "Elena Kosygina",
      "Jonathon Peterson"
    ],
    "abstract": "We prove that the rescaled ``true'' self-avoiding walk $(n^{-2/3}X_{\\lfloor\nnt \\rfloor})_{t\\in\\mathbb{R}_+}$ converges weakly as $n$ goes to infinity to\nthe ``true'' self-repelling motion constructed by T\\'oth and Werner. The proof\nfeatures a joint generalized Ray-Knight theorem for the rescaled local times\nprocesses and their merge and absorption points as the main tool for showing\nboth the tightness and convergence of the finite dimensional distributions.\nThus, our result can be seen as an example of establishing a functional limit\ntheorem for a family of processes by inverting the joint generalized Ray-Knight\ntheorem.",
    "pdf_url": "http://arxiv.org/pdf/2502.10960v2",
    "published": "2025-02-16T02:35:33+00:00",
    "categories": [
      "math.PR",
      "60K35, 60F17, 60J55"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2502.10959v1",
    "title": "Revisiting the Design of In-Memory Dynamic Graph Storage",
    "authors": [
      "Jixian Su",
      "Chiyu Hao",
      "Shixuan Sun",
      "Hao Zhang",
      "Sen Gao",
      "Jiaxin Jiang",
      "Yao Chen",
      "Chenyi Zhang",
      "Bingsheng He",
      "Minyi Guo"
    ],
    "abstract": "The effectiveness of in-memory dynamic graph storage (DGS) for supporting\nconcurrent graph read and write queries is crucial for real-time graph\nanalytics and updates. Various methods have been proposed, for example, LLAMA,\nAspen, LiveGraph, Teseo, and Sortledton. These approaches differ significantly\nin their support for read and write operations, space overhead, and concurrency\ncontrol. However, there has been no systematic study to explore the trade-offs\namong these dimensions. In this paper, we evaluate the effectiveness of\nindividual techniques and identify the performance factors affecting these\nstorage methods by proposing a common abstraction for DGS design and\nimplementing a generic test framework based on this abstraction. Our findings\nhighlight several key insights: 1) Existing DGS methods exhibit substantial\nspace overhead. For example, Aspen consumes 3.3-10.8x more memory than CSR,\nwhile the optimal fine-grained methods consume 4.1-8.9x more memory than CSR,\nindicating a significant memory overhead. 2) Existing methods often overlook\nmemory access impact of modern architectures, leading to performance\ndegradation compared to continuous storage methods. 3) Fine-grained concurrency\ncontrol methods, in particular, suffer from severe efficiency and space issues\ndue to maintaining versions and performing checks for each neighbor. These\nmethods also experience significant contention on high-degree vertices. Our\nsystematic study reveals these performance bottlenecks and outlines future\ndirections to improve DGS for real-time graph analytics.",
    "pdf_url": "http://arxiv.org/pdf/2502.10959v1",
    "published": "2025-02-16T02:30:16+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2502.10958v1",
    "title": "Estimation of Treatment Effects based on Kernel Matching",
    "authors": [
      "Chong Ding",
      "Zheng Li",
      "Hon Keung Tony Ng",
      "Wei Gao"
    ],
    "abstract": "The treatment effect represents the average causal impact or outcome\ndifference between treatment and control groups. Treatment effects can be\n  estimated through social experiments, regression models, matching estimators,\nand instrumental variables. In this paper, we introduce a novel\n  kernel-matching estimator for treatment effect estimation. This method is\n  particularly beneficial in observational studies where randomized control\n  trials are not feasible, as it uses the full sample to increase the\nefficiency\n  and robustness of treatment effect estimates. We demonstrate that the\n  proposed estimator is consistent and asymptotically efficient under certain\n  conditions. Through Monte Carlo simulations, we show that the estimator\n  performs favorably against other estimators in the literature. Finally, we\n  apply our method to data from the National Supported Work Demonstration to\nillustrate its practical application.",
    "pdf_url": "http://arxiv.org/pdf/2502.10958v1",
    "published": "2025-02-16T02:30:08+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.10957v1",
    "title": "Skillful Nowcasting of Convective Clouds With a Cascade Diffusion Model",
    "authors": [
      "Haoming Chen",
      "Xiaohui Zhong",
      "Qiang Zhai",
      "Xiaomeng Li",
      "Ying Wa Chan",
      "Pak Wai Chan",
      "Yuanyuan Huang",
      "Hao Li",
      "Xiaoming Shi"
    ],
    "abstract": "Accurate nowcasting of convective clouds from satellite imagery is essential\nfor mitigating the impacts of meteorological disasters, especially in\ndeveloping countries and remote regions with limited ground-based observations.\nRecent advances in deep learning have shown promise in video prediction;\nhowever, existing models frequently produce blurry results and exhibit reduced\naccuracy when forecasting physical fields. Here, we introduce SATcast, a\ndiffusion model that leverages a cascade architecture and multimodal inputs for\nnowcasting cloud fields in satellite imagery. SATcast incorporates physical\nfields predicted by FuXi, a deep-learning weather model, alongside past\nsatellite observations as conditional inputs to generate high-quality future\ncloud fields. Through comprehensive evaluation, SATcast outperforms\nconventional methods on multiple metrics, demonstrating its superior accuracy\nand robustness. Ablation studies underscore the importance of its multimodal\ndesign and the cascade architecture in achieving reliable predictions. Notably,\nSATcast maintains predictive skill for up to 24 hours, underscoring its\npotential for operational nowcasting applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.10957v1",
    "published": "2025-02-16T02:29:13+00:00",
    "categories": [
      "cs.CV",
      "physics.ao-ph"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.10956v1",
    "title": "Fine-Tuning Hard-to-Simulate Objectives for Quadruped Locomotion: A Case Study on Total Power Saving",
    "authors": [
      "Ruiqian Nai",
      "Jiacheng You",
      "Liu Cao",
      "Hanchen Cui",
      "Shiyuan Zhang",
      "Huazhe Xu",
      "Yang Gao"
    ],
    "abstract": "Legged locomotion is not just about mobility; it also encompasses crucial\nobjectives such as energy efficiency, safety, and user experience, which are\nvital for real-world applications. However, key factors such as battery power\nconsumption and stepping noise are often inaccurately modeled or missing in\ncommon simulators, leaving these aspects poorly optimized or unaddressed by\ncurrent sim-to-real methods. Hand-designed proxies, such as mechanical power\nand foot contact forces, have been used to address these challenges but are\noften problem-specific and inaccurate.\n  In this paper, we propose a data-driven framework for fine-tuning locomotion\npolicies, targeting these hard-to-simulate objectives. Our framework leverages\nreal-world data to model these objectives and incorporates the learned model\ninto simulation for policy improvement. We demonstrate the effectiveness of our\nframework on power saving for quadruped locomotion, achieving a significant\n24-28\\% net reduction in total power consumption from the battery pack at\nvarious speeds. In essence, our approach offers a versatile solution for\noptimizing hard-to-simulate objectives in quadruped locomotion, providing an\neasy-to-adapt paradigm for continual improving with real-world knowledge.\nProject page https://hard-to-sim.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2502.10956v1",
    "published": "2025-02-16T02:22:50+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2502.10955v1",
    "title": "A recurrent vision transformer shows signatures of primate visual attention",
    "authors": [
      "Jonathan Morgan",
      "Badr Albanna",
      "James P. Herman"
    ],
    "abstract": "Attention is fundamental to both biological and artificial intelligence, yet\nresearch on animal attention and AI self attention remains largely\ndisconnected. We propose a Recurrent Vision Transformer (Recurrent ViT) that\nintegrates self-attention with recurrent memory, allowing both current inputs\nand stored information to guide attention allocation. Trained solely via sparse\nreward feedback on a spatially cued orientation change detection task, a\nparadigm used in primate studies, our model exhibits primate like signatures of\nattention, including improved accuracy and faster responses for cued stimuli\nthat scale with cue validity. Analysis of self-attention maps reveals dynamic\nspatial prioritization with reactivation prior to expected changes, and\ntargeted perturbations produce performance shifts similar to those observed in\nprimate frontal eye fields and superior colliculus. These findings demonstrate\nthat incorporating recurrent feedback into self attention can capture key\naspects of primate visual attention.",
    "pdf_url": "http://arxiv.org/pdf/2502.10955v1",
    "published": "2025-02-16T02:22:27+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.10954v2",
    "title": "Learning to Stop Overthinking at Test Time",
    "authors": [
      "Hieu Tran Bao",
      "Nguyen Cong Dat",
      "Nguyen Duc Anh",
      "Hoang Thanh-Tung"
    ],
    "abstract": "Test time scaling is currently one of the most active research areas that\nshows promise after training time scaling has reached its limits. Deep-thinking\n(DT) models are a class of recurrent models that can perform easy-to-hard\ngeneralization by assigning more compute to harder test samples. However, due\nto their inability to determine the complexity of a test sample, DT models have\nto use a large amount of computation for both easy and hard test samples.\nExcessive test time computation is wasteful and can cause the ``overthinking''\nproblem where more test time computation leads to worse results. In this paper,\nwe introduce a test time training method for determining the optimal amount of\ncomputation needed for each sample during test time. We also propose\nConv-LiGRU, a novel recurrent architecture for efficient and robust visual\nreasoning. Extensive experiments demonstrate that Conv-LiGRU is more stable\nthan DT, effectively mitigates the ``overthinking'' phenomenon, and achieves\nsuperior accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2502.10954v2",
    "published": "2025-02-16T02:17:05+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2502.10953v1",
    "title": "Empirical evaluation of LLMs in predicting fixes of Configuration bugs in Smart Home System",
    "authors": [
      "Sheikh Moonwara Anjum Monisha",
      "Atul Bharadwaj"
    ],
    "abstract": "This empirical study evaluates the effectiveness of Large Language Models\n(LLMs) in predicting fixes for configuration bugs in smart home systems. The\nresearch analyzes three prominent LLMs - GPT-4, GPT-4o (GPT-4 Turbo), and\nClaude 3.5 Sonnet - using four distinct prompt designs to assess their ability\nto identify appropriate fix strategies and generate correct solutions. The\nstudy utilized a dataset of 129 debugging issues from the Home Assistant\nCommunity, focusing on 21 randomly selected cases for in-depth analysis.\nResults demonstrate that GPT-4 and Claude 3.5 Sonnet achieved 80\\% accuracy in\nstrategy prediction when provided with both bug descriptions and original\nscripts. GPT-4 exhibited consistent performance across different prompt types,\nwhile GPT-4o showed advantages in speed and cost-effectiveness despite slightly\nlower accuracy. The findings reveal that prompt design significantly impacts\nmodel performance, with comprehensive prompts containing both description and\noriginal script yielding the best results. This research provides valuable\ninsights for improving automated bug fixing in smart home system configurations\nand demonstrates the potential of LLMs in addressing configuration-related\nchallenges.",
    "pdf_url": "http://arxiv.org/pdf/2502.10953v1",
    "published": "2025-02-16T02:11:36+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2502.10952v1",
    "title": "Egg yolk as a model for gelation: from rheometry to flow physics",
    "authors": [
      "Maxwell Marsh",
      "Mohammad Tanver Hossain",
      "Randy Ewoldt"
    ],
    "abstract": "Egg yolks are an excellent model for studying sol-gel transitions,\nparticularly the power law viscoelasticity that defines the critical point of\ngelation. However, prior studies lack comprehensive datasets and fail to\nvisualize flow behavior linked to temperature and time-dependent linear and\nnonlinear rheology. Here we present a detailed dataset characterizing egg yolk\nviscoelasticity across temperature, time, and forcing amplitude using\noscillatory shear, step strain, step stress, and constant high strain rate.\nNovel protorheology visualizations link rheological properties with observable\nflow behavior. Our findings highlight the nuanced determination of the critical\ngel point, emphasizing observation timescale dependencies. We compare methods\nto identify critical temperatures for gelation, including power law\nviscoelasticity, moduli crossover, diverging zero-shear viscosity, and emerging\nequilibrium elastic modulus, while visualizing flow consequences near these\ntransitions. Egg yolk is an accessible non-toxic material relevant to the\nphysicist and the chef alike, making it ideal for understanding the rheology of\ncritical gels. By integrating protorheology photos and videos with rigorous\nrheometric data, we deepen the understanding of critical gels, with broader\nimpacts for teaching and modeling sol-gel transitions.",
    "pdf_url": "http://arxiv.org/pdf/2502.10952v1",
    "published": "2025-02-16T02:11:11+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2502.10951v2",
    "title": "Prompt and Conventional High-Energy Muon Spectra from a full Monte Carlo Simulation via $\\texttt{CORSIKA7}$",
    "authors": [
      "Ludwig Neste",
      "Pascal Gutjahr",
      "Mirco Hnnefeld",
      "Jean-Marco Alameddine",
      "Wolfgang Rhode",
      "Julia Becker Tjus",
      "Felix Riehn",
      "Kevin Krninger",
      "Johannes Albrecht"
    ],
    "abstract": "Extensive air showers produce high-energy muons that can be utilized to probe\nhadronic interaction models in cosmic ray interactions. Most muons originate\nfrom pion and kaon decays, called $\\textit{conventional}$ muons, while a\nsmaller fraction, referred to as $\\textit{prompt}$ muons, arises from the decay\nof heavier, short-lived hadrons. The $\\texttt{EHISTORY}$ option of the air\nshower simulation tool $\\texttt{CORSIKA7}$ is used in this work to investigate\nthe prompt and conventional muon flux in the energy range of 100 TeV to 100\nPeV, utilizing the newly developed open-source python software\n$\\texttt{PANAMA}$. Identifying the muon parent particles allows for scaling the\ncontribution of prompt particles, which can be leveraged by future experimental\nanalyses to measure the normalization of the prompt muon flux. Obtained prompt\nmuon spectra from $\\texttt{CORSIKA7}$ are compared to $\\texttt{MCEq}$ results.\nThe relevance to large-volume neutrino detectors, such as IceCube and KM3NeT,\nand the connection to hadronic interaction models is discussed.",
    "pdf_url": "http://arxiv.org/pdf/2502.10951v2",
    "published": "2025-02-16T02:03:02+00:00",
    "categories": [
      "astro-ph.HE",
      "hep-ex"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2502.10950v2",
    "title": "SpeechT-RAG: Reliable Depression Detection in LLMs with Retrieval-Augmented Generation Using Speech Timing Information",
    "authors": [
      "Xiangyu Zhang",
      "Hexin Liu",
      "Qiquan Zhang",
      "Beena Ahmed",
      "Julien Epps"
    ],
    "abstract": "Large Language Models (LLMs) have been increasingly adopted for\nhealth-related tasks, yet their performance in depression detection remains\nlimited when relying solely on text input. While Retrieval-Augmented Generation\n(RAG) typically enhances LLM capabilities, our experiments indicate that\ntraditional text-based RAG systems struggle to significantly improve depression\ndetection accuracy. This challenge stems partly from the rich\ndepression-relevant information encoded in acoustic speech patterns information\nthat current text-only approaches fail to capture effectively. To address this\nlimitation, we conduct a systematic analysis of temporal speech patterns,\ncomparing healthy individuals with those experiencing depression. Based on our\nfindings, we introduce Speech Timing-based Retrieval-Augmented Generation,\nSpeechT-RAG, a novel system that leverages speech timing features for both\naccurate depression detection and reliable confidence estimation. This\nintegrated approach not only outperforms traditional text-based RAG systems in\ndetection accuracy but also enhances uncertainty quantification through a\nconfidence scoring mechanism that naturally extends from the same temporal\nfeatures. Our unified framework achieves comparable results to fine-tuned LLMs\nwithout additional training while simultaneously addressing the fundamental\nrequirements for both accuracy and trustworthiness in mental health assessment.",
    "pdf_url": "http://arxiv.org/pdf/2502.10950v2",
    "published": "2025-02-16T02:02:19+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2502.10949v1",
    "title": "Learning the Exact Time Integration Algorithm for Initial Value Problems by Randomized Neural Networks",
    "authors": [
      "Suchuan Dong",
      "Naxian Ni"
    ],
    "abstract": "We present a method leveraging extreme learning machine (ELM) type randomized\nneural networks (NNs) for learning the exact time integration algorithm for\ninitial value problems (IVPs). The exact time integration algorithm for\nnon-autonomous systems can be represented by an algorithmic function in higher\ndimensions, which satisfies an associated system of partial differential\nequations with corresponding boundary conditions. Our method learns the\nalgorithmic function by solving this associated system using ELM with a physics\ninformed approach. The trained ELM network serves as the learned algorithm and\ncan be used to solve the IVP with arbitrary initial data or step sizes from\nsome domain. When the right hand side of the non-autonomous system exhibits a\nperiodicity with respect to any of its arguments, while the solution itself to\nthe problem is not periodic, we show that the algorithmic function is either\nperiodic, or when it is not, satisfies a well-defined relation for different\nperiods. This property can greatly simplify the algorithm learning in many\nproblems. We consider explicit and implicit NN formulations, leading to\nexplicit or implicit time integration algorithms, and discuss how to train the\nELM network by the nonlinear least squares method. Extensive numerical\nexperiments with benchmark problems, including non-stiff, stiff and chaotic\nsystems, show that the learned NN algorithm produces highly accurate solutions\nin long-time simulations, with its time-marching errors decreasing nearly\nexponentially with increasing degrees of freedom in the neural network. We\ncompare extensively the computational performance (accuracy vs.~cost) between\nthe current NN algorithm and the leading traditional time integration\nalgorithms. The learned NN algorithm is computationally competitive, markedly\noutperforming the traditional algorithms in many problems.",
    "pdf_url": "http://arxiv.org/pdf/2502.10949v1",
    "published": "2025-02-16T01:53:52+00:00",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "physics.comp-ph"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2502.10948v2",
    "title": "Flat Convergence of Pushforwards of Rectifiable Currents Under $C^0-$Diffeomorphism Limits",
    "authors": [
      "Stephane Tchuiaga"
    ],
    "abstract": "This article deals with the stability of the pushforward operation on\ncurrents with respect to $C^0$ limits of diffeomorphisms on compact Riemannian\nmanifolds. We have established the uniform convergence of pullbacks of smooth\nforms and weak-* convergence of pushforwards of general currents. The key lemma\nbrings convergence on closed 1-forms for the evaluation of 1-currents. The main\ntheorem shows that the pushforward of rectifiable $k$-currents converges in the\nflat topology for $C^0$ convergent sequences of diffeomorphisms. We discuss\nimplications in symplectic, cosymplectic, and contact geometry, making\nconnections with the $C^0$ rigidity of certain geometric structures. We also\nconsider applications to free boundary problems and stochastic currents. These\nresults provide insight into the behavior of geometric objects under non-smooth\nperturbations, which have relevance in geometric measure theory, dynamical\nsystems, and optimal transport. We highlight various open problems regarding\nweaker regularity and more involved geometric settings.",
    "pdf_url": "http://arxiv.org/pdf/2502.10948v2",
    "published": "2025-02-16T01:51:31+00:00",
    "categories": [
      "math.DG",
      "math.DS"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2502.10947v1",
    "title": "The Relationship between No-Regret Learning and Online Conformal Prediction",
    "authors": [
      "Ramya Ramalingam",
      "Shayan Kiyani",
      "Aaron Roth"
    ],
    "abstract": "Existing algorithms for online conformal prediction -- guaranteeing marginal\ncoverage in adversarial settings -- are variants of online gradient descent\n(OGD), but their analyses of worst-case coverage do not follow from the regret\nguarantee of OGD. What is the relationship between no-regret learning and\nonline conformal prediction? We observe that although standard regret\nguarantees imply marginal coverage in i.i.d. settings, this connection fails as\nsoon as we either move to adversarial environments or ask for group conditional\ncoverage. On the other hand, we show a tight connection between threshold\ncalibrated coverage and swap-regret in adversarial settings, which extends to\ngroup-conditional (multi-valid) coverage. We also show that algorithms in the\nfollow the perturbed leader family of no regret learning algorithms (which\nincludes online gradient descent) can be used to give group-conditional\ncoverage guarantees in adversarial settings for arbitrary grouping functions.\nVia this connection we analyze and conduct experiments using a multi-group\ngeneralization of the ACI algorithm of Gibbs & Candes [2021]\n(arXiv:2106.00170).",
    "pdf_url": "http://arxiv.org/pdf/2502.10947v1",
    "published": "2025-02-16T01:39:05+00:00",
    "categories": [
      "cs.LG",
      "cs.GT",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.10946v2",
    "title": "Emergent functions of noise-driven spontaneous activity: Homeostatic maintenance of criticality and memory consolidation",
    "authors": [
      "Narumitsu Ikeda",
      "Dai Akita",
      "Hirokazu Takahashi"
    ],
    "abstract": "Unlike digital computers, the brain exhibits spontaneous activity even during\ncomplete rest, despite the evolutionary pressure for energy efficiency.\nInspired by the critical brain hypothesis, which proposes that the brain\noperates optimally near a critical point of phase transition in the dynamics of\nneural networks to improve computational efficiency, we postulate that\nspontaneous activity plays a homeostatic role in the development and\nmaintenance of criticality. Criticality in the brain is associated with the\nbalance between excitatory and inhibitory synaptic inputs (EI balance), which\nis essential for maintaining neural computation performance. Here, we\nhypothesize that both criticality and EI balance are stabilized by appropriate\nnoise levels and spike-timing-dependent plasticity (STDP) windows. Using\nspiking neural network (SNN) simulations and in vitro experiments with\ndissociated neuronal cultures, we demonstrated that while repetitive stimuli\ntransiently disrupt both criticality and EI balance, spontaneous activity can\ndevelop and maintain these properties and prolong the fading memory of past\nstimuli. Our findings suggest that the brain may achieve self-optimization and\nmemory consolidation as emergent functions of noise-driven spontaneous\nactivity. This noise-harnessing mechanism provides insights for designing\nenergy-efficient neural networks, and may explain the critical function of\nsleep in maintaining homeostasis and consolidating memory.",
    "pdf_url": "http://arxiv.org/pdf/2502.10946v2",
    "published": "2025-02-16T01:37:38+00:00",
    "categories": [
      "q-bio.NC",
      "nlin.AO"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2502.10945v2",
    "title": "Tannakian categories: origins and summary",
    "authors": [
      "James S Milne"
    ],
    "abstract": "We describe the origins of the theory of tannakian categories, and summarize\nits main results.",
    "pdf_url": "http://arxiv.org/pdf/2502.10945v2",
    "published": "2025-02-16T01:29:38+00:00",
    "categories": [
      "math.AG",
      "math.CT",
      "14C15, 18M25"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2502.10944v1",
    "title": "The Halo Occupation Distribution Modeling of the X-ray-selected AGNs at 0.6 < z < 2.6 in the COSMOS field",
    "authors": [
      "Hiroyuki Ikeda",
      "Takamitsu Miyaji",
      "Taira Oogi",
      "Yoshiki Toba",
      "Hctor Aceves",
      "Stefano Marchesi",
      "Viola Allevato",
      "Akke Viitanen",
      "Francesca Civano"
    ],
    "abstract": "We conducted precise measurements of Active Galactic Nuclei (AGNs) clustering\nat $z\\sim1$ and $z\\sim2$ by measuring the two-point cross-correlation function\n(CCF) between galaxies and X-ray-selected AGNs, and the two-point\nauto-correlation function (ACF) of galaxies in the COSMOS field to interpret\nthe CCF results. The galaxy sample was selected from the COSMOS2015 catalog,\nwhile the AGN sample was chosen from the {\\sl Chandra} COSMOS-Legacy survey\ncatalog. For the AGN samples at $z\\sim1$ and $z\\sim2$, we calculated AGN bias\nvalues of $b=1.16\\ (1.16;1.31)$ and $b=2.95\\ (2.30;3.55)$, respectively. These\nvalues correspond to typical host dark matter halo (DMH) masses of log$(M_{\\rm\ntyp}/M_{\\odot})=11.82\\ (11.82;12.12)$ and log$(M_{\\rm typ}/M_{\\odot})=12.80\\\n(12.38;13.06)$, respectively. Subsequently, we performed Halo Occupation\nDistribution (HOD) modeling of X-ray-selected AGNs using the CCF and ACF of\ngalaxies. We have found a significant satellite AGN population at $z\\sim 1$ all\nover the DMH mass ($M_{\\rm DMH}$) range occupied by AGNs. While $z\\sim 2$ AGNs\nin our sample are associated with higher mass DMHs and smaller satellite\nfractions. The HOD analysis suggests a marginal tendency of increasing\nsatellite slope with redshift, but larger samples are needed to confirm this\nwith sufficient statistical significance. We find that the best-fit values of\nsatellite slope in both redshift bins are greater than 0, suggesting tendencies\nof increasing satellite AGN number with $M_{\\rm DMH}$.",
    "pdf_url": "http://arxiv.org/pdf/2502.10944v1",
    "published": "2025-02-16T01:29:09+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2502.10943v1",
    "title": "Spectral analysis of spatial-sign covariance matrices for heavy-tailed data with dependence",
    "authors": [
      "Hantao Chen",
      "Cheng Wang"
    ],
    "abstract": "This paper investigates the spectral properties of spatial-sign covariance\nmatrices, a self-normalized version of sample covariance matrices, for data\nfrom $\\alpha$-regularly varying populations with general covariance structures.\nBy exploiting the elegant properties of self-normalized random variables, we\nestablish the limiting spectral distribution and a central limit theorem for\nlinear spectral statistics. We demonstrate that the Mar{\\u{c}}enko-Pastur\nequation holds under the condition $\\alpha \\geq 2$, while the central limit\ntheorem for linear spectral statistics is valid for $\\alpha>4$, which are shown\nto be nearly the weakest possible conditions for spatial-sign covariance\nmatrices from heavy-tailed data in the presence of dependence.",
    "pdf_url": "http://arxiv.org/pdf/2502.10943v1",
    "published": "2025-02-16T01:22:03+00:00",
    "categories": [
      "math.ST",
      "stat.TH",
      "62H10, 62E17"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2502.10942v2",
    "title": "Exploring Contextual Flux in Large Language Models: A Novel Approach to Self-Modulating Semantic Networks",
    "authors": [
      "Henry Evidail",
      "Zachary Mountebank",
      "Alistair Hathersage",
      "Peter Stanhope",
      "Basil Ravenscroft",
      "Tobias Waddingham"
    ],
    "abstract": "Self-modulating mechanisms introduce dynamic adaptation capabilities within\nlanguage models through contextual realignment strategies that influence token\nembedding trajectories across extended sequences. Contextual Flux is explored\nas an approach to embedding modulation, integrating an auxiliary gating\nmechanism within the self-attention framework to dynamically adjust token\nrepresentations based on evolving contextual dependencies. The empirical\nanalysis evaluates entropy variations, latent space realignments, and coherence\nstability to assess the extent to which self-regulation enhances text\ngeneration consistency while preserving generative flexibility. Quantitative\nassessments suggest that embedding shifts contribute to more structured\nadaptation in long-form sequences, with measured reductions in redundant phrase\nrepetitions and improvements in thematic retention. Variability in contextual\nweight computation affects modulation stability, leading to differing levels of\nadaptation across diverse linguistic structures. The computational demands\nintroduced through real-time embedding reconfiguration are examined in relation\nto model scalability, emphasizing the need for optimization strategies in\nhigh-volume generative applications. The findings suggest that while adaptive\nembedding updates improve certain aspects of coherence, their impact remains\ncontingent on model capacity and input complexity.",
    "pdf_url": "http://arxiv.org/pdf/2502.10942v2",
    "published": "2025-02-16T01:08:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2502.10941v1",
    "title": "Compact Turnkey Soliton Microcombs at Microwave Rates via Wafer-Scale Fabrication",
    "authors": [
      "Yuanlei Wang",
      "Ze Wang",
      "Chenghao Lao",
      "Tianyu Xu",
      "Yinke Cheng",
      "Zhenyu Xie",
      "Junqi Wang",
      "Haoyang Luo",
      "Xin Zhou",
      "Bo Ni",
      "Kaixuan Zhu",
      "Yanwu Liu",
      "Xing Jin",
      "Min Wang",
      "Jian-Fei Liu",
      "Xuening Cao",
      "Ting Wang",
      "Qihuang Gong",
      "Bei-Bei Li",
      "Fangxing Zhang",
      "Yun-Feng Xiao",
      "Qi-Fan Yang"
    ],
    "abstract": "Soliton microcombs generated in nonlinear microresonators facilitate the\nphotonic integration of timing, frequency synthesis, and astronomical\ncalibration functionalities. For these applications, low-repetition-rate\nsoliton microcombs are essential as they establish a coherent link between\noptical and microwave signals. However, the required pump power typically\nscales with the inverse of the repetition rate, and the device footprint scales\nwith the inverse of square of the repetition rate, rendering\nlow-repetition-rate soliton microcombs challenging to integrate within photonic\ncircuits. This study designs and fabricates silicon nitride microresonators on\n4-inch wafers with highly compact form factors. The resonator geometries are\nengineered from ring to finger and spiral shapes to enhance integration density\nwhile attaining quality factors over 10^7. Driven directly by an integrated\nlaser, soliton microcombs with repetition rates below 10 GHz are demonstrated\nvia turnkey initiation. The phase noise performance of the synthesized\nmicrowave signals reaches -130 dBc/Hz at 100 kHz offset frequency for 10 GHz\ncarrier frequencies. This work enables the high-density integration of soliton\nmicrocombs for chip-based microwave photonics and spectroscopy applications.",
    "pdf_url": "http://arxiv.org/pdf/2502.10941v1",
    "published": "2025-02-16T01:06:26+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2502.10940v2",
    "title": "CoLA: Compute-Efficient Pre-Training of LLMs via Low-Rank Activation",
    "authors": [
      "Ziyue Liu",
      "Ruijie Zhang",
      "Zhengyang Wang",
      "Zi Yang",
      "Paul Hovland",
      "Bogdan Nicolae",
      "Franck Cappello",
      "Zheng Zhang"
    ],
    "abstract": "The full-size MLPs and the projection layers in attention introduce\ntremendous model sizes of large language models (LLMs), imposing extremely\ndemanding needs of computational resources in the pre-training stage. However,\nwe empirically observe that the activations of pre-trained LLMs exhibit\nlow-rank property. Motivated by such observations, we propose CoLA and its\nmemory-efficient implementation, CoLA-M, to replace these full-size layers with\ncompute-efficient auto-encoders that naturally enforce low-rank activations\nthroughout training. This fundamental architectural change eliminates the\nactivation redundancy and significantly boosts model capacity and training\nefficiency. Experiments on LLaMA models with 60 million to 7 billion parameters\nshow that CoLA reduces the computing cost by $\\bf 2\\pmb{\\times}$ and improves\ntraining throughput by $\\bf 1.86\\pmb{\\times}$ while maintaining full-rank level\nperformance. CoLA-M further squeezes memory cost without sacrificing\nthroughput, offering a pre-training approach with collectively superior\nparameter, computing, and memory efficiency. The LLMs produced are also $\\bf\n2\\pmb{\\times}$ smaller, enabling faster inference with lower memory cost on\nresource-constrained platforms.",
    "pdf_url": "http://arxiv.org/pdf/2502.10940v2",
    "published": "2025-02-16T01:05:16+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.10939v1",
    "title": "Model-assisted inference for dynamic causal effects in staggered rollout cluster randomized experiments",
    "authors": [
      "Xinyuan Chen",
      "Fan Li"
    ],
    "abstract": "Staggered rollout cluster randomized experiments (SR-CREs) are increasingly\nused for their practical feasibility and logistical convenience. These designs\ninvolve staggered treatment adoption across clusters, requiring analysis\nmethods that account for an exhaustive class of dynamic causal effects,\nanticipation, and non-ignorable cluster-period sizes. Without imposing outcome\nmodeling assumptions, we study regression estimators using individual data,\ncluster-period averages, and scaled cluster-period totals, with and without\ncovariate adjustment from a design-based perspective, where only the treatment\nadoption time is random. We establish consistency and asymptotic normality of\neach regression estimator under a finite-population framework and formally\nprove that the associated variance estimators are asymptotically conservative\nin the Lowner ordering. Furthermore, we conduct a unified efficiency comparison\nof the estimators and provide practical recommendations. We highlight the\nefficiency advantage of using estimators based on scaled cluster-period totals\nwith covariate adjustment over their counterparts using individual-level data\nand cluster-period averages. Our results rigorously justify linear regression\nestimators as model-assisted methods to address an entire class of dynamic\ncausal effects in SR-CREs and significantly expand those developed for\nparallel-arm CREs by Su and Ding (JRSSB, 2021) to accommodate a wider class of\ncomplex experimental settings with staggered randomization.",
    "pdf_url": "http://arxiv.org/pdf/2502.10939v1",
    "published": "2025-02-16T00:51:04+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2502.12198v1",
    "title": "Maximize Your Diffusion: A Study into Reward Maximization and Alignment for Diffusion-based Control",
    "authors": [
      "Dom Huh",
      "Prasant Mohapatra"
    ],
    "abstract": "Diffusion-based planning, learning, and control methods present a promising\nbranch of powerful and expressive decision-making solutions. Given the growing\ninterest, such methods have undergone numerous refinements over the past years.\nHowever, despite these advancements, existing methods are limited in their\ninvestigations regarding general methods for reward maximization within the\ndecision-making process. In this work, we study extensions of fine-tuning\napproaches for control applications. Specifically, we explore extensions and\nvarious design choices for four fine-tuning approaches: reward alignment\nthrough reinforcement learning, direct preference optimization, supervised\nfine-tuning, and cascading diffusion. We optimize their usage to merge these\nindependent efforts into one unified paradigm. We show the utility of such\npropositions in offline RL settings and demonstrate empirical improvements over\na rich array of control tasks.",
    "pdf_url": "http://arxiv.org/pdf/2502.12198v1",
    "published": "2025-02-16T00:30:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2502.10938v1",
    "title": "PEA: Enhancing LLM Performance on Computational-Reasoning Tasks",
    "authors": [
      "Zi Wang",
      "Shiwei Weng",
      "Mohannad Alhanahnah",
      "Somesh Jha",
      "Tom Reps"
    ],
    "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities across\ndiverse domains, prompting investigations into their potential as generic\nreasoning engines. While recent studies have explored inference-time\ncomputation to enhance model performance on complex problems, current research\nlacks a formal framework to characterize the complexity of reasoning tasks.\nThis study introduces the Predicate-Enumeration-Aggregation (PEA) framework, a\nformal approach to describe and solve a class of important reasoning tasks\ntermed computational reasoning problems. The PEA framework decomposes these\nproblems into predicate and enumeration components, using LLMs to synthesize\nprograms based on specified predicates, enumeration, and aggregation rules.\nThese synthesized programs are then executed to obtain solutions to the\ncomputational tasks. We demonstrate the framework's efficacy on benchmark tasks\nincluding Boolean satisfiability problems, game of $24$, and planning problems.\nEmpirical evaluation reveals that PEA substantially enhances the performance of\nunderlying models on benchmark computational problems, yielding an average\naccuracy improvement of approximately $50\\%$, coupled with increased\nefficiency.",
    "pdf_url": "http://arxiv.org/pdf/2502.10938v1",
    "published": "2025-02-16T00:27:05+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.17474v2",
    "title": "Estimating Time Delays between Signals under Mixed Noise Influence with Novel Cross- and Bispectral Methods",
    "authors": [
      "Tin Jurhar",
      "Franziska Pellegrini",
      "Ana I. Nues del Toro",
      "Tilman Stephani",
      "Guido Nolte",
      "Stefan Haufe"
    ],
    "abstract": "A common problem to signal processing are biases introduced by correlated\nnoise. When quantifying time delays between two signals, mixed noise introduces\na bias towards zero delay in conventional delay estimates based on the cross-\nor bispectrum. Here we propose two novel time delay estimators that address\nthese shortcomings: (1) A cross-spectrum based approach that relies on\nestimating the periodicity of the phase spectrum rather than its slope, and (2)\na bispectrum based approach, bispectral antisymmetrization, which removes\ncontributions from not just Gaussian but all independent sources. In a\nsimulation study, we compare conventional and novel TDE approaches and resolve\ndifferences in performance with respect to noise Gaussianity and\nauto-correlation structure. As a proof-of concept, we also perform TDE analysis\non a neural stimulation dataset (n=3). We find that antisymmetrization\nconsistently outperforms conventional bispectral methods at low signal-to-noise\nratios (SNR) and prevents spurious zero-delay estimates in all mixed-noise\nenvironments. Time delay estimation based on phase periodicity also improves\nsignal sensitivity compared to conventional cross-spectral methods. These\nobservations are stable with respect to the magnitude of the delay and the\nstatistical properties of the noise.",
    "pdf_url": "http://arxiv.org/pdf/2502.17474v2",
    "published": "2025-02-16T00:19:48+00:00",
    "categories": [
      "eess.SP",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2502.10937v2",
    "title": "SCALE: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention",
    "authors": [
      "Chengshuai Zhao",
      "Zhen Tan",
      "Chau-Wai Wong",
      "Xinyan Zhao",
      "Tianlong Chen",
      "Huan Liu"
    ],
    "abstract": "Content analysis breaks down complex and unstructured texts into\ntheory-informed numerical categories. Particularly, in social science, this\nprocess usually relies on multiple rounds of manual annotation, domain expert\ndiscussion, and rule-based refinement. In this paper, we introduce SCALE, a\nnovel multi-agent framework that effectively $\\underline{\\textbf{S}}$imulates\n$\\underline{\\textbf{C}}$ontent $\\underline{\\textbf{A}}$nalysis via\n$\\underline{\\textbf{L}}$arge language model (LLM)\nag$\\underline{\\textbf{E}}$nts. SCALE imitates key phases of content analysis,\nincluding text coding, collaborative discussion, and dynamic codebook\nevolution, capturing the reflective depth and adaptive discussions of human\nresearchers. Furthermore, by integrating diverse modes of human intervention,\nSCALE is augmented with expert input to further enhance its performance.\nExtensive evaluations on real-world datasets demonstrate that SCALE achieves\nhuman-approximated performance across various complex content analysis tasks,\noffering an innovative potential for future social science research.",
    "pdf_url": "http://arxiv.org/pdf/2502.10937v2",
    "published": "2025-02-16T00:19:07+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2502.10936v1",
    "title": "Generalized principal eigenvalue of time-periodic cooperative nonlocal dispersal systems and applications",
    "authors": [
      "Mingxin Wang",
      "Lei Zhang"
    ],
    "abstract": "It is well known that, in the study of the dynamical properties of nonlinear\nreaction-diffusion systems, the sign of the principal eigenvalue of the\nlinearized system plays an important role. However, for the nonlocal dispersal\nsystems, due to the lack of compactness, the essential spectrum appear, and the\nprincipal eigenvalue may not exist. In this paper, by constructing monotonic\nupper and lower control systems, we obtain the generalized principal eigenvalue\nof the cooperative irreducible system and demonstrate that this generalized\nprincipal eigenvalue plays the same role as the usual principal eigenvalue.",
    "pdf_url": "http://arxiv.org/pdf/2502.10936v1",
    "published": "2025-02-16T00:01:56+00:00",
    "categories": [
      "math.AP",
      "math.CA",
      "35R20, 47G20, 47A75, 45M15, 92D30"
    ],
    "primary_category": "math.AP"
  }
]